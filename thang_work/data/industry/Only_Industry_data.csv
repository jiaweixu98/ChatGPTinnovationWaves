id_x,submitter,authors_x,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed,ContainChatGPT,ContainGPT,publish_date_v1,versionsNumber,authorNumber,categoryNumber,modelNumber,OpenModelNumber,CloseModelNumber,id_y,corpusId,url,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authors_y,Institute,Country,month_year,Institute Type
1903.11437,Franck Burlot,Franck Burlot and Fran\c{c}ois Yvon,Using Monolingual Data in Neural Machine Translation: a Systematic Study,"Published in the Proceedings of the Third Conference on Machine
  Translation (Research Papers), 2018",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural Machine Translation (MT) has radically changed the way systems are developed. A major difference with the previous generation (Phrase-Based MT) is the way monolingual target data, which often abounds, is used in these two paradigms. While Phrase-Based MT can seamlessly integrate very large language models trained on billions of sentences, the best option for Neural MT developers seems to be the generation of artificial parallel data through \textsl{back-translation} - a technique that fails to fully take advantage of existing datasets. In this paper, we conduct a systematic study of back-translation, comparing alternative uses of monolingual data, as well as multiple data generation procedures. Our findings confirm that back-translation is very effective and give new explanations as to why this is the case. We also introduce new data simulation techniques that are almost as effective, yet much cheaper to implement. ","[{'version': 'v1', 'created': 'Wed, 27 Mar 2019 14:11:18 GMT'}]",2019-03-28,"[['Burlot', 'Franck', ''], ['Yvon', 'François', '']]",0,0,2019-03-27,1,2,1,0,0,0,e6deb7f451931b28bc6936d5fa703bc392c4cf4c,53222583.0,https://www.semanticscholar.org/paper/e6deb7f451931b28bc6936d5fa703bc392c4cf4c,Conference on Machine Translation,2018.0,40.0,85.0,8.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '3456893', 'name': 'Franck Burlot'}, {'authorId': '1846431', 'name': 'François Yvon'}]","['Lingua Custodia 1, Place Charles de Gaulle 78180 Montigny-le-Bretonneux', 'French National Centre for Scientific Research']",['France'],2019-03,"['industrial', 'industrial']"
1904.05152,Alessandro Seganti,"Alessandro Seganti, Helena Sobol, Iryna Orlova, Hannam Kim, Jakub
  Staniszewski, Tymoteusz Krumholc, Krystian Koziel",NLPR@SRPOL at SemEval-2019 Task 6 and Task 5: Linguistically enhanced deep learning offensive sentence classifier,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper presents a system developed for the SemEval-2019 competition Task 5 hat-Eval Basile et al. (2019) (team name: LU Team) and Task 6 OffensEval Zampieri et al. (2019b) (team name: NLPR@SRPOL), where we achieved 2nd position in Subtask C. The system combines in an ensemble several models (LSTM, Transformer, OpenAI's GPT, Random forest, SVM) with various embeddings (custom, ELMo, fastText, Universal Encoder) together with additional linguistic features (number of blacklisted words, special characters, etc.). The system works with a multi-tier blacklist and a large corpus of crawled data, annotated for general offensiveness. In the paper we do an extensive analysis of our results and show how the combination of features and embedding affect the performance of the models. ","[{'version': 'v1', 'created': 'Wed, 10 Apr 2019 12:56:50 GMT'}]",2019-04-11,"[['Seganti', 'Alessandro', ''], ['Sobol', 'Helena', ''], ['Orlova', 'Iryna', ''], ['Kim', 'Hannam', ''], ['Staniszewski', 'Jakub', ''], ['Krumholc', 'Tymoteusz', ''], ['Koziel', 'Krystian', '']]",0,1,2019-04-10,1,7,1,0,0,0,0aacc3d2af7eb6e50dbc83949ee056096379055e,131773893.0,https://www.semanticscholar.org/paper/0aacc3d2af7eb6e50dbc83949ee056096379055e,International Workshop on Semantic Evaluation,2019.0,39.0,18.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46539208', 'name': 'Alessandro Seganti'}, {'authorId': '108527573', 'name': 'Helena Sobol'}, {'authorId': '2065377788', 'name': 'Iryna Orlova'}, {'authorId': '107928214', 'name': 'Hannam Kim'}, {'authorId': '103958013', 'name': 'J. Staniszewski'}, {'authorId': '108284000', 'name': 'Tymoteusz Krumholc'}, {'authorId': '2066149234', 'name': 'Krystian Koziel'}]",['Samsung'],"['South Korea', 'Poland']",2019-04,['industrial']
1904.13258,Samuel Thomas,"Samuel Thomas, Masayuki Suzuki, Yinghui Huang, Gakuto Kurata, Zoltan
  Tuske, George Saon, Brian Kingsbury, Michael Picheny, Tom Dibert, Alice
  Kaiser-Schatzlein, Bern Samko",English Broadcast News Speech Recognition by Humans and Machines,"\copyright 2019 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works",,10.1109/ICASSP.2019.8683211,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With recent advances in deep learning, considerable attention has been given to achieving automatic speech recognition performance close to human performance on tasks like conversational telephone speech (CTS) recognition. In this paper we evaluate the usefulness of these proposed techniques on broadcast news (BN), a similar challenging task. We also perform a set of recognition measurements to understand how close the achieved automatic speech recognition results are to human performance on this task. On two publicly available BN test sets, DEV04F and RT04, our speech recognition system using LSTM and residual network based acoustic models with a combination of n-gram and neural network language models performs at 6.5% and 5.9% word error rate. By achieving new performance milestones on these test sets, our experiments show that techniques developed on other related tasks, like CTS, can be transferred to achieve similar performance. In contrast, the best measured human recognition performance on these test sets is much lower, at 3.6% and 2.8% respectively, indicating that there is still room for new techniques and improvements in this space, to reach human performance levels. ","[{'version': 'v1', 'created': 'Tue, 30 Apr 2019 13:59:18 GMT'}]",2019-05-01,"[['Thomas', 'Samuel', ''], ['Suzuki', 'Masayuki', ''], ['Huang', 'Yinghui', ''], ['Kurata', 'Gakuto', ''], ['Tuske', 'Zoltan', ''], ['Saon', 'George', ''], ['Kingsbury', 'Brian', ''], ['Picheny', 'Michael', ''], ['Dibert', 'Tom', ''], ['Kaiser-Schatzlein', 'Alice', ''], ['Samko', 'Bern', '']]",0,0,2019-04-30,1,11,3,0,0,0,cac802fb42d8d806dfcad22973e4c10a133bb98c,140220003.0,https://www.semanticscholar.org/paper/cac802fb42d8d806dfcad22973e4c10a133bb98c,"IEEE International Conference on Acoustics, Speech, and Signal Processing",2019.0,24.0,14.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '152809214', 'name': 'Samuel Thomas'}, {'authorId': '2218438720', 'name': 'Masayuki Suzuki'}, {'authorId': '1500662534', 'name': 'Yinghui Huang'}, {'authorId': '1787226', 'name': 'Gakuto Kurata'}, {'authorId': '1790221', 'name': 'Zoltán Tüske'}, {'authorId': '1698208', 'name': 'G. Saon'}, {'authorId': '144707379', 'name': 'Brian Kingsbury'}, {'authorId': '1774515', 'name': 'M. Picheny'}, {'authorId': '1414379458', 'name': 'Tom Dibert'}, {'authorId': '1410751226', 'name': 'Alice Kaiser-Schatzlein'}, {'authorId': '70702579', 'name': 'Bern Samko'}]","['IBM Research - Tokyo', 'IBM Research - Thomas J. Watson Research Center']","['United States', 'Japan']",2019-04,"['industrial', 'industrial']"
1906.03088,"Marc H\""ubner","Christoph Alt, Marc H\""ubner, Leonhard Hennig",Improving Relation Extraction by Pre-trained Language Representations,Code and models available at: https://github.com/DFKI-NLP/TRE,Proceedings of AKBC 2019,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current state-of-the-art relation extraction methods typically rely on a set of lexical, syntactic, and semantic features, explicitly computed in a pre-processing step. Training feature extraction models requires additional annotated language resources, which severely restricts the applicability and portability of relation extraction to novel languages. Similarly, pre-processing introduces an additional source of error. To address these limitations, we introduce TRE, a Transformer for Relation Extraction, extending the OpenAI Generative Pre-trained Transformer [Radford et al., 2018]. Unlike previous relation extraction models, TRE uses pre-trained deep language representations instead of explicit linguistic features to inform the relation classification and combines it with the self-attentive Transformer architecture to effectively model long-range dependencies between entity mentions. TRE allows us to learn implicit linguistic features solely from plain text corpora by unsupervised pre-training, before fine-tuning the learned language representations on the relation extraction task. TRE obtains a new state-of-the-art result on the TACRED and SemEval 2010 Task 8 datasets, achieving a test F1 of 67.4 and 87.1, respectively. Furthermore, we observe a significant increase in sample efficiency. With only 20% of the training examples, TRE matches the performance of our baselines and our model trained from scratch on 100% of the TACRED dataset. We open-source our trained models, experiments, and source code. ","[{'version': 'v1', 'created': 'Fri, 7 Jun 2019 13:31:09 GMT'}]",2019-06-10,"[['Alt', 'Christoph', ''], ['Hübner', 'Marc', ''], ['Hennig', 'Leonhard', '']]",0,1,2019-06-07,1,3,1,0,0,0,28f3a20ebd5e2f3afa871b1784076cf7004415b8,54023707.0,https://www.semanticscholar.org/paper/28f3a20ebd5e2f3afa871b1784076cf7004415b8,Conference on Automated Knowledge Base Construction,2019.0,34.0,71.0,9.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3413117', 'name': 'Christoph Alt'}, {'authorId': '143914106', 'name': 'Marc Hübner'}, {'authorId': '36943315', 'name': 'Leonhard Hennig'}]",['German Research Centre for Artificial Intelligence'],['Germany'],2019-06,['industrial']
1906.05714,Jesse Vig,Jesse Vig,A Multiscale Visualization of Attention in the Transformer Model,"To appear in ACL 2019 (System Demonstrations). arXiv admin note:
  substantial text overlap with arXiv:1904.02679",,,,cs.HC cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior. ","[{'version': 'v1', 'created': 'Wed, 12 Jun 2019 15:45:26 GMT'}]",2019-06-14,"[['Vig', 'Jesse', '']]",0,1,2019-06-12,1,1,3,1,1,0,0de0a44b859a3719d11834479112314b4caba669,189762556.0,https://www.semanticscholar.org/paper/0de0a44b859a3719d11834479112314b4caba669,Annual Meeting of the Association for Computational Linguistics,2019.0,21.0,417.0,18.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2056908', 'name': 'Jesse Vig'}]",['Palo Alto Research Center'],['United States'],2019-06,['industrial']
1906.08646,Christoph Alt,"Christoph Alt, Marc H\""ubner, Leonhard Hennig",Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction,"To appear in Proceedings of ACL 2019 (11 pages). arXiv admin note:
  text overlap with arXiv:1906.03088",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distantly supervised relation extraction is widely used to extract relational facts from text, but suffers from noisy labels. Current relation extraction methods try to alleviate the noise by multi-instance learning and by providing supporting linguistic and contextual information to more efficiently guide the relation classification. While achieving state-of-the-art results, we observed these models to be biased towards recognizing a limited set of relations with high precision, while ignoring those in the long tail. To address this gap, we utilize a pre-trained language model, the OpenAI Generative Pre-trained Transformer (GPT) [Radford et al., 2018]. The GPT and similar models have been shown to capture semantic and syntactic features, and also a notable amount of ""common-sense"" knowledge, which we hypothesize are important features for recognizing a more diverse set of relations. By extending the GPT to the distantly supervised setting, and fine-tuning it on the NYT10 dataset, we show that it predicts a larger set of distinct relation types with high confidence. Manual and automated evaluation of our model shows that it achieves a state-of-the-art AUC score of 0.422 on the NYT10 dataset, and performs especially well at higher recall levels. ","[{'version': 'v1', 'created': 'Wed, 19 Jun 2019 11:04:51 GMT'}]",2019-06-21,"[['Alt', 'Christoph', ''], ['Hübner', 'Marc', ''], ['Hennig', 'Leonhard', '']]",0,1,2019-06-19,1,3,1,0,0,0,68e686817f2c33cd09ba3805fa082348f18affd9,195218574.0,https://www.semanticscholar.org/paper/68e686817f2c33cd09ba3805fa082348f18affd9,Annual Meeting of the Association for Computational Linguistics,2019.0,46.0,101.0,24.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3413117', 'name': 'Christoph Alt'}, {'authorId': '143914106', 'name': 'Marc Hübner'}, {'authorId': '36943315', 'name': 'Leonhard Hennig'}]",['German Research Centre for Artificial Intelligence'],['Germany'],2019-06,['industrial']
1907.00151,Yi Liao,"Yi Liao, Yasheng Wang, Qun Liu, Xin Jiang",GPT-based Generation for Classical Chinese Poetry,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a simple yet effective method for generating high quality classical Chinese poetry with Generative Pre-trained Language Model (GPT). The method adopts a simple GPT model, without using any human crafted rules or features, or designing any additional neural components. While the proposed model learns to generate various forms of classical Chinese poems, including Jueju, L\""{u}shi, various Cipai and Couples, the generated poems are of very high quality. We also propose and implement a method to fine-tune the model to generate acrostic poetry. To the best of our knowledge, this is the first to employ GPT in developing a poetry generation system. We have released an online mini demonstration program on Wechat to show the generation capability of the proposed method for classical Chinese poetry. ","[{'version': 'v1', 'created': 'Sat, 29 Jun 2019 06:04:48 GMT'}, {'version': 'v2', 'created': 'Tue, 2 Jul 2019 14:18:55 GMT'}, {'version': 'v3', 'created': 'Wed, 3 Jul 2019 12:55:06 GMT'}, {'version': 'v4', 'created': 'Fri, 12 Jul 2019 05:44:58 GMT'}, {'version': 'v5', 'created': 'Thu, 5 Sep 2019 02:34:36 GMT'}]",2019-09-06,"[['Liao', 'Yi', ''], ['Wang', 'Yasheng', ''], ['Liu', 'Qun', ''], ['Jiang', 'Xin', '']]",0,1,2019-06-29,5,4,2,0,0,0,83b56c3c7a61767bd88d85796aa5dbc4976912c3,195767456.0,https://www.semanticscholar.org/paper/83b56c3c7a61767bd88d85796aa5dbc4976912c3,arXiv.org,2019.0,15.0,32.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2048004675', 'name': 'Yi Liao'}, {'authorId': '2108738457', 'name': 'Yasheng Wang'}, {'authorId': '30738758', 'name': 'Qun Liu'}, {'authorId': '145820291', 'name': 'Xin Jiang'}]",['Huawei Technologies (China)'],['China'],2019-06,['industrial']
1910.04732,Jeremy Wohlwend,"Ziheng Wang, Jeremy Wohlwend, Tao Lei",Structured Pruning of Large Language Models,,,10.18653/v1/2020.emnlp-main.496,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models have recently achieved state of the art performance across a wide variety of natural language tasks. Meanwhile, the size of these models and their latency have significantly increased, which makes their usage costly, and raises an interesting question: do language models need to be large? We study this question through the lens of model compression. We present a generic, structured pruning approach by parameterizing each weight matrix using its low-rank factorization, and adaptively removing rank-1 components during training. On language modeling tasks, our structured approach outperforms other unstructured and block-structured pruning baselines at various compression levels, while achieving significant speedups during both training and inference. We also demonstrate that our method can be applied to pruning adaptive word embeddings in large language models, and to pruning the BERT model on several downstream fine-tuning classification benchmarks. ","[{'version': 'v1', 'created': 'Thu, 10 Oct 2019 17:44:18 GMT'}, {'version': 'v2', 'created': 'Sun, 28 Mar 2021 19:04:25 GMT'}]",2021-03-30,"[['Wang', 'Ziheng', ''], ['Wohlwend', 'Jeremy', ''], ['Lei', 'Tao', '']]",0,0,2019-10-10,2,3,3,0,0,0,83b8108014e3db4f46354a28ae68193f143c4e7e,204009154.0,https://www.semanticscholar.org/paper/83b8108014e3db4f46354a28ae68193f143c4e7e,Conference on Empirical Methods in Natural Language Processing,2019.0,62.0,164.0,23.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2860279', 'name': 'Ziheng Wang'}, {'authorId': '39749986', 'name': 'Jeremy Wohlwend'}, {'authorId': '49986267', 'name': 'Tao Lei'}]","['ASAPP, Inc.']",,2019-10,['industrial']
1910.05276,Sebastian Gehrmann,"Benjamin Hoover, Hendrik Strobelt, Sebastian Gehrmann",exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models can produce powerful contextual representations that lead to improvements across many NLP tasks. Since these models are typically guided by a sequence of learned self attention mechanisms and may comprise undesired inductive biases, it is paramount to be able to explore what the attention has learned. While static analyses of these models lead to targeted insights, interactive tools are more dynamic and can help humans better gain an intuition for the model-internal reasoning process. We present exBERT, an interactive tool named after the popular BERT language model, that provides insights into the meaning of the contextual representations by matching a human-specified input to similar contexts in a large annotated dataset. By aggregating the annotations of the matching similar contexts, exBERT helps intuitively explain what each attention-head has learned. ","[{'version': 'v1', 'created': 'Fri, 11 Oct 2019 16:10:55 GMT'}]",2019-10-14,"[['Hoover', 'Benjamin', ''], ['Strobelt', 'Hendrik', ''], ['Gehrmann', 'Sebastian', '']]",0,0,2019-10-11,1,3,2,0,0,0,327d7e55d64cb34d55bd3a3fe58233c238a312cd,204402756.0,https://www.semanticscholar.org/paper/327d7e55d64cb34d55bd3a3fe58233c238a312cd,arXiv.org,2019.0,25.0,97.0,4.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '2061407009', 'name': 'Benjamin Hoover'}, {'authorId': '2879705', 'name': 'Hendrik Strobelt'}, {'authorId': '3159346', 'name': 'Sebastian Gehrmann'}]",['MIT-IBM Watson AI Lab'],['United States'],2019-10,['industrial']
1910.06188,Ofir Zafrir,"Ofir Zafrir, Guy Boudoukh, Peter Izsak, Moshe Wasserblat",Q8BERT: Quantized 8Bit BERT,"5 Pages, Accepted at the 5th Workshop on Energy Efficient Machine
  Learning and Cognitive Computing - NeurIPS 2019",,10.1109/EMC2-NIPS53020.2019.00016,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, pre-trained Transformer based language models such as BERT and GPT, have shown great improvement in many Natural Language Processing (NLP) tasks. However, these models contain a large amount of parameters. The emergence of even larger and more accurate models such as GPT2 and Megatron, suggest a trend of large pre-trained Transformer models. However, using these large models in production environments is a complex task requiring a large amount of compute, memory and power resources. In this work we show how to perform quantization-aware training during the fine-tuning phase of BERT in order to compress BERT by $4\times$ with minimal accuracy loss. Furthermore, the produced quantized model can accelerate inference speed if it is optimized for 8bit Integer supporting hardware. ","[{'version': 'v1', 'created': 'Mon, 14 Oct 2019 14:55:19 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Oct 2019 17:15:24 GMT'}]",2021-12-20,"[['Zafrir', 'Ofir', ''], ['Boudoukh', 'Guy', ''], ['Izsak', 'Peter', ''], ['Wasserblat', 'Moshe', '']]",0,1,2019-10-14,2,4,2,1,1,0,ce106590145e89ea4b621c99665862967ccf5dac,204509218.0,https://www.semanticscholar.org/paper/ce106590145e89ea4b621c99665862967ccf5dac,2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS),2019.0,18.0,363.0,27.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1387202086', 'name': 'Ofir Zafrir'}, {'authorId': '3150063', 'name': 'Guy Boudoukh'}, {'authorId': '2477428', 'name': 'Peter Izsak'}, {'authorId': '2134755', 'name': 'Moshe Wasserblat'}]",['Intel'],['United States'],2019-10,['industrial']
1910.08381,Ming Gong,"Ze Yang, Linjun Shou, Ming Gong, Wutao Lin, Daxin Jiang",Model Compression with Two-stage Multi-teacher Knowledge Distillation for Web Question Answering System,Accepted by WSDM 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep pre-training and fine-tuning models (such as BERT and OpenAI GPT) have demonstrated excellent results in question answering areas. However, due to the sheer amount of model parameters, the inference speed of these models is very slow. How to apply these complex models to real business scenarios becomes a challenging but practical problem. Previous model compression methods usually suffer from information loss during the model compression procedure, leading to inferior models compared with the original one. To tackle this challenge, we propose a Two-stage Multi-teacher Knowledge Distillation (TMKD for short) method for web Question Answering system. We first develop a general Q\&A distillation task for student model pre-training, and further fine-tune this pre-trained student model with multi-teacher knowledge distillation on downstream tasks (like Web Q\&A task, MNLI, SNLI, RTE tasks from GLUE), which effectively reduces the overfitting bias in individual teacher models, and transfers more general knowledge to the student model. The experiment results show that our method can significantly outperform the baseline methods and even achieve comparable results with the original teacher models, along with substantial speedup of model inference. ","[{'version': 'v1', 'created': 'Fri, 18 Oct 2019 12:36:52 GMT'}]",2019-10-21,"[['Yang', 'Ze', ''], ['Shou', 'Linjun', ''], ['Gong', 'Ming', ''], ['Lin', 'Wutao', ''], ['Jiang', 'Daxin', '']]",0,1,2019-10-18,1,5,1,0,0,0,3de9d381813ec99441a55f248c41570410e4062b,204788964.0,https://www.semanticscholar.org/paper/3de9d381813ec99441a55f248c41570410e4062b,Web Search and Data Mining,2019.0,31.0,71.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1971985', 'name': 'Ze Yang'}, {'authorId': '24962156', 'name': 'Linjun Shou'}, {'authorId': '50175330', 'name': 'Ming Gong'}, {'authorId': '5617558', 'name': 'Wutao Lin'}, {'authorId': '71790825', 'name': 'Daxin Jiang'}]",['Microsoft'],"['United States', 'United Kingdom']",2019-10,['industrial']
1911.02365,Tassilo Klein,"Tassilo Klein, Moin Nabi",Learning to Answer by Learning to Ask: Getting the Best of GPT-2 and BERT Worlds,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic question generation aims at the generation of questions from a context, with the corresponding answers being sub-spans of the given passage. Whereas, most of the methods mostly rely on heuristic rules to generate questions, more recently also neural network approaches have been proposed. In this work, we propose a variant of the self-attention Transformer network architectures model to generate meaningful and diverse questions. To this end, we propose an easy to use model consisting of the conjunction of the Transformer decoder GPT-2 model with Transformer encoder BERT for the downstream task for question answering. The model is trained in an end-to-end fashion, where the language model is trained to produce a question-answer-aware input representation that facilitates to generate an answer focused question. Our result of neural question generation from text on the SQuAD 1.1 dataset suggests that our method can produce semantically correct and diverse questions. Additionally, we assessed the performance of our proposed method for the downstream task of question answering. The analysis shows that our proposed generation & answering collaboration framework relatively improves both tasks and is particularly powerful in the semi-supervised setup. The results further suggest a robust and comparably lean pipeline facilitating question generation in the small-data regime. ","[{'version': 'v1', 'created': 'Wed, 6 Nov 2019 13:23:41 GMT'}]",2019-11-07,"[['Klein', 'Tassilo', ''], ['Nabi', 'Moin', '']]",0,1,2019-11-06,1,2,3,1,1,0,c1ac3fbf530bf2eb207aa1a20dd14c8ed9f6766b,207880647.0,https://www.semanticscholar.org/paper/c1ac3fbf530bf2eb207aa1a20dd14c8ed9f6766b,arXiv.org,2019.0,27.0,51.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35660331', 'name': 'T. Klein'}, {'authorId': '1848946', 'name': 'Moin Nabi'}]","['SAP Machine Learning Research, Berlin, Germany']",['Germany'],2019-11,['industrial']
1911.03597,Yinpeng Guo,"Yinpeng Guo, Yi Liao, Xin Jiang, Qing Zhang, Yibo Zhang, Qun Liu",Zero-Shot Paraphrase Generation with Multilingual Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Leveraging multilingual parallel texts to automatically generate paraphrases has drawn much attention as size of high-quality paraphrase corpus is limited. Round-trip translation, also known as the pivoting method, is a typical approach to this end. However, we notice that the pivoting process involves multiple machine translation models and is likely to incur semantic drift during the two-step translations. In this paper, inspired by the Transformer-based language models, we propose a simple and unified paraphrasing model, which is purely trained on multilingual parallel data and can conduct zero-shot paraphrase generation in one step. Compared with the pivoting approach, paraphrases generated by our model is more semantically similar to the input sentence. Moreover, since our model shares the same architecture as GPT (Radford et al., 2018), we are able to pre-train the model on large-scale unparallel corpus, which further improves the fluency of the output sentences. In addition, we introduce the mechanism of denoising auto-encoder (DAE) to improve diversity and robustness of the model. Experimental results show that our model surpasses the pivoting method in terms of relevance, diversity, fluency and efficiency. ","[{'version': 'v1', 'created': 'Sat, 9 Nov 2019 02:49:31 GMT'}]",2019-11-12,"[['Guo', 'Yinpeng', ''], ['Liao', 'Yi', ''], ['Jiang', 'Xin', ''], ['Zhang', 'Qing', ''], ['Zhang', 'Yibo', ''], ['Liu', 'Qun', '']]",0,1,2019-11-09,1,6,1,0,0,0,68d8eced6b881e408a61bd2dd642c5a11ebb9192,207852917.0,https://www.semanticscholar.org/paper/68d8eced6b881e408a61bd2dd642c5a11ebb9192,arXiv.org,2019.0,33.0,20.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '121083081', 'name': 'Yinpeng Guo'}, {'authorId': '2048004675', 'name': 'Yi Liao'}, {'authorId': '145820291', 'name': 'Xin Jiang'}, {'authorId': '2112724233', 'name': 'Qing Zhang'}, {'authorId': '2107986486', 'name': 'Yibo Zhang'}, {'authorId': '1688015', 'name': 'Qun Liu'}]",['Huawei Technologies (China)'],['China'],2019-11,['industrial']
1911.09661,Martin Andrews,"Sam Witteveen, Martin Andrews",Paraphrasing with Large Language Models,"Accepted paper for WNGT workshop at EMNLP-IJCNLP 2019. (7 pages
  including references and supplemental material)",,10.18653/v1/D19-5623,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, large language models such as GPT-2 have shown themselves to be extremely adept at text generation and have also been able to achieve high-quality results in many downstream NLP tasks such as text classification, sentiment analysis and question answering with the aid of fine-tuning. We present a useful technique for using a large language model to perform the task of paraphrasing on a variety of texts and subjects. Our approach is demonstrated to be capable of generating paraphrases not only at a sentence level but also for longer spans of text such as paragraphs without needing to break the text into smaller chunks. ","[{'version': 'v1', 'created': 'Thu, 21 Nov 2019 18:45:54 GMT'}]",2019-11-22,"[['Witteveen', 'Sam', ''], ['Andrews', 'Martin', '']]",0,1,2019-11-21,1,2,2,1,1,0,aa68ea557777908e76f02c433f14ef6b968d4a82,208092413.0,https://www.semanticscholar.org/paper/aa68ea557777908e76f02c433f14ef6b968d4a82,Conference on Empirical Methods in Natural Language Processing,2019.0,26.0,60.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '115583560', 'name': 'Sam Witteveen'}, {'authorId': '145054309', 'name': 'Martin Andrews'}]",['Red Dragon AI'],,2019-11,['industrial']
1912.00742,Alexey Svyatkovskiy,"Alexey Svyatkovskiy, Ying Zhao, Shengyu Fu, Neel Sundaresan",Pythia: AI-assisted Code Completion System,"Published in Proceedings of the 25th ACM SIGKDD International
  Conference on Knowledge Discovery & Data Mining (KDD '19)",,10.1145/3292500.3330699,,cs.SE cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose a novel end-to-end approach for AI-assisted code completion called Pythia. It generates ranked lists of method and API recommendations which can be used by software developers at edit time. The system is currently deployed as part of Intellicode extension in Visual Studio Code IDE. Pythia exploits state-of-the-art large-scale deep learning models trained on code contexts extracted from abstract syntax trees. It is designed to work at a high throughput predicting the best matching code completions on the order of 100 $ms$.   We describe the architecture of the system, perform comparisons to frequency-based approach and invocation-based Markov Chain language model, and discuss challenges serving Pythia models on lightweight client devices.   The offline evaluation results obtained on 2700 Python open source software GitHub repositories show a top-5 accuracy of 92\%, surpassing the baseline models by 20\% averaged over classes, for both intra and cross-project settings. ","[{'version': 'v1', 'created': 'Fri, 29 Nov 2019 04:22:48 GMT'}]",2019-12-03,"[['Svyatkovskiy', 'Alexey', ''], ['Zhao', 'Ying', ''], ['Fu', 'Shengyu', ''], ['Sundaresan', 'Neel', '']]",0,0,2019-11-29,1,4,2,1,1,0,79b7a61abd4a4b4cf62c26cec815b55b0778f48d,196177632.0,https://www.semanticscholar.org/paper/79b7a61abd4a4b4cf62c26cec815b55b0778f48d,Knowledge Discovery and Data Mining,2019.0,22.0,107.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '47090739', 'name': 'Alexey Svyatkovskiy'}, {'authorId': '2118977303', 'name': 'Ying Zhao'}, {'authorId': '2072784644', 'name': 'Shengyu Fu'}, {'authorId': '145507437', 'name': 'Neel Sundaresan'}]",['Microsoft'],['United States'],2019-11,['industrial']
1912.05239,Stefano Nolfi,"Paolo Pagliuca, Nicola Milano, and Stefano Nolfi",Efficacy of Modern Neuro-Evolutionary Strategies for Continuous Control Optimization,"17 pages, 5 Figures, 4 Tables",,,,cs.NE cs.LG cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We analyze the efficacy of modern neuro-evolutionary strategies for continuous control optimization. Overall, the results collected on a wide variety of qualitatively different benchmark problems indicate that these methods are generally effective and scale well with respect to the number of parameters and the complexity of the problem. Moreover, they are relatively robust with respect to the setting of hyper-parameters. The comparison of the most promising methods indicates that the OpenAI-ES algorithm outperforms or equals the other algorithms on all considered problems. Moreover, we demonstrate how the reward functions optimized for reinforcement learning methods are not necessarily effective for evolutionary strategies and vice versa. This finding can lead to reconsideration of the relative efficacy of the two classes of algorithm since it implies that the comparisons performed to date are biased toward one or the other class. ","[{'version': 'v1', 'created': 'Wed, 11 Dec 2019 11:29:12 GMT'}, {'version': 'v2', 'created': 'Mon, 1 Jun 2020 09:50:08 GMT'}]",2020-06-02,"[['Pagliuca', 'Paolo', ''], ['Milano', 'Nicola', ''], ['Nolfi', 'Stefano', '']]",0,0,2019-12-11,2,3,3,0,0,0,6ae59a2ebba165609d6ce25a8725fc03157b0191,209202760.0,https://www.semanticscholar.org/paper/6ae59a2ebba165609d6ce25a8725fc03157b0191,Frontiers in Robotics and AI,2019.0,39.0,21.0,2.0,True,"['Computer Science', 'Medicine']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1873471', 'name': 'Paolo Pagliuca'}, {'authorId': '32302973', 'name': 'Nicola Milano'}, {'authorId': '3015062', 'name': 'S. Nolfi'}]",['National Research Council'],['Italy'],2019-12,['industrial']
2004.02644,Pedro Henrique Martins,Pedro Henrique Martins and Zita Marinho and Andr\'e F. T. Martins,Sparse Text Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current state-of-the-art text generators build on powerful language models such as GPT-2, achieving impressive performance. However, to avoid degenerate text, they require sampling from a modified softmax, via temperature parameters or ad-hoc truncation techniques, as in top-$k$ or nucleus sampling. This creates a mismatch between training and testing conditions. In this paper, we use the recently introduced entmax transformation to train and sample from a natively sparse language model, avoiding this mismatch. The result is a text generator with favorable performance in terms of fluency and consistency, fewer repetitions, and n-gram diversity closer to human text. In order to evaluate our model, we propose three new metrics for comparing sparse or truncated distributions: $\epsilon$-perplexity, sparsemax score, and Jensen-Shannon divergence. Human-evaluated experiments in story completion and dialogue generation show that entmax sampling leads to more engaging and coherent stories and conversations. ","[{'version': 'v1', 'created': 'Mon, 6 Apr 2020 13:09:10 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Sep 2020 11:17:53 GMT'}, {'version': 'v3', 'created': 'Mon, 5 Oct 2020 11:20:54 GMT'}]",2020-10-06,"[['Martins', 'Pedro Henrique', ''], ['Marinho', 'Zita', ''], ['Martins', 'André F. T.', '']]",0,1,2020-04-06,3,3,1,1,1,0,3a5f479d15a3300a2fbfb868f80339431b452a5b,214802971.0,https://www.semanticscholar.org/paper/3a5f479d15a3300a2fbfb868f80339431b452a5b,Conference on Empirical Methods in Natural Language Processing,2020.0,56.0,33.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144869806', 'name': 'Pedro Henrique Martins'}, {'authorId': '2566656', 'name': 'Zita Marinho'}, {'authorId': '145644643', 'name': 'André F. T. Martins'}]",['Instituto Superior Técnico'],['Portugal'],2020-04,['industrial']
2004.04092,Chunyuan Li,"Chunyuan Li, Xiang Gao, Yuan Li, Baolin Peng, Xiujun Li, Yizhe Zhang,
  Jianfeng Gao",Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space,"Accepted in EMNLP 2020; Code: https://github.com/ChunyuanLI/Optimus
  Demo: http://aka.ms/optimus",,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  When trained effectively, the Variational Autoencoder (VAE) can be both a powerful generative model and an effective representation learning framework for natural language. In this paper, we propose the first large-scale language VAE model, Optimus. A universal latent embedding space for sentences is first pre-trained on large text corpus, and then fine-tuned for various language generation and understanding tasks. Compared with GPT-2, Optimus enables guided language generation from an abstract level using the latent vectors. Compared with BERT, Optimus can generalize better on low-resource language understanding tasks due to the smooth latent space structure. Extensive experimental results on a wide range of language tasks demonstrate the effectiveness of Optimus. It achieves new state-of-the-art on VAE language modeling benchmarks. We hope that our first pre-trained big VAE language model itself and results can help the NLP community renew the interests of deep generative models in the era of large-scale pre-training, and make these principled methods more practical. ","[{'version': 'v1', 'created': 'Sun, 5 Apr 2020 06:20:18 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Oct 2020 19:11:42 GMT'}, {'version': 'v3', 'created': 'Wed, 7 Oct 2020 00:41:43 GMT'}, {'version': 'v4', 'created': 'Sun, 11 Oct 2020 23:33:10 GMT'}]",2020-10-13,"[['Li', 'Chunyuan', ''], ['Gao', 'Xiang', ''], ['Li', 'Yuan', ''], ['Peng', 'Baolin', ''], ['Li', 'Xiujun', ''], ['Zhang', 'Yizhe', ''], ['Gao', 'Jianfeng', '']]",0,1,2020-04-05,4,7,3,1,1,0,00696ba295d66f049d70272219f7fea4266171be,215416349.0,https://www.semanticscholar.org/paper/00696ba295d66f049d70272219f7fea4266171be,Conference on Empirical Methods in Natural Language Processing,2020.0,69.0,134.0,36.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109737569', 'name': 'Chunyuan Li'}, {'authorId': '71886367', 'name': 'Xiang Gao'}, {'authorId': '2118204633', 'name': 'Yuan Li'}, {'authorId': '47058148', 'name': 'Xiujun Li'}, {'authorId': '1780690', 'name': 'Baolin Peng'}, {'authorId': '48378494', 'name': 'Yizhe Zhang'}, {'authorId': '1800422', 'name': 'Jianfeng Gao'}]",['Microsoft'],['United States'],2020-04,['industrial']
2004.11579,Yi Liao,"Yi Liao, Xin Jiang, Qun Liu",Probabilistically Masked Language Model Capable of Autoregressive Generation in Arbitrary Word Order,Accepted by ACL 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Masked language model and autoregressive language model are two types of language models. While pretrained masked language models such as BERT overwhelm the line of natural language understanding (NLU) tasks, autoregressive language models such as GPT are especially capable in natural language generation (NLG). In this paper, we propose a probabilistic masking scheme for the masked language model, which we call probabilistically masked language model (PMLM). We implement a specific PMLM with a uniform prior distribution on the masking ratio named u-PMLM. We prove that u-PMLM is equivalent to an autoregressive permutated language model. One main advantage of the model is that it supports text generation in arbitrary order with surprisingly good quality, which could potentially enable new applications over traditional unidirectional generation. Besides, the pretrained u-PMLM also outperforms BERT on a set of downstream NLU tasks. ","[{'version': 'v1', 'created': 'Fri, 24 Apr 2020 07:38:19 GMT'}]",2020-04-27,"[['Liao', 'Yi', ''], ['Jiang', 'Xin', ''], ['Liu', 'Qun', '']]",0,1,2020-04-24,1,3,1,0,0,0,f02bb4bc0b711fd90d32bd7dadd505465d6b45e1,216144416.0,https://www.semanticscholar.org/paper/f02bb4bc0b711fd90d32bd7dadd505465d6b45e1,Annual Meeting of the Association for Computational Linguistics,2020.0,34.0,27.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2048004675', 'name': 'Yi Liao'}, {'authorId': '2110310493', 'name': 'Xin Jiang'}, {'authorId': '1688015', 'name': 'Qun Liu'}]",['Huawei Technologies (China)'],['China'],2020-04,['industrial']
2004.12303,Xinyue Zheng,"Xinyue Zheng, Peng Wang, Qigang Wang, Zhongchao Shi",Challenge Closed-book Science Exam: A Meta-learning Based Question Answering System,,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prior work in standardized science exams requires support from large text corpus, such as targeted science corpus fromWikipedia or SimpleWikipedia. However, retrieving knowledge from the large corpus is time-consuming and questions embedded in complex semantic representation may interfere with retrieval. Inspired by the dual process theory in cognitive science, we propose a MetaQA framework, where system 1 is an intuitive meta-classifier and system 2 is a reasoning module. Specifically, our method based on meta-learning method and large language model BERT, which can efficiently solve science problems by learning from related example questions without relying on external knowledge bases. We evaluate our method on AI2 Reasoning Challenge (ARC), and the experimental results show that meta-classifier yields considerable classification performance on emerging question types. The information provided by meta-classifier significantly improves the accuracy of reasoning module from 46.6% to 64.2%, which has a competitive advantage over retrieval-based QA methods. ","[{'version': 'v1', 'created': 'Sun, 26 Apr 2020 07:43:30 GMT'}]",2020-04-28,"[['Zheng', 'Xinyue', ''], ['Wang', 'Peng', ''], ['Wang', 'Qigang', ''], ['Shi', 'Zhongchao', '']]",0,0,2020-04-26,1,4,2,0,0,0,ac39d602fb265c78994ca6be2f6596977f50f694,216553690.0,https://www.semanticscholar.org/paper/ac39d602fb265c78994ca6be2f6596977f50f694,Pacific Rim Knowledge Acquisition Workshop,2020.0,32.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151482815', 'name': 'Xinyue Zheng'}, {'authorId': '2155300440', 'name': 'Peng Wang'}, {'authorId': '2145778553', 'name': 'Qigang Wang'}, {'authorId': '2558130', 'name': 'Zhongchao Shi'}]","['AI Lab, Lenovo Research, Beijing, 100089, China']",['China'],2020-04,['industrial']
2004.13845,Yannis Papanikolaou,Yannis Papanikolaou and Andrea Pierleoni,DARE: Data Augmented Relation Extraction with GPT-2,,,,,cs.CL cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Real-world Relation Extraction (RE) tasks are challenging to deal with, either due to limited training data or class imbalance issues. In this work, we present Data Augmented Relation Extraction(DARE), a simple method to augment training data by properly fine-tuning GPT-2 to generate examples for specific relation types. The generated training data is then used in combination with the gold dataset to train a BERT-based RE classifier. In a series of experiments we show the advantages of our method, which leads in improvements of up to 11 F1 score points against a strong base-line. Also, DARE achieves new state of the art in three widely used biomedical RE datasets surpassing the previous best results by 4.7 F1 points on average. ","[{'version': 'v1', 'created': 'Mon, 6 Apr 2020 14:38:36 GMT'}]",2020-04-30,"[['Papanikolaou', 'Yannis', ''], ['Pierleoni', 'Andrea', '']]",0,1,2020-04-06,1,2,3,1,1,0,1ed7cad908eebfc3d3807f8f5f1bc47103da2578,208634994.0,https://www.semanticscholar.org/paper/1ed7cad908eebfc3d3807f8f5f1bc47103da2578,arXiv.org,2020.0,40.0,53.0,1.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '10225537', 'name': 'Yannis Papanikolaou'}, {'authorId': '2993424', 'name': 'A. Pierleoni'}]","['Healx, Cambridge, UK']",,2020-04,['industrial']
2005.06166,Boliang Zhang,"Boliang Zhang, Ajay Nagesh, and Kevin Knight",Parallel Corpus Filtering via Pre-trained Language Models,ACL 2020,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Web-crawled data provides a good source of parallel corpora for training machine translation models. It is automatically obtained, but extremely noisy, and recent work shows that neural machine translation systems are more sensitive to noise than traditional statistical machine translation methods. In this paper, we propose a novel approach to filter out noisy sentence pairs from web-crawled corpora via pre-trained language models. We measure sentence parallelism by leveraging the multilingual capability of BERT and use the Generative Pre-training (GPT) language model as a domain filter to balance data domains. We evaluate the proposed method on the WMT 2018 Parallel Corpus Filtering shared task, and on our own web-crawled Japanese-Chinese parallel corpus. Our method significantly outperforms baselines and achieves a new state-of-the-art. In an unsupervised setting, our method achieves comparable performance to the top-1 supervised method. We also evaluate on a web-crawled Japanese-Chinese parallel corpus that we make publicly available. ","[{'version': 'v1', 'created': 'Wed, 13 May 2020 06:06:23 GMT'}]",2020-05-14,"[['Zhang', 'Boliang', ''], ['Nagesh', 'Ajay', ''], ['Knight', 'Kevin', '']]",0,1,2020-05-13,1,3,2,0,0,0,f14b811ce52e4317aaa82705724503aeaa7c4f61,218613853.0,https://www.semanticscholar.org/paper/f14b811ce52e4317aaa82705724503aeaa7c4f61,Annual Meeting of the Association for Computational Linguistics,2020.0,33.0,23.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '38629264', 'name': 'Boliang Zhang'}, {'authorId': '145773546', 'name': 'Ajay Nagesh'}, {'authorId': '152971314', 'name': 'Kevin Knight'}]",['DiDi Labs'],,2020-05,['industrial']
2005.14664,Josef Urban,Josef Urban and Jan Jakub\r{u}v,First Neural Conjecturing Datasets and Experiments,Accepted to CICM 2020,,,,cs.AI cs.LG cs.LO cs.NE cs.SC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,  We describe several datasets and first experiments with creating conjectures by neural methods. The datasets are based on the Mizar Mathematical Library processed in several forms and the problems extracted from it by the MPTP system and proved by the E prover using the ENIGMA guidance. The conjecturing experiments use the Transformer architecture and in particular its GPT-2 implementation. ,"[{'version': 'v1', 'created': 'Fri, 29 May 2020 16:46:25 GMT'}]",2020-06-01,"[['Urban', 'Josef', ''], ['Jakubův', 'Jan', '']]",0,1,2020-05-29,1,2,5,1,1,0,268fc2b1cb4afa59f088b1aa7e47e1b4abb0d1b5,219124086.0,https://www.semanticscholar.org/paper/268fc2b1cb4afa59f088b1aa7e47e1b4abb0d1b5,International Conference on Intelligent Computer Mathematics,2020.0,22.0,26.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '2087993', 'name': 'J. Urban'}, {'authorId': '2171321', 'name': 'Jan Jakubuv'}]","['Czech Institute of Informatics, Robotics and Cybernetics, Prague, Czech Republic']",['Czech Republic'],2020-05,['industrial']
2006.05477,Chaitra Vishwanatha Hegde,"Chaitra Hegde, Shrikumar Patil",Unsupervised Paraphrase Generation using Pre-trained Language Models,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large scale Pre-trained Language Models have proven to be very powerful approach in various Natural language tasks. OpenAI's GPT-2 \cite{radford2019language} is notable for its capability to generate fluent, well formulated, grammatically consistent text and for phrase completions. In this paper we leverage this generation capability of GPT-2 to generate paraphrases without any supervision from labelled data. We examine how the results compare with other supervised and unsupervised approaches and the effect of using paraphrases for data augmentation on downstream tasks such as classification. Our experiments show that paraphrases generated with our model are of good quality, are diverse and improves the downstream task performance when used for data augmentation. ","[{'version': 'v1', 'created': 'Tue, 9 Jun 2020 19:40:19 GMT'}]",2020-06-11,"[['Hegde', 'Chaitra', ''], ['Patil', 'Shrikumar', '']]",0,1,2020-06-09,1,2,2,1,1,0,2e35a88aab7b5636ca8ec68967c0e91fee7e9583,219559147.0,https://www.semanticscholar.org/paper/2e35a88aab7b5636ca8ec68967c0e91fee7e9583,arXiv.org,2020.0,31.0,29.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1406369362', 'name': 'Chaitra V. Hegde'}, {'authorId': '1741619403', 'name': 'Shrikumar Patil'}]",['Fidelity Investments (United States)'],['United States'],2020-06,['industrial']
2007.00655,Corbin Rosset,"Corby Rosset, Chenyan Xiong, Minh Phan, Xia Song, Paul Bennett,
  Saurabh Tiwary",Knowledge-Aware Language Model Pretraining,,,,,cs.CL cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  How much knowledge do pretrained language models hold? Recent research observed that pretrained transformers are adept at modeling semantics but it is unclear to what degree they grasp human knowledge, or how to ensure they do so. In this paper we incorporate knowledge-awareness in language model pretraining without changing the transformer architecture, inserting explicit knowledge layers, or adding external storage of semantic information. Rather, we simply signal the existence of entities to the input of the transformer in pretraining, with an entity-extended tokenizer; and at the output, with an additional entity prediction task. Our experiments show that solely by adding these entity signals in pretraining, significantly more knowledge is packed into the transformer parameters: we observe improved language modeling accuracy, factual correctness in LAMA knowledge probing tasks, and semantics in the hidden representations through edge probing.We also show that our knowledge-aware language model (KALM) can serve as a drop-in replacement for GPT-2 models, significantly improving downstream tasks like zero-shot question-answering with no task-related training. ","[{'version': 'v1', 'created': 'Mon, 29 Jun 2020 06:09:59 GMT'}, {'version': 'v2', 'created': 'Thu, 4 Feb 2021 06:54:39 GMT'}]",2021-02-05,"[['Rosset', 'Corby', ''], ['Xiong', 'Chenyan', ''], ['Phan', 'Minh', ''], ['Song', 'Xia', ''], ['Bennett', 'Paul', ''], ['Tiwary', 'Saurabh', '']]",0,1,2020-06-29,2,6,3,1,1,0,8668fd1cb5cab820f8b2a136b2ef4adfad6c4dc1,220280797.0,https://www.semanticscholar.org/paper/8668fd1cb5cab820f8b2a136b2ef4adfad6c4dc1,arXiv.org,2020.0,39.0,53.0,7.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '41016119', 'name': 'Corby Rosset'}, {'authorId': '144628574', 'name': 'Chenyan Xiong'}, {'authorId': '1754253385', 'name': 'M. Phan'}, {'authorId': '50706785', 'name': 'Xia Song'}, {'authorId': '153335844', 'name': 'Paul Bennett'}, {'authorId': '40070335', 'name': 'Saurabh Tiwary'}]",['Microsoft'],['United States'],2020-06,['industrial']
2007.01528,Hai Wang,"Hai Wang, David McAllester",On-The-Fly Information Retrieval Augmentation for Language Models,ACL 2020 NUSE Workshop,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,  Here we experiment with the use of information retrieval as an augmentation for pre-trained language models. The text corpus used in information retrieval can be viewed as form of episodic memory which grows over time. By augmenting GPT 2.0 with information retrieval we achieve a zero shot 15% relative reduction in perplexity on Gigaword corpus without any re-training. We also validate our IR augmentation on an event co-reference task. ,"[{'version': 'v1', 'created': 'Fri, 3 Jul 2020 07:31:14 GMT'}]",2020-07-06,"[['Wang', 'Hai', ''], ['McAllester', 'David', '']]",0,1,2020-07-03,1,2,1,1,1,0,6491d8bcac8490d9ffde33612f87e15c90a44e97,220347127.0,https://www.semanticscholar.org/paper/6491d8bcac8490d9ffde33612f87e15c90a44e97,NUSE,2020.0,34.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2113221447', 'name': 'Hai Wang'}, {'authorId': '145689002', 'name': 'David A. McAllester'}]",['Toyota Technological Institute at Chicago'],['United States'],2020-07,['industrial']
2009.01303,Sasi Kiran Gaddipati,"Sasi Kiran Gaddipati, Deebul Nair, Paul G. Pl\""oger",Comparative Evaluation of Pretrained Transfer Learning Models on Automatic Short Answer Grading,"7 pages, 3 figures, 3 tables. ""for associated work, refer
  https://github.com/gsasikiran/Evaluation-of-transfer-learning-models-on-automatic-short-answer-grading""",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic Short Answer Grading (ASAG) is the process of grading the student answers by computational approaches given a question and the desired answer. Previous works implemented the methods of concept mapping, facet mapping, and some used the conventional word embeddings for extracting semantic features. They extracted multiple features manually to train on the corresponding datasets. We use pretrained embeddings of the transfer learning models, ELMo, BERT, GPT, and GPT-2 to assess their efficiency on this task. We train with a single feature, cosine similarity, extracted from the embeddings of these models. We compare the RMSE scores and correlation measurements of the four models with previous works on Mohler dataset. Our work demonstrates that ELMo outperformed the other three models. We also, briefly describe the four transfer learning models and conclude with the possible causes of poor results of transfer learning models. ","[{'version': 'v1', 'created': 'Wed, 2 Sep 2020 19:07:34 GMT'}]",2020-09-04,"[['Gaddipati', 'Sasi Kiran', ''], ['Nair', 'Deebul', ''], ['Plöger', 'Paul G.', '']]",0,1,2020-09-02,1,3,1,1,1,0,1a8a4686f81efdcb5b1dd1e24eca9997280e2521,221470365.0,https://www.semanticscholar.org/paper/1a8a4686f81efdcb5b1dd1e24eca9997280e2521,arXiv.org,2020.0,30.0,13.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1924542474', 'name': 'Sasi Kiran Gaddipati'}, {'authorId': '1454453926', 'name': 'Deebul Nair'}, {'authorId': '1775016', 'name': 'P. Plöger'}]",['Hochschule Bonn-Rhein-Sieg'],['Germany'],2020-09,['industrial']
2009.04765,Damian Pascual,"Nicolas Affolter, Beni Egressy, Damian Pascual, Roger Wattenhofer",Brain2Word: Decoding Brain Activity for Language Generation,Preprint. Work in progress,,,,cs.CL cs.LG q-bio.NC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Brain decoding, understood as the process of mapping brain activities to the stimuli that generated them, has been an active research area in the last years. In the case of language stimuli, recent studies have shown that it is possible to decode fMRI scans into an embedding of the word a subject is reading. However, such word embeddings are designed for natural language processing tasks rather than for brain decoding. Therefore, they limit our ability to recover the precise stimulus. In this work, we propose to directly classify an fMRI scan, mapping it to the corresponding word within a fixed vocabulary. Unlike existing work, we evaluate on scans from previously unseen subjects. We argue that this is a more realistic setup and we present a model that can decode fMRI data from unseen subjects. Our model achieves 5.22% Top-1 and 13.59% Top-5 accuracy in this challenging task, significantly outperforming all the considered competitive baselines. Furthermore, we use the decoded words to guide language generation with the GPT-2 model. This way, we advance the quest for a system that translates brain activities into coherent text. ","[{'version': 'v1', 'created': 'Thu, 10 Sep 2020 10:47:36 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 08:05:08 GMT'}, {'version': 'v3', 'created': 'Wed, 11 Nov 2020 08:07:08 GMT'}]",2020-11-12,"[['Affolter', 'Nicolas', ''], ['Egressy', 'Beni', ''], ['Pascual', 'Damian', ''], ['Wattenhofer', 'Roger', '']]",0,1,2020-09-10,3,4,3,1,1,0,769b2f239bde15c01dbe3856a2ff216f6b0e003b,221586298.0,https://www.semanticscholar.org/paper/769b2f239bde15c01dbe3856a2ff216f6b0e003b,arXiv.org,2020.0,30.0,11.0,0.0,False,"['Computer Science', 'Biology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1935004796', 'name': 'Nicolas Affolter'}, {'authorId': '1935472784', 'name': 'Béni Egressy'}, {'authorId': '150973452', 'name': 'Damian Pascual'}, {'authorId': '1716440', 'name': 'Roger Wattenhofer'}]",['ETH Zurich'],['Switzerland'],2020-09,['industrial']
2009.06807,Alex Newhouse,"Kris McGuffie, Alex Newhouse",The Radicalization Risks of GPT-3 and Advanced Neural Language Models,,,,,cs.CY cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we expand on our previous research of the potential for abuse of generative language models by assessing GPT-3. Experimenting with prompts representative of different types of extremist narrative, structures of social interaction, and radical ideologies, we find that GPT-3 demonstrates significant improvement over its predecessor, GPT-2, in generating extremist texts. We also show GPT-3's strength in generating text that accurately emulates interactive, informational, and influential content that could be utilized for radicalizing individuals into violent far-right extremist ideologies and behaviors. While OpenAI's preventative measures are strong, the possibility of unregulated copycat technology represents significant risk for large-scale online radicalization and recruitment; thus, in the absence of safeguards, successful and efficient weaponization that requires little experimentation is likely. AI stakeholders, the policymaking community, and governments should begin investing as soon as possible in building social norms, public policy, and educational initiatives to preempt an influx of machine-generated disinformation and propaganda. Mitigation will require effective policy and partnerships across industry, government, and civil society. ","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 00:55:00 GMT'}]",2020-09-16,"[['McGuffie', 'Kris', ''], ['Newhouse', 'Alex', '']]",0,1,2020-09-15,1,2,2,2,1,1,02fde8bfd9259a4f53316579eb0bf97213559e5c,221703020.0,https://www.semanticscholar.org/paper/02fde8bfd9259a4f53316579eb0bf97213559e5c,arXiv.org,2020.0,10.0,111.0,5.0,False,"['Computer Science', 'Political Science']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1944357049', 'name': 'Kris McGuffie'}, {'authorId': '1944111259', 'name': 'Alex Newhouse'}]",['Middlebury Institute of International Studies at Monterey'],['United States'],2020-09,['industrial']
2009.06978,Xiang Gao,"Xiang Gao, Yizhe Zhang, Michel Galley, Chris Brockett, Bill Dolan",Dialogue Response Ranking Training with Large-Scale Human Feedback Data,Accepted to appear at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing open-domain dialog models are generally trained to minimize the perplexity of target human responses. However, some human replies are more engaging than others, spawning more followup interactions. Current conversational models are increasingly capable of producing turns that are context-relevant, but in order to produce compelling agents, these models need to be able to predict and optimize for turns that are genuinely engaging. We leverage social media feedback data (number of replies and upvotes) to build a large-scale training dataset for feedback prediction. To alleviate possible distortion between the feedback and engagingness, we convert the ranking problem to a comparison of response pairs which involve few confounding factors. We trained DialogRPT, a set of GPT-2 based models on 133M pairs of human feedback data and the resulting ranker outperformed several baselines. Particularly, our ranker outperforms the conventional dialog perplexity baseline with a large margin on predicting Reddit feedback. We finally combine the feedback prediction models and a human-like scoring model to rank the machine-generated dialog responses. Crowd-sourced human evaluation shows that our ranking method correlates better with real human preferences than baseline models. ","[{'version': 'v1', 'created': 'Tue, 15 Sep 2020 10:50:05 GMT'}]",2020-09-16,"[['Gao', 'Xiang', ''], ['Zhang', 'Yizhe', ''], ['Galley', 'Michel', ''], ['Brockett', 'Chris', ''], ['Dolan', 'Bill', '']]",0,1,2020-09-15,1,5,1,1,1,0,32722fb49e981d0e53b1ff3c064850548f0b54e0,221703773.0,https://www.semanticscholar.org/paper/32722fb49e981d0e53b1ff3c064850548f0b54e0,Conference on Empirical Methods in Natural Language Processing,2020.0,35.0,79.0,21.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '71886367', 'name': 'Xiang Gao'}, {'authorId': '3272356', 'name': 'Yizhe Zhang'}, {'authorId': '1947267', 'name': 'Michel Galley'}, {'authorId': '3125776', 'name': 'Chris Brockett'}, {'authorId': '66648221', 'name': 'Bill Dolan'}]",['Microsoft'],['United States'],2020-09,['industrial']
2010.01693,Oluwatobi Olabiyi,"Oluwatobi O. Olabiyi, Prarthana Bhattarai, C. Bayan Bruss, Zachary
  Kulis",DLGNet-Task: An End-to-end Neural Network Framework for Modeling Multi-turn Multi-domain Task-Oriented Dialogue,,,,,cs.CL cs.AI cs.HC cs.LG cs.NE,http://creativecommons.org/publicdomain/zero/1.0/,"  Task oriented dialogue (TOD) requires the complex interleaving of a number of individually controllable components with strong guarantees for explainability and verifiability. This has made it difficult to adopt the multi-turn multi-domain dialogue generation capabilities of streamlined end-to-end open-domain dialogue systems. In this paper, we present a new framework, DLGNet-Task, a unified task-oriented dialogue system which employs autoregressive transformer networks such as DLGNet and GPT-2/3 to complete user tasks in multi-turn multi-domain conversations. Our framework enjoys the controllable, verifiable, and explainable outputs of modular approaches, and the low development, deployment and maintenance cost of end-to-end systems. Treating open-domain system components as additional TOD system modules allows DLGNet-Task to learn the joint distribution of the inputs and outputs of all the functional blocks of existing modular approaches such as, natural language understanding (NLU), state tracking, action policy, as well as natural language generation (NLG). Rather than training the modules individually, as is common in real-world systems, we trained them jointly with appropriate module separations. When evaluated on the MultiWOZ2.1 dataset, DLGNet-Task shows comparable performance to the existing state-of-the-art approaches. Furthermore, using DLGNet-Task in conversational AI systems reduces the level of effort required for developing, deploying, and maintaining intelligent assistants at scale. ","[{'version': 'v1', 'created': 'Sun, 4 Oct 2020 21:43:17 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Oct 2020 16:31:06 GMT'}]",2020-10-07,"[['Olabiyi', 'Oluwatobi O.', ''], ['Bhattarai', 'Prarthana', ''], ['Bruss', 'C. Bayan', ''], ['Kulis', 'Zachary', '']]",0,1,2020-10-04,2,4,5,1,1,0,4cfb727384d3b338c00c7f2b2726f2971be4139d,222132878.0,https://www.semanticscholar.org/paper/4cfb727384d3b338c00c7f2b2726f2971be4139d,arXiv.org,2020.0,24.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1696821', 'name': 'O. Olabiyi'}, {'authorId': '1985858043', 'name': 'P. Bhattarai'}, {'authorId': '8954363', 'name': 'C. B. Bruss'}, {'authorId': '30574093', 'name': 'Zachary Kulis'}]","['Capital One -Conversation Research, McLean, VA', 'Capital One -Center for Machine Learning, McLean, VA']",,2020-10,"['industrial', 'industrial']"
2010.03073,Cicero Nogueira dos Santos,"Cicero Nogueira dos Santos, Xiaofei Ma, Ramesh Nallapati, Zhiheng
  Huang, Bing Xiang",Beyond [CLS] through Ranking by Generation,EMNLP 2020,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative models for Information Retrieval, where ranking of documents is viewed as the task of generating a query from a document's language model, were very successful in various IR tasks in the past. However, with the advent of modern deep neural networks, attention has shifted to discriminative ranking functions that model the semantic similarity of documents and queries instead. Recently, deep generative models such as GPT2 and BART have been shown to be excellent text generators, but their effectiveness as rankers have not been demonstrated yet. In this work, we revisit the generative framework for information retrieval and show that our generative approaches are as effective as state-of-the-art semantic similarity-based discriminative models for the answer selection task. Additionally, we demonstrate the effectiveness of unlikelihood losses for IR. ","[{'version': 'v1', 'created': 'Tue, 6 Oct 2020 22:56:31 GMT'}]",2020-10-08,"[['Santos', 'Cicero Nogueira dos', ''], ['Ma', 'Xiaofei', ''], ['Nallapati', 'Ramesh', ''], ['Huang', 'Zhiheng', ''], ['Xiang', 'Bing', '']]",0,1,2020-10-06,1,5,2,1,1,0,8c21b1df7ac375742e412251cb37f10966bb3bfa,222178252.0,https://www.semanticscholar.org/paper/8c21b1df7ac375742e412251cb37f10966bb3bfa,Conference on Empirical Methods in Natural Language Processing,2020.0,28.0,29.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1790831', 'name': 'C. D. Santos'}, {'authorId': '47646605', 'name': 'Xiaofei Ma'}, {'authorId': '1701451', 'name': 'Ramesh Nallapati'}, {'authorId': '3109481', 'name': 'Zhiheng Huang'}, {'authorId': '144028698', 'name': 'Bing Xiang'}]",['Amazon'],['United States'],2020-10,['industrial']
2010.08618,Sudha Rao,"Allison Hegel, Sudha Rao, Asli Celikyilmaz and Bill Dolan",Substance over Style: Document-Level Targeted Content Transfer,This paper has been accepted to be published at EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Existing language models excel at writing from scratch, but many real-world scenarios require rewriting an existing document to fit a set of constraints. Although sentence-level rewriting has been fairly well-studied, little work has addressed the challenge of rewriting an entire document coherently. In this work, we introduce the task of document-level targeted content transfer and address it in the recipe domain, with a recipe as the document and a dietary restriction (such as vegan or dairy-free) as the targeted constraint. We propose a novel model for this task based on the generative pre-trained language model (GPT-2) and train on a large number of roughly-aligned recipe pairs (https://github.com/microsoft/document-level-targeted-content-transfer). Both automatic and human evaluations show that our model out-performs existing methods by generating coherent and diverse rewrites that obey the constraint while remaining close to the original document. Finally, we analyze our model's rewrites to assess progress toward the goal of making language generation more attuned to constraints that are substantive rather than stylistic. ","[{'version': 'v1', 'created': 'Fri, 16 Oct 2020 20:26:10 GMT'}]",2020-10-20,"[['Hegel', 'Allison', ''], ['Rao', 'Sudha', ''], ['Celikyilmaz', 'Asli', ''], ['Dolan', 'Bill', '']]",0,1,2020-10-16,1,4,1,1,1,0,03763454e488be8530468b3f99c93d5211c7748f,224703411.0,https://www.semanticscholar.org/paper/03763454e488be8530468b3f99c93d5211c7748f,Conference on Empirical Methods in Natural Language Processing,2020.0,41.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '70414766', 'name': 'Allison Hegel'}, {'authorId': '1845230025', 'name': 'Sudha Rao'}, {'authorId': '1709797', 'name': 'Asli Celikyilmaz'}, {'authorId': '66648221', 'name': 'Bill Dolan'}]","['Microsoft', 'Lexion, Seattle, WA, USA']","['China', 'United States']",2020-10,"['industrial', 'industrial']"
2010.10216,Biswesh Mohapatra,"Biswesh Mohapatra, Gaurav Pandey, Danish Contractor, Sachindra Joshi",Simulated Chats for Building Dialog Systems: Learning to Generate Conversations from Instructions,Accepted in the Findings of EMNLP 2021,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Popular dialog datasets such as MultiWOZ are created by providing crowd workers an instruction, expressed in natural language, that describes the task to be accomplished. Crowd workers play the role of a user and an agent to generate dialogs to accomplish tasks involving booking restaurant tables, calling a taxi etc. In this paper, we present a data creation strategy that uses the pre-trained language model, GPT2, to simulate the interaction between crowd workers by creating a user bot and an agent bot. We train the simulators using a smaller percentage of actual crowd-generated conversations and their corresponding instructions. We demonstrate that by using the simulated data, we achieve significant improvements in low-resource settings on two publicly available datasets - the MultiWOZ dataset and the Persona chat dataset. ","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 12:04:19 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Oct 2021 08:48:55 GMT'}, {'version': 'v3', 'created': 'Tue, 19 Oct 2021 10:11:50 GMT'}, {'version': 'v4', 'created': 'Wed, 20 Oct 2021 13:13:03 GMT'}]",2021-10-22,"[['Mohapatra', 'Biswesh', ''], ['Pandey', 'Gaurav', ''], ['Contractor', 'Danish', ''], ['Joshi', 'Sachindra', '']]",0,1,2020-10-20,4,4,2,1,1,0,0f3596364943bb03f14cd75d9595a2c465831edb,239016412.0,https://www.semanticscholar.org/paper/0f3596364943bb03f14cd75d9595a2c465831edb,Conference on Empirical Methods in Natural Language Processing,2020.0,44.0,16.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1999633074', 'name': 'Biswesh Mohapatra'}, {'authorId': '2686270', 'name': 'Gaurav Pandey'}, {'authorId': '2075459', 'name': 'Danish Contractor'}, {'authorId': '1703799', 'name': 'Sachindra Joshi'}]","['IBM Research - India', 'International Institute of Information Technology Bangalore']",['India'],2020-10,"['industrial', 'industrial']"
2011.01843,Inkit Padhi,"Inkit Padhi, Yair Schiff, Igor Melnyk, Mattia Rigotti, Youssef Mroueh,
  Pierre Dognin, Jerret Ross, Ravi Nair, Erik Altman",Tabular Transformers for Modeling Multivariate Time Series,"Accepted to ICASSP, 2021; https://github.com/IBM/TabFormer",,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Tabular datasets are ubiquitous in data science applications. Given their importance, it seems natural to apply state-of-the-art deep learning algorithms in order to fully unlock their potential. Here we propose neural network models that represent tabular time series that can optionally leverage their hierarchical structure. This results in two architectures for tabular time series: one for learning representations that is analogous to BERT and can be pre-trained end-to-end and used in downstream tasks, and one that is akin to GPT and can be used for generation of realistic synthetic tabular sequences. We demonstrate our models on two datasets: a synthetic credit card transaction dataset, where the learned representations are used for fraud detection and synthetic data generation, and on a real pollution dataset, where the learned encodings are used to predict atmospheric pollutant concentrations. Code and data are available at https://github.com/IBM/TabFormer. ","[{'version': 'v1', 'created': 'Tue, 3 Nov 2020 16:58:08 GMT'}, {'version': 'v2', 'created': 'Thu, 11 Feb 2021 22:11:40 GMT'}]",2021-02-15,"[['Padhi', 'Inkit', ''], ['Schiff', 'Yair', ''], ['Melnyk', 'Igor', ''], ['Rigotti', 'Mattia', ''], ['Mroueh', 'Youssef', ''], ['Dognin', 'Pierre', ''], ['Ross', 'Jerret', ''], ['Nair', 'Ravi', ''], ['Altman', 'Erik', '']]",0,1,2020-11-03,2,9,2,0,0,0,1b055049c568be70d6a762679cdb93f630d5d6e6,226237049.0,https://www.semanticscholar.org/paper/1b055049c568be70d6a762679cdb93f630d5d6e6,"IEEE International Conference on Acoustics, Speech, and Signal Processing",2020.0,24.0,43.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8350409', 'name': 'Inkit Padhi'}, {'authorId': '1999174380', 'name': 'Yair Schiff'}, {'authorId': '2576373', 'name': 'Igor Melnyk'}, {'authorId': '2535094', 'name': 'Mattia Rigotti'}, {'authorId': '2211263', 'name': 'Youssef Mroueh'}, {'authorId': '1839363', 'name': 'Pierre L. Dognin'}, {'authorId': '39320489', 'name': 'Jerret Ross'}, {'authorId': '2066328036', 'name': 'Ravi Nair'}, {'authorId': '40021617', 'name': 'Erik Altman'}]","['IBM (United States)', 'MIT-IBM Watson AI Lab']",['United States'],2020-11,"['industrial', 'industrial']"
2011.07962,William Hui,William Hui,Performance of Transfer Learning Model vs. Traditional Neural Network in Low System Resource Environment,"5 pages, testing result, feature engineering",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, the use of pre-trained model to build neural network based on transfer learning methodology is increasingly popular. These pre-trained models present the benefit of using less computing resources to train model with smaller amount of training data. The rise of state-of-the-art models such as BERT, XLNet and GPT boost accuracy and benefit as a base model for transfer leanring. However, these models are still too complex and consume many computing resource to train for transfer learning with low GPU memory. We will compare the performance and cost between lighter transfer learning model and purposely built neural network for NLP application of text classification and NER model. ","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 08:12:56 GMT'}]",2020-11-17,"[['Hui', 'William', '']]",0,1,2020-10-20,1,1,2,0,0,0,eab6119ed809f4ebbfcaf7e4cdb2765f955e54b8,226965640.0,https://www.semanticscholar.org/paper/eab6119ed809f4ebbfcaf7e4cdb2765f955e54b8,arXiv.org,2020.0,8.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2057148886', 'name': 'W. Hui'}]",['Active Intelligence Holdings Limited'],,2020-10,['industrial']
2011.12692,Deheng Ye,"Deheng Ye, Guibin Chen, Wen Zhang, Sheng Chen, Bo Yuan, Bo Liu, Jia
  Chen, Zhao Liu, Fuhao Qiu, Hongsheng Yu, Yinyuting Yin, Bei Shi, Liang Wang,
  Tengfei Shi, Qiang Fu, Wei Yang, Lanxiao Huang, Wei Liu",Towards Playing Full MOBA Games with Deep Reinforcement Learning,NeurIPS 2020,,,,cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  MOBA games, e.g., Honor of Kings, League of Legends, and Dota 2, pose grand challenges to AI systems such as multi-agent, enormous state-action space, complex action control, etc. Developing AI for playing MOBA games has raised much attention accordingly. However, existing work falls short in handling the raw game complexity caused by the explosion of agent combinations, i.e., lineups, when expanding the hero pool in case that OpenAI's Dota AI limits the play to a pool of only 17 heroes. As a result, full MOBA games without restrictions are far from being mastered by any existing AI system. In this paper, we propose a MOBA AI learning paradigm that methodologically enables playing full MOBA games with deep reinforcement learning. Specifically, we develop a combination of novel and existing learning techniques, including curriculum self-play learning, policy distillation, off-policy adaption, multi-head value estimation, and Monte-Carlo tree-search, in training and playing a large pool of heroes, meanwhile addressing the scalability issue skillfully. Tested on Honor of Kings, a popular MOBA game, we show how to build superhuman AI agents that can defeat top esports players. The superiority of our AI is demonstrated by the first large-scale performance test of MOBA AI agent in the literature. ","[{'version': 'v1', 'created': 'Wed, 25 Nov 2020 12:52:33 GMT'}, {'version': 'v2', 'created': 'Thu, 26 Nov 2020 03:30:08 GMT'}, {'version': 'v3', 'created': 'Tue, 22 Dec 2020 11:58:54 GMT'}, {'version': 'v4', 'created': 'Thu, 31 Dec 2020 13:25:17 GMT'}]",2021-01-01,"[['Ye', 'Deheng', ''], ['Chen', 'Guibin', ''], ['Zhang', 'Wen', ''], ['Chen', 'Sheng', ''], ['Yuan', 'Bo', ''], ['Liu', 'Bo', ''], ['Chen', 'Jia', ''], ['Liu', 'Zhao', ''], ['Qiu', 'Fuhao', ''], ['Yu', 'Hongsheng', ''], ['Yin', 'Yinyuting', ''], ['Shi', 'Bei', ''], ['Wang', 'Liang', ''], ['Shi', 'Tengfei', ''], ['Fu', 'Qiang', ''], ['Yang', 'Wei', ''], ['Huang', 'Lanxiao', ''], ['Liu', 'Wei', '']]",0,0,2020-11-25,4,18,2,0,0,0,681bbcf763fd7c59869853bedfe6b9f02a3364e6,227162956.0,https://www.semanticscholar.org/paper/681bbcf763fd7c59869853bedfe6b9f02a3364e6,Neural Information Processing Systems,2020.0,39.0,115.0,7.0,False,"['Computer Science', 'Psychology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2055648566', 'name': 'Deheng Ye'}, {'authorId': '1510409929', 'name': 'Guibin Chen'}, {'authorId': '2108543115', 'name': 'Wen Zhang'}, {'authorId': '2118529933', 'name': 'Sheng Chen'}, {'authorId': '2055907828', 'name': 'Bo Yuan'}, {'authorId': '40107085', 'name': 'Bo Liu'}, {'authorId': '2144157470', 'name': 'Jia Chen'}, {'authorId': '2118395857', 'name': 'Zhao Liu'}, {'authorId': '2072293042', 'name': 'Fuhao Qiu'}, {'authorId': '1417653814', 'name': 'Hongsheng Yu'}, {'authorId': '1470464839', 'name': 'Yinyuting Yin'}, {'authorId': '46318189', 'name': 'Bei Shi'}, {'authorId': '2144696467', 'name': 'Liang Wang'}, {'authorId': '1596814619', 'name': 'Tengfei Shi'}, {'authorId': '2091914469', 'name': 'Qiang Fu'}, {'authorId': '2005150594', 'name': 'Wei Yang'}, {'authorId': '2108955773', 'name': 'Lanxiao Huang'}, {'authorId': '2157221557', 'name': 'Wei Liu'}]",['Tencent'],['China'],2020-11,['industrial']
2012.08787,Vincent Claveau,Vincent Claveau,Query expansion with artificially generated texts,"12 pages, 2 figures",,,,cs.IR,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  A well-known way to improve the performance of document retrieval is to expand the user's query. Several approaches have been proposed in the literature, and some of them are considered as yielding state-of-the-art results in IR. In this paper, we explore the use of text generation to automatically expand the queries. We rely on a well-known neural generative model, GPT-2, that comes with pre-trained models for English but can also be fine-tuned on specific corpora. Through different experiments, we show that text generation is a very effective way to improve the performance of an IR system, with a large margin (+10% MAP gains), and that it outperforms strong baselines also relying on query expansion (LM+RM3). This conceptually simple approach can easily be implemented on any IR system thanks to the availability of GPT code and models. ","[{'version': 'v1', 'created': 'Wed, 16 Dec 2020 08:13:08 GMT'}]",2020-12-17,"[['Claveau', 'Vincent', '']]",0,1,2020-12-16,1,1,1,1,1,0,55ae264ff9cdc855b1f8f0f17b3300f200b7a1a6,229220964.0,https://www.semanticscholar.org/paper/55ae264ff9cdc855b1f8f0f17b3300f200b7a1a6,arXiv.org,2020.0,26.0,9.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1735666', 'name': 'V. Claveau'}]","['CNRS -IRISA, Univ. Rennes Campus de Beaulieu, F-35042 Rennes, France']",['France'],2020-12,['industrial']
2012.15416,Damian Pascual,"Damian Pascual, Beni Egressy, Florian Bolli, Roger Wattenhofer",Directed Beam Search: Plug-and-Play Lexically Constrained Language Generation,Preprint. Work in progress,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large pre-trained language models are capable of generating realistic text. However, controlling these models so that the generated text satisfies lexical constraints, i.e., contains specific words, is a challenging problem. Given that state-of-the-art language models are too large to be trained from scratch in a manageable time, it is desirable to control these models without re-training them. Methods capable of doing this are called plug-and-play. Recent plug-and-play methods have been successful in constraining small bidirectional language models as well as forward models in tasks with a restricted search space, e.g., machine translation. However, controlling large transformer-based models to meet lexical constraints without re-training them remains a challenge. In this work, we propose Directed Beam Search (DBS), a plug-and-play method for lexically constrained language generation. Our method can be applied to any language model, is easy to implement and can be used for general language generation. In our experiments we use DBS to control GPT-2. We demonstrate its performance on keyword-to-phrase generation and we obtain comparable results as a state-of-the-art non-plug-and-play model for lexically constrained story generation. ","[{'version': 'v1', 'created': 'Thu, 31 Dec 2020 03:05:44 GMT'}]",2021-01-01,"[['Pascual', 'Damian', ''], ['Egressy', 'Beni', ''], ['Bolli', 'Florian', ''], ['Wattenhofer', 'Roger', '']]",0,1,2020-12-31,1,4,3,1,1,0,568deb4817e7633483c93be3f50dcf51493963ff,229923101.0,https://www.semanticscholar.org/paper/568deb4817e7633483c93be3f50dcf51493963ff,arXiv.org,2020.0,27.0,12.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150973452', 'name': 'Damian Pascual'}, {'authorId': '1935472784', 'name': 'Béni Egressy'}, {'authorId': '2043231121', 'name': 'Florian Bolli'}, {'authorId': '1716440', 'name': 'Roger Wattenhofer'}]",['ETH Zurich'],['Switzerland'],2020-12,['industrial']
2101.00027,Leo Gao,"Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe,
  Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn
  Presser, Connor Leahy",The Pile: An 800GB Dataset of Diverse Text for Language Modeling,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent work has demonstrated that increased training dataset diversity improves general cross-domain knowledge and downstream generalization capability for large-scale language models. With this in mind, we present \textit{the Pile}: an 825 GiB English text corpus targeted at training large-scale language models. The Pile is constructed from 22 diverse high-quality subsets -- both existing and newly constructed -- many of which derive from academic or professional sources. Our evaluation of the untuned performance of GPT-2 and GPT-3 on the Pile shows that these models struggle on many of its components, such as academic writing. Conversely, models trained on the Pile improve significantly over both Raw CC and CC-100 on all components of the Pile, while improving performance on downstream evaluations. Through an in-depth exploratory analysis, we document potentially concerning aspects of the data for prospective users. We make publicly available the code used in its construction. ","[{'version': 'v1', 'created': 'Thu, 31 Dec 2020 19:00:10 GMT'}]",2021-01-05,"[['Gao', 'Leo', ''], ['Biderman', 'Stella', ''], ['Black', 'Sid', ''], ['Golding', 'Laurence', ''], ['Hoppe', 'Travis', ''], ['Foster', 'Charles', ''], ['Phang', 'Jason', ''], ['He', 'Horace', ''], ['Thite', 'Anish', ''], ['Nabeshima', 'Noa', ''], ['Presser', 'Shawn', ''], ['Leahy', 'Connor', '']]",0,1,2020-12-31,1,12,1,2,1,1,db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e,230435736.0,https://www.semanticscholar.org/paper/db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e,arXiv.org,2020.0,1.0,820.0,173.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2027599537', 'name': 'Leo Gao'}, {'authorId': '103476203', 'name': 'Stella Rose Biderman'}, {'authorId': '2044098905', 'name': 'Sid Black'}, {'authorId': '2044198157', 'name': 'Laurence Golding'}, {'authorId': '47000911', 'name': 'Travis Hoppe'}, {'authorId': '2064610125', 'name': 'Charles Foster'}, {'authorId': '80842917', 'name': 'Jason Phang'}, {'authorId': '46350295', 'name': 'Horace He'}, {'authorId': '2044198037', 'name': 'Anish Thite'}, {'authorId': '2044198503', 'name': 'Noa Nabeshima'}, {'authorId': '2037326180', 'name': 'Shawn Presser'}, {'authorId': '2044198134', 'name': 'Connor Leahy'}]",['Stella Biderman Sid Black Laurence Golding Travis Hoppe Charles Foster Jason Phang Horace He'],,2020-12,['industrial']
2101.03961,William Fedus,"William Fedus, Barret Zoph, Noam Shazeer",Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,JMLR,,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In deep learning, models typically reuse the same parameters for all inputs. Mixture of Experts (MoE) defies this and instead selects different parameters for each incoming example. The result is a sparsely-activated model -- with outrageous numbers of parameters -- but a constant computational cost. However, despite several notable successes of MoE, widespread adoption has been hindered by complexity, communication costs and training instability -- we address these with the Switch Transformer. We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and computational costs. Our proposed training techniques help wrangle the instabilities and we show large sparse models may be trained, for the first time, with lower precision (bfloat16) formats. We design models based off T5-Base and T5-Large to obtain up to 7x increases in pre-training speed with the same computational resources. These improvements extend into multilingual settings where we measure gains over the mT5-Base version across all 101 languages. Finally, we advance the current scale of language models by pre-training up to trillion parameter models on the ""Colossal Clean Crawled Corpus"" and achieve a 4x speedup over the T5-XXL model. ","[{'version': 'v1', 'created': 'Mon, 11 Jan 2021 16:11:52 GMT'}, {'version': 'v2', 'created': 'Sat, 30 Apr 2022 00:02:01 GMT'}, {'version': 'v3', 'created': 'Thu, 16 Jun 2022 20:36:07 GMT'}]",2022-06-20,"[['Fedus', 'William', ''], ['Zoph', 'Barret', ''], ['Shazeer', 'Noam', '']]",0,0,2021-01-11,3,3,2,2,2,0,fdacf2a732f55befdc410ea927091cad3b791f13,231573431.0,https://www.semanticscholar.org/paper/fdacf2a732f55befdc410ea927091cad3b791f13,Journal of machine learning research,2021.0,75.0,944.0,186.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '26958176', 'name': 'W. Fedus'}, {'authorId': '2368067', 'name': 'Barret Zoph'}, {'authorId': '1846258', 'name': 'Noam M. Shazeer'}]",['Google'],['United States'],2021-01,['industrial']
2101.12462,Benjamin Marie,"Benjamin Marie, Atsushi Fujita",Synthesizing Monolingual Data for Neural Machine Translation,Preliminary work,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In neural machine translation (NMT), monolingual data in the target language are usually exploited through a method so-called ""back-translation"" to synthesize additional training parallel data. The synthetic data have been shown helpful to train better NMT, especially for low-resource language pairs and domains. Nonetheless, large monolingual data in the target domains or languages are not always available to generate large synthetic parallel data. In this work, we propose a new method to generate large synthetic parallel data leveraging very small monolingual data in a specific domain. We fine-tune a pre-trained GPT-2 model on such small in-domain monolingual data and use the resulting model to generate a large amount of synthetic in-domain monolingual data. Then, we perform back-translation, or forward translation, to generate synthetic in-domain parallel data. Our preliminary experiments on three language pairs and five domains show the effectiveness of our method to generate fully synthetic but useful in-domain parallel data for improving NMT in all configurations. We also show promising results in extreme adaptation for personalized NMT. ","[{'version': 'v1', 'created': 'Fri, 29 Jan 2021 08:17:40 GMT'}]",2021-02-01,"[['Marie', 'Benjamin', ''], ['Fujita', 'Atsushi', '']]",0,1,2021-01-29,1,2,1,1,1,0,3f8a02ef40c772a2f05a4689daa94c1cfa975495,231728613.0,https://www.semanticscholar.org/paper/3f8a02ef40c772a2f05a4689daa94c1cfa975495,arXiv.org,2021.0,18.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064068087', 'name': 'Benjamin Marie'}, {'authorId': '46566611', 'name': 'Atsushi Fujita'}]",['National Institute of Information and Communications Technology'],['Japan'],2021-01,['industrial']
2102.00426,Teja Kanchinadam,"Teja Kanchinadam, Qian You, Keith Westpfahl, James Kim, Siva Gunda,
  Sebastian Seith, Glenn Fung",A Simple yet Brisk and Efficient Active Learning Platform for Text Classification,,,,,cs.LG cs.HC cs.IR,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this work, we propose the use of a fully managed machine learning service, which utilizes active learning to directly build models from unstructured data. With this tool, business users can quickly and easily build machine learning models and then directly deploy them into a production ready hosted environment without much involvement from data scientists. Our approach leverages state-of-the-art text representation like OpenAI's GPT2 and a fast implementation of the active learning workflow that relies on a simple construction of incremental learning using linear models, thus providing a brisk and efficient labeling experience for the users. Experiments on both publicly available and real-life insurance datasets empirically show why our choices of simple and fast classification algorithms are ideal for the task at hand. ","[{'version': 'v1', 'created': 'Sun, 31 Jan 2021 10:44:04 GMT'}]",2021-02-02,"[['Kanchinadam', 'Teja', ''], ['You', 'Qian', ''], ['Westpfahl', 'Keith', ''], ['Kim', 'James', ''], ['Gunda', 'Siva', ''], ['Seith', 'Sebastian', ''], ['Fung', 'Glenn', '']]",0,1,2021-01-31,1,7,3,1,1,0,88e7dcb64dbea28dd25f0d8c4641bdddf8090229,231740567.0,https://www.semanticscholar.org/paper/88e7dcb64dbea28dd25f0d8c4641bdddf8090229,arXiv.org,2021.0,33.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66479836', 'name': 'Teja Kanchinadam'}, {'authorId': '49038552', 'name': 'Qian You'}, {'authorId': '2047550189', 'name': 'Keith Westpfahl'}, {'authorId': '2109236251', 'name': 'James Kim'}, {'authorId': '2047544883', 'name': 'S. Gunda'}, {'authorId': '3141777', 'name': 'Sebastian Seith'}, {'authorId': '2064481572', 'name': 'G. Fung'}]","['American Family Insurance, Machine Learning Research Group']",,2021-01,['industrial']
2102.00875,Agrin Aram Hilmkil,"Agrin Hilmkil and Sebastian Callh and Matteo Barbieri and Leon Ren\'e
  S\""utfeld and Edvin Listo Zec and Olof Mogren",Scaling Federated Learning for Fine-tuning of Large Language Models,,,,,cs.LG cs.CL cs.DC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Federated learning (FL) is a promising approach to distributed compute, as well as distributed data, and provides a level of privacy and compliance to legal frameworks. This makes FL attractive for both consumer and healthcare applications. While the area is actively being explored, few studies have examined FL in the context of larger language models and there is a lack of comprehensive reviews of robustness across tasks, architectures, numbers of clients, and other relevant factors. In this paper, we explore the fine-tuning of Transformer-based language models in a federated learning setting. We evaluate three popular BERT-variants of different sizes (BERT, ALBERT, and DistilBERT) on a number of text classification tasks such as sentiment analysis and author identification. We perform an extensive sweep over the number of clients, ranging up to 32, to evaluate the impact of distributed compute on task performance in the federated averaging setting. While our findings suggest that the large sizes of the evaluated models are not generally prohibitive to federated training, we found that the different models handle federated averaging to a varying degree. Most notably, DistilBERT converges significantly slower with larger numbers of clients, and under some circumstances, even collapses to chance level performance. Investigating this issue presents an interesting perspective for future research. ","[{'version': 'v1', 'created': 'Mon, 1 Feb 2021 14:31:39 GMT'}]",2021-02-02,"[['Hilmkil', 'Agrin', ''], ['Callh', 'Sebastian', ''], ['Barbieri', 'Matteo', ''], ['Sütfeld', 'Leon René', ''], ['Zec', 'Edvin Listo', ''], ['Mogren', 'Olof', '']]",0,0,2021-02-01,1,6,3,0,0,0,a29d29095fa45a9ccac75ecd2a6ff7ad47a0b02f,231740914.0,https://www.semanticscholar.org/paper/a29d29095fa45a9ccac75ecd2a6ff7ad47a0b02f,International Conference on Applications of Natural Language to Data Bases,2021.0,28.0,16.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51215320', 'name': 'Agrin Hilmkil'}, {'authorId': '72185529', 'name': 'Sebastian Callh'}, {'authorId': '152192465', 'name': 'Matteo Barbieri'}, {'authorId': '19298650', 'name': 'L. R. Sütfeld'}, {'authorId': '52197229', 'name': 'Edvin Listo Zec'}, {'authorId': '2682635', 'name': 'Olof Mogren'}]",['RISE Research Institutes of Sweden'],['Sweden'],2021-02,['industrial']
2102.04506,Boliang Zhang,"Boliang Zhang, Ying Lyu, Ning Ding, Tianhao Shen, Zhaoyang Jia, Kun
  Han, Kevin Knight",A Hybrid Task-Oriented Dialog System with Domain and Task Adaptive Pretraining,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper describes our submission for the End-to-end Multi-domain Task Completion Dialog shared task at the 9th Dialog System Technology Challenge (DSTC-9). Participants in the shared task build an end-to-end task completion dialog system which is evaluated by human evaluation and a user simulator based automatic evaluation. Different from traditional pipelined approaches where modules are optimized individually and suffer from cascading failure, we propose an end-to-end dialog system that 1) uses Generative Pretraining 2 (GPT-2) as the backbone to jointly solve Natural Language Understanding, Dialog State Tracking, and Natural Language Generation tasks, 2) adopts Domain and Task Adaptive Pretraining to tailor GPT-2 to the dialog domain before finetuning, 3) utilizes heuristic pre/post-processing rules that greatly simplify the prediction tasks and improve generalizability, and 4) equips a fault tolerance module to correct errors and inappropriate responses. Our proposed method significantly outperforms baselines and ties for first place in the official evaluation. We make our source code publicly available. ","[{'version': 'v1', 'created': 'Mon, 8 Feb 2021 20:02:30 GMT'}]",2021-02-10,"[['Zhang', 'Boliang', ''], ['Lyu', 'Ying', ''], ['Ding', 'Ning', ''], ['Shen', 'Tianhao', ''], ['Jia', 'Zhaoyang', ''], ['Han', 'Kun', ''], ['Knight', 'Kevin', '']]",0,1,2021-02-08,1,7,2,1,1,0,da4bc774e2f6b00e665c581a5386b1f84de5934a,231855315.0,https://www.semanticscholar.org/paper/da4bc774e2f6b00e665c581a5386b1f84de5934a,arXiv.org,2021.0,27.0,5.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '38629264', 'name': 'Boliang Zhang'}, {'authorId': '134891055', 'name': 'Ying Lyu'}, {'authorId': '2066768061', 'name': 'N. Ding'}, {'authorId': '2057973326', 'name': 'Tianhao Shen'}, {'authorId': '2072783119', 'name': 'Zhaoyang Jia'}, {'authorId': '47054374', 'name': 'Kun Han'}, {'authorId': '152971314', 'name': 'Kevin Knight'}]",['DiDi AI Labs'],,2021-02,['industrial']
2102.09094,Adam D. Lelkes,"Adam D. Lelkes, Vinh Q. Tran, Cong Yu",Quiz-Style Question Generation for News Stories,,,,,cs.CL cs.CY cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  A large majority of American adults get at least some of their news from the Internet. Even though many online news products have the goal of informing their users about the news, they lack scalable and reliable tools for measuring how well they are achieving this goal, and therefore have to resort to noisy proxy metrics (e.g., click-through rates or reading time) to track their performance.   As a first step towards measuring news informedness at a scale, we study the problem of quiz-style multiple-choice question generation, which may be used to survey users about their knowledge of recent news. In particular, we formulate the problem as two sequence-to-sequence tasks: question-answer generation (QAG) and distractor, or incorrect answer, generation (DG). We introduce NewsQuizQA, the first dataset intended for quiz-style question-answer generation, containing 20K human written question-answer pairs from 5K news article summaries. Using this dataset, we propose a series of novel techniques for applying large pre-trained Transformer encoder-decoder models, namely PEGASUS and T5, to the tasks of question-answer generation and distractor generation.   We show that our models outperform strong baselines using both automated metrics and human raters. We provide a case study of running weekly quizzes on real-world users via the Google Surveys platform over the course of two months. We found that users generally found the automatically generated questions to be educational and enjoyable. Finally, to serve the research community, we are releasing the NewsQuizQA dataset. ","[{'version': 'v1', 'created': 'Thu, 18 Feb 2021 01:06:58 GMT'}]",2021-02-19,"[['Lelkes', 'Adam D.', ''], ['Tran', 'Vinh Q.', ''], ['Yu', 'Cong', '']]",0,0,2021-02-18,1,3,3,1,1,0,121ec105fed37e0f40deba6915a5b2a57e17e337,231951637.0,https://www.semanticscholar.org/paper/121ec105fed37e0f40deba6915a5b2a57e17e337,The Web Conference,2021.0,58.0,27.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143828990', 'name': 'Á. Lelkes'}, {'authorId': '2057663102', 'name': 'Vinh Q. Tran'}, {'authorId': '82737548', 'name': 'Cong Yu'}]",['Google'],['United States'],2021-02,['industrial']
2104.06182,Jose Manuel Gomez-Perez,"Andres Garcia-Silva, Cristian Berrio, Jose Manuel Gomez-Perez",Understanding Transformers for Bot Detection in Twitter,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we shed light on the impact of fine-tuning over social media data in the internal representations of neural language models. We focus on bot detection in Twitter, a key task to mitigate and counteract the automatic spreading of disinformation and bias in social media. We investigate the use of pre-trained language models to tackle the detection of tweets generated by a bot or a human account based exclusively on its content. Unlike the general trend in benchmarks like GLUE, where BERT generally outperforms generative transformers like GPT and GPT-2 for most classification tasks on regular text, we observe that fine-tuning generative transformers on a bot detection task produces higher accuracies. We analyze the architectural components of each transformer and study the effect of fine-tuning on their hidden states and output representations. Among our findings, we show that part of the syntactical information and distributional properties captured by BERT during pre-training is lost upon fine-tuning while the generative pre-training approach manage to preserve these properties. ","[{'version': 'v1', 'created': 'Tue, 13 Apr 2021 13:32:55 GMT'}]",2021-04-14,"[['Garcia-Silva', 'Andres', ''], ['Berrio', 'Cristian', ''], ['Gomez-Perez', 'Jose Manuel', '']]",0,1,2021-04-13,1,3,2,1,1,0,b43b6eccea45eb485305dbfc20aa6f994e065490,233219846.0,https://www.semanticscholar.org/paper/b43b6eccea45eb485305dbfc20aa6f994e065490,arXiv.org,2021.0,39.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1401950156', 'name': 'Andres Garcia-Silva'}, {'authorId': '2064324876', 'name': 'Cristian Berrio'}, {'authorId': '2420472', 'name': 'José Manuél Gómez-Pérez'}]","['Expert.ai Research Lab Prof. Waksman 10 28036 Madrid, Spain']",['Spain'],2021-04,['industrial']
2104.08231,Xiang Gao,"Xiang Gao, Yizhe Zhang, Michel Galley, Bill Dolan",An Adversarially-Learned Turing Test for Dialog Generation Models,"7 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The design of better automated dialogue evaluation metrics offers the potential of accelerate evaluation research on conversational AI. However, existing trainable dialogue evaluation models are generally restricted to classifiers trained in a purely supervised manner, which suffer a significant risk from adversarial attacking (e.g., a nonsensical response that enjoys a high classification score). To alleviate this risk, we propose an adversarial training approach to learn a robust model, ATT (Adversarial Turing Test), that discriminates machine-generated responses from human-written replies. In contrast to previous perturbation-based methods, our discriminator is trained by iteratively generating unrestricted and diverse adversarial examples using reinforcement learning. The key benefit of this unrestricted adversarial training approach is allowing the discriminator to improve robustness in an iterative attack-defense game. Our discriminator shows high accuracy on strong attackers including DialoGPT and GPT-3. ","[{'version': 'v1', 'created': 'Fri, 16 Apr 2021 17:13:14 GMT'}]",2021-04-19,"[['Gao', 'Xiang', ''], ['Zhang', 'Yizhe', ''], ['Galley', 'Michel', ''], ['Dolan', 'Bill', '']]",0,1,2021-04-16,1,4,1,1,0,1,574cddb0d56fa84708b259dcd2d81473b810e7ad,233289893.0,https://www.semanticscholar.org/paper/574cddb0d56fa84708b259dcd2d81473b810e7ad,arXiv.org,2021.0,38.0,1.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '71886367', 'name': 'Xiang Gao'}, {'authorId': '48378494', 'name': 'Yizhe Zhang'}, {'authorId': '1947267', 'name': 'Michel Galley'}, {'authorId': '66648221', 'name': 'Bill Dolan'}]",['Microsoft'],['United States'],2021-04,['industrial']
2104.08704,Tianyu Liu,"Tianyu Liu, Yizhe Zhang, Chris Brockett, Yi Mao, Zhifang Sui, Weizhu
  Chen and Bill Dolan",A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation,Accepted by ACL2022 main conference,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large pretrained generative models like GPT-3 often suffer from hallucinating non-existent or incorrect content, which undermines their potential merits in real applications. Existing work usually attempts to detect these hallucinations based on a corresponding oracle reference at a sentence or document level. However ground-truth references may not be readily available for many free-form text generation applications, and sentence- or document-level detection may fail to provide the fine-grained signals that would prevent fallacious content in real time. As a first step to addressing these issues, we propose a novel token-level, reference-free hallucination detection task and an associated annotated dataset named HaDes (HAllucination DEtection dataSet). To create this dataset, we first perturb a large number of text segments extracted from English language Wikipedia, and then verify these with crowd-sourced annotations. To mitigate label imbalance during annotation, we utilize an iterative model-in-loop strategy. We conduct comprehensive data analyses and create multiple baseline models. ","[{'version': 'v1', 'created': 'Sun, 18 Apr 2021 04:09:48 GMT'}, {'version': 'v2', 'created': 'Sat, 2 Apr 2022 15:23:44 GMT'}]",2022-04-05,"[['Liu', 'Tianyu', ''], ['Zhang', 'Yizhe', ''], ['Brockett', 'Chris', ''], ['Mao', 'Yi', ''], ['Sui', 'Zhifang', ''], ['Chen', 'Weizhu', ''], ['Dolan', 'Bill', '']]",0,1,2021-04-18,2,7,2,1,0,1,c6bf48f25e0a65d64d658b47326de5922ea7dd44,233296648.0,https://www.semanticscholar.org/paper/c6bf48f25e0a65d64d658b47326de5922ea7dd44,Annual Meeting of the Association for Computational Linguistics,2021.0,64.0,41.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1500520681', 'name': 'Tianyu Liu'}, {'authorId': '48378494', 'name': 'Yizhe Zhang'}, {'authorId': '70087270', 'name': 'C. Brockett'}, {'authorId': '145469202', 'name': 'Yi Mao'}, {'authorId': '3335836', 'name': 'Zhifang Sui'}, {'authorId': '2109136147', 'name': 'Weizhu Chen'}, {'authorId': '83415753', 'name': 'W. Dolan'}]",['Microsoft'],['United States'],2021-04,['industrial']
2104.08826,Kang Min Yoo,"Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, Woomyeong Park",GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation,"Accepted to EMNLP2021 Findings; 11 pages, 7 tables, 2 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large-scale language models such as GPT-3 are excellent few-shot learners, allowing them to be controlled via natural text prompts. Recent studies report that prompt-based direct classification eliminates the need for fine-tuning but lacks data and inference scalability. This paper proposes a novel data augmentation technique that leverages large-scale language models to generate realistic text samples from a mixture of real samples. We also propose utilizing soft-labels predicted by the language models, effectively distilling knowledge from the large-scale language models and creating textual perturbations simultaneously. We perform data augmentation experiments on diverse classification tasks and show that our method hugely outperforms existing text augmentation methods. Ablation studies and a qualitative analysis provide more insights into our approach. ","[{'version': 'v1', 'created': 'Sun, 18 Apr 2021 11:39:33 GMT'}, {'version': 'v2', 'created': 'Thu, 18 Nov 2021 07:56:58 GMT'}]",2021-11-19,"[['Yoo', 'Kang Min', ''], ['Park', 'Dongju', ''], ['Kang', 'Jaewook', ''], ['Lee', 'Sang-Woo', ''], ['Park', 'Woomyeong', '']]",0,1,2021-04-18,2,5,2,1,0,1,bbfdcbfee1762d48cae9db8637f21ea3c234ba30,233296100.0,https://www.semanticscholar.org/paper/bbfdcbfee1762d48cae9db8637f21ea3c234ba30,Conference on Empirical Methods in Natural Language Processing,2021.0,61.0,102.0,11.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31760501', 'name': 'Kang Min Yoo'}, {'authorId': '13453892', 'name': 'Dongju Park'}, {'authorId': '35518563', 'name': 'Jaewook Kang'}, {'authorId': '3226948', 'name': 'Sang-Woo Lee'}, {'authorId': '2087289230', 'name': 'Woomyeong Park'}]",['NAVER'],['South Korea'],2021-04,['industrial']
2104.12395,Ryuichi Yamamoto,"Kosuke Futamata, Byeongseon Park, Ryuichi Yamamoto, Kentaro Tachibana",Phrase break prediction with bidirectional encoder representations in Japanese text-to-speech synthesis,Submitted to INTERSPEECH 2021,,,,eess.AS cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel phrase break prediction method that combines implicit features extracted from a pre-trained large language model, a.k.a BERT, and explicit features extracted from BiLSTM with linguistic features. In conventional BiLSTM based methods, word representations and/or sentence representations are used as independent components. The proposed method takes account of both representations to extract the latent semantics, which cannot be captured by previous methods. The objective evaluation results show that the proposed method obtains an absolute improvement of 3.2 points for the F1 score compared with BiLSTM-based conventional methods using linguistic features. Moreover, the perceptual listening test results verify that a TTS system that applied our proposed method achieved a mean opinion score of 4.39 in prosody naturalness, which is highly competitive with the score of 4.37 for synthesized speech with ground-truth phrase breaks. ","[{'version': 'v1', 'created': 'Mon, 26 Apr 2021 08:29:29 GMT'}]",2021-04-27,"[['Futamata', 'Kosuke', ''], ['Park', 'Byeongseon', ''], ['Yamamoto', 'Ryuichi', ''], ['Tachibana', 'Kentaro', '']]",0,0,2021-04-26,1,4,3,0,0,0,cb608e823089311eab56e6f0c23e44e8282f932e,233394246.0,https://www.semanticscholar.org/paper/cb608e823089311eab56e6f0c23e44e8282f932e,Interspeech,2021.0,29.0,12.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2084555045', 'name': 'Kosuke Futamata'}, {'authorId': '102536428', 'name': 'Byeong-Cheol Park'}, {'authorId': '47146577', 'name': 'Ryuichi Yamamoto'}, {'authorId': '2940047', 'name': 'Kentaro Tachibana'}]",['Line Corporation (Japan)'],['Japan'],2021-04,['industrial']
2105.03023,Alisa Liu,"Alisa Liu, Maarten Sap, Ximing Lu, Swabha Swayamdipta, Chandra
  Bhagavatula, Noah A. Smith, Yejin Choi",DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts,ACL 2021 camera-ready,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Despite recent advances in natural language generation, it remains challenging to control attributes of generated text. We propose DExperts: Decoding-time Experts, a decoding-time method for controlled text generation that combines a pretrained language model with ""expert"" LMs and/or ""anti-expert"" LMs in a product of experts. Intuitively, under the ensemble, tokens only get high probability if they are considered likely by the experts, and unlikely by the anti-experts. We apply DExperts to language detoxification and sentiment-controlled generation, where we outperform existing controllable generation methods on both automatic and human evaluations. Moreover, because DExperts operates only on the output of the pretrained LM, it is effective with (anti-)experts of smaller size, including when operating on GPT-3. Our work highlights the promise of tuning small LMs on text with (un)desirable attributes for efficient decoding-time steering. ","[{'version': 'v1', 'created': 'Fri, 7 May 2021 01:19:38 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Jun 2021 05:26:11 GMT'}]",2021-06-04,"[['Liu', 'Alisa', ''], ['Sap', 'Maarten', ''], ['Lu', 'Ximing', ''], ['Swayamdipta', 'Swabha', ''], ['Bhagavatula', 'Chandra', ''], ['Smith', 'Noah A.', ''], ['Choi', 'Yejin', '']]",0,1,2021-05-07,2,7,1,1,0,1,02f033482b8045c687316ef81ba7aaae9f0a2e1c,235313967.0,https://www.semanticscholar.org/paper/02f033482b8045c687316ef81ba7aaae9f0a2e1c,Annual Meeting of the Association for Computational Linguistics,2021.0,52.0,156.0,45.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '94500147', 'name': 'Alisa Liu'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '2705113', 'name': 'Swabha Swayamdipta'}, {'authorId': '1857797', 'name': 'Chandra Bhagavatula'}, {'authorId': '144365875', 'name': 'Noah A. Smith'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]",['Allen Institute for Artificial Intelligence'],['United States'],2021-05,['industrial']
2105.09052,Daryna Dementieva,"Daryna Dementieva, Daniil Moskovskiy, Varvara Logacheva, David Dale,
  Olga Kozlova, Nikita Semenov, and Alexander Panchenko",Methods for Detoxification of Texts for the Russian Language,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce the first study of automatic detoxification of Russian texts to combat offensive language. Such a kind of textual style transfer can be used, for instance, for processing toxic content in social media. While much work has been done for the English language in this field, it has never been solved for the Russian language yet. We test two types of models - unsupervised approach based on BERT architecture that performs local corrections and supervised approach based on pretrained language GPT-2 model - and compare them with several baselines. In addition, we describe evaluation setup providing training datasets and metrics for automatic evaluation. The results show that the tested approaches can be successfully used for detoxification, although there is room for improvement. ","[{'version': 'v1', 'created': 'Wed, 19 May 2021 10:37:44 GMT'}]",2021-05-20,"[['Dementieva', 'Daryna', ''], ['Moskovskiy', 'Daniil', ''], ['Logacheva', 'Varvara', ''], ['Dale', 'David', ''], ['Kozlova', 'Olga', ''], ['Semenov', 'Nikita', ''], ['Panchenko', 'Alexander', '']]",0,1,2021-05-19,1,7,2,1,1,0,2c5b31a02133dea21cf94fde67c8948115441432,234777967.0,https://www.semanticscholar.org/paper/2c5b31a02133dea21cf94fde67c8948115441432,Multimodal Technologies and Interaction,2021.0,46.0,8.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2027664710', 'name': 'D. Dementieva'}, {'authorId': '2097709956', 'name': 'Daniil Moskovskiy'}, {'authorId': '145089549', 'name': 'V. Logacheva'}, {'authorId': '2097711561', 'name': 'David Dale'}, {'authorId': '2062842110', 'name': 'Olga Kozlova'}, {'authorId': '2094581992', 'name': 'Nikita Semenov'}, {'authorId': '2027664756', 'name': 'A. Panchenko'}]","['Skolkovo Institute of Science and Technology', 'Mobile TeleSystems (MTS), Moscow, Russia']",['Russia'],2021-05,"['industrial', 'industrial']"
2105.11812,Firas Jarboui,"Firas Jarboui, Vianney Perchet",A Generalised Inverse Reinforcement Learning Framework,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The gloabal objective of inverse Reinforcement Learning (IRL) is to estimate the unknown cost function of some MDP base on observed trajectories generated by (approximate) optimal policies. The classical approach consists in tuning this cost function so that associated optimal trajectories (that minimise the cumulative discounted cost, i.e. the classical RL loss) are 'similar' to the observed ones. Prior contributions focused on penalising degenerate solutions and improving algorithmic scalability. Quite orthogonally to them, we question the pertinence of characterising optimality with respect to the cumulative discounted cost as it induces an implicit bias against policies with longer mixing times. State of the art value based RL algorithms circumvent this issue by solving for the fixed point of the Bellman optimality operator, a stronger criterion that is not well defined for the inverse problem. To alleviate this bias in IRL, we introduce an alternative training loss that puts more weights on future states which yields a reformulation of the (maximum entropy) IRL problem. The algorithms we devised exhibit enhanced performances (and similar tractability) than off-the-shelf ones in multiple OpenAI gym environments. ","[{'version': 'v1', 'created': 'Tue, 25 May 2021 10:30:45 GMT'}]",2021-05-26,"[['Jarboui', 'Firas', ''], ['Perchet', 'Vianney', '']]",0,0,2021-05-25,1,2,1,0,0,0,03e87b08f4d9d512e8da2d8d788eec0f67363eac,235187320.0,https://www.semanticscholar.org/paper/03e87b08f4d9d512e8da2d8d788eec0f67363eac,arXiv.org,2021.0,42.0,4.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '25905248', 'name': 'Firas Jarboui'}, {'authorId': '3087994', 'name': 'Vianney Perchet'}]","[""École Nationale de la Statistique et de l'Administration Économique"", 'École Normale Supérieure - PSL']",['France'],2021-05,"['industrial', 'industrial']"
2105.13328,Pratyush Muthukumar,"Pratyush Muthukumar, Karishma Muthukumar, Deepan Muthirayan, Pramod
  Khargonekar",Generative Adversarial Imitation Learning for Empathy-based AI,"11 pages, 6 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Generative adversarial imitation learning (GAIL) is a model-free algorithm that has been shown to provide strong results in imitating complex behaviors in high-dimensional environments. In this paper, we utilize the GAIL model for text generation to develop empathy-based context-aware conversational AI. Our model uses an expert trajectory of empathetic prompt-response dialogues which can accurately exhibit the correct empathetic emotion when generating a response. The Generator of the GAIL model uses the GPT-2 sequential pre-trained language model trained on 117 million parameters from 40 GB of internet data. We propose a novel application of an approach used in transfer learning to fine tune the GPT-2 model in order to generate concise, user-specific empathetic responses validated against the Discriminator. Our novel GAIL model utilizes a sentiment analysis history-based reinforcement learning approach to empathetically respond to human interactions in a personalized manner. We find that our model's response scores on various human-generated prompts collected from the Facebook Empathetic Dialogues dataset outperform baseline counterparts. Moreover, our model improves upon various history-based conversational AI models developed recently, as our model's performance over a sustained conversation of 3 or more interactions outperform similar conversational AI models. ","[{'version': 'v1', 'created': 'Thu, 27 May 2021 17:37:37 GMT'}]",2021-05-28,"[['Muthukumar', 'Pratyush', ''], ['Muthukumar', 'Karishma', ''], ['Muthirayan', 'Deepan', ''], ['Khargonekar', 'Pramod', '']]",0,1,2021-05-27,1,4,1,1,1,0,3708ed2aa909ebde32647257f5ffb3c6548b0e8d,235212102.0,https://www.semanticscholar.org/paper/3708ed2aa909ebde32647257f5ffb3c6548b0e8d,arXiv.org,2021.0,25.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1578249201', 'name': 'Pratyush Muthukumar'}, {'authorId': '2105839949', 'name': 'Karishma Muthukumar'}, {'authorId': '19278602', 'name': 'Deepan Muthirayan'}, {'authorId': '1759103', 'name': 'P. Khargonekar'}]","['Information and Computer Science UC Irvine Irvine, CA 92697']",,2021-05,['industrial']
2106.04279,Sainbayar Sukhbaatar,"Da Ju, Stephen Roller, Sainbayar Sukhbaatar, Jason Weston",Staircase Attention for Recurrent Processing of Sequences,,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Attention mechanisms have become a standard tool for sequence modeling tasks, in particular by stacking self-attention layers over the entire input sequence as in the Transformer architecture. In this work we introduce a novel attention procedure called staircase attention that, unlike self-attention, operates across the sequence (in time) recurrently processing the input by adding another step of processing. A step in the staircase comprises of backward tokens (encoding the sequence so far seen) and forward tokens (ingesting a new part of the sequence), or an extreme Ladder version with a forward step of zero that simply repeats the Transformer on each step of the ladder, sharing the weights. We thus describe a family of such models that can trade off performance and compute, by either increasing the amount of recurrence through time, the amount of sequential processing via recurrence in depth, or both. Staircase attention is shown to be able to solve tasks that involve tracking that conventional Transformers cannot, due to this recurrence. Further, it is shown to provide improved modeling power for the same size model (number of parameters) compared to self-attentive Transformers on large language modeling and dialogue tasks, yielding significant perplexity gains. ","[{'version': 'v1', 'created': 'Tue, 8 Jun 2021 12:19:31 GMT'}]",2021-06-09,"[['Ju', 'Da', ''], ['Roller', 'Stephen', ''], ['Sukhbaatar', 'Sainbayar', ''], ['Weston', 'Jason', '']]",0,0,2021-06-08,1,4,2,0,0,0,b50815251c948f00baedccaf5f56c281ffa7650f,235368027.0,https://www.semanticscholar.org/paper/b50815251c948f00baedccaf5f56c281ffa7650f,Neural Information Processing Systems,2021.0,35.0,7.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3092435', 'name': 'Da Ju'}, {'authorId': '3849208', 'name': 'Stephen Roller'}, {'authorId': '2265067', 'name': 'Sainbayar Sukhbaatar'}, {'authorId': '145183709', 'name': 'J. Weston'}]",['Meta'],['United States'],2021-06,['industrial']
2106.04426,Jason  Weston,"Stephen Roller, Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston",Hash Layers For Large Sparse Models,,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the training of sparse layers that use different parameters for different inputs based on hashing in large Transformer models. Specifically, we modify the feedforward layer to hash to different sets of weights depending on the current token, over all tokens in the sequence. We show that this procedure either outperforms or is competitive with learning-to-route mixture-of-expert methods such as Switch Transformers and BASE Layers, while requiring no routing parameters or extra terms in the objective function such as a load balancing loss, and no sophisticated assignment algorithm. We study the performance of different hashing techniques, hash sizes and input features, and show that balanced and random hashes focused on the most local features work best, compared to either learning clusters or using longer-range context. We show our approach works well both on large language modeling and dialogue tasks, and on downstream fine-tuning tasks. ","[{'version': 'v1', 'created': 'Tue, 8 Jun 2021 14:54:24 GMT'}, {'version': 'v2', 'created': 'Wed, 16 Jun 2021 15:30:23 GMT'}, {'version': 'v3', 'created': 'Tue, 20 Jul 2021 13:46:33 GMT'}]",2021-07-21,"[['Roller', 'Stephen', ''], ['Sukhbaatar', 'Sainbayar', ''], ['Szlam', 'Arthur', ''], ['Weston', 'Jason', '']]",0,0,2021-06-08,3,4,2,0,0,0,0611d2f2ea6a3c8fb8534f42758a5a3e9c7bc8fe,235367626.0,https://www.semanticscholar.org/paper/0611d2f2ea6a3c8fb8534f42758a5a3e9c7bc8fe,Neural Information Processing Systems,2021.0,39.0,98.0,29.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3849208', 'name': 'Stephen Roller'}, {'authorId': '2265067', 'name': 'Sainbayar Sukhbaatar'}, {'authorId': '3149531', 'name': 'Arthur Szlam'}, {'authorId': '145183709', 'name': 'J. Weston'}]",['Meta'],['United States'],2021-06,['industrial']
2106.05068,Firas Jarboui,"Firas Jarboui, Vianney Perchet",Offline Inverse Reinforcement Learning,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The objective of offline RL is to learn optimal policies when a fixed exploratory demonstrations data-set is available and sampling additional observations is impossible (typically if this operation is either costly or rises ethical questions). In order to solve this problem, off the shelf approaches require a properly defined cost function (or its evaluation on the provided data-set), which are seldom available in practice. To circumvent this issue, a reasonable alternative is to query an expert for few optimal demonstrations in addition to the exploratory data-set. The objective is then to learn an optimal policy w.r.t. the expert's latent cost function. Current solutions either solve a behaviour cloning problem (which does not leverage the exploratory data) or a reinforced imitation learning problem (using a fixed cost function that discriminates available exploratory trajectories from expert ones). Inspired by the success of IRL techniques in achieving state of the art imitation performances in online settings, we exploit GAN based data augmentation procedures to construct the first offline IRL algorithm. The obtained policies outperformed the aforementioned solutions on multiple OpenAI gym environments. ","[{'version': 'v1', 'created': 'Wed, 9 Jun 2021 13:44:06 GMT'}]",2021-06-10,"[['Jarboui', 'Firas', ''], ['Perchet', 'Vianney', '']]",0,0,2021-06-09,1,2,1,0,0,0,97b5623306afe19757946c7bc449277981c9e335,235376869.0,https://www.semanticscholar.org/paper/97b5623306afe19757946c7bc449277981c9e335,arXiv.org,2021.0,32.0,8.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '25905248', 'name': 'Firas Jarboui'}, {'authorId': '3087994', 'name': 'Vianney Perchet'}]","[""École Nationale de la Statistique et de l'Administration Économique"", 'École Normale Supérieure - PSL']",['France'],2021-06,"['industrial', 'industrial']"
2106.05784,Tal Schuster,"Tal Schuster, Ashwin Kalyan, Oleksandr Polozov, Adam Tauman Kalai",Programming Puzzles,"NeurIPS 2021 (Datasets and Benchmarks Track). Puzzles repository:
  https://github.com/microsoft/PythonProgrammingPuzzles",,,,cs.LG cs.AI cs.CL cs.PL cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a new type of programming challenge called programming puzzles, as an objective and comprehensive evaluation of program synthesis, and release an open-source dataset of Python Programming Puzzles (P3). Each puzzle is defined by a short Python program $f$, and the goal is to find an input which makes $f$ return True. The puzzles are objective in that each one is specified entirely by the source code of its verifier $f$, so evaluating $f$ is all that is needed to test a candidate solution. They do not require an answer key or input/output examples, nor do they depend on natural language understanding. The dataset is comprehensive in that it spans problems of a range of difficulties and domains, ranging from trivial string manipulation problems, to classic programming puzzles (e.g., Tower of Hanoi), to interview/competitive-programming problems (e.g., dynamic programming), to longstanding open problems in algorithms and mathematics (e.g., factoring). We develop baseline enumerative program synthesis, GPT-3 and Codex solvers that are capable of solving puzzles -- even without access to any reference solutions -- by learning from their own past solutions. Codex performs best, solving up to 18% of 397 test problems with a single try and 80% of the problems with 1,000 tries per problem. In a small user study, we find a positive correlation between puzzle-solving performance and coding experience, and between the puzzle difficulty for humans and AI solvers. Therefore, further improvements on P3 could have a significant impact on many program synthesis areas. ","[{'version': 'v1', 'created': 'Thu, 10 Jun 2021 14:37:28 GMT'}, {'version': 'v2', 'created': 'Mon, 20 Sep 2021 03:41:06 GMT'}, {'version': 'v3', 'created': 'Sat, 6 Nov 2021 20:53:50 GMT'}]",2021-11-09,"[['Schuster', 'Tal', ''], ['Kalyan', 'Ashwin', ''], ['Polozov', 'Oleksandr', ''], ['Kalai', 'Adam Tauman', '']]",0,1,2021-06-10,3,4,5,2,0,2,f7664102a451332ed7e1286561b2f621eaff128d,235390706.0,https://www.semanticscholar.org/paper/f7664102a451332ed7e1286561b2f621eaff128d,NeurIPS Datasets and Benchmarks,2021.0,85.0,22.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32303439', 'name': 'Tal Schuster'}, {'authorId': '51043791', 'name': 'A. Kalyan'}, {'authorId': '2636739', 'name': 'Oleksandr Polozov'}, {'authorId': '2186481', 'name': 'A. Kalai'}]","['Allen In', 'Microsoft']","['India', 'United States']",2021-06,"['industrial', 'industrial']"
2106.09685,Edward J. Hu,"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi
  Li, Shean Wang, Lu Wang, Weizhu Chen",LoRA: Low-Rank Adaptation of Large Language Models,"Draft V2 includes better baselines, experiments on GLUE, and more on
  adapter latency",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA. ","[{'version': 'v1', 'created': 'Thu, 17 Jun 2021 17:37:18 GMT'}, {'version': 'v2', 'created': 'Sat, 16 Oct 2021 18:40:34 GMT'}]",2021-10-19,"[['Hu', 'Edward J.', ''], ['Shen', 'Yelong', ''], ['Wallis', 'Phillip', ''], ['Allen-Zhu', 'Zeyuan', ''], ['Li', 'Yuanzhi', ''], ['Wang', 'Shean', ''], ['Wang', 'Lu', ''], ['Chen', 'Weizhu', '']]",0,1,2021-06-17,2,8,3,2,1,1,a8ca46b171467ceb2d7652fbfb67fe701ad86092,235458009.0,https://www.semanticscholar.org/paper/a8ca46b171467ceb2d7652fbfb67fe701ad86092,International Conference on Learning Representations,2021.0,65.0,1546.0,374.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2157840220', 'name': 'J. E. Hu'}, {'authorId': '1752875', 'name': 'Yelong Shen'}, {'authorId': '104100507', 'name': 'Phillip Wallis'}, {'authorId': '1388725932', 'name': 'Zeyuan Allen-Zhu'}, {'authorId': '2110486765', 'name': 'Yuanzhi Li'}, {'authorId': '2135571585', 'name': 'Shean Wang'}, {'authorId': '2109136147', 'name': 'Weizhu Chen'}]",['Microsoft'],['United States'],2021-06,['industrial']
2106.10328,Christy Dennison,Irene Solaiman (1) and Christy Dennison (1) ((1) OpenAI),Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets,Both authors contributed equally. Accepted at NeurIPS 2021,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by-sa/4.0/,"  Language models can generate harmful and biased outputs and exhibit undesirable behavior according to a given cultural context. We propose a Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets, an iterative process to significantly change model behavior by crafting and fine-tuning on a dataset that reflects a predetermined set of target values. We evaluate our process using three metrics: quantitative metrics with human evaluations that score output adherence to a target value, toxicity scoring on outputs; and qualitative metrics analyzing the most common word associated with a given social category. Through each iteration, we add additional training dataset examples based on observed shortcomings from evaluations. PALMS performs significantly better on all metrics compared to baseline and control models for a broad range of GPT-3 language model sizes without compromising capability integrity. We find that the effectiveness of PALMS increases with model size. We show that significantly adjusting language model behavior is feasible with a small, hand-curated dataset. ","[{'version': 'v1', 'created': 'Fri, 18 Jun 2021 19:38:28 GMT'}, {'version': 'v2', 'created': 'Tue, 23 Nov 2021 17:23:12 GMT'}]",2021-11-24,"[['Solaiman', 'Irene', '', 'OpenAI'], ['Dennison', 'Christy', '', 'OpenAI']]",0,1,2021-06-18,2,2,2,1,0,1,d624bc273821c871f899d8256a34be40c09fc3cd,235489789.0,https://www.semanticscholar.org/paper/d624bc273821c871f899d8256a34be40c09fc3cd,Neural Information Processing Systems,2021.0,42.0,139.0,12.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1404060690', 'name': 'Irene Solaiman'}, {'authorId': '1468636850', 'name': 'Christy Dennison'}]","['Zillow Group (United States)', 'Neuroscience Research Australia']","['United States', 'Australia']",2021-06,"['industrial', 'industrial']"
2106.13928,Rui Huang,"Jingxuan Li, Rui Huang, Wei Li, Kai Yao, Weiguo Tan",Toward Less Hidden Cost of Code Completion with Acceptance and Ranking Models,"10 pages, 7 figures, accepted by ICSME 2021",,,,cs.SE cs.AI cs.PL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Code completion is widely used by software developers to provide coding suggestions given a partially written code snippet. Apart from the traditional code completion methods, which only support single token completion at minimal positions, recent studies show the ability to provide longer code completion at more flexible positions. However, such frequently triggered and longer completion results reduce the overall precision as they generate more invalid results. Moreover, different studies are mostly incompatible with each other. Thus, it is vital to develop an ensemble framework that can combine results from multiple models to draw merits and offset defects of each model.   This paper conducts a coding simulation to collect data from code context and different code completion models and then apply the data in two tasks. First, we introduce an acceptance model which can dynamically control whether to display completion results to the developer. It uses simulation features to predict whether correct results exist in the output of these models. Our best model reduces the percentage of false-positive completion from 55.09% to 17.44%. Second, we design a fusion ranking scheme that can automatically identify the priority of the completion results and reorder the candidates from multiple code completion models. This scheme is flexible in dealing with various models, regardless of the type or the length of their completion results. We integrate this ranking scheme with two frequency models and a GPT-2 styled language model, along with the acceptance model to yield 27.80% and 37.64% increase in TOP1 and TOP5 accuracy, respectively. In addition, we propose a new code completion evaluation metric, Benefit-Cost Ratio(BCR), taking into account the benefit of keystrokes saving and hidden cost of completion list browsing, which is closer to real coder experience scenario. ","[{'version': 'v1', 'created': 'Sat, 26 Jun 2021 03:02:49 GMT'}]",2021-06-29,"[['Li', 'Jingxuan', ''], ['Huang', 'Rui', ''], ['Li', 'Wei', ''], ['Yao', 'Kai', ''], ['Tan', 'Weiguo', '']]",0,1,2021-06-26,1,5,3,1,1,0,eb41816d63465d8cb6af546ccfa28de029b027ee,235658662.0,https://www.semanticscholar.org/paper/eb41816d63465d8cb6af546ccfa28de029b027ee,IEEE International Conference on Software Maintenance and Evolution,2021.0,41.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2157341042', 'name': 'Jingxuan Li'}, {'authorId': '2140386274', 'name': 'Rui Huang'}, {'authorId': '2157337593', 'name': 'Wei Li'}, {'authorId': '40895035', 'name': 'Kai-Lang Yao'}, {'authorId': '2115474385', 'name': 'Weiguo Tan'}]",['Huawei Technologies (China)'],['China'],2021-06,['industrial']
2107.02137,Shuohuan Wang,"Yu Sun, Shuohuan Wang, Shikun Feng, Siyu Ding, Chao Pang, Junyuan
  Shang, Jiaxiang Liu, Xuyi Chen, Yanbin Zhao, Yuxiang Lu, Weixin Liu, Zhihua
  Wu, Weibao Gong, Jianzhong Liang, Zhizhou Shang, Peng Sun, Wei Liu, Xuan
  Ouyang, Dianhai Yu, Hao Tian, Hua Wu, Haifeng Wang",ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained models have achieved state-of-the-art results in various Natural Language Processing (NLP) tasks. Recent works such as T5 and GPT-3 have shown that scaling up pre-trained language models can improve their generalization abilities. Particularly, the GPT-3 model with 175 billion parameters shows its strong task-agnostic zero-shot/few-shot learning capabilities. Despite their success, these large-scale models are trained on plain texts without introducing knowledge such as linguistic knowledge and world knowledge. In addition, most large-scale models are trained in an auto-regressive way. As a result, this kind of traditional fine-tuning approach demonstrates relatively weak performance when solving downstream language understanding tasks. In order to solve the above problems, we propose a unified framework named ERNIE 3.0 for pre-training large-scale knowledge enhanced models. It fuses auto-regressive network and auto-encoding network, so that the trained model can be easily tailored for both natural language understanding and generation tasks with zero-shot learning, few-shot learning or fine-tuning. We trained the model with 10 billion parameters on a 4TB corpus consisting of plain texts and a large-scale knowledge graph. Empirical results show that the model outperforms the state-of-the-art models on 54 Chinese NLP tasks, and its English version achieves the first place on the SuperGLUE benchmark (July 3, 2021), surpassing the human performance by +0.8% (90.6% vs. 89.8%). ","[{'version': 'v1', 'created': 'Mon, 5 Jul 2021 16:54:59 GMT'}]",2021-07-06,"[['Sun', 'Yu', ''], ['Wang', 'Shuohuan', ''], ['Feng', 'Shikun', ''], ['Ding', 'Siyu', ''], ['Pang', 'Chao', ''], ['Shang', 'Junyuan', ''], ['Liu', 'Jiaxiang', ''], ['Chen', 'Xuyi', ''], ['Zhao', 'Yanbin', ''], ['Lu', 'Yuxiang', ''], ['Liu', 'Weixin', ''], ['Wu', 'Zhihua', ''], ['Gong', 'Weibao', ''], ['Liang', 'Jianzhong', ''], ['Shang', 'Zhizhou', ''], ['Sun', 'Peng', ''], ['Liu', 'Wei', ''], ['Ouyang', 'Xuan', ''], ['Yu', 'Dianhai', ''], ['Tian', 'Hao', ''], ['Wu', 'Hua', ''], ['Wang', 'Haifeng', '']]",0,1,2021-07-05,1,22,1,3,1,2,319b84be7a843250bc81d7086f79a4126d550277,235731579.0,https://www.semanticscholar.org/paper/319b84be7a843250bc81d7086f79a4126d550277,arXiv.org,2021.0,102.0,194.0,27.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2117103617', 'name': 'Yu Sun'}, {'authorId': '104463827', 'name': 'Shuohuan Wang'}, {'authorId': '1718657', 'name': 'Shikun Feng'}, {'authorId': '2093193326', 'name': 'Siyu Ding'}, {'authorId': '2054086618', 'name': 'Chao Pang'}, {'authorId': '40861754', 'name': 'Junyuan Shang'}, {'authorId': '2144130913', 'name': 'Jiaxiang Liu'}, {'authorId': '2109214103', 'name': 'Xuyi Chen'}, {'authorId': '2117889541', 'name': 'Yanbin Zhao'}, {'authorId': '2140025135', 'name': 'Yuxiang Lu'}, {'authorId': '2109563578', 'name': 'Weixin Liu'}, {'authorId': '47039787', 'name': 'Zhihua Wu'}, {'authorId': '2117587198', 'name': 'Weibao Gong'}, {'authorId': '2118676105', 'name': 'Jianzhong Liang'}, {'authorId': '2117586669', 'name': 'Zhizhou Shang'}, {'authorId': '2075416111', 'name': 'Peng Sun'}, {'authorId': None, 'name': 'Wei Liu'}, {'authorId': '2227615315', 'name': 'Ouyang Xuan'}, {'authorId': '3046102', 'name': 'Dianhai Yu'}, {'authorId': '50007795', 'name': 'Hao Tian'}, {'authorId': '40354707', 'name': 'Hua Wu'}, {'authorId': '144270731', 'name': 'Haifeng Wang'}]",['Siyu Ding Chao Pang'],,2021-07,['industrial']
2107.03374,Mark Chen,"Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de
  Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,
  Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy
  Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder,
  Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens
  Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias
  Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William
  Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor
  Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher
  Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa,
  Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter
  Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech
  Zaremba",Evaluating Large Language Models Trained on Code,"corrected typos, added references, added authors, added
  acknowledgements",,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics. ","[{'version': 'v1', 'created': 'Wed, 7 Jul 2021 17:41:24 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Jul 2021 17:16:02 GMT'}]",2021-07-15,"[['Chen', 'Mark', ''], ['Tworek', 'Jerry', ''], ['Jun', 'Heewoo', ''], ['Yuan', 'Qiming', ''], ['Pinto', 'Henrique Ponde de Oliveira', ''], ['Kaplan', 'Jared', ''], ['Edwards', 'Harri', ''], ['Burda', 'Yuri', ''], ['Joseph', 'Nicholas', ''], ['Brockman', 'Greg', ''], ['Ray', 'Alex', ''], ['Puri', 'Raul', ''], ['Krueger', 'Gretchen', ''], ['Petrov', 'Michael', ''], ['Khlaaf', 'Heidy', ''], ['Sastry', 'Girish', ''], ['Mishkin', 'Pamela', ''], ['Chan', 'Brooke', ''], ['Gray', 'Scott', ''], ['Ryder', 'Nick', ''], ['Pavlov', 'Mikhail', ''], ['Power', 'Alethea', ''], ['Kaiser', 'Lukasz', ''], ['Bavarian', 'Mohammad', ''], ['Winter', 'Clemens', ''], ['Tillet', 'Philippe', ''], ['Such', 'Felipe Petroski', ''], ['Cummings', 'Dave', ''], ['Plappert', 'Matthias', ''], ['Chantzis', 'Fotios', ''], ['Barnes', 'Elizabeth', ''], ['Herbert-Voss', 'Ariel', ''], ['Guss', 'William Hebgen', ''], ['Nichol', 'Alex', ''], ['Paino', 'Alex', ''], ['Tezak', 'Nikolas', ''], ['Tang', 'Jie', ''], ['Babuschkin', 'Igor', ''], ['Balaji', 'Suchir', ''], ['Jain', 'Shantanu', ''], ['Saunders', 'William', ''], ['Hesse', 'Christopher', ''], ['Carr', 'Andrew N.', ''], ['Leike', 'Jan', ''], ['Achiam', 'Josh', ''], ['Misra', 'Vedant', ''], ['Morikawa', 'Evan', ''], ['Radford', 'Alec', ''], ['Knight', 'Matthew', ''], ['Brundage', 'Miles', ''], ['Murati', 'Mira', ''], ['Mayer', 'Katie', ''], ['Welinder', 'Peter', ''], ['McGrew', 'Bob', ''], ['Amodei', 'Dario', ''], ['McCandlish', 'Sam', ''], ['Sutskever', 'Ilya', ''], ['Zaremba', 'Wojciech', '']]",0,1,2021-07-07,2,58,1,2,0,2,acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269,235755472.0,https://www.semanticscholar.org/paper/acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269,arXiv.org,2021.0,127.0,1729.0,375.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108828435', 'name': 'Mark Chen'}, {'authorId': '2065005836', 'name': 'Jerry Tworek'}, {'authorId': '35450887', 'name': 'Heewoo Jun'}, {'authorId': '153930486', 'name': 'Qiming Yuan'}, {'authorId': '2117715024', 'name': 'Henrique Ponde'}, {'authorId': '2053807409', 'name': 'Jared Kaplan'}, {'authorId': '144632352', 'name': 'Harrison Edwards'}, {'authorId': '51178856', 'name': 'Yura Burda'}, {'authorId': '2117706920', 'name': 'Nicholas Joseph'}, {'authorId': '2065151121', 'name': 'Greg Brockman'}, {'authorId': '2064770039', 'name': 'Alex Ray'}, {'authorId': '41158993', 'name': 'Raul Puri'}, {'authorId': '2064404342', 'name': 'Gretchen Krueger'}, {'authorId': '2136008481', 'name': 'Michael Petrov'}, {'authorId': '2103414', 'name': 'Heidy Khlaaf'}, {'authorId': '144864359', 'name': 'Girish Sastry'}, {'authorId': '2051714782', 'name': 'Pamela Mishkin'}, {'authorId': '1466431052', 'name': 'Brooke Chan'}, {'authorId': '145565184', 'name': 'S. Gray'}, {'authorId': '39849748', 'name': 'Nick Ryder'}, {'authorId': '2068123790', 'name': 'Mikhail Pavlov'}, {'authorId': '146162186', 'name': 'Alethea Power'}, {'authorId': '40527594', 'name': 'Lukasz Kaiser'}, {'authorId': '2400764', 'name': 'Mohammad Bavarian'}, {'authorId': '2059411355', 'name': 'Clemens Winter'}, {'authorId': '2704719', 'name': 'Philippe Tillet'}, {'authorId': '9927844', 'name': 'F. Such'}, {'authorId': '80876468', 'name': 'D. Cummings'}, {'authorId': '3407285', 'name': 'Matthias Plappert'}, {'authorId': '2117714459', 'name': 'Fotios Chantzis'}, {'authorId': '2057742918', 'name': 'Elizabeth Barnes'}, {'authorId': '1404060687', 'name': 'Ariel Herbert-Voss'}, {'authorId': '39121861', 'name': 'William H. Guss'}, {'authorId': '38967461', 'name': 'Alex Nichol'}, {'authorId': '2256699302', 'name': 'Igor Babuschkin'}, {'authorId': '2054519183', 'name': 'S. Balaji'}, {'authorId': '150298413', 'name': 'Shantanu Jain'}, {'authorId': '153480842', 'name': 'A. Carr'}, {'authorId': '2990741', 'name': 'J. Leike'}, {'authorId': '3381809', 'name': 'Joshua Achiam'}, {'authorId': '40055795', 'name': 'Vedant Misra'}, {'authorId': '1404556973', 'name': 'Evan Morikawa'}, {'authorId': '38909097', 'name': 'Alec Radford'}, {'authorId': '3555117', 'name': 'M. Knight'}, {'authorId': '35167962', 'name': 'Miles Brundage'}, {'authorId': '2117715631', 'name': 'Mira Murati'}, {'authorId': '2059169400', 'name': 'Katie Mayer'}, {'authorId': '2930640', 'name': 'P. Welinder'}, {'authorId': '39593364', 'name': 'Bob McGrew'}, {'authorId': '2698777', 'name': 'Dario Amodei'}, {'authorId': '52238703', 'name': 'Sam McCandlish'}, {'authorId': '1701686', 'name': 'Ilya Sutskever'}, {'authorId': '2563432', 'name': 'Wojciech Zaremba'}]","['OpenAI', 'Jerry Tworek', 'Zipline, South San Francisco, California, USA.', 'Anthropic']",['United States'],2021-07,"['industrial', 'industrial', 'industrial', 'industrial']"
2107.04009,Byungsoo Kim,"Byungsoo Kim, Hangyeol Yu, Dongmin Shin, Youngduck Choi",Knowledge Transfer by Discriminative Pre-training for Academic Performance Prediction,"Nominated for the best short paper award of EDM 2021. This is an
  extended version of the published one",,,,cs.CY cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The needs for precisely estimating a student's academic performance have been emphasized with an increasing amount of attention paid to Intelligent Tutoring System (ITS). However, since labels for academic performance, such as test scores, are collected from outside of ITS, obtaining the labels is costly, leading to label-scarcity problem which brings challenge in taking machine learning approaches for academic performance prediction. To this end, inspired by the recent advancement of pre-training method in natural language processing community, we propose DPA, a transfer learning framework with Discriminative Pre-training tasks for Academic performance prediction. DPA pre-trains two models, a generator and a discriminator, and fine-tunes the discriminator on academic performance prediction. In DPA's pre-training phase, a sequence of interactions where some tokens are masked is provided to the generator which is trained to reconstruct the original sequence. Then, the discriminator takes an interaction sequence where the masked tokens are replaced by the generator's outputs, and is trained to predict the originalities of all tokens in the sequence. Compared to the previous state-of-the-art generative pre-training method, DPA is more sample efficient, leading to fast convergence to lower academic performance prediction error. We conduct extensive experimental studies on a real-world dataset obtained from a multi-platform ITS application and show that DPA outperforms the previous state-of-the-art generative pre-training method with a reduction of 4.05% in mean absolute error and more robust to increased label-scarcity. ","[{'version': 'v1', 'created': 'Mon, 28 Jun 2021 13:02:23 GMT'}, {'version': 'v2', 'created': 'Fri, 9 Jul 2021 03:42:14 GMT'}, {'version': 'v3', 'created': 'Mon, 12 Jul 2021 05:36:22 GMT'}]",2021-07-13,"[['Kim', 'Byungsoo', ''], ['Yu', 'Hangyeol', ''], ['Shin', 'Dongmin', ''], ['Choi', 'Youngduck', '']]",0,1,2021-06-28,3,4,3,0,0,0,68ba1c084972c4446cab907de8ad943e33dabd07,235765858.0,https://www.semanticscholar.org/paper/68ba1c084972c4446cab907de8ad943e33dabd07,Educational Data Mining,2021.0,35.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152063296', 'name': 'Byungsoo Kim'}, {'authorId': '50984319', 'name': 'Hangyeol Yu'}, {'authorId': '46714224', 'name': 'Dongmin Shin'}, {'authorId': '3461360', 'name': 'Youngduck Choi'}]",['Riiid! AI Research'],,2021-06,['industrial']
2107.06925,Shigang Li,"Shigang Li, Torsten Hoefler",Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines,"Published in Proceedings of the 2021 International Conference for
  High Performance Computing, Networking, Storage and Analysis (SC'21),
  November 2021, Article No.: 27, Pages 1-14. Best Paper Finalist",,10.1145/3458817.3476145,,cs.DC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Training large deep learning models at scale is very challenging. This paper proposes Chimera, a novel pipeline parallelism scheme which combines bidirectional pipelines for efficiently training large-scale models. Chimera is a synchronous approach and therefore no loss of accuracy, which is more convergence-friendly than asynchronous approaches. Compared with the latest synchronous pipeline approach, Chimera reduces the number of bubbles by up to 50%; benefiting from the sophisticated scheduling of bidirectional pipelines, Chimera has a more balanced activation memory consumption. Evaluations are conducted on Transformer based language models. For a GPT-2 model with 1.3 billion parameters running on 2,048 GPU nodes of the Piz Daint supercomputer, Chimera improves the training throughput by 1.16x-2.34x over the state-of-the-art synchronous and asynchronous pipeline approaches. ","[{'version': 'v1', 'created': 'Wed, 14 Jul 2021 18:16:20 GMT'}, {'version': 'v2', 'created': 'Mon, 15 Nov 2021 14:32:19 GMT'}, {'version': 'v3', 'created': 'Fri, 25 Feb 2022 10:49:12 GMT'}]",2022-02-28,"[['Li', 'Shigang', ''], ['Hoefler', 'Torsten', '']]",0,1,2021-07-14,3,2,2,1,1,0,10f3ca78e194552427ebe9173b19d1b910469e27,235898937.0,https://www.semanticscholar.org/paper/10f3ca78e194552427ebe9173b19d1b910469e27,"International Conference for High Performance Computing, Networking, Storage and Analysis",2021.0,58.0,51.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1738041', 'name': 'Shigang Li'}, {'authorId': '1713648', 'name': 'T. Hoefler'}]",['ETH Zurich'],['Switzerland'],2021-07,['industrial']
2107.07253,Asier Guti\'errez-Fandi\~no,"Asier Guti\'errez-Fandi\~no, Jordi Armengol-Estap\'e, Marc P\`amies,
  Joan Llop-Palao, Joaqu\'in Silveira-Ocampo, Casimiro Pio Carrino, Aitor
  Gonzalez-Agirre, Carme Armentano-Oller, Carlos Rodriguez-Penagos, Marta
  Villegas",MarIA: Spanish Language Models,,"Procesamiento del Lenguaje Natural, v. 68, p. 39-60, mar. 2022.
  ISSN 1989-7553",10.26342/2022-68-3,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This work presents MarIA, a family of Spanish language models and associated resources made available to the industry and the research community. Currently, MarIA includes RoBERTa-base, RoBERTa-large, GPT2 and GPT2-large Spanish language models, which can arguably be presented as the largest and most proficient language models in Spanish. The models were pretrained using a massive corpus of 570GB of clean and deduplicated texts with 135 billion words extracted from the Spanish Web Archive crawled by the National Library of Spain between 2009 and 2019. We assessed the performance of the models with nine existing evaluation datasets and with a novel extractive Question Answering dataset created ex novo. Overall, MarIA models outperform the existing Spanish models across a variety of NLU tasks and training settings. ","[{'version': 'v1', 'created': 'Thu, 15 Jul 2021 11:23:05 GMT'}, {'version': 'v2', 'created': 'Fri, 13 Aug 2021 13:47:44 GMT'}, {'version': 'v3', 'created': 'Fri, 1 Apr 2022 13:03:32 GMT'}, {'version': 'v4', 'created': 'Mon, 4 Apr 2022 16:25:12 GMT'}, {'version': 'v5', 'created': 'Tue, 5 Apr 2022 11:13:46 GMT'}]",2022-04-06,"[['Gutiérrez-Fandiño', 'Asier', ''], ['Armengol-Estapé', 'Jordi', ''], ['Pàmies', 'Marc', ''], ['Llop-Palao', 'Joan', ''], ['Silveira-Ocampo', 'Joaquín', ''], ['Carrino', 'Casimiro Pio', ''], ['Gonzalez-Agirre', 'Aitor', ''], ['Armentano-Oller', 'Carme', ''], ['Rodriguez-Penagos', 'Carlos', ''], ['Villegas', 'Marta', '']]",0,1,2021-07-15,5,10,2,1,1,0,2132eac5628bc200de226b51f1dfb82423ff1d24,252847802.0,https://www.semanticscholar.org/paper/2132eac5628bc200de226b51f1dfb82423ff1d24,Proces. del Leng. Natural,2021.0,55.0,58.0,10.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2078772072', 'name': 'Asier Gutiérrez-Fandiño'}, {'authorId': '1405319696', 'name': ""Jordi Armengol-Estap'e""}, {'authorId': '1850527789', 'name': 'Marc Pàmies'}, {'authorId': '2119550454', 'name': 'Joan Llop-Palao'}, {'authorId': '2119543279', 'name': 'Joaquín Silveira-Ocampo'}, {'authorId': '1416319999', 'name': 'C. Carrino'}, {'authorId': '1405518065', 'name': 'Carme Armentano-Oller'}, {'authorId': '2687070', 'name': 'C. R. Penagos'}, {'authorId': '1403836100', 'name': 'Aitor Gonzalez-Agirre'}, {'authorId': '2066499928', 'name': 'Marta Villegas'}]",['Barcelona Supercomputing Center'],['Spain'],2021-07,['industrial']
2107.07566,Jason  Weston,"Mojtaba Komeili, Kurt Shuster, Jason Weston",Internet-Augmented Dialogue Generation,,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The largest store of continually updating knowledge on our planet can be accessed via internet search. In this work we study giving access to this information to conversational agents. Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue (Shuster et al., 2021); moreover, those facts are frozen in time at the point of model training. In contrast, we propose an approach that learns to generate an internet search query based on the context, and then conditions on the search results to finally generate a response, a method that can employ up-to-the-minute relevant information. We train and evaluate such models on a newly collected dataset of human-human conversations whereby one of the speakers is given access to internet search during knowledgedriven discussions in order to ground their responses. We find that search-query based access of the internet in conversation provides superior performance compared to existing approaches that either use no augmentation or FAISS-based retrieval (Lewis et al., 2020). ","[{'version': 'v1', 'created': 'Thu, 15 Jul 2021 19:00:35 GMT'}]",2021-07-19,"[['Komeili', 'Mojtaba', ''], ['Shuster', 'Kurt', ''], ['Weston', 'Jason', '']]",0,0,2021-07-15,1,3,2,0,0,0,de549c1592a62c129b8d49c8c0137aa6859b103f,236034557.0,https://www.semanticscholar.org/paper/de549c1592a62c129b8d49c8c0137aa6859b103f,Annual Meeting of the Association for Computational Linguistics,2021.0,45.0,187.0,36.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '100653935', 'name': 'M. Komeili'}, {'authorId': '35752280', 'name': 'Kurt Shuster'}, {'authorId': '145183709', 'name': 'J. Weston'}]",['Meta'],['United States'],2021-07,['industrial']
2108.11696,Ting-Yun Chang,Ting-Yun Chang and Chi-Jen Lu,Rethinking Why Intermediate-Task Fine-Tuning Works,Findings of EMNLP 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a widely applied technique, which first fine-tunes the pretrained language models on an intermediate task before on the target task of interest. While STILTs is able to further improve the performance of pretrained language models, it is still unclear why and when it works. Previous research shows that those intermediate tasks involving complex inference, such as commonsense reasoning, work especially well for RoBERTa. In this paper, we discover that the improvement from an intermediate task could be orthogonal to it containing reasoning or other complex skills -- a simple real-fake discrimination task synthesized by GPT2 can benefit diverse target tasks. We conduct extensive experiments to study the impact of different factors on STILTs. These findings suggest rethinking the role of intermediate fine-tuning in the STILTs pipeline. ","[{'version': 'v1', 'created': 'Thu, 26 Aug 2021 10:34:37 GMT'}, {'version': 'v2', 'created': 'Wed, 1 Sep 2021 12:07:55 GMT'}]",2021-09-02,"[['Chang', 'Ting-Yun', ''], ['Lu', 'Chi-Jen', '']]",0,1,2021-08-26,2,2,1,1,1,0,e6f94081276a7a5e6aef34a080cb3d3a4b1b9c20,237303924.0,https://www.semanticscholar.org/paper/e6f94081276a7a5e6aef34a080cb3d3a4b1b9c20,Conference on Empirical Methods in Natural Language Processing,2021.0,38.0,20.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3386996', 'name': 'Ting-Yun Chang'}, {'authorId': '1390518825', 'name': 'Chi-Jen Lu'}]","['Institute of Information Science, Academia Sinica']",['Taiwan'],2021-08,['industrial']
2108.13349,Jordi Armengol-Estap\'e,"Jordi Armengol-Estap\'e, Ona de Gibert Bonet and Maite Melero",On the Multilingual Capabilities of Very Large-Scale English Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative Pre-trained Transformers (GPTs) have recently been scaled to unprecedented sizes in the history of machine learning. These models, solely trained on the language modeling objective, have been shown to exhibit outstanding few-shot learning capabilities in a number of different tasks. Nevertheless, aside from anecdotal experiences, little is known regarding their multilingual capabilities, given the fact that the pre-training corpus is almost entirely composed of English text. In this work, we investigate the multilingual skills of GPT-3, focusing on one language that barely appears in the pre-training corpus, Catalan, which makes the results especially meaningful; we assume that our results may be relevant for other languages as well. We find that the model shows an outstanding performance, particularly in generative tasks, with predictable limitations mostly in language understanding tasks but still with remarkable results given the zero-shot scenario. We investigate its potential and limits in extractive question-answering and natural language generation, as well as the effect of scale in terms of model size. ","[{'version': 'v1', 'created': 'Mon, 30 Aug 2021 16:18:50 GMT'}]",2021-08-31,"[['Armengol-Estapé', 'Jordi', ''], ['Bonet', 'Ona de Gibert', ''], ['Melero', 'Maite', '']]",0,1,2021-08-30,1,3,2,1,0,1,88afeaf0a4208477e845170daa8a189cc0a13a73,237352964.0,https://www.semanticscholar.org/paper/88afeaf0a4208477e845170daa8a189cc0a13a73,International Conference on Language Resources and Evaluation,2021.0,32.0,9.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2123452669', 'name': ""Jordi Armengol-Estap'e""}, {'authorId': '73879139', 'name': 'Ona de Gibert Bonet'}, {'authorId': '144431961', 'name': 'Maite Melero'}]",['Barcelona Supercomputing Center'],['Spain'],2021-08,['industrial']
2108.13487,Shuohang Wang,"Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu, Michael Zeng",Want To Reduce Labeling Cost? GPT-3 Can Help,"Findings of EMNLP 2021, 11 pages",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Data annotation is a time-consuming and labor-intensive process for many NLP tasks. Although there exist various methods to produce pseudo data labels, they are often task-specific and require a decent amount of labeled data to start with. Recently, the immense language model GPT-3 with 175 billion parameters has achieved tremendous improvement across many few-shot learning tasks. In this paper, we explore ways to leverage GPT-3 as a low-cost data labeler to train other models. We find that, to make the downstream model achieve the same performance on a variety of NLU and NLG tasks, it costs 50% to 96% less to use labels from GPT-3 than using labels from humans. Furthermore, we propose a novel framework of combining pseudo labels from GPT-3 with human labels, which leads to even better performance with limited labeling budget. These results present a cost-effective data labeling methodology that is generalizable to many practical applications. ","[{'version': 'v1', 'created': 'Mon, 30 Aug 2021 19:18:24 GMT'}]",2021-09-01,"[['Wang', 'Shuohang', ''], ['Liu', 'Yang', ''], ['Xu', 'Yichong', ''], ['Zhu', 'Chenguang', ''], ['Zeng', 'Michael', '']]",0,1,2021-08-30,1,5,2,1,0,1,4e263b4cd6998bff2501dd143e685f413179b12d,237363383.0,https://www.semanticscholar.org/paper/4e263b4cd6998bff2501dd143e685f413179b12d,Conference on Empirical Methods in Natural Language Processing,2021.0,40.0,89.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2992833', 'name': 'Shuohang Wang'}, {'authorId': '39798499', 'name': 'Yang Liu'}, {'authorId': '2110197273', 'name': 'Yichong Xu'}, {'authorId': '1456009348', 'name': 'Chenguang Zhu'}, {'authorId': '48262024', 'name': 'Michael Zeng'}]",['Microsoft'],['United States'],2021-08,['industrial']
2109.00729,Cagri Toraman,Eyup Halit Yilmaz and Cagri Toraman,ConQX: Semantic Expansion of Spoken Queries for Intent Detection based on Conditioned Text Generation,"5 pages, 1 figure, conference",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Intent detection of spoken queries is a challenging task due to their noisy structure and short length. To provide additional information regarding the query and enhance the performance of intent detection, we propose a method for semantic expansion of spoken queries, called ConQX, which utilizes the text generation ability of an auto-regressive language model, GPT-2. To avoid off-topic text generation, we condition the input query to a structured context with prompt mining. We then apply zero-shot, one-shot, and few-shot learning. We lastly use the expanded queries to fine-tune BERT and RoBERTa for intent detection. The experimental results show that the performance of intent detection can be improved by our semantic expansion method. ","[{'version': 'v1', 'created': 'Thu, 2 Sep 2021 05:57:07 GMT'}]",2021-09-03,"[['Yilmaz', 'Eyup Halit', ''], ['Toraman', 'Cagri', '']]",0,1,2021-09-02,1,2,2,1,1,0,2afde58474acb35f1091614f189d731e4d47861f,237385837.0,https://www.semanticscholar.org/paper/2afde58474acb35f1091614f189d731e4d47861f,arXiv.org,2021.0,22.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1830448719', 'name': 'E. Yilmaz'}, {'authorId': '2648640', 'name': 'Cagri Toraman'}]","['Aselsan Research Center Ankara, Turkey']",['Turkey'],2021-09,['industrial']
2109.02593,Peter Clark,Oyvind Tafjord and Peter Clark,General-Purpose Question-Answering with Macaw,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Despite the successes of pretrained language models, there are still few high-quality, general-purpose QA systems that are freely available. In response, we present Macaw, a versatile, generative question-answering (QA) system that we are making available to the community. Macaw is built on UnifiedQA, itself built on T5, and exhibits strong performance, zero-shot, on a wide variety of topics, including outperforming GPT-3 by over 10% (absolute) on Challenge300, a suite of 300 challenge questions, despite being an order of magnitude smaller (11 billion vs. 175 billion parameters). In addition, Macaw allows different permutations (""angles"") of its inputs and outputs to be used, for example Macaw can take a question and produce an answer; or take an answer and produce a question; or take an answer and question, and produce multiple-choice options. We describe the system, and illustrate a variety of question types where it produces surprisingly good answers, well outside the training setup. We also identify question classes where it still appears to struggle, offering insights into the limitations of pretrained language models. Macaw is freely available, and we hope that it proves useful to the community. Macaw is available at https://github.com/allenai/macaw ","[{'version': 'v1', 'created': 'Mon, 6 Sep 2021 16:37:46 GMT'}]",2021-09-07,"[['Tafjord', 'Oyvind', ''], ['Clark', 'Peter', '']]",0,1,2021-09-06,1,2,2,2,1,1,e3480d9395e692833b722b2e957d51139985f310,237420665.0,https://www.semanticscholar.org/paper/e3480d9395e692833b722b2e957d51139985f310,arXiv.org,2021.0,26.0,48.0,13.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3385516', 'name': 'Oyvind Tafjord'}, {'authorId': '2069640813', 'name': 'Peter Clark'}]",['Allen Institute for Artificial Intelligence'],['United States'],2021-09,['industrial']
2109.03264,Wei-Ning Hsu,"Eugene Kharitonov, Ann Lee, Adam Polyak, Yossi Adi, Jade Copet, Kushal
  Lakhotia, Tu-Anh Nguyen, Morgane Rivi\`ere, Abdelrahman Mohamed, Emmanuel
  Dupoux, Wei-Ning Hsu",Text-Free Prosody-Aware Generative Spoken Language Modeling,ACL 2022,,,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech pre-training has primarily demonstrated efficacy on classification tasks, while its capability of generating novel speech, similar to how GPT-2 can generate coherent paragraphs, has barely been explored. Generative Spoken Language Modeling (GSLM) \cite{Lakhotia2021} is the only prior work addressing the generative aspects of speech pre-training, which replaces text with discovered phone-like units for language modeling and shows the ability to generate meaningful novel sentences. Unfortunately, despite eliminating the need of text, the units used in GSLM discard most of the prosodic information. Hence, GSLM fails to leverage prosody for better comprehension, and does not generate expressive speech. In this work, we present a prosody-aware generative spoken language model (pGSLM). It is composed of a multi-stream transformer language model (MS-TLM) of speech, represented as discovered unit and prosodic feature streams, and an adapted HiFi-GAN model converting MS-TLM outputs to waveforms. We devise a series of metrics for prosody modeling and generation, and re-use metrics from GSLM for content modeling. Experimental results show that the pGSLM can utilize prosody to improve both prosody and content modeling, and also generate natural, meaningful, and coherent speech given a spoken prompt. Audio samples can be found at https://speechbot.github.io/pgslm. Codes and models are available at https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm. ","[{'version': 'v1', 'created': 'Tue, 7 Sep 2021 18:03:21 GMT'}, {'version': 'v2', 'created': 'Tue, 10 May 2022 16:41:20 GMT'}]",2022-05-11,"[['Kharitonov', 'Eugene', ''], ['Lee', 'Ann', ''], ['Polyak', 'Adam', ''], ['Adi', 'Yossi', ''], ['Copet', 'Jade', ''], ['Lakhotia', 'Kushal', ''], ['Nguyen', 'Tu-Anh', ''], ['Rivière', 'Morgane', ''], ['Mohamed', 'Abdelrahman', ''], ['Dupoux', 'Emmanuel', ''], ['Hsu', 'Wei-Ning', '']]",0,1,2021-09-07,2,11,4,1,1,0,65b20b3e6f81f6567e41e353a47a2380c6cc4b77,237439400.0,https://www.semanticscholar.org/paper/65b20b3e6f81f6567e41e353a47a2380c6cc4b77,Annual Meeting of the Association for Computational Linguistics,2021.0,48.0,62.0,2.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144875326', 'name': 'E. Kharitonov'}, {'authorId': '145732777', 'name': 'Ann Lee'}, {'authorId': '33964593', 'name': 'A. Polyak'}, {'authorId': '2727584', 'name': 'Yossi Adi'}, {'authorId': '1805998294', 'name': 'Jade Copet'}, {'authorId': '1410624139', 'name': 'Kushal Lakhotia'}, {'authorId': '2116225477', 'name': 'Tu Nguyen'}, {'authorId': '46928736', 'name': 'M. Rivière'}, {'authorId': '40360972', 'name': 'Abdel-rahman Mohamed'}, {'authorId': '90049550', 'name': 'E. Dupoux'}, {'authorId': '2957796', 'name': 'Wei-Ning Hsu'}]",['Meta'],['United States'],2021-09,['industrial']
2109.04645,Fei Mi,"Fei Mi, Yitong Li, Yasheng Wang, Xin Jiang and Qun Liu",CINS: Comprehensive Instruction for Few-shot Learning in Task-oriented Dialog Systems,Accepted at AAAI2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As labeling cost for different modules in task-oriented dialog (ToD) systems is high, a major challenge in practice is to learn different tasks with the least amount of labeled data. Recently, prompting methods over pre-trained language models (PLMs) have shown promising results for few-shot learning in ToD. To better utilize the power of PLMs, this paper proposes Comprehensive Instruction (CINS) that exploits PLMs with extra task-specific instructions. We design a schema (definition, constraint, prompt) of instructions and their customized realizations for three important downstream tasks in ToD, i.e. intent classification, dialog state tracking, and natural language generation. A sequence-to-sequence model (T5) is adopted to solve these three tasks in a unified framework. Extensive experiments are conducted on these ToD tasks in realistic few-shot learning scenarios with small validation data. Empirical results demonstrate that the proposed CINS approach consistently improves techniques that finetune PLMs with raw input or short prompts. ","[{'version': 'v1', 'created': 'Fri, 10 Sep 2021 03:23:06 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Sep 2021 09:35:51 GMT'}, {'version': 'v3', 'created': 'Mon, 13 Dec 2021 11:46:18 GMT'}, {'version': 'v4', 'created': 'Mon, 21 Mar 2022 14:24:12 GMT'}]",2022-03-22,"[['Mi', 'Fei', ''], ['Li', 'Yitong', ''], ['Wang', 'Yasheng', ''], ['Jiang', 'Xin', ''], ['Liu', 'Qun', '']]",0,0,2021-09-10,4,5,2,1,1,0,20da8033ed8b696e2e27ec40b1aa8a0ab82b964c,237485305.0,https://www.semanticscholar.org/paper/20da8033ed8b696e2e27ec40b1aa8a0ab82b964c,AAAI Conference on Artificial Intelligence,2021.0,46.0,30.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '33727421', 'name': 'Fei Mi'}, {'authorId': '50024168', 'name': 'Yitong Li'}, {'authorId': '2136912252', 'name': 'Yasheng Wang'}, {'authorId': '2110310493', 'name': 'Xin Jiang'}, {'authorId': '30738758', 'name': 'Qun Liu'}]",['Huawei Technologies (China)'],['China'],2021-09,['industrial']
2109.05014,Zhengyuan Yang,"Zhengyuan Yang, Zhe Gan, Jianfeng Wang, Xiaowei Hu, Yumao Lu, Zicheng
  Liu, Lijuan Wang",An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA,AAAI 2022 (Oral Presentation),,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge-based visual question answering (VQA) involves answering questions that require external knowledge not present in the image. Existing methods first retrieve knowledge from external resources, then reason over the selected knowledge, the input image, and question for answer prediction. However, this two-step approach could lead to mismatches that potentially limit the VQA performance. For example, the retrieved knowledge might be noisy and irrelevant to the question, and the re-embedded knowledge features during reasoning might deviate from their original meanings in the knowledge base (KB). To address this challenge, we propose PICa, a simple yet effective method that Prompts GPT3 via the use of Image Captions, for knowledge-based VQA. Inspired by GPT-3's power in knowledge retrieval and question answering, instead of using structured KBs as in previous work, we treat GPT-3 as an implicit and unstructured KB that can jointly acquire and process relevant knowledge. Specifically, we first convert the image into captions (or tags) that GPT-3 can understand, then adapt GPT-3 to solve the VQA task in a few-shot manner by just providing a few in-context VQA examples. We further boost performance by carefully investigating: (i) what text formats best describe the image content, and (ii) how in-context examples can be better selected and used. PICa unlocks the first use of GPT-3 for multimodal tasks. By using only 16 examples, PICa surpasses the supervised state of the art by an absolute +8.6 points on the OK-VQA dataset. We also benchmark PICa on VQAv2, where PICa also shows a decent few-shot performance. ","[{'version': 'v1', 'created': 'Fri, 10 Sep 2021 17:51:06 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Sep 2022 04:01:50 GMT'}]",2022-09-15,"[['Yang', 'Zhengyuan', ''], ['Gan', 'Zhe', ''], ['Wang', 'Jianfeng', ''], ['Hu', 'Xiaowei', ''], ['Lu', 'Yumao', ''], ['Liu', 'Zicheng', ''], ['Wang', 'Lijuan', '']]",0,1,2021-09-10,2,7,1,1,0,1,2672777d25562c9df6fc13b653181db62d39bece,237485500.0,https://www.semanticscholar.org/paper/2672777d25562c9df6fc13b653181db62d39bece,AAAI Conference on Artificial Intelligence,2021.0,44.0,183.0,41.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2149231840', 'name': 'Zhengyuan Yang'}, {'authorId': '144702900', 'name': 'Zhe Gan'}, {'authorId': '2124948371', 'name': 'Jianfeng Wang'}, {'authorId': '2148941781', 'name': 'Xiaowei Hu'}, {'authorId': '2143520239', 'name': 'Yumao Lu'}, {'authorId': '2145253136', 'name': 'Zicheng Liu'}, {'authorId': '29957038', 'name': 'Lijuan Wang'}]",['Microsoft'],['United States'],2021-09,['industrial']
2109.06538,Yao Qiu,"Yao Qiu, Jinchao Zhang, Huiying Ren, Jie Zhou",Challenging Instances are Worth Learning: Generating Valuable Negative Samples for Response Selection Training,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Retrieval-based chatbot selects the appropriate response from candidates according to the context, which heavily depends on a response selection module. A response selection module is generally a scoring model to evaluate candidates and is usually trained on the annotated positive response and sampled negative responses. Sampling negative responses lead to two risks: a). The sampled negative instances, especially that from random sampling methods, are mostly irrelevant to the dialogue context and too easy to be fitted at the training stage while causing a weak model in the real scenario. b). The so-called negative instances may be positive, which is known as the fake negative problem. To address the above issue, we employ pre-trained language models, such as the DialoGPT to construct more challenging negative instances to enhance the model robustness. Specifically, we provide garbled context to the pre-trained model to generate responses and filter the fake negative ones. In this way, our negative instances are fluent, context-related, and more challenging for the model to learn, while can not be positive. Extensive experiments show that our method brings significant and stable improvements on the dialogue response selection capacity. ","[{'version': 'v1', 'created': 'Tue, 14 Sep 2021 09:16:24 GMT'}]",2021-09-15,"[['Qiu', 'Yao', ''], ['Zhang', 'Jinchao', ''], ['Ren', 'Huiying', ''], ['Zhou', 'Jie', '']]",0,1,2021-09-14,1,4,1,0,0,0,13c7580b0846416e9c024c027eaf33ed82a940bb,237503082.0,https://www.semanticscholar.org/paper/13c7580b0846416e9c024c027eaf33ed82a940bb,arXiv.org,2021.0,27.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153278060', 'name': 'Yao Qiu'}, {'authorId': '2108970018', 'name': 'Jinchao Zhang'}, {'authorId': '2114293494', 'name': 'Huiying Ren'}, {'authorId': '2108485135', 'name': 'Jie Zhou'}]",['Tencent'],['China'],2021-09,['industrial']
2109.10638,Alexis-Michel Mugabushaka,"Alexis-Michel Mugabushaka, Miriam Baglioni, Alessia Bardi and Paolo
  Manghi",Scholarly outputs of EU Research Funding Programs: Understanding differences between datasets of publications reported by grant holders and OpenAIRE Research Graph in H2020,,,,,cs.DL,http://creativecommons.org/licenses/by/4.0/,"  Linking research results to grants is an essential prerequisite for an effective monitoring and evaluation of funding programs. For the EU research funding programs, there are multiple datasets linking scholarly publications to the individual grants, including both open data and those from commercial bibliometric databases. In this paper, we systematically compare openly available data from two data sources: on one hand those reported by the Grant holders (and subsequently published by the European Commission on open data portal) and those from the OpenAIRE Research Graph which collect data from multiple sources. We describe the dataflow leading to their creation and assess the quality of data by validating, on sample basis, the link <project, publications>. We report that, by and large, OpenAIRE Research Graph offers a more complete dataset of scholarly outputs of from EU Research funding programs. We identify also possible improvements and make recommendations on how they can be addressed. ","[{'version': 'v1', 'created': 'Wed, 22 Sep 2021 10:31:21 GMT'}]",2021-09-23,"[['Mugabushaka', 'Alexis-Michel', ''], ['Baglioni', 'Miriam', ''], ['Bardi', 'Alessia', ''], ['Manghi', 'Paolo', '']]",0,0,2021-09-22,1,4,1,0,0,0,fcb6a14ff8ef2195ab57e01531193818202605fc,237592577.0,https://www.semanticscholar.org/paper/fcb6a14ff8ef2195ab57e01531193818202605fc,arXiv.org,2021.0,14.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2234648', 'name': 'Alexis-Michel Mugabushaka'}, {'authorId': '1824207', 'name': 'Miriam Baglioni'}, {'authorId': '39565794', 'name': 'A. Bardi'}, {'authorId': '1799502', 'name': 'P. Manghi'}]","['Institute of Information Science and Technologies', 'European Commission']","['Belgium', 'Italy']",2021-09,"['industrial', 'industrial']"
2109.13582,Antoine Chaffin,"Antoine Chaffin, Vincent Claveau, Ewa Kijak",PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided MCTS Decoding,"15 pages, 5 tables, 7 figures, accepted to NAACL 2022",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large language models (LM) based on Transformers allow to generate plausible long texts. In this paper, we explore how this generation can be further controlled at decoding time to satisfy certain constraints (e.g. being non-toxic, conveying certain emotions, using a specific writing style, etc.) without fine-tuning the LM. Precisely, we formalize constrained generation as a tree exploration process guided by a discriminator that indicates how well the associated sequence respects the constraint. This approach, in addition to being easier and cheaper to train than fine-tuning the LM, allows to apply the constraint more finely and dynamically. We propose several original methods to search this generation tree, notably the Monte Carlo Tree Search (MCTS) which provides theoretical guarantees on the search efficiency, but also simpler methods based on re-ranking a pool of diverse sequences using the discriminator scores. These methods are evaluated, with automatic and human-based metrics, on two types of constraints and languages: review polarity and emotion control in French and English. We show that discriminator-guided MCTS decoding achieves state-of-the-art results without having to tune the language model, in both tasks and languages. We also demonstrate that other proposed decoding methods based on re-ranking can be really effective when diversity among the generated propositions is encouraged. ","[{'version': 'v1', 'created': 'Tue, 28 Sep 2021 09:29:15 GMT'}, {'version': 'v2', 'created': 'Wed, 4 May 2022 08:55:21 GMT'}]",2022-05-05,"[['Chaffin', 'Antoine', ''], ['Claveau', 'Vincent', ''], ['Kijak', 'Ewa', '']]",0,0,2021-09-28,2,3,1,0,0,0,6dc1db69749fcb6484a11cd9465e9945068027bf,248512793.0,https://www.semanticscholar.org/paper/6dc1db69749fcb6484a11cd9465e9945068027bf,North American Chapter of the Association for Computational Linguistics,2021.0,39.0,15.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2129106958', 'name': 'Antoine Chaffin'}, {'authorId': '1735666', 'name': 'V. Claveau'}, {'authorId': '1801242', 'name': 'Ewa Kijak'}]","['IMATAG, 13 Rue Dupont-des-Loges, 35000 Rennes, France', 'CNRS, IRISA, Univ. Rennes 1, Campus de Beaulieu, 35000 Rennes, France']",['France'],2021-09,"['industrial', 'industrial']"
2110.03888,An Yang,"Junyang Lin, An Yang, Jinze Bai, Chang Zhou, Le Jiang, Xianyan Jia,
  Ang Wang, Jie Zhang, Yong Li, Wei Lin, Jingren Zhou, Hongxia Yang",M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining,"14 pages, 4 figures",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Recent expeditious developments in deep learning algorithms, distributed training, and even hardware design for large models have enabled training extreme-scale models, say GPT-3 and Switch Transformer possessing hundreds of billions or even trillions of parameters. However, under limited resources, extreme-scale model training that requires enormous amounts of computes and memory footprint suffers from frustratingly low efficiency in model convergence. In this paper, we propose a simple training strategy called ""Pseudo-to-Real"" for high-memory-footprint-required large models. Pseudo-to-Real is compatible with large models with architecture of sequential layers. We demonstrate a practice of pretraining unprecedented 10-trillion-parameter model, an order of magnitude larger than the state-of-the-art, on solely 512 GPUs within 10 days. Besides demonstrating the application of Pseudo-to-Real, we also provide a technique, Granular CPU offloading, to manage CPU memory for training large model and maintain high GPU utilities. Fast training of extreme-scale models on a decent amount of resources can bring much smaller carbon footprint and contribute to greener AI. ","[{'version': 'v1', 'created': 'Fri, 8 Oct 2021 04:24:51 GMT'}, {'version': 'v2', 'created': 'Wed, 13 Oct 2021 08:52:00 GMT'}, {'version': 'v3', 'created': 'Mon, 25 Oct 2021 06:24:41 GMT'}]",2021-10-26,"[['Lin', 'Junyang', ''], ['Yang', 'An', ''], ['Bai', 'Jinze', ''], ['Zhou', 'Chang', ''], ['Jiang', 'Le', ''], ['Jia', 'Xianyan', ''], ['Wang', 'Ang', ''], ['Zhang', 'Jie', ''], ['Li', 'Yong', ''], ['Lin', 'Wei', ''], ['Zhou', 'Jingren', ''], ['Yang', 'Hongxia', '']]",0,1,2021-10-08,3,12,2,1,0,1,24e775b20adf21e9b5b95c6a9b7a5c164d055849,238531482.0,https://www.semanticscholar.org/paper/24e775b20adf21e9b5b95c6a9b7a5c164d055849,arXiv.org,2021.0,52.0,27.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35996608', 'name': 'Junyang Lin'}, {'authorId': '143936592', 'name': 'An Yang'}, {'authorId': '41211611', 'name': 'Jinze Bai'}, {'authorId': '144161025', 'name': 'Chang Zhou'}, {'authorId': '1485086888', 'name': 'Le Jiang'}, {'authorId': '3440541', 'name': 'Xianyan Jia'}, {'authorId': '153294981', 'name': 'Ang Wang'}, {'authorId': '40539618', 'name': 'J. Zhang'}, {'authorId': '1962987077', 'name': 'Yong Li'}, {'authorId': '71666838', 'name': 'Wei Lin'}, {'authorId': '1709595', 'name': 'Jingren Zhou'}, {'authorId': '38385080', 'name': 'Hongxia Yang'}]",['Alibaba'],['China'],2021-10,['industrial']
2110.04071,Ricard Delgado-Gonzalo,"Pierre Louis Gaudilliere, Halla Sigurthorsdottir, Cl\'ementine Aguet,
  J\'er\^ome Van Zaen, Mathieu Lemay, Ricard Delgado-Gonzalo",Generative Pre-Trained Transformer for Cardiac Abnormality Detection,"4 pages, 2 figures, accepted for publication in CinC 2021",,,,eess.SP cs.LG,http://creativecommons.org/licenses/by/4.0/,"  ECG heartbeat classification plays a vital role in diagnosis of cardiac arrhythmia. The goal of the Physionet/CinC 2021 challenge was to accurately classify clinical diagnosis based on 12, 6, 4, 3 or 2-lead ECG recordings in order to aid doctors in the diagnoses of different heart conditions. Transformers have had great success in the field of natural language processing in the past years. Our team, CinCSEM, proposes to draw the parallel between text and periodic time series signals by viewing the repeated period as words and the whole signal as a sequence of such words. In this way, the attention mechanisms of the transformers can be applied to periodic time series signals. In our implementation, we follow the Transformer Encoder architecture, which combines several encoder layers followed by a dense layer with linear or sigmoid activation for generative pre-training or classification, respectively. The use case presented here is multi-label classification of heartbeat abnormalities of ECG recordings shared by the challenge. Our best entry, not exceeding the challenge's hardware limitations, achieved a score of 0.12, 0.07, 0.10, 0.10 and 0.07 on 12-lead, 6-lead, 4-lead, 3-lead and 2-lead test set respectively. Unfortunately, our team was unable to be ranked because of a missing pre-print. ","[{'version': 'v1', 'created': 'Thu, 7 Oct 2021 12:01:12 GMT'}]",2021-10-11,"[['Gaudilliere', 'Pierre Louis', ''], ['Sigurthorsdottir', 'Halla', ''], ['Aguet', 'Clémentine', ''], ['Van Zaen', 'Jérôme', ''], ['Lemay', 'Mathieu', ''], ['Delgado-Gonzalo', 'Ricard', '']]",0,1,2021-10-07,1,6,2,0,0,0,3b6230d62c1ceaef53089e825c3c41d5c37cf8d1,237589655.0,https://www.semanticscholar.org/paper/3b6230d62c1ceaef53089e825c3c41d5c37cf8d1,2021 Computing in Cardiology (CinC),2021.0,10.0,2.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '121957434', 'name': 'P. Gaudilliere'}, {'authorId': '1972387119', 'name': 'Halla Sigurthorsdottir'}, {'authorId': '1505816242', 'name': 'Clémentine Aguet'}, {'authorId': '9092152', 'name': 'J. V. Zaen'}, {'authorId': '12693205', 'name': 'M. Lemay'}, {'authorId': '1397904342', 'name': 'R. Delgado-Gonzalo'}]",['Swiss Center for Electronics and Microtechnology (Switzerland)'],['Switzerland'],2021-10,['industrial']
2110.06905,Moya Chen,"Moya Chen, Paul A. Crook, Stephen Roller",Teaching Models new APIs: Domain-Agnostic Simulators for Task Oriented Dialogue,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We demonstrate that large language models are able to simulate Task Oriented Dialogues in novel domains, provided only with an API implementation and a list of goals. We show these simulations can formulate online, automatic metrics that correlate well with human evaluations. Furthermore, by checking for whether the User's goals are met, we can use simulation to repeatedly generate training data and improve the quality of simulations themselves. With no human intervention or domain-specific training data, our simulations bootstrap end-to-end models which achieve a 37\% error reduction in previously unseen domains. By including as few as 32 domain-specific conversations, bootstrapped models can match the performance of a fully-supervised model with $10\times$ more data. To our knowledge, this is the first time simulations have been shown to be effective at bootstrapping models without explicitly requiring any domain-specific training data, rule-engineering, or humans-in-the-loop. ","[{'version': 'v1', 'created': 'Wed, 13 Oct 2021 17:39:25 GMT'}]",2021-10-14,"[['Chen', 'Moya', ''], ['Crook', 'Paul A.', ''], ['Roller', 'Stephen', '']]",0,0,2021-10-13,1,3,1,0,0,0,5f811236ccca35eb43bca0dbfdbd81004e73eb60,238744355.0,https://www.semanticscholar.org/paper/5f811236ccca35eb43bca0dbfdbd81004e73eb60,arXiv.org,2021.0,54.0,5.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108267192', 'name': 'Moya Chen'}, {'authorId': '34963487', 'name': 'Paul A. Crook'}, {'authorId': '3849208', 'name': 'Stephen Roller'}]",['Meta'],['United States'],2021-10,['industrial']
2110.06961,Arvid Frydenlund,"Arvid Frydenlund, Gagandeep Singh, Frank Rudzicz",Language Modelling via Learning to Rank,Accepted to AAAI22. Minor writing fixes,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We consider language modelling (LM) as a multi-label structured prediction task by re-framing training from solely predicting a single ground-truth word to ranking a set of words which could continue a given context. To avoid annotating top-$k$ ranks, we generate them using pre-trained LMs: GPT-2, BERT, and Born-Again models. This leads to a rank-based form of knowledge distillation (KD). We also develop a method using $N$-grams to create a non-probabilistic teacher which generates the ranks without the need of a pre-trained LM.   We confirm the hypotheses that we can treat LMing as a ranking task and that we can do so without the use of a pre-trained LM. We show that rank-based KD generally improves perplexity (PPL), often with statistical significance, when compared to Kullback-Leibler-based KD. Surprisingly, given the simplicity of the method, $N$-grams act as competitive teachers and achieve similar performance as using either BERT or a Born-Again model teachers. GPT-2 always acts as the best teacher, though, and using it and a Transformer-XL student on Wiki-02, rank-based KD reduces a cross-entropy baseline from 65.27 to 55.94 and against a KL-based KD of 56.70. ","[{'version': 'v1', 'created': 'Wed, 13 Oct 2021 18:03:47 GMT'}, {'version': 'v2', 'created': 'Fri, 10 Dec 2021 19:49:23 GMT'}]",2021-12-14,"[['Frydenlund', 'Arvid', ''], ['Singh', 'Gagandeep', ''], ['Rudzicz', 'Frank', '']]",0,1,2021-10-13,2,3,2,1,1,0,f21be3f230cb2721904671c7747165edad8bd033,238856846.0,https://www.semanticscholar.org/paper/f21be3f230cb2721904671c7747165edad8bd033,AAAI Conference on Artificial Intelligence,2021.0,58.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '94728448', 'name': 'A. Frydenlund'}, {'authorId': '2117029335', 'name': 'Gagandeep Singh'}, {'authorId': '2479037', 'name': 'Frank Rudzicz'}]","['Nuance Communications (Canada)', 'Vector Institute']",['Canada'],2021-10,"['industrial', 'industrial']"
2110.07178,Peter West,"Peter West, Chandra Bhagavatula, Jack Hessel, Jena D. Hwang, Liwei
  Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, Yejin Choi",Symbolic Knowledge Distillation: from General Language Models to Commonsense Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The common practice for training commonsense models has gone from-human-to-corpus-to-machine: humans author commonsense knowledge graphs in order to train commonsense models. In this work, we investigate an alternative, from-machine-to-corpus-to-machine: general language models author these commonsense knowledge graphs to train commonsense models. Our study leads to a new framework, Symbolic Knowledge Distillation. As with prior art in Knowledge Distillation (Hinton et al., 2015), our approach uses larger models to teach smaller models. A key difference is that we distill knowledge symbolically-as text-in addition to the neural model. We also distill only one aspect-the commonsense of a general language model teacher, allowing the student to be a different type, a commonsense model. Altogether, we show that careful prompt engineering and a separately trained critic model allow us to selectively distill high-quality causal commonsense from GPT-3, a general language model. Empirical results demonstrate that, for the first time, a human-authored commonsense knowledge graph is surpassed by our automatically distilled variant in all three criteria: quantity, quality, and diversity. In addition, it results in a neural commonsense model that surpasses the teacher model's commonsense capabilities despite its 100x smaller size. We apply this to the ATOMIC resource, and share our new symbolic knowledge graph and commonsense models. ","[{'version': 'v1', 'created': 'Thu, 14 Oct 2021 06:50:19 GMT'}, {'version': 'v2', 'created': 'Mon, 28 Nov 2022 23:28:35 GMT'}]",2022-11-30,"[['West', 'Peter', ''], ['Bhagavatula', 'Chandra', ''], ['Hessel', 'Jack', ''], ['Hwang', 'Jena D.', ''], ['Jiang', 'Liwei', ''], ['Bras', 'Ronan Le', ''], ['Lu', 'Ximing', ''], ['Welleck', 'Sean', ''], ['Choi', 'Yejin', '']]",0,1,2021-10-14,2,9,1,1,0,1,521ccc898395a2818fced22b4cf371b0e5121f94,238857304.0,https://www.semanticscholar.org/paper/521ccc898395a2818fced22b4cf371b0e5121f94,North American Chapter of the Association for Computational Linguistics,2021.0,76.0,166.0,17.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '119659229', 'name': 'Peter West'}, {'authorId': '51177106', 'name': 'Chandrasekhar Bhagavatula'}, {'authorId': '2689239', 'name': 'Jack Hessel'}, {'authorId': '2012510', 'name': 'Jena D. Hwang'}, {'authorId': '2112504145', 'name': 'Liwei Jiang'}, {'authorId': '39227408', 'name': 'Ronan Le Bras'}, {'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '2129663', 'name': 'S. Welleck'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]",['Allen Institute for Artificial Intelligence'],['United States'],2021-10,['industrial']
2110.08554,Iacopo Poli,"Julien Launay, Elena Tommasone, Baptiste Pannier, Fran\c{c}ois
  Boniface, Am\'elie Chatelain, Alessandro Cappelli, Iacopo Poli, Djam\'e
  Seddah",PAGnol: An Extra-Large French Generative Model,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Access to large pre-trained models of varied architectures, in many different languages, is central to the democratization of NLP. We introduce PAGnol, a collection of French GPT models. Using scaling laws, we efficiently train PAGnol-XL (1.5B parameters) with the same computational budget as CamemBERT, a model 13 times smaller. PAGnol-XL is the largest model trained to date for the French language. We plan to train increasingly large and performing versions of PAGnol, exploring the capabilities of French extreme-scale models.   For this first release, we focus on the pre-training and scaling calculations underlining PAGnol. We fit a scaling law for compute for the French language, and compare it with its English counterpart. We find the pre-training dataset significantly conditions the quality of the outputs, with common datasets such as OSCAR leading to low-quality offensive text. We evaluate our models on discriminative and generative tasks in French, comparing to other state-of-the-art French and multilingual models, and reaching the state of the art in the abstract summarization task. Our research was conducted on the public GENCI Jean Zay supercomputer, and our models up to the Large are made publicly available. ","[{'version': 'v1', 'created': 'Sat, 16 Oct 2021 11:44:23 GMT'}]",2022-10-26,"[['Launay', 'Julien', ''], ['Tommasone', 'Elena', ''], ['Pannier', 'Baptiste', ''], ['Boniface', 'François', ''], ['Chatelain', 'Amélie', ''], ['Cappelli', 'Alessandro', ''], ['Poli', 'Iacopo', ''], ['Seddah', 'Djamé', '']]",0,1,2021-10-16,1,8,1,0,0,0,92bc69500c16fce47bcfd06ada14ffc4a7e8ddca,239016819.0,https://www.semanticscholar.org/paper/92bc69500c16fce47bcfd06ada14ffc4a7e8ddca,International Conference on Language Resources and Evaluation,2021.0,57.0,3.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143945447', 'name': 'Julien Launay'}, {'authorId': '2133304066', 'name': 'E. L. Tommasone'}, {'authorId': '91723794', 'name': 'B. Pannier'}, {'authorId': '1753690402', 'name': 'Franccois Boniface'}, {'authorId': '102303348', 'name': 'A. Chatelain'}, {'authorId': '2069293685', 'name': 'Alessandro Cappelli'}, {'authorId': '46186238', 'name': 'Iacopo Poli'}, {'authorId': '1679170', 'name': 'Djamé Seddah'}]","['Inria, Paris']",,2021-10,['industrial']
2110.10024,Su Lin Blodgett,"Su Lin Blodgett, Michael Madaio",Risks of AI Foundation Models in Education,,,,,cs.CY cs.AI,http://creativecommons.org/licenses/by/4.0/,"  If the authors of a recent Stanford report (Bommasani et al., 2021) on the opportunities and risks of ""foundation models"" are to be believed, these models represent a paradigm shift for AI and for the domains in which they will supposedly be used, including education. Although the name is new (and contested (Field, 2021)), the term describes existing types of algorithmic models that are ""trained on broad data at scale"" and ""fine-tuned"" (i.e., adapted) for particular downstream tasks, and is intended to encompass large language models such as BERT or GPT-3 and computer vision models such as CLIP. Such technologies have the potential for harm broadly speaking (e.g., Bender et al., 2021), but their use in the educational domain is particularly fraught, despite the potential benefits for learners claimed by the authors. In section 3.3 of the Stanford report, Malik et al. argue that achieving the goal of providing education for all learners requires more efficient computational approaches that can rapidly scale across educational domains and across educational contexts, for which they argue foundation models are uniquely well-suited. However, evidence suggests that not only are foundation models not likely to achieve the stated benefits for learners, but their use may also introduce new risks for harm. ","[{'version': 'v1', 'created': 'Tue, 19 Oct 2021 14:44:02 GMT'}]",2021-10-20,"[['Blodgett', 'Su Lin', ''], ['Madaio', 'Michael', '']]",0,1,2021-10-19,1,2,2,1,0,1,6b7019e2cc1b3cc9d8e93e39de02d1a8eab278d9,239024554.0,https://www.semanticscholar.org/paper/6b7019e2cc1b3cc9d8e93e39de02d1a8eab278d9,arXiv.org,2021.0,32.0,7.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '3422038', 'name': 'Su Lin Blodgett'}, {'authorId': '38113700', 'name': 'Michael A. Madaio'}]",['Microsoft'],"['Canada', 'United States']",2021-10,['industrial']
2110.14843,Praneeth Gubbala,"Praneeth Gubbala, Xuan Zhang",A Sequence to Sequence Model for Extracting Multiple Product Name Entities from Dialog,WeCNLP 2021 camera-ready,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  E-commerce voice ordering systems need to recognize multiple product name entities from ordering utterances. Existing voice ordering systems such as Amazon Alexa can capture only a single product name entity. This restrains users from ordering multiple items with one utterance. In recent years, pre-trained language models, e.g., BERT and GPT-2, have shown promising results on NLP benchmarks like Super-GLUE. However, they can't perfectly generalize to this Multiple Product Name Entity Recognition (MPNER) task due to the ambiguity in voice ordering utterances. To fill this research gap, we propose Entity Transformer (ET) neural network architectures which recognize up to 10 items in an utterance. In our evaluation, the best ET model (conveRT + ngram + ET) has a performance improvement of 12% on our test set compared to the non-neural model, and outperforms BERT with ET as well. This helps customers finalize their shopping cart via voice dialog, which improves shopping efficiency and experience. ","[{'version': 'v1', 'created': 'Thu, 28 Oct 2021 01:54:02 GMT'}]",2021-10-29,"[['Gubbala', 'Praneeth', ''], ['Zhang', 'Xuan', '']]",0,1,2021-10-28,1,2,2,1,1,0,ae54a3426f1d3daed0bbb88791b28e76c1e669b5,240070850.0,https://www.semanticscholar.org/paper/ae54a3426f1d3daed0bbb88791b28e76c1e669b5,arXiv.org,2021.0,10.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2135517984', 'name': 'Praneeth Gubbala'}, {'authorId': '2108231687', 'name': 'Xuan Zhang'}]",['Walmart Global Tech'],,2021-10,['industrial']
2111.02878,Matthias Gall\'e,"Matthias Gall\'e, Jos Rozen, Germ\'an Kruszewski, Hady Elsahar",Unsupervised and Distributional Detection of Machine-Generated Text,10 pages,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The power of natural language generation models has provoked a flurry of interest in automatic methods to detect if a piece of text is human or machine-authored. The problem so far has been framed in a standard supervised way and consists in training a classifier on annotated data to predict the origin of one given new document. In this paper, we frame the problem in an unsupervised and distributional way: we assume that we have access to a large collection of unannotated documents, a big fraction of which is machine-generated. We propose a method to detect those machine-generated documents leveraging repeated higher-order n-grams, which we show over-appear in machine-generated text as compared to human ones. That weak signal is the starting point of a self-training setting where pseudo-labelled documents are used to train an ensemble of classifiers. Our experiments show that leveraging that signal allows us to rank suspicious documents accurately. Precision at 5000 is over 90% for top-k sampling strategies, and over 80% for nucleus sampling for the largest model we used (GPT2-large). The drop with increased size of model is small, which could indicate that the results hold for other current and future large language models. ","[{'version': 'v1', 'created': 'Thu, 4 Nov 2021 14:07:46 GMT'}]",2021-11-05,"[['Gallé', 'Matthias', ''], ['Rozen', 'Jos', ''], ['Kruszewski', 'Germán', ''], ['Elsahar', 'Hady', '']]",0,1,2021-11-04,1,4,2,1,1,0,49fc8eb2c3770b005b1b0d34febf14de838aa238,242757564.0,https://www.semanticscholar.org/paper/49fc8eb2c3770b005b1b0d34febf14de838aa238,arXiv.org,2021.0,33.0,16.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2907260', 'name': 'Matthias Gallé'}, {'authorId': '120419790', 'name': 'Jos Rozen'}, {'authorId': '2067996', 'name': 'Germán Kruszewski'}, {'authorId': '2218938', 'name': 'Hady ElSahar'}]",['NAVER'],['South Korea'],2021-11,['industrial']
2111.05204,Leonard Adolphs,"Leonard Adolphs, Kurt Shuster, Jack Urbanek, Arthur Szlam, Jason
  Weston","Reason first, then respond: Modular Generation for Knowledge-infused Dialogue",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models can produce fluent dialogue but often hallucinate factual inaccuracies. While retrieval-augmented models help alleviate this issue, they still face a difficult challenge of both reasoning to provide correct knowledge and generating conversation simultaneously. In this work, we propose a modular model, Knowledge to Response (K2R), for incorporating knowledge into conversational agents, which breaks down this problem into two easier steps. K2R first generates a knowledge sequence, given a dialogue context, as an intermediate step. After this ""reasoning step"", the model then attends to its own generated knowledge sequence, as well as the dialogue context, to produce a final response. In detailed experiments, we find that such a model hallucinates less in knowledge-grounded dialogue tasks, and has advantages in terms of interpretability and modularity. In particular, it can be used to fuse QA and dialogue systems together to enable dialogue agents to give knowledgeable answers, or QA models to give conversational responses in a zero-shot setting. ","[{'version': 'v1', 'created': 'Tue, 9 Nov 2021 15:29:43 GMT'}]",2021-11-10,"[['Adolphs', 'Leonard', ''], ['Shuster', 'Kurt', ''], ['Urbanek', 'Jack', ''], ['Szlam', 'Arthur', ''], ['Weston', 'Jason', '']]",0,0,2021-11-09,1,5,3,0,0,0,d15d96517370c9ed0658d176b979bcf92d1373ea,243860761.0,https://www.semanticscholar.org/paper/d15d96517370c9ed0658d176b979bcf92d1373ea,Conference on Empirical Methods in Natural Language Processing,2021.0,49.0,25.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46196592', 'name': 'Leonard Adolphs'}, {'authorId': '35752280', 'name': 'Kurt Shuster'}, {'authorId': '39219656', 'name': 'Jack Urbanek'}, {'authorId': '3149531', 'name': 'Arthur Szlam'}, {'authorId': '145183709', 'name': 'J. Weston'}]","['ETH Zurich', 'Meta']","['United States', 'Switzerland']",2021-11,"['industrial', 'industrial']"
2111.08284,Ana Marasovi\'c,"Ana Marasovi\'c, Iz Beltagy, Doug Downey, Matthew E. Peters",Few-Shot Self-Rationalization with Natural Language Prompts,"v2: NAACL Findings 2022 accepted paper camera-ready version. First
  two authors contributed equally. 9 pages main, 3 pages appendix",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Self-rationalization models that predict task labels and generate free-text elaborations for their predictions could enable more intuitive interaction with NLP systems. These models are, however, currently trained with a large amount of human-written free-text explanations for each task which hinders their broader usage. We propose to study a more realistic setting of self-rationalization using few training examples. We present FEB -- a standardized collection of four existing English-language datasets and associated metrics. We identify the right prompting approach by extensively exploring natural language prompts on FEB. Then, by using this prompt and scaling the model size, we demonstrate that making progress on few-shot self-rationalization is possible. We show there is still ample room for improvement in this task: the average plausibility of generated explanations assessed by human annotators is at most 51% (with GPT-3), while plausibility of human explanations is 76%. We hope that FEB and our proposed approach will spur the community to take on the few-shot self-rationalization challenge. ","[{'version': 'v1', 'created': 'Tue, 16 Nov 2021 08:21:40 GMT'}, {'version': 'v2', 'created': 'Tue, 26 Apr 2022 00:34:47 GMT'}]",2022-04-27,"[['Marasović', 'Ana', ''], ['Beltagy', 'Iz', ''], ['Downey', 'Doug', ''], ['Peters', 'Matthew E.', '']]",0,1,2021-11-16,2,4,1,1,0,1,9a258f42e333ed5ff79037724eb01747ede0bb49,244130199.0,https://www.semanticscholar.org/paper/9a258f42e333ed5ff79037724eb01747ede0bb49,NAACL-HLT,2021.0,74.0,62.0,13.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '3451494', 'name': 'Ana Marasović'}, {'authorId': '46181066', 'name': 'Iz Beltagy'}, {'authorId': '145612610', 'name': 'Doug Downey'}, {'authorId': '39139825', 'name': 'Matthew E. Peters'}]",['Allen Institute for Artificial Intelligence'],['United States'],2021-11,['industrial']
2111.11294,Kyuyong Shin,"Kyuyong Shin, Hanock Kwak, Su Young Kim, Max Nihlen Ramstrom, Jisu
  Jeong, Jung-Woo Ha, Kyung-Min Kim",Scaling Law for Recommendation Models: Towards General-purpose User Representations,Accepted at AAAI 2023. This version includes the technical appendix,,,,cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advancement of large-scale pretrained models such as BERT, GPT-3, CLIP, and Gopher, has shown astonishing achievements across various task domains. Unlike vision recognition and language models, studies on general-purpose user representation at scale still remain underexplored. Here we explore the possibility of general-purpose user representation learning by training a universal user encoder at large scales. We demonstrate that the scaling law is present in user representation learning areas, where the training error scales as a power-law with the amount of computation. Our Contrastive Learning User Encoder (CLUE), optimizes task-agnostic objectives, and the resulting user embeddings stretch our expectation of what is possible to do in various downstream tasks. CLUE also shows great transferability to other domains and companies, as performances on an online experiment shows significant improvements in Click-Through-Rate (CTR). Furthermore, we also investigate how the model performance is influenced by the scale factors, such as training data size, model capacity, sequence length, and batch size. Finally, we discuss the broader impacts of CLUE in general. ","[{'version': 'v1', 'created': 'Mon, 15 Nov 2021 10:39:29 GMT'}, {'version': 'v2', 'created': 'Wed, 1 Dec 2021 12:49:38 GMT'}, {'version': 'v3', 'created': 'Sat, 5 Feb 2022 08:09:24 GMT'}, {'version': 'v4', 'created': 'Mon, 21 Nov 2022 10:52:55 GMT'}, {'version': 'v5', 'created': 'Tue, 22 Nov 2022 07:15:03 GMT'}]",2022-11-23,"[['Shin', 'Kyuyong', ''], ['Kwak', 'Hanock', ''], ['Kim', 'Su Young', ''], ['Ramstrom', 'Max Nihlen', ''], ['Jeong', 'Jisu', ''], ['Ha', 'Jung-Woo', ''], ['Kim', 'Kyung-Min', '']]",0,1,2021-11-15,5,7,2,2,0,2,7567744a0e23174166575e8d98590967684696b4,244477730.0,https://www.semanticscholar.org/paper/7567744a0e23174166575e8d98590967684696b4,AAAI Conference on Artificial Intelligence,2021.0,57.0,18.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2810739', 'name': 'Kyuyong Shin'}, {'authorId': '3434480', 'name': 'Hanock Kwak'}, {'authorId': '2109351321', 'name': 'KyungHyun Kim'}, {'authorId': '2143061094', 'name': 'S. Kim'}, {'authorId': '2141575359', 'name': ""Max Nihl'en Ramstrom""}]",['NAVER'],['South Korea'],2021-11,['industrial']
2112.08414,Xueying Zhang,"Xueying Zhang, Yunjiang Jiang, Yue Shang, Zhaomeng Cheng, Chi Zhang,
  Xiaochuan Fan, Yun Xiao, Bo Long",DSGPT: Domain-Specific Generative Pre-Training of Transformers for Text Generation in E-commerce Title and Review Summarization,,"SIGIR 2021: Proceedings of the 44th International ACM SIGIR
  Conference on Research and Development in Information Retrieval, July 2021,
  Pages 2146-2150",10.1145/3404835.3463037,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We propose a novel domain-specific generative pre-training (DS-GPT) method for text generation and apply it to the product titleand review summarization problems on E-commerce mobile display.First, we adopt a decoder-only transformer architecture, which fitswell for fine-tuning tasks by combining input and output all to-gether. Second, we demonstrate utilizing only small amount of pre-training data in related domains is powerful. Pre-training a languagemodel from a general corpus such as Wikipedia or the CommonCrawl requires tremendous time and resource commitment, andcan be wasteful if the downstream tasks are limited in variety. OurDSGPT is pre-trained on a limited dataset, the Chinese short textsummarization dataset (LCSTS). Third, our model does not requireproduct-related human-labeled data. For title summarization task,the state of art explicitly uses additional background knowledgein training and predicting stages. In contrast, our model implic-itly captures this knowledge and achieves significant improvementover other methods, after fine-tuning on the public Taobao.comdataset. For review summarization task, we utilize JD.com in-housedataset, and observe similar improvement over standard machinetranslation methods which lack the flexibility of fine-tuning. Ourproposed work can be simply extended to other domains for a widerange of text generation tasks. ","[{'version': 'v1', 'created': 'Wed, 15 Dec 2021 19:02:49 GMT'}]",2021-12-17,"[['Zhang', 'Xueying', ''], ['Jiang', 'Yunjiang', ''], ['Shang', 'Yue', ''], ['Cheng', 'Zhaomeng', ''], ['Zhang', 'Chi', ''], ['Fan', 'Xiaochuan', ''], ['Xiao', 'Yun', ''], ['Long', 'Bo', '']]",0,1,2021-12-15,1,8,2,0,0,0,0f6297a1bd9311bacbe57fdde945d0e1d46f59be,235792325.0,https://www.semanticscholar.org/paper/0f6297a1bd9311bacbe57fdde945d0e1d46f59be,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2021.0,18.0,13.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2118889880', 'name': 'Xueying Zhang'}, {'authorId': '2131218', 'name': 'Yunjiang Jiang'}, {'authorId': '2053234459', 'name': 'Yue Shang'}, {'authorId': '2113279258', 'name': 'Zhaomeng Cheng'}, {'authorId': '2145179631', 'name': 'Chi Zhang'}, {'authorId': '49537566', 'name': 'Xiaochuan Fan'}, {'authorId': '2122427161', 'name': 'Yun Xiao'}, {'authorId': '2052143728', 'name': 'Bo Long'}]",['Jingdong'],['United States'],2021-12,['industrial']
2112.08653,Davis Yoshida,Davis Yoshida and Kevin Gimpel,Reconsidering the Past: Optimizing Hidden States in Language Models,Findings of EMNLP version,"Findings of the Association for Computational Linguistics: EMNLP
  2021, pages 4099-4105",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present Hidden-State Optimization (HSO), a gradient-based method for improving the performance of transformer language models at inference time. Similar to dynamic evaluation (Krause et al., 2018), HSO computes the gradient of the log-probability the language model assigns to an evaluation text, but uses it to update the cached hidden states rather than the model parameters. We test HSO with pretrained Transformer-XL and GPT-2 language models, finding improvement on the WikiText103 and PG-19 datasets in terms of perplexity, especially when evaluating a model outside of its training distribution. We also demonstrate downstream applicability by showing gains in the recently developed prompt-based few-shot evaluation setting, again with no extra parameters or training data. ","[{'version': 'v1', 'created': 'Thu, 16 Dec 2021 06:14:37 GMT'}]",2021-12-17,"[['Yoshida', 'Davis', ''], ['Gimpel', 'Kevin', '']]",0,1,2021-12-16,1,2,1,1,1,0,b7e94220176d9d329ee064fd4359229bf92ef360,237568129.0,https://www.semanticscholar.org/paper/b7e94220176d9d329ee064fd4359229bf92ef360,Conference on Empirical Methods in Natural Language Processing,2021.0,30.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '74884989', 'name': 'Davis Yoshida'}, {'authorId': '1700980', 'name': 'Kevin Gimpel'}]",['Toyota Technological Institute at Chicago'],['United States'],2021-12,['industrial']
2112.09332,Jacob Hilton,"Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang,
  Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William
  Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin
  Button, Matthew Knight, Benjamin Chess, John Schulman",WebGPT: Browser-assisted question-answering with human feedback,32 pages,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We fine-tune GPT-3 to answer long-form questions using a text-based web-browsing environment, which allows the model to search and navigate the web. By setting up the task so that it can be performed by humans, we are able to train models on the task using imitation learning, and then optimize answer quality with human feedback. To make human evaluation of factual accuracy easier, models must collect references while browsing in support of their answers. We train and evaluate our models on ELI5, a dataset of questions asked by Reddit users. Our best model is obtained by fine-tuning GPT-3 using behavior cloning, and then performing rejection sampling against a reward model trained to predict human preferences. This model's answers are preferred by humans 56% of the time to those of our human demonstrators, and 69% of the time to the highest-voted answer from Reddit. ","[{'version': 'v1', 'created': 'Fri, 17 Dec 2021 05:43:43 GMT'}, {'version': 'v2', 'created': 'Sat, 12 Mar 2022 22:49:16 GMT'}, {'version': 'v3', 'created': 'Wed, 1 Jun 2022 19:08:11 GMT'}]",2022-06-03,"[['Nakano', 'Reiichiro', ''], ['Hilton', 'Jacob', ''], ['Balaji', 'Suchir', ''], ['Wu', 'Jeff', ''], ['Ouyang', 'Long', ''], ['Kim', 'Christina', ''], ['Hesse', 'Christopher', ''], ['Jain', 'Shantanu', ''], ['Kosaraju', 'Vineet', ''], ['Saunders', 'William', ''], ['Jiang', 'Xu', ''], ['Cobbe', 'Karl', ''], ['Eloundou', 'Tyna', ''], ['Krueger', 'Gretchen', ''], ['Button', 'Kevin', ''], ['Knight', 'Matthew', ''], ['Chess', 'Benjamin', ''], ['Schulman', 'John', '']]",0,1,2021-12-17,3,18,3,2,0,2,2f3efe44083af91cef562c1a3451eee2f8601d22,245329531.0,https://www.semanticscholar.org/paper/2f3efe44083af91cef562c1a3451eee2f8601d22,arXiv.org,2021.0,44.0,446.0,58.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '7406311', 'name': 'Reiichiro Nakano'}, {'authorId': '2052366271', 'name': 'Jacob Hilton'}, {'authorId': '2054519183', 'name': 'S. Balaji'}, {'authorId': '49387725', 'name': 'Jeff Wu'}, {'authorId': '2228518120', 'name': 'Ouyang Long'}, {'authorId': '2149054292', 'name': 'Christina Kim'}, {'authorId': '144239765', 'name': 'Christopher Hesse'}, {'authorId': '150298413', 'name': 'Shantanu Jain'}, {'authorId': '13622184', 'name': 'V. Kosaraju'}, {'authorId': '2058848938', 'name': 'W. Saunders'}, {'authorId': '2115903168', 'name': 'Xu Jiang'}, {'authorId': '6062736', 'name': 'Karl Cobbe'}, {'authorId': '2146257131', 'name': 'Tyna Eloundou'}, {'authorId': '2064404342', 'name': 'Gretchen Krueger'}, {'authorId': '2146257251', 'name': 'Kevin Button'}, {'authorId': '2146257375', 'name': 'Matthew Knight'}, {'authorId': '1490681878', 'name': 'Benjamin Chess'}, {'authorId': '47971768', 'name': 'J. Schulman'}]",['Jeff Wu Long Ouyang Christina Kim'],,2021-12,['industrial']
2112.11446,Jack Rae,"Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan
  Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah
  Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard
  Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen
  Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang,
  Jonathan Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese,
  Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden,
  Esme Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena
  Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena
  Gribovskaya, Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste
  Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux,
  Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson
  d'Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan
  Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew
  Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed
  Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem
  Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu,
  Geoffrey Irving","Scaling Language Models: Methods, Analysis & Insights from Training Gopher",120 pages,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language modelling provides a step towards intelligent communication systems by harnessing large repositories of written human knowledge to better predict and understand the world. In this paper, we present an analysis of Transformer-based language model performance across a wide range of model scales -- from models with tens of millions of parameters up to a 280 billion parameter model called Gopher. These models are evaluated on 152 diverse tasks, achieving state-of-the-art performance across the majority. Gains from scale are largest in areas such as reading comprehension, fact-checking, and the identification of toxic language, but logical and mathematical reasoning see less benefit. We provide a holistic analysis of the training dataset and model's behaviour, covering the intersection of model scale with bias and toxicity. Finally we discuss the application of language models to AI safety and the mitigation of downstream harms. ","[{'version': 'v1', 'created': 'Wed, 8 Dec 2021 19:41:47 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Jan 2022 18:39:38 GMT'}]",2022-01-24,"[['Rae', 'Jack W.', ''], ['Borgeaud', 'Sebastian', ''], ['Cai', 'Trevor', ''], ['Millican', 'Katie', ''], ['Hoffmann', 'Jordan', ''], ['Song', 'Francis', ''], ['Aslanides', 'John', ''], ['Henderson', 'Sarah', ''], ['Ring', 'Roman', ''], ['Young', 'Susannah', ''], ['Rutherford', 'Eliza', ''], ['Hennigan', 'Tom', ''], ['Menick', 'Jacob', ''], ['Cassirer', 'Albin', ''], ['Powell', 'Richard', ''], ['Driessche', 'George van den', ''], ['Hendricks', 'Lisa Anne', ''], ['Rauh', 'Maribeth', ''], ['Huang', 'Po-Sen', ''], ['Glaese', 'Amelia', ''], ['Welbl', 'Johannes', ''], ['Dathathri', 'Sumanth', ''], ['Huang', 'Saffron', ''], ['Uesato', 'Jonathan', ''], ['Mellor', 'John', ''], ['Higgins', 'Irina', ''], ['Creswell', 'Antonia', ''], ['McAleese', 'Nat', ''], ['Wu', 'Amy', ''], ['Elsen', 'Erich', ''], ['Jayakumar', 'Siddhant', ''], ['Buchatskaya', 'Elena', ''], ['Budden', 'David', ''], ['Sutherland', 'Esme', ''], ['Simonyan', 'Karen', ''], ['Paganini', 'Michela', ''], ['Sifre', 'Laurent', ''], ['Martens', 'Lena', ''], ['Li', 'Xiang Lorraine', ''], ['Kuncoro', 'Adhiguna', ''], ['Nematzadeh', 'Aida', ''], ['Gribovskaya', 'Elena', ''], ['Donato', 'Domenic', ''], ['Lazaridou', 'Angeliki', ''], ['Mensch', 'Arthur', ''], ['Lespiau', 'Jean-Baptiste', ''], ['Tsimpoukelli', 'Maria', ''], ['Grigorev', 'Nikolai', ''], ['Fritz', 'Doug', ''], ['Sottiaux', 'Thibault', ''], ['Pajarskas', 'Mantas', ''], ['Pohlen', 'Toby', ''], ['Gong', 'Zhitao', ''], ['Toyama', 'Daniel', ''], [""d'Autume"", 'Cyprien de Masson', ''], ['Li', 'Yujia', ''], ['Terzi', 'Tayfun', ''], ['Mikulik', 'Vladimir', ''], ['Babuschkin', 'Igor', ''], ['Clark', 'Aidan', ''], ['Casas', 'Diego de Las', ''], ['Guy', 'Aurelia', ''], ['Jones', 'Chris', ''], ['Bradbury', 'James', ''], ['Johnson', 'Matthew', ''], ['Hechtman', 'Blake', ''], ['Weidinger', 'Laura', ''], ['Gabriel', 'Iason', ''], ['Isaac', 'William', ''], ['Lockhart', 'Ed', ''], ['Osindero', 'Simon', ''], ['Rimell', 'Laura', ''], ['Dyer', 'Chris', ''], ['Vinyals', 'Oriol', ''], ['Ayoub', 'Kareem', ''], ['Stanway', 'Jeff', ''], ['Bennett', 'Lorrayne', ''], ['Hassabis', 'Demis', ''], ['Kavukcuoglu', 'Koray', ''], ['Irving', 'Geoffrey', '']]",0,0,2021-12-08,2,80,2,1,0,1,68f141724814839d556a989646194be88641b143,245353475.0,https://www.semanticscholar.org/paper/68f141724814839d556a989646194be88641b143,arXiv.org,2021.0,0.0,724.0,64.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '34269227', 'name': 'Jack W. Rae'}, {'authorId': '148016269', 'name': 'Sebastian Borgeaud'}, {'authorId': '2072572294', 'name': 'Trevor Cai'}, {'authorId': '2143434227', 'name': 'Katie Millican'}, {'authorId': '46616544', 'name': 'Jordan Hoffmann'}, {'authorId': '2059836321', 'name': 'Francis Song'}, {'authorId': '9958912', 'name': 'J. Aslanides'}, {'authorId': '2057025033', 'name': 'Sarah Henderson'}, {'authorId': '81387328', 'name': 'Roman Ring'}, {'authorId': '116494324', 'name': 'Susannah Young'}, {'authorId': '2143538252', 'name': 'Eliza Rutherford'}, {'authorId': '2146532222', 'name': 'Tom Hennigan'}, {'authorId': '10698483', 'name': 'Jacob Menick'}, {'authorId': '51042571', 'name': 'Albin Cassirer'}, {'authorId': '2067745837', 'name': 'Richard Powell'}, {'authorId': '47568983', 'name': 'George van den Driessche'}, {'authorId': '2234342', 'name': 'Lisa Anne Hendricks'}, {'authorId': '94483529', 'name': 'M. Rauh'}, {'authorId': '2421691', 'name': 'Po-Sen Huang'}, {'authorId': '2105840001', 'name': 'A. Glaese'}, {'authorId': '1851564', 'name': 'Johannes Welbl'}, {'authorId': '3491117', 'name': 'Sumanth Dathathri'}, {'authorId': '2148653469', 'name': 'Saffron Huang'}, {'authorId': '9960452', 'name': 'J. Uesato'}, {'authorId': '1386957852', 'name': 'John F. J. Mellor'}, {'authorId': '39051054', 'name': 'I. Higgins'}, {'authorId': '3433026', 'name': 'Antonia Creswell'}, {'authorId': '147687624', 'name': 'Nathan McAleese'}, {'authorId': '2147235306', 'name': 'Amy Wu'}, {'authorId': '152585800', 'name': 'Erich Elsen'}, {'authorId': '35880964', 'name': 'Siddhant M. Jayakumar'}, {'authorId': '118801223', 'name': 'Elena Buchatskaya'}, {'authorId': '2508525', 'name': 'D. Budden'}, {'authorId': '2146531039', 'name': 'Esme Sutherland'}, {'authorId': '34838386', 'name': 'K. Simonyan'}, {'authorId': '35550664', 'name': 'Michela Paganini'}, {'authorId': '2175946', 'name': 'L. Sifre'}, {'authorId': '2146532326', 'name': 'Lena Martens'}, {'authorId': '1737850', 'name': 'Xiang Lorraine Li'}, {'authorId': '3376845', 'name': 'A. Kuncoro'}, {'authorId': '3208081', 'name': 'Aida Nematzadeh'}, {'authorId': '1980809', 'name': 'E. Gribovskaya'}, {'authorId': '119050937', 'name': 'Domenic Donato'}, {'authorId': '2672644', 'name': 'Angeliki Lazaridou'}, {'authorId': '1697879', 'name': 'A. Mensch'}, {'authorId': '143783339', 'name': 'J. Lespiau'}, {'authorId': '2010057', 'name': 'Maria Tsimpoukelli'}, {'authorId': '84052496', 'name': 'N. Grigorev'}, {'authorId': '40514522', 'name': 'Doug Fritz'}, {'authorId': '2070364520', 'name': 'Thibault Sottiaux'}, {'authorId': '2146532125', 'name': 'Mantas Pajarskas'}, {'authorId': '3408089', 'name': 'Tobias Pohlen'}, {'authorId': '5145075', 'name': 'Z. Gong'}, {'authorId': '1393948967', 'name': 'Daniel Toyama'}, {'authorId': '1413221272', 'name': ""Cyprien de Masson d'Autume""}, {'authorId': '47002813', 'name': 'Yujia Li'}, {'authorId': '114261380', 'name': 'Tayfun Terzi'}, {'authorId': '148305440', 'name': 'Vladimir Mikulik'}, {'authorId': '2256699276', 'name': 'Igor Babuschkin'}, {'authorId': '31993415', 'name': 'Aidan Clark'}, {'authorId': '40550616', 'name': 'Diego de Las Casas'}, {'authorId': '40895205', 'name': 'Aurelia Guy'}, {'authorId': '2115601070', 'name': 'Chris Jones'}, {'authorId': '2065251344', 'name': 'James Bradbury'}, {'authorId': '2124469920', 'name': 'Matthew G. Johnson'}, {'authorId': '3135881', 'name': 'Blake A. Hechtman'}, {'authorId': '51932191', 'name': 'Laura Weidinger'}, {'authorId': '116589025', 'name': 'Iason Gabriel'}, {'authorId': '103087275', 'name': 'William S. Isaac'}, {'authorId': '49860549', 'name': 'Edward Lockhart'}, {'authorId': '2217144', 'name': 'Simon Osindero'}, {'authorId': '2554988', 'name': 'Laura Rimell'}, {'authorId': '1745899', 'name': 'Chris Dyer'}, {'authorId': '1689108', 'name': 'Oriol Vinyals'}, {'authorId': '34122449', 'name': 'Kareem W. Ayoub'}, {'authorId': '35149729', 'name': 'Jeff Stanway'}, {'authorId': '121282413', 'name': 'L. Bennett'}, {'authorId': '48987704', 'name': 'D. Hassabis'}, {'authorId': '2645384', 'name': 'K. Kavukcuoglu'}, {'authorId': '2060655766', 'name': 'G. Irving'}]","['Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa']",,2021-12,['industrial']
2112.12731,Shuohuan Wang,"Shuohuan Wang, Yu Sun, Yang Xiang, Zhihua Wu, Siyu Ding, Weibao Gong,
  Shikun Feng, Junyuan Shang, Yanbin Zhao, Chao Pang, Jiaxiang Liu, Xuyi Chen,
  Yuxiang Lu, Weixin Liu, Xi Wang, Yangfan Bai, Qiuliang Chen, Li Zhao, Shiyong
  Li, Peng Sun, Dianhai Yu, Yanjun Ma, Hao Tian, Hua Wu, Tian Wu, Wei Zeng, Ge
  Li, Wen Gao, Haifeng Wang",ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation,arXiv admin note: text overlap with arXiv:2107.02137,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models have achieved state-of-the-art results in various Natural Language Processing (NLP) tasks. GPT-3 has shown that scaling up pre-trained language models can further exploit their enormous potential. A unified framework named ERNIE 3.0 was recently proposed for pre-training large-scale knowledge enhanced models and trained a model with 10 billion parameters. ERNIE 3.0 outperformed the state-of-the-art models on various NLP tasks. In order to explore the performance of scaling up ERNIE 3.0, we train a hundred-billion-parameter model called ERNIE 3.0 Titan with up to 260 billion parameters on the PaddlePaddle platform. Furthermore, we design a self-supervised adversarial loss and a controllable language modeling loss to make ERNIE 3.0 Titan generate credible and controllable texts. To reduce the computation overhead and carbon emission, we propose an online distillation framework for ERNIE 3.0 Titan, where the teacher model will teach students and train itself simultaneously. ERNIE 3.0 Titan is the largest Chinese dense pre-trained model so far. Empirical results show that the ERNIE 3.0 Titan outperforms the state-of-the-art models on 68 NLP datasets. ","[{'version': 'v1', 'created': 'Thu, 23 Dec 2021 17:35:48 GMT'}]",2021-12-24,"[['Wang', 'Shuohuan', ''], ['Sun', 'Yu', ''], ['Xiang', 'Yang', ''], ['Wu', 'Zhihua', ''], ['Ding', 'Siyu', ''], ['Gong', 'Weibao', ''], ['Feng', 'Shikun', ''], ['Shang', 'Junyuan', ''], ['Zhao', 'Yanbin', ''], ['Pang', 'Chao', ''], ['Liu', 'Jiaxiang', ''], ['Chen', 'Xuyi', ''], ['Lu', 'Yuxiang', ''], ['Liu', 'Weixin', ''], ['Wang', 'Xi', ''], ['Bai', 'Yangfan', ''], ['Chen', 'Qiuliang', ''], ['Zhao', 'Li', ''], ['Li', 'Shiyong', ''], ['Sun', 'Peng', ''], ['Yu', 'Dianhai', ''], ['Ma', 'Yanjun', ''], ['Tian', 'Hao', ''], ['Wu', 'Hua', ''], ['Wu', 'Tian', ''], ['Zeng', 'Wei', ''], ['Li', 'Ge', ''], ['Gao', 'Wen', ''], ['Wang', 'Haifeng', '']]",0,1,2021-12-23,1,29,1,3,0,3,a3184d40d390793232c99c89b57b8f65c16320b2,245425057.0,https://www.semanticscholar.org/paper/a3184d40d390793232c99c89b57b8f65c16320b2,arXiv.org,2021.0,104.0,37.0,11.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '104463827', 'name': 'Shuohuan Wang'}, {'authorId': '2117103617', 'name': 'Yu Sun'}, {'authorId': '2068340960', 'name': 'Yang Xiang'}, {'authorId': '47039787', 'name': 'Zhihua Wu'}, {'authorId': '2152123817', 'name': 'Siyu Ding'}, {'authorId': '2117587198', 'name': 'Weibao Gong'}, {'authorId': '144588144', 'name': 'Shi Feng'}, {'authorId': '40861754', 'name': 'Junyuan Shang'}, {'authorId': '2117889541', 'name': 'Yanbin Zhao'}, {'authorId': '2054086618', 'name': 'Chao Pang'}, {'authorId': '2144130913', 'name': 'Jiaxiang Liu'}, {'authorId': '2109214103', 'name': 'Xuyi Chen'}, {'authorId': '2140025135', 'name': 'Yuxiang Lu'}, {'authorId': '2109563578', 'name': 'Weixin Liu'}, {'authorId': '2108249583', 'name': 'Xi Wang'}, {'authorId': '2153241479', 'name': 'Yangfan Bai'}, {'authorId': '2157776938', 'name': 'Qiuliang Chen'}, {'authorId': '2116548646', 'name': 'Li Zhao'}, {'authorId': '2155911527', 'name': 'Shiyong Li'}, {'authorId': '2075416480', 'name': 'Peng Sun'}, {'authorId': '3046102', 'name': 'Dianhai Yu'}, {'authorId': '2148985098', 'name': 'Yanjun Ma'}, {'authorId': '50007795', 'name': 'Hao Tian'}, {'authorId': '40354707', 'name': 'Hua Wu'}, {'authorId': '2112663486', 'name': 'Tian Wu'}, {'authorId': '144424265', 'name': 'Wei Zeng'}, {'authorId': '2154591487', 'name': 'Ge Li'}, {'authorId': '2153578299', 'name': 'Wen Gao'}, {'authorId': '144270731', 'name': 'Haifeng Wang'}]","['Peng Cheng Laboratory', 'Baidu']",['China'],2021-12,"['industrial', 'industrial']"
2112.15283,Weichong Yin,"Han Zhang, Weichong Yin, Yewei Fang, Lanxin Li, Boqiang Duan, Zhihua
  Wu, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang",ERNIE-ViLG: Unified Generative Pre-training for Bidirectional Vision-Language Generation,"15 pages, 7 figures",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conventional methods for the image-text generation tasks mainly tackle the naturally bidirectional generation tasks separately, focusing on designing task-specific frameworks to improve the quality and fidelity of the generated samples. Recently, Vision-Language Pre-training models have greatly improved the performance of the image-to-text generation tasks, but large-scale pre-training models for text-to-image synthesis task are still under-developed. In this paper, we propose ERNIE-ViLG, a unified generative pre-training framework for bidirectional image-text generation with transformer model. Based on the image quantization models, we formulate both image generation and text generation as autoregressive generative tasks conditioned on the text/image input. The bidirectional image-text generative modeling eases the semantic alignments across vision and language. For the text-to-image generation process, we further propose an end-to-end training method to jointly learn the visual sequence generator and the image reconstructor. To explore the landscape of large-scale pre-training for bidirectional text-image generation, we train a 10-billion parameter ERNIE-ViLG model on a large-scale dataset of 145 million (Chinese) image-text pairs which achieves state-of-the-art performance for both text-to-image and image-to-text tasks, obtaining an FID of 7.9 on MS-COCO for text-to-image synthesis and best results on COCO-CN and AIC-ICC for image captioning. ","[{'version': 'v1', 'created': 'Fri, 31 Dec 2021 03:53:33 GMT'}]",2022-01-03,"[['Zhang', 'Han', ''], ['Yin', 'Weichong', ''], ['Fang', 'Yewei', ''], ['Li', 'Lanxin', ''], ['Duan', 'Boqiang', ''], ['Wu', 'Zhihua', ''], ['Sun', 'Yu', ''], ['Tian', 'Hao', ''], ['Wu', 'Hua', ''], ['Wang', 'Haifeng', '']]",0,1,2021-12-31,1,10,2,0,0,0,a02a3e4e3f8c1f185954af9b401f7100a45075a2,245634812.0,https://www.semanticscholar.org/paper/a02a3e4e3f8c1f185954af9b401f7100a45075a2,arXiv.org,2021.0,54.0,38.0,5.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48213346', 'name': 'Han Zhang'}, {'authorId': '2318321', 'name': 'Weichong Yin'}, {'authorId': '37578937', 'name': 'Yewei Fang'}, {'authorId': '2145482889', 'name': 'Lanxin Li'}, {'authorId': '2148228671', 'name': 'Boqiang Duan'}, {'authorId': '47039787', 'name': 'Zhihua Wu'}, {'authorId': '2117103617', 'name': 'Yu Sun'}, {'authorId': '50007795', 'name': 'Hao Tian'}, {'authorId': '40354707', 'name': 'Hua Wu'}, {'authorId': '144270731', 'name': 'Haifeng Wang'}]",['Baidu'],['China'],2021-12,['industrial']
2201.06642,Pedro Ortiz Suarez,"Julien Abadji, Pedro Ortiz Suarez, Laurent Romary, Beno\^it Sagot",Towards a Cleaner Document-Oriented Multilingual Crawled Corpus,"12 pages, 6 figures, 2 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The need for raw large raw corpora has dramatically increased in recent years with the introduction of transfer learning and semi-supervised learning methods to Natural Language Processing. And while there have been some recent attempts to manually curate the amount of data necessary to train large language models, the main way to obtain this data is still through automatic web crawling. In this paper we take the existing multilingual web corpus OSCAR and its pipeline Ungoliant that extracts and classifies data from Common Crawl at the line level, and propose a set of improvements and automatic annotations in order to produce a new document-oriented version of OSCAR that could prove more suitable to pre-train large generative language models as well as hopefully other applications in Natural Language Processing and Digital Humanities. ","[{'version': 'v1', 'created': 'Mon, 17 Jan 2022 22:12:59 GMT'}]",2022-01-19,"[['Abadji', 'Julien', ''], ['Suarez', 'Pedro Ortiz', ''], ['Romary', 'Laurent', ''], ['Sagot', 'Benoît', '']]",0,0,2022-01-17,1,4,1,0,0,0,645a317c9305207e95d03b5756a65e7e850f32d5,246015576.0,https://www.semanticscholar.org/paper/645a317c9305207e95d03b5756a65e7e850f32d5,International Conference on Language Resources and Evaluation,2022.0,49.0,58.0,8.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2122367898', 'name': 'Julien Abadji'}, {'authorId': '147846651', 'name': 'Pedro Ortiz Suarez'}, {'authorId': '1714893', 'name': 'Laurent Romary'}, {'authorId': '68990982', 'name': 'Benoît Sagot'}]","["", 21 rue de l' École de médecine, 75006 Paris""]",,2022-01,['industrial']
2201.07406,Stella Biderman,Stella Biderman and Edward Raff,Fooling MOSS Detection with Pretrained Language Models,"To appear in the Proceedings of the 29th ACM International Conference
  on Information & Knowledge Management (CIKM)",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  As artificial intelligence (AI) technologies become increasingly powerful and prominent in society, their misuse is a growing concern. In educational settings, AI technologies could be used by students to cheat on assignments and exams. In this paper we explore whether transformers can be used to solve introductory level programming assignments while bypassing commonly used AI tools to detect similarities between pieces of software. We find that a student using GPT-J [Wang and Komatsuzaki, 2021] can complete introductory level programming assignments without triggering suspicion from MOSS [Aiken, 2000], a widely used software similarity and plagiarism detection tool. This holds despite the fact that GPT-J was not trained on the problems in question and is not provided with any examples to work from. We further find that the code written by GPT-J is diverse in structure, lacking any particular tells that future plagiarism detection techniques may use to try to identify algorithmically generated code. We conclude with a discussion of the ethical and educational implications of large language models and directions for future research. ","[{'version': 'v1', 'created': 'Wed, 19 Jan 2022 04:00:46 GMT'}, {'version': 'v2', 'created': 'Wed, 7 Sep 2022 01:37:06 GMT'}]",2022-09-08,"[['Biderman', 'Stella', ''], ['Raff', 'Edward', '']]",0,1,2022-01-19,2,2,2,0,0,0,3d5463a16d85d9d1d0d8ebb4117a31aca3c240ff,252110940.0,https://www.semanticscholar.org/paper/3d5463a16d85d9d1d0d8ebb4117a31aca3c240ff,International Conference on Information and Knowledge Management,2022.0,69.0,14.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '103476203', 'name': 'Stella Rose Biderman'}, {'authorId': '34885007', 'name': 'Edward Raff'}]","['Booz Allen Hamilton (United States)', 'Booz Allen Foundation']",['United States'],2022-01,"['industrial', 'industrial']"
2201.08239,Romal Thoppilan,"Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv
  Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,
  YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo
  Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao
  Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao,
  Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett,
  Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel
  Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben
  Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen
  Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi
  Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron
  Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui,
  Marian Croak, Ed Chi, Quoc Le",LaMDA: Language Models for Dialog Applications,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformer-based neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model's responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency. ","[{'version': 'v1', 'created': 'Thu, 20 Jan 2022 15:44:37 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Jan 2022 19:41:03 GMT'}, {'version': 'v3', 'created': 'Thu, 10 Feb 2022 16:30:11 GMT'}]",2022-02-11,"[['Thoppilan', 'Romal', ''], ['De Freitas', 'Daniel', ''], ['Hall', 'Jamie', ''], ['Shazeer', 'Noam', ''], ['Kulshreshtha', 'Apoorv', ''], ['Cheng', 'Heng-Tze', ''], ['Jin', 'Alicia', ''], ['Bos', 'Taylor', ''], ['Baker', 'Leslie', ''], ['Du', 'Yu', ''], ['Li', 'YaGuang', ''], ['Lee', 'Hongrae', ''], ['Zheng', 'Huaixiu Steven', ''], ['Ghafouri', 'Amin', ''], ['Menegali', 'Marcelo', ''], ['Huang', 'Yanping', ''], ['Krikun', 'Maxim', ''], ['Lepikhin', 'Dmitry', ''], ['Qin', 'James', ''], ['Chen', 'Dehao', ''], ['Xu', 'Yuanzhong', ''], ['Chen', 'Zhifeng', ''], ['Roberts', 'Adam', ''], ['Bosma', 'Maarten', ''], ['Zhao', 'Vincent', ''], ['Zhou', 'Yanqi', ''], ['Chang', 'Chung-Ching', ''], ['Krivokon', 'Igor', ''], ['Rusch', 'Will', ''], ['Pickett', 'Marc', ''], ['Srinivasan', 'Pranesh', ''], ['Man', 'Laichee', ''], ['Meier-Hellstern', 'Kathleen', ''], ['Morris', 'Meredith Ringel', ''], ['Doshi', 'Tulsee', ''], ['Santos', 'Renelito Delos', ''], ['Duke', 'Toju', ''], ['Soraker', 'Johnny', ''], ['Zevenbergen', 'Ben', ''], ['Prabhakaran', 'Vinodkumar', ''], ['Diaz', 'Mark', ''], ['Hutchinson', 'Ben', ''], ['Olson', 'Kristen', ''], ['Molina', 'Alejandra', ''], ['Hoffman-John', 'Erin', ''], ['Lee', 'Josh', ''], ['Aroyo', 'Lora', ''], ['Rajakumar', 'Ravi', ''], ['Butryna', 'Alena', ''], ['Lamm', 'Matthew', ''], ['Kuzmina', 'Viktoriya', ''], ['Fenton', 'Joe', ''], ['Cohen', 'Aaron', ''], ['Bernstein', 'Rachel', ''], ['Kurzweil', 'Ray', ''], ['Aguera-Arcas', 'Blaise', ''], ['Cui', 'Claire', ''], ['Croak', 'Marian', ''], ['Chi', 'Ed', ''], ['Le', 'Quoc', '']]",0,0,2022-01-20,3,60,2,1,0,1,b3848d32f7294ec708627897833c4097eb4d8778,246063428.0,https://www.semanticscholar.org/paper/b3848d32f7294ec708627897833c4097eb4d8778,arXiv.org,2022.0,120.0,867.0,78.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '9501591', 'name': 'Romal Thoppilan'}, {'authorId': '1490889580', 'name': 'Daniel De Freitas'}, {'authorId': '2115876918', 'name': 'Jamie Hall'}, {'authorId': '1846258', 'name': 'Noam M. Shazeer'}, {'authorId': '1490888815', 'name': 'Apoorv Kulshreshtha'}, {'authorId': '2061550', 'name': 'Heng-Tze Cheng'}, {'authorId': '2150572756', 'name': 'Alicia Jin'}, {'authorId': '2150572221', 'name': 'Taylor Bos'}, {'authorId': '2150777298', 'name': 'Leslie Baker'}, {'authorId': '144708948', 'name': 'Yu Du'}, {'authorId': '1720837956', 'name': 'Yaguang Li'}, {'authorId': '8386466', 'name': 'Hongrae Lee'}, {'authorId': '2115689465', 'name': 'H. Zheng'}, {'authorId': '3010652', 'name': 'Amin Ghafouri'}, {'authorId': '2150572520', 'name': 'Marcelo Menegali'}, {'authorId': '2145438541', 'name': 'Yanping Huang'}, {'authorId': '2048712', 'name': 'M. Krikun'}, {'authorId': '150077954', 'name': 'Dmitry Lepikhin'}, {'authorId': '47901308', 'name': 'James Qin'}, {'authorId': '7167328', 'name': 'Dehao Chen'}, {'authorId': '2145139570', 'name': 'Yuanzhong Xu'}, {'authorId': '2111317372', 'name': 'Zhifeng Chen'}, {'authorId': '145625142', 'name': 'Adam Roberts'}, {'authorId': '40377863', 'name': 'Maarten Bosma'}, {'authorId': '2389316', 'name': 'Yanqi Zhou'}, {'authorId': '2152948655', 'name': 'Chung-Ching Chang'}, {'authorId': '115361655', 'name': 'I. Krivokon'}, {'authorId': '69540629', 'name': 'W. Rusch'}, {'authorId': '144851733', 'name': 'Marc Pickett'}, {'authorId': '1398655031', 'name': 'K. Meier-Hellstern'}, {'authorId': '144844426', 'name': 'M. Morris'}, {'authorId': '2155007', 'name': 'Tulsee Doshi'}, {'authorId': '2150575477', 'name': 'Renelito Delos Santos'}, {'authorId': '2145151992', 'name': 'Toju Duke'}, {'authorId': '152181934', 'name': 'J. Søraker'}, {'authorId': '70326942', 'name': 'Ben Zevenbergen'}, {'authorId': '3331141', 'name': 'Vinodkumar Prabhakaran'}, {'authorId': '2152965375', 'name': 'Mark Díaz'}, {'authorId': '2083807', 'name': 'B. Hutchinson'}, {'authorId': '2053872069', 'name': 'Kristen Olson'}, {'authorId': '145142660', 'name': 'Alejandra Molina'}, {'authorId': '1413971055', 'name': 'Erin Hoffman-John'}, {'authorId': '2108300711', 'name': 'Josh Lee'}, {'authorId': '1745337', 'name': 'Lora Aroyo'}, {'authorId': '22167999', 'name': 'Ravi Rajakumar'}, {'authorId': '1724714282', 'name': 'Alena Butryna'}, {'authorId': '48024953', 'name': 'Matthew Lamm'}, {'authorId': '104146486', 'name': 'V. Kuzmina'}, {'authorId': '2067536215', 'name': 'Joseph Fenton'}, {'authorId': '2112929869', 'name': 'Aaron Cohen'}, {'authorId': '144864136', 'name': 'R. Bernstein'}, {'authorId': '2186634', 'name': 'R. Kurzweil'}, {'authorId': '1453482151', 'name': 'Blaise Aguera-Arcas'}, {'authorId': '40498222', 'name': 'Claire Cui'}, {'authorId': '2098130534', 'name': 'M. Croak'}, {'authorId': '143829044', 'name': 'E. Chi'}, {'authorId': '1998340269', 'name': 'Quoc Le'}]",['Apoorv Kulshreshtha Heng-Tze Cheng Alicia Jin Taylor Bos Leslie Baker Yu Du YaGuang Li Hongrae Lee'],,2022-01,['industrial']
2202.03753,Hannes Hansen,"Hannes Hansen, Martin N. Hebart",Semantic features of object concepts generated with GPT-3,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Semantic features have been playing a central role in investigating the nature of our conceptual representations. Yet the enormous time and effort required to empirically sample and norm features from human raters has restricted their use to a limited set of manually curated concepts. Given recent promising developments with transformer-based language models, here we asked whether it was possible to use such models to automatically generate meaningful lists of properties for arbitrary object concepts and whether these models would produce features similar to those found in humans. To this end, we probed a GPT-3 model to generate semantic features for 1,854 objects and compared automatically-generated features to existing human feature norms. GPT-3 generated many more features than humans, yet showed a similar distribution in the types of generated features. Generated feature norms rivaled human norms in predicting similarity, relatedness, and category membership, while variance partitioning demonstrated that these predictions were driven by similar variance in humans and GPT-3. Together, these results highlight the potential of large language models to capture important facets of human knowledge and yield a new approach for automatically generating interpretable feature sets, thus drastically expanding the potential use of semantic features in psychological and linguistic studies. ","[{'version': 'v1', 'created': 'Tue, 8 Feb 2022 09:51:48 GMT'}, {'version': 'v2', 'created': 'Tue, 10 May 2022 13:30:20 GMT'}]",2022-05-11,"[['Hansen', 'Hannes', ''], ['Hebart', 'Martin N.', '']]",0,1,2022-02-08,2,2,2,1,0,1,a02aee5f1a1e5921a1e273dc25eb1ecba2f47b97,246652331.0,https://www.semanticscholar.org/paper/a02aee5f1a1e5921a1e273dc25eb1ecba2f47b97,arXiv.org,2022.0,32.0,10.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2153711516', 'name': 'Hannes J. Hansen'}, {'authorId': '1838629', 'name': 'M. Hebart'}]",['Max Planck Institute for Human Cognitive and Brain Sciences'],['Germany'],2022-02,['industrial']
2202.03799,Pierre Colombo,"Pierre Colombo and Nathan Noiry and Ekhine Irurozki and Stephan
  Clemencon",What are the best systems? New perspectives on NLP Benchmarking,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In Machine Learning, a benchmark refers to an ensemble of datasets associated with one or multiple metrics together with a way to aggregate different systems performances. They are instrumental in (i) assessing the progress of new methods along different axes and (ii) selecting the best systems for practical use. This is particularly the case for NLP with the development of large pre-trained models (e.g. GPT, BERT) that are expected to generalize well on a variety of tasks. While the community mainly focused on developing new datasets and metrics, there has been little interest in the aggregation procedure, which is often reduced to a simple average over various performance measures. However, this procedure can be problematic when the metrics are on a different scale, which may lead to spurious conclusions. This paper proposes a new procedure to rank systems based on their performance across different tasks. Motivated by the social choice theory, the final system ordering is obtained through aggregating the rankings induced by each task and is theoretically grounded. We conduct extensive numerical experiments (on over 270k scores) to assess the soundness of our approach both on synthetic and real scores (e.g. GLUE, EXTREM, SEVAL, TAC, FLICKR). In particular, we show that our method yields different conclusions on state-of-the-art systems than the mean-aggregation procedure while being both more reliable and robust. ","[{'version': 'v1', 'created': 'Tue, 8 Feb 2022 11:44:20 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Feb 2022 11:22:35 GMT'}, {'version': 'v3', 'created': 'Thu, 2 Jun 2022 14:38:46 GMT'}, {'version': 'v4', 'created': 'Fri, 7 Oct 2022 17:52:53 GMT'}]",2022-10-10,"[['Colombo', 'Pierre', ''], ['Noiry', 'Nathan', ''], ['Irurozki', 'Ekhine', ''], ['Clemencon', 'Stephan', '']]",0,1,2022-02-08,4,4,2,0,0,0,82b3a2559b5cf1528348b9d35285868e1c154fce,246652319.0,https://www.semanticscholar.org/paper/82b3a2559b5cf1528348b9d35285868e1c154fce,Neural Information Processing Systems,2022.0,120.0,18.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46985469', 'name': 'Pierre Colombo'}, {'authorId': '88972690', 'name': 'Nathan Noiry'}, {'authorId': '2217198', 'name': 'Ekhine Irurozki'}, {'authorId': '1696620', 'name': 'S. Clémençon'}]","['Télécom Paris', 'CentraleSupélec']",['France'],2022-02,"['industrial', 'industrial']"
2202.09368,Yanqi Zhou,"Yanqi Zhou and Tao Lei and Hanxiao Liu and Nan Du and Yanping Huang
  and Vincent Zhao and Andrew Dai and Zhifeng Chen and Quoc Le and James Laudon",Mixture-of-Experts with Expert Choice Routing,,,,,cs.LG cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Sparsely-activated Mixture-of-experts (MoE) models allow the number of parameters to greatly increase while keeping the amount of computation for a given token or a given sample unchanged. However, a poor expert routing strategy (e.g. one resulting in load imbalance) can cause certain experts to be under-trained, leading to an expert being under or over-specialized. Prior work allocates a fixed number of experts to each token using a top-k function regardless of the relative importance of different tokens. To address this, we propose a heterogeneous mixture-of-experts employing an expert choice method. Instead of letting tokens select the top-k experts, we have experts selecting the top-k tokens. As a result, each token can be routed to a variable number of experts and each expert can have a fixed bucket size. We systematically study pre-training speedups using the same computational resources of the Switch Transformer top-1 and GShard top-2 gating of prior work and find that our method improves training convergence time by more than 2x. For the same computational cost, our method demonstrates higher performance in fine-tuning 11 selected tasks in the GLUE and SuperGLUE benchmarks. For a smaller activation cost, our method outperforms the T5 dense model in 7 out of the 11 tasks. ","[{'version': 'v1', 'created': 'Fri, 18 Feb 2022 17:46:11 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Oct 2022 00:08:24 GMT'}]",2022-10-17,"[['Zhou', 'Yanqi', ''], ['Lei', 'Tao', ''], ['Liu', 'Hanxiao', ''], ['Du', 'Nan', ''], ['Huang', 'Yanping', ''], ['Zhao', 'Vincent', ''], ['Dai', 'Andrew', ''], ['Chen', 'Zhifeng', ''], ['Le', 'Quoc', ''], ['Laudon', 'James', '']]",0,0,2022-02-18,2,10,2,2,1,1,bbc57e1b3cf90e09b64377f13de455793bc81ad5,247011948.0,https://www.semanticscholar.org/paper/bbc57e1b3cf90e09b64377f13de455793bc81ad5,Neural Information Processing Systems,2022.0,35.0,61.0,7.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1929135', 'name': 'Yan-Quan Zhou'}, {'authorId': '2055852528', 'name': 'Tao Lei'}, {'authorId': '46935491', 'name': 'Han-Chu Liu'}, {'authorId': '2140321952', 'name': 'Nan Du'}, {'authorId': '2145438541', 'name': 'Yanping Huang'}, {'authorId': '2664737', 'name': 'Vincent Zhao'}, {'authorId': '2555924', 'name': 'Andrew M. Dai'}, {'authorId': '2111317372', 'name': 'Zhifeng Chen'}, {'authorId': '1397917613', 'name': 'Quoc V. Le'}, {'authorId': '2926266', 'name': 'J. Laudon'}]",['Google'],['United States'],2022-02,['industrial']
2202.12107,Ilya Jackson,Ilya Jackson and Maria Jesus Saenz,From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems,,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Our work is the first attempt to apply Natural Language Processing to automate the development of simulation models of systems vitally important for logistics. We demonstrated that the framework built on top of the fine-tuned GPT-3 Codex, a Transformer-based language model, could produce functionally valid simulations of queuing and inventory control systems given the verbal description. In conducted experiments, GPT-3 Codex demonstrated convincing expertise in Python as well as an understanding of the domain-specific vocabulary. As a result, the language model could produce simulations of a single-product inventory-control system and single-server queuing system given the domain-specific context, a detailed description of the process, and a list of variables with the corresponding values. The demonstrated results, along with the rapid improvement of language models, open the door for significant simplification of the workflow behind the simulation model development, which will allow experts to focus on the high-level consideration of the problem and holistic thinking. ","[{'version': 'v1', 'created': 'Thu, 24 Feb 2022 14:01:50 GMT'}, {'version': 'v2', 'created': 'Tue, 9 Aug 2022 13:59:55 GMT'}, {'version': 'v3', 'created': 'Thu, 30 Mar 2023 21:00:17 GMT'}]",2023-04-03,"[['Jackson', 'Ilya', ''], ['Saenz', 'Maria Jesus', '']]",0,1,2022-02-24,3,2,2,2,0,2,1b45949be1b203f096d6451d88cf91174c620be7,247084001.0,https://www.semanticscholar.org/paper/1b45949be1b203f096d6451d88cf91174c620be7,Social Science Research Network,2022.0,74.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145151731', 'name': 'I. Jackson'}, {'authorId': '40584295', 'name': 'M. J. Sáenz'}]","['MIT Center for Transportation and Logistics. Room E40-357, 1 Amherst St, Cambridge, MA 02139, United States', 'MIT Center for Transportation and Logistics. 1 Amherst St, Cambridge, MA 02139, United States', 'MIT Center for Transportation and Logistics. Room E40-379, 1 Amherst St, Cambridge, MA 02139, United States']",['United States'],2022-02,"['industrial', 'industrial', 'industrial']"
2203.00748,Mohammad Akbari,"Mohammad Akbari, Amin Banitalebi-Dehkordi, Yong Zhang",E-LANG: Energy-Based Joint Inferencing of Super and Swift Language Models,ACL 2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Building huge and highly capable language models has been a trend in the past years. Despite their great performance, they incur high computational cost. A common solution is to apply model compression or choose light-weight architectures, which often need a separate fixed-size model for each desirable computational budget, and may lose performance in case of heavy compression. This paper proposes an effective dynamic inference approach, called E-LANG, which distributes the inference between large accurate Super-models and light-weight Swift models. To this end, a decision making module routes the inputs to Super or Swift models based on the energy characteristics of the representations in the latent space. This method is easily adoptable and architecture agnostic. As such, it can be applied to black-box pre-trained models without a need for architectural manipulations, reassembling of modules, or re-training. Unlike existing methods that are only applicable to encoder-only backbones and classification tasks, our method also works for encoder-decoder structures and sequence-to-sequence tasks such as translation. The E-LANG performance is verified through a set of experiments with T5 and BERT backbones on GLUE, SuperGLUE, and WMT. In particular, we outperform T5-11B with an average computations speed-up of 3.3$\times$ on GLUE and 2.9$\times$ on SuperGLUE. We also achieve BERT-based SOTA on GLUE with 3.2$\times$ less computations. Code and demo are available in the supplementary materials. ","[{'version': 'v1', 'created': 'Tue, 1 Mar 2022 21:21:27 GMT'}]",2022-03-03,"[['Akbari', 'Mohammad', ''], ['Banitalebi-Dehkordi', 'Amin', ''], ['Zhang', 'Yong', '']]",0,0,2022-03-01,1,3,2,1,1,0,3a56263ab3f6301b3696631551bb2032676a2d28,247218447.0,https://www.semanticscholar.org/paper/3a56263ab3f6301b3696631551bb2032676a2d28,Annual Meeting of the Association for Computational Linguistics,2022.0,40.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143742896', 'name': 'Mohammad Akbari'}, {'authorId': '1398288379', 'name': 'Amin Banitalebi-Dehkordi'}, {'authorId': '2144289260', 'name': 'Yong Zhang'}]",['Huawei Technologies (Canada)'],['Canada'],2022-03,['industrial']
2203.11171,Xuezhi Wang,"Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan
  Narang, Aakanksha Chowdhery, Denny Zhou",Self-Consistency Improves Chain of Thought Reasoning in Language Models,"Published at ICLR 2023. V2: added PaLM results; V3: added UL2
  results; V4: camera ready version at ICLR 2023",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%). ","[{'version': 'v1', 'created': 'Mon, 21 Mar 2022 17:48:52 GMT'}, {'version': 'v2', 'created': 'Wed, 6 Apr 2022 04:40:11 GMT'}, {'version': 'v3', 'created': 'Tue, 4 Oct 2022 16:46:29 GMT'}, {'version': 'v4', 'created': 'Tue, 7 Mar 2023 17:57:37 GMT'}]",2023-03-08,"[['Wang', 'Xuezhi', ''], ['Wei', 'Jason', ''], ['Schuurmans', 'Dale', ''], ['Le', 'Quoc', ''], ['Chi', 'Ed', ''], ['Narang', 'Sharan', ''], ['Chowdhery', 'Aakanksha', ''], ['Zhou', 'Denny', '']]",0,0,2022-03-21,4,8,2,0,0,0,5f19ae1135a9500940978104ec15a5b8751bc7d2,247595263.0,https://www.semanticscholar.org/paper/5f19ae1135a9500940978104ec15a5b8751bc7d2,International Conference on Learning Representations,2022.0,80.0,786.0,123.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1524732527', 'name': 'Xuezhi Wang'}, {'authorId': '119640649', 'name': 'Jason Wei'}, {'authorId': '50319359', 'name': 'D. Schuurmans'}, {'authorId': '1998340269', 'name': 'Quoc Le'}, {'authorId': '143829044', 'name': 'E. Chi'}, {'authorId': '65855107', 'name': 'Denny Zhou'}]",['Google'],['United States'],2022-03,['industrial']
2203.13224,Kurt Shuster,"Kurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur
  Szlam, Jason Weston",Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models (LMs) have recently been shown to generate more factual responses by employing modularity (Zhou et al., 2021) in combination with retrieval (Adolphs et al., 2021). We extend the recent approach of Adolphs et al. (2021) to include internet search as a module. Our SeeKeR (Search engine->Knowledge->Response) method thus applies a single LM to three modular tasks in succession: search, generating knowledge, and generating a final response. We show that, when using SeeKeR as a dialogue model, it outperforms the state-of-the-art model BlenderBot 2 (Chen et al., 2021) on open-domain knowledge-grounded conversations for the same number of parameters, in terms of consistency, knowledge and per-turn engagingness. SeeKeR applied to topical prompt completions as a standard language model outperforms GPT2 (Radford et al., 2019) and GPT3 (Brown et al., 2020) in terms of factuality and topicality, despite GPT3 being a vastly larger model. Our code and models are made publicly available. ","[{'version': 'v1', 'created': 'Thu, 24 Mar 2022 17:31:26 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Mar 2022 18:03:46 GMT'}]",2022-03-31,"[['Shuster', 'Kurt', ''], ['Komeili', 'Mojtaba', ''], ['Adolphs', 'Leonard', ''], ['Roller', 'Stephen', ''], ['Szlam', 'Arthur', ''], ['Weston', 'Jason', '']]",0,1,2022-03-24,2,6,2,2,1,1,f8292d4ddf7a6dfe240eeaa9685f5d18eed9a3f6,247627671.0,https://www.semanticscholar.org/paper/f8292d4ddf7a6dfe240eeaa9685f5d18eed9a3f6,Conference on Empirical Methods in Natural Language Processing,2022.0,54.0,75.0,12.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35752280', 'name': 'Kurt Shuster'}, {'authorId': '100653935', 'name': 'M. Komeili'}, {'authorId': '46196592', 'name': 'Leonard Adolphs'}, {'authorId': '3849208', 'name': 'Stephen Roller'}, {'authorId': '3149531', 'name': 'Arthur Szlam'}, {'authorId': '145183709', 'name': 'J. Weston'}]","['ETH Zurich', 'Meta']","['United States', 'Switzerland', 'Israel']",2022-03,"['industrial', 'industrial']"
2203.15556,Jordan Hoffmann,"Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya,
  Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks,
  Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican,
  George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen
  Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, Laurent Sifre",Training Compute-Optimal Large Language Models,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4$\times$ more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher. ","[{'version': 'v1', 'created': 'Tue, 29 Mar 2022 13:38:03 GMT'}]",2023-01-08,"[['Hoffmann', 'Jordan', ''], ['Borgeaud', 'Sebastian', ''], ['Mensch', 'Arthur', ''], ['Buchatskaya', 'Elena', ''], ['Cai', 'Trevor', ''], ['Rutherford', 'Eliza', ''], ['Casas', 'Diego de Las', ''], ['Hendricks', 'Lisa Anne', ''], ['Welbl', 'Johannes', ''], ['Clark', 'Aidan', ''], ['Hennigan', 'Tom', ''], ['Noland', 'Eric', ''], ['Millican', 'Katie', ''], ['Driessche', 'George van den', ''], ['Damoc', 'Bogdan', ''], ['Guy', 'Aurelia', ''], ['Osindero', 'Simon', ''], ['Simonyan', 'Karen', ''], ['Elsen', 'Erich', ''], ['Rae', 'Jack W.', ''], ['Vinyals', 'Oriol', ''], ['Sifre', 'Laurent', '']]",0,1,2022-03-29,1,22,2,4,0,4,8342b592fe238f3d230e4959b06fd10153c45db1,247778764.0,https://www.semanticscholar.org/paper/8342b592fe238f3d230e4959b06fd10153c45db1,arXiv.org,2022.0,78.0,774.0,76.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46616544', 'name': 'Jordan Hoffmann'}, {'authorId': '148016269', 'name': 'Sebastian Borgeaud'}, {'authorId': '1697879', 'name': 'A. Mensch'}, {'authorId': '118801223', 'name': 'Elena Buchatskaya'}, {'authorId': '2072572294', 'name': 'Trevor Cai'}, {'authorId': '2143538252', 'name': 'Eliza Rutherford'}, {'authorId': '40550616', 'name': 'Diego de Las Casas'}, {'authorId': '2234342', 'name': 'Lisa Anne Hendricks'}, {'authorId': '1851564', 'name': 'Johannes Welbl'}, {'authorId': '31993415', 'name': 'Aidan Clark'}, {'authorId': '2146532222', 'name': 'Tom Hennigan'}, {'authorId': '51210148', 'name': 'Eric Noland'}, {'authorId': '2143434227', 'name': 'Katie Millican'}, {'authorId': '47568983', 'name': 'George van den Driessche'}, {'authorId': '2143374656', 'name': 'Bogdan Damoc'}, {'authorId': '40895205', 'name': 'Aurelia Guy'}, {'authorId': '2217144', 'name': 'Simon Osindero'}, {'authorId': '34838386', 'name': 'K. Simonyan'}, {'authorId': '152585800', 'name': 'Erich Elsen'}, {'authorId': '34269227', 'name': 'Jack W. Rae'}, {'authorId': '1689108', 'name': 'Oriol Vinyals'}, {'authorId': '2175946', 'name': 'L. Sifre'}]",['Equal contributions'],,2022-03,['industrial']
2204.00212,Takuma Udagawa,"Takuma Udagawa, Masayuki Suzuki, Gakuto Kurata, Nobuyasu Itoh, George
  Saon",Effect and Analysis of Large-scale Language Model Rescoring on Competitive ASR Systems,Accepted to Interspeech 2022,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale language models (LLMs) such as GPT-2, BERT and RoBERTa have been successfully applied to ASR N-best rescoring. However, whether or how they can benefit competitive, near state-of-the-art ASR systems remains unexplored. In this study, we incorporate LLM rescoring into one of the most competitive ASR baselines: the Conformer-Transducer model. We demonstrate that consistent improvement is achieved by the LLM's bidirectionality, pretraining, in-domain finetuning and context augmentation. Furthermore, our lexical analysis sheds light on how each of these components may be contributing to the ASR performance. ","[{'version': 'v1', 'created': 'Fri, 1 Apr 2022 05:20:55 GMT'}, {'version': 'v2', 'created': 'Thu, 18 Aug 2022 05:57:13 GMT'}]",2022-08-19,"[['Udagawa', 'Takuma', ''], ['Suzuki', 'Masayuki', ''], ['Kurata', 'Gakuto', ''], ['Itoh', 'Nobuyasu', ''], ['Saon', 'George', '']]",0,1,2022-04-01,2,5,3,1,1,0,22897f34bb9984bd06b9b1810e3d3c48fdcb30d1,247922719.0,https://www.semanticscholar.org/paper/22897f34bb9984bd06b9b1810e3d3c48fdcb30d1,Interspeech,2022.0,36.0,14.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '80927455', 'name': 'Takuma Udagawa'}, {'authorId': '2218438720', 'name': 'Masayuki Suzuki'}, {'authorId': '1787226', 'name': 'Gakuto Kurata'}, {'authorId': '3061813', 'name': 'N. Itoh'}, {'authorId': '1698208', 'name': 'G. Saon'}]","['IBM Research - Tokyo', 'IBM Research - Thomas J. Watson Research Center']","['United States', 'Japan']",2022-04,"['industrial', 'industrial']"
2204.01691,Brian Ichter,"Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes,
  Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol
  Hausman, Alex Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter,
  Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth,
  Nikhil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei
  Lee, Sergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell
  Quiambao, Kanishka Rao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet,
  Nicolas Sievers, Clayton Tan, Alexander Toshev, Vincent Vanhoucke, Fei Xia,
  Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, Andy Zeng","Do As I Can, Not As I Say: Grounding Language in Robotic Affordances","See website at https://say-can.github.io/ V1. Initial Upload. V2.
  Added PaLM results. Added study about new capabilities (drawer manipulation,
  chain of thought prompting, multilingual instructions). Added an ablation
  study of language model size. Added an open-source version of \algname on a
  simulated tabletop environment. Improved readability",,,,cs.RO cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's ""hands and eyes,"" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https://say-can.github.io/. ","[{'version': 'v1', 'created': 'Mon, 4 Apr 2022 17:57:11 GMT'}, {'version': 'v2', 'created': 'Tue, 16 Aug 2022 16:06:33 GMT'}]",2022-08-17,"[['Ahn', 'Michael', ''], ['Brohan', 'Anthony', ''], ['Brown', 'Noah', ''], ['Chebotar', 'Yevgen', ''], ['Cortes', 'Omar', ''], ['David', 'Byron', ''], ['Finn', 'Chelsea', ''], ['Fu', 'Chuyuan', ''], ['Gopalakrishnan', 'Keerthana', ''], ['Hausman', 'Karol', ''], ['Herzog', 'Alex', ''], ['Ho', 'Daniel', ''], ['Hsu', 'Jasmine', ''], ['Ibarz', 'Julian', ''], ['Ichter', 'Brian', ''], ['Irpan', 'Alex', ''], ['Jang', 'Eric', ''], ['Ruano', 'Rosario Jauregui', ''], ['Jeffrey', 'Kyle', ''], ['Jesmonth', 'Sally', ''], ['Joshi', 'Nikhil J', ''], ['Julian', 'Ryan', ''], ['Kalashnikov', 'Dmitry', ''], ['Kuang', 'Yuheng', ''], ['Lee', 'Kuang-Huei', ''], ['Levine', 'Sergey', ''], ['Lu', 'Yao', ''], ['Luu', 'Linda', ''], ['Parada', 'Carolina', ''], ['Pastor', 'Peter', ''], ['Quiambao', 'Jornell', ''], ['Rao', 'Kanishka', ''], ['Rettinghouse', 'Jarek', ''], ['Reyes', 'Diego', ''], ['Sermanet', 'Pierre', ''], ['Sievers', 'Nicolas', ''], ['Tan', 'Clayton', ''], ['Toshev', 'Alexander', ''], ['Vanhoucke', 'Vincent', ''], ['Xia', 'Fei', ''], ['Xiao', 'Ted', ''], ['Xu', 'Peng', ''], ['Xu', 'Sichun', ''], ['Yan', 'Mengyuan', ''], ['Zeng', 'Andy', '']]",0,0,2022-04-04,2,45,3,0,0,0,cb5e3f085caefd1f3d5e08637ab55d39e61234fc,247939706.0,https://www.semanticscholar.org/paper/cb5e3f085caefd1f3d5e08637ab55d39e61234fc,Conference on Robot Learning,2022.0,114.0,642.0,63.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","[{'authorId': '2106194123', 'name': 'Michael Ahn'}, {'authorId': '118025075', 'name': 'Anthony Brohan'}, {'authorId': '2161343011', 'name': 'Noah Brown'}, {'authorId': '2527420', 'name': 'Yevgen Chebotar'}, {'authorId': '2161341260', 'name': 'Omar Cortes'}, {'authorId': '2131683144', 'name': 'Byron David'}, {'authorId': '46881670', 'name': 'Chelsea Finn'}, {'authorId': '2161342233', 'name': 'K. Gopalakrishnan'}, {'authorId': '1944801', 'name': 'Karol Hausman'}, {'authorId': '1505793452', 'name': 'Alexander Herzog'}, {'authorId': '2056459339', 'name': 'Daniel Ho'}, {'authorId': '2726592', 'name': 'Jasmine Hsu'}, {'authorId': '46920727', 'name': 'Julian Ibarz'}, {'authorId': '2704814', 'name': 'Brian Ichter'}, {'authorId': '17818078', 'name': 'A. Irpan'}, {'authorId': '145116380', 'name': 'Eric Jang'}, {'authorId': '2161341254', 'name': 'Rosario Jauregui Ruano'}, {'authorId': '2161341110', 'name': 'Kyle Jeffrey'}, {'authorId': '2161341920', 'name': 'Sally Jesmonth'}, {'authorId': '2641664', 'name': 'N. Joshi'}, {'authorId': '144885996', 'name': 'Ryan C. Julian'}, {'authorId': '48313860', 'name': 'Dmitry Kalashnikov'}, {'authorId': '2161342687', 'name': 'Yuheng Kuang'}, {'authorId': '2145145412', 'name': 'Kuang-Huei Lee'}, {'authorId': '1736651', 'name': 'S. Levine'}, {'authorId': '2161346119', 'name': 'Yao Lu'}, {'authorId': '13219952', 'name': 'Linda Luu'}, {'authorId': '2057314286', 'name': 'Carolina Parada'}, {'authorId': '143970835', 'name': 'P. Pastor'}, {'authorId': '2161342191', 'name': 'Jornell Quiambao'}, {'authorId': '2251957', 'name': 'Kanishka Rao'}, {'authorId': '2161341616', 'name': 'Jarek Rettinghouse'}, {'authorId': '48674590', 'name': 'D. Reyes'}, {'authorId': '3142556', 'name': 'P. Sermanet'}, {'authorId': '2153300433', 'name': 'Nicolas Sievers'}, {'authorId': '2161386250', 'name': 'Clayton Tan'}, {'authorId': '1726415', 'name': 'Alexander Toshev'}, {'authorId': '2657155', 'name': 'Vincent Vanhoucke'}, {'authorId': '144956443', 'name': 'F. Xia'}, {'authorId': '9961095', 'name': 'Ted Xiao'}, {'authorId': '2153917744', 'name': 'Peng Xu'}, {'authorId': '3068504', 'name': 'Sichun Xu'}, {'authorId': '3235234', 'name': 'Mengyuan Yan'}]",['Google'],['United States'],2022-04,['industrial']
2204.03542,Patrizio Bellan,"Patrizio Bellan, Mauro Dragoni and Chiara Ghidini",Leveraging pre-trained language models for conversational information seeking from text,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recent advances in Natural Language Processing, and in particular on the construction of very large pre-trained language representation models, is opening up new perspectives on the construction of conversational information seeking (CIS) systems. In this paper we investigate the usage of in-context learning and pre-trained language representation models to address the problem of information extraction from process description documents, in an incremental question and answering oriented fashion. In particular we investigate the usage of the native GPT-3 (Generative Pre-trained Transformer 3) model, together with two in-context learning customizations that inject conceptual definitions and a limited number of samples in a few shot-learning fashion. The results highlight the potential of the approach and the usefulness of the in-context learning customizations, which can substantially contribute to address the ""training data challenge"" of deep learning based NLP techniques the BPM field. It also highlight the challenge posed by control flow relations for which further training needs to be devised. ","[{'version': 'v1', 'created': 'Thu, 31 Mar 2022 09:00:46 GMT'}]",2022-04-08,"[['Bellan', 'Patrizio', ''], ['Dragoni', 'Mauro', ''], ['Ghidini', 'Chiara', '']]",0,1,2022-03-31,1,3,2,1,0,1,4b0e6b4b451ddc7e6b1bbb480e206c18f498ee82,248006156.0,https://www.semanticscholar.org/paper/4b0e6b4b451ddc7e6b1bbb480e206c18f498ee82,arXiv.org,2022.0,30.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51891870', 'name': 'Patrizio Bellan'}, {'authorId': '2346796', 'name': 'M. Dragoni'}, {'authorId': '1704711', 'name': 'Chiara Ghidini'}]",['Fondazione Bruno Kessler'],['Italy'],2022-03,['industrial']
2204.04892,Kyushik Min,"Kyushik Min, Hyunho Lee, Kwansu Shin, Taehak Lee, Hojoon Lee, Jinwon
  Choi, Sungho Son",JORLDY: a fully customizable open source framework for reinforcement learning,"12 pages, 6 figures",,,,cs.LG cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Recently, Reinforcement Learning (RL) has been actively researched in both academic and industrial fields. However, there exist only a few RL frameworks which are developed for researchers or students who want to study RL. In response, we propose an open-source RL framework ""Join Our Reinforcement Learning framework for Developing Yours"" (JORLDY). JORLDY provides more than 20 widely used RL algorithms which are implemented with Pytorch. Also, JORLDY supports multiple RL environments which include OpenAI gym, Unity ML-Agents, Mujoco, Super Mario Bros and Procgen. Moreover, the algorithmic components such as agent, network, environment can be freely customized, so that the users can easily modify and append algorithmic components. We expect that JORLDY will support various RL research and contribute further advance the field of RL. The source code of JORLDY is provided on the following Github: https://github.com/kakaoenterprise/JORLDY ","[{'version': 'v1', 'created': 'Mon, 11 Apr 2022 06:28:27 GMT'}]",2022-04-12,"[['Min', 'Kyushik', ''], ['Lee', 'Hyunho', ''], ['Shin', 'Kwansu', ''], ['Lee', 'Taehak', ''], ['Lee', 'Hojoon', ''], ['Choi', 'Jinwon', ''], ['Son', 'Sungho', '']]",0,0,2022-04-11,1,7,2,0,0,0,bcd03da5babc0aac9b8b10d8819dc30078021c1c,248085875.0,https://www.semanticscholar.org/paper/bcd03da5babc0aac9b8b10d8819dc30078021c1c,arXiv.org,2022.0,42.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51478767', 'name': 'Kyushik Min'}, {'authorId': '2162205515', 'name': 'Hyunho Lee'}, {'authorId': '2162047543', 'name': 'Kwansu Shin'}, {'authorId': '2152474995', 'name': 'Tae-woo Lee'}, {'authorId': '2163406260', 'name': 'Hojoon Lee'}, {'authorId': '2162090891', 'name': 'Jinwon Choi'}, {'authorId': '2891663', 'name': 'Sung-Hyun Son'}]","['Kakao Enterprise Seongnam, South Korea']",,2022-04,['industrial']
2204.05356,Ehsan Hosseini-Asl,"Ehsan Hosseini-Asl, Wenhao Liu, Caiming Xiong",A Generative Language Model for Few-shot Aspect-Based Sentiment Analysis,Accepted to Findings of NAACL 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sentiment analysis is an important task in natural language processing. In recent works, pre-trained language models are often used to achieve state-of-the-art results, especially when training data is scarce. It is common to fine-tune on the downstream task, usually by adding task-specific layers on top of the model. In this paper, we focus on aspect-based sentiment analysis, which involves extracting aspect term, category, and predicting their corresponding polarities. In particular, we are interested in few-shot settings. We propose to reformulate the extraction and prediction tasks into the sequence generation task, using a generative language model with unidirectional attention (GPT2 is used unless stated otherwise). This way, the model learns to accomplish the tasks via language generation without the need of training task-specific layers. Our evaluation results on the single-task polarity prediction show that our approach outperforms the previous state-of-the-art (based on BERT) on average performance by a large margins in few-shot and full-shot settings. More importantly, our generative approach significantly reduces the model variance caused by low-resource data. We further demonstrate that the proposed generative language model can handle joint and multi-task settings, unlike previous work. We observe that the proposed sequence generation method achieves further improved performances on polarity prediction when the model is trained via joint and multi-task settings. Further evaluation on similar sentiment analysis datasets, SST-2, SST- and OOS intent detection validates the superiority and noise robustness of generative language model in few-shot settings. ","[{'version': 'v1', 'created': 'Mon, 11 Apr 2022 18:31:53 GMT'}]",2022-04-13,"[['Hosseini-Asl', 'Ehsan', ''], ['Liu', 'Wenhao', ''], ['Xiong', 'Caiming', '']]",0,1,2022-04-11,1,3,1,1,1,0,9684827f01aa5e61f599c8f7f65927c7486a8675,248119039.0,https://www.semanticscholar.org/paper/9684827f01aa5e61f599c8f7f65927c7486a8675,NAACL-HLT,2022.0,39.0,14.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1401953786', 'name': 'Ehsan Hosseini-Asl'}, {'authorId': '120639804', 'name': 'Wenhao Liu'}, {'authorId': '2054594326', 'name': 'Caiming Xiong'}]",['Salesforce AI Research'],,2022-04,['industrial']
2204.06745,Stella Biderman,"Sid Black and Stella Biderman and Eric Hallahan and Quentin Anthony
  and Leo Gao and Laurence Golding and Horace He and Connor Leahy and Kyle
  McDonell and Jason Phang and Michael Pieler and USVSN Sai Prashanth and
  Shivanshu Purohit and Laria Reynolds and Jonathan Tow and Ben Wang and Samuel
  Weinbach",GPT-NeoX-20B: An Open-Source Autoregressive Language Model,"To appear in the Proceedings of the ACL Workshop on Challenges &
  Perspectives in Creating Large Language Models",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We introduce GPT-NeoX-20B, a 20 billion parameter autoregressive language model trained on the Pile, whose weights will be made freely and openly available to the public through a permissive license. It is, to the best of our knowledge, the largest dense autoregressive model that has publicly available weights at the time of submission. In this work, we describe \model{}'s architecture and training and evaluate its performance on a range of language-understanding, mathematics, and knowledge-based tasks. We find that GPT-NeoX-20B is a particularly powerful few-shot reasoner and gains far more in performance when evaluated five-shot than similarly sized GPT-3 and FairSeq models. We open-source the training and evaluation code, as well as the model weights, at https://github.com/EleutherAI/gpt-neox. ","[{'version': 'v1', 'created': 'Thu, 14 Apr 2022 04:00:27 GMT'}]",2022-04-15,"[['Black', 'Sid', ''], ['Biderman', 'Stella', ''], ['Hallahan', 'Eric', ''], ['Anthony', 'Quentin', ''], ['Gao', 'Leo', ''], ['Golding', 'Laurence', ''], ['He', 'Horace', ''], ['Leahy', 'Connor', ''], ['McDonell', 'Kyle', ''], ['Phang', 'Jason', ''], ['Pieler', 'Michael', ''], ['Prashanth', 'USVSN Sai', ''], ['Purohit', 'Shivanshu', ''], ['Reynolds', 'Laria', ''], ['Tow', 'Jonathan', ''], ['Wang', 'Ben', ''], ['Weinbach', 'Samuel', '']]",0,1,2022-04-14,1,17,1,2,1,1,e37018d3cfab9cfc29a7b78404e6c86ea18a907e,248177957.0,https://www.semanticscholar.org/paper/e37018d3cfab9cfc29a7b78404e6c86ea18a907e,BIGSCIENCE,2022.0,142.0,358.0,38.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2044098905', 'name': 'Sid Black'}, {'authorId': '103476203', 'name': 'Stella Rose Biderman'}, {'authorId': '2162462983', 'name': 'Eric Hallahan'}, {'authorId': '1404060481', 'name': 'Quentin G. Anthony'}, {'authorId': '2027599537', 'name': 'Leo Gao'}, {'authorId': '2044198157', 'name': 'Laurence Golding'}, {'authorId': '46350295', 'name': 'Horace He'}, {'authorId': '2044198134', 'name': 'Connor Leahy'}, {'authorId': '2049410219', 'name': 'Kyle McDonell'}, {'authorId': '80842917', 'name': 'Jason Phang'}, {'authorId': '15043672', 'name': 'M. Pieler'}, {'authorId': '2162462141', 'name': 'USVSN Sai Prashanth'}, {'authorId': '2162467233', 'name': 'Shivanshu Purohit'}, {'authorId': '2049583158', 'name': 'Laria Reynolds'}, {'authorId': '50195579', 'name': 'J. Tow'}, {'authorId': '2167077094', 'name': 'Benqi Wang'}, {'authorId': '2024731554', 'name': 'Samuel Weinbach'}]",['USVSN Sai Prashanth Shivanshu Purohit Laria Reynolds Jonathan Tow Ben Wang Samuel Weinbach'],,2022-04,['industrial']
2204.08405,Sharath Srivatsa,"Sharath Srivatsa, Tushar Mohan, Kumari Neha, Nishchay Malakar,
  Ponnurangam Kumaraguru, and Srinath Srinivasa",Zero-shot Entity and Tweet Characterization with Designed Conditional Prompts and Contexts,,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Online news and social media have been the de facto mediums to disseminate information globally from the beginning of the last decade. However, bias in content and purpose of intentions are not regulated, and managing bias is the responsibility of content consumers. In this regard, understanding the stances and biases of news sources towards specific entities becomes important. To address this problem, we use pretrained language models, which have been shown to bring about good results with no task-specific training or few-shot training. In this work, we approach the problem of characterizing Named Entities and Tweets as an open-ended text classification and open-ended fact probing problem.We evaluate the zero-shot language model capabilities of Generative Pretrained Transformer 2 (GPT-2) to characterize Entities and Tweets subjectively with human psychology-inspired and logical conditional prefixes and contexts. First, we fine-tune the GPT-2 model on a sufficiently large news corpus and evaluate subjective characterization of popular entities in the corpus by priming with prefixes. Second, we fine-tune GPT-2 with a Tweets corpus from a few popular hashtags and evaluate characterizing tweets by priming the language model with prefixes, questions, and contextual synopsis prompts. Entity characterization results were positive across measures and human evaluation. ","[{'version': 'v1', 'created': 'Mon, 18 Apr 2022 17:01:49 GMT'}]",2022-04-19,"[['Srivatsa', 'Sharath', ''], ['Mohan', 'Tushar', ''], ['Neha', 'Kumari', ''], ['Malakar', 'Nishchay', ''], ['Kumaraguru', 'Ponnurangam', ''], ['Srinivasa', 'Srinath', '']]",0,1,2022-04-18,1,6,2,1,1,0,b758359af8c509cf99cc5c0f9b4293e200903880,248227869.0,https://www.semanticscholar.org/paper/b758359af8c509cf99cc5c0f9b4293e200903880,arXiv.org,2022.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1870621', 'name': 'S. Srivatsa'}, {'authorId': '145562743', 'name': 'T. Mohan'}, {'authorId': '144244906', 'name': 'Kumari Neha'}, {'authorId': '2162781630', 'name': 'Nishchay Malakar'}, {'authorId': '1734731', 'name': 'P. Kumaraguru'}, {'authorId': '144427922', 'name': 'S. Srinivasa'}]","['International Institute of Information Technology, Hyderabad', 'Indraprastha Institute of Information Technology Delhi', 'International Institute of Information Technology Bangalore', 'International Institute of Information Technology']",['India'],2022-04,"['industrial', 'industrial', 'industrial', 'industrial']"
2204.08832,Cagri Toraman,"Cagri Toraman, Eyup Halit Yilmaz, Furkan \c{S}ahinu\c{c}, Oguzhan
  Ozcelik",Impact of Tokenization on Language Models: An Analysis for Turkish,submitted to ACM TALLIP,"ACM Transactions on Asian and Low-Resource Language Information
  Processing (2023) Volume 22 Issue 4 pp 1-21",10.1145/3578707,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Tokenization is an important text preprocessing step to prepare input tokens for deep language models. WordPiece and BPE are de facto methods employed by important models, such as BERT and GPT. However, the impact of tokenization can be different for morphologically rich languages, such as Turkic languages, where many words can be generated by adding prefixes and suffixes. We compare five tokenizers at different granularity levels, i.e. their outputs vary from smallest pieces of characters to the surface form of words, including a Morphological-level tokenizer. We train these tokenizers and pretrain medium-sized language models using RoBERTa pretraining procedure on the Turkish split of the OSCAR corpus. We then fine-tune our models on six downstream tasks. Our experiments, supported by statistical tests, reveal that Morphological-level tokenizer has challenging performance with de facto tokenizers. Furthermore, we find that increasing the vocabulary size improves the performance of Morphological and Word-level tokenizers more than that of de facto tokenizers. The ratio of the number of vocabulary parameters to the total number of model parameters can be empirically chosen as 20% for de facto tokenizers and 40% for other tokenizers to obtain a reasonable trade-off between model size and performance. ","[{'version': 'v1', 'created': 'Tue, 19 Apr 2022 12:01:46 GMT'}]",2023-03-28,"[['Toraman', 'Cagri', ''], ['Yilmaz', 'Eyup Halit', ''], ['Şahinuç', 'Furkan', ''], ['Ozcelik', 'Oguzhan', '']]",0,1,2022-04-19,1,4,1,0,0,0,0de580957d23dd65e31b6c95e6bc5d15bc15c57d,248240018.0,https://www.semanticscholar.org/paper/0de580957d23dd65e31b6c95e6bc5d15bc15c57d,ACM Trans. Asian Low Resour. Lang. Inf. Process.,2022.0,68.0,19.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2648640', 'name': 'Cagri Toraman'}, {'authorId': '1830448719', 'name': 'E. Yilmaz'}, {'authorId': '107973475', 'name': 'Furkan Şahinuç'}, {'authorId': '2162838582', 'name': 'Oguzhan Ozcelik'}]","['Aselsan Research Center, Turkey', 'Aselsan Research Center, Ankara, Turkey']",['Turkey'],2022-04,"['industrial', 'industrial']"
2204.12951,Abed Asi,"Abedelkadir Asi, Song Wang, Roy Eisenstadt, Dean Geckt, Yarin Kuper,
  Yi Mao, Royi Ronen",An End-to-End Dialogue Summarization System for Sales Calls,To be published in NAACL 2022,,,,cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Summarizing sales calls is a routine task performed manually by salespeople. We present a production system which combines generative models fine-tuned for customer-agent setting, with a human-in-the-loop user experience for an interactive summary curation process. We address challenging aspects of dialogue summarization task in a real-world setting including long input dialogues, content validation, lack of labeled data and quality evaluation. We show how GPT-3 can be leveraged as an offline data labeler to handle training data scarcity and accommodate privacy constraints in an industrial setting. Experiments show significant improvements by our models in tackling the summarization and content validation tasks on public datasets. ","[{'version': 'v1', 'created': 'Wed, 27 Apr 2022 14:02:50 GMT'}, {'version': 'v2', 'created': 'Thu, 28 Apr 2022 13:59:48 GMT'}]",2022-04-29,"[['Asi', 'Abedelkadir', ''], ['Wang', 'Song', ''], ['Eisenstadt', 'Roy', ''], ['Geckt', 'Dean', ''], ['Kuper', 'Yarin', ''], ['Mao', 'Yi', ''], ['Ronen', 'Royi', '']]",0,1,2022-04-27,2,7,2,1,0,1,6d2feef6d8c3ccc34d982e4db43f96efba5d7c64,248406121.0,https://www.semanticscholar.org/paper/6d2feef6d8c3ccc34d982e4db43f96efba5d7c64,North American Chapter of the Association for Computational Linguistics,2022.0,48.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145766704', 'name': 'Abedelkadir Asi'}, {'authorId': '2117074851', 'name': 'Song Wang'}, {'authorId': '2121374479', 'name': 'Roy Eisenstadt'}, {'authorId': '2163587488', 'name': 'Dean Geckt'}, {'authorId': '2163587192', 'name': 'Yarin Kuper'}, {'authorId': '145469202', 'name': 'Yi Mao'}, {'authorId': '2445296', 'name': 'Royi Ronen'}]",['Microsoft'],['United States'],2022-04,['industrial']
2205.07592,Nicola Milano,Nicola Milano and Stefano Nolfi,Qualitative Differences Between Evolutionary Strategies and Reinforcement Learning Methods for Control of Autonomous Agents,,,,,cs.AI cs.LG cs.NE,http://creativecommons.org/licenses/by/4.0/,"  In this paper we analyze the qualitative differences between evolutionary strategies and reinforcement learning algorithms by focusing on two popular state-of-the-art algorithms: the OpenAI-ES evolutionary strategy and the Proximal Policy Optimization (PPO) reinforcement learning algorithm -- the most similar methods of the two families. We analyze how the methods differ with respect to: (i) general efficacy, (ii) ability to cope with sparse rewards, (iii) propensity/capacity to discover minimal solutions, (iv) dependency on reward shaping, and (v) ability to cope with variations of the environmental conditions. The analysis of the performance and of the behavioral strategies displayed by the agents trained with the two methods on benchmark problems enable us to demonstrate qualitative differences which were not identified in previous studies, to identify the relative weakness of the two methods, and to propose ways to ameliorate some of those weakness. We show that the characteristics of the reward function has a strong impact which vary qualitatively not only for the OpenAI-ES and the PPO but also for alternative reinforcement learning algorithms, thus demonstrating the importance of optimizing the characteristic of the reward function to the algorithm used. ","[{'version': 'v1', 'created': 'Mon, 16 May 2022 11:51:36 GMT'}]",2022-05-17,"[['Milano', 'Nicola', ''], ['Nolfi', 'Stefano', '']]",0,0,2022-05-16,1,2,3,0,0,0,068fe983f0e2c8f0430d05c6130ea270336a8ad4,248811016.0,https://www.semanticscholar.org/paper/068fe983f0e2c8f0430d05c6130ea270336a8ad4,Evolutionary Intelligence,2022.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32302973', 'name': 'Nicola Milano'}, {'authorId': '3015062', 'name': 'S. Nolfi'}]",['National Research Council'],['Italy'],2022-05,['industrial']
2205.08808,Piotr Rybak,"Aleksandra Chrabrowa, {\L}ukasz Dragan, Karol Grzegorczyk, Dariusz
  Kajtoch, Miko{\l}aj Koszowski, Robert Mroczkowski, Piotr Rybak",Evaluation of Transfer Learning for Polish with a Text-to-Text Model,Accepted at LREC 2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a new benchmark for assessing the quality of text-to-text models for Polish. The benchmark consists of diverse tasks and datasets: KLEJ benchmark adapted for text-to-text, en-pl translation, summarization, and question answering. In particular, since summarization and question answering lack benchmark datasets for the Polish language, we describe their construction and make them publicly available. Additionally, we present plT5 - a general-purpose text-to-text model for Polish that can be fine-tuned on various Natural Language Processing (NLP) tasks with a single training objective. Unsupervised denoising pre-training is performed efficiently by initializing the model weights with a multi-lingual T5 (mT5) counterpart. We evaluate the performance of plT5, mT5, Polish BART (plBART), and Polish GPT-2 (papuGaPT2). The plT5 scores top on all of these tasks except summarization, where plBART is best. In general (except for summarization), the larger the model, the better the results. The encoder-decoder architectures prove to be better than the decoder-only equivalent. ","[{'version': 'v1', 'created': 'Wed, 18 May 2022 09:17:14 GMT'}]",2022-05-19,"[['Chrabrowa', 'Aleksandra', ''], ['Dragan', 'Łukasz', ''], ['Grzegorczyk', 'Karol', ''], ['Kajtoch', 'Dariusz', ''], ['Koszowski', 'Mikołaj', ''], ['Mroczkowski', 'Robert', ''], ['Rybak', 'Piotr', '']]",0,1,2022-05-18,1,7,2,3,3,0,267dcb61f72f48dadd60a3a770493c0c9f70be65,248863247.0,https://www.semanticscholar.org/paper/267dcb61f72f48dadd60a3a770493c0c9f70be65,International Conference on Language Resources and Evaluation,2022.0,45.0,11.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8769976', 'name': 'Aleksandra Chrabrowa'}, {'authorId': '2165569779', 'name': 'Lukasz Dragan'}, {'authorId': '2473173', 'name': 'Karol Grzegorczyk'}, {'authorId': '102712558', 'name': 'D. Kajtoch'}, {'authorId': '2040902194', 'name': 'Mikołaj Koszowski'}, {'authorId': '1667962595', 'name': 'Robert Mroczkowski'}, {'authorId': '52078780', 'name': 'Piotr Rybak'}]","['Allegro ML Research at Allegro.pl, ul. Grunwaldzka 182, 60-166 Poznań, Poland']",['Poland'],2022-05,['industrial']
2205.10183,Li Dong,"Zhixiong Han, Yaru Hao, Li Dong, Yutao Sun, Furu Wei",Prototypical Calibration for Few-shot Learning of Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In-context learning of GPT-like models has been recognized as fragile across different hand-crafted templates, and demonstration permutations. In this work, we propose prototypical calibration to adaptively learn a more robust decision boundary for zero- and few-shot classification, instead of greedy decoding. Concretely, our method first adopts Gaussian mixture distribution to estimate the prototypical clusters for all categories. Then we assign each cluster to the corresponding label by solving a weighted bipartite matching problem. Given an example, its prediction is calibrated by the likelihood of prototypical clusters. Experimental results show that prototypical calibration yields a substantial improvement on a diverse set of tasks. Extensive analysis across different scales also indicates that our method calibrates the decision boundary as expected, greatly improving the robustness of GPT to templates, permutations, and class imbalance. ","[{'version': 'v1', 'created': 'Fri, 20 May 2022 13:50:07 GMT'}, {'version': 'v2', 'created': 'Wed, 5 Oct 2022 01:33:07 GMT'}]",2022-10-06,"[['Han', 'Zhixiong', ''], ['Hao', 'Yaru', ''], ['Dong', 'Li', ''], ['Sun', 'Yutao', ''], ['Wei', 'Furu', '']]",0,1,2022-05-20,2,5,1,0,0,0,6a483cd1cbecd66150c9bbcd01606723950281bc,248964978.0,https://www.semanticscholar.org/paper/6a483cd1cbecd66150c9bbcd01606723950281bc,International Conference on Learning Representations,2022.0,31.0,18.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2835766', 'name': 'Zhixiong Han'}, {'authorId': '34128716', 'name': 'Y. Hao'}, {'authorId': '145307652', 'name': 'Li Dong'}, {'authorId': '2108540694', 'name': 'Yutao Sun'}, {'authorId': '49807919', 'name': 'Furu Wei'}]",['Microsoft'],"['China', 'India']",2022-05,['industrial']
2205.10625,Denny Zhou,"Denny Zhou, Nathanael Sch\""arli, Le Hou, Jason Wei, Nathan Scales,
  Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, Ed Chi",Least-to-Most Prompting Enables Complex Reasoning in Large Language Models,ICLR 2023,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99% using just 14 exemplars, compared to only 16% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix. ","[{'version': 'v1', 'created': 'Sat, 21 May 2022 15:34:53 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Oct 2022 14:49:26 GMT'}, {'version': 'v3', 'created': 'Sun, 16 Apr 2023 22:08:08 GMT'}]",2023-04-18,"[['Zhou', 'Denny', ''], ['Schärli', 'Nathanael', ''], ['Hou', 'Le', ''], ['Wei', 'Jason', ''], ['Scales', 'Nathan', ''], ['Wang', 'Xuezhi', ''], ['Schuurmans', 'Dale', ''], ['Cui', 'Claire', ''], ['Bousquet', 'Olivier', ''], ['Le', 'Quoc', ''], ['Chi', 'Ed', '']]",0,1,2022-05-21,3,11,2,1,0,1,5437e8adab596d7294124c0e798708e050e25321,248986239.0,https://www.semanticscholar.org/paper/5437e8adab596d7294124c0e798708e050e25321,International Conference on Learning Representations,2022.0,73.0,412.0,35.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '65855107', 'name': 'Denny Zhou'}, {'authorId': '1821614764', 'name': 'Nathanael Scharli'}, {'authorId': '2153400663', 'name': 'Le Hou'}, {'authorId': '119640649', 'name': 'Jason Wei'}, {'authorId': '1471909492', 'name': 'Nathan Scales'}, {'authorId': '1524732527', 'name': 'Xuezhi Wang'}, {'authorId': '50319359', 'name': 'D. Schuurmans'}, {'authorId': '1698617', 'name': 'O. Bousquet'}, {'authorId': '1998340269', 'name': 'Quoc Le'}, {'authorId': '143829044', 'name': 'E. Chi'}]",['Google'],['United States'],2022-05,['industrial']
2205.11005,Yuchao Li,"Yuchao Li, Fuli Luo, Chuanqi Tan, Mengdi Wang, Songfang Huang, Shen
  Li, Junjie Bai",Parameter-Efficient Sparsity for Large Language Models Fine-Tuning,This paper is published in IJCAI 2022,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  With the dramatically increased number of parameters in language models, sparsity methods have received ever-increasing research focus to compress and accelerate the models. While most research focuses on how to accurately retain appropriate weights while maintaining the performance of the compressed model, there are challenges in the computational overhead and memory footprint of sparse training when compressing large-scale language models. To address this problem, we propose a Parameter-efficient Sparse Training (PST) method to reduce the number of trainable parameters during sparse-aware training in downstream tasks. Specifically, we first combine the data-free and data-driven criteria to efficiently and accurately measure the importance of weights. Then we investigate the intrinsic redundancy of data-driven weight importance and derive two obvious characteristics i.e., low-rankness and structuredness. Based on that, two groups of small matrices are introduced to compute the data-driven importance of weights, instead of using the original large importance score matrix, which therefore makes the sparse training resource-efficient and parameter-efficient. Experiments with diverse networks (i.e., BERT, RoBERTa and GPT-2) on dozens of datasets demonstrate PST performs on par or better than previous sparsity methods, despite only training a small number of parameters. For instance, compared with previous sparsity methods, our PST only requires 1.5% trainable parameters to achieve comparable performance on BERT. ","[{'version': 'v1', 'created': 'Mon, 23 May 2022 02:43:45 GMT'}]",2022-05-24,"[['Li', 'Yuchao', ''], ['Luo', 'Fuli', ''], ['Tan', 'Chuanqi', ''], ['Wang', 'Mengdi', ''], ['Huang', 'Songfang', ''], ['Li', 'Shen', ''], ['Bai', 'Junjie', '']]",0,1,2022-05-23,1,7,1,1,1,0,03d19fde1df67c7ea8dedc750dcd3a6291032577,248986195.0,https://www.semanticscholar.org/paper/03d19fde1df67c7ea8dedc750dcd3a6291032577,International Joint Conference on Artificial Intelligence,2022.0,27.0,7.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2110482496', 'name': 'Yuchao Li'}, {'authorId': '2140495101', 'name': 'Fuli Luo'}, {'authorId': '2111727840', 'name': 'Chuanqi Tan'}, {'authorId': '50468734', 'name': 'Mengdi Wang'}, {'authorId': '2410938', 'name': 'Songfang Huang'}, {'authorId': '2153701890', 'name': 'Shen Li'}, {'authorId': '2113829116', 'name': 'Junjie Bai'}]",['Alibaba'],['China'],2022-05,['industrial']
2205.12368,Jingqing Zhang,"Heng-Yi Wu, Jingqing Zhang, Julia Ive, Tong Li, Vibhor Gupta, Bingyuan
  Chen, Yike Guo",Medical Scientific Table-to-Text Generation with Human-in-the-Loop under the Data Sparsity Constraint,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Structured (tabular) data in the preclinical and clinical domains contains valuable information about individuals and an efficient table-to-text summarization system can drastically reduce manual efforts to condense this data into reports. However, in practice, the problem is heavily impeded by the data paucity, data sparsity and inability of the state-of-the-art natural language generation models (including T5, PEGASUS and GPT-Neo) to produce accurate and reliable outputs. In this paper, we propose a novel table-to-text approach and tackle these problems with a novel two-step architecture which is enhanced by auto-correction, copy mechanism and synthetic data augmentation. The study shows that the proposed approach selects salient biomedical entities and values from structured data with improved precision (up to 0.13 absolute increase) of copying the tabular values to generate coherent and accurate text for assay validation reports and toxicology reports. Moreover, we also demonstrate a light-weight adaptation of the proposed system to new datasets by fine-tuning with as little as 40\% training examples. The outputs of our model are validated by human experts in the Human-in-the-Loop scenario. ","[{'version': 'v1', 'created': 'Tue, 24 May 2022 21:10:57 GMT'}, {'version': 'v2', 'created': 'Wed, 13 Jul 2022 19:34:55 GMT'}]",2022-07-15,"[['Wu', 'Heng-Yi', ''], ['Zhang', 'Jingqing', ''], ['Ive', 'Julia', ''], ['Li', 'Tong', ''], ['Gupta', 'Vibhor', ''], ['Chen', 'Bingyuan', ''], ['Guo', 'Yike', '']]",0,1,2022-05-24,2,7,1,1,1,0,03e7ddee912013e8e55eda92219d517b2bb51cec,249062890.0,https://www.semanticscholar.org/paper/03e7ddee912013e8e55eda92219d517b2bb51cec,arXiv.org,2022.0,28.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '7264080', 'name': 'Heng-Yi Wu'}, {'authorId': '47540100', 'name': 'Jingqing Zhang'}, {'authorId': '3456894', 'name': 'Julia Ive'}, {'authorId': '29855912', 'name': 'T. Li'}, {'authorId': '46241251', 'name': 'N. Tabari'}, {'authorId': '2146713213', 'name': 'Bingyuan Chen'}, {'authorId': '2110652718', 'name': 'Vibhor Gupta'}, {'authorId': '2118269437', 'name': 'Yike Guo'}]","['Pangaea Data Limited, UK, USA', 'Development Science Informatics, Genentech Inc, USA']",['United States'],2022-05,"['industrial', 'industrial']"
2205.12586,Rebecca Qian,"Rebecca Qian, Candace Ross, Jude Fernandes, Eric Smith, Douwe Kiela,
  Adina Williams",Perturbation Augmentation for Fairer NLP,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets. In this work, we ask whether training on demographically perturbed data leads to fairer language models. We collect a large dataset of human annotated text perturbations and train a neural perturbation model, which we show outperforms heuristic alternatives. We find that (i) language models (LMs) pre-trained on demographically perturbed corpora are typically more fair, and (ii) LMs finetuned on perturbed GLUE datasets exhibit less demographic bias on downstream tasks, and (iii) fairness improvements do not come at the expense of performance on downstream tasks. Lastly, we discuss outstanding questions about how best to evaluate the (un)fairness of large language models. We hope that this exploration of neural demographic perturbation will help drive more improvement towards fairer NLP. ","[{'version': 'v1', 'created': 'Wed, 25 May 2022 09:00:29 GMT'}, {'version': 'v2', 'created': 'Wed, 12 Oct 2022 21:31:55 GMT'}]",2022-10-14,"[['Qian', 'Rebecca', ''], ['Ross', 'Candace', ''], ['Fernandes', 'Jude', ''], ['Smith', 'Eric', ''], ['Kiela', 'Douwe', ''], ['Williams', 'Adina', '']]",0,0,2022-05-25,2,6,2,0,0,0,011095a0082e5e301f9bf30267b193c1c9e7e370,249062690.0,https://www.semanticscholar.org/paper/011095a0082e5e301f9bf30267b193c1c9e7e370,Conference on Empirical Methods in Natural Language Processing,2022.0,145.0,32.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2149798086', 'name': 'Rebecca Qian'}, {'authorId': '51519704', 'name': 'Candace Ross'}, {'authorId': '2166312768', 'name': 'Jude Fernandes'}, {'authorId': '51324296', 'name': 'Eric Michael Smith'}, {'authorId': '2111313627', 'name': 'Douwe Kiela'}, {'authorId': '2110032535', 'name': 'Adina Williams'}]","['Hugging Face', 'Meta']",['United States'],2022-05,"['industrial', 'industrial']"
2206.03865,Jeevana Priya Inala,"Jeevana Priya Inala, Chenglong Wang, Mei Yang, Andres Codas, Mark
  Encarnaci\'on, Shuvendu K Lahiri, Madanlal Musuvathi, Jianfeng Gao",Fault-Aware Neural Code Rankers,"In the proceedings of Advances in Neural Information Processing
  Systems, 2022",,,,cs.PL cs.AI cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated an impressive ability to generate code for various programming tasks. In many instances, LLMs can generate a correct program for a task when given numerous trials. Consequently, a recent trend is to do large scale sampling of programs using a model and then filtering/ranking the programs based on the program execution on a small number of known unit tests to select one candidate solution. However, these approaches assume that the unit tests are given and assume the ability to safely execute the generated programs (which can do arbitrary dangerous operations such as file manipulations). Both of the above assumptions are impractical in real-world software development. In this paper, we propose CodeRanker, a neural ranker that can predict the correctness of a sampled program without executing it. Our CodeRanker is fault-aware i.e., it is trained to predict different kinds of execution information such as predicting the exact compile/runtime error type (e.g., an IndexError or a TypeError). We show that CodeRanker can significantly increase the pass@1 accuracy of various code generation models (including Codex, GPT-Neo, GPT-J) on APPS, HumanEval and MBPP datasets. ","[{'version': 'v1', 'created': 'Sat, 4 Jun 2022 22:01:05 GMT'}, {'version': 'v2', 'created': 'Fri, 9 Dec 2022 22:10:02 GMT'}]",2022-12-13,"[['Inala', 'Jeevana Priya', ''], ['Wang', 'Chenglong', ''], ['Yang', 'Mei', ''], ['Codas', 'Andres', ''], ['Encarnación', 'Mark', ''], ['Lahiri', 'Shuvendu K', ''], ['Musuvathi', 'Madanlal', ''], ['Gao', 'Jianfeng', '']]",0,1,2022-06-04,2,8,3,1,0,1,075b6fb7d3787953164eecc1bd2e13f97c9f3c44,249462026.0,https://www.semanticscholar.org/paper/075b6fb7d3787953164eecc1bd2e13f97c9f3c44,Neural Information Processing Systems,2022.0,46.0,27.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1827015', 'name': 'J. Inala'}, {'authorId': '2144523164', 'name': 'Chenglong Wang'}, {'authorId': '2168617007', 'name': 'Mei Yang'}, {'authorId': '2097627', 'name': 'Andrés Codas'}, {'authorId': '2168879819', 'name': ""Mark Encarnaci'on""}, {'authorId': '145474353', 'name': 'Shuvendu K. Lahiri'}, {'authorId': '1702346', 'name': 'M. Musuvathi'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}]",['Microsoft'],['India'],2022-06,['industrial']
2206.05802,Jeffrey Wu,"William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang,
  Jonathan Ward, Jan Leike",Self-critiquing models for assisting human evaluators,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We fine-tune large language models to write natural language critiques (natural language critical comments) using behavioral cloning. On a topic-based summarization task, critiques written by our models help humans find flaws in summaries that they would have otherwise missed. Our models help find naturally occurring flaws in both model and human written summaries, and intentional flaws in summaries written by humans to be deliberately misleading. We study scaling properties of critiquing with both topic-based summarization and synthetic tasks. Larger models write more helpful critiques, and on most tasks, are better at self-critiquing, despite having harder-to-critique outputs. Larger models can also integrate their own self-critiques as feedback, refining their own summaries into better ones. Finally, we motivate and introduce a framework for comparing critiquing ability to generation and discrimination ability. Our measurements suggest that even large models may still have relevant knowledge they cannot or do not articulate as critiques. These results are a proof of concept for using AI-assisted human feedback to scale the supervision of machine learning systems to tasks that are difficult for humans to evaluate directly. We release our training datasets, as well as samples from our critique assistance experiments. ","[{'version': 'v1', 'created': 'Sun, 12 Jun 2022 17:40:53 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Jun 2022 01:16:24 GMT'}]",2022-06-15,"[['Saunders', 'William', ''], ['Yeh', 'Catherine', ''], ['Wu', 'Jeff', ''], ['Bills', 'Steven', ''], ['Ouyang', 'Long', ''], ['Ward', 'Jonathan', ''], ['Leike', 'Jan', '']]",0,0,2022-06-12,2,7,2,0,0,0,29acc890e521f7a6415666ab9eb3432c49b4587a,249626555.0,https://www.semanticscholar.org/paper/29acc890e521f7a6415666ab9eb3432c49b4587a,arXiv.org,2022.0,46.0,87.0,11.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2058848938', 'name': 'W. Saunders'}, {'authorId': None, 'name': 'Catherine Yeh'}, {'authorId': '49387725', 'name': 'Jeff Wu'}, {'authorId': '87299088', 'name': 'Steven Bills'}, {'authorId': '2228518120', 'name': 'Ouyang Long'}, {'authorId': '2170081200', 'name': 'Jonathan Ward'}, {'authorId': '2990741', 'name': 'J. Leike'}]",['Steven Bills Long Ouyang Jonathan Ward'],,2022-06,['industrial']
2206.08267,Ganesh Bagler Dr,"Mansi Goel, Pallab Chakraborty, Vijay Ponnaganti, Minnet Khan,
  Sritanaya Tatipamala, Aakanksha Saini and Ganesh Bagler",Ratatouille: A tool for Novel Recipe Generation,"4 pages, 5 figures, 38th IEEE International Conference on Data
  Engineering, DECOR Workshop",,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Due to availability of a large amount of cooking recipes online, there is a growing interest in using this as data to create novel recipes. Novel Recipe Generation is a problem in the field of Natural Language Processing in which our main interest is to generate realistic, novel cooking recipes. To come up with such novel recipes, we trained various Deep Learning models such as LSTMs and GPT-2 with a large amount of recipe data. We present Ratatouille (https://cosylab.iiitd.edu.in/ratatouille2/), a web based application to generate novel recipes. ","[{'version': 'v1', 'created': 'Tue, 10 May 2022 11:20:19 GMT'}]",2022-06-17,"[['Goel', 'Mansi', ''], ['Chakraborty', 'Pallab', ''], ['Ponnaganti', 'Vijay', ''], ['Khan', 'Minnet', ''], ['Tatipamala', 'Sritanaya', ''], ['Saini', 'Aakanksha', ''], ['Bagler', 'Ganesh', '']]",0,1,2022-05-10,1,7,1,1,1,0,3cbba1c864b740d793035711da8810f6ee58f63e,249712131.0,https://www.semanticscholar.org/paper/3cbba1c864b740d793035711da8810f6ee58f63e,2022 IEEE 38th International Conference on Data Engineering Workshops (ICDEW),2022.0,25.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32839391', 'name': 'Mansi Goel'}, {'authorId': '1726629034', 'name': 'Pallab Chakraborty'}, {'authorId': '2170538137', 'name': 'Vijay Ponnaganti'}, {'authorId': '2170659719', 'name': 'Minnet Khan'}, {'authorId': '2170536094', 'name': 'Sritanaya Tatipamala'}, {'authorId': '3328119', 'name': 'Aakanksha Saini'}, {'authorId': '2080658', 'name': 'Ganesh Bagler'}]",['Indraprastha Institute of Information Technology Delhi'],['India'],2022-05,['industrial']
2206.13757,Zee Fryer,"Zee Fryer, Vera Axelrod, Ben Packer, Alex Beutel, Jilin Chen, Kellie
  Webster",Flexible text generation for counterfactual fairness probing,,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  A common approach for testing fairness issues in text-based classifiers is through the use of counterfactuals: does the classifier output change if a sensitive attribute in the input is changed? Existing counterfactual generation methods typically rely on wordlists or templates, producing simple counterfactuals that don't take into account grammar, context, or subtle sensitive attribute references, and could miss issues that the wordlist creators had not considered. In this paper, we introduce a task for generating counterfactuals that overcomes these shortcomings, and demonstrate how large language models (LLMs) can be leveraged to make progress on this task. We show that this LLM-based method can produce complex counterfactuals that existing methods cannot, comparing the performance of various counterfactual generation methods on the Civil Comments dataset and showing their value in evaluating a toxicity classifier. ","[{'version': 'v1', 'created': 'Tue, 28 Jun 2022 05:07:20 GMT'}]",2022-06-29,"[['Fryer', 'Zee', ''], ['Axelrod', 'Vera', ''], ['Packer', 'Ben', ''], ['Beutel', 'Alex', ''], ['Chen', 'Jilin', ''], ['Webster', 'Kellie', '']]",0,0,2022-06-28,1,6,2,0,0,0,7e7cc29b042793b27688beb765dc604dee65d536,250089342.0,https://www.semanticscholar.org/paper/7e7cc29b042793b27688beb765dc604dee65d536,WOAH,2022.0,53.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2540014', 'name': 'Zee Fryer'}, {'authorId': '82840075', 'name': 'Vera Axelrod'}, {'authorId': '1409971380', 'name': 'Ben Packer'}, {'authorId': '2638246', 'name': 'Alex Beutel'}, {'authorId': '2144168512', 'name': 'Jilin Chen'}, {'authorId': '20825661', 'name': 'Kellie Webster'}]",['Google'],['United States'],2022-06,['industrial']
2206.14576,Marcel Binz,Marcel Binz and Eric Schulz,Using cognitive psychology to understand GPT-3,,,10.1073/pnas.2218523120,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We study GPT-3, a recent large language model, using tools from cognitive psychology. More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature. We find that much of GPT-3's behavior is impressive: it solves vignette-based tasks similarly or better than human subjects, is able to make decent decisions from descriptions, outperforms humans in a multi-armed bandit task, and shows signatures of model-based reinforcement learning. Yet we also find that small perturbations to vignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures of directed exploration, and that it fails miserably in a causal reasoning task. These results enrich our understanding of current large language models and pave the way for future investigations using tools from cognitive psychology to study increasingly capable and opaque artificial agents. ","[{'version': 'v1', 'created': 'Tue, 21 Jun 2022 20:06:03 GMT'}]",2023-02-22,"[['Binz', 'Marcel', ''], ['Schulz', 'Eric', '']]",0,1,2022-06-21,1,2,3,1,0,1,fa3609e00f9f422a309c621a35394c4a38f88687,250113371.0,https://www.semanticscholar.org/paper/fa3609e00f9f422a309c621a35394c4a38f88687,Proceedings of the National Academy of Sciences of the United States of America,2022.0,73.0,136.0,9.0,True,"['Computer Science', 'Medicine']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32354733', 'name': 'Marcel Binz'}, {'authorId': '49427184', 'name': 'Eric Schulz'}]",['Max Planck Institute for Biological Cybernetics'],['Germany'],2022-06,['industrial']
2206.14858,Guy Gur-Ari,"Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk
  Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo
  Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, Vedant Misra",Solving Quantitative Reasoning Problems with Language Models,"12 pages, 5 figures + references and appendices",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Language models have achieved remarkable performance on a wide range of tasks that require natural language understanding. Nevertheless, state-of-the-art models have generally struggled with tasks that require quantitative reasoning, such as solving mathematics, science, and engineering problems at the college level. To help close this gap, we introduce Minerva, a large language model pretrained on general natural language data and further trained on technical content. The model achieves state-of-the-art performance on technical benchmarks without the use of external tools. We also evaluate our model on over two hundred undergraduate-level problems in physics, biology, chemistry, economics, and other sciences that require quantitative reasoning, and find that the model can correctly answer nearly a third of them. ","[{'version': 'v1', 'created': 'Wed, 29 Jun 2022 18:54:49 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Jul 2022 02:15:12 GMT'}]",2022-07-04,"[['Lewkowycz', 'Aitor', ''], ['Andreassen', 'Anders', ''], ['Dohan', 'David', ''], ['Dyer', 'Ethan', ''], ['Michalewski', 'Henryk', ''], ['Ramasesh', 'Vinay', ''], ['Slone', 'Ambrose', ''], ['Anil', 'Cem', ''], ['Schlag', 'Imanol', ''], ['Gutman-Solo', 'Theo', ''], ['Wu', 'Yuhuai', ''], ['Neyshabur', 'Behnam', ''], ['Gur-Ari', 'Guy', ''], ['Misra', 'Vedant', '']]",0,0,2022-06-29,2,14,3,0,0,0,ab0e3d3e4d42369de5933a3b4c237780b41c0d77,250144408.0,https://www.semanticscholar.org/paper/ab0e3d3e4d42369de5933a3b4c237780b41c0d77,Neural Information Processing Systems,2022.0,71.0,298.0,32.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '102549875', 'name': 'Aitor Lewkowycz'}, {'authorId': '39552848', 'name': 'Anders Andreassen'}, {'authorId': '35363891', 'name': 'David Dohan'}, {'authorId': '52136425', 'name': 'Ethan Dyer'}, {'authorId': '47407464', 'name': 'H. Michalewski'}, {'authorId': '96641652', 'name': 'V. Ramasesh'}, {'authorId': '133666998', 'name': 'Ambrose Slone'}, {'authorId': '48314480', 'name': 'Cem Anil'}, {'authorId': '35328044', 'name': 'Imanol Schlag'}, {'authorId': '2174177407', 'name': 'Theo Gutman-Solo'}, {'authorId': '3374063', 'name': 'Yuhuai Wu'}, {'authorId': '3007442', 'name': 'Behnam Neyshabur'}, {'authorId': '1403749855', 'name': 'Guy Gur-Ari'}, {'authorId': '40055795', 'name': 'Vedant Misra'}]",['Google'],['United States'],2022-06,['industrial']
2206.15067,Hyun-Wook Yoon,"Hyun-Wook Yoon, Ohsung Kwon, Hoyeon Lee, Ryuichi Yamamoto, Eunwoo
  Song, Jae-Min Kim, and Min-Jae Hwang",Language Model-Based Emotion Prediction Methods for Emotional Speech Synthesis Systems,Accepted by INTERSPEECH2022,,,,cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes an effective emotional text-to-speech (TTS) system with a pre-trained language model (LM)-based emotion prediction method. Unlike conventional systems that require auxiliary inputs such as manually defined emotion classes, our system directly estimates emotion-related attributes from the input text. Specifically, we utilize generative pre-trained transformer (GPT)-3 to jointly predict both an emotion class and its strength in representing emotions coarse and fine properties, respectively. Then, these attributes are combined in the emotional embedding space and used as conditional features of the TTS model for generating output speech signals. Consequently, the proposed system can produce emotional speech only from text without any auxiliary inputs. Furthermore, because the GPT-3 enables to capture emotional context among the consecutive sentences, the proposed method can effectively handle the paragraph-level generation of emotional speech. ","[{'version': 'v1', 'created': 'Thu, 30 Jun 2022 07:03:01 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Jul 2022 01:13:10 GMT'}]",2022-07-04,"[['Yoon', 'Hyun-Wook', ''], ['Kwon', 'Ohsung', ''], ['Lee', 'Hoyeon', ''], ['Yamamoto', 'Ryuichi', ''], ['Song', 'Eunwoo', ''], ['Kim', 'Jae-Min', ''], ['Hwang', 'Min-Jae', '']]",0,1,2022-06-30,2,7,2,1,0,1,4b7576815cc9cbb75ed72801791eb8d4dfd6484b,250144632.0,https://www.semanticscholar.org/paper/4b7576815cc9cbb75ed72801791eb8d4dfd6484b,Interspeech,2022.0,36.0,5.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1879512618', 'name': 'Hyun-Wook Yoon'}, {'authorId': '152406499', 'name': 'Ohsung Kwon'}, {'authorId': '2174373459', 'name': 'Hoyeon Lee'}, {'authorId': '47146577', 'name': 'Ryuichi Yamamoto'}, {'authorId': '37826449', 'name': 'Eunwoo Song'}, {'authorId': '2125028067', 'name': 'Jae-Min Kim'}, {'authorId': '47350043', 'name': 'Min-Jae Hwang'}]","['NAVER', 'Line Corporation (Japan)']","['South Korea', 'Japan']",2022-06,"['industrial', 'industrial']"
2207.02516,Su Young Kim,"Su Young Kim, Hyeonjin Park, Kyuyong Shin, Kyung-Min Kim",Ask Me What You Need: Product Retrieval using Knowledge from GPT-3,Accepted to DLP-KDD 2022 Workshop,,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As online merchandise become more common, many studies focus on embedding-based methods where queries and products are represented in the semantic space. These methods alleviate the problem of vocab mismatch between the language of queries and products. However, past studies usually dealt with queries that precisely describe the product, and there still exists the need to answer imprecise queries that may require common sense knowledge, i.e., 'what should I get my mom for Mother's Day.' In this paper, we propose a GPT-3 based product retrieval system that leverages the knowledge-base (KB) of GPT-3 for question answering; users do not need to know the specific illustrative keywords for a product when querying. Our method tunes prompt tokens of GPT-3 to prompt knowledge and render answers that are mapped directly to products without further processing. Our method shows consistent performance improvement on two real-world and one public dataset, compared to the baseline methods. We provide an in-depth discussion on leveraging GPT-3 knowledge into a question answering based retrieval system. ","[{'version': 'v1', 'created': 'Wed, 6 Jul 2022 08:44:38 GMT'}]",2022-07-07,"[['Kim', 'Su Young', ''], ['Park', 'Hyeonjin', ''], ['Shin', 'Kyuyong', ''], ['Kim', 'Kyung-Min', '']]",0,1,2022-07-06,1,4,1,1,0,1,62595a575c2c4a01b868de226aa68cfe17ea1fa3,250311310.0,https://www.semanticscholar.org/paper/62595a575c2c4a01b868de226aa68cfe17ea1fa3,arXiv.org,2022.0,15.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143061094', 'name': 'S. Kim'}, {'authorId': '2110832174', 'name': 'Hyeon-ju Park'}, {'authorId': '2810739', 'name': 'Kyuyong Shin'}, {'authorId': '2109351321', 'name': 'KyungHyun Kim'}]",['NAVER'],['South Korea'],2022-07,['industrial']
2207.06814,Javier de la Rosa,"Javier de la Rosa, Eduardo G. Ponferrada, Paulo Villegas, Pablo
  Gonzalez de Prado Salas, Manu Romero, Mar{\i}a Grandury",BERTIN: Efficient Pre-Training of a Spanish Language Model using Perplexity Sampling,Published at Procesamiento del Lenguaje Natural,"Procesamiento del Lenguaje Natural, 68 (2022): 13-23",,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  The pre-training of large language models usually requires massive amounts of resources, both in terms of computation and data. Frequently used web sources such as Common Crawl might contain enough noise to make this pre-training sub-optimal. In this work, we experiment with different sampling methods from the Spanish version of mC4, and present a novel data-centric technique which we name $\textit{perplexity sampling}$ that enables the pre-training of language models in roughly half the amount of steps and using one fifth of the data. The resulting models are comparable to the current state-of-the-art, and even achieve better results for certain tasks. Our work is proof of the versatility of Transformers, and paves the way for small teams to train their models on a limited budget. Our models are available at this $\href{https://huggingface.co/bertin-project}{URL}$. ","[{'version': 'v1', 'created': 'Thu, 14 Jul 2022 10:48:42 GMT'}]",2022-07-15,"[['de la Rosa', 'Javier', ''], ['Ponferrada', 'Eduardo G.', ''], ['Villegas', 'Paulo', ''], ['Salas', 'Pablo Gonzalez de Prado', ''], ['Romero', 'Manu', ''], ['Grandury', 'Marıa', '']]",0,0,2022-07-14,1,6,2,0,0,0,13773b39a116effa9f948febac59fe302924bec1,250526558.0,https://www.semanticscholar.org/paper/13773b39a116effa9f948febac59fe302924bec1,Proces. del Leng. Natural,2022.0,57.0,40.0,5.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144979591', 'name': 'Javier de la Rosa'}, {'authorId': '2260133312', 'name': 'E. G. Ponferrada'}, {'authorId': '2176184659', 'name': 'Paulo Villegas'}, {'authorId': '9947685', 'name': 'Pablo González de Prado Salas'}, {'authorId': '2176185463', 'name': 'Manu Romero'}, {'authorId': '2176184513', 'name': 'María Grandury'}]","['Telefonica Research and Development', 'Foqum, Madrid, Spain', 'Narrativa, Madrid, Spain', 'National Library of Norway, Mo i Rana, Norway']","['Spain', 'Norway']",2022-07,"['industrial', 'industrial', 'industrial', 'industrial']"
2207.08766,David Noever,"Samantha E. Miller Noever, David Noever",Word Play for Playing Othello (Reverses),,,,,cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Language models like OpenAI's Generative Pre-Trained Transformers (GPT-2/3) capture the long-term correlations needed to generate text in a variety of domains (such as language translators) and recently in gameplay (chess, Go, and checkers). The present research applies both the larger (GPT-3) and smaller (GPT-2) language models to explore the complex strategies for the game of Othello (or Reverses). Given the game rules for rapid reversals of fortune, the language model not only represents a candidate predictor of the next move based on previous game moves but also avoids sparse rewards in gameplay. The language model automatically captures or emulates championship-level strategies. The fine-tuned GPT-2 model generates Othello games ranging from 13-71% completion, while the larger GPT-3 model reaches 41% of a complete game. Like previous work with chess and Go, these language models offer a novel way to generate plausible game archives, particularly for comparing opening moves across a larger sample than humanly possible to explore. A primary contribution of these models magnifies (by two-fold) the previous record for player archives (120,000 human games over 45 years from 1977-2022), thus supplying the research community with more diverse and original strategies for sampling with other reinforcement learning techniques. ","[{'version': 'v1', 'created': 'Mon, 18 Jul 2022 17:13:32 GMT'}]",2022-07-19,"[['Noever', 'Samantha E. Miller', ''], ['Noever', 'David', '']]",0,1,2022-07-18,1,2,1,2,1,1,09658606353ec900e09232f2bfa6273bf10707dd,250626494.0,https://www.semanticscholar.org/paper/09658606353ec900e09232f2bfa6273bf10707dd,arXiv.org,2022.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2047999094', 'name': 'S. M. Noever'}, {'authorId': '46787948', 'name': 'David Noever'}]",['PeopleTec (United States)'],['United States'],2022-07,['industrial']
2207.10397,Bei Chen,"Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang
  Lou, Weizhu Chen",CodeT: Code Generation with Generated Tests,,,,,cs.CL cs.AI cs.PL cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The task of generating code solutions for a given programming problem can benefit from the use of pre-trained language models such as Codex, which can produce multiple diverse samples. However, a major challenge for this task is to select the most appropriate solution from the multiple samples generated by the pre-trained language models. A natural way to evaluate the quality and correctness of a code solution is to run it against a set of test cases, but the manual creation of such test cases is often costly and time-consuming. In this paper, we propose a novel method, CodeT, that leverages the same pre-trained language models to automatically generate test cases for the code samples, thus reducing the human effort and increasing the coverage of the test scenarios. CodeT then executes the code samples using the generated test cases, and performs a dual execution agreement, which considers both the consistency of the outputs against the generated test cases and the agreement of the outputs with other code samples. We conduct comprehensive experiments on four benchmarks, HumanEval, MBPP, APPS and CodeContests, using five different pre-trained language models with varying sizes and capabilities. Our results show that CodeT can significantly improve the performance of code solution selection over previous methods, achieving remarkable and consistent gains across different models and benchmarks. For instance, CodeT improves the pass@1 metric on HumanEval to 65.8%, which represents an absolute improvement of 18.8% over the code-davinci-002 model, and an absolute improvement of more than 20% over the previous state-of-the-art results. ","[{'version': 'v1', 'created': 'Thu, 21 Jul 2022 10:18:37 GMT'}, {'version': 'v2', 'created': 'Wed, 23 Nov 2022 07:42:10 GMT'}]",2022-11-24,"[['Chen', 'Bei', ''], ['Zhang', 'Fengji', ''], ['Nguyen', 'Anh', ''], ['Zan', 'Daoguang', ''], ['Lin', 'Zeqi', ''], ['Lou', 'Jian-Guang', ''], ['Chen', 'Weizhu', '']]",0,0,2022-07-21,2,7,4,1,0,1,876eb375cb7b365475040046df669c039ad54202,250920542.0,https://www.semanticscholar.org/paper/876eb375cb7b365475040046df669c039ad54202,International Conference on Learning Representations,2022.0,41.0,107.0,20.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': None, 'name': 'Bei Chen'}, {'authorId': '2158120018', 'name': 'Fengji Zhang'}, {'authorId': '1997993126', 'name': 'A. Nguyen'}, {'authorId': '2134434187', 'name': 'Daoguang Zan'}, {'authorId': '2284174', 'name': 'Zeqi Lin'}, {'authorId': '153249455', 'name': 'Jian-Guang Lou'}, {'authorId': '2109136147', 'name': 'Weizhu Chen'}]",['Microsoft'],['United States'],2022-07,['industrial']
2207.10648,Michael Desmond,"Michael Desmond, Evelyn Duesterwald, Vatche Isahagian, Vinod Muthusamy",A No-Code Low-Code Paradigm for Authoring Business Automations Using Natural Language,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Most business process automation is still developed using traditional automation technologies such as workflow engines. These systems provide domain specific languages that require both business knowledge and programming skills to effectively use. As such, business users often lack adequate programming skills to fully leverage these code oriented environments. We propose a paradigm for the construction of business automations using natural language. The approach applies a large language model to translate business rules and automations described in natural language, into a domain specific language interpretable by a business rule engine. We compare the performance of various language model configurations, across various target domains, and explore the use of constrained decoding to ensure syntactically correct generation of output. ","[{'version': 'v1', 'created': 'Fri, 15 Jul 2022 19:17:55 GMT'}]",2022-07-22,"[['Desmond', 'Michael', ''], ['Duesterwald', 'Evelyn', ''], ['Isahagian', 'Vatche', ''], ['Muthusamy', 'Vinod', '']]",0,0,2022-07-15,1,4,2,0,0,0,a84ad8292b5536e49322e414c70cde73daef9eb4,250917225.0,https://www.semanticscholar.org/paper/a84ad8292b5536e49322e414c70cde73daef9eb4,arXiv.org,2022.0,17.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3635336', 'name': 'Michael Desmond'}, {'authorId': '1757254', 'name': 'E. Duesterwald'}, {'authorId': '1482469814', 'name': 'Vatche Ishakian'}, {'authorId': '46761645', 'name': 'Vinod Muthusamy'}]",['IBM (United States)'],['United States'],2022-07,['industrial']
2207.10739,Paul Kassianik,"Paul Kassianik, Erik Nijkamp, Bo Pang, Yingbo Zhou, Caiming Xiong",BigIssue: A Realistic Bug Localization Benchmark,,,,,cs.LG cs.SE,http://creativecommons.org/licenses/by/4.0/,"  As machine learning tools progress, the inevitable question arises: How can machine learning help us write better code? With significant progress being achieved in natural language processing with models like GPT-3 and Bert, the applications of natural language processing techniques to code are starting to be explored. Most of the research has been focused on automatic program repair (APR), and while the results on synthetic or highly filtered datasets are promising, such models are hard to apply in real-world scenarios because of inadequate bug localization. We propose BigIssue: a benchmark for realistic bug localization. The goal of the benchmark is two-fold. We provide (1) a general benchmark with a diversity of real and synthetic Java bugs and (2) a motivation to improve bug localization capabilities of models through attention to the full repository context. With the introduction of BigIssue, we hope to advance the state of the art in bug localization, in turn improving APR performance and increasing its applicability to the modern development cycle. ","[{'version': 'v1', 'created': 'Thu, 21 Jul 2022 20:17:53 GMT'}, {'version': 'v2', 'created': 'Thu, 4 May 2023 22:31:12 GMT'}]",2023-05-08,"[['Kassianik', 'Paul', ''], ['Nijkamp', 'Erik', ''], ['Pang', 'Bo', ''], ['Zhou', 'Yingbo', ''], ['Xiong', 'Caiming', '']]",0,1,2022-07-21,2,5,2,1,0,1,311f171287dba3823547c6fd703c1ab8a2d45995,251018214.0,https://www.semanticscholar.org/paper/311f171287dba3823547c6fd703c1ab8a2d45995,arXiv.org,2022.0,56.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2127465423', 'name': 'Paul Kassianik'}, {'authorId': '2043490', 'name': 'Erik Nijkamp'}, {'authorId': '2063096824', 'name': 'Bo Pang'}, {'authorId': '2118860628', 'name': 'Yingbo Zhou'}, {'authorId': '2054594326', 'name': 'Caiming Xiong'}]",['Salesforce Research'],,2022-07,['industrial']
2207.14157,Pamela Mishkin,"Heidy Khlaaf, Pamela Mishkin, Joshua Achiam, Gretchen Krueger, Miles
  Brundage",A Hazard Analysis Framework for Code Synthesis Large Language Models,,,,,cs.SE cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  Codex, a large language model (LLM) trained on a variety of codebases, exceeds the previous state of the art in its capacity to synthesize and generate code. Although Codex provides a plethora of benefits, models that may generate code on such scale have significant limitations, alignment problems, the potential to be misused, and the possibility to increase the rate of progress in technical fields that may themselves have destabilizing impacts or have misuse potential. Yet such safety impacts are not yet known or remain to be explored. In this paper, we outline a hazard analysis framework constructed at OpenAI to uncover hazards or safety risks that the deployment of models like Codex may impose technically, socially, politically, and economically. The analysis is informed by a novel evaluation framework that determines the capacity of advanced code generation techniques against the complexity and expressivity of specification prompts, and their capability to understand and execute them relative to human ability. ","[{'version': 'v1', 'created': 'Mon, 25 Jul 2022 20:44:40 GMT'}]",2022-07-29,"[['Khlaaf', 'Heidy', ''], ['Mishkin', 'Pamela', ''], ['Achiam', 'Joshua', ''], ['Krueger', 'Gretchen', ''], ['Brundage', 'Miles', '']]",0,0,2022-07-25,1,5,2,1,0,1,dd112d4dbd4656223770989778f39700de3052bc,251134866.0,https://www.semanticscholar.org/paper/dd112d4dbd4656223770989778f39700de3052bc,arXiv.org,2022.0,41.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2103414', 'name': 'Heidy Khlaaf'}, {'authorId': '2051714782', 'name': 'Pamela Mishkin'}, {'authorId': '3381809', 'name': 'Joshua Achiam'}, {'authorId': '2064404342', 'name': 'Gretchen Krueger'}, {'authorId': '35167962', 'name': 'Miles Brundage'}]",['OpenAI'],['United States'],2022-07,['industrial']
2207.14561,Yuki Kadokawa,"Yuki Kadokawa, Lingwei Zhu, Yoshihisa Tsurumine, Takamitsu Matsubara",Cyclic Policy Distillation: Sample-Efficient Sim-to-Real Reinforcement Learning with Domain Randomization,,,,,cs.RO cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep reinforcement learning with domain randomization learns a control policy in various simulations with randomized physical and sensor model parameters to become transferable to the real world in a zero-shot setting. However, a huge number of samples are often required to learn an effective policy when the range of randomized parameters is extensive due to the instability of policy updates. To alleviate this problem, we propose a sample-efficient method named cyclic policy distillation (CPD). CPD divides the range of randomized parameters into several small sub-domains and assigns a local policy to each one. Then local policies are learned while cyclically transitioning to sub-domains. CPD accelerates learning through knowledge transfer based on expected performance improvements. Finally, all of the learned local policies are distilled into a global policy for sim-to-real transfers. CPD's effectiveness and sample efficiency are demonstrated through simulations with four tasks (Pendulum from OpenAIGym and Pusher, Swimmer, and HalfCheetah from Mujoco), and a real-robot, ball-dispersal task. We published code and videos from our experiments at https://github.com/yuki-kadokawa/cyclic-policy-distillation. ","[{'version': 'v1', 'created': 'Fri, 29 Jul 2022 09:22:53 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Apr 2023 07:02:05 GMT'}]",2023-04-11,"[['Kadokawa', 'Yuki', ''], ['Zhu', 'Lingwei', ''], ['Tsurumine', 'Yoshihisa', ''], ['Matsubara', 'Takamitsu', '']]",0,0,2022-07-29,2,4,2,0,0,0,e05da3172b0672aacb85913fe6e9f27243171a37,251197048.0,https://www.semanticscholar.org/paper/e05da3172b0672aacb85913fe6e9f27243171a37,Robotics Auton. Syst.,2022.0,45.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '80320916', 'name': 'Y. Kadokawa'}, {'authorId': '1750926460', 'name': 'Lingwei Zhu'}, {'authorId': '31991119', 'name': 'Yoshihisa Tsurumine'}, {'authorId': '3248224', 'name': 'Takamitsu Matsubara'}]",['Nara Institute of Science and Technology'],['Japan'],2022-07,['industrial']
2208.01448,Stephen Rawls,"Saleh Soltan, Shankar Ananthakrishnan, Jack FitzGerald, Rahul Gupta,
  Wael Hamza, Haidar Khan, Charith Peris, Stephen Rawls, Andy Rosenbaum, Anna
  Rumshisky, Chandana Satya Prakash, Mukund Sridhar, Fabian Triefenbach, Apurv
  Verma, Gokhan Tur, Prem Natarajan",AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we demonstrate that multilingual large-scale sequence-to-sequence (seq2seq) models, pre-trained on a mixture of denoising and Causal Language Modeling (CLM) tasks, are more efficient few-shot learners than decoder-only models on various tasks. In particular, we train a 20 billion parameter multilingual seq2seq model called Alexa Teacher Model (AlexaTM 20B) and show that it achieves state-of-the-art (SOTA) performance on 1-shot summarization tasks, outperforming a much larger 540B PaLM decoder model. AlexaTM 20B also achieves SOTA in 1-shot machine translation, especially for low-resource languages, across almost all language pairs supported by the model (Arabic, English, French, German, Hindi, Italian, Japanese, Marathi, Portuguese, Spanish, Tamil, and Telugu) on Flores-101 dataset. We also show in zero-shot setting, AlexaTM 20B outperforms GPT3 (175B) on SuperGLUE and SQuADv2 datasets and provides SOTA performance on multilingual tasks such as XNLI, XCOPA, Paws-X, and XWinograd. Overall, our results present a compelling case for seq2seq models as a powerful alternative to decoder-only models for Large-scale Language Model (LLM) training. ","[{'version': 'v1', 'created': 'Tue, 2 Aug 2022 13:30:07 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Aug 2022 12:42:52 GMT'}]",2022-08-04,"[['Soltan', 'Saleh', ''], ['Ananthakrishnan', 'Shankar', ''], ['FitzGerald', 'Jack', ''], ['Gupta', 'Rahul', ''], ['Hamza', 'Wael', ''], ['Khan', 'Haidar', ''], ['Peris', 'Charith', ''], ['Rawls', 'Stephen', ''], ['Rosenbaum', 'Andy', ''], ['Rumshisky', 'Anna', ''], ['Prakash', 'Chandana Satya', ''], ['Sridhar', 'Mukund', ''], ['Triefenbach', 'Fabian', ''], ['Verma', 'Apurv', ''], ['Tur', 'Gokhan', ''], ['Natarajan', 'Prem', '']]",0,1,2022-08-02,2,16,2,3,0,3,914254fac74a2da051cccf6ca16afcaad416a079,251253416.0,https://www.semanticscholar.org/paper/914254fac74a2da051cccf6ca16afcaad416a079,arXiv.org,2022.0,91.0,54.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2805456', 'name': 'Saleh Soltan'}, {'authorId': '2773408', 'name': 'Shankar Ananthakrishnan'}, {'authorId': '120590817', 'name': 'Jack G. M. FitzGerald'}, {'authorId': '145542597', 'name': 'Rahul Gupta'}, {'authorId': '1836135', 'name': 'Wael Hamza'}, {'authorId': '144165565', 'name': 'Haidar Khan'}, {'authorId': '102648923', 'name': 'Charith S. Peris'}, {'authorId': '38696444', 'name': 'Stephen Rawls'}, {'authorId': '146177177', 'name': 'Andrew Rosenbaum'}, {'authorId': '1681193', 'name': 'Anna Rumshisky'}, {'authorId': '1588348842', 'name': 'Chandan Prakash'}, {'authorId': '1734869335', 'name': 'Mukund Sridhar'}, {'authorId': '1761263', 'name': 'Fabian Triefenbach'}, {'authorId': '3363380', 'name': 'Apurv Verma'}, {'authorId': '5108268', 'name': 'G. Tur'}, {'authorId': '2104644641', 'name': 'Premkumar Natarajan'}]",['Amazon'],['United States'],2022-08,['industrial']
2208.06825,Manzil Zaheer,"Manzil Zaheer, Ankit Singh Rawat, Seungyeon Kim, Chong You, Himanshu
  Jain, Andreas Veit, Rob Fergus, Sanjiv Kumar",Teacher Guided Training: An Efficient Framework for Knowledge Transfer,,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The remarkable performance gains realized by large pretrained models, e.g., GPT-3, hinge on the massive amounts of data they are exposed to during training. Analogously, distilling such large models to compact models for efficient deployment also necessitates a large amount of (labeled or unlabeled) training data. In this paper, we propose the teacher-guided training (TGT) framework for training a high-quality compact model that leverages the knowledge acquired by pretrained generative models, while obviating the need to go through a large volume of data. TGT exploits the fact that the teacher has acquired a good representation of the underlying data domain, which typically corresponds to a much lower dimensional manifold than the input space. Furthermore, we can use the teacher to explore input space more efficiently through sampling or gradient-based methods; thus, making TGT especially attractive for limited data or long-tail settings. We formally capture this benefit of proposed data-domain exploration in our generalization bounds. We find that TGT can improve accuracy on several image classification benchmarks as well as a range of text classification and retrieval tasks. ","[{'version': 'v1', 'created': 'Sun, 14 Aug 2022 10:33:58 GMT'}]",2022-08-16,"[['Zaheer', 'Manzil', ''], ['Rawat', 'Ankit Singh', ''], ['Kim', 'Seungyeon', ''], ['You', 'Chong', ''], ['Jain', 'Himanshu', ''], ['Veit', 'Andreas', ''], ['Fergus', 'Rob', ''], ['Kumar', 'Sanjiv', '']]",0,1,2022-08-14,1,8,1,1,0,1,13df9e045024fcbc5ed0e33829ca8e02986bcbcb,251564473.0,https://www.semanticscholar.org/paper/13df9e045024fcbc5ed0e33829ca8e02986bcbcb,International Conference on Learning Representations,2022.0,105.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1771307', 'name': 'M. Zaheer'}, {'authorId': '2241094', 'name': 'A. Rawat'}, {'authorId': '2109548913', 'name': 'Seungyeon Kim'}, {'authorId': '1878841', 'name': 'Chong You'}, {'authorId': '2059143344', 'name': 'Himanshu Jain'}, {'authorId': '2799898', 'name': 'Andreas Veit'}, {'authorId': '2276554', 'name': 'R. Fergus'}, {'authorId': '49596260', 'name': 'Surinder Kumar'}]",['Google'],['United States'],2022-08,['industrial']
2208.07084,Daniele Comi,"Daniele Comi, Dimitrios Christofidellis, Pier Francesco Piazza and
  Matteo Manica",Z-BERT-A: a zero-shot Pipeline for Unknown Intent detection,"7 pages, 3 figures, 7 tables, https://github.com/GT4SD/zberta",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Intent discovery is a fundamental task in NLP, and it is increasingly relevant for a variety of industrial applications (Quarteroni 2018). The main challenge resides in the need to identify from input utterances novel unseen in-tents. Herein, we propose Z-BERT-A, a two-stage method for intent discovery relying on a Transformer architecture (Vaswani et al. 2017; Devlin et al. 2018), fine-tuned with Adapters (Pfeiffer et al. 2020), initially trained for Natural Language Inference (NLI), and later applied for unknown in-tent classification in a zero-shot setting. In our evaluation, we firstly analyze the quality of the model after adaptive fine-tuning on known classes. Secondly, we evaluate its performance casting intent classification as an NLI task. Lastly, we test the zero-shot performance of the model on unseen classes, showing how Z-BERT-A can effectively perform in-tent discovery by generating intents that are semantically similar, if not equal, to the ground truth ones. Our experiments show how Z-BERT-A is outperforming a wide variety of baselines in two zero-shot settings: known intents classification and unseen intent discovery. The proposed pipeline holds the potential to be widely applied in a variety of application for customer care. It enables automated dynamic triage using a lightweight model that, unlike large language models, can be easily deployed and scaled in a wide variety of business scenarios. Especially when considering a setting with limited hardware availability and performance whereon-premise or low resource cloud deployments are imperative. Z-BERT-A, predicting novel intents from a single utterance, represents an innovative approach for intent discovery, enabling online generation of novel intents. The pipeline is available as an installable python package at the following link: https://github.com/GT4SD/zberta. ","[{'version': 'v1', 'created': 'Mon, 15 Aug 2022 09:27:34 GMT'}, {'version': 'v2', 'created': 'Thu, 18 Aug 2022 14:41:30 GMT'}]",2022-08-19,"[['Comi', 'Daniele', ''], ['Christofidellis', 'Dimitrios', ''], ['Piazza', 'Pier Francesco', ''], ['Manica', 'Matteo', '']]",0,0,2022-08-15,2,4,2,0,0,0,6ae2c935293cedb83dd15fad64885eac6e9eaac1,251563983.0,https://www.semanticscholar.org/paper/6ae2c935293cedb83dd15fad64885eac6e9eaac1,arXiv.org,2022.0,38.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2181500236', 'name': 'Daniele Comi'}, {'authorId': '2039675061', 'name': 'Dimitrios Christofidellis'}, {'authorId': '2027103', 'name': 'Pier Francesco Piazza'}, {'authorId': '35904689', 'name': 'Matteo Manica'}]","['IBM Research Europe', 'IBM (Italy)']",['Italy'],2022-08,"['industrial', 'industrial']"
2208.09554,Robert Wray,"James R. Kirk, Robert E. Wray, Peter Lindes, John E. Laird",Integrating Diverse Knowledge Sources for Online One-shot Learning of Novel Tasks,"20 pages, 3 figures. (Added technical appendix based on reviewer
  feedback.)",,,,cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Autonomous agents are able to draw on a wide variety of potential sources of task knowledge; however current approaches invariably focus on only one or two. Here we investigate the challenges and impact of exploiting diverse knowledge sources to learn online, in one-shot, new tasks for a simulated office mobile robot. The resulting agent, developed in the Soar cognitive architecture, uses the following sources of domain and task knowledge: interaction with the environment, task execution and search knowledge, human natural language instruction, and responses retrieved from a large language model (GPT-3). We explore the distinct contributions of these knowledge sources and evaluate the performance of different combinations in terms of learning correct task knowledge and human workload. Results show that an agent's online integration of diverse knowledge sources improves one-shot task learning overall, reducing human feedback needed for rapid and reliable task learning. ","[{'version': 'v1', 'created': 'Fri, 19 Aug 2022 21:53:15 GMT'}, {'version': 'v2', 'created': 'Fri, 3 Feb 2023 02:55:43 GMT'}, {'version': 'v3', 'created': 'Mon, 15 May 2023 16:34:58 GMT'}]",2023-05-16,"[['Kirk', 'James R.', ''], ['Wray', 'Robert E.', ''], ['Lindes', 'Peter', ''], ['Laird', 'John E.', '']]",0,1,2022-08-19,3,4,1,1,0,1,fa009ee01cbf4843ee505063f172c87a66cf7c12,256597818.0,https://www.semanticscholar.org/paper/fa009ee01cbf4843ee505063f172c87a66cf7c12,,2022.0,29.0,4.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145845123', 'name': 'James R. Kirk'}, {'authorId': '1721974', 'name': 'R. Wray'}, {'authorId': '2780534', 'name': 'Peter Lindes'}, {'authorId': '1715438', 'name': 'J. Laird'}]",['IQM (Finland)'],['Finland'],2022-08,['industrial']
2208.10063,Emily McMilin,Emily McMilin,Selection Collider Bias in Large Language Models,"12 pages, 16 figures, UAI 2022 Causal Representation Learning
  Workshop",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this paper we motivate the causal mechanisms behind sample selection induced collider bias (selection collider bias) that can cause Large Language Models (LLMs) to learn unconditional dependence between entities that are unconditionally independent in the real world. We show that selection collider bias can become amplified in underspecified learning tasks, and although difficult to overcome, we describe a method to exploit the resulting spurious correlations for determination of when a model may be uncertain about its prediction. We demonstrate an uncertainty metric that matches human uncertainty in tasks with gender pronoun underspecification on an extended version of the Winogender Schemas evaluation set, and we provide an online demo where users can apply our uncertainty metric to their own texts and models. ","[{'version': 'v1', 'created': 'Mon, 22 Aug 2022 05:38:15 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Sep 2022 04:30:35 GMT'}]",2022-09-14,"[['McMilin', 'Emily', '']]",0,0,2022-08-22,2,1,2,0,0,0,320927acca3625b895df90f9e113565520602146,251718825.0,https://www.semanticscholar.org/paper/320927acca3625b895df90f9e113565520602146,arXiv.org,2022.0,11.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2147830', 'name': 'Emily McMilin'}]",['Independent Researcher'],,2022-08,['industrial']
2209.03118,Alexei Grinbaum,Alexei Grinbaum and Laurynas Adomaitis,The Ethical Need for Watermarks in Machine-Generated Language,,,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Watermarks should be introduced in the natural language outputs of AI systems in order to maintain the distinction between human and machine-generated text. The ethical imperative to not blur this distinction arises from the asemantic nature of large language models and from human projections of emotional and cognitive states on machines, possibly leading to manipulation, spreading falsehoods or emotional distress. Enforcing this distinction requires unintrusive, yet easily accessible marks of the machine origin. We propose to implement a code based on equidistant letter sequences. While no such code exists in human-written texts, its appearance in machine-generated ones would prove helpful for ethical reasons. ","[{'version': 'v1', 'created': 'Wed, 7 Sep 2022 13:09:44 GMT'}]",2022-09-08,"[['Grinbaum', 'Alexei', ''], ['Adomaitis', 'Laurynas', '']]",0,0,2022-09-07,1,2,2,0,0,0,01bcdf931e38f32f15562a178b7abd8233386ab1,252110611.0,https://www.semanticscholar.org/paper/01bcdf931e38f32f15562a178b7abd8233386ab1,arXiv.org,2022.0,30.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40371965', 'name': 'A. Grinbaum'}, {'authorId': '108814448', 'name': 'Laurynas Adomaitis'}]",['CEA Saclay'],['France'],2022-09,['industrial']
2209.04299,Stephan Bialonski,"Patrick Gustav Blaneck, Tobias Bornheim, Niklas Grieger, Stephan
  Bialonski",Automatic Readability Assessment of German Sentences with Transformer Ensembles,"6 pages, 3 figures","In Proc. GermEval 2022 Workshop on Text Complexity Assessment of
  German Text: 18th KONVENS 2022, pages 57-62, Online (2022)",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reliable methods for automatic readability assessment have the potential to impact a variety of fields, ranging from machine translation to self-informed learning. Recently, large language models for the German language (such as GBERT and GPT-2-Wechsel) have become available, allowing to develop Deep Learning based approaches that promise to further improve automatic readability assessment. In this contribution, we studied the ability of ensembles of fine-tuned GBERT and GPT-2-Wechsel models to reliably predict the readability of German sentences. We combined these models with linguistic features and investigated the dependence of prediction performance on ensemble size and composition. Mixed ensembles of GBERT and GPT-2-Wechsel performed better than ensembles of the same size consisting of only GBERT or GPT-2-Wechsel models. Our models were evaluated in the GermEval 2022 Shared Task on Text Complexity Assessment on data of German sentences. On out-of-sample data, our best ensemble achieved a root mean squared error of 0.435. ","[{'version': 'v1', 'created': 'Fri, 9 Sep 2022 13:47:55 GMT'}]",2022-09-12,"[['Blaneck', 'Patrick Gustav', ''], ['Bornheim', 'Tobias', ''], ['Grieger', 'Niklas', ''], ['Bialonski', 'Stephan', '']]",0,1,2022-09-09,1,4,1,1,1,0,7d81b11a1b2b3ecd179afd1783a6a905fed86b20,252091118.0,https://www.semanticscholar.org/paper/7d81b11a1b2b3ecd179afd1783a6a905fed86b20,GERMEVAL,2022.0,24.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2184146158', 'name': 'Patrick Gustav Blaneck'}, {'authorId': '2125818889', 'name': 'Tobias Bornheim'}, {'authorId': '2088382168', 'name': 'Niklas Grieger'}, {'authorId': '1775634', 'name': 'S. Bialonski'}]","['FH Aachen', 'Team Industrial Services (United States)']","['Germany', 'United States']",2022-09,"['industrial', 'industrial']"
2209.04683,Shankar Kumar,Jared Lichtarge and Chris Alberti and Shankar Kumar,Simple and Effective Gradient-Based Tuning of Sequence-to-Sequence Models,"18 pages, 6 figures, In Proceedings of AutoML 2022 (Workshop track),
  Baltimore, MD, USA",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent trends towards training ever-larger language models have substantially improved machine learning performance across linguistic tasks. However, the huge cost of training larger models can make tuning them prohibitively expensive, motivating the study of more efficient methods. Gradient-based hyper-parameter optimization offers the capacity to tune hyper-parameters during training, yet has not previously been studied in a sequence-to-sequence setting. We apply a simple and general gradient-based hyperparameter optimization method to sequence-to-sequence tasks for the first time, demonstrating both efficiency and performance gains over strong baselines for both Neural Machine Translation and Natural Language Understanding (NLU) tasks (via T5 pretraining). For translation, we show the method generalizes across language pairs, is more efficient than Bayesian hyper-parameter optimization, and that learned schedules for some hyper-parameters can out-perform even optimal constant-valued tuning. For T5, we show that learning hyper-parameters during pretraining can improve performance across downstream NLU tasks. When learning multiple hyper-parameters concurrently, we show that the global learning rate can follow a schedule over training that improves performance and is not explainable by the `short-horizon bias' of greedy methods \citep{wu2018}. We release the code used to facilitate further research. ","[{'version': 'v1', 'created': 'Sat, 10 Sep 2022 14:52:41 GMT'}]",2022-09-13,"[['Lichtarge', 'Jared', ''], ['Alberti', 'Chris', ''], ['Kumar', 'Shankar', '']]",0,0,2022-09-10,1,3,2,1,1,0,9237b9e65eb3ca60bc92b086e78e29280bd6fda4,252200056.0,https://www.semanticscholar.org/paper/9237b9e65eb3ca60bc92b086e78e29280bd6fda4,arXiv.org,2022.0,69.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51888730', 'name': 'Jared Lichtarge'}, {'authorId': '114577307', 'name': 'Chris Alberti'}, {'authorId': '2109681515', 'name': 'Shankar Kumar'}]",['Google'],['United States'],2022-09,['industrial']
2209.07753,Jacky Liang,"Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian
  Ichter, Pete Florence, Andy Zeng",Code as Policies: Language Model Programs for Embodied Control,,,,,cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) trained on code completion have been shown to be capable of synthesizing simple Python programs from docstrings [1]. We find that these code-writing LLMs can be re-purposed to write robot policy code, given natural language commands. Specifically, policy code can express functions or feedback loops that process perception outputs (e.g.,from object detectors [2], [3]) and parameterize control primitive APIs. When provided as input several example language commands (formatted as comments) followed by corresponding policy code (via few-shot prompting), LLMs can take in new commands and autonomously re-compose API calls to generate new policy code respectively. By chaining classic logic structures and referencing third-party libraries (e.g., NumPy, Shapely) to perform arithmetic, LLMs used in this way can write robot policies that (i) exhibit spatial-geometric reasoning, (ii) generalize to new instructions, and (iii) prescribe precise values (e.g., velocities) to ambiguous descriptions (""faster"") depending on context (i.e., behavioral commonsense). This paper presents code as policies: a robot-centric formulation of language model generated programs (LMPs) that can represent reactive policies (e.g., impedance controllers), as well as waypoint-based policies (vision-based pick and place, trajectory-based control), demonstrated across multiple real robot platforms. Central to our approach is prompting hierarchical code-gen (recursively defining undefined functions), which can write more complex code and also improves state-of-the-art to solve 39.8% of problems on the HumanEval [1] benchmark. Code and videos are available at https://code-as-policies.github.io ","[{'version': 'v1', 'created': 'Fri, 16 Sep 2022 07:17:23 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Sep 2022 23:31:52 GMT'}, {'version': 'v3', 'created': 'Wed, 1 Mar 2023 04:02:50 GMT'}, {'version': 'v4', 'created': 'Thu, 25 May 2023 03:50:11 GMT'}]",2023-05-26,"[['Liang', 'Jacky', ''], ['Huang', 'Wenlong', ''], ['Xia', 'Fei', ''], ['Xu', 'Peng', ''], ['Hausman', 'Karol', ''], ['Ichter', 'Brian', ''], ['Florence', 'Pete', ''], ['Zeng', 'Andy', '']]",0,0,2022-09-16,4,8,1,0,0,0,41531594d7e0f3b2e138ae43e0a0f6e24a9b014c,252355542.0,https://www.semanticscholar.org/paper/41531594d7e0f3b2e138ae43e0a0f6e24a9b014c,IEEE International Conference on Robotics and Automation,2022.0,62.0,180.0,21.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '6454541', 'name': 'Jacky Liang'}, {'authorId': '2158105356', 'name': 'Wenlong Huang'}, {'authorId': '144956443', 'name': 'F. Xia'}, {'authorId': '2153917744', 'name': 'Peng Xu'}, {'authorId': '1944801', 'name': 'Karol Hausman'}, {'authorId': '2704814', 'name': 'Brian Ichter'}, {'authorId': '47686265', 'name': 'Peter R. Florence'}, {'authorId': '38591293', 'name': 'Andy Zeng'}]",['Google'],['United States'],2022-09,['industrial']
2209.08372,Surya Prakash Sahu,"Surya Prakash Sahu, Madhurima Mandal, Shikhar Bharadwaj, Aditya
  Kanade, Petros Maniatis, Shirish Shevade",CodeQueries: A Dataset of Semantic Queries over Code,,,,,cs.SE cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Developers often have questions about semantic aspects of code they are working on, e.g., ""Is there a class whose parent classes declare a conflicting attribute?"". Answering them requires understanding code semantics such as attributes and inheritance relation of classes. An answer to such a question should identify code spans constituting the answer (e.g., the declaration of the subclass) as well as supporting facts (e.g., the definitions of the conflicting attributes). The existing work on question-answering over code has considered yes/no questions or method-level context. We contribute a labeled dataset, called CodeQueries, of semantic queries over Python code. Compared to the existing datasets, in CodeQueries, the queries are about code semantics, the context is file level and the answers are code spans. We curate the dataset based on queries supported by a widely-used static analysis tool, CodeQL, and include both positive and negative examples, and queries requiring single-hop and multi-hop reasoning.   To assess the value of our dataset, we evaluate baseline neural approaches. We study a large language model (GPT3.5-Turbo) in zero-shot and few-shot settings on a subset of CodeQueries. We also evaluate a BERT style model (CuBERT) with fine-tuning. We find that these models achieve limited success on CodeQueries. CodeQueries is thus a challenging dataset to test the ability of neural models, to understand code semantics, in the extractive question-answering setting. ","[{'version': 'v1', 'created': 'Sat, 17 Sep 2022 17:09:30 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Jul 2023 11:01:45 GMT'}]",2023-07-17,"[['Sahu', 'Surya Prakash', ''], ['Mandal', 'Madhurima', ''], ['Bharadwaj', 'Shikhar', ''], ['Kanade', 'Aditya', ''], ['Maniatis', 'Petros', ''], ['Shevade', 'Shirish', '']]",0,1,2022-09-17,2,6,2,1,0,1,cd937849a314b3e5eb4862a3b55aa823811a5996,259924447.0,https://www.semanticscholar.org/paper/cd937849a314b3e5eb4862a3b55aa823811a5996,,2022.0,49.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2185411106', 'name': 'Surya Prakash Sahu'}, {'authorId': '2185411327', 'name': 'Madhurima Mandal'}, {'authorId': '2136381352', 'name': 'Shikhar Bharadwaj'}, {'authorId': '2594759', 'name': 'Aditya Kanade'}, {'authorId': '2286904', 'name': 'Petros Maniatis'}, {'authorId': '1772326', 'name': 'S. Shevade'}]","['Indian Institute of Science Bangalore', 'Microsoft']",['India'],2022-09,"['industrial', 'industrial']"
2209.15259,L\^e-Nguy\^en Hoang,"El-Mahdi El-Mhamdi, Sadegh Farhadkhani, Rachid Guerraoui, Nirupam
  Gupta, L\^e-Nguy\^en Hoang, Rafael Pinot, S\'ebastien Rouault, John Stephan",On the Impossible Safety of Large AI Models,40 pages,,,,cs.LG cs.AI cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large AI Models (LAIMs), of which large language models are the most prominent recent example, showcase some impressive performance. However they have been empirically found to pose serious security issues. This paper systematizes our knowledge about the fundamental impossibility of building arbitrarily accurate and secure machine learning models. More precisely, we identify key challenging features of many of today's machine learning settings. Namely, high accuracy seems to require memorizing large training datasets, which are often user-generated and highly heterogeneous, with both sensitive information and fake users. We then survey statistical lower bounds that, we argue, constitute a compelling case against the possibility of designing high-accuracy LAIMs with strong security guarantees. ","[{'version': 'v1', 'created': 'Fri, 30 Sep 2022 06:36:49 GMT'}, {'version': 'v2', 'created': 'Tue, 9 May 2023 10:24:28 GMT'}]",2023-05-10,"[['El-Mhamdi', 'El-Mahdi', ''], ['Farhadkhani', 'Sadegh', ''], ['Guerraoui', 'Rachid', ''], ['Gupta', 'Nirupam', ''], ['Hoang', 'Lê-Nguyên', ''], ['Pinot', 'Rafael', ''], ['Rouault', 'Sébastien', ''], ['Stephan', 'John', '']]",0,0,2022-09-30,2,8,3,0,0,0,546e4f4a8b6b8443428109f320f0dcf798efca8a,258564935.0,https://www.semanticscholar.org/paper/546e4f4a8b6b8443428109f320f0dcf798efca8a,arXiv.org,2022.0,224.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1412478053', 'name': 'El-Mahdi El-Mhamdi'}, {'authorId': '2044392690', 'name': 'Sadegh Farhadkhani'}, {'authorId': '1727558', 'name': 'R. Guerraoui'}, {'authorId': '7639794', 'name': 'Nirupam Gupta'}, {'authorId': '3438462', 'name': 'L. Hoang'}, {'authorId': '35449300', 'name': 'Rafael Pinot'}, {'authorId': '2096027197', 'name': 'John Stephan'}]",['Tournesol Association'],,2022-09,['industrial']
2210.00185,Zhenhailong Wang,"Zhenhailong Wang, Xiaoman Pan, Dian Yu, Dong Yu, Jianshu Chen, Heng Ji",Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks,Accepted as a conference paper at Findings of ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Although large language models have achieved impressive zero-shot ability, the huge model size generally incurs high cost. Recently, semi-parametric language models, which augment a smaller language model with an external retriever, have demonstrated promising language modeling capabilities. However, it remains unclear whether such semi-parametric language models can perform competitively well as their fully-parametric counterparts on zero-shot generalization to downstream tasks. In this work, we introduce $\text{Zemi}$, a zero-shot semi-parametric language model. To our best knowledge, this is the first semi-parametric language model that can demonstrate strong zero-shot performance on a wide range of held-out unseen tasks. We train $\text{Zemi}$ with a novel semi-parametric multitask prompted training paradigm, which shows significant improvement compared with the parametric multitask training as proposed by T0. Specifically, we augment the multitask training and zero-shot evaluation with retrieval from a large-scale task-agnostic unlabeled corpus. In order to incorporate multiple potentially noisy retrieved augmentations, we further propose a novel $\text{augmentation fusion}$ module leveraging perceiver resampler and gated cross-attention. Notably, our proposed $\text{Zemi}_\text{LARGE}$ outperforms T0-3B by 16% on all seven evaluation tasks while being 3.9x smaller in model size. ","[{'version': 'v1', 'created': 'Sat, 1 Oct 2022 04:08:50 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 00:49:44 GMT'}]",2023-05-24,"[['Wang', 'Zhenhailong', ''], ['Pan', 'Xiaoman', ''], ['Yu', 'Dian', ''], ['Yu', 'Dong', ''], ['Chen', 'Jianshu', ''], ['Ji', 'Heng', '']]",0,0,2022-10-01,2,6,1,1,1,0,ec97c3248537bb0b455b3fe9bc341110cfceffde,252683285.0,https://www.semanticscholar.org/paper/ec97c3248537bb0b455b3fe9bc341110cfceffde,Annual Meeting of the Association for Computational Linguistics,2022.0,88.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2052036545', 'name': 'Zhenhailong Wang'}, {'authorId': '34741133', 'name': 'Xiaoman Pan'}, {'authorId': '41190054', 'name': 'Dian Yu'}, {'authorId': '144580027', 'name': 'Dong Yu'}, {'authorId': '2108276402', 'name': 'Jianshu Chen'}, {'authorId': '2113323573', 'name': 'Heng Ji'}]",['Tencent'],['China'],2022-10,['industrial']
2210.02617,Manzil Zaheer,"Soumya Basu, Ankit Singh Rawat, Manzil Zaheer",Generalization Properties of Retrieval-based Models,,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Many modern high-performing machine learning models such as GPT-3 primarily rely on scaling up models, e.g., transformer networks. Simultaneously, a parallel line of work aims to improve the model performance by augmenting an input instance with other (labeled) instances during inference. Examples of such augmentations include task-specific prompts and similar examples retrieved from the training data by a nonparametric component. Remarkably, retrieval-based methods have enjoyed success on a wide range of problems, ranging from standard natural language processing and vision tasks to protein folding, as demonstrated by many recent efforts, including WebGPT and AlphaFold. Despite growing literature showcasing the promise of these models, the theoretical underpinning for such models remains underexplored. In this paper, we present a formal treatment of retrieval-based models to characterize their generalization ability. In particular, we focus on two classes of retrieval-based classification approaches: First, we analyze a local learning framework that employs an explicit local empirical risk minimization based on retrieved examples for each input instance. Interestingly, we show that breaking down the underlying learning task into local sub-tasks enables the model to employ a low complexity parametric component to ensure good overall accuracy. The second class of retrieval-based approaches we explore learns a global model using kernel methods to directly map an input instance and retrieved examples to a prediction, without explicitly solving a local learning task. ","[{'version': 'v1', 'created': 'Thu, 6 Oct 2022 00:33:01 GMT'}]",2022-10-07,"[['Basu', 'Soumya', ''], ['Rawat', 'Ankit Singh', ''], ['Zaheer', 'Manzil', '']]",0,1,2022-10-06,1,3,1,2,0,2,6a0321b05af7ed549309a05be5f9e335396d3a3d,252734904.0,https://www.semanticscholar.org/paper/6a0321b05af7ed549309a05be5f9e335396d3a3d,arXiv.org,2022.0,62.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143627291', 'name': 'S. Basu'}, {'authorId': '2241094', 'name': 'A. Rawat'}, {'authorId': '1771307', 'name': 'M. Zaheer'}]",['Google'],['United States'],2022-10,['industrial']
2210.03078,Jiacheng Liu,"Jiacheng Liu, Skyler Hallinan, Ximing Lu, Pengfei He, Sean Welleck,
  Hannaneh Hajishirzi, Yejin Choi",Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering,EMNLP 2022 main conference,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Knowledge underpins reasoning. Recent research demonstrates that when relevant knowledge is provided as additional context to commonsense question answering (QA), it can substantially enhance the performance even on top of state-of-the-art. The fundamental challenge is where and how to find such knowledge that is high quality and on point with respect to the question; knowledge retrieved from knowledge bases are incomplete and knowledge generated from language models are inconsistent. We present Rainier, or Reinforced Knowledge Introspector, that learns to generate contextually relevant knowledge in response to given questions. Our approach starts by imitating knowledge generated by GPT-3, then learns to generate its own knowledge via reinforcement learning where rewards are shaped based on the increased performance on the resulting question answering. Rainier demonstrates substantial and consistent performance gains when tested over 9 different commonsense benchmarks: including 5 datasets that are seen during model training, as well as 4 datasets that are kept unseen. Our work is the first to report that knowledge generated by models that are orders of magnitude smaller than GPT-3, even without direct supervision on the knowledge itself, can exceed the quality of commonsense knowledge elicited from GPT-3. ","[{'version': 'v1', 'created': 'Thu, 6 Oct 2022 17:34:06 GMT'}, {'version': 'v2', 'created': 'Sat, 22 Oct 2022 04:45:48 GMT'}]",2022-10-25,"[['Liu', 'Jiacheng', ''], ['Hallinan', 'Skyler', ''], ['Lu', 'Ximing', ''], ['He', 'Pengfei', ''], ['Welleck', 'Sean', ''], ['Hajishirzi', 'Hannaneh', ''], ['Choi', 'Yejin', '']]",0,1,2022-10-06,2,7,2,1,0,1,2591c66c6006c9c275a3dc7108a487934bc1c06f,252735191.0,https://www.semanticscholar.org/paper/2591c66c6006c9c275a3dc7108a487934bc1c06f,Conference on Empirical Methods in Natural Language Processing,2022.0,48.0,32.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2144174497', 'name': 'Jiacheng Liu'}, {'authorId': '1474550731', 'name': 'Skyler Hallinan'}, {'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '2153239696', 'name': 'Pengfei He'}, {'authorId': '2129663', 'name': 'S. Welleck'}, {'authorId': '2548384', 'name': 'Hannaneh Hajishirzi'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]",['Allen Institute for Artificial Intelligence'],['United States'],2022-10,['industrial']
2210.04834,Charith Peris,"Charith Peris, Lizhen Tan, Thomas Gueudre, Turan Gojayev, Pan Wei,
  Gokmen Oz",Knowledge Distillation Transfer Sets and their Impact on Downstream NLU Tasks,"7 pages, 2 figures, 2 tables (+ 4 tables in Appendix), Accepted to
  EMNLP 2022 (industry track)",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Teacher-student knowledge distillation is a popular technique for compressing today's prevailing large language models into manageable sizes that fit low-latency downstream applications. Both the teacher and the choice of transfer set used for distillation are crucial ingredients in creating a high quality student. Yet, the generic corpora used to pretrain the teacher and the corpora associated with the downstream target domain are often significantly different, which raises a natural question: should the student be distilled over the generic corpora, so as to learn from high-quality teacher predictions, or over the downstream task corpora to align with finetuning? Our study investigates this trade-off using Domain Classification (DC) and Intent Classification/Named Entity Recognition (ICNER) as downstream tasks. We distill several multilingual students from a larger multilingual LM with varying proportions of generic and task-specific datasets, and report their performance after finetuning on DC and ICNER. We observe significant improvements across tasks and test sets when only task-specific corpora is used. We also report on how the impact of adding task-specific data to the transfer set correlates with the similarity between generic and task-specific data. Our results clearly indicate that, while distillation from a generic LM benefits downstream tasks, students learn better using target domain data even if it comes at the price of noisier teacher predictions. In other words, target domain data still trumps teacher knowledge. ","[{'version': 'v1', 'created': 'Mon, 10 Oct 2022 16:49:52 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Oct 2022 14:25:43 GMT'}, {'version': 'v3', 'created': 'Mon, 17 Oct 2022 20:10:40 GMT'}]",2022-10-19,"[['Peris', 'Charith', ''], ['Tan', 'Lizhen', ''], ['Gueudre', 'Thomas', ''], ['Gojayev', 'Turan', ''], ['Wei', 'Pan', ''], ['Oz', 'Gokmen', '']]",0,0,2022-10-10,3,6,2,0,0,0,a001facb5cf130893f090239473888a78c75ef93,252780614.0,https://www.semanticscholar.org/paper/a001facb5cf130893f090239473888a78c75ef93,Conference on Empirical Methods in Natural Language Processing,2022.0,20.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '102648923', 'name': 'Charith S. Peris'}, {'authorId': '2087344242', 'name': 'Lizhen Tan'}, {'authorId': '2308928', 'name': 'Thomas Gueudré'}, {'authorId': '2820794', 'name': 'Turan Gojayev'}, {'authorId': '2187301092', 'name': 'Vivi Wei'}, {'authorId': '2033358253', 'name': 'Gokmen Oz'}]",['Amazon'],"['Germany', 'United States', 'Italy']",2022-10,['industrial']
2210.06384,Eldar Kurtic,Eldar Kurtic and Dan Alistarh,GMP*: Well-Tuned Gradual Magnitude Pruning Can Outperform Most BERT-Pruning Methods,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We revisit the performance of the classic gradual magnitude pruning (GMP) baseline for large language models, focusing on the classic BERT benchmark on various popular tasks. Despite existing evidence in the literature that GMP performs poorly, we show that a simple and general variant, which we call GMP*, can match and sometimes outperform more complex state-of-the-art methods. Our results provide a simple yet strong baseline for future work, highlight the importance of parameter tuning for baselines, and even improve the performance of the state-of-the-art second-order pruning method in this setting. ","[{'version': 'v1', 'created': 'Wed, 12 Oct 2022 16:35:47 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Oct 2022 06:50:05 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Dec 2022 19:24:00 GMT'}]",2022-12-12,"[['Kurtic', 'Eldar', ''], ['Alistarh', 'Dan', '']]",0,0,2022-10-12,3,2,1,0,0,0,a8c7dd6a9955a3976785f70146f32c77ed2b2eca,252846445.0,https://www.semanticscholar.org/paper/a8c7dd6a9955a3976785f70146f32c77ed2b2eca,,2022.0,21.0,10.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40992614', 'name': 'Eldar Kurtic'}, {'authorId': '3311387', 'name': 'Dan Alistarh'}]","['Neuroscience Research Australia', 'Institute of Science and Technology Austria']","['Austria', 'Australia']",2022-10,"['industrial', 'industrial']"
2210.07074,Andy Rosenbaum,"Andy Rosenbaum, Saleh Soltan, Wael Hamza, Amir Saffari, Marco Damonte,
  Isabel Groves",CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing,"Accepted to AACL-IJCNLP 2022: The 2nd Conference of the Asia-Pacific
  Chapter of the Association for Computational Linguistics and the 12th
  International Joint Conference on Natural Language Processing, November
  20-23, 2022. See https://www.aacl2022.org/",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  A bottleneck to developing Semantic Parsing (SP) models is the need for a large volume of human-labeled training data. Given the complexity and cost of human annotation for SP, labeled data is often scarce, particularly in multilingual settings. Large Language Models (LLMs) excel at SP given only a few examples, however LLMs are unsuitable for runtime systems which require low latency. In this work, we propose CLASP, a simple method to improve low-resource SP for moderate-sized models: we generate synthetic data from AlexaTM 20B to augment the training set for a model 40x smaller (500M parameters). We evaluate on two datasets in low-resource settings: English PIZZA, containing either 348 or 16 real examples, and mTOP cross-lingual zero-shot, where training data is available only in English, and the model must generalize to four new languages. On both datasets, we show significant improvements over strong baseline methods. ","[{'version': 'v1', 'created': 'Thu, 13 Oct 2022 15:01:03 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Oct 2022 09:50:24 GMT'}]",2022-10-17,"[['Rosenbaum', 'Andy', ''], ['Soltan', 'Saleh', ''], ['Hamza', 'Wael', ''], ['Saffari', 'Amir', ''], ['Damonte', 'Marco', ''], ['Groves', 'Isabel', '']]",0,0,2022-10-13,2,6,3,1,0,1,190b831643573cd73d543f620c50051078d8bce9,252873555.0,https://www.semanticscholar.org/paper/190b831643573cd73d543f620c50051078d8bce9,AACL,2022.0,48.0,13.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '146177177', 'name': 'Andrew Rosenbaum'}, {'authorId': '2805456', 'name': 'Saleh Soltan'}, {'authorId': '1836135', 'name': 'Wael Hamza'}, {'authorId': '1741702', 'name': 'Amir Saffari'}, {'authorId': '2187685542', 'name': 'Macro Damonte'}, {'authorId': '51893886', 'name': 'Isabel Groves'}]",['Amazon'],"['United States', 'United Kingdom']",2022-10,['industrial']
2210.07993,Iulia Comsa,"Iulia-Maria Comsa, Julian Martin Eisenschlos, Srini Narayanan",MiQA: A Benchmark for Inference on Metaphorical Questions,AACL-IJCNLP 2022 conference paper,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We propose a benchmark to assess the capability of large language models to reason with conventional metaphors. Our benchmark combines the previously isolated topics of metaphor detection and commonsense reasoning into a single task that requires a model to make inferences by accurately selecting between the literal and metaphorical register. We examine the performance of state-of-the-art pre-trained models on binary-choice tasks and find a large discrepancy between the performance of small and very large models, going from chance to near-human level. We also analyse the largest model in a generative setting and find that although human performance is approached, careful multiple-shot prompting is required. ","[{'version': 'v1', 'created': 'Fri, 14 Oct 2022 17:46:05 GMT'}]",2022-10-17,"[['Comsa', 'Iulia-Maria', ''], ['Eisenschlos', 'Julian Martin', ''], ['Narayanan', 'Srini', '']]",0,0,2022-10-14,1,3,1,0,0,0,777683db4795ff691533c2c4be3244fabd826842,252907241.0,https://www.semanticscholar.org/paper/777683db4795ff691533c2c4be3244fabd826842,AACL,2022.0,31.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '30134687', 'name': 'I. Comsa'}, {'authorId': '117595858', 'name': 'Julian Martin Eisenschlos'}, {'authorId': '144928136', 'name': 'S. Narayanan'}]",['Google'],['Switzerland'],2022-10,['industrial']
2210.08207,Parth Dandavate,Mihir Godbole and Parth Dandavate and Aditya Kane,Temporal Word Meaning Disambiguation using TimeLMs,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Meaning of words constantly changes given the events in modern civilization. Large Language Models use word embeddings, which are often static and thus cannot cope with this semantic change. Thus,it is important to resolve ambiguity in word meanings. This paper is an effort in this direction, where we explore methods for word sense disambiguation for the EvoNLP shared task. We conduct rigorous ablations for two solutions to this problem. We see that an approach using time-aware language models helps this task. Furthermore, we explore possible future directions to this problem. ","[{'version': 'v1', 'created': 'Sat, 15 Oct 2022 06:34:59 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Nov 2022 08:39:55 GMT'}]",2022-11-18,"[['Godbole', 'Mihir', ''], ['Dandavate', 'Parth', ''], ['Kane', 'Aditya', '']]",0,0,2022-10-15,2,3,1,0,0,0,0fd97ed923a570367fc88668f820b1bf1941432d,252918635.0,https://www.semanticscholar.org/paper/0fd97ed923a570367fc88668f820b1bf1941432d,EVONLP,2022.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2187929222', 'name': 'Mihir Godbole'}, {'authorId': '2187928164', 'name': 'Parth Dandavate'}, {'authorId': '2159555605', 'name': 'Aditya Kane'}]","['Indian Institute of Information Technology, Pune']",['India'],2022-10,['industrial']
2210.08209,Tanmay Chavan,Tanmay Chavan and Aditya Kane,Large Language Models for Multi-label Propaganda Detection,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The spread of propaganda through the internet has increased drastically over the past years. Lately, propaganda detection has started gaining importance because of the negative impact it has on society. In this work, we describe our approach for the WANLP 2022 shared task which handles the task of propaganda detection in a multi-label setting. The task demands the model to label the given text as having one or more types of propaganda techniques. There are a total of 21 propaganda techniques to be detected. We show that an ensemble of five models performs the best on the task, scoring a micro-F1 score of 59.73%. We also conduct comprehensive ablations and propose various future directions for this work. ","[{'version': 'v1', 'created': 'Sat, 15 Oct 2022 06:47:31 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Oct 2022 17:26:01 GMT'}]",2022-10-21,"[['Chavan', 'Tanmay', ''], ['Kane', 'Aditya', '']]",0,0,2022-10-15,2,2,1,0,0,0,898fdcd1a45137ecf7c315fd06762d47eaec61fb,263796264.0,https://www.semanticscholar.org/paper/898fdcd1a45137ecf7c315fd06762d47eaec61fb,arXiv.org,2022.0,14.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2063049987', 'name': 'Tanmay Chavan'}, {'authorId': '2159555605', 'name': 'Aditya Kane'}]","['Indian Institute of Information Technology, Pune']",['India'],2022-10,['industrial']
2210.12023,Alessandro Stolfo,"Alessandro Stolfo, Zhijing Jin, Kumar Shridhar, Bernhard Sch\""olkopf
  and Mrinmaya Sachan",A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models,"ACL 2023. A shorter version of the paper was accepted at the MATH-AI
  Workshop at NeurIPS 2022. 15 pages, 8 figures",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We have recently witnessed a number of impressive results on hard mathematical reasoning problems with language models. At the same time, the robustness of these models has also been called into question; recent works have shown that models can rely on shallow patterns in the problem description when generating a solution. Building on the idea of behavioral testing, we propose a novel framework, which pins down the causal effect of various factors in the input, e.g., the surface form of the problem text, the operands, and math operators on the output solution. By grounding the behavioral analysis in a causal graph describing an intuitive reasoning process, we study the behavior of language models in terms of robustness and sensitivity to direct interventions in the input space. We apply our framework on a test bed of math word problems. Our analysis shows that robustness does not appear to continuously improve as a function of size, but the GPT-3 Davinci models (175B) achieve a dramatic improvement in both robustness and sensitivity compared to all other GPT variants. ","[{'version': 'v1', 'created': 'Fri, 21 Oct 2022 15:12:37 GMT'}, {'version': 'v2', 'created': 'Mon, 24 Oct 2022 10:16:07 GMT'}, {'version': 'v3', 'created': 'Wed, 7 Jun 2023 22:03:16 GMT'}]",2023-06-09,"[['Stolfo', 'Alessandro', ''], ['Jin', 'Zhijing', ''], ['Shridhar', 'Kumar', ''], ['Schölkopf', 'Bernhard', ''], ['Sachan', 'Mrinmaya', '']]",0,1,2022-10-21,3,5,2,1,0,1,9b45af10429681249fafb07c3b6012ea4ce63ffe,253080612.0,https://www.semanticscholar.org/paper/9b45af10429681249fafb07c3b6012ea4ce63ffe,Annual Meeting of the Association for Computational Linguistics,2022.0,77.0,17.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2175480389', 'name': 'Alessandro Stolfo'}, {'authorId': '2111472502', 'name': 'Zhijing Jin'}, {'authorId': '50812160', 'name': 'K. Shridhar'}, {'authorId': '1707625', 'name': 'B. Scholkopf'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]","['Materials Processing (United States)', 'ETH Zurich', 'Equal contribution.']","['United States', 'Switzerland']",2022-10,"['industrial', 'industrial', 'industrial']"
2210.13979,Arijit Sehanobish,"Arijit Sehanobish, Kawshik Kannan, Nabila Abraham, Anasuya Das,
  Benjamin Odry",Meta-learning Pathologies from Radiology Reports using Variance Aware Prototypical Networks,"EMNLP'22 Industry Track. Extended Abstract presented at Machine
  Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans,
  United States & Virtual, http://www.ml4h.cc, 16 pages",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large pretrained Transformer-based language models like BERT and GPT have changed the landscape of Natural Language Processing (NLP). However, fine tuning such models still requires a large number of training examples for each target task, thus annotating multiple datasets and training these models on various downstream tasks becomes time consuming and expensive. In this work, we propose a simple extension of the Prototypical Networks for few-shot text classification. Our main idea is to replace the class prototypes by Gaussians and introduce a regularization term that encourages the examples to be clustered near the appropriate class centroids. Experimental results show that our method outperforms various strong baselines on 13 public and 4 internal datasets. Furthermore, we use the class distributions as a tool for detecting potential out-of-distribution (OOD) data points during deployment. ","[{'version': 'v1', 'created': 'Sat, 22 Oct 2022 05:22:29 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Nov 2022 16:54:18 GMT'}]",2022-11-11,"[['Sehanobish', 'Arijit', ''], ['Kannan', 'Kawshik', ''], ['Abraham', 'Nabila', ''], ['Das', 'Anasuya', ''], ['Odry', 'Benjamin', '']]",0,1,2022-10-22,2,5,2,0,0,0,aeb621626570243cadf963a7304501b6c1d2be42,253107656.0,https://www.semanticscholar.org/paper/aeb621626570243cadf963a7304501b6c1d2be42,Conference on Empirical Methods in Natural Language Processing,2022.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2131857530', 'name': 'Arijit Sehanobish'}, {'authorId': '37325070', 'name': 'Kawshik Kannan'}, {'authorId': '51461934', 'name': 'Nabila Abraham'}, {'authorId': '5441339', 'name': 'Anasuya Das'}, {'authorId': '2709133', 'name': 'B. Odry'}]",['New York City Department of Health and Mental Hygiene'],['United States'],2022-10,['industrial']
2210.14739,Yara Rizk,"Yara Rizk, Praveen Venkateswaran, Vatche Isahagian, Vinod Muthusamy",A Case for Business Process-Specific Foundation Models,,,,,cs.AI cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The inception of large language models has helped advance state-of-the-art performance on numerous natural language tasks. This has also opened the door for the development of foundation models for other domains and data modalities such as images, code, and music. In this paper, we argue that business process data representations have unique characteristics that warrant the development of a new class of foundation models to handle tasks like process mining, optimization, and decision making. These models should also tackle the unique challenges of applying AI to business processes which include data scarcity, multi-modal representations, domain specific terminology, and privacy concerns. ","[{'version': 'v1', 'created': 'Wed, 26 Oct 2022 14:17:47 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Nov 2022 19:35:57 GMT'}]",2022-12-02,"[['Rizk', 'Yara', ''], ['Venkateswaran', 'Praveen', ''], ['Isahagian', 'Vatche', ''], ['Muthusamy', 'Vinod', '']]",0,0,2022-10-26,2,4,2,0,0,0,30477855d76058a9b542cabea3058aad1a837d51,253116622.0,https://www.semanticscholar.org/paper/30477855d76058a9b542cabea3058aad1a837d51,arXiv.org,2022.0,51.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2587541', 'name': 'Yara Rizk'}, {'authorId': '2077182665', 'name': 'P. Venkateswaran'}, {'authorId': '1482469814', 'name': 'Vatche Ishakian'}, {'authorId': '46761645', 'name': 'Vinod Muthusamy'}]",['IBM Research - China'],['China'],2022-10,['industrial']
2210.15104,Piyush Behre,"Piyush Behre, Sharman Tan, Amy Shah, Harini Kesavamoorthy, Shuangyu
  Chang, Fei Zuo, Chris Basoglu, Sayan Pathak",TRScore: A Novel GPT-based Readability Scorer for ASR Segmentation and Punctuation model evaluation and selection,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Punctuation and Segmentation are key to readability in Automatic Speech Recognition (ASR), often evaluated using F1 scores that require high-quality human transcripts and do not reflect readability well. Human evaluation is expensive, time-consuming, and suffers from large inter-observer variability, especially in conversational speech devoid of strict grammatical structures. Large pre-trained models capture a notion of grammatical structure. We present TRScore, a novel readability measure using the GPT model to evaluate different segmentation and punctuation systems. We validate our approach with human experts. Additionally, our approach enables quantitative assessment of text post-processing techniques such as capitalization, inverse text normalization (ITN), and disfluency on overall readability, which traditional word error rate (WER) and slot error rate (SER) metrics fail to capture. TRScore is strongly correlated to traditional F1 and human readability scores, with Pearson's correlation coefficients of 0.67 and 0.98, respectively. It also eliminates the need for human transcriptions for model selection. ","[{'version': 'v1', 'created': 'Thu, 27 Oct 2022 01:11:32 GMT'}]",2022-10-28,"[['Behre', 'Piyush', ''], ['Tan', 'Sharman', ''], ['Shah', 'Amy', ''], ['Kesavamoorthy', 'Harini', ''], ['Chang', 'Shuangyu', ''], ['Zuo', 'Fei', ''], ['Basoglu', 'Chris', ''], ['Pathak', 'Sayan', '']]",0,1,2022-10-27,1,8,1,0,0,0,d5a31ae503a6693b8fdda357f92e19ff455230bc,253157741.0,https://www.semanticscholar.org/paper/d5a31ae503a6693b8fdda357f92e19ff455230bc,arXiv.org,2022.0,19.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2095236480', 'name': 'Piyush Behre'}, {'authorId': '2110333719', 'name': 'S.S. Tan'}, {'authorId': '2107664494', 'name': 'A. Shah'}, {'authorId': '51434736', 'name': 'Harini Kesavamoorthy'}, {'authorId': '39513746', 'name': 'Shuangyu Chang'}, {'authorId': '2064366202', 'name': 'Fei Zuo'}, {'authorId': '2950435', 'name': 'C. Basoglu'}, {'authorId': '38950865', 'name': 'Sayan D. Pathak'}]",['Microsoft'],['United States'],2022-10,['industrial']
2210.15718,Karthik Raman,"Krishna Srinivasan, Karthik Raman, Anupam Samanta, Lingrui Liao, Luca
  Bertelli and Mike Bendersky",QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation,EMNLP 2022 Industry Track,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have shown impressive results on a variety of text understanding tasks. Search queries though pose a unique challenge, given their short-length and lack of nuance or context. Complicated feature engineering efforts do not always lead to downstream improvements as their performance benefits may be offset by increased complexity of knowledge distillation. Thus, in this paper we make the following contributions: (1) We demonstrate that Retrieval Augmentation of queries provides LLMs with valuable additional context enabling improved understanding. While Retrieval Augmentation typically increases latency of LMs (thus hurting distillation efficacy), (2) we provide a practical and effective way of distilling Retrieval Augmentation LLMs. Specifically, we use a novel two-stage distillation approach that allows us to carry over the gains of retrieval augmentation, without suffering the increased compute typically associated with it. (3) We demonstrate the benefits of the proposed approach (QUILL) on a billion-scale, real-world query understanding system resulting in huge gains. Via extensive experiments, including on public benchmarks, we believe this work offers a recipe for practical use of retrieval-augmented query understanding. ","[{'version': 'v1', 'created': 'Thu, 27 Oct 2022 18:44:58 GMT'}]",2022-10-31,"[['Srinivasan', 'Krishna', ''], ['Raman', 'Karthik', ''], ['Samanta', 'Anupam', ''], ['Liao', 'Lingrui', ''], ['Bertelli', 'Luca', ''], ['Bendersky', 'Mike', '']]",0,0,2022-10-27,1,6,2,0,0,0,65bad077608a3c2ed8eac242e993aa40aa8c13e9,253224416.0,https://www.semanticscholar.org/paper/65bad077608a3c2ed8eac242e993aa40aa8c13e9,Conference on Empirical Methods in Natural Language Processing,2022.0,32.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1391084712', 'name': 'Krishna Srinivasan'}, {'authorId': '2062947723', 'name': 'K. Raman'}, {'authorId': '1705129804', 'name': 'Anupam Samanta'}, {'authorId': '2150041430', 'name': 'Ling-Yen Liao'}, {'authorId': '49622020', 'name': 'L. Bertelli'}, {'authorId': '1815447', 'name': 'Michael Bendersky'}]",['Google'],['United States'],2022-10,['industrial']
2210.16433,Xiaoman Pan,"Xiaoman Pan, Wenlin Yao, Hongming Zhang, Dian Yu, Dong Yu, Jianshu
  Chen",Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fully-parametric language models generally require a huge number of model parameters to store the necessary knowledge for solving multiple natural language tasks in zero/few-shot settings. In addition, it is hard to adapt to the evolving world knowledge without the costly model re-training. In this paper, we develop a novel semi-parametric language model architecture, Knowledge-in-Context (KiC), which empowers a parametric text-to-text language model with a knowledge-rich external memory. Specifically, the external memory contains six different types of knowledge: entity, dictionary, commonsense, event, script, and causality knowledge. For each input instance, the KiC model adaptively selects a knowledge type and retrieves the most helpful pieces of knowledge. The input instance along with its knowledge augmentation is fed into a text-to-text model (e.g., T5) to generate the output answer, where both the input and the output are in natural language forms after prompting. Interestingly, we find that KiC can be identified as a special mixture-of-experts (MoE) model, where the knowledge selector plays the role of a router that is used to determine the sequence-to-expert assignment in MoE. This key observation inspires us to develop a novel algorithm for training KiC with an instance-adaptive knowledge selector. As a knowledge-rich semi-parametric language model, KiC only needs a much smaller parametric part to achieve superior zero-shot performance on unseen tasks. By evaluating on 40+ different tasks, we show that KiC_Large with 770M parameters easily outperforms large language models (LMs) that are 4-39x larger by a large margin. We also demonstrate that KiC exhibits emergent abilities at a much smaller model scale compared to the fully-parametric models. ","[{'version': 'v1', 'created': 'Fri, 28 Oct 2022 23:18:43 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Feb 2023 02:42:53 GMT'}, {'version': 'v3', 'created': 'Mon, 27 Mar 2023 07:33:14 GMT'}]",2023-03-28,"[['Pan', 'Xiaoman', ''], ['Yao', 'Wenlin', ''], ['Zhang', 'Hongming', ''], ['Yu', 'Dian', ''], ['Yu', 'Dong', ''], ['Chen', 'Jianshu', '']]",0,0,2022-10-28,3,6,1,1,1,0,7ffb3a27a2a4da5c35472bd3a3a4dee8d40a6d86,253238033.0,https://www.semanticscholar.org/paper/7ffb3a27a2a4da5c35472bd3a3a4dee8d40a6d86,International Conference on Learning Representations,2022.0,93.0,14.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '34741133', 'name': 'Xiaoman Pan'}, {'authorId': '2087264100', 'name': 'Wenlin Yao'}, {'authorId': '49723569', 'name': 'Hongming Zhang'}, {'authorId': '41190054', 'name': 'Dian Yu'}, {'authorId': '144580027', 'name': 'Dong Yu'}, {'authorId': '2108276402', 'name': 'Jianshu Chen'}]",['Tencent'],['United States'],2022-10,['industrial']
2210.17323,Elias Frantar,"Elias Frantar, Saleh Ashkboos, Torsten Hoefler, Dan Alistarh",GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers,ICLR 2023,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Generative Pre-trained Transformer models, known as GPT or OPT, set themselves apart through breakthrough performance across complex language modelling tasks, but also by their extremely high computational and storage costs. Specifically, due to their massive size, even inference for large, highly-accurate GPT models may require multiple performant GPUs, which limits the usability of such models. While there is emerging work on relieving this pressure via model compression, the applicability and performance of existing compression techniques is limited by the scale and complexity of GPT models. In this paper, we address this challenge, and propose GPTQ, a new one-shot weight quantization method based on approximate second-order information, that is both highly-accurate and highly-efficient. Specifically, GPTQ can quantize GPT models with 175 billion parameters in approximately four GPU hours, reducing the bitwidth down to 3 or 4 bits per weight, with negligible accuracy degradation relative to the uncompressed baseline. Our method more than doubles the compression gains relative to previously-proposed one-shot quantization methods, preserving accuracy, allowing us for the first time to execute an 175 billion-parameter model inside a single GPU for generative inference. Moreover, we also show that our method can still provide reasonable accuracy in the extreme quantization regime, in which weights are quantized to 2-bit or even ternary quantization levels. We show experimentally that these improvements can be leveraged for end-to-end inference speedups over FP16, of around 3.25x when using high-end GPUs (NVIDIA A100) and 4.5x when using more cost-effective ones (NVIDIA A6000). The implementation is available at https://github.com/IST-DASLab/gptq. ","[{'version': 'v1', 'created': 'Mon, 31 Oct 2022 13:42:40 GMT'}, {'version': 'v2', 'created': 'Wed, 22 Mar 2023 13:10:47 GMT'}]",2023-03-23,"[['Frantar', 'Elias', ''], ['Ashkboos', 'Saleh', ''], ['Hoefler', 'Torsten', ''], ['Alistarh', 'Dan', '']]",0,1,2022-10-31,2,4,1,1,1,0,7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6,253237200.0,https://www.semanticscholar.org/paper/7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6,arXiv.org,2022.0,37.0,118.0,29.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1502248377', 'name': 'Elias Frantar'}, {'authorId': '9543395', 'name': 'S. Ashkboos'}, {'authorId': '1713648', 'name': 'T. Hoefler'}, {'authorId': '3311387', 'name': 'Dan Alistarh'}]","['ETH Zurich', 'Institute of Science and Technology Austria']","['Austria', 'Switzerland']",2022-10,"['industrial', 'industrial']"
2210.17497,Kenneth Ezukwoke,"Kenneth Ezukwoke, Anis Hoayek, Mireille Batton-Hubert, Xavier Boucher,
  Pascal Gounet and Jerome Adrian",Leveraging Pre-trained Models for Failure Analysis Triplets Generation,"33 pages, 11 figures, 9 tables",,,,cs.CL cs.LG stat.AP,http://creativecommons.org/licenses/by/4.0/,"  Pre-trained Language Models recently gained traction in the Natural Language Processing (NLP) domain for text summarization, generation and question-answering tasks. This stems from the innovation introduced in Transformer models and their overwhelming performance compared with Recurrent Neural Network Models (Long Short Term Memory (LSTM)). In this paper, we leverage the attention mechanism of pre-trained causal language models such as Transformer model for the downstream task of generating Failure Analysis Triplets (FATs) - a sequence of steps for analyzing defected components in the semiconductor industry. We compare different transformer models for this generative task and observe that Generative Pre-trained Transformer 2 (GPT2) outperformed other transformer model for the failure analysis triplet generation (FATG) task. In particular, we observe that GPT2 (trained on 1.5B parameters) outperforms pre-trained BERT, BART and GPT3 by a large margin on ROUGE. Furthermore, we introduce Levenshstein Sequential Evaluation metric (LESE) for better evaluation of the structured FAT data and show that it compares exactly with human judgment than existing metrics. ","[{'version': 'v1', 'created': 'Mon, 31 Oct 2022 17:21:15 GMT'}]",2022-11-01,"[['Ezukwoke', 'Kenneth', ''], ['Hoayek', 'Anis', ''], ['Batton-Hubert', 'Mireille', ''], ['Boucher', 'Xavier', ''], ['Gounet', 'Pascal', ''], ['Adrian', 'Jerome', '']]",0,1,2022-10-31,1,6,3,2,1,1,587373fe118f4d6ae8a184d7ee622fb9f7c25dd8,253237663.0,https://www.semanticscholar.org/paper/587373fe118f4d6ae8a184d7ee622fb9f7c25dd8,arXiv.org,2022.0,58.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2129401036', 'name': 'Kenneth Ezukwoke'}, {'authorId': '87793822', 'name': 'Anis Hoayek'}, {'authorId': '1442061049', 'name': 'M. Batton-Hubert'}, {'authorId': '2169563252', 'name': 'Xavier Boucher'}, {'authorId': '9104568', 'name': 'Pascal Gounet'}, {'authorId': '2189377591', 'name': 'Jerome Adrian'}]","['Failure Analysis Laboratory STMicroelectronics Grenoble, France', 'Mines Saint-Étienne']",['France'],2022-10,"['industrial', 'industrial']"
2211.01334,Zhang Junlin,Pengtao Zhang and Junlin Zhang,MemoNet: Memorizing All Cross Features' Representations Efficiently via Multi-Hash Codebook Network for CTR Prediction,,"ACM International Conference on Information and Knowledge
  Management(CIKM '23), October 21-25,2023,Birmingham,United Kingdom",10.1145/3583780.3614963,,cs.IR cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  New findings in natural language processing (NLP) demonstrate that the strong memorization capability contributes a lot to the success of Large Language Models (LLM). This inspires us to explicitly bring an independent memory mechanism into CTR ranking model to learn and memorize cross features' representations. In this paper, we propose multi-Hash Codebook NETwork (HCNet) as the memory mechanism for efficiently learning and memorizing representations of cross features in CTR tasks. HCNet uses a multi-hash codebook as the main memory place and the whole memory procedure consists of three phases: multi-hash addressing, memory restoring, and feature shrinking. We also propose a new CTR model named MemoNet which combines HCNet with a DNN backbone. Extensive experimental results on three public datasets and online test show that MemoNet reaches superior performance over state-of-the-art approaches. Besides, MemoNet shows scaling law of large language model in NLP, which means we can enlarge the size of the codebook in HCNet to sustainably obtain performance gains. Our work demonstrates the importance and feasibility of learning and memorizing representations of cross features, which sheds light on a new promising research direction. ","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 12:08:14 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Nov 2022 06:49:56 GMT'}, {'version': 'v3', 'created': 'Mon, 4 Sep 2023 08:58:04 GMT'}]",2023-09-06,"[['Zhang', 'Pengtao', ''], ['Zhang', 'Junlin', '']]",0,0,2022-10-25,3,2,3,0,0,0,a43101d6dcaf417cdd5b143654cb51273422a49e,253254821.0,https://www.semanticscholar.org/paper/a43101d6dcaf417cdd5b143654cb51273422a49e,International Conference on Information and Knowledge Management,2022.0,36.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40627025', 'name': 'P. Zhang'}, {'authorId': '2048571', 'name': 'Junlin Zhang'}]","['Sina Weibo Beijing, China']",['China'],2022-10,['industrial']
2211.02556,Lingxi Xie,"Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, Qi Tian",Pangu-Weather: A 3D High-Resolution Model for Fast and Accurate Global Weather Forecast,"19 pages, 13 figures: the first ever AI-based method that outperforms
  traditional numerical weather prediction methods",,,,physics.ao-ph cs.AI cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present Pangu-Weather, a deep learning based system for fast and accurate global weather forecast. For this purpose, we establish a data-driven environment by downloading $43$ years of hourly global weather data from the 5th generation of ECMWF reanalysis (ERA5) data and train a few deep neural networks with about $256$ million parameters in total. The spatial resolution of forecast is $0.25^\circ\times0.25^\circ$, comparable to the ECMWF Integrated Forecast Systems (IFS). More importantly, for the first time, an AI-based method outperforms state-of-the-art numerical weather prediction (NWP) methods in terms of accuracy (latitude-weighted RMSE and ACC) of all factors (e.g., geopotential, specific humidity, wind speed, temperature, etc.) and in all time ranges (from one hour to one week). There are two key strategies to improve the prediction accuracy: (i) designing a 3D Earth Specific Transformer (3DEST) architecture that formulates the height (pressure level) information into cubic data, and (ii) applying a hierarchical temporal aggregation algorithm to alleviate cumulative forecast errors. In deterministic forecast, Pangu-Weather shows great advantages for short to medium-range forecast (i.e., forecast time ranges from one hour to one week). Pangu-Weather supports a wide range of downstream forecast scenarios, including extreme weather forecast (e.g., tropical cyclone tracking) and large-member ensemble forecast in real-time. Pangu-Weather not only ends the debate on whether AI-based methods can surpass conventional NWP methods, but also reveals novel directions for improving deep learning weather forecast systems. ","[{'version': 'v1', 'created': 'Thu, 3 Nov 2022 17:19:43 GMT'}]",2022-11-07,"[['Bi', 'Kaifeng', ''], ['Xie', 'Lingxi', ''], ['Zhang', 'Hengheng', ''], ['Chen', 'Xin', ''], ['Gu', 'Xiaotao', ''], ['Tian', 'Qi', '']]",0,0,2022-11-03,1,6,4,0,0,0,4405874879827cacf199d26e8e23e4f547f72a2c,253370735.0,https://www.semanticscholar.org/paper/4405874879827cacf199d26e8e23e4f547f72a2c,arXiv.org,2022.0,59.0,52.0,9.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","[{'authorId': '94365920', 'name': 'Kaifeng Bi'}, {'authorId': '3041937', 'name': 'Lingxi Xie'}, {'authorId': '1983351', 'name': 'Hengheng Zhang'}, {'authorId': '2145229597', 'name': 'Xin Chen'}, {'authorId': '7787721', 'name': 'Xiaotao Gu'}, {'authorId': '1400120070', 'name': 'Qi Tian'}]",['Huawei Technologies (China)'],['China'],2022-11,['industrial']
2211.09527,F\'abio Vin\'icius Moreira Perez,F\'abio Perez and Ian Ribeiro,Ignore Previous Prompt: Attack Techniques For Language Models,ML Safety Workshop NeurIPS 2022,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Transformer-based large language models (LLMs) provide a powerful foundation for natural language tasks in large-scale customer-facing applications. However, studies that explore their vulnerabilities emerging from malicious user interaction are scarce. By proposing PromptInject, a prosaic alignment framework for mask-based iterative adversarial prompt composition, we examine how GPT-3, the most widely deployed language model in production, can be easily misaligned by simple handcrafted inputs. In particular, we investigate two types of attacks -- goal hijacking and prompt leaking -- and demonstrate that even low-aptitude, but sufficiently ill-intentioned agents, can easily exploit GPT-3's stochastic nature, creating long-tail risks. The code for PromptInject is available at https://github.com/agencyenterprise/PromptInject. ","[{'version': 'v1', 'created': 'Thu, 17 Nov 2022 13:43:20 GMT'}]",2022-11-18,"[['Perez', 'Fábio', ''], ['Ribeiro', 'Ian', '']]",0,1,2022-11-17,1,2,2,1,0,1,9716a2876d08fce9d8e5c5ba4d7b1a9af44806d6,253581710.0,https://www.semanticscholar.org/paper/9716a2876d08fce9d8e5c5ba4d7b1a9af44806d6,arXiv.org,2022.0,40.0,81.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2191070702', 'name': 'Fábio Perez'}, {'authorId': '2191076673', 'name': 'Ian Ribeiro'}]",['Studi'],['Sweden'],2022-11,['industrial']
2211.12835,Jakub Macina,"Kumar Shridhar, Jakub Macina, Mennatallah El-Assady, Tanmay Sinha,
  Manu Kapur, Mrinmaya Sachan",Automatic Generation of Socratic Subquestions for Teaching Math Word Problems,"Kumar Shridhar and Jakub Macina contributed equally to this work.
  Accepted at the 2022 Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2022). Code available:
  https://github.com/eth-nlped/scaffolding-generation",,,,cs.CL cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Socratic questioning is an educational method that allows students to discover answers to complex problems by asking them a series of thoughtful questions. Generation of didactically sound questions is challenging, requiring understanding of the reasoning process involved in the problem. We hypothesize that such questioning strategy can not only enhance the human performance, but also assist the math word problem (MWP) solvers. In this work, we explore the ability of large language models (LMs) in generating sequential questions for guiding math word problem-solving. We propose various guided question generation schemes based on input conditioning and reinforcement learning. On both automatic and human quality evaluations, we find that LMs constrained with desirable question properties generate superior questions and improve the overall performance of a math word problem solver. We conduct a preliminary user study to examine the potential value of such question generation models in the education domain. Results suggest that the difficulty level of problems plays an important role in determining whether questioning improves or hinders human performance. We discuss the future of using such questioning strategies in education. ","[{'version': 'v1', 'created': 'Wed, 23 Nov 2022 10:40:22 GMT'}]",2022-11-24,"[['Shridhar', 'Kumar', ''], ['Macina', 'Jakub', ''], ['El-Assady', 'Mennatallah', ''], ['Sinha', 'Tanmay', ''], ['Kapur', 'Manu', ''], ['Sachan', 'Mrinmaya', '']]",0,0,2022-11-23,1,6,3,0,0,0,e6745fb621481ccb0ed53c267a37292e499c1b42,253801800.0,https://www.semanticscholar.org/paper/e6745fb621481ccb0ed53c267a37292e499c1b42,Conference on Empirical Methods in Natural Language Processing,2022.0,65.0,12.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50812160', 'name': 'K. Shridhar'}, {'authorId': '23126830', 'name': 'Jakub Macina'}, {'authorId': '1401917601', 'name': 'Mennatallah El-Assady'}, {'authorId': '145679048', 'name': 'Tanmay Sinha'}, {'authorId': '2465316', 'name': 'Manu Kapur'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]",['ETH Zurich'],['Switzerland'],2022-11,['industrial']
2211.14865,Sai Krishna Rallabandi,"Parag Pravin Dakle, SaiKrishna Rallabandi and Preethi Raghavan",Understanding BLOOM: An empirical study on diverse NLP tasks,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We view the landscape of large language models (LLMs) through the lens of the recently released BLOOM model to understand the performance of BLOOM and other decoder-only LLMs compared to BERT-style encoder-only models. We achieve this by evaluating the smaller BLOOM model variants (\textit{350m/560m} and \textit{1b3/1b7}) on several NLP benchmark datasets and popular leaderboards. We make the following observations: (1) BLOOM performance does not scale with parameter size, unlike other LLMs like GPT and BERT. Experiments fine-tuning BLOOM models show that the 560m variant performs similarly to or better than the 1b7 variant, (2) Zero-shot cross-lingual and multi-lingual fine-tuning experiments show that BLOOM is at par or worse than monolingual GPT-2 models, and (3) Toxicity analysis of prompt-based text generation using the RealToxicityPrompts dataset shows that the text generated by BLOOM is at least 17\% less toxic than GPT-2 and GPT-3 models. ","[{'version': 'v1', 'created': 'Sun, 27 Nov 2022 15:48:14 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Mar 2023 03:54:14 GMT'}]",2023-03-16,"[['Dakle', 'Parag Pravin', ''], ['Rallabandi', 'SaiKrishna', ''], ['Raghavan', 'Preethi', '']]",0,1,2022-11-27,2,3,1,3,2,1,fb49e38135302a1c16d644c0f746cef7d5f10ee4,254044603.0,https://www.semanticscholar.org/paper/fb49e38135302a1c16d644c0f746cef7d5f10ee4,arXiv.org,2022.0,74.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51116864', 'name': 'Parag Dakle'}, {'authorId': '3167650', 'name': 'Sai Krishna Rallabandi'}, {'authorId': '30088877', 'name': 'Preethi Raghavan'}]",['Fidelity Investments (United States)'],['United States'],2022-11,['industrial']
2211.14875,Nghi D. Q. Bui,"Nghi D. Q. Bui, Yue Wang, Steven Hoi",Detect-Localize-Repair: A Unified Framework for Learning to Debug with CodeT5,Accepted to EMNLP 2022 Findings Track,,,,cs.SE cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automated software debugging is a crucial task for improving the productivity of software developers. Many neural-based techniques have been proven effective for debugging-related tasks such as bug localization and program repair (or bug fixing). However, these techniques often focus only on either one of them or approach them in a stage-wise manner, ignoring the mutual benefits between them. In this work, we propose a novel unified \emph{Detect-Localize-Repair} framework based on a pretrained programming language model CodeT5 to seamlessly address these tasks, named CodeT5-DLR. Specifically, we propose three objectives to adapt the generic CodeT5 for debugging: a bug detection objective to determine whether a given code snippet is buggy or not, a bug localization objective to identify the buggy lines, and a program repair objective to translate the buggy code to its fixed version. We evaluate it on each of these tasks and their combined setting on two newly collected line-level debugging datasets in Java and Python. Extensive results show that our model significantly outperforms existing baselines from both NLP and software engineering domains. ","[{'version': 'v1', 'created': 'Sun, 27 Nov 2022 16:11:29 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Dec 2022 17:28:40 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Dec 2022 11:58:46 GMT'}]",2022-12-23,"[['Bui', 'Nghi D. Q.', ''], ['Wang', 'Yue', ''], ['Hoi', 'Steven', '']]",0,0,2022-11-27,3,3,2,0,0,0,6f0bfec3a245f1aa203d16469ec313f2eb02e028,254044129.0,https://www.semanticscholar.org/paper/6f0bfec3a245f1aa203d16469ec313f2eb02e028,Conference on Empirical Methods in Natural Language Processing,2022.0,45.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '26910508', 'name': 'Nghi D. Q. Bui'}, {'authorId': '49416727', 'name': 'Yue Wang'}, {'authorId': '2184854289', 'name': 'Steven C. H. Hoi'}]",['Salesforce Research Asia'],,2022-11,['industrial']
2211.15603,Ravi Kiran Sarvadevabhatla,"Sai Shashank Kalakonda, Shubh Maheshwari, Ravi Kiran Sarvadevabhatla",Action-GPT: Leveraging Large-scale Language Models for Improved and Generalized Action Generation,"Code, pretrained models and sample videos will be made available at
  \url{https://actiongpt.github.io}",,,,cs.CV cs.GR cs.MM,http://creativecommons.org/licenses/by/4.0/,"  We introduce Action-GPT, a plug-and-play framework for incorporating Large Language Models (LLMs) into text-based action generation models. Action phrases in current motion capture datasets contain minimal and to-the-point information. By carefully crafting prompts for LLMs, we generate richer and fine-grained descriptions of the action. We show that utilizing these detailed descriptions instead of the original action phrases leads to better alignment of text and motion spaces. We introduce a generic approach compatible with stochastic (e.g. VAE-based) and deterministic (e.g. MotionCLIP) text-to-motion models. In addition, the approach enables multiple text descriptions to be utilized. Our experiments show (i) noticeable qualitative and quantitative improvement in the quality of synthesized motions, (ii) benefits of utilizing multiple LLM-generated descriptions, (iii) suitability of the prompt function, and (iv) zero-shot generation capabilities of the proposed approach. Project page: https://actiongpt.github.io ","[{'version': 'v1', 'created': 'Mon, 28 Nov 2022 17:57:48 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Nov 2022 13:13:29 GMT'}, {'version': 'v3', 'created': 'Tue, 7 Mar 2023 06:14:56 GMT'}]",2023-03-08,"[['Kalakonda', 'Sai Shashank', ''], ['Maheshwari', 'Shubh', ''], ['Sarvadevabhatla', 'Ravi Kiran', '']]",0,1,2022-11-28,3,3,3,0,0,0,cb2954127a7fce8ab84486765392ce95dcdd8175,257378694.0,https://www.semanticscholar.org/paper/cb2954127a7fce8ab84486765392ce95dcdd8175,IEEE International Conference on Multimedia and Expo,2022.0,18.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2192604064', 'name': 'Sai Shashank Kalakonda'}, {'authorId': '51440276', 'name': 'Shubham Maheshwari'}, {'authorId': '1730952', 'name': 'Ravi Kiran Sarvadevabhatla'}]","['International Institute of Information Technology, Hyderabad']",['India'],2022-11,['industrial']
2211.16912,Minseop Park,"Minseop Park, Jaeseong You, Markus Nagel, Simyung Chang",Quadapter: Adapter for GPT-2 Quantization,,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Transformer language models such as GPT-2 are difficult to quantize because of outliers in activations leading to a large quantization error. To adapt to the error, one must use quantization-aware training, which entails a fine-tuning process based on the dataset and the training pipeline identical to those for the original model. Pretrained language models, however, often do not grant access to their datasets and training pipelines, forcing us to rely on arbitrary ones for fine-tuning. In that case, it is observed that quantization-aware training overfits the model to the fine-tuning data. For quantization without overfitting, we introduce a quantization adapter (Quadapter), a small set of parameters that are learned to make activations quantization-friendly by scaling them channel-wise. It keeps the model parameters unchanged. By applying our method to the challenging task of quantizing GPT-2, we demonstrate that it effectively prevents the overfitting and improves the quantization performance. ","[{'version': 'v1', 'created': 'Wed, 30 Nov 2022 11:20:33 GMT'}]",2022-12-01,"[['Park', 'Minseop', ''], ['You', 'Jaeseong', ''], ['Nagel', 'Markus', ''], ['Chang', 'Simyung', '']]",0,1,2022-11-30,1,4,1,1,1,0,3d4923d3ccf09334023e2bad293cd84f91105ffe,254096429.0,https://www.semanticscholar.org/paper/3d4923d3ccf09334023e2bad293cd84f91105ffe,Conference on Empirical Methods in Natural Language Processing,2022.0,26.0,5.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144568677', 'name': 'Minseop Park'}, {'authorId': '2629994', 'name': 'J. You'}, {'authorId': '41229153', 'name': 'Markus Nagel'}, {'authorId': '26375572', 'name': 'Simyung Chang'}]","['Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc.']",,2022-11,['industrial']
2212.00193,Kumar Shridhar,"Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan",Distilling Reasoning Capabilities into Smaller Language Models,Accepted at ACL 2023 (Findings),,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Step-by-step reasoning approaches like chain of thought (CoT) have proved to be very effective in inducing reasoning capabilities in large language models. However, the success of the CoT approach is fundamentally tied to the model size, and billion parameter-scale models are often needed to get CoT to work. In this paper, we propose a knowledge distillation approach that leverages the step-by-step CoT reasoning capabilities of larger models and distills these abilities into smaller models.   In this work, we propose an alternative reasoning scheme, Socratic CoT, that learns a decomposition of the original problem into a sequence of subproblems and uses it to guide the intermediate reasoning steps. We use Socratic CoT to train a combination of two small distilled models: a problem decomposer and a subproblem solver. In practice, given a new problem, the two distilled models work in sync to decompose and solve complex problems. On multiple reasoning datasets (GSM8K, StrategyQA, and SVAMP), our proposed distillation strategies boosts the performance of smaller models over 70% compared to the baselines. Finally, we investigate when Socratic CoT is an effective alternative to CoT, demonstrating cases where a much smaller model (GPT-2 large) can outperform a 10X larger model (GPT-3 6B). Our code is available here: https://github.com/kumar-shridhar/Distiiling-LM ","[{'version': 'v1', 'created': 'Thu, 1 Dec 2022 00:39:56 GMT'}, {'version': 'v2', 'created': 'Thu, 18 May 2023 04:44:51 GMT'}]",2023-05-19,"[['Shridhar', 'Kumar', ''], ['Stolfo', 'Alessandro', ''], ['Sachan', 'Mrinmaya', '']]",0,1,2022-12-01,2,3,2,2,1,1,8fd462f6248d5e3f1b6602697c09489086b5655f,258762841.0,https://www.semanticscholar.org/paper/8fd462f6248d5e3f1b6602697c09489086b5655f,Annual Meeting of the Association for Computational Linguistics,2022.0,43.0,19.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50812160', 'name': 'K. Shridhar'}, {'authorId': '2175480389', 'name': 'Alessandro Stolfo'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]",['ETH Zurich'],['Switzerland'],2022-12,['industrial']
2212.01757,Siddharth Patwardhan,"Benjamin Muller, Deepanshu Gupta, Siddharth Patwardhan, Jean-Philippe
  Fauconnier, David Vandyke, Sachin Agarwal",Languages You Know Influence Those You Learn: Impact of Language Characteristics on Multi-Lingual Text-to-Text Transfer,"In NeurIPS Workshop on Transfer Learning for Natural Language
  Processing, 2022, New Orleans. 15 pages, 8 figures, 5 tables",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Multi-lingual language models (LM), such as mBERT, XLM-R, mT5, mBART, have been remarkably successful in enabling natural language tasks in low-resource languages through cross-lingual transfer from high-resource ones. In this work, we try to better understand how such models, specifically mT5, transfer *any* linguistic and semantic knowledge across languages, even though no explicit cross-lingual signals are provided during pre-training. Rather, only unannotated texts from each language are presented to the model separately and independently of one another, and the model appears to implicitly learn cross-lingual connections. This raises several questions that motivate our study, such as: Are the cross-lingual connections between every language pair equally strong? What properties of source and target language impact the strength of cross-lingual transfer? Can we quantify the impact of those properties on the cross-lingual transfer?   In our investigation, we analyze a pre-trained mT5 to discover the attributes of cross-lingual connections learned by the model. Through a statistical interpretation framework over 90 language pairs across three tasks, we show that transfer performance can be modeled by a few linguistic and data-derived features. These observations enable us to interpret cross-lingual understanding of the mT5 model. Through these observations, one can favorably choose the best source language for a task, and can anticipate its training data demands. A key finding of this work is that similarity of syntax, morphology and phonology are good predictors of cross-lingual transfer, significantly more than just the lexical similarity of languages. For a given language, we are able to predict zero-shot performance, that increases on a logarithmic scale with the number of few-shot target language data points. ","[{'version': 'v1', 'created': 'Sun, 4 Dec 2022 07:22:21 GMT'}]",2022-12-06,"[['Muller', 'Benjamin', ''], ['Gupta', 'Deepanshu', ''], ['Patwardhan', 'Siddharth', ''], ['Fauconnier', 'Jean-Philippe', ''], ['Vandyke', 'David', ''], ['Agarwal', 'Sachin', '']]",0,0,2022-12-04,1,6,3,1,1,0,2e0caf5cc32390692eac3f9c7bdf5de3b19f7e04,254246695.0,https://www.semanticscholar.org/paper/2e0caf5cc32390692eac3f9c7bdf5de3b19f7e04,TL4NLP,2022.0,39.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '150045488', 'name': 'Benjamin Muller'}, {'authorId': '2085030068', 'name': 'Deepanshu Gupta'}, {'authorId': '2106189043', 'name': 'Siddharth Patwardhan'}, {'authorId': '1816732', 'name': 'J. Fauconnier'}, {'authorId': '92480907', 'name': 'David Vandyke'}, {'authorId': '2114357803', 'name': 'Sachin Agarwal'}]","['Apple', 'French Institute for Research in Computer Science and Automation']","['United States', 'France']",2022-12,"['industrial', 'industrial']"
2212.02199,Dietrich Trautmann,"Dietrich Trautmann, Alina Petrova, Frank Schilder",Legal Prompt Engineering for Multilingual Legal Judgement Prediction,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Legal Prompt Engineering (LPE) or Legal Prompting is a process to guide and assist a large language model (LLM) with performing a natural legal language processing (NLLP) skill. Our goal is to use LPE with LLMs over long legal documents for the Legal Judgement Prediction (LJP) task. We investigate the performance of zero-shot LPE for given facts in case-texts from the European Court of Human Rights (in English) and the Federal Supreme Court of Switzerland (in German, French and Italian). Our results show that zero-shot LPE is better compared to the baselines, but it still falls short compared to current state of the art supervised approaches. Nevertheless, the results are important, since there was 1) no explicit domain-specific data used - so we show that the transfer to the legal domain is possible for general-purpose LLMs, and 2) the LLMs where directly applied without any further training or fine-tuning - which in turn saves immensely in terms of additional computational costs. ","[{'version': 'v1', 'created': 'Mon, 5 Dec 2022 12:17:02 GMT'}]",2022-12-06,"[['Trautmann', 'Dietrich', ''], ['Petrova', 'Alina', ''], ['Schilder', 'Frank', '']]",0,0,2022-12-05,1,3,2,0,0,0,ec27f85979899a4193a8ec3b932ddb677c59be62,254246291.0,https://www.semanticscholar.org/paper/ec27f85979899a4193a8ec3b932ddb677c59be62,arXiv.org,2022.0,30.0,20.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}]","[{'authorId': '2628264', 'name': 'Dietrich Trautmann'}, {'authorId': '3355396', 'name': 'Alina Petrova'}, {'authorId': '145837551', 'name': 'Frank Schilder'}]","['Thomson Reuters Labs, Eagan, MN, United States of America', 'Thomson Reuters Labs, Zug, Switzerland', 'Thomson Reuters Foundation']","['United States', 'United Kingdom', 'Switzerland']",2022-12,"['industrial', 'industrial', 'industrial']"
2212.06094,Marc Fischer,"Luca Beurer-Kellner, Marc Fischer, Martin Vechev",Prompting Is Programming: A Query Language for Large Language Models,"To be published at PLDI'23: 44th ACM SIGPLAN International Conference
  on Programming Language Design and Implementation",,10.1145/3591300,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large language models have demonstrated outstanding performance on a wide range of tasks such as question answering and code generation. On a high level, given an input, a language model can be used to automatically complete the sequence in a statistically-likely way. Based on this, users prompt these models with language instructions or examples, to implement a variety of downstream tasks. Advanced prompting methods can even imply interaction between the language model, a user, and external tools such as calculators. However, to obtain state-of-the-art performance or adapt language models for specific tasks, complex task- and model-specific programs have to be implemented, which may still require ad-hoc interaction.   Based on this, we present the novel idea of Language Model Programming (LMP). LMP generalizes language model prompting from pure text prompts to an intuitive combination of text prompting and scripting. Additionally, LMP allows constraints to be specified over the language model output. This enables easy adaption to many tasks while abstracting language model internals and providing high-level semantics.   To enable LMP, we implement LMQL(short for Language Model Query Language), which leverages the constraints and control flow from an LMP prompt to generate an efficient inference procedure that minimizes the number of expensive calls to the underlying language model.   We show that LMQL can capture a wide range of state-of-the-art prompting methods in an intuitive way, especially facilitating interactive flows that are challenging to implement with existing high-level APIs. Our evaluation shows that we retain or increase the accuracy on several downstream tasks, while also significantly reducing the required amount of computation or cost in the case of pay-to-use APIs (26-85% cost savings). ","[{'version': 'v1', 'created': 'Mon, 12 Dec 2022 18:09:09 GMT'}, {'version': 'v2', 'created': 'Wed, 26 Apr 2023 15:11:38 GMT'}, {'version': 'v3', 'created': 'Tue, 30 May 2023 12:56:41 GMT'}]",2023-05-31,"[['Beurer-Kellner', 'Luca', ''], ['Fischer', 'Marc', ''], ['Vechev', 'Martin', '']]",0,0,2022-12-12,3,3,2,0,0,0,c2329c685f11efa25c562f97be71ff03103423fd,254564450.0,https://www.semanticscholar.org/paper/c2329c685f11efa25c562f97be71ff03103423fd,Proc. ACM Program. Lang.,2022.0,42.0,29.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2150869869', 'name': 'Luca Beurer-Kellner'}, {'authorId': '48849093', 'name': 'Marc Fischer'}, {'authorId': '1736447', 'name': 'Martin T. Vechev'}]","['Martin Vechev, ETH Zurich, Switzerland', 'ETH Zurich']",['Switzerland'],2022-12,"['industrial', 'industrial']"
2212.06573,Yiting Qu,"Yiting Qu, Xinlei He, Shannon Pierson, Michael Backes, Yang Zhang,
  Savvas Zannettou",On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning,"To Appear in the 44th IEEE Symposium on Security and Privacy, May
  22-25, 2023",,,,cs.SI cs.CR cs.CY cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The dissemination of hateful memes online has adverse effects on social media platforms and the real world. Detecting hateful memes is challenging, one of the reasons being the evolutionary nature of memes; new hateful memes can emerge by fusing hateful connotations with other cultural ideas or symbols. In this paper, we propose a framework that leverages multimodal contrastive learning models, in particular OpenAI's CLIP, to identify targets of hateful content and systematically investigate the evolution of hateful memes. We find that semantic regularities exist in CLIP-generated embeddings that describe semantic relationships within the same modality (images) or across modalities (images and text). Leveraging this property, we study how hateful memes are created by combining visual elements from multiple images or fusing textual information with a hateful image. We demonstrate the capabilities of our framework for analyzing the evolution of hateful memes by focusing on antisemitic memes, particularly the Happy Merchant meme. Using our framework on a dataset extracted from 4chan, we find 3.3K variants of the Happy Merchant meme, with some linked to specific countries, persons, or organizations. We envision that our framework can be used to aid human moderators by flagging new variants of hateful memes so that moderators can manually verify them and mitigate the problem of hateful content online. ","[{'version': 'v1', 'created': 'Tue, 13 Dec 2022 13:38:04 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Jul 2023 14:24:04 GMT'}]",2023-07-10,"[['Qu', 'Yiting', ''], ['He', 'Xinlei', ''], ['Pierson', 'Shannon', ''], ['Backes', 'Michael', ''], ['Zhang', 'Yang', ''], ['Zannettou', 'Savvas', '']]",0,0,2022-12-13,2,6,4,0,0,0,c29e3d050612175023a7c4bbb166181208c1bd6d,254591373.0,https://www.semanticscholar.org/paper/c29e3d050612175023a7c4bbb166181208c1bd6d,IEEE Symposium on Security and Privacy,2022.0,71.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2158023237', 'name': 'Y. Qu'}, {'authorId': '2116553732', 'name': 'Xinlei He'}, {'authorId': '100914066', 'name': 'S. Pierson'}, {'authorId': '144588806', 'name': 'M. Backes'}, {'authorId': '1698138', 'name': 'Yang Zhang'}, {'authorId': '3447293', 'name': 'Savvas Zannettou'}]","['Xinlei He Shannon Pierson Michael Backes', 'Helmholtz Center for Information Security']",['Germany'],2022-12,"['industrial', 'industrial']"
2212.06721,David Noever,"David Noever, Matt Ciolino",The Turing Deception,,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This research revisits the classic Turing test and compares recent large language models such as ChatGPT for their abilities to reproduce human-level comprehension and compelling text generation. Two task challenges -- summarization, and question answering -- prompt ChatGPT to produce original content (98-99%) from a single text entry and also sequential questions originally posed by Turing in 1950. We score the original and generated content against the OpenAI GPT-2 Output Detector from 2019, and establish multiple cases where the generated content proves original and undetectable (98%). The question of a machine fooling a human judge recedes in this work relative to the question of ""how would one prove it?"" The original contribution of the work presents a metric and simple grammatical set for understanding the writing mechanics of chatbots in evaluating their readability and statistical clarity, engagement, delivery, and overall quality. While Turing's original prose scores at least 14% below the machine-generated output, the question of whether an algorithm displays hints of Turing's truly original thoughts (the ""Lovelace 2.0"" test) remains unanswered and potentially unanswerable for now. ","[{'version': 'v1', 'created': 'Fri, 9 Dec 2022 16:32:11 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Dec 2022 21:41:36 GMT'}]",2022-12-27,"[['Noever', 'David', ''], ['Ciolino', 'Matt', '']]",1,1,2022-12-09,2,2,3,2,1,1,905c886090f1943da1e44ab2ece7e7659cf5a35c,254591525.0,https://www.semanticscholar.org/paper/905c886090f1943da1e44ab2ece7e7659cf5a35c,International Journal on Cybernetics &amp; Informatics,2022.0,24.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46787948', 'name': 'David Noever'}, {'authorId': '1866333313', 'name': 'Matt Ciolino'}]",['PeopleTec (United States)'],['United States'],2022-12,['industrial']
2212.07919,Olga Golovneva,"Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke
  Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz",ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer) is difficult without reliable methods for automatic evaluation. We simply do not know how often the stated reasoning steps actually support the final end task predictions. In this work, we present ROSCOE, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a typology of reasoning errors and collect synthetic and human evaluation scores on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE can measure semantic consistency, logicality, informativeness, fluency, and factuality - among other traits - by leveraging properties of step-by-step rationales. We empirically verify the strength of our metrics on five human annotated and six programmatically perturbed diagnostics datasets - covering a diverse set of tasks that require reasoning skills and show that ROSCOE can consistently outperform baseline metrics. ","[{'version': 'v1', 'created': 'Thu, 15 Dec 2022 15:52:39 GMT'}, {'version': 'v2', 'created': 'Tue, 12 Sep 2023 15:08:46 GMT'}]",2023-09-13,"[['Golovneva', 'Olga', ''], ['Chen', 'Moya', ''], ['Poff', 'Spencer', ''], ['Corredor', 'Martin', ''], ['Zettlemoyer', 'Luke', ''], ['Fazel-Zarandi', 'Maryam', ''], ['Celikyilmaz', 'Asli', '']]",0,0,2022-12-15,2,7,2,0,0,0,391246ce9c59d61c94cca3f8bef56c95542a4708,254685985.0,https://www.semanticscholar.org/paper/391246ce9c59d61c94cca3f8bef56c95542a4708,arXiv.org,2022.0,54.0,41.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '100664938', 'name': 'O. Yu. Golovneva'}, {'authorId': '2108267192', 'name': 'Moya Chen'}, {'authorId': '1753626755', 'name': 'Spencer Poff'}, {'authorId': '2197061658', 'name': 'Martin Corredor'}, {'authorId': '1982950', 'name': 'Luke Zettlemoyer'}, {'authorId': '1399159921', 'name': 'Maryam Fazel-Zarandi'}, {'authorId': '1709797', 'name': 'Asli Celikyilmaz'}]",['Meta'],['United States'],2022-12,['industrial']
2212.07993,David Dowell,"David H. Dowell, Munther Hindi, S.B. van der Geer and M. J. de Loos",Combining Particle Tracking with Electromagnetic Radiation Showers: Merging GPT and Geant4 with Visualization,,,,,physics.acc-ph,http://creativecommons.org/licenses/by/4.0/,"  Field emitted electrons can seriously affect the operation of high-field, high-duty factor electron accelerators. Accelerated field emission can result in high average power beams which can radiation damage beamline components. In addition, localized losses generate thermal hot spots whose outgassing degrades the ultra-high vacuum required in photoinjectors and cryomodules. However, despite their importance, the effects of field emission are rarely included in the design and engineering of electron injectors. This work attempts to remedy this situation by combining two well-known and well-documented programs, GPT and Geant4, to track electrons and their losses in an injector beamline. This paper describes a system of programs which simulates electron paths and losses along the beamline. In addition, the tracking results can be zoomed and panned along and about the beampipe envelope using an open-source 3D CAD program. The scattering albedo calculations of the combined program, GPT-Geant4, are shown to be in good agreement with the literature albedos. The paper concludes with a dark current simulation for the LCLS-II injector from the cathode to the collimator at 1.5 m from the cathode. ","[{'version': 'v1', 'created': 'Thu, 15 Dec 2022 17:46:58 GMT'}]",2022-12-16,"[['Dowell', 'David H.', ''], ['Hindi', 'Munther', ''], ['van der Geer', 'S. B.', ''], ['de Loos', 'M. J.', '']]",0,1,2022-12-15,1,4,1,0,0,0,e109c390bf1a8e63a07d604f505bda0c9f75e925,254685856.0,https://www.semanticscholar.org/paper/e109c390bf1a8e63a07d604f505bda0c9f75e925,,2022.0,8.0,1.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '10316820', 'name': 'D. Dowell'}, {'authorId': '2043056616', 'name': 'M. Hindi'}, {'authorId': '21738201', 'name': 'S. Geer'}, {'authorId': '38967434', 'name': 'M. Loos'}]","['Pulsar Physics', 'SLAC National Accelerator Laboratory', 'Linac Coherent Light Source', 'Independent Researcher']",['United States'],2022-12,"['industrial', 'industrial', 'industrial', 'industrial']"
2212.10029,Yuling Gu,"Yuling Gu, Bhavana Dalvi Mishra, Peter Clark",Do language models have coherent mental models of everyday things?,ACL 2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  When people think of everyday things like an egg, they typically have a mental image associated with it. This allows them to correctly judge, for example, that ""the yolk surrounds the shell"" is a false statement. Do language models similarly have a coherent picture of such everyday things? To investigate this, we propose a benchmark dataset consisting of 100 everyday things, their parts, and the relationships between these parts, expressed as 11,720 ""X relation Y?"" true/false questions. Using these questions as probes, we observe that state-of-the-art pre-trained language models (LMs) like GPT-3 and Macaw have fragments of knowledge about these everyday things, but do not have fully coherent ""parts mental models"" (54-59% accurate, 19-43% conditional constraint violation). We propose an extension where we add a constraint satisfaction layer on top of the LM's raw predictions to apply commonsense constraints. As well as removing inconsistencies, we find that this also significantly improves accuracy (by 16-20%), suggesting how the incoherence of the LM's pictures of everyday things can be significantly reduced. ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 06:54:04 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 20:40:18 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Jun 2023 17:27:44 GMT'}]",2023-06-09,"[['Gu', 'Yuling', ''], ['Mishra', 'Bhavana Dalvi', ''], ['Clark', 'Peter', '']]",0,1,2022-12-20,3,3,2,1,0,1,5bfeb86095a9b6634a9dc7053c0aa184f6807db4,254877558.0,https://www.semanticscholar.org/paper/5bfeb86095a9b6634a9dc7053c0aa184f6807db4,Annual Meeting of the Association for Computational Linguistics,2022.0,38.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51299053', 'name': 'Yuling Gu'}, {'authorId': '40135250', 'name': 'Bhavana Dalvi'}, {'authorId': '48323507', 'name': 'Peter Clark'}]",['Allen Institute for Artificial Intelligence'],['United States'],2022-12,['industrial']
2212.11126,David Noever,"Forrest McKee, David Noever",Chatbots in a Botnet World,,,,,cs.CR cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Question-and-answer formats provide a novel experimental platform for investigating cybersecurity questions. Unlike previous chatbots, the latest ChatGPT model from OpenAI supports an advanced understanding of complex coding questions. The research demonstrates thirteen coding tasks that generally qualify as stages in the MITRE ATT&CK framework, ranging from credential access to defense evasion. With varying success, the experimental prompts generate examples of keyloggers, logic bombs, obfuscated worms, and payment-fulfilled ransomware. The empirical results illustrate cases that support the broad gain of functionality, including self-replication and self-modification, evasion, and strategic understanding of complex cybersecurity goals. One surprising feature of ChatGPT as a language-only model centers on its ability to spawn coding approaches that yield images that obfuscate or embed executable programming steps or links. ","[{'version': 'v1', 'created': 'Sun, 18 Dec 2022 16:08:40 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Dec 2022 17:20:36 GMT'}]",2022-12-23,"[['McKee', 'Forrest', ''], ['Noever', 'David', '']]",1,1,2022-12-18,2,2,3,1,0,1,3b8ccc7ec80b8775de603e248ac1ca2b919d6b70,254926835.0,https://www.semanticscholar.org/paper/3b8ccc7ec80b8775de603e248ac1ca2b919d6b70,International Journal on Cybernetics &amp; Informatics,2022.0,35.0,15.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2197525782', 'name': 'Forrest McKee'}, {'authorId': '46787948', 'name': 'David Noever'}]","['4901-D Corporate Drive, Huntsville, AL, USA, 35805']",['United States'],2022-12,['industrial']
2301.01743,David Noever,"David Noever, Forrest McKee",Chatbots as Problem Solvers: Playing Twenty Questions with Role Reversals,,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  New chat AI applications like ChatGPT offer an advanced understanding of question context and memory across multi-step tasks, such that experiments can test its deductive reasoning. This paper proposes a multi-role and multi-step challenge, where ChatGPT plays the classic twenty-questions game but innovatively switches roles from the questioner to the answerer. The main empirical result establishes that this generation of chat applications can guess random object names in fewer than twenty questions (average, 12) and correctly guess 94% of the time across sixteen different experimental setups. The research introduces four novel cases where the chatbot fields the questions, asks the questions, both question-answer roles, and finally tries to guess appropriate contextual emotions. One task that humans typically fail but trained chat applications complete involves playing bilingual games of twenty questions (English answers to Spanish questions). Future variations address direct problem-solving using a similar inquisitive format to arrive at novel outcomes deductively, such as patentable inventions or combination thinking. Featured applications of this dialogue format include complex protein designs, neuroscience metadata, and child development educational materials. ","[{'version': 'v1', 'created': 'Sun, 1 Jan 2023 03:04:04 GMT'}]",2023-01-05,"[['Noever', 'David', ''], ['McKee', 'Forrest', '']]",1,1,2023-01-01,1,2,2,1,0,1,cc4bac2342a3189a43fc8f63820c74e9b1584828,255415951.0,https://www.semanticscholar.org/paper/cc4bac2342a3189a43fc8f63820c74e9b1584828,arXiv.org,2023.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46787948', 'name': 'David Noever'}, {'authorId': '2197525782', 'name': 'Forrest McKee'}]","['4901-D Corporate Drive, Huntsville, AL, USA, 35805']",['United States'],2023-01,['industrial']
2301.03416,Jiaxiang Liu,"Weixin Liu, Xuyi Chen, Jiaxiang Liu, Shikun Feng, Yu Sun, Hao Tian,
  Hua Wu",ERNIE 3.0 Tiny: Frustratingly Simple Method to Improve Task-Agnostic Distillation Generalization,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Task-agnostic knowledge distillation attempts to address the problem of deploying large pretrained language model in resource-constrained scenarios by compressing a large pretrained model called teacher into a smaller one called student such that the student can be directly finetuned on downstream tasks and retains comparable performance. However, we empirically find that there is a generalization gap between the student and the teacher in existing methods. In this work, we show that we can leverage multi-task learning in task-agnostic distillation to advance the generalization of the resulted student. In particular, we propose Multi-task Infused Task-agnostic Knowledge Distillation (MITKD). We first enhance the teacher by multi-task training it on multiple downstream tasks and then perform distillation to produce the student. Experimental results demonstrate that our method yields a student with much better generalization, significantly outperforms existing baselines, and establishes a new state-of-the-art result on in-domain, out-domain, and low-resource datasets in the setting of task-agnostic distillation. Moreover, our method even exceeds an 8x larger BERT$_{\text{Base}}$ on SQuAD and four GLUE tasks. In addition, by combining ERNIE 3.0, our method achieves state-of-the-art results on 10 Chinese datasets. ","[{'version': 'v1', 'created': 'Mon, 9 Jan 2023 15:12:50 GMT'}]",2023-01-10,"[['Liu', 'Weixin', ''], ['Chen', 'Xuyi', ''], ['Liu', 'Jiaxiang', ''], ['Feng', 'Shikun', ''], ['Sun', 'Yu', ''], ['Tian', 'Hao', ''], ['Wu', 'Hua', '']]",0,0,2023-01-09,1,7,1,1,0,1,44d02cf6cd5ab64a2eaa3f724545ca849cecc164,255546131.0,https://www.semanticscholar.org/paper/44d02cf6cd5ab64a2eaa3f724545ca849cecc164,arXiv.org,2023.0,98.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109563578', 'name': 'Weixin Liu'}, {'authorId': '2109214103', 'name': 'Xuyi Chen'}, {'authorId': '2144130913', 'name': 'Jiaxiang Liu'}, {'authorId': '144588144', 'name': 'Shi Feng'}, {'authorId': '2117103617', 'name': 'Yu Sun'}, {'authorId': '50007795', 'name': 'Hao Tian'}, {'authorId': '2190177674', 'name': 'Hua Wu'}]",['Baidu'],['China'],2023-01,['industrial']
2301.03771,David Noever,"Forrest McKee, David Noever",Chatbots in a Honeypot World,,,,,cs.CR cs.CY cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Question-and-answer agents like ChatGPT offer a novel tool for use as a potential honeypot interface in cyber security. By imitating Linux, Mac, and Windows terminal commands and providing an interface for TeamViewer, nmap, and ping, it is possible to create a dynamic environment that can adapt to the actions of attackers and provide insight into their tactics, techniques, and procedures (TTPs). The paper illustrates ten diverse tasks that a conversational agent or large language model might answer appropriately to the effects of command-line attacker. The original result features feasibility studies for ten model tasks meant for defensive teams to mimic expected honeypot interfaces with minimal risks. Ultimately, the usefulness outside of forensic activities stems from whether the dynamic honeypot can extend the time-to-conquer or otherwise delay attacker timelines short of reaching key network assets like databases or confidential information. While ongoing maintenance and monitoring may be required, ChatGPT's ability to detect and deflect malicious activity makes it a valuable option for organizations seeking to enhance their cyber security posture. Future work will focus on cybersecurity layers, including perimeter security, host virus detection, and data security. ","[{'version': 'v1', 'created': 'Tue, 10 Jan 2023 03:43:35 GMT'}]",2023-01-11,"[['McKee', 'Forrest', ''], ['Noever', 'David', '']]",1,1,2023-01-10,1,2,3,1,0,1,c0f3072aeab373fd64c98126afe1b3964ed3438d,255569854.0,https://www.semanticscholar.org/paper/c0f3072aeab373fd64c98126afe1b3964ed3438d,arXiv.org,2023.0,28.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2197525782', 'name': 'Forrest McKee'}, {'authorId': '46787948', 'name': 'David Noever'}]","['4901-D Corporate Drive, Huntsville, AL, USA, 35805 1']",['United States'],2023-01,['industrial']
2301.08745,Wenxiang Jiao,"Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, Zhaopeng Tu",Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine,8 pages; added GPT-3 data statistics reference; added GPT-4 results,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This report provides a preliminary evaluation of ChatGPT for machine translation, including translation prompt, multilingual translation, and translation robustness. We adopt the prompts advised by ChatGPT to trigger its translation ability and find that the candidate prompts generally work well and show minor performance differences. By evaluating on a number of benchmark test sets, we find that ChatGPT performs competitively with commercial translation products (e.g., Google Translate) on high-resource European languages but lags behind significantly on low-resource or distant languages. For distant languages, we explore an interesting strategy named $\mathbf{pivot~prompting}$ that asks ChatGPT to translate the source sentence into a high-resource pivot language before into the target language, which improves the translation performance significantly. As for the translation robustness, ChatGPT does not perform as well as the commercial systems on biomedical abstracts or Reddit comments but exhibits good results on spoken language. With the launch of the GPT-4 engine, the translation performance of ChatGPT is significantly boosted, becoming comparable to commercial translation products, even for distant languages. In other words, $\mathbf{ChatGPT~has~already~become~a~good~translator!}$ Scripts and data: https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator ","[{'version': 'v1', 'created': 'Fri, 20 Jan 2023 08:51:36 GMT'}, {'version': 'v2', 'created': 'Tue, 31 Jan 2023 16:39:51 GMT'}, {'version': 'v3', 'created': 'Sun, 19 Mar 2023 11:53:20 GMT'}]",2023-03-21,"[['Jiao', 'Wenxiang', ''], ['Wang', 'Wenxuan', ''], ['Huang', 'Jen-tse', ''], ['Wang', 'Xing', ''], ['Tu', 'Zhaopeng', '']]",1,1,2023-01-20,3,5,1,2,0,2,780c99d13537370f63c03feeb1343bed9d98a4f9,257631519.0,https://www.semanticscholar.org/paper/780c99d13537370f63c03feeb1343bed9d98a4f9,,2023.0,28.0,94.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '12386833', 'name': 'Wenxiang Jiao'}, {'authorId': '2144328160', 'name': 'Wenxuan Wang'}, {'authorId': '2161306685', 'name': 'Jen-tse Huang'}, {'authorId': '48631170', 'name': 'Xing Wang'}, {'authorId': '2909321', 'name': 'Zhaopeng Tu'}]",['Tencent'],['China'],2023-01,['industrial']
2301.13382,David Noever,"David Noever, Forrest McKee",Numeracy from Literacy: Data Science as an Emergent Skill from Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Large language models (LLM) such as OpenAI's ChatGPT and GPT-3 offer unique testbeds for exploring the translation challenges of turning literacy into numeracy. Previous publicly-available transformer models from eighteen months prior and 1000 times smaller failed to provide basic arithmetic. The statistical analysis of four complex datasets described here combines arithmetic manipulations that cannot be memorized or encoded by simple rules. The work examines whether next-token prediction succeeds from sentence completion into the realm of actual numerical understanding. For example, the work highlights cases for descriptive statistics on in-memory datasets that the LLM initially loads from memory or generates randomly using python libraries. The resulting exploratory data analysis showcases the model's capabilities to group by or pivot categorical sums, infer feature importance, derive correlations, and predict unseen test cases using linear regression. To extend the model's testable range, the research deletes and appends random rows such that recall alone cannot explain emergent numeracy. ","[{'version': 'v1', 'created': 'Tue, 31 Jan 2023 03:14:57 GMT'}]",2023-02-01,"[['Noever', 'David', ''], ['McKee', 'Forrest', '']]",1,1,2023-01-31,1,2,1,2,0,2,f0ea9e2d3889d37f34743ed1dc64f11e8e0484de,256416333.0,https://www.semanticscholar.org/paper/f0ea9e2d3889d37f34743ed1dc64f11e8e0484de,arXiv.org,2023.0,44.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46787948', 'name': 'David Noever'}, {'authorId': '2197525782', 'name': 'Forrest McKee'}]","['4901-D Corporate Drive, Huntsville, AL, USA, 35805 1']",['United States'],2023-01,['industrial']
2302.01318,Charlie Chen,"Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste
  Lespiau, Laurent Sifre, John Jumper",Accelerating Large Language Model Decoding with Speculative Sampling,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present speculative sampling, an algorithm for accelerating transformer decoding by enabling the generation of multiple tokens from each transformer call. Our algorithm relies on the observation that the latency of parallel scoring of short continuations, generated by a faster but less powerful draft model, is comparable to that of sampling a single token from the larger target model. This is combined with a novel modified rejection sampling scheme which preserves the distribution of the target model within hardware numerics. We benchmark speculative sampling with Chinchilla, a 70 billion parameter language model, achieving a 2-2.5x decoding speedup in a distributed setup, without compromising the sample quality or making modifications to the model itself. ","[{'version': 'v1', 'created': 'Thu, 2 Feb 2023 18:44:11 GMT'}]",2023-02-03,"[['Chen', 'Charlie', ''], ['Borgeaud', 'Sebastian', ''], ['Irving', 'Geoffrey', ''], ['Lespiau', 'Jean-Baptiste', ''], ['Sifre', 'Laurent', ''], ['Jumper', 'John', '']]",0,0,2023-02-02,1,6,1,1,0,1,a1f8082505c7e90b0a033e1b9da0a97d67aad66c,256503945.0,https://www.semanticscholar.org/paper/a1f8082505c7e90b0a033e1b9da0a97d67aad66c,arXiv.org,2023.0,22.0,42.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2182971260', 'name': 'Charlie Chen'}, {'authorId': '148016269', 'name': 'Sebastian Borgeaud'}, {'authorId': '2060655766', 'name': 'G. Irving'}, {'authorId': '143783339', 'name': 'J. Lespiau'}, {'authorId': '2175946', 'name': 'L. Sifre'}, {'authorId': '47921134', 'name': 'J. Jumper'}]",['All authors from DeepMind'],,2023-02,['industrial']
2302.01806,Hoang Nguyen Hung Van,Hoang Van,Mitigating Data Scarcity for Large Language Models,"155 pages, 26 tables, 11 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, pretrained neural language models (PNLMs) have taken the field of natural language processing by storm, achieving new benchmarks and state-of-the-art performances. These models often rely heavily on annotated data, which may not always be available. Data scarcity are commonly found in specialized domains, such as medical, or in low-resource languages that are underexplored by AI research. In this dissertation, we focus on mitigating data scarcity using data augmentation and neural ensemble learning techniques for neural language models. In both research directions, we implement neural network algorithms and evaluate their impact on assisting neural language models in downstream NLP tasks. Specifically, for data augmentation, we explore two techniques: 1) creating positive training data by moving an answer span around its original context and 2) using text simplification techniques to introduce a variety of writing styles to the original training data. Our results indicate that these simple and effective solutions improve the performance of neural language models considerably in low-resource NLP domains and tasks. For neural ensemble learning, we use a multilabel neural classifier to select the best prediction outcome from a variety of individual pretrained neural language models trained for a low-resource medical text simplification task. ","[{'version': 'v1', 'created': 'Fri, 3 Feb 2023 15:17:53 GMT'}]",2023-02-06,"[['Van', 'Hoang', '']]",0,0,2023-02-03,1,1,2,0,0,0,f913a76a0ef09b522feed776f07407cf3d28801a,256598090.0,https://www.semanticscholar.org/paper/f913a76a0ef09b522feed776f07407cf3d28801a,arXiv.org,2023.0,0.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064662741', 'name': 'Hoang Van'}]",['Computer Science Department'],,2023-02,['industrial']
2302.03036,Joe Toplyn,Joe Toplyn,Witscript 2: A System for Generating Improvised Jokes Without Wordplay,"5 pages. Published in the Proceedings of the 13th International
  Conference on Computational Creativity (ICCC 2022), pages 54-58. arXiv admin
  note: text overlap with arXiv:2301.02695. substantial text overlap with
  arXiv:2302.02008",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A previous paper presented Witscript, a system for generating conversational jokes that rely on wordplay. This paper extends that work by presenting Witscript 2, which uses a large language model to generate conversational jokes that rely on common sense instead of wordplay. Like Witscript, Witscript 2 is based on joke-writing algorithms created by an expert comedy writer. Human evaluators judged Witscript 2's responses to input sentences to be jokes 46% of the time, compared to 70% of the time for human-written responses. This is evidence that Witscript 2 represents another step toward giving a chatbot a humanlike sense of humor. ","[{'version': 'v1', 'created': 'Fri, 3 Feb 2023 21:51:55 GMT'}]",2023-02-08,"[['Toplyn', 'Joe', '']]",0,0,2023-02-03,1,1,2,0,0,0,08d15be13c3bbdc203cdc3ec1100a876579bd420,252440664.0,https://www.semanticscholar.org/paper/08d15be13c3bbdc203cdc3ec1100a876579bd420,International Conference on Innovative Computing and Cloud Computing,2023.0,11.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146299920', 'name': 'Joe Toplyn'}]","['Twenty Lane Media, LLC P. O. Box 51 Rye, NY 10580 USA']",['United States'],2023-02,['industrial']
2302.05319,Jingxuan He,Jingxuan He and Martin Vechev,Large Language Models for Code: Security Hardening and Adversarial Testing,Accepted to ACM CCS 2023,,10.1145/3576915.3623175,,cs.CR cs.LG cs.PL cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Large language models (large LMs) are increasingly trained on massive codebases and used to generate code. However, LMs lack awareness of security and are found to frequently produce unsafe code. This work studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs' reliability in generating secure code, and (ii) adversarial testing, which seeks to evaluate LMs' security at an adversarial standpoint. We address both of these by formulating a new security task called controlled code generation. The task is parametric and takes as input a binary property to guide the LM to generate secure or unsafe code, while preserving the LM's capability of generating functionally correct code. We propose a novel learning-based approach called SVEN to solve this task. SVEN leverages property-specific continuous vectors to guide program generation towards the given property, without modifying the LM's weights. Our training procedure optimizes these continuous vectors by enforcing specialized loss terms on different regions of code, using a high-quality dataset carefully curated by us. Our extensive evaluation shows that SVEN is highly effective in achieving strong security control. For instance, a state-of-the-art CodeGen LM with 2.7B parameters generates secure code for 59.1% of the time. When we employ SVEN to perform security hardening (or adversarial testing) on this LM, the ratio is significantly boosted to 92.3% (or degraded to 36.8%). Importantly, SVEN closely matches the original LMs in functional correctness. ","[{'version': 'v1', 'created': 'Fri, 10 Feb 2023 15:28:55 GMT'}, {'version': 'v2', 'created': 'Fri, 5 May 2023 19:08:15 GMT'}, {'version': 'v3', 'created': 'Tue, 12 Sep 2023 11:46:55 GMT'}, {'version': 'v4', 'created': 'Fri, 29 Sep 2023 13:53:43 GMT'}]",2023-10-02,"[['He', 'Jingxuan', ''], ['Vechev', 'Martin', '']]",0,0,2023-02-10,4,2,4,1,1,0,63e2740dc581b4186b4e277a9955e8048c414521,258557402.0,https://www.semanticscholar.org/paper/63e2740dc581b4186b4e277a9955e8048c414521,,2023.0,72.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8516542', 'name': 'Jingxuan He'}, {'authorId': '1736447', 'name': 'Martin T. Vechev'}]",['ETH Zurich'],['Switzerland'],2023-02,['industrial']
2302.05729,Ha Thanh Nguyen,Ha-Thanh Nguyen,A Brief Report on LawGPT 1.0: A Virtual Legal Assistant Based on GPT-3,,,,,cs.CL cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  LawGPT 1.0 is a virtual legal assistant built on the state-of-the-art language model GPT-3, fine-tuned for the legal domain. The system is designed to provide legal assistance to users in a conversational manner, helping them with tasks such as answering legal questions, generating legal documents, and providing legal advice. In this paper, we provide a brief overview of LawGPT 1.0, its architecture, and its performance on a set of legal benchmark tasks. Please note that the detailed information about the model is protected by a non-disclosure agreement (NDA) and cannot be disclosed in this report. ","[{'version': 'v1', 'created': 'Sat, 11 Feb 2023 15:50:20 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Feb 2023 06:26:42 GMT'}]",2023-02-15,"[['Nguyen', 'Ha-Thanh', '']]",0,1,2023-02-11,2,1,2,1,0,1,41b360c5b4ae9c5bfcf3891c45319a9e0b3e6d81,256827839.0,https://www.semanticscholar.org/paper/41b360c5b4ae9c5bfcf3891c45319a9e0b3e6d81,arXiv.org,2023.0,1.0,13.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Law', 'source': 's2-fos-model'}]","[{'authorId': '2716209', 'name': 'Nguyen Ha Thanh'}]",['National Institute of Informatics'],['Japan'],2023-02,['industrial']
2302.06716,Elizabeth Merkhofer,"Elizabeth Merkhofer, Deepesh Chaudhari, Hyrum S. Anderson, Keith
  Manville, Lily Wong, Jo\~ao Gante",Machine Learning Model Attribution Challenge,,,,,cs.LG cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present the findings of the Machine Learning Model Attribution Challenge. Fine-tuned machine learning models may derive from other trained models without obvious attribution characteristics. In this challenge, participants identify the publicly-available base models that underlie a set of anonymous, fine-tuned large language models (LLMs) using only textual output of the models. Contestants aim to correctly attribute the most fine-tuned models, with ties broken in the favor of contestants whose solutions use fewer calls to the fine-tuned models' API. The most successful approaches were manual, as participants observed similarities between model outputs and developed attribution heuristics based on public documentation of the base models, though several teams also submitted automated, statistical solutions. ","[{'version': 'v1', 'created': 'Mon, 13 Feb 2023 22:05:27 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Feb 2023 14:43:59 GMT'}, {'version': 'v3', 'created': 'Fri, 17 Feb 2023 15:48:46 GMT'}]",2023-02-20,"[['Merkhofer', 'Elizabeth', ''], ['Chaudhari', 'Deepesh', ''], ['Anderson', 'Hyrum S.', ''], ['Manville', 'Keith', ''], ['Wong', 'Lily', ''], ['Gante', 'João', '']]",0,0,2023-02-13,3,6,3,0,0,0,172fcc92100ddd8691c787cb91e6f3d04cdd3100,256846569.0,https://www.semanticscholar.org/paper/172fcc92100ddd8691c787cb91e6f3d04cdd3100,arXiv.org,2023.0,11.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2205657530', 'name': 'Elizabeth Merkhofe'}, {'authorId': '2146692648', 'name': 'Deepesh Chaudhari'}, {'authorId': '2639880', 'name': 'H. Anderson'}, {'authorId': '51218583', 'name': 'Keith Manville'}, {'authorId': '2184600561', 'name': 'Lily Wong'}, {'authorId': '145369749', 'name': 'João Gante'}]","['Robust Intelligence', 'MITRE Corporation', 'Plaintext Group']",,2023-02,"['industrial', 'industrial', 'industrial']"
2302.11054,Lu Zeng,"Sree Hari Krishnan Parthasarathi, Lu Zeng, Dilek Hakkani-Tur",Conversational Text-to-SQL: An Odyssey into State-of-the-Art and Challenges Ahead,Accepted for publication at ICASSP 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Conversational, multi-turn, text-to-SQL (CoSQL) tasks map natural language utterances in a dialogue to SQL queries. State-of-the-art (SOTA) systems use large, pre-trained and finetuned language models, such as the T5-family, in conjunction with constrained decoding. With multi-tasking (MT) over coherent tasks with discrete prompts during training, we improve over specialized text-to-SQL T5-family models. Based on Oracle analyses over n-best hypotheses, we apply a query plan model and a schema linking algorithm as rerankers. Combining MT and reranking, our results using T5-3B show absolute accuracy improvements of 1.0% in exact match and 3.4% in execution match over a SOTA baseline on CoSQL. While these gains consistently manifest at turn level, context dependent turns are considerably harder. We conduct studies to tease apart errors attributable to domain and compositional generalization, with the latter remaining a challenge for multi-turn conversations, especially in generating SQL with unseen parse trees. ","[{'version': 'v1', 'created': 'Tue, 21 Feb 2023 23:15:33 GMT'}]",2023-02-23,"[['Parthasarathi', 'Sree Hari Krishnan', ''], ['Zeng', 'Lu', ''], ['Hakkani-Tur', 'Dilek', '']]",0,0,2023-02-21,1,3,1,1,1,0,7678d1862140d84f9c15d95e7d4d085857f332eb,257078882.0,https://www.semanticscholar.org/paper/7678d1862140d84f9c15d95e7d4d085857f332eb,"IEEE International Conference on Acoustics, Speech, and Signal Processing",2023.0,27.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2181961', 'name': 'S. Parthasarathi'}, {'authorId': '2176186004', 'name': 'Lu Zeng'}, {'authorId': '1395813836', 'name': 'Dilek Z. Hakkani-Tür'}]",['Amazon'],['United States'],2023-02,['industrial']
2302.12367,Mian Zhong,"Mian Zhong, Shehzaad Dhuliawala, Niklas Stoehr",Extracting Victim Counts from Text,Long paper accepted at EACL 2023 main conference,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Decision-makers in the humanitarian sector rely on timely and exact information during crisis events. Knowing how many civilians were injured during an earthquake is vital to allocate aids properly. Information about such victim counts is often only available within full-text event descriptions from newspapers and other reports. Extracting numbers from text is challenging: numbers have different formats and may require numeric reasoning. This renders purely string matching-based approaches insufficient. As a consequence, fine-grained counts of injured, displaced, or abused victims beyond fatalities are often not extracted and remain unseen. We cast victim count extraction as a question answering (QA) task with a regression or classification objective. We compare regex, dependency parsing, semantic role labeling-based approaches, and advanced text-to-text models. Beyond model accuracy, we analyze extraction reliability and robustness which are key for this sensitive task. In particular, we discuss model calibration and investigate few-shot and out-of-distribution performance. Ultimately, we make a comprehensive recommendation on which model to select for different desiderata and data domains. Our work is among the first to apply numeracy-focused large language models in a real-world use case with a positive impact. ","[{'version': 'v1', 'created': 'Thu, 23 Feb 2023 23:50:24 GMT'}]",2023-02-27,"[['Zhong', 'Mian', ''], ['Dhuliawala', 'Shehzaad', ''], ['Stoehr', 'Niklas', '']]",0,0,2023-02-23,1,3,3,0,0,0,032962bfc563e2caf986d3b3746f3217303be1b0,257205955.0,https://www.semanticscholar.org/paper/032962bfc563e2caf986d3b3746f3217303be1b0,Conference of the European Chapter of the Association for Computational Linguistics,2023.0,67.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143562289', 'name': 'Mian Zhong'}, {'authorId': '3448411', 'name': 'S. Dhuliawala'}, {'authorId': '2121363803', 'name': 'Niklas Stoehr'}]",['ETH Zurich'],['Switzerland'],2023-02,['industrial']
2302.12369,Naoyuki Kanda,"Naoyuki Kanda, Takuya Yoshioka, Yang Liu",Factual Consistency Oriented Speech Recognition,"5 pages, 1 figure, 3 tables",,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a novel optimization framework for automatic speech recognition (ASR) with the aim of reducing hallucinations produced by an ASR model. The proposed framework optimizes the ASR model to maximize an expected factual consistency score between ASR hypotheses and ground-truth transcriptions, where the factual consistency score is computed by a separately trained estimator. Experimental results using the AMI meeting corpus and the VoxPopuli corpus show that the ASR model trained with the proposed framework generates ASR hypotheses that have significantly higher consistency scores with ground-truth transcriptions while maintaining the word error rates close to those of cross entropy-trained ASR models. Furthermore, it is shown that training the ASR models with the proposed framework improves the speech summarization quality as measured by the factual consistency of meeting conversation summaries generated by a large language model. ","[{'version': 'v1', 'created': 'Fri, 24 Feb 2023 00:01:41 GMT'}]",2023-02-27,"[['Kanda', 'Naoyuki', ''], ['Yoshioka', 'Takuya', ''], ['Liu', 'Yang', '']]",0,0,2023-02-24,1,3,3,0,0,0,979a68d069fe7b41105085e9c6182da5058665b6,257205767.0,https://www.semanticscholar.org/paper/979a68d069fe7b41105085e9c6182da5058665b6,Interspeech,2023.0,45.0,0.0,0.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1833359', 'name': 'Naoyuki Kanda'}, {'authorId': '34638725', 'name': 'Takuya Yoshioka'}, {'authorId': '40457423', 'name': 'Yang Liu'}]",['Microsoft'],['United States'],2023-02,['industrial']
2302.14389,Alexandre Pasquiou,"Alexandre Pasquiou, Yair Lakretz, Bertrand Thirion, Christophe Pallier","Information-Restricted Neural Language Models Reveal Different Brain Regions' Sensitivity to Semantics, Syntax and Context","19 pages, 8 figures, 10 pages of Appendix, 5 appendix figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  A fundamental question in neurolinguistics concerns the brain regions involved in syntactic and semantic processing during speech comprehension, both at the lexical (word processing) and supra-lexical levels (sentence and discourse processing). To what extent are these regions separated or intertwined? To address this question, we trained a lexical language model, Glove, and a supra-lexical language model, GPT-2, on a text corpus from which we selectively removed either syntactic or semantic information. We then assessed to what extent these information-restricted models were able to predict the time-courses of fMRI signal of humans listening to naturalistic text. We also manipulated the size of contextual information provided to GPT-2 in order to determine the windows of integration of brain regions involved in supra-lexical processing. Our analyses show that, while most brain regions involved in language are sensitive to both syntactic and semantic variables, the relative magnitudes of these effects vary a lot across these regions. Furthermore, we found an asymmetry between the left and right hemispheres, with semantic and syntactic processing being more dissociated in the left hemisphere than in the right, and the left and right hemispheres showing respectively greater sensitivity to short and long contexts. The use of information-restricted NLP models thus shed new light on the spatial organization of syntactic processing, semantic processing and compositionality. ","[{'version': 'v1', 'created': 'Tue, 28 Feb 2023 08:16:18 GMT'}]",2023-03-01,"[['Pasquiou', 'Alexandre', ''], ['Lakretz', 'Yair', ''], ['Thirion', 'Bertrand', ''], ['Pallier', 'Christophe', '']]",0,1,2023-02-28,1,4,1,1,1,0,71226f3f7844de23f6ac464a75597b3e28462933,257232607.0,https://www.semanticscholar.org/paper/71226f3f7844de23f6ac464a75597b3e28462933,Neurobiology of Language,2023.0,93.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '2175249740', 'name': 'Alexandre Pasquiou'}, {'authorId': '3051598', 'name': 'Yair Lakretz'}, {'authorId': '8493461', 'name': 'B. Thirion'}, {'authorId': '7892142', 'name': 'Christophe Pallier'}]","['Inserm', 'French Institute for Research in Computer Science and Automation']",['France'],2023-02,"['industrial', 'industrial']"
2302.14691,Seonghyeon Ye,"Seonghyeon Ye, Hyeonbin Hwang, Sohee Yang, Hyeongu Yun, Yireun Kim,
  Minjoon Seo",In-Context Instruction Learning,Work In Progress,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Instruction learning of Large Language Models (LLMs) has enabled zero-shot task generalization. However, instruction learning has been predominantly approached as a fine-tuning problem, including instruction tuning and reinforcement learning from human feedback, where LLMs are multi-task fine-tuned on various tasks with instructions. In this paper, we present a surprising finding that applying in-context learning to instruction learning, referred to as In-Context Instruction Learning (ICIL), significantly improves the zero-shot task generalization performance for both pretrained and instruction-fine-tuned models. One of the core advantages of ICIL is that it uses a single fixed prompt to evaluate all tasks, which is a concatenation of cross-task demonstrations. In particular, we demonstrate that the most powerful instruction-fine-tuned baseline (text-davinci-003) also benefits from ICIL by 9.3%, indicating that the effect of ICIL is complementary to instruction-based fine-tuning. ","[{'version': 'v1', 'created': 'Tue, 28 Feb 2023 16:06:35 GMT'}]",2023-03-01,"[['Ye', 'Seonghyeon', ''], ['Hwang', 'Hyeonbin', ''], ['Yang', 'Sohee', ''], ['Yun', 'Hyeongu', ''], ['Kim', 'Yireun', ''], ['Seo', 'Minjoon', '']]",0,0,2023-02-28,1,6,2,0,0,0,4f53020119eba43891d4566df28466a92229b8fb,257233109.0,https://www.semanticscholar.org/paper/4f53020119eba43891d4566df28466a92229b8fb,arXiv.org,2023.0,32.0,19.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152111477', 'name': 'Seonghyeon Ye'}, {'authorId': '2161436241', 'name': 'Hyeonbin Hwang'}, {'authorId': '16110760', 'name': 'Sohee Yang'}, {'authorId': '8787946', 'name': 'Hyeongu Yun'}, {'authorId': '2181032855', 'name': 'Yireun Kim'}, {'authorId': '4418074', 'name': 'Minjoon Seo'}]",['LG AI Research'],,2023-02,['industrial']
2303.02155,Daniele Loiacono,Pier Luca Lanzi and Daniele Loiacono,ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design,(Submitted),,,,cs.AI cs.HC cs.LG cs.NE,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large language models (LLMs) have taken the scientific world by storm, changing the landscape of natural language processing and human-computer interaction. These powerful tools can answer complex questions and, surprisingly, perform challenging creative tasks (e.g., generate code and applications to solve problems, write stories, pieces of music, etc.). In this paper, we present a collaborative game design framework that combines interactive evolution and large language models to simulate the typical human design process. We use the former to exploit users' feedback for selecting the most promising ideas and large language models for a very complex creative task - the recombination and variation of ideas. In our framework, the process starts with a brief and a set of candidate designs, either generated using a language model or proposed by the users. Next, users collaborate on the design process by providing feedback to an interactive genetic algorithm that selects, recombines, and mutates the most promising designs. We evaluated our framework on three game design tasks with human designers who collaborated remotely. ","[{'version': 'v1', 'created': 'Thu, 9 Feb 2023 15:44:43 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Apr 2023 16:58:20 GMT'}]",2023-04-14,"[['Lanzi', 'Pier Luca', ''], ['Loiacono', 'Daniele', '']]",1,1,2023-02-09,2,2,4,1,0,1,09239dac5b1cded9414c946333eaf619dca9aaa7,257364995.0,https://www.semanticscholar.org/paper/09239dac5b1cded9414c946333eaf619dca9aaa7,Annual Conference on Genetic and Evolutionary Computation,2023.0,61.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1796949', 'name': 'P. Lanzi'}, {'authorId': '1775166', 'name': 'D. Loiacono'}]","['Politecnico di Milano', 'Daniele Loiacono,']",['Italy'],2023-02,"['industrial', 'industrial']"
2303.02927,Victor Dibia,Victor Dibia,LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models,"Accepted at ACL 2023 (Demonstration track). Fix formatting issues,
  update information on evaluation metrics, prompts and project website
  (https://microsoft.github.io/lida/)",,,,cs.AI cs.HC cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Systems that support users in the automatic creation of visualizations must address several subtasks - understand the semantics of data, enumerate relevant visualization goals and generate visualization specifications. In this work, we pose visualization generation as a multi-stage generation problem and argue that well-orchestrated pipelines based on large language models (LLMs) such as ChatGPT/GPT-4 and image generation models (IGMs) are suitable to addressing these tasks. We present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data into a rich but compact natural language summary, a GOAL EXPLORER that enumerates visualization goals given the data, a VISGENERATOR that generates, refines, executes and filters visualization code and an INFOGRAPHER module that yields data-faithful stylized graphics using IGMs. LIDA provides a python api, and a hybrid user interface (direct manipulation and multilingual natural language) for interactive chart, infographics and data story generation. Learn more about the project here - https://microsoft.github.io/lida/ ","[{'version': 'v1', 'created': 'Mon, 6 Mar 2023 06:47:22 GMT'}, {'version': 'v2', 'created': 'Fri, 2 Jun 2023 21:57:13 GMT'}, {'version': 'v3', 'created': 'Tue, 6 Jun 2023 01:21:41 GMT'}]",2023-06-07,"[['Dibia', 'Victor', '']]",1,1,2023-03-06,3,1,3,2,0,2,1f8efdaa56df0ede1c2b7c6cb55f0640f1ed43df,257365015.0,https://www.semanticscholar.org/paper/1f8efdaa56df0ede1c2b7c6cb55f0640f1ed43df,Annual Meeting of the Association for Computational Linguistics,2023.0,48.0,15.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3353344', 'name': 'Victor C. Dibia'}]",['Microsoft'],['India'],2023-03,['industrial']
2303.03103,Hangyeol Yu,"Hangyeol Yu, Myeongho Jeong, Jamin Shin, Hyeongdon Moon, Juneyoung
  Park, Seungtaek Choi",Towards Zero-Shot Functional Compositionality of Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Pre-trained Language Models (PLM) have become the most desirable starting point in the field of NLP, as they have become remarkably good at solving many individual tasks. Despite such success, in this paper, we argue that current paradigms of working with PLMs are neglecting a critical aspect of modeling human intelligence: functional compositionality. Functional compositionality - the ability to compose learned tasks - has been a long-standing challenge in the field of AI (and many other fields) as it is considered one of the hallmarks of human intelligence. An illustrative example of such is cross-lingual summarization, where a bilingual person (English-French) could directly summarize an English document into French sentences without having to translate the English document or summary into French explicitly. We discuss why this matter is an important open problem that requires further attention from the field. Then, we show that current PLMs (e.g., GPT-2 and T5) don't have functional compositionality yet and it is far from human-level generalizability. Finally, we suggest several research directions that could push the field towards zero-shot functional compositionality of language models. ","[{'version': 'v1', 'created': 'Mon, 6 Mar 2023 13:15:25 GMT'}]",2023-03-07,"[['Yu', 'Hangyeol', ''], ['Jeong', 'Myeongho', ''], ['Shin', 'Jamin', ''], ['Moon', 'Hyeongdon', ''], ['Park', 'Juneyoung', ''], ['Choi', 'Seungtaek', '']]",0,1,2023-03-06,1,6,2,2,2,0,aba36ad7021f615bd350d7e3f7c3218cf7bcd550,253082773.0,https://www.semanticscholar.org/paper/aba36ad7021f615bd350d7e3f7c3218cf7bcd550,arXiv.org,2023.0,65.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50984319', 'name': 'Hangyeol Yu'}, {'authorId': '98089930', 'name': 'Myeongho Jeong'}, {'authorId': '51228826', 'name': 'Jamin Shin'}, {'authorId': '2157044837', 'name': 'Hyeongdon Moon'}, {'authorId': '2115955448', 'name': 'Juneyoung Park'}, {'authorId': '5841595', 'name': 'Seungtaek Choi'}]","['Equal Contribution.', 'NAVER', 'Riiid AI Research.', 'Riiid AI Research']",['South Korea'],2023-03,"['industrial', 'industrial', 'industrial', 'industrial']"
2303.03487,Ankit Vaidya,Ankit Vaidya and Aditya Kane,Two-stage Pipeline for Multilingual Dialect Detection,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,  Dialect Identification is a crucial task for localizing various Large Language Models. This paper outlines our approach to the VarDial 2023 shared task. Here we have to identify three or two dialects from three languages each which results in a 9-way classification for Track-1 and 6-way classification for Track-2 respectively. Our proposed approach consists of a two-stage system and outperforms other participants' systems and previous works in this domain. We achieve a score of 58.54% for Track-1 and 85.61% for Track-2. Our codebase is available publicly (https://github.com/ankit-vaidya19/EACL_VarDial2023). ,"[{'version': 'v1', 'created': 'Mon, 6 Mar 2023 20:35:51 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Mar 2023 17:55:52 GMT'}]",2023-03-29,"[['Vaidya', 'Ankit', ''], ['Kane', 'Aditya', '']]",0,0,2023-03-06,2,2,2,0,0,0,f34864dc393b8f44776bd4ae34efd30b4e4c7afd,257378222.0,https://www.semanticscholar.org/paper/f34864dc393b8f44776bd4ae34efd30b4e4c7afd,"Workshop on NLP for Similar Languages, Varieties and Dialects",2023.0,35.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2210857786', 'name': 'Ankit Vaidya'}, {'authorId': '2159555605', 'name': 'Aditya Kane'}]","['Indian Institute of Information Technology, Pune']",['India'],2023-03,['industrial']
2303.03953,Taja Kuzman,"Taja Kuzman, Igor Mozeti\v{c}, Nikola Ljube\v{s}i\'c",ChatGPT: Beginning of an End of Manual Linguistic Data Annotation? Use Case of Automatic Genre Identification,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  ChatGPT has shown strong capabilities in natural language generation tasks, which naturally leads researchers to explore where its abilities end. In this paper, we examine whether ChatGPT can be used for zero-shot text classification, more specifically, automatic genre identification. We compare ChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on datasets, manually annotated with genres. The models are compared on test sets in two languages: English and Slovenian. Results show that ChatGPT outperforms the fine-tuned model when applied to the dataset which was not seen before by either of the models. Even when applied on Slovenian language as an under-resourced language, ChatGPT's performance is no worse than when applied to English. However, if the model is fully prompted in Slovenian, the performance drops significantly, showing the current limitations of ChatGPT usage on smaller languages. The presented results lead us to questioning whether this is the beginning of an end of laborious manual annotation campaigns even for smaller languages, such as Slovenian. ","[{'version': 'v1', 'created': 'Tue, 7 Mar 2023 14:59:33 GMT'}, {'version': 'v2', 'created': 'Wed, 8 Mar 2023 09:35:09 GMT'}]",2023-03-09,"[['Kuzman', 'Taja', ''], ['Mozetič', 'Igor', ''], ['Ljubešić', 'Nikola', '']]",1,1,2023-03-07,2,3,2,1,0,1,31f44f0f2124c54e47f4df54dec63118232c25da,257405186.0,https://www.semanticscholar.org/paper/31f44f0f2124c54e47f4df54dec63118232c25da,arXiv.org,2023.0,47.0,24.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '28089460', 'name': 'Taja Kuzman'}, {'authorId': '1715207', 'name': 'I. Mozetič'}, {'authorId': '3358706', 'name': 'Nikola Ljubesic'}]","['Jožef Stefan Institute', 'Center za jezikovne vire in tehnologije Univerze v Ljubljani, Slovenia']",['Slovenia'],2023-03,"['industrial', 'industrial']"
2303.04671,Chenfei Wu,"Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang,
  Nan Duan","Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models",,,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT is attracting a cross-field interest as it provides a language interface with remarkable conversational competency and reasoning capabilities across many domains. However, since ChatGPT is trained with languages, it is currently not capable of processing or generating images from the visual world. At the same time, Visual Foundation Models, such as Visual Transformers or Stable Diffusion, although showing great visual understanding and generation capabilities, they are only experts on specific tasks with one-round fixed inputs and outputs. To this end, We build a system called \textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps. 3) providing feedback and asking for corrected results. We design a series of prompts to inject the visual model information into ChatGPT, considering models of multiple inputs/outputs and models that require visual feedback. Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models. Our system is publicly available at \url{https://github.com/microsoft/visual-chatgpt}. ","[{'version': 'v1', 'created': 'Wed, 8 Mar 2023 15:50:02 GMT'}]",2023-03-09,"[['Wu', 'Chenfei', ''], ['Yin', 'Shengming', ''], ['Qi', 'Weizhen', ''], ['Wang', 'Xiaodong', ''], ['Tang', 'Zecheng', ''], ['Duan', 'Nan', '']]",1,1,2023-03-08,1,6,1,1,0,1,af997821231898a5f8d0fd78dad4eec526acabe5,257404891.0,https://www.semanticscholar.org/paper/af997821231898a5f8d0fd78dad4eec526acabe5,arXiv.org,2023.0,62.0,225.0,32.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Art', 'source': 's2-fos-model'}]","[{'authorId': '2151101534', 'name': 'Chenfei Wu'}, {'authorId': '2333305', 'name': 'Sheng-Kai Yin'}, {'authorId': '15629561', 'name': 'Weizhen Qi'}, {'authorId': '2211071131', 'name': 'Xiaodong Wang'}, {'authorId': '1576234850', 'name': 'Zecheng Tang'}, {'authorId': '2072609829', 'name': 'Nan Duan'}]",['Microsoft'],['China'],2023-03,['industrial']
2303.05383,Dell Zhang,"Dell Zhang, Frank Schilder, Jack G. Conrad, Masoud Makrehchi, David
  von Rickenbach, Isabelle Moulinier",Making a Computational Attorney,"To be published in the Proceedings of the 2023 SIAM International
  Conference on Data Mining (SDM'23)",,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This ""blue sky idea"" paper outlines the opportunities and challenges in data mining and machine learning involving making a computational attorney -- an intelligent software agent capable of helping human lawyers with a wide range of complex high-level legal tasks such as drafting legal briefs for the prosecution or defense in court. In particular, we discuss what a ChatGPT-like Large Legal Language Model (L$^3$M) can and cannot do today, which will inspire researchers with promising short-term and long-term research objectives. ","[{'version': 'v1', 'created': 'Tue, 7 Mar 2023 16:44:29 GMT'}]",2023-03-10,"[['Zhang', 'Dell', ''], ['Schilder', 'Frank', ''], ['Conrad', 'Jack G.', ''], ['Makrehchi', 'Masoud', ''], ['von Rickenbach', 'David', ''], ['Moulinier', 'Isabelle', '']]",1,1,2023-03-07,1,6,3,1,0,1,2226d26497dc6b1c5922992c9b22ce08899379c0,257427583.0,https://www.semanticscholar.org/paper/2226d26497dc6b1c5922992c9b22ce08899379c0,SDM,2023.0,26.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '37510526', 'name': 'Dell Zhang'}, {'authorId': '145837551', 'name': 'Frank Schilder'}, {'authorId': '1683048', 'name': 'Jack G. Conrad'}, {'authorId': '3183840', 'name': 'M. Makrehchi'}, {'authorId': '2211100280', 'name': 'David von Rickenbach'}, {'authorId': '1789324', 'name': 'Isabelle Moulinier'}]",['Thomson Reuters (United States)'],['United States'],2023-03,['industrial']
2303.05398,Harsh Shrivastava,"Shima Imani, Liang Du, Harsh Shrivastava",MathPrompter: Mathematical Reasoning using Large Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large Language Models (LLMs) have limited performance when solving arithmetic reasoning tasks and often provide incorrect answers. Unlike natural language understanding, math problems typically have a single correct answer, making the task of generating accurate solutions more challenging for LLMs. To the best of our knowledge, we are not aware of any LLMs that indicate their level of confidence in their responses which fuels a trust deficit in these models impeding their adoption. To address this deficiency, we propose `MathPrompter', a technique that improves performance of LLMs on arithmetic problems along with increased reliance in the predictions. MathPrompter uses the Zero-shot chain-of-thought prompting technique to generate multiple Algebraic expressions or Python functions to solve the same math problem in different ways and thereby raise the confidence level in the output results. This is in contrast to other prompt based CoT methods, where there is no check on the validity of the intermediate steps followed. Our technique improves over state-of-the-art on the MultiArith dataset ($78.7\%\rightarrow92.5\%$) evaluated using 175B parameter GPT-based LLM. ","[{'version': 'v1', 'created': 'Sat, 4 Mar 2023 04:43:49 GMT'}]",2023-03-10,"[['Imani', 'Shima', ''], ['Du', 'Liang', ''], ['Shrivastava', 'Harsh', '']]",0,1,2023-03-04,1,3,2,0,0,0,b626560f19f815808a289ef5c24a17c57320da70,257427208.0,https://www.semanticscholar.org/paper/b626560f19f815808a289ef5c24a17c57320da70,Annual Meeting of the Association for Computational Linguistics,2023.0,26.0,51.0,5.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40203626', 'name': 'Shima Imani'}, {'authorId': '1669396676', 'name': 'Liang Du'}, {'authorId': '1442157164', 'name': 'H. Shrivastava'}]",['Microsoft'],['United States'],2023-03,['industrial']
2303.06135,Douglas Boubert,"Robert Irvine, Douglas Boubert, Vyas Raina, Adian Liusie, Ziyi Zhu,
  Vineet Mudupalli, Aliaksei Korshuk, Zongyi Liu, Fritz Cremer, Valentin
  Assassi, Christie-Carol Beauchamp, Xiaoding Lu, Thomas Rialan, William
  Beauchamp",Rewarding Chatbots for Real-World Engagement with Millions of Users,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The emergence of pretrained large language models has led to the deployment of a range of social chatbots for chitchat. Although these chatbots demonstrate language ability and fluency, they are not guaranteed to be engaging and can struggle to retain users. This work investigates the development of social chatbots that prioritize user engagement to enhance retention, specifically examining the use of human feedback to efficiently develop highly engaging chatbots. The proposed approach uses automatic pseudo-labels collected from user interactions to train a reward model that can be used to reject low-scoring sample responses generated by the chatbot model at inference time. Intuitive evaluation metrics, such as mean conversation length (MCL), are introduced as proxies to measure the level of engagement of deployed chatbots. A/B testing on groups of 10,000 new daily chatbot users on the Chai Research platform shows that this approach increases the MCL by up to 70%, which translates to a more than 30% increase in user retention for a GPT-J 6B model. Future work aims to use the reward model to realise a data fly-wheel, where the latest user conversations can be used to alternately fine-tune the language model and the reward model. ","[{'version': 'v1', 'created': 'Fri, 10 Mar 2023 18:53:52 GMT'}, {'version': 'v2', 'created': 'Thu, 30 Mar 2023 18:28:05 GMT'}]",2023-04-03,"[['Irvine', 'Robert', ''], ['Boubert', 'Douglas', ''], ['Raina', 'Vyas', ''], ['Liusie', 'Adian', ''], ['Zhu', 'Ziyi', ''], ['Mudupalli', 'Vineet', ''], ['Korshuk', 'Aliaksei', ''], ['Liu', 'Zongyi', ''], ['Cremer', 'Fritz', ''], ['Assassi', 'Valentin', ''], ['Beauchamp', 'Christie-Carol', ''], ['Lu', 'Xiaoding', ''], ['Rialan', 'Thomas', ''], ['Beauchamp', 'William', '']]",0,1,2023-03-10,2,14,3,0,0,0,851893ca18d52c77d60f79228fdf3e61eaf23fd1,257482614.0,https://www.semanticscholar.org/paper/851893ca18d52c77d60f79228fdf3e61eaf23fd1,arXiv.org,2023.0,47.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '118573183', 'name': 'R. Irvine'}, {'authorId': '102506664', 'name': 'D. Boubert'}, {'authorId': '2007545675', 'name': 'Vyas Raina'}, {'authorId': '2190750613', 'name': 'Adian Liusie'}, {'authorId': '2214424924', 'name': 'Ziyi Zhu'}, {'authorId': '2211334203', 'name': 'Vineet Mudupalli'}, {'authorId': '2211335875', 'name': 'Aliaksei Korshuk'}, {'authorId': '152613893', 'name': 'Z. Liu'}, {'authorId': '2211339086', 'name': 'Fritz Cremer'}, {'authorId': '102427650', 'name': 'Valentin Assassi'}, {'authorId': '2211332479', 'name': 'Christie-Carol Beauchamp'}, {'authorId': '2152840460', 'name': 'Xiaoding Lu'}, {'authorId': '2211335873', 'name': 'Thomas Rialan'}, {'authorId': '2070240871', 'name': 'W. Beauchamp'}]",['Clinton Health Access Initiative'],['United States'],2023-03,['industrial']
2303.06832,Seungpyo Choi,"SP Choi, Jihun Lee, Hyeongseok Ahn, Sanghee Jung, Bumsoo Kang",ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in,15 pages,,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset. ","[{'version': 'v1', 'created': 'Mon, 13 Mar 2023 03:28:36 GMT'}, {'version': 'v2', 'created': 'Thu, 16 Mar 2023 05:44:50 GMT'}]",2023-03-17,"[['Choi', 'SP', ''], ['Lee', 'Jihun', ''], ['Ahn', 'Hyeongseok', ''], ['Jung', 'Sanghee', ''], ['Kang', 'Bumsoo', '']]",1,1,2023-03-13,2,5,2,1,0,1,e5a7be5b9e6c368a1839455bfbb51bc07ed161f1,257495966.0,https://www.semanticscholar.org/paper/e5a7be5b9e6c368a1839455bfbb51bc07ed161f1,arXiv.org,2023.0,39.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2212204910', 'name': 'SP Choi'}, {'authorId': '2212170673', 'name': 'Jihun Lee'}, {'authorId': '2211430232', 'name': 'HyeongSeok Ahn'}, {'authorId': '2110428075', 'name': 'S. Jung'}, {'authorId': '3215814', 'name': 'Bumsoo Kang'}]",['Charlottesville Medical Research'],['United States'],2023-03,['industrial']
2303.07142,Benjamin Clavi\'e,"Benjamin Clavi\'e and Alexandru Ciceu and Frederick Naylor and
  Guillaume Souli\'e and Thomas Brightwell",Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification,Accepted as a long paper at NLDB 2023,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This case study investigates the task of job classification in a real-world setting, where the goal is to determine whether an English-language job posting is appropriate for a graduate or entry-level position. We explore multiple approaches to text classification, including supervised approaches such as traditional models like Support Vector Machines (SVMs) and state-of-the-art deep learning methods such as DeBERTa. We compare them with Large Language Models (LLMs) used in both few-shot and zero-shot classification settings. To accomplish this task, we employ prompt engineering, a technique that involves designing prompts to guide the LLMs towards the desired output. Specifically, we evaluate the performance of two commercially available state-of-the-art GPT-3.5-based language models, text-davinci-003 and gpt-3.5-turbo. We also conduct a detailed analysis of the impact of different aspects of prompt engineering on the model's performance. Our results show that, with a well-designed prompt, a zero-shot gpt-3.5-turbo classifier outperforms all other models, achieving a 6% increase in Precision@95% Recall compared to the best supervised approach. Furthermore, we observe that the wording of the prompt is a critical factor in eliciting the appropriate ""reasoning"" in the model, and that seemingly minor aspects of the prompt significantly affect the model's performance. ","[{'version': 'v1', 'created': 'Mon, 13 Mar 2023 14:09:53 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Mar 2023 17:01:59 GMT'}, {'version': 'v3', 'created': 'Tue, 18 Apr 2023 09:58:53 GMT'}]",2023-04-19,"[['Clavié', 'Benjamin', ''], ['Ciceu', 'Alexandru', ''], ['Naylor', 'Frederick', ''], ['Soulié', 'Guillaume', ''], ['Brightwell', 'Thomas', '']]",0,1,2023-03-13,3,5,1,1,0,1,aa2fa431ce1d5a8d56d138e3330d3df381d36e3a,257496827.0,https://www.semanticscholar.org/paper/aa2fa431ce1d5a8d56d138e3330d3df381d36e3a,International Conference on Applications of Natural Language to Data Bases,2023.0,32.0,8.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31430199', 'name': 'Benjamin Clavié'}, {'authorId': '2211431510', 'name': 'Alexandru Ciceu'}, {'authorId': '2211431037', 'name': 'Frederick Naylor'}, {'authorId': '2211430897', 'name': ""Guillaume Souli'e""}, {'authorId': '2211431326', 'name': 'Thomas Brightwell'}]","['Bright Network, Edinburgh, UK', 'Silicon Grove, Edinburgh, UK']",,2023-03,"['industrial', 'industrial']"
2303.07678,Liang Wang,"Liang Wang, Nan Yang, Furu Wei",Query2doc: Query Expansion with Large Language Models,9 pages,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper introduces a simple yet effective query expansion approach, denoted as query2doc, to improve both sparse and dense retrieval systems. The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudo-documents. LLMs are trained on web-scale text corpora and are adept at knowledge memorization. The pseudo-documents from LLMs often contain highly relevant information that can aid in query disambiguation and guide the retrievers. Experimental results demonstrate that query2doc boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning. Furthermore, our method also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results. ","[{'version': 'v1', 'created': 'Tue, 14 Mar 2023 07:27:30 GMT'}]",2023-03-15,"[['Wang', 'Liang', ''], ['Yang', 'Nan', ''], ['Wei', 'Furu', '']]",0,0,2023-03-14,1,3,2,0,0,0,ccc772d88c231275f24c4fac9b28bbe0942e1107,257505063.0,https://www.semanticscholar.org/paper/ccc772d88c231275f24c4fac9b28bbe0942e1107,arXiv.org,2023.0,36.0,21.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145769448', 'name': 'Liang Wang'}, {'authorId': '144610884', 'name': 'Nan Yang'}, {'authorId': '49807919', 'name': 'Furu Wei'}]",['Microsoft'],['India'],2023-03,['industrial']
2303.08697,Canwen Xu,Canwen Xu and Julian McAuley and Penghan Wang,"Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization",The Web Conference (WWW 2023) Demo,,10.1145/3543873.3587309,,cs.DB cs.AI cs.CL cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present Mirror, an open-source platform for data exploration and analysis powered by large language models. Mirror offers an intuitive natural language interface for querying databases, and automatically generates executable SQL commands to retrieve relevant data and summarize it in natural language. In addition, users can preview and manually edit the generated SQL commands to ensure the accuracy of their queries. Mirror also generates visualizations to facilitate understanding of the data. Designed with flexibility and human input in mind, Mirror is suitable for both experienced data analysts and non-technical professionals looking to gain insights from their data. ","[{'version': 'v1', 'created': 'Wed, 15 Mar 2023 15:31:51 GMT'}]",2023-03-16,"[['Xu', 'Canwen', ''], ['McAuley', 'Julian', ''], ['Wang', 'Penghan', '']]",0,0,2023-03-15,1,3,4,0,0,0,8ed0ee821e28ff01d1e275a4728f248e3bbeff9a,257532430.0,https://www.semanticscholar.org/paper/8ed0ee821e28ff01d1e275a4728f248e3bbeff9a,The Web Conference,2023.0,26.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66247317', 'name': 'Canwen Xu'}, {'authorId': '35660011', 'name': 'Julian McAuley'}, {'authorId': '2108242653', 'name': 'Penghan Wang'}]","['of , , USA']",['United States'],2023-03,['industrial']
2303.09184,Gaochen Dong,"Gaochen Dong, Wei Chen",Block-wise Bit-Compression of Transformer-based Models,Need to add figures and adjust languages to improve readability,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the popularity of the recent Transformer-based models represented by BERT, GPT-3 and ChatGPT, there has been state-of-the-art performance in a range of natural language processing tasks. However, the massive computations, huge memory footprint, and thus high latency of Transformer-based models is an inevitable challenge for the cloud with high real-time requirement. To tackle the issue, we propose BBCT, a method of block-wise bit-compression for transformer without retraining. Our method achieves more fine-grained compression of the whole transformer, including embedding, matrix multiplication, GELU, softmax, layer normalization, and all the intermediate results. As a case, we compress an efficient BERT with the method of BBCT. Our benchmark test results on General Language Understanding Evaluation (GLUE) show that BBCT can achieve less than 1% accuracy drop in most tasks. ","[{'version': 'v1', 'created': 'Thu, 16 Mar 2023 09:53:57 GMT'}, {'version': 'v2', 'created': 'Sat, 1 Apr 2023 12:50:29 GMT'}]",2023-04-04,"[['Dong', 'Gaochen', ''], ['Chen', 'Wei', '']]",1,1,2023-03-16,2,2,2,2,0,2,9891d1b67c92f283aa283c27e87d0676c068a818,257557845.0,https://www.semanticscholar.org/paper/9891d1b67c92f283aa283c27e87d0676c068a818,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2211733371', 'name': 'Gaochen Dong'}, {'authorId': '2154939788', 'name': 'W. Chen'}]",['China Iron and Steel Research Institute Group'],['China'],2023-03,['industrial']
2303.10464,Vithursan Thangarasa,"Vithursan Thangarasa, Abhay Gupta, William Marshall, Tianda Li, Kevin
  Leong, Dennis DeCoste, Sean Lie, Shreyas Saxena",SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models,"Accepted to Uncertainty in Artificial Intelligence (UAI) 2023
  Conference; 13 pages, 4 figures (Main Paper) + 5 pages (Supplementary
  Material)",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The pre-training and fine-tuning paradigm has contributed to a number of breakthroughs in Natural Language Processing (NLP). Instead of directly training on a downstream task, language models are first pre-trained on large datasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then fine-tuned on task-specific data (e.g., natural language generation, text summarization, etc.). Scaling the model and dataset size has helped improve the performance of LLMs, but unfortunately, this also lead to highly prohibitive computational costs. Pre-training LLMs often require orders of magnitude more FLOPs than fine-tuning and the model capacity often remains the same between the two phases. To achieve training efficiency w.r.t training FLOPs, we propose to decouple the model capacity between the two phases and introduce Sparse Pre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits of using unstructured weight sparsity to train only a subset of weights during pre-training (Sparse Pre-training) and then recover the representational capacity by allowing the zeroed weights to learn (Dense Fine-tuning). We demonstrate that we can induce up to 75% sparsity into a 1.3B parameter GPT-3 XL model resulting in a 2.5x reduction in pre-training FLOPs, without a significant loss in accuracy on the downstream tasks relative to the dense baseline. By rigorously evaluating multiple downstream tasks, we also establish a relationship between sparsity, task complexity and dataset size. Our work presents a promising direction to train large GPT models at a fraction of the training FLOPs using weight sparsity, while retaining the benefits of pre-trained textual representations for downstream tasks. ","[{'version': 'v1', 'created': 'Sat, 18 Mar 2023 17:56:01 GMT'}, {'version': 'v2', 'created': 'Sat, 29 Jul 2023 19:56:50 GMT'}]",2023-08-01,"[['Thangarasa', 'Vithursan', ''], ['Gupta', 'Abhay', ''], ['Marshall', 'William', ''], ['Li', 'Tianda', ''], ['Leong', 'Kevin', ''], ['DeCoste', 'Dennis', ''], ['Lie', 'Sean', ''], ['Saxena', 'Shreyas', '']]",0,1,2023-03-18,2,8,2,1,0,1,7d46073cce9f5ed8d931b804cfaf327201dd4e26,257631823.0,https://www.semanticscholar.org/paper/7d46073cce9f5ed8d931b804cfaf327201dd4e26,Conference on Uncertainty in Artificial Intelligence,2023.0,87.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51153332', 'name': 'Vithursan Thangarasa'}, {'authorId': '1922581610', 'name': 'Abhay Gupta'}, {'authorId': '2058346405', 'name': 'William Marshall'}, {'authorId': '6574899', 'name': 'Tianda Li'}, {'authorId': '2212028628', 'name': 'Kevin Leong'}, {'authorId': '1703049', 'name': 'D. DeCoste'}, {'authorId': '2212029838', 'name': 'Sean Lie'}, {'authorId': '46708564', 'name': 'S. Saxena'}]",['Integrated Systems Incorporation (United States)'],['United States'],2023-03,['industrial']
2303.11381,Zhengyuan Yang,"Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab,
  Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, Lijuan Wang",MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,,,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose MM-REACT, a system paradigm that integrates ChatGPT with a pool of vision experts to achieve multimodal reasoning and action. In this paper, we define and explore a comprehensive list of advanced vision tasks that are intriguing to solve, but may exceed the capabilities of existing vision and vision-language models. To achieve such advanced visual intelligence, MM-REACT introduces a textual prompt design that can represent text descriptions, textualized spatial coordinates, and aligned file names for dense visual signals such as images and videos. MM-REACT's prompt design allows language models to accept, associate, and process multimodal information, thereby facilitating the synergetic combination of ChatGPT and various vision experts. Zero-shot experiments demonstrate MM-REACT's effectiveness in addressing the specified capabilities of interests and its wide application in different scenarios that require advanced visual understanding. Furthermore, we discuss and compare MM-REACT's system paradigm with an alternative approach that extends language models for multimodal scenarios through joint finetuning. Code, demo, video, and visualization are available at https://multimodal-react.github.io/ ","[{'version': 'v1', 'created': 'Mon, 20 Mar 2023 18:31:47 GMT'}]",2023-03-22,"[['Yang', 'Zhengyuan', ''], ['Li', 'Linjie', ''], ['Wang', 'Jianfeng', ''], ['Lin', 'Kevin', ''], ['Azarnasab', 'Ehsan', ''], ['Ahmed', 'Faisal', ''], ['Liu', 'Zicheng', ''], ['Liu', 'Ce', ''], ['Zeng', 'Michael', ''], ['Wang', 'Lijuan', '']]",1,1,2023-03-20,1,10,3,1,0,1,c7a9c7302a72301ed79a7c0696d5af2e03ad3ac4,257637012.0,https://www.semanticscholar.org/paper/c7a9c7302a72301ed79a7c0696d5af2e03ad3ac4,arXiv.org,2023.0,45.0,116.0,12.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2149231840', 'name': 'Zhengyuan Yang'}, {'authorId': '50703697', 'name': 'Linjie Li'}, {'authorId': '2124948371', 'name': 'Jianfeng Wang'}, {'authorId': '143786724', 'name': 'Kevin Lin'}, {'authorId': '3212449', 'name': 'E. Azarnasab'}, {'authorId': '2054472958', 'name': 'Faisal Ahmed'}, {'authorId': '2145253136', 'name': 'Zicheng Liu'}, {'authorId': '2107890439', 'name': 'Ce Liu'}, {'authorId': '48262024', 'name': 'Michael Zeng'}, {'authorId': '29957038', 'name': 'Lijuan Wang'}]",['Microsoft'],['United States'],2023-03,['industrial']
2303.11525,Vithursan Thangarasa,"Shreyas Saxena, Vithursan Thangarasa, Abhay Gupta, Sean Lie",Sparse Iso-FLOP Transformations for Maximizing Training Efficiency,"Code available from Cerebras Systems:
  https://github.com/CerebrasResearch/Sparse-IFT",,,,cs.LG cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Recent works have explored the use of weight sparsity to improve the training efficiency (test accuracy w.r.t training FLOPs) of deep neural networks (DNNs). These works aim to reduce training FLOPs but training with sparse weights often leads to accuracy loss or requires longer training schedules, making the resulting training efficiency less clear. In contrast, we focus on using sparsity to increase accuracy while using the same FLOPs as the dense model and show training efficiency gains through higher accuracy. In this work, we introduce Sparse-IFT, a family of Sparse Iso-FLOP Transformations which are used as drop-in replacements for dense layers to improve their representational capacity and FLOP efficiency. Each transformation is parameterized by a single hyperparameter (sparsity level) and provides a larger search space to find optimal sparse masks. Without changing any training hyperparameters, replacing dense layers with Sparse-IFT leads to significant improvements across computer vision (CV) and natural language processing (NLP) tasks, including ResNet-18 on ImageNet (+3.5%) and GPT-3 Small on WikiText-103 (-0.4 PPL), both matching larger dense model variants that use 2x or more FLOPs. To our knowledge, this is the first work to demonstrate the use of sparsity for improving the accuracy of dense models via a simple-to-use set of sparse transformations. Code is available at: https://github.com/CerebrasResearch/Sparse-IFT. ","[{'version': 'v1', 'created': 'Tue, 21 Mar 2023 01:06:37 GMT'}, {'version': 'v2', 'created': 'Sat, 25 Mar 2023 15:35:03 GMT'}]",2023-03-28,"[['Saxena', 'Shreyas', ''], ['Thangarasa', 'Vithursan', ''], ['Gupta', 'Abhay', ''], ['Lie', 'Sean', '']]",0,1,2023-03-21,2,4,3,1,0,1,9c5b457ca44c56bd9c57033ff28fbb614275cf04,257636503.0,https://www.semanticscholar.org/paper/9c5b457ca44c56bd9c57033ff28fbb614275cf04,arXiv.org,2023.0,96.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46708564', 'name': 'S. Saxena'}, {'authorId': '51153332', 'name': 'Vithursan Thangarasa'}, {'authorId': '1922581610', 'name': 'Abhay Gupta'}, {'authorId': '2212029838', 'name': 'Sean Lie'}]",['Cerebras Systems'],,2023-03,['industrial']
2303.12038,David Noever,"Grant Rosario, David Noever",Grading Conversational Responses Of Chatbots,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Chatbots have long been capable of answering basic questions and even responding to obscure prompts, but recently their improvements have been far more significant. Modern chatbots like Open AIs ChatGPT3 not only have the ability to answer basic questions but can write code and movie scripts and imitate well-known people. In this paper, we analyze ChatGPTs' responses to various questions from a dataset of queries from the popular Quora forum. We submitted sixty questions to ChatGPT and scored the answers based on three industry-standard metrics for grading machine translation: BLEU, METEOR, and ROUGE. These metrics allow us to compare the machine responses with the most upvoted human answer to the same question to assess ChatGPT's ability to submit a humanistic reply. The results showed that while the responses and translation abilities of ChatGPT are remarkable, they still fall short of what a typical human reaction would be. ","[{'version': 'v1', 'created': 'Wed, 1 Feb 2023 02:54:43 GMT'}]",2023-03-22,"[['Rosario', 'Grant', ''], ['Noever', 'David', '']]",1,1,2023-02-01,1,2,2,1,0,1,2424a94fcb5c498265333c5a1c591cf36fc29a01,257636913.0,https://www.semanticscholar.org/paper/2424a94fcb5c498265333c5a1c591cf36fc29a01,arXiv.org,2023.0,14.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2055130169', 'name': 'Grant Rosario'}, {'authorId': '46787948', 'name': 'David Noever'}]","['4901-D Corporate Drive, Huntsville, AL, USA, 35805']",['United States'],2023-02,['industrial']
2303.12712,Sebastien Bubeck,"S\'ebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes
  Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott
  Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, Yi Zhang",Sparks of Artificial General Intelligence: Early experiments with GPT-4,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions. ","[{'version': 'v1', 'created': 'Wed, 22 Mar 2023 16:51:28 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Mar 2023 17:07:43 GMT'}, {'version': 'v3', 'created': 'Mon, 27 Mar 2023 22:36:40 GMT'}, {'version': 'v4', 'created': 'Wed, 12 Apr 2023 17:00:10 GMT'}, {'version': 'v5', 'created': 'Thu, 13 Apr 2023 20:41:31 GMT'}]",2023-04-17,"[['Bubeck', 'Sébastien', ''], ['Chandrasekaran', 'Varun', ''], ['Eldan', 'Ronen', ''], ['Gehrke', 'Johannes', ''], ['Horvitz', 'Eric', ''], ['Kamar', 'Ece', ''], ['Lee', 'Peter', ''], ['Lee', 'Yin Tat', ''], ['Li', 'Yuanzhi', ''], ['Lundberg', 'Scott', ''], ['Nori', 'Harsha', ''], ['Palangi', 'Hamid', ''], ['Ribeiro', 'Marco Tulio', ''], ['Zhang', 'Yi', '']]",1,1,2023-03-22,5,14,2,3,0,3,574beee702be3856d60aa482ec725168fe64fc99,257663729.0,https://www.semanticscholar.org/paper/574beee702be3856d60aa482ec725168fe64fc99,arXiv.org,2023.0,0.0,909.0,95.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '121645690', 'name': 'Sébastien Bubeck'}, {'authorId': '143754359', 'name': 'Varun Chandrasekaran'}, {'authorId': '2315830', 'name': 'Ronen Eldan'}, {'authorId': '120962807', 'name': 'John A. Gehrke'}, {'authorId': '2064595436', 'name': 'Eric Horvitz'}, {'authorId': '1783184', 'name': 'Ece Kamar'}, {'authorId': '2212084492', 'name': 'Peter Lee'}, {'authorId': '2109308930', 'name': 'Y. Lee'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}, {'authorId': '23451726', 'name': 'Scott M. Lundberg'}, {'authorId': '40900039', 'name': 'Harsha Nori'}, {'authorId': '2542427', 'name': 'H. Palangi'}, {'authorId': '78846919', 'name': 'Marco Tulio Ribeiro'}, {'authorId': '144884116', 'name': 'Yi Zhang'}]",['Microsoft'],['India'],2023-03,['industrial']
2303.13521,Luca Caviglione,Enrico Cambiaso and Luca Caviglione,Scamming the Scammers: Using ChatGPT to Reply Mails for Wasting Time and Resources,,,,,cs.CR cs.AI cs.HC,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The use of Artificial Intelligence (AI) to support cybersecurity operations is now a consolidated practice, e.g., to detect malicious code or configure traffic filtering policies. The recent surge of AI, generative techniques and frameworks with efficient natural language processing capabilities dramatically magnifies the number of possible applications aimed at increasing the security of the Internet. Specifically, the ability of ChatGPT to produce textual contents while mimicking realistic human interactions can be used to mitigate the plague of emails containing scams. Therefore, this paper investigates the use of AI to engage scammers in automatized and pointless communications, with the goal of wasting both their time and resources. Preliminary results showcase that ChatGPT is able to decoy scammers, thus confirming that AI is an effective tool to counteract threats delivered via mail. In addition, we highlight the multitude of implications and open research questions to be addressed in the perspective of the ubiquitous adoption of AI. ","[{'version': 'v1', 'created': 'Fri, 10 Feb 2023 08:54:05 GMT'}]",2023-03-27,"[['Cambiaso', 'Enrico', ''], ['Caviglione', 'Luca', '']]",1,1,2023-02-10,1,2,3,1,0,1,9a147712d46d1b01a761987c874b628c34c52cda,257757409.0,https://www.semanticscholar.org/paper/9a147712d46d1b01a761987c874b628c34c52cda,Italian Conference on Cybersecurity,2023.0,33.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2979543', 'name': 'E. Cambiaso'}, {'authorId': '1728002', 'name': 'L. Caviglione'}]",['National Research Council'],['Italy'],2023-02,['industrial']
2303.14822,XInlei He,"Xinlei He and Xinyue Shen and Zeyuan Chen and Michael Backes and Yang
  Zhang",MGTBench: Benchmarking Machine-Generated Text Detection,,,,,cs.CR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Nowadays large language models (LLMs) have shown revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. In this way, detecting machine-generated texts (MGTs) is becoming increasingly important as LLMs become more advanced and prevalent. These models can generate human-like language that can be difficult to distinguish from text written by a human, which raises concerns about authenticity, accountability, and potential bias. However, existing detection methods against MGTs are evaluated under different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework across different methodologies   In this paper, we fill this gap by proposing the first benchmark framework for MGT detection, named MGTBench. Extensive evaluations on public datasets with curated answers generated by ChatGPT (the most representative and powerful LLMs thus far) show that most of the current detection methods perform less satisfactorily against MGTs. An exceptional case is ChatGPT Detector, which is trained with ChatGPT-generated texts and shows great performance in detecting MGTs. Nonetheless, we note that only a small fraction of adversarial-crafted perturbations on MGTs can evade the ChatGPT Detector, thus highlighting the need for more robust MGT detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of state-of-the-art MGT detection methods on their respective datasets and the development of more advanced MGT detection methods. Our source code and datasets are available at https://github.com/xinleihe/MGTBench. ","[{'version': 'v1', 'created': 'Sun, 26 Mar 2023 21:12:36 GMT'}, {'version': 'v2', 'created': 'Fri, 9 Jun 2023 06:50:57 GMT'}]",2023-06-12,"[['He', 'Xinlei', ''], ['Shen', 'Xinyue', ''], ['Chen', 'Zeyuan', ''], ['Backes', 'Michael', ''], ['Zhang', 'Yang', '']]",1,1,2023-03-26,2,5,2,1,0,1,e7ba478aad9b9534a9f632b85ad87177f5587189,257766697.0,https://www.semanticscholar.org/paper/e7ba478aad9b9534a9f632b85ad87177f5587189,arXiv.org,2023.0,30.0,24.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2116553732', 'name': 'Xinlei He'}, {'authorId': '2047395411', 'name': 'Xinyue Shen'}, {'authorId': '2111435173', 'name': 'Z. Chen'}, {'authorId': '144588806', 'name': 'M. Backes'}, {'authorId': '1698138', 'name': 'Yang Zhang'}]",['Helmholtz Center for Information Security'],['Germany'],2023-03,['industrial']
2303.15078,Ning Wu,"Ning Wu, Ming Gong, Linjun Shou, Shining Liang, Daxin Jiang",Large Language Models are Diverse Role-Players for Summarization Evaluation,NLPCC 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Text summarization has a wide range of applications in many scenarios. The evaluation of the quality of the generated text is a complex problem. A big challenge to language evaluation is that there is a clear divergence between existing metrics and human evaluation. A document summary's quality can be assessed by human annotators on various criteria, both objective ones like grammar and correctness, and subjective ones like informativeness, succinctness, and appeal. Most of the automatic evaluation methods like BLUE/ROUGE may be not able to adequately capture the above dimensions. In this paper, we propose a new evaluation framework based on LLMs, which provides a comprehensive evaluation framework by comparing generated text and reference text from both objective and subjective aspects. First, we propose to model objective and subjective dimensions of generated text based on roleplayers prompting mechanism. Furthermore, we introduce a context-based prompting mechanism that is able to generate dynamic roleplayer profiles based on input context. Finally, we design a multi-roleplayer prompting technology based on batch prompting and integrate multiple outputs into the final evaluation results. Experimental results on three real datasets for summarization show that our model is highly competitive and has a very high consistency with human annotators. ","[{'version': 'v1', 'created': 'Mon, 27 Mar 2023 10:40:59 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Mar 2023 15:25:19 GMT'}, {'version': 'v3', 'created': 'Tue, 19 Sep 2023 10:07:55 GMT'}]",2023-09-20,"[['Wu', 'Ning', ''], ['Gong', 'Ming', ''], ['Shou', 'Linjun', ''], ['Liang', 'Shining', ''], ['Jiang', 'Daxin', '']]",0,0,2023-03-27,3,5,1,0,0,0,4a4f81543a424ab2494cfb0fb49e0e47329b5cb6,257767249.0,https://www.semanticscholar.org/paper/4a4f81543a424ab2494cfb0fb49e0e47329b5cb6,Natural Language Processing and Chinese Computing,2023.0,25.0,11.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2068345080', 'name': 'Ning Wu'}, {'authorId': '50175330', 'name': 'Ming Gong'}, {'authorId': '24962156', 'name': 'Linjun Shou'}, {'authorId': '31314451', 'name': 'Shining Liang'}, {'authorId': '71790825', 'name': 'Daxin Jiang'}]",['Microsoft'],['China'],2023-03,['industrial']
2303.15233,Priyank Jaini,"Kevin Clark, Priyank Jaini",Text-to-Image Diffusion Models are Zero-Shot Classifiers,,,,,cs.CV cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The excellent generative capabilities of text-to-image diffusion models suggest they learn informative representations of image-text data. However, what knowledge their representations capture is not fully understood, and they have not been thoroughly explored on downstream tasks. We investigate diffusion models by proposing a method for evaluating them as zero-shot classifiers. The key idea is using a diffusion model's ability to denoise a noised image given a text description of a label as a proxy for that label's likelihood. We apply our method to Stable Diffusion and Imagen, using it to probe fine-grained aspects of the models' knowledge and comparing them with CLIP's zero-shot abilities. They perform competitively with CLIP on a wide range of zero-shot image classification datasets. Additionally, they achieve state-of-the-art results on shape/texture bias tests and can successfully perform attribute binding while CLIP cannot. Although generative pre-training is prevalent in NLP, visual foundation models often use other methods such as contrastive learning. Based on our findings, we argue that generative pre-training should be explored as a compelling alternative for vision-language tasks. ","[{'version': 'v1', 'created': 'Mon, 27 Mar 2023 14:15:17 GMT'}, {'version': 'v2', 'created': 'Tue, 5 Sep 2023 18:21:16 GMT'}]",2023-09-07,"[['Clark', 'Kevin', ''], ['Jaini', 'Priyank', '']]",0,1,2023-03-27,2,2,3,0,0,0,1bba2a9c6db3b356b8ae6ef2efff5645e4d96c2b,257767039.0,https://www.semanticscholar.org/paper/1bba2a9c6db3b356b8ae6ef2efff5645e4d96c2b,arXiv.org,2023.0,53.0,14.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144358401', 'name': 'Kevin Clark'}, {'authorId': '144818264', 'name': 'P. Jaini'}]",['Google'],['Canada'],2023-03,['industrial']
2303.16634,Yang Liu,"Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu and
  Chenguang Zhu",G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present G-Eval, a framework of using large language models with chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that G-Eval with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperforming all previous methods by a large margin. We also propose preliminary analysis on the behavior of LLM-based evaluators, and highlight the potential issue of LLM-based evaluators having a bias towards the LLM-generated texts. The code is at https://github.com/nlpyang/geval ","[{'version': 'v1', 'created': 'Wed, 29 Mar 2023 12:46:54 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Apr 2023 23:49:08 GMT'}, {'version': 'v3', 'created': 'Tue, 23 May 2023 22:12:16 GMT'}]",2023-05-25,"[['Liu', 'Yang', ''], ['Iter', 'Dan', ''], ['Xu', 'Yichong', ''], ['Wang', 'Shuohang', ''], ['Xu', 'Ruochen', ''], ['Zhu', 'Chenguang', '']]",0,1,2023-03-29,3,6,2,1,0,1,381ab7a640f5b46b62f7e08d1af4a8e0d3eadd55,257804696.0,https://www.semanticscholar.org/paper/381ab7a640f5b46b62f7e08d1af4a8e0d3eadd55,arXiv.org,2023.0,34.0,181.0,29.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152797401', 'name': 'Yang Liu'}, {'authorId': '3310951', 'name': 'Dan Iter'}, {'authorId': '2110197273', 'name': 'Yichong Xu'}, {'authorId': '2146294891', 'name': 'Shuo Wang'}, {'authorId': '8233965', 'name': 'Ruochen Xu'}, {'authorId': '8652308', 'name': 'Chenguang Zhu'}]",['Microsoft'],['United States'],2023-03,['industrial']
2303.17628,Floor Broekgaarden,Floor S. Broekgaarden,ChatGPT scores a bad birdie in counting gravitational-wave chirps,"1 April submission, with fun videos for visualizing the landscape of
  gravitational waves! (they are awesome!) See
  http://www.broekgaarden.nl/floor/wordpress/elementor-967/",,,,astro-ph.HE astro-ph.IM gr-qc physics.pop-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  How many gravitational-wave observations from compact object mergers have we seen to date? This seemingly simple question has a surprisingly complex answer that even ChatGPT struggles to answer. To shed light on this, we present a database with the literature's answers to this question. We find values spanning 67-100 for the number of detections from double compact object mergers to date, emphasizing that the exact number of detections is uncertain and depends on the chosen data analysis pipeline and underlying assumptions. We also review the number of gravitational-wave detections expected in the coming decades with future observing runs, finding values up to millions of detections per year in the era of Cosmic Explorer and Einstein Telescope. We present a publicly available code to visualize the detection numbers, highlighting the exponential growth in gravitational-wave observations in the coming decades and the exciting prospects of gravitational-wave astrophysics. See http://www.broekgaarden.nl/floor/wordpress/elementor-967/. We plan to keep this database up-to-date and welcome comments and suggestions for additional references. ","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 18:00:01 GMT'}]",2023-04-03,"[['Broekgaarden', 'Floor S.', '']]",1,1,2023-03-30,1,1,4,1,0,1,beb797758a2e756e32a8a91d6b8ddee53af3f117,257900966.0,https://www.semanticscholar.org/paper/beb797758a2e756e32a8a91d6b8ddee53af3f117,,2023.0,1.0,0.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '117198415', 'name': 'F. Broekgaarden'}]",['Center for Astrophysics Harvard & Smithsonian'],['United States'],2023-03,['industrial']
2304.00472,Paolo Papotti,"Mohammed Saeed, Nicola De Cao, Paolo Papotti",Querying Large Language Models with SQL,,,,,cs.DB cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In many use-cases, information is stored in text but not available in structured data. However, extracting data from natural language text to precisely fit a schema, and thus enable querying, is a challenging task. With the rise of pre-trained Large Language Models (LLMs), there is now an effective solution to store and use information extracted from massive corpora of text documents. Thus, we envision the use of SQL queries to cover a broad range of data that is not captured by traditional databases by tapping the information in LLMs. To ground this vision, we present Galois, a prototype based on a traditional database architecture, but with new physical operators for querying the underlying LLM. The main idea is to execute some operators of the the query plan with prompts that retrieve data from the LLM. For a large class of SQL queries, querying LLMs returns well structured relations, with encouraging qualitative results. Preliminary experimental results make pre-trained LLMs a promising addition to the field of database systems, introducing a new direction for hybrid query processing. However, we pinpoint several research challenges that must be addressed to build a DBMS that exploits LLMs. While some of these challenges necessitate integrating concepts from the NLP literature, others offer novel research avenues for the DB community. ","[{'version': 'v1', 'created': 'Sun, 2 Apr 2023 06:58:14 GMT'}]",2023-04-04,"[['Saeed', 'Mohammed', ''], ['De Cao', 'Nicola', ''], ['Papotti', 'Paolo', '']]",0,0,2023-04-02,1,3,2,0,0,0,7c9415a749beea50b5b2ad5d0dcce9e8d36f9b3c,257913347.0,https://www.semanticscholar.org/paper/7c9415a749beea50b5b2ad5d0dcce9e8d36f9b3c,arXiv.org,2023.0,62.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2073358417', 'name': 'Mohammed Saeed'}, {'authorId': '41019080', 'name': 'Nicola De Cao'}, {'authorId': '1802817', 'name': 'Paolo Papotti'}]",['UK Paolo Papotti'],,2023-04,['industrial']
2304.00477,Pingchuan Ma,"Pingchuan Ma, Rui Ding, Shuai Wang, Shi Han, Dongmei Zhang",Demonstration of InsightPilot: An LLM-Empowered Automated Data Exploration System,,,,,cs.DB cs.AI cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Exploring data is crucial in data analysis, as it helps users understand and interpret the data more effectively. However, performing effective data exploration requires in-depth knowledge of the dataset and expertise in data analysis techniques. Not being familiar with either can create obstacles that make the process time-consuming and overwhelming for data analysts. To address this issue, we introduce InsightPilot, an LLM (Large Language Model)-based, automated data exploration system designed to simplify the data exploration process. InsightPilot automatically selects appropriate analysis intents, such as understanding, summarizing, and explaining. Then, these analysis intents are concretized by issuing corresponding intentional queries (IQueries) to create a meaningful and coherent exploration sequence. In brief, an IQuery is an abstraction and automation of data analysis operations, which mimics the approach of data analysts and simplifies the exploration process for users. By employing an LLM to iteratively collaborate with a state-of-the-art insight engine via IQueries, InsightPilot is effective in analyzing real-world datasets, enabling users to gain valuable insights through natural language inquiries. We demonstrate the effectiveness of InsightPilot in a case study, showing how it can help users gain valuable insights from their datasets. ","[{'version': 'v1', 'created': 'Sun, 2 Apr 2023 07:27:49 GMT'}]",2023-04-04,"[['Ma', 'Pingchuan', ''], ['Ding', 'Rui', ''], ['Wang', 'Shuai', ''], ['Han', 'Shi', ''], ['Zhang', 'Dongmei', '']]",0,0,2023-04-02,1,5,3,0,0,0,3603e74611f1438141af17d4c73af81d8c3bc024,257912912.0,https://www.semanticscholar.org/paper/3603e74611f1438141af17d4c73af81d8c3bc024,arXiv.org,2023.0,9.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1384480816', 'name': 'Pingchuan Ma'}, {'authorId': '145789861', 'name': 'Rui Ding'}, {'authorId': '2118511999', 'name': 'Shuai Wang'}, {'authorId': '123443478', 'name': 'Shi Han'}, {'authorId': '2140415600', 'name': 'Dongmei Zhang'}]",['Microsoft'],['India'],2023-04,['industrial']
2304.01483,Gaochen Dong,"Gaochen Dong, Wei Chen",Blockwise Compression of Transformer-based Models without Retraining,"6 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:2303.09184",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformer-based models, exemplified by GPT-3, ChatGPT, and GPT-4, have recently garnered considerable attention in both academia and industry due to their promising performance in general language tasks. Nevertheless, these models typically involve computationally encoding processes, and in some cases, decoding processes as well, both of which are fundamentally large-scale matrix multiplication. These operations bring the inevitable challenges of massive computation resources and huge memory footprint, usually requiring at least 10^23 FLOPs and hundreds of gigabytes, respectively. A common method to address this issue is to reduce the computational and memory requirements by applying layerwise quantization to the transformer, replacing the usual fp32 data type with a low-bit equivalent. Unfortunately, this method often leads to decreased model accuracy and necessitates time-consuming retraining. Such retraining not only requires fine-tuning skills but also substantial computational resources, posing challenges for users. To specifically tackle these issues, we propose BCT, a framework of blockwise compression for transformers without retraining, aiming to facilitate model deployment. Unlike layerwise compression methods, BCT achieves finer compression of the entire transformer by operating blockwise. This method mitigates data distribution deviation caused by quantization, eliminating the requirement for retraining. BCT effectively compresses all components of the model, including but not limited to the embedding, matrix multiplication, GELU, Softmax, layer normalization, and intermediate results. In a case study, an efficient model is compressed by BCT achieving up to 7.988x compression. Subsequently, we also evaluate it on several General Language Understanding Evaluation (GLUE) datasets. ","[{'version': 'v1', 'created': 'Tue, 4 Apr 2023 02:55:40 GMT'}, {'version': 'v2', 'created': 'Sun, 17 Sep 2023 22:47:50 GMT'}]",2023-09-19,"[['Dong', 'Gaochen', ''], ['Chen', 'Wei', '']]",1,1,2023-04-04,2,2,2,3,0,3,4f72c61ad7f5f6379b26083fc7da52598334c503,257921638.0,https://www.semanticscholar.org/paper/4f72c61ad7f5f6379b26083fc7da52598334c503,arXiv.org,2023.0,14.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2211733371', 'name': 'Gaochen Dong'}, {'authorId': '2154939788', 'name': 'W. Chen'}]",['China Iron and Steel Research Institute Group'],['China'],2023-04,['industrial']
2304.02016,David Noever,David Noever and Samantha Elizabeth Miller Noever,The Multimodal And Modular Ai Chef: Complex Recipe Generation From Imagery,,,,,cs.CL cs.CV cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  The AI community has embraced multi-sensory or multi-modal approaches to advance this generation of AI models to resemble expected intelligent understanding. Combining language and imagery represents a familiar method for specific tasks like image captioning or generation from descriptions. This paper compares these monolithic approaches to a lightweight and specialized method based on employing image models to label objects, then serially submitting this resulting object list to a large language model (LLM). This use of multiple Application Programming Interfaces (APIs) enables better than 95% mean average precision for correct object lists, which serve as input to the latest Open AI text generator (GPT-4). To demonstrate the API as a modular alternative, we solve the problem of a user taking a picture of ingredients available in a refrigerator, then generating novel recipe cards tailored to complex constraints on cost, preparation time, dietary restrictions, portion sizes, and multiple meal plans. The research concludes that monolithic multimodal models currently lack the coherent memory to maintain context and format for this task and that until recently, the language models like GPT-2/3 struggled to format similar problems without degenerating into repetitive or non-sensical combinations of ingredients. For the first time, an AI chef or cook seems not only possible but offers some enhanced capabilities to augment human recipe libraries in pragmatic ways. The work generates a 100-page recipe book featuring the thirty top ingredients using over 2000 refrigerator images as initializing lists. ","[{'version': 'v1', 'created': 'Mon, 20 Mar 2023 01:57:52 GMT'}]",2023-04-06,"[['Noever', 'David', ''], ['Noever', 'Samantha Elizabeth Miller', '']]",0,1,2023-03-20,1,2,3,2,1,1,d4ea4646decb723198e1c9cb18042fa133b7dd22,257952356.0,https://www.semanticscholar.org/paper/d4ea4646decb723198e1c9cb18042fa133b7dd22,arXiv.org,2023.0,65.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46787948', 'name': 'David Noever'}, {'authorId': '2047999094', 'name': 'S. M. Noever'}]","['4901-D Corporate Drive, Huntsville, AL, USA, 35805']",['United States'],2023-03,['industrial']
2304.03022,Chen Li,"Chen Li, Yixiao Ge, Jiayong Mao, Dian Li, Ying Shan",TagGPT: Large Language Models are Zero-shot Multimodal Taggers,"13 pages, 6 figures",,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Tags are pivotal in facilitating the effective distribution of multimedia content in various applications in the contemporary Internet era, such as search engines and recommendation systems. Recently, large language models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. In this work, we propose TagGPT, a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion. Our core insight is that, through elaborate prompt engineering, LLMs are able to extract and reason about proper tags given textual clues of multimodal data, e.g., OCR, ASR, title, etc. Specifically, to automatically build a high-quality tag set that reflects user intent and interests for a specific application, TagGPT predicts large-scale candidate tags from a series of raw data via prompting LLMs, filtered with frequency and semantics. Given a new entity that needs tagging for distribution, TagGPT introduces two alternative options for zero-shot tagging, i.e., a generative method with late semantic matching with the tag set, and another selective method with early matching in prompts. It is well noticed that TagGPT provides a system-level solution based on a modular framework equipped with a pre-trained LLM (GPT-3.5 used here) and a sentence embedding model (SimCSE used here), which can be seamlessly replaced with any more advanced one you want. TagGPT is applicable for various modalities of data in modern social media and showcases strong generalization ability to a wide range of applications. We evaluate TagGPT on publicly available datasets, i.e., Kuaishou and Food.com, and demonstrate the effectiveness of TagGPT compared to existing hashtags and off-the-shelf taggers. Project page: https://github.com/TencentARC/TagGPT. ","[{'version': 'v1', 'created': 'Thu, 6 Apr 2023 12:17:46 GMT'}]",2023-04-07,"[['Li', 'Chen', ''], ['Ge', 'Yixiao', ''], ['Mao', 'Jiayong', ''], ['Li', 'Dian', ''], ['Shan', 'Ying', '']]",0,1,2023-04-06,1,5,1,1,0,1,4895d443c36bd136a818be2db34442354ba408d1,257984964.0,https://www.semanticscholar.org/paper/4895d443c36bd136a818be2db34442354ba408d1,arXiv.org,2023.0,23.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40475614', 'name': 'Chen Li'}, {'authorId': '152988335', 'name': 'Yixiao Ge'}, {'authorId': '2213513905', 'name': 'Jiayong Mao'}, {'authorId': '2151495740', 'name': 'Dian Li'}, {'authorId': '1387190008', 'name': 'Ying Shan'}]","['Tencent', 'Proton Collaborative Group']","['China', 'United States']",2023-04,"['industrial', 'industrial']"
2304.03277,Baolin Peng,"Baolin Peng and Chunyuan Li and Pengcheng He and Michel Galley and
  Jianfeng Gao",Instruction Tuning with GPT-4,"8 pages. Work in progress. Project page:
  https://instruction-tuning-with-gpt-4.github.io",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed. In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning. Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models. We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training. We make our data generated using GPT-4 as well as our codebase publicly available. ","[{'version': 'v1', 'created': 'Thu, 6 Apr 2023 17:58:09 GMT'}]",2023-04-07,"[['Peng', 'Baolin', ''], ['Li', 'Chunyuan', ''], ['He', 'Pengcheng', ''], ['Galley', 'Michel', ''], ['Gao', 'Jianfeng', '']]",0,1,2023-04-06,1,5,2,2,1,1,9e8cb8c91a0acb6e661b58ad724aa758490f2bea,257985497.0,https://www.semanticscholar.org/paper/9e8cb8c91a0acb6e661b58ad724aa758490f2bea,arXiv.org,2023.0,27.0,217.0,23.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1780690', 'name': 'Baolin Peng'}, {'authorId': '2109737569', 'name': 'Chunyuan Li'}, {'authorId': '50462546', 'name': 'Pengcheng He'}, {'authorId': '1947267', 'name': 'Michel Galley'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}]",['Microsoft'],['India'],2023-04,['industrial']
2304.03287,Ganesh Prasath Ramani,Ganesh Prasath and Shirish Karande,Synthesis of Mathematical programs from Natural Language Specifications,Accepted in ICLR 2023 DL4C stream,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Several decision problems that are encountered in various business domains can be modeled as mathematical programs, i.e. optimization problems. The process of conducting such modeling often requires the involvement of experts trained in operations research and advanced algorithms. Surprisingly, despite the significant advances in the methods for program and code synthesis, AutoML, learning to optimize etc., there has been little or no attention paid to automating the task of synthesizing mathematical programs. We imagine a scenario where the specifications for modeling, i.e. the objective and constraints are expressed in an unstructured form in natural language (NL) and the mathematical program has to be synthesized from such an NL specification. In this work we evaluate the efficacy of employing CodeT5 with data augmentation and post-processing of beams. We utilize GPT-3 with back translation for generation of synthetic examples. Further we apply rules of linear programming to score beams and correct beams based on common error patterns. We observe that with these enhancements CodeT5 base gives an execution accuracy of 0.73 which is significantly better than zero-shot execution accuracy of 0.41 by ChatGPT and 0.36 by Codex. ","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 06:10:00 GMT'}]",2023-04-10,"[['Prasath', 'Ganesh', ''], ['Karande', 'Shirish', '']]",1,1,2023-03-30,1,2,3,3,0,3,d9bd490aba3a7995f728594403b3358cb79aacd6,258041092.0,https://www.semanticscholar.org/paper/d9bd490aba3a7995f728594403b3358cb79aacd6,arXiv.org,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2084478142', 'name': 'G. Prasath'}, {'authorId': '40151143', 'name': 'S. Karande'}]",['Tata Consultancy Services (India)'],['India'],2023-03,['industrial']
2304.03816,Sarah Fakhoury,"Sarah Fakhoury, Saikat Chakraborty, Madan Musuvathi, and Shuvendu K.
  Lahiri",Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions,,,,,cs.SE cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs), such as OpenAI's Codex, have demonstrated their potential to generate code from natural language descriptions across a wide range of programming tasks. Several benchmarks have recently emerged to evaluate the ability of LLMs to generate functionally correct code from natural language intent with respect to a set of hidden test cases. This has enabled the research community to identify significant and reproducible advancements in LLM capabilities. However, there is currently a lack of benchmark datasets for assessing the ability of LLMs to generate functionally correct code edits based on natural language descriptions of intended changes. This paper aims to address this gap by motivating the problem NL2Fix of translating natural language descriptions of code changes (namely bug fixes described in Issue reports in repositories) into correct code fixes. To this end, we introduce Defects4J-NL2Fix, a dataset of 283 Java programs from the popular Defects4J dataset augmented with high-level descriptions of bug fixes, and empirically evaluate the performance of several state-of-the-art LLMs for the this task. Results show that these LLMS together are capable of generating plausible fixes for 64.6% of the bugs, and the best LLM-based technique can achieve up to 21.20% top-1 and 35.68% top-5 accuracy on this benchmark. ","[{'version': 'v1', 'created': 'Fri, 7 Apr 2023 18:58:33 GMT'}]",2023-04-11,"[['Fakhoury', 'Sarah', ''], ['Chakraborty', 'Saikat', ''], ['Musuvathi', 'Madan', ''], ['Lahiri', 'Shuvendu K.', '']]",0,0,2023-04-07,1,4,2,1,0,1,34d12432af63915caf14eab9a362f7e7d24e4c13,258049098.0,https://www.semanticscholar.org/paper/34d12432af63915caf14eab9a362f7e7d24e4c13,arXiv.org,2023.0,60.0,12.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40895660', 'name': 'Sarah Fakhoury'}, {'authorId': '47570053', 'name': 'Saikat Chakraborty'}, {'authorId': '1702346', 'name': 'M. Musuvathi'}, {'authorId': '145474353', 'name': 'Shuvendu K. Lahiri'}]",['Microsoft'],['India'],2023-04,['industrial']
2304.04498,Naruya Kondo,"Yoichi Ochiai, Naruya Kondo, Tatsuki Fushimi",Towards Digital Nature: Bridging the Gap between Turing Machine Objects and Linguistic Objects in LLMMs for Universal Interaction of Object-Oriented Descriptions,"10 pages, 6 figures",,,,cs.HC,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose a novel approach to establish a connection between linguistic objects and classes in Large Language Model Machines (LLMMs) such as GPT3.5 and GPT4, and their counterparts in high level programming languages like Python. Our goal is to promote the development of Digital Nature: a worldview where digital and physical realities are seamlessly intertwined and can be easily manipulated by computational means. To achieve this, we exploit the inherent abstraction capabilities of LLMMs to build a bridge between human perception of the real world and the computational processes that mimic it. This approach enables ambiguous class definitions and interactions between objects to be realized in programming and ubiquitous computing scenarios. By doing so, we aim to facilitate seamless interaction between Turing Machine objects and Linguistic Objects, paving the way for universally accessible object oriented descriptions. We demonstrate a method for automatically transforming real world objects and their corresponding simulations into language simulable worlds using LLMMs, thus advancing the digital twin concept. This process can then be extended to high level programming languages, making the implementation of these simulations more accessible and practical. In summary, our research introduces a groundbreaking approach to connect linguistic objects in LLMMs with high level programming languages, allowing for the efficient implementation of real world simulations. This ultimately contributes to the realization of Digital Nature, where digital and physical worlds are interconnected, and objects and simulations can be effortlessly manipulated through computational means. ","[{'version': 'v1', 'created': 'Mon, 10 Apr 2023 10:25:55 GMT'}, {'version': 'v2', 'created': 'Wed, 12 Apr 2023 11:48:48 GMT'}]",2023-04-13,"[['Ochiai', 'Yoichi', ''], ['Kondo', 'Naruya', ''], ['Fushimi', 'Tatsuki', '']]",0,1,2023-04-10,2,3,1,2,0,2,3452746bfda18dd59dad9ce5a5802f721a10a4d4,258049252.0,https://www.semanticscholar.org/paper/3452746bfda18dd59dad9ce5a5802f721a10a4d4,arXiv.org,2023.0,23.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2059595927', 'name': 'Y. Ochiai'}, {'authorId': '2028904904', 'name': 'Naruya Kondo'}, {'authorId': '52567877', 'name': 'Tatsuki Fushimi'}]","['and for Digital Nature, of , ,']",,2023-04,['industrial']
2304.04576,Jane Dwivedi-Yu,Alon Halevy and Jane Dwivedi-Yu,Learnings from Data Integration for Augmented Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One of the limitations of large language models is that they do not have access to up-to-date, proprietary or personal data. As a result, there are multiple efforts to extend language models with techniques for accessing external data. In that sense, LLMs share the vision of data integration systems whose goal is to provide seamless access to a large collection of heterogeneous data sources. While the details and the techniques of LLMs differ greatly from those of data integration, this paper shows that some of the lessons learned from research on data integration can elucidate the research path we are conducting today on language models. ","[{'version': 'v1', 'created': 'Mon, 10 Apr 2023 13:28:35 GMT'}]",2023-04-11,"[['Halevy', 'Alon', ''], ['Dwivedi-Yu', 'Jane', '']]",0,0,2023-04-10,1,2,1,0,0,0,2bc5239c7696598ec64ceaa26a859ff6480f6dda,258048409.0,https://www.semanticscholar.org/paper/2bc5239c7696598ec64ceaa26a859ff6480f6dda,arXiv.org,2023.0,12.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1770962', 'name': 'A. Halevy'}, {'authorId': '2173509991', 'name': 'Jane Dwivedi-Yu'}]",['Meta'],['United States'],2023-04,['industrial']
2304.05511,Urmish Thakker,"Venkat Srinivasan, Darshan Gandhi, Urmish Thakker and Raghu Prabhakar",Training Large Language Models Efficiently with Sparsity and Dataflow,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large foundation language models have shown their versatility in being able to be adapted to perform a wide variety of downstream tasks, such as text generation, sentiment analysis, semantic search etc. However, training such large foundational models is a non-trivial exercise that requires a significant amount of compute power and expertise from machine learning and systems experts. As models get larger, these demands are only increasing. Sparsity is a promising technique to relieve the compute requirements for training. However, sparsity introduces new challenges in training the sparse model to the same quality as the dense counterparts. Furthermore, sparsity drops the operation intensity and introduces irregular memory access patterns that makes it challenging to efficiently utilize compute resources. This paper demonstrates an end-to-end training flow on a large language model - 13 billion GPT - using sparsity and dataflow. The dataflow execution model and architecture enables efficient on-chip irregular memory accesses as well as native kernel fusion and pipelined parallelism that helps recover device utilization. We show that we can successfully train GPT 13B to the same quality as the dense GPT 13B model, while achieving an end-end speedup of 4.5x over dense A100 baseline. ","[{'version': 'v1', 'created': 'Tue, 11 Apr 2023 21:37:13 GMT'}]",2023-04-13,"[['Srinivasan', 'Venkat', ''], ['Gandhi', 'Darshan', ''], ['Thakker', 'Urmish', ''], ['Prabhakar', 'Raghu', '']]",0,1,2023-04-11,1,4,1,0,0,0,0312e70901f352a6d95f23573788f9f7b737c983,258079324.0,https://www.semanticscholar.org/paper/0312e70901f352a6d95f23573788f9f7b737c983,arXiv.org,2023.0,55.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145949278', 'name': 'V. Srinivasan'}, {'authorId': '144280544', 'name': 'Darshan Gandhi'}, {'authorId': '70296695', 'name': 'Urmish Thakker'}, {'authorId': '2688640', 'name': 'R. Prabhakar'}]",['VA Palo Alto Health Care System'],['United States'],2023-04,['industrial']
2304.05969,Christopher MacLeod,"Nicholas Goldowsky-Dill, Chris MacLeod, Lucas Sato, Aryaman Arora",Localizing Model Behavior with Path Patching,"20 pages, 16 figures",,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Localizing behaviors of neural networks to a subset of the network's components or a subset of interactions between components is a natural first step towards analyzing network mechanisms and possible failure modes. Existing work is often qualitative and ad-hoc, and there is no consensus on the appropriate way to evaluate localization claims. We introduce path patching, a technique for expressing and quantitatively testing a natural class of hypotheses expressing that behaviors are localized to a set of paths. We refine an explanation of induction heads, characterize a behavior of GPT-2, and open source a framework for efficiently running similar experiments. ","[{'version': 'v1', 'created': 'Wed, 12 Apr 2023 16:46:43 GMT'}, {'version': 'v2', 'created': 'Tue, 16 May 2023 16:24:55 GMT'}]",2023-05-17,"[['Goldowsky-Dill', 'Nicholas', ''], ['MacLeod', 'Chris', ''], ['Sato', 'Lucas', ''], ['Arora', 'Aryaman', '']]",0,1,2023-04-12,2,4,1,1,1,0,8d8fc878bf4c7005546c866824a72d0c46ca91a3,258079237.0,https://www.semanticscholar.org/paper/8d8fc878bf4c7005546c866824a72d0c46ca91a3,arXiv.org,2023.0,27.0,11.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1446593290', 'name': 'Nicholas W. Goldowsky-Dill'}, {'authorId': '2214462349', 'name': 'Chris MacLeod'}, {'authorId': '1948167532', 'name': 'L. Sato'}, {'authorId': '1575802390', 'name': 'Aryaman Arora'}]",['Redwood Research'],,2023-04,['industrial']
2304.06123,Tarry Singh,Tarry Singh,The Impact of Large Language Multi-Modal Models on the Future of Job Market,"16 pages, 1 Table",,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  The rapid advancements in artificial intelligence, particularly in large language multi-modal models like GPT-4, have raised concerns about the potential displacement of human workers in various industries. This position paper aims to analyze the current state of job replacement by AI models and explores potential implications and strategies for a balanced coexistence between AI and human workers. ","[{'version': 'v1', 'created': 'Wed, 22 Mar 2023 16:33:57 GMT'}]",2023-04-14,"[['Singh', 'Tarry', '']]",0,1,2023-03-22,1,1,1,1,0,1,b30f09043449b9d55ad7978086359ef6c76fec36,258108234.0,https://www.semanticscholar.org/paper/b30f09043449b9d55ad7978086359ef6c76fec36,arXiv.org,2023.0,3.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '21914709', 'name': 'Tarry Singh'}]","['Department of AI Research deepkapha AI Research 9401 GE, Assen The Netherlands']",['Netherlands'],2023-03,['industrial']
2304.07854,Baochang Ma,"Yunjie Ji, Yan Gong, Yong Deng, Yiping Peng, Qiang Niu, Baochang Ma,
  Xiangang Li",Towards Better Instruction Following Language Models for Chinese: Investigating the Impact of Training Data and Evaluation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, significant public efforts have been directed towards developing low-cost models with capabilities akin to ChatGPT, thereby fostering the growth of open-source conversational models. However, there remains a scarcity of comprehensive and in-depth evaluations of these models' performance. In this study, we examine the influence of training data factors, including quantity, quality, and linguistic distribution, on model performance. Our analysis is grounded in several publicly accessible, high-quality instruction datasets, as well as our own Chinese multi-turn conversations. We assess various models using a evaluation set of 1,000 samples, encompassing nine real-world scenarios. Our goal is to supplement manual evaluations with quantitative analyses, offering valuable insights for the continued advancement of open-source chat models. Furthermore, to enhance the performance and training and inference efficiency of models in the Chinese domain, we extend the vocabulary of LLaMA - the model with the closest open-source performance to proprietary language models like GPT-3 - and conduct secondary pre-training on 3.4B Chinese words. We make our model, data, as well as code publicly available. ","[{'version': 'v1', 'created': 'Sun, 16 Apr 2023 18:37:39 GMT'}]",2023-04-18,"[['Ji', 'Yunjie', ''], ['Gong', 'Yan', ''], ['Deng', 'Yong', ''], ['Peng', 'Yiping', ''], ['Niu', 'Qiang', ''], ['Ma', 'Baochang', ''], ['Li', 'Xiangang', '']]",1,1,2023-04-16,1,7,1,3,1,2,a8d740aff768210d21bf30cd83bab156d78a232a,258180415.0,https://www.semanticscholar.org/paper/a8d740aff768210d21bf30cd83bab156d78a232a,arXiv.org,2023.0,58.0,7.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '24780166', 'name': 'Yunjie Ji'}, {'authorId': '2211736448', 'name': 'Yan Gong'}, {'authorId': '2111213765', 'name': 'Yang Deng'}, {'authorId': '2111015160', 'name': 'Yiping Peng'}, {'authorId': '2212854899', 'name': 'Qiang Niu'}, {'authorId': '152358488', 'name': 'Baochang Ma'}, {'authorId': '1898780', 'name': 'Xiangang Li'}]","['Bell (Canada)', 'Beike']","['China', 'Canada']",2023-04,"['industrial', 'industrial']"
2304.08103,Shaoguang Mao,"Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge,
  Chenfei Wu, Wang You, Ting Song, Yan Xia, Jonathan Tien, Nan Duan",Low-code LLM: Visual Programming over LLMs,,,,,cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Effectively utilizing LLMs for complex tasks is challenging, often involving a time-consuming and uncontrollable prompt engineering process. This paper introduces a novel human-LLM interaction framework, Low-code LLM. It incorporates six types of simple low-code visual programming interactions, all supported by clicking, dragging, or text editing, to achieve more controllable and stable responses. Through visual interaction with a graphical user interface, users can incorporate their ideas into the workflow without writing trivial prompts. The proposed Low-code LLM framework consists of a Planning LLM that designs a structured planning workflow for complex tasks, which can be correspondingly edited and confirmed by users through low-code visual programming operations, and an Executing LLM that generates responses following the user-confirmed workflow. We highlight three advantages of the low-code LLM: controllable generation results, user-friendly human-LLM interaction, and broadly applicable scenarios. We demonstrate its benefits using four typical applications. By introducing this approach, we aim to bridge the gap between humans and LLMs, enabling more effective and efficient utilization of LLMs for complex tasks. Our system will be soon publicly available at LowCodeLLM. ","[{'version': 'v1', 'created': 'Mon, 17 Apr 2023 09:27:40 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Apr 2023 06:42:24 GMT'}]",2023-04-21,"[['Cai', 'Yuzhe', ''], ['Mao', 'Shaoguang', ''], ['Wu', 'Wenshan', ''], ['Wang', 'Zehua', ''], ['Liang', 'Yaobo', ''], ['Ge', 'Tao', ''], ['Wu', 'Chenfei', ''], ['You', 'Wang', ''], ['Song', 'Ting', ''], ['Xia', 'Yan', ''], ['Tien', 'Jonathan', ''], ['Duan', 'Nan', '']]",0,0,2023-04-17,2,12,2,0,0,0,be2b0396de9431bae931642516a1d3e4906329f5,258180418.0,https://www.semanticscholar.org/paper/be2b0396de9431bae931642516a1d3e4906329f5,arXiv.org,2023.0,27.0,11.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '116275985', 'name': 'Yuzhe Cai'}, {'authorId': '35374367', 'name': 'Shaoguang Mao'}, {'authorId': '51198241', 'name': 'Wenshan Wu'}, {'authorId': '2108725194', 'name': 'Zehua Wang'}, {'authorId': '3887469', 'name': 'Yaobo Liang'}, {'authorId': '48741177', 'name': 'Tao Ge'}, {'authorId': '2151101534', 'name': 'Chenfei Wu'}, {'authorId': '2214585980', 'name': 'Wang You'}, {'authorId': '2212903837', 'name': 'Ting Song'}, {'authorId': '2111130689', 'name': 'Yan Xia'}, {'authorId': '2069738994', 'name': 'Jonathan Tien'}, {'authorId': '2072609829', 'name': 'Nan Duan'}]",['Microsoft'],['China'],2023-04,['industrial']
2304.08109,Baochang Ma,"Xianghui Sun, Yunjie Ji, Baochang Ma, Xiangang Li",A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on Chinese Instruction Data for Instruction Following Large Language Model,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, the instruction-tuning of large language models is a crucial area of research in the field of natural language processing. Due to resource and cost limitations, several researchers have employed parameter-efficient tuning techniques, such as LoRA, for instruction tuning, and have obtained encouraging results In comparison to full-parameter fine-tuning, LoRA-based tuning demonstrates salient benefits in terms of training costs. In this study, we undertook experimental comparisons between full-parameter fine-tuning and LoRA-based tuning methods, utilizing LLaMA as the base model. The experimental results show that the selection of the foundational model, training dataset scale, learnable parameter quantity, and model training cost are all important factors. We hope that the experimental conclusions of this paper can provide inspiration for training large language models, especially in the field of Chinese, and help researchers find a better trade-off strategy between training cost and model performance. To facilitate the reproduction of the paper's results, the dataset, model and code will be released. ","[{'version': 'v1', 'created': 'Mon, 17 Apr 2023 09:36:36 GMT'}, {'version': 'v2', 'created': 'Tue, 18 Apr 2023 03:08:18 GMT'}]",2023-04-19,"[['Sun', 'Xianghui', ''], ['Ji', 'Yunjie', ''], ['Ma', 'Baochang', ''], ['Li', 'Xiangang', '']]",0,0,2023-04-17,2,4,1,1,1,0,f05011f5a485e59896db81c8700c27e7d5c6622f,258179474.0,https://www.semanticscholar.org/paper/f05011f5a485e59896db81c8700c27e7d5c6622f,arXiv.org,2023.0,48.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49816188', 'name': 'Xianghui Sun'}, {'authorId': '24780166', 'name': 'Yunjie Ji'}, {'authorId': '152358488', 'name': 'Baochang Ma'}, {'authorId': '1898780', 'name': 'Xiangang Li'}]","['Bell (Canada)', 'Beike']","['China', 'Canada']",2023-04,"['industrial', 'industrial']"
2304.08979,Xinyue Shen,Xinyue Shen and Zeyuan Chen and Michael Backes and Yang Zhang,In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT,,,,,cs.CR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The way users acquire information is undergoing a paradigm shift with the advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves knowledge from the model itself and generates answers for users. ChatGPT's impressive question-answering (QA) capability has attracted more than 100 million users within a short period of time but has also raised concerns regarding its reliability. In this paper, we perform the first large-scale measurement of ChatGPT's reliability in the generic QA scenario with a carefully curated set of 5,695 questions across ten datasets and eight domains. We find that ChatGPT's reliability varies across different domains, especially underperforming in law and science questions. We also demonstrate that system roles, originally designed by OpenAI to allow users to steer ChatGPT's behavior, can impact ChatGPT's reliability in an imperceptible way. We further show that ChatGPT is vulnerable to adversarial examples, and even a single character change can negatively affect its reliability in certain cases. We believe that our study provides valuable insights into ChatGPT's reliability and underscores the need for strengthening the reliability and security of large language models (LLMs). ","[{'version': 'v1', 'created': 'Tue, 18 Apr 2023 13:20:45 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Oct 2023 13:27:12 GMT'}]",2023-10-06,"[['Shen', 'Xinyue', ''], ['Chen', 'Zeyuan', ''], ['Backes', 'Michael', ''], ['Zhang', 'Yang', '']]",1,1,2023-04-18,2,4,2,1,0,1,ba82f8aa4526c326dc0e82e7443a017a409b865a,258187122.0,https://www.semanticscholar.org/paper/ba82f8aa4526c326dc0e82e7443a017a409b865a,arXiv.org,2023.0,78.0,26.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2047395411', 'name': 'Xinyue Shen'}, {'authorId': '2111435173', 'name': 'Z. Chen'}, {'authorId': '144588806', 'name': 'M. Backes'}, {'authorId': '1698138', 'name': 'Yang Zhang'}]","['Helmholtz Center for Information Security', 'Individual Researcher']",['Germany'],2023-04,"['industrial', 'industrial']"
2304.09823,Hengshu Zhu,"Lan Chen, Xi Chen, Shiyu Wu, Yaqi Yang, Meng Chang, Hengshu Zhu",The Future of ChatGPT-enabled Labor Market: A Preliminary Study,,,,,cs.CY cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As a phenomenal large language model, ChatGPT has achieved unparalleled success in various real-world tasks and increasingly plays an important role in our daily lives and work. However, extensive concerns are also raised about the potential ethical issues, especially about whether ChatGPT-like artificial general intelligence (AGI) will replace human jobs. To this end, in this paper, we introduce a preliminary data-driven study on the future of ChatGPT-enabled labor market from the view of Human-AI Symbiosis instead of Human-AI Confrontation. To be specific, we first conduct an in-depth analysis of large-scale job posting data in BOSS Zhipin, the largest online recruitment platform in China. The results indicate that about 28% of occupations in the current labor market require ChatGPT-related skills. Furthermore, based on a large-scale occupation-centered knowledge graph, we develop a semantic information enhanced collaborative filtering algorithm to predict the future occupation-skill relations in the labor market. As a result, we find that additional 45% occupations in the future will require ChatGPT-related skills. In particular, industries related to technology, products, and operations are expected to have higher proficiency requirements for ChatGPT-related skills, while the manufacturing, services, education, and health science related industries will have lower requirements for ChatGPT-related skills. ","[{'version': 'v1', 'created': 'Fri, 14 Apr 2023 06:56:35 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Apr 2023 10:10:48 GMT'}, {'version': 'v3', 'created': 'Mon, 4 Sep 2023 09:15:24 GMT'}]",2023-09-06,"[['Chen', 'Lan', ''], ['Chen', 'Xi', ''], ['Wu', 'Shiyu', ''], ['Yang', 'Yaqi', ''], ['Chang', 'Meng', ''], ['Zhu', 'Hengshu', '']]",1,1,2023-04-14,3,6,2,1,0,1,7387a9a614e2289e18c328e4c16bb25421c54ff7,258212806.0,https://www.semanticscholar.org/paper/7387a9a614e2289e18c328e4c16bb25421c54ff7,arXiv.org,2023.0,5.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2214736837', 'name': 'Lan Chen'}, {'authorId': '66273808', 'name': 'Xi Chen'}, {'authorId': '48915053', 'name': 'Shiyu Wu'}, {'authorId': '2144142655', 'name': 'Yaqi Yang'}, {'authorId': '2214829057', 'name': 'Meng Chang'}, {'authorId': '1968806', 'name': 'Hengshu Zhu'}]","['Career Science Lab, BOSS Zhipin.']",,2023-04,['industrial']
2304.09871,Igor Molybog,"Igor Molybog, Peter Albert, Moya Chen, Zachary DeVito, David Esiobu,
  Naman Goyal, Punit Singh Koura, Sharan Narang, Andrew Poulton, Ruan Silva,
  Binh Tang, Diana Liskovich, Puxin Xu, Yuchen Zhang, Melanie Kambadur, Stephen
  Roller, Susan Zhang",A Theory on Adam Instability in Large-Scale Machine Learning,,,,,cs.LG cs.AI math.OC,http://creativecommons.org/licenses/by/4.0/,"  We present a theory for the previously unexplained divergent behavior noticed in the training of large language models. We argue that the phenomenon is an artifact of the dominant optimization algorithm used for training, called Adam. We observe that Adam can enter a state in which the parameter update vector has a relatively large norm and is essentially uncorrelated with the direction of descent on the training loss landscape, leading to divergence. This artifact is more likely to be observed in the training of a deep model with a large batch size, which is the typical setting of large-scale language model training. To argue the theory, we present observations from the training runs of the language models of different scales: 7 billion, 30 billion, 65 billion, and 546 billion parameters. ","[{'version': 'v1', 'created': 'Wed, 19 Apr 2023 06:15:11 GMT'}, {'version': 'v2', 'created': 'Tue, 25 Apr 2023 04:48:47 GMT'}]",2023-04-26,"[['Molybog', 'Igor', ''], ['Albert', 'Peter', ''], ['Chen', 'Moya', ''], ['DeVito', 'Zachary', ''], ['Esiobu', 'David', ''], ['Goyal', 'Naman', ''], ['Koura', 'Punit Singh', ''], ['Narang', 'Sharan', ''], ['Poulton', 'Andrew', ''], ['Silva', 'Ruan', ''], ['Tang', 'Binh', ''], ['Liskovich', 'Diana', ''], ['Xu', 'Puxin', ''], ['Zhang', 'Yuchen', ''], ['Kambadur', 'Melanie', ''], ['Roller', 'Stephen', ''], ['Zhang', 'Susan', '']]",0,0,2023-04-19,2,17,3,0,0,0,88c94b11bd18161d027a28dd758b58698063e029,258236633.0,https://www.semanticscholar.org/paper/88c94b11bd18161d027a28dd758b58698063e029,arXiv.org,2023.0,27.0,8.0,1.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66839644', 'name': 'Igor Molybog'}, {'authorId': '2214809450', 'name': 'Peter Albert'}, {'authorId': '2108267192', 'name': 'Moya Chen'}, {'authorId': '2375710', 'name': 'Zach DeVito'}, {'authorId': '71039937', 'name': 'David Esiobu'}, {'authorId': '39589154', 'name': 'Naman Goyal'}, {'authorId': '2146367061', 'name': 'Punit Singh Koura'}, {'authorId': '46617804', 'name': 'Sharan Narang'}, {'authorId': '38579672', 'name': 'Andrew Poulton'}, {'authorId': '2214818043', 'name': 'Ruan Silva'}, {'authorId': '71292072', 'name': 'Binh Tang'}, {'authorId': '2145259939', 'name': 'Diana Liskovich'}, {'authorId': '2214843767', 'name': 'Puxin Xu'}, {'authorId': '2108473229', 'name': 'Yuchen Zhang'}, {'authorId': '2272979', 'name': 'Melanie Kambadur'}, {'authorId': '3849208', 'name': 'Stephen Roller'}, {'authorId': '2108244542', 'name': 'Susan Zhang'}]",['Meta'],['United States'],2023-04,['industrial']
2304.10417,Nikos Athanasiou,"Nikos Athanasiou, Mathis Petrovich, Michael J. Black and G\""ul Varol",SINC: Spatial Composition of 3D Human Motions for Simultaneous Action Generation,ICCV 2023 Camera Ready,,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our goal is to synthesize 3D human motions given textual inputs describing simultaneous actions, for example 'waving hand' while 'walking' at the same time. We refer to generating such simultaneous movements as performing 'spatial compositions'. In contrast to temporal compositions that seek to transition from one action to another, spatial compositing requires understanding which body parts are involved in which action, to be able to move them simultaneously. Motivated by the observation that the correspondence between actions and body parts is encoded in powerful language models, we extract this knowledge by prompting GPT-3 with text such as ""what are the body parts involved in the action <action name>?"", while also providing the parts list and few-shot examples. Given this action-part mapping, we combine body parts from two motions together and establish the first automated method to spatially compose two actions. However, training data with compositional actions is always limited by the combinatorics. Hence, we further create synthetic data with this approach, and use it to train a new state-of-the-art text-to-motion generation model, called SINC (""SImultaneous actioN Compositions for 3D human motions""). In our experiments, that training with such GPT-guided synthetic data improves spatial composition generation over baselines. Our code is publicly available at https://sinc.is.tue.mpg.de/. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 16:01:55 GMT'}, {'version': 'v2', 'created': 'Sat, 19 Aug 2023 20:34:13 GMT'}]",2023-08-22,"[['Athanasiou', 'Nikos', ''], ['Petrovich', 'Mathis', ''], ['Black', 'Michael J.', ''], ['Varol', 'Gül', '']]",0,1,2023-04-20,2,4,1,1,0,1,ff969f811673061e50ba2c384e3034ce30c1d561,258236650.0,https://www.semanticscholar.org/paper/ff969f811673061e50ba2c384e3034ce30c1d561,arXiv.org,2023.0,75.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51174183', 'name': 'Nikos Athanasiou'}, {'authorId': '1562113276', 'name': 'Mathis Petrovich'}, {'authorId': '2105795', 'name': 'Michael J. Black'}, {'authorId': '2668759', 'name': 'Gül Varol'}]","[""Laboratoire d'Informatique Gaspard-Monge"", 'Max Planck Institute for Intelligent Systems']","['Germany', 'France']",2023-04,"['industrial', 'industrial']"
2304.10427,Ana Claudia Sima,Ana-Claudia Sima and Tarcisio Mendes de Farias,On the Potential of Artificial Intelligence Chatbots for Data Exploration of Federated Bioinformatics Knowledge Graphs,,,,https://ceur-ws.org/Vol-3466/paper1.pdf,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present work in progress on the role of artificial intelligence (AI) chatbots, such as ChatGPT, in facilitating data access to federated knowledge graphs. In particular, we provide examples from the field of bioinformatics, to illustrate the potential use of Conversational AI to describe datasets, as well as generate and explain (federated) queries across datasets for the benefit of domain experts. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 16:16:40 GMT'}]",2023-09-27,"[['Sima', 'Ana-Claudia', ''], ['de Farias', 'Tarcisio Mendes', '']]",1,1,2023-04-20,1,2,1,1,0,1,2dc6d884562c89514bb10e5a20028bbf0dda9548,258236513.0,https://www.semanticscholar.org/paper/2dc6d884562c89514bb10e5a20028bbf0dda9548,SeWeBMeDA@ESWC,2023.0,12.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2723088', 'name': 'A. Sima'}, {'authorId': '1725471', 'name': 'T. M. Farias'}]",['SIB Swiss Institute of Bioinformatics'],['Switzerland'],2023-04,['industrial']
2304.10548,Ziang Xiao,"Ziang Xiao, Xingdi Yuan, Q. Vera Liao, Rania Abdelghani, Pierre-Yves
  Oudeyer",Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding,"28th International Conference on Intelligent User Interfaces (IUI '23
  Companion), March 27--31, 2023, Sydney, NSW, Australia",,10.1145/3581754.3584136,,cs.CL cs.AI cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Qualitative analysis of textual contents unpacks rich and valuable information by assigning labels to the data. However, this process is often labor-intensive, particularly when working with large datasets. While recent AI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let alone be challenged by the limited generalizability of those task-specific models. In this study, we explored the use of large language models (LLMs) in supporting deductive coding, a major category of qualitative analysis where researchers use pre-determined codebooks to label the data into a fixed set of codes. Instead of training task-specific models, a pre-trained LLM could be used directly for various tasks without fine-tuning through prompt learning. Using a curiosity-driven questions coding task as a case study, we found, by combining GPT-3 with expert-drafted codebooks, our proposed approach achieved fair to substantial agreements with expert-coded results. We lay out challenges and opportunities in using LLMs to support qualitative coding and beyond. ","[{'version': 'v1', 'created': 'Mon, 17 Apr 2023 04:52:43 GMT'}]",2023-04-24,"[['Xiao', 'Ziang', ''], ['Yuan', 'Xingdi', ''], ['Liao', 'Q. Vera', ''], ['Abdelghani', 'Rania', ''], ['Oudeyer', 'Pierre-Yves', '']]",0,1,2023-04-17,1,5,3,1,0,1,6a3d0b11a0b22bafcce7739cc5eb12dad8bd7565,257758261.0,https://www.semanticscholar.org/paper/6a3d0b11a0b22bafcce7739cc5eb12dad8bd7565,IUI Companion,2023.0,16.0,22.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '9605732', 'name': 'Ziang Xiao'}, {'authorId': '2854297', 'name': 'Xingdi Yuan'}, {'authorId': '144921048', 'name': 'Q. Liao'}, {'authorId': '2154047060', 'name': 'Rania Abdelghani'}, {'authorId': '1720664', 'name': 'Pierre-Yves Oudeyer'}]","['PIERRE-YVES OUDEYER, Inria, France']",['France'],2023-04,['industrial']
2304.10977,Matteo Muffo,"Matteo Muffo, Aldo Cocco, Enrico Bertino",Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition,"7 pages, 1 figure, published at LREC 2022","Proceedings of the 13th Conference on Language Resources and
  Evaluation (LREC 2022), pages 291-297",,,cs.CL stat.ML,http://creativecommons.org/licenses/by/4.0/,"  In recent years, Large Language Models such as GPT-3 showed remarkable capabilities in performing NLP tasks in the zero and few shot settings. On the other hand, the experiments highlighted the difficulty of GPT-3 in carrying out tasks that require a certain degree of reasoning, such as arithmetic operations. In this paper we evaluate the ability of Transformer Language Models to perform arithmetic operations following a pipeline that, before performing computations, decomposes numbers in units, tens, and so on. We denote the models fine-tuned with this pipeline with the name Calculon and we test them in the task of performing additions, subtractions and multiplications on the same test sets of GPT-3. Results show an increase of accuracy of 63% in the five-digit addition task. Moreover, we demonstrate the importance of the decomposition pipeline introduced, since fine-tuning the same Language Model without decomposing numbers results in 0% accuracy in the five-digit addition task. ","[{'version': 'v1', 'created': 'Fri, 21 Apr 2023 14:21:52 GMT'}]",2023-04-24,"[['Muffo', 'Matteo', ''], ['Cocco', 'Aldo', ''], ['Bertino', 'Enrico', '']]",0,1,2023-04-21,1,3,2,1,0,1,a5808ccc50f77083bd3be926fb2af05cf34563ff,251406206.0,https://www.semanticscholar.org/paper/a5808ccc50f77083bd3be926fb2af05cf34563ff,International Conference on Language Resources and Evaluation,2023.0,22.0,13.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2038110760', 'name': 'Matteo Muffo'}, {'authorId': '2005057281', 'name': 'A. Cocco'}, {'authorId': '2065641522', 'name': 'Enrico Bertino'}]","['Indigo.ai Via Torino 61, Milan, Italy']",['Italy'],2023-04,['industrial']
2304.11075,Cl\'ement Sicard,"Clement Sicard, Kajetan Pyszkowski, Victor Gillioz",Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects,"8 pages, SwissText conference","Swiss Text Analytics Conference, 2023",,,cs.CL cs.LG cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Recent breakthroughs in NLP largely increased the presence of ASR systems in our daily lives. However, for many low-resource languages, ASR models still need to be improved due in part to the difficulty of acquiring pertinent data. This project aims to help advance research in ASR models for Swiss German dialects, by providing insights about the performance of state-of-the-art ASR models on recently published Swiss German speech datasets. We propose a novel loss that takes into account the semantic distance between the predicted and the ground-truth labels. We outperform current state-of-the-art results by fine-tuning OpenAI's Whisper model on Swiss-German datasets. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 14:42:54 GMT'}, {'version': 'v2', 'created': 'Wed, 13 Sep 2023 16:12:56 GMT'}]",2023-09-14,"[['Sicard', 'Clement', ''], ['Pyszkowski', 'Kajetan', ''], ['Gillioz', 'Victor', '']]",0,0,2023-04-20,2,3,4,0,0,0,849bb44a67e02269e6668a2374a96d4adaa6f861,258291445.0,https://www.semanticscholar.org/paper/849bb44a67e02269e6668a2374a96d4adaa6f861,arXiv.org,2023.0,25.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2215168485', 'name': ""Cl'ement Sicard""}, {'authorId': '2215168906', 'name': 'Kajetan Pyszkowski'}, {'authorId': '2124394656', 'name': 'Victor Gillioz'}]",['ETH Zurich'],['Switzerland'],2023-04,['industrial']
2304.12272,Young-Suk Lee Dr.,"Young-Suk Lee, Ram\'on Fernandez Astudillo, Radu Florian, Tahira
  Naseem, Salim Roukos",AMR Parsing with Instruction Fine-tuned Pre-trained Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Instruction fine-tuned language models on a collection of instruction annotated datasets (FLAN) have shown highly effective to improve model performance and generalization to unseen tasks. However, a majority of standard parsing tasks including abstract meaning representation (AMR), universal dependency (UD), semantic role labeling (SRL) has been excluded from the FLAN collections for both model training and evaluations. In this paper, we take one of such instruction fine-tuned pre-trained language models, i.e. FLAN-T5, and fine-tune them for AMR parsing. Our extensive experiments on various AMR parsing tasks including AMR2.0, AMR3.0 and BioAMR indicate that FLAN-T5 fine-tuned models out-perform previous state-of-the-art models across all tasks. In addition, full fine-tuning followed by the parameter efficient fine-tuning, LoRA, further improves the model performances, setting new state-of-the-arts in Smatch on AMR2.0 (86.4), AMR3.0 (84.9) and BioAMR (82.3). ","[{'version': 'v1', 'created': 'Mon, 24 Apr 2023 17:12:17 GMT'}]",2023-04-25,"[['Lee', 'Young-Suk', ''], ['Astudillo', 'Ramón Fernandez', ''], ['Florian', 'Radu', ''], ['Naseem', 'Tahira', ''], ['Roukos', 'Salim', '']]",0,0,2023-04-24,1,5,2,3,2,1,1e4acf7ec40e6477d8cbb3a956838dbd90c6c150,258298140.0,https://www.semanticscholar.org/paper/1e4acf7ec40e6477d8cbb3a956838dbd90c6c150,arXiv.org,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2145430350', 'name': 'Young-Suk Lee'}, {'authorId': '3394760', 'name': 'Ramón Fernández Astudillo'}, {'authorId': '1707117', 'name': 'Radu Florian'}, {'authorId': '2138053379', 'name': 'Tahira Naseem'}, {'authorId': '1781292', 'name': 'S. Roukos'}]",['IBM (United States)'],['United States'],2023-04,['industrial']
2304.14178,Qinghao Ye,"Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou,
  Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu,
  Hehong Chen, Junfeng Tian, Qian Qi, Ji Zhang, Fei Huang",mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality,Working in Process,,,,cs.CL cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated impressive zero-shot abilities on a variety of open-ended tasks, while recent research has also explored the use of LLMs for multi-modal generation. In this study, we introduce mPLUG-Owl, a novel training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. This approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The training paradigm of mPLUG-Owl involves a two-stage method for aligning image and text, which learns visual knowledge with the assistance of LLM while maintaining and even improving the generation abilities of LLM. In the first stage, the visual knowledge module and abstractor module are trained with a frozen LLM module to align the image and text. In the second stage, language-only and multi-modal supervised datasets are used to jointly fine-tune a low-rank adaption (LoRA) module on LLM and the abstractor module by freezing the visual knowledge module. We carefully build a visually-related instruction evaluation set OwlEval. Experimental results show that our model outperforms existing multi-modal models, demonstrating mPLUG-Owl's impressive instruction and visual understanding ability, multi-turn conversation ability, and knowledge reasoning ability. Besides, we observe some unexpected and exciting abilities such as multi-image correlation and scene text understanding, which makes it possible to leverage it for harder real scenarios, such as vision-only document comprehension. Our code, pre-trained model, instruction-tuned models, and evaluation set are available at https://github.com/X-PLUG/mPLUG-Owl. The online demo is available at https://www.modelscope.cn/studios/damo/mPLUG-Owl. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 13:27:01 GMT'}]",2023-04-28,"[['Ye', 'Qinghao', ''], ['Xu', 'Haiyang', ''], ['Xu', 'Guohai', ''], ['Ye', 'Jiabo', ''], ['Yan', 'Ming', ''], ['Zhou', 'Yiyang', ''], ['Wang', 'Junyang', ''], ['Hu', 'Anwen', ''], ['Shi', 'Pengcheng', ''], ['Shi', 'Yaya', ''], ['Li', 'Chenliang', ''], ['Xu', 'Yuanhong', ''], ['Chen', 'Hehong', ''], ['Tian', 'Junfeng', ''], ['Qi', 'Qian', ''], ['Zhang', 'Ji', ''], ['Huang', 'Fei', '']]",0,0,2023-04-27,1,17,3,0,0,0,7e32aac43e9f1df49e116add03327ee6f365dbf3,258352455.0,https://www.semanticscholar.org/paper/7e32aac43e9f1df49e116add03327ee6f365dbf3,arXiv.org,2023.0,36.0,153.0,22.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2199011713', 'name': 'Qinghao Ye'}, {'authorId': '153194420', 'name': 'Haiyang Xu'}, {'authorId': '2115723816', 'name': 'Guohai Xu'}, {'authorId': '2153258288', 'name': 'Jiabo Ye'}, {'authorId': '2047087220', 'name': 'Ming Yan'}, {'authorId': '2118764703', 'name': 'Yi Zhou'}, {'authorId': '2110125710', 'name': 'Junyan Wang'}, {'authorId': '120897486', 'name': 'Anwen Hu'}, {'authorId': '2055357477', 'name': 'Pengcheng Shi'}, {'authorId': '37198550', 'name': 'Yaya Shi'}, {'authorId': '2829009', 'name': 'Chenliang Li'}, {'authorId': '2110355824', 'name': 'Yuanhong Xu'}, {'authorId': '123655156', 'name': 'Hehong Chen'}, {'authorId': '2122989639', 'name': 'Junfeng Tian'}, {'authorId': '50480206', 'name': 'Qiang Qi'}, {'authorId': '2116921824', 'name': 'Ji Zhang'}, {'authorId': '2194508991', 'name': 'Feiyan Huang'}]",['Alibaba'],['China'],2023-04,['industrial']
2304.14233,Tao Shen,"Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Tianyi Zhou, Daxin
  Jiang",Large Language Models are Strong Zero-Shot Retriever,Work in progress,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  In this work, we propose a simple method that applies a large language model (LLM) to large-scale retrieval in zero-shot scenarios. Our method, the Language language model as Retriever (LameR), is built upon no other neural models but an LLM, while breaking brute-force combinations of retrievers with LLMs and lifting the performance of zero-shot retrieval to be very competitive on benchmark datasets. Essentially, we propose to augment a query with its potential answers by prompting LLMs with a composition of the query and the query's in-domain candidates. The candidates, regardless of correct or wrong, are obtained by a vanilla retrieval procedure on the target collection. As a part of the prompts, they are likely to help LLM generate more precise answers by pattern imitation or candidate summarization. Even if all the candidates are wrong, the prompts at least make LLM aware of in-collection patterns and genres. Moreover, due to the low performance of a self-supervised retriever, the LLM-based query augmentation becomes less effective as the retriever bottlenecks the whole pipeline. Therefore, we propose to leverage a non-parametric lexicon-based method (e.g., BM25) as the retrieval module to capture query-document overlap in a literal fashion. As such, LameR makes the retrieval procedure transparent to the LLM, thus circumventing the performance bottleneck. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 14:45:55 GMT'}, {'version': 'v2', 'created': 'Wed, 2 Aug 2023 02:06:28 GMT'}]",2023-08-03,"[['Shen', 'Tao', ''], ['Long', 'Guodong', ''], ['Geng', 'Xiubo', ''], ['Tao', 'Chongyang', ''], ['Zhou', 'Tianyi', ''], ['Jiang', 'Daxin', '']]",0,0,2023-04-27,2,6,2,0,0,0,718989761d0dc0f97727470f0dc23de7ea48c26d,258352285.0,https://www.semanticscholar.org/paper/718989761d0dc0f97727470f0dc23de7ea48c26d,arXiv.org,2023.0,46.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143681703', 'name': 'Tao Shen'}, {'authorId': '2062835', 'name': 'Guodong Long'}, {'authorId': '2442662', 'name': 'Xiubo Geng'}, {'authorId': '8801869', 'name': 'Chongyang Tao'}, {'authorId': '2213956781', 'name': 'Tianyi Zhou'}, {'authorId': '2086994543', 'name': 'Daxin Jiang'}]",['Finance and Economics Institute of Tajikistan'],['Tajikistan'],2023-04,['industrial']
2304.14275,Joseph G Lambourne,"Peter Meltzer, Joseph G. Lambourne, Daniele Grandi",What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Semantic knowledge of part-part and part-whole relationships in assemblies is useful for a variety of tasks from searching design repositories to the construction of engineering knowledge bases. In this work we propose that the natural language names designers use in Computer Aided Design (CAD) software are a valuable source of such knowledge, and that Large Language Models (LLMs) contain useful domain-specific information for working with this data as well as other CAD and engineering-related tasks.   In particular we extract and clean a large corpus of natural language part, feature and document names and use this to quantitatively demonstrate that a pre-trained language model can outperform numerous benchmarks on three self-supervised tasks, without ever having seen this data before. Moreover, we show that fine-tuning on the text data corpus further boosts the performance on all tasks, thus demonstrating the value of the text data which until now has been largely ignored. We also identify key limitations to using LLMs with text data alone, and our findings provide a strong motivation for further work into multi-modal text-geometry models.   To aid and encourage further work in this area we make all our data and code publicly available. ","[{'version': 'v1', 'created': 'Tue, 25 Apr 2023 12:30:01 GMT'}]",2023-04-28,"[['Meltzer', 'Peter', ''], ['Lambourne', 'Joseph G.', ''], ['Grandi', 'Daniele', '']]",0,0,2023-04-25,1,3,2,0,0,0,4a1bd9d0b0462d521fe43d34964eb31b53dbbf34,258352368.0,https://www.semanticscholar.org/paper/4a1bd9d0b0462d521fe43d34964eb31b53dbbf34,Journal of Computing and Information Science in Engineering,2023.0,56.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2063838444', 'name': 'Peter Meltzer'}, {'authorId': '1752580200', 'name': 'J. Lambourne'}, {'authorId': '2055589093', 'name': 'Daniele Grandi'}]","['Autodesk Research London, UK', 'Daniele Grandi Autodesk Research San Fransciso, USA']",['United States'],2023-04,"['industrial', 'industrial']"
2304.14979,Yuge Zhang,"Lei Zhang, Yuge Zhang, Kan Ren, Dongsheng Li, Yuqing Yang",MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks,,,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The field of machine learning (ML) has gained widespread adoption, leading to a significant demand for adapting ML to specific scenarios, which is yet expensive and non-trivial. The predominant approaches towards the automation of solving ML tasks (e.g., AutoML) are often time consuming and hard to understand for human developers. In contrast, though human engineers have the incredible ability to understand tasks and reason about solutions, their experience and knowledge are often sparse and difficult to utilize by quantitative approaches. In this paper, we aim to bridge the gap between machine intelligence and human knowledge by introducing a novel framework MLCopilot, which leverages the state-of-the-art LLMs to develop ML solutions for novel tasks. We showcase the possibility of extending the capability of LLMs to comprehend structured inputs and perform thorough reasoning for solving novel ML tasks. And we find that, after some dedicated design, the LLM can (i) observe from the existing experiences of ML tasks and (ii) reason effectively to deliver promising results for new tasks. The solution generated can be used directly to achieve high levels of competitiveness. ","[{'version': 'v1', 'created': 'Fri, 28 Apr 2023 17:03:57 GMT'}]",2023-05-01,"[['Zhang', 'Lei', ''], ['Zhang', 'Yuge', ''], ['Ren', 'Kan', ''], ['Li', 'Dongsheng', ''], ['Yang', 'Yuqing', '']]",0,0,2023-04-28,1,5,2,0,0,0,fce42753155280051ac64817404b4e1d3be6ebaa,258418182.0,https://www.semanticscholar.org/paper/fce42753155280051ac64817404b4e1d3be6ebaa,arXiv.org,2023.0,86.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1452981772', 'name': 'Lei Zhang'}, {'authorId': '8795401', 'name': 'Yuge Zhang'}, {'authorId': '2214617008', 'name': 'Kan Ren'}, {'authorId': '2181524288', 'name': 'Dongsheng Li'}, {'authorId': '2125051198', 'name': 'Yuqing Yang'}]",['Microsoft'],"['China', 'India']",2023-04,['industrial']
2305.00833,Jack Lanchantin,"Jack Lanchantin, Shubham Toshniwal, Jason Weston, Arthur Szlam,
  Sainbayar Sukhbaatar",Learning to Reason and Memorize with Self-Notes,"15 pages, 5 figures, 6 tables",,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models have been shown to struggle with limited context memory and multi-step reasoning. We propose a simple method for solving both of these problems by allowing the model to take Self-Notes. Unlike recent scratchpad approaches, the model can deviate from the input context at any time to explicitly think. This allows the model to recall information and perform reasoning on the fly as it reads the context, thus extending its memory and enabling multi-step reasoning. Our experiments on multiple tasks demonstrate that our method can successfully generalize to longer and more complicated instances from their training setup by taking Self-Notes at inference time. ","[{'version': 'v1', 'created': 'Mon, 1 May 2023 14:02:48 GMT'}]",2023-05-02,"[['Lanchantin', 'Jack', ''], ['Toshniwal', 'Shubham', ''], ['Weston', 'Jason', ''], ['Szlam', 'Arthur', ''], ['Sukhbaatar', 'Sainbayar', '']]",0,0,2023-05-01,1,5,3,0,0,0,1db6836f61695e558608bb57166feca6876edabf,258426780.0,https://www.semanticscholar.org/paper/1db6836f61695e558608bb57166feca6876edabf,arXiv.org,2023.0,50.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3369052', 'name': 'Jack Lanchantin'}, {'authorId': '2634203', 'name': 'Shubham Toshniwal'}, {'authorId': '145183709', 'name': 'J. Weston'}, {'authorId': '3149531', 'name': 'Arthur Szlam'}, {'authorId': '2265067', 'name': 'Sainbayar Sukhbaatar'}]",['Meta'],['United States'],2023-05,['industrial']
2305.00905,Maniraman Periyasamy,"Maniraman Periyasamy and Marc H\""olle and Marco Wiedmann and Daniel D.
  Scherer and Axel Plinge and Christopher Mutschler",Batch Quantum Reinforcement Learning,,,,,quant-ph cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Training DRL agents is often a time-consuming process as a large number of samples and environment interactions is required. This effect is even amplified in the case of Batch RL, where the agent is trained without environment interactions solely based on a set of previously collected data. Novel approaches based on quantum computing suggest an advantage compared to classical approaches in terms of sample efficiency. To investigate this advantage, we propose a batch RL algorithm leveraging VQC as function approximators in the discrete BCQ algorithm. Additionally, we present a novel data re-uploading scheme based on cyclically shifting the input variables' order in the data encoding layers. We show the efficiency of our algorithm on the OpenAI CartPole environment and compare its performance to classical neural network-based discrete BCQ. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 16:43:01 GMT'}]",2023-05-02,"[['Periyasamy', 'Maniraman', ''], ['Hölle', 'Marc', ''], ['Wiedmann', 'Marco', ''], ['Scherer', 'Daniel D.', ''], ['Plinge', 'Axel', ''], ['Mutschler', 'Christopher', '']]",0,0,2023-04-27,1,6,2,0,0,0,50f0168cf8b0a48094976142dfc346baef3dbd39,258426588.0,https://www.semanticscholar.org/paper/50f0168cf8b0a48094976142dfc346baef3dbd39,arXiv.org,2023.0,44.0,1.0,0.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152740023', 'name': 'Maniraman Periyasamy'}, {'authorId': '2216332592', 'name': 'Marc Hölle'}, {'authorId': '2130089840', 'name': 'Marco Wiedmann'}, {'authorId': '145134906', 'name': 'D. D. Scherer'}, {'authorId': '2556699', 'name': 'A. Plinge'}, {'authorId': '3058617', 'name': 'Christopher Mutschler'}]",['Fraunhofer Institute for Integrated Circuits'],['Germany'],2023-04,['industrial']
2305.01157,Nurendra Choudhary,Nurendra Choudhary and Chandan K. Reddy,Complex Logical Reasoning over Knowledge Graphs using Large Language Models,Code available at https://github.com/Akirato/LLM-KG-Reasoning,,,,cs.LO cs.AI cs.IR,http://creativecommons.org/licenses/by-sa/4.0/,"  Reasoning over knowledge graphs (KGs) is a challenging task that requires a deep understanding of the complex relationships between entities and the underlying logic of their relations. Current approaches rely on learning geometries to embed entities in vector space for logical query operations, but they suffer from subpar performance on complex queries and dataset-specific representations. In this paper, we propose a novel decoupled approach, Language-guided Abstract Reasoning over Knowledge graphs (LARK), that formulates complex KG reasoning as a combination of contextual KG search and logical query reasoning, to leverage the strengths of graph extraction algorithms and large language models (LLM), respectively. Our experiments demonstrate that the proposed approach outperforms state-of-the-art KG reasoning methods on standard benchmark datasets across several logical query constructs, with significant performance gain for queries of higher complexity. Furthermore, we show that the performance of our approach improves proportionally to the increase in size of the underlying LLM, enabling the integration of the latest advancements in LLMs for logical reasoning over KGs. Our work presents a new direction for addressing the challenges of complex KG reasoning and paves the way for future research in this area. ","[{'version': 'v1', 'created': 'Tue, 2 May 2023 02:21:49 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 21:08:09 GMT'}]",2023-05-26,"[['Choudhary', 'Nurendra', ''], ['Reddy', 'Chandan K.', '']]",0,0,2023-05-02,2,2,3,0,0,0,5f9f6b462759b56c242459b7e976b8858b141eeb,258436828.0,https://www.semanticscholar.org/paper/5f9f6b462759b56c242459b7e976b8858b141eeb,arXiv.org,2023.0,30.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2726036', 'name': 'Nurendra Choudhary'}, {'authorId': '144417522', 'name': 'C. Reddy'}]",['Virginia Tech'],['United States'],2023-05,['industrial']
2305.02239,Lingyu Gao,"Lingyu Gao, Debanjan Ghosh, Kevin Gimpel",The Benefits of Label-Description Training for Zero-Shot Text Classification,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large language models have improved zero-shot text classification by allowing the transfer of semantic knowledge from the training data in order to classify among specific label sets in downstream tasks. We propose a simple way to further improve zero-shot accuracies with minimal effort. We curate small finetuning datasets intended to describe the labels for a task. Unlike typical finetuning data, which has texts annotated with labels, our data simply describes the labels in language, e.g., using a few related terms, dictionary/encyclopedia entries, and short templates. Across a range of topic and sentiment datasets, our method is more accurate than zero-shot by 15-17% absolute. It is also more robust to choices required for zero-shot classification, such as patterns for prompting the model to classify and mappings from labels to tokens in the model's vocabulary. Furthermore, since our data merely describes the labels but does not use input texts, finetuning on it yields a model that performs strongly on multiple text domains for a given label set, even improving over few-shot out-of-domain classification in multiple settings. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 16:19:31 GMT'}]",2023-05-04,"[['Gao', 'Lingyu', ''], ['Ghosh', 'Debanjan', ''], ['Gimpel', 'Kevin', '']]",0,0,2023-05-03,1,3,2,0,0,0,f5927ed60855381d694d8af015fbdb1c4edb6532,258461421.0,https://www.semanticscholar.org/paper/f5927ed60855381d694d8af015fbdb1c4edb6532,arXiv.org,2023.0,44.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '13382973', 'name': 'Lingyu Gao'}, {'authorId': '39013305', 'name': 'Debanjan Ghosh'}, {'authorId': '1700980', 'name': 'Kevin Gimpel'}]","['Toyota Technological Institute at Chicago', 'Educational Testing Service']",['United States'],2023-05,"['industrial', 'industrial']"
2305.02309,Erik Nijkamp Dr.,"Erik Nijkamp, Hiroaki Hayashi, Caiming Xiong, Silvio Savarese, Yingbo
  Zhou",CodeGen2: Lessons for Training LLMs on Programming and Natural Languages,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have demonstrated remarkable abilities in representation learning for program synthesis and understanding tasks. The quality of the learned representations appears to be dictated by the neural scaling laws as a function of the number of model parameters and observations, while imposing upper bounds on the model performance by the amount of available data and compute, which is costly.   In this study, we attempt to render the training of LLMs for program synthesis more efficient by unifying four key components: (1) model architectures, (2) learning methods, (3) infill sampling, and, (4) data distributions. Specifically, for the model architecture, we attempt to unify encoder and decoder-based models into a single prefix-LM. For learning methods, (i) causal language modeling, (ii) span corruption, (iii) infilling are unified into a simple learning algorithm. For infill sampling, we explore the claim of a ""free lunch"" hypothesis. For data distributions, the effect of a mixture distribution and multi-epoch training of programming and natural languages on model performance is explored.   We conduct a comprehensive series of empirical experiments on 1B LLMs, for which failures and successes of this exploration are distilled into five lessons. We will provide a final recipe for training and release CodeGen2 models in size 1B, 3.7B, 7B, and, 16B parameters, along with the training framework as open-source: https://github.com/salesforce/CodeGen. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 17:55:25 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Jul 2023 21:11:23 GMT'}]",2023-07-13,"[['Nijkamp', 'Erik', ''], ['Hayashi', 'Hiroaki', ''], ['Xiong', 'Caiming', ''], ['Savarese', 'Silvio', ''], ['Zhou', 'Yingbo', '']]",0,0,2023-05-03,2,5,1,1,1,0,886e0962479ec6dac563666399ca4c96a468fcaa,258461229.0,https://www.semanticscholar.org/paper/886e0962479ec6dac563666399ca4c96a468fcaa,arXiv.org,2023.0,31.0,25.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2043490', 'name': 'Erik Nijkamp'}, {'authorId': '50376014', 'name': 'Hiroaki Hayashi'}, {'authorId': '2054594326', 'name': 'Caiming Xiong'}, {'authorId': '1702137', 'name': 'S. Savarese'}, {'authorId': '2118860628', 'name': 'Yingbo Zhou'}]",['Equal contribution.'],,2023-05,['industrial']
2305.03017,AmirHossein Naghshzan,"Sajjad Rahmani, AmirHossein Naghshzan, Latifa Guerrouj",Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study,,,,,cs.SE cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our research investigates the recommendation of code examples to aid software developers, a practice that saves developers significant time by providing ready-to-use code snippets. The focus of our study is Stack Overflow, a commonly used resource for coding discussions and solutions, particularly in the context of the Java programming language. We applied BERT, a powerful Large Language Model (LLM) that enables us to transform code examples into numerical vectors by extracting their semantic information. Once these numerical representations are prepared, we identify Approximate Nearest Neighbors (ANN) using Locality-Sensitive Hashing (LSH). Our research employed two variants of LSH: Random Hyperplane-based LSH and Query-Aware LSH. We rigorously compared these two approaches across four parameters: HitRate, Mean Reciprocal Rank (MRR), Average Execution Time, and Relevance. Our study revealed that the Query-Aware (QA) approach showed superior performance over the Random Hyperplane-based (RH) method. Specifically, it exhibited a notable improvement of 20% to 35% in HitRate for query pairs compared to the RH approach. Furthermore, the QA approach proved significantly more time-efficient, with its speed in creating hashing tables and assigning data samples to buckets being at least four times faster. It can return code examples within milliseconds, whereas the RH approach typically requires several seconds to recommend code examples. Due to the superior performance of the QA approach, we tested it against PostFinder and FaCoY, the state-of-the-art baselines. Our QA method showed comparable efficiency proving its potential for effective code recommendation. ","[{'version': 'v1', 'created': 'Thu, 4 May 2023 17:43:19 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Jul 2023 22:15:31 GMT'}, {'version': 'v3', 'created': 'Thu, 20 Jul 2023 16:05:39 GMT'}]",2023-07-21,"[['Rahmani', 'Sajjad', ''], ['Naghshzan', 'AmirHossein', ''], ['Guerrouj', 'Latifa', '']]",0,0,2023-05-04,3,3,3,0,0,0,d91413b011141a2312e727b8c9ae1a9b2d2b43f9,258479779.0,https://www.semanticscholar.org/paper/d91413b011141a2312e727b8c9ae1a9b2d2b43f9,arXiv.org,2023.0,40.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143785857', 'name': 'Sajjad Rahmani'}, {'authorId': '2141777131', 'name': 'AmirHossein Naghshzan'}, {'authorId': '1782697', 'name': 'Latifa Guerrouj'}]",['École de Technologie Supérieure'],['Canada'],2023-05,['industrial']
2305.03495,Reid Pryzant,"Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, Michael
  Zeng","Automatic Prompt Optimization with ""Gradient Descent"" and Beam Search",,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have shown impressive performance as general purpose agents, but their abilities remain highly dependent on prompts which are hand written with onerous trial-and-error effort. We propose a simple and nonparametric solution to this problem, Automatic Prompt Optimization (APO), which is inspired by numerical gradient descent to automatically improve prompts, assuming access to training data and an LLM API. The algorithm uses minibatches of data to form natural language ``gradients'' that criticize the current prompt. The gradients are then ``propagated'' into the prompt by editing the prompt in the opposite semantic direction of the gradient. These gradient descent steps are guided by a beam search and bandit selection procedure which significantly improves algorithmic efficiency. Preliminary results across three benchmark NLP tasks and the novel problem of LLM jailbreak detection suggest that Automatic Prompt Optimization can outperform prior prompt editing techniques and improve an initial prompt's performance by up to 31\%, by using data to rewrite vague task descriptions into more precise annotation instructions. ","[{'version': 'v1', 'created': 'Thu, 4 May 2023 15:15:22 GMT'}]",2023-05-08,"[['Pryzant', 'Reid', ''], ['Iter', 'Dan', ''], ['Li', 'Jerry', ''], ['Lee', 'Yin Tat', ''], ['Zhu', 'Chenguang', ''], ['Zeng', 'Michael', '']]",0,0,2023-05-04,1,6,3,0,0,0,c76dd4a70361c3afd2e19d046343e2dedd16ecc3,258546785.0,https://www.semanticscholar.org/paper/c76dd4a70361c3afd2e19d046343e2dedd16ecc3,arXiv.org,2023.0,44.0,34.0,8.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '4099006', 'name': 'Reid Pryzant'}, {'authorId': '3310951', 'name': 'Dan Iter'}, {'authorId': '2800851', 'name': 'Jerry Li'}, {'authorId': '2109308930', 'name': 'Y. Lee'}, {'authorId': '8652308', 'name': 'Chenguang Zhu'}, {'authorId': '48262024', 'name': 'Michael Zeng'}]",['Microsoft'],['United States'],2023-05,['industrial']
2305.04928,Nikola Milo\v{s}evi\'c Dr,"Milo\v{s} Ko\v{s}prdi\'c, Nikola Prodanovi\'c, Adela Ljaji\'c, Bojana
  Ba\v{s}aragin and Nikola Milo\v{s}evi\'c",From Zero to Hero: Harnessing Transformers for Biomedical Named Entity Recognition in Zero- and Few-shot Contexts,"Collaboration between Bayer Pharma R&D and Serbian Institute for
  Artificial Intelligence Research and Development",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Supervised named entity recognition (NER) in the biomedical domain depends on large sets of annotated texts with the given named entities. The creation of such datasets can be time-consuming and expensive, while extraction of new entities requires additional annotation tasks and retraining the model. To address these challenges, this paper proposes a method for zero- and few-shot NER in the biomedical domain. The method is based on transforming the task of multi-class token classification into binary token classification and pre-training on a large amount of datasets and biomedical entities, which allow the model to learn semantic relations between the given and potentially novel named entity labels. We have achieved average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical entities with fine-tuned PubMedBERT-based model. The results demonstrate the effectiveness of the proposed method for recognizing new biomedical entities with no or limited number of examples, outperforming previous transformer-based methods, and being comparable to GPT3-based models using models with over 1000 times fewer parameters. We make models and developed code publicly available. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 12:14:22 GMT'}, {'version': 'v2', 'created': 'Fri, 12 May 2023 10:10:06 GMT'}, {'version': 'v3', 'created': 'Sat, 27 May 2023 19:52:16 GMT'}]",2023-05-31,"[['Košprdić', 'Miloš', ''], ['Prodanović', 'Nikola', ''], ['Ljajić', 'Adela', ''], ['Bašaragin', 'Bojana', ''], ['Milošević', 'Nikola', '']]",0,1,2023-05-05,3,5,2,1,0,1,76c26e1a30d665c62fe78b7e9c31ed8358915dcc,258967223.0,https://www.semanticscholar.org/paper/76c26e1a30d665c62fe78b7e9c31ed8358915dcc,arXiv.org,2023.0,64.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '118640249', 'name': 'Milos Kosprdic'}, {'authorId': '2216605243', 'name': 'Nikola Prodanović'}, {'authorId': '31302722', 'name': 'A. Ljajić'}, {'authorId': '2186574263', 'name': 'Bojana Bašaragin'}, {'authorId': '143860899', 'name': 'Nikola Milosevic'}]","['BioSense Institute', 'Bayer A.G., Reaserch and Development, Mullerstrasse 173, Berlin, 13342, Germany']","['Germany', 'Serbia']",2023-05,"['industrial', 'industrial']"
2305.05027,"Tam\'as V\""or\""os","Tam\'as V\""or\""os, Sean Paul Bergeron, Konstantin Berlin",Web Content Filtering through knowledge distillation of Large Language Models,,,,,cs.LG cs.CL cs.IR,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  We introduce a state-of-the-art approach for URL categorization that leverages the power of Large Language Models (LLMs) to address the primary objectives of web content filtering: safeguarding organizations from legal and ethical risks, limiting access to high-risk or suspicious websites, and fostering a secure and professional work environment. Our method utilizes LLMs to generate accurate classifications and then employs established knowledge distillation techniques to create smaller, more specialized student models tailored for web content filtering. Distillation results in a student model with a 9% accuracy rate improvement in classifying websites, sourced from customer telemetry data collected by a large security vendor, into 30 distinct content categories based on their URLs, surpassing the current state-of-the-art approach. Our student model matches the performance of the teacher LLM with 175 times less parameters, allowing the model to be used for in-line scanning of large volumes of URLs, and requires 3 orders of magnitude less manually labeled training data than the current state-of-the-art approach. Depending on the specific use case, the output generated by our approach can either be directly returned or employed as a pre-filter for more resource-intensive operations involving website images or HTML. ","[{'version': 'v1', 'created': 'Mon, 8 May 2023 20:09:27 GMT'}, {'version': 'v2', 'created': 'Wed, 10 May 2023 08:36:57 GMT'}]",2023-05-11,"[['Vörös', 'Tamás', ''], ['Bergeron', 'Sean Paul', ''], ['Berlin', 'Konstantin', '']]",0,0,2023-05-08,2,3,3,0,0,0,714704b7b17beb2b03dbc5c0270666a18adf7c4b,258564612.0,https://www.semanticscholar.org/paper/714704b7b17beb2b03dbc5c0270666a18adf7c4b,arXiv.org,2023.0,55.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2208917637', 'name': 'Tamás Vörös'}, {'authorId': '89824049', 'name': 'Sean P. Bergeron'}, {'authorId': '2040708537', 'name': 'Konstantin Berlin'}]",['Sophos Inc.'],,2023-05,['industrial']
2305.05061,Tao Hong,Tao Hong,Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer,"10 pages, 7 figures for conference publication",,,,cs.CL nlin.PS,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large Language Models (LLMs), such as the Generative Pretrained Transformer (GPT), have achieved tremendous success in various language tasks, but their emergent abilities have also raised many questions, concerns, and challenges that need to be addressed. To gain a better understanding of the models' inner mechanisms, we analyze the hidden state and channel wave dynamics in a small GPT, focusing on the coherence of wave patterns in terms of cross-channel correlation and individual auto-correlation. Our findings suggest that wave dynamics offer consistent and repeatable intrinsic oscillation modes, along with context-aware plasticity and expressiveness in language generation. By analyzing wave patterns, coherence, and clustering, we provide a systematic way to identify and interpret the functionality of the hidden state channels, paving the way to understand and control higher-level language pattern formation. In addition, we investigate the Poisson statistics of spelling errors in text sequence generation across various levels of model training and observe a phase-transition-like process. As coherence builds up, there is a competition between the generation of correct and misspelled words. However, once the model is adequately trained and significant coherence has emerged, the coherent process becomes strong enough to effectively suppress spelling errors, preventing the cascade amplification of defects. The distribution of correct spellings transitions from Poissonian to Sub-Poissonian, while the distribution of misspellings shows the opposite trend. By leveraging concepts and techniques from quantum physics, we gain novel insights into the dynamics of the small GPT. This approach can be extended to larger language models that exhibit more complex coherent language patterns, opening up opportunities to interpret their emergent capabilities and develop more specialized models. ","[{'version': 'v1', 'created': 'Mon, 8 May 2023 21:35:12 GMT'}]",2023-05-10,"[['Hong', 'Tao', '']]",0,1,2023-05-08,1,1,2,0,0,0,1ac4c9d857ba3d8b22858f8d0ddff9597eb36005,258564693.0,https://www.semanticscholar.org/paper/1ac4c9d857ba3d8b22858f8d0ddff9597eb36005,arXiv.org,2023.0,15.0,0.0,0.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2052210673', 'name': 'Tao Hong'}]",['Meta'],['United States'],2023-05,['industrial']
2305.05377,David Noever,David Noever and Matt Ciolino,Professional Certification Benchmark Dataset: The First 500 Jobs For Large Language Models,,,,,cs.AI cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  The research creates a professional certification survey to test large language models and evaluate their employable skills. It compares the performance of two AI models, GPT-3 and Turbo-GPT3.5, on a benchmark dataset of 1149 professional certifications, emphasizing vocational readiness rather than academic performance. GPT-3 achieved a passing score (>70% correct) in 39% of the professional certifications without fine-tuning or exam preparation. The models demonstrated qualifications in various computer-related fields, such as cloud and virtualization, business analytics, cybersecurity, network setup and repair, and data analytics. Turbo-GPT3.5 scored 100% on the valuable Offensive Security Certified Professional (OSCP) exam. The models also displayed competence in other professional domains, including nursing, licensed counseling, pharmacy, and teaching. Turbo-GPT3.5 passed the Financial Industry Regulatory Authority (FINRA) Series 6 exam with a 70% grade without preparation. Interestingly, Turbo-GPT3.5 performed well on customer service tasks, suggesting potential applications in human augmentation for chatbots in call centers and routine advice services. The models also score well on sensory and experience-based tests such as wine sommelier, beer taster, emotional quotient, and body language reader. The OpenAI model improvement from Babbage to Turbo resulted in a median 60% better-graded performance in less than a few years. This progress suggests that focusing on the latest model's shortcomings could lead to a highly performant AI capable of mastering the most demanding professional certifications. We open-source the benchmark to expand the range of testable professional skills as the models improve or gain emergent capabilities. ","[{'version': 'v1', 'created': 'Sun, 7 May 2023 00:56:58 GMT'}]",2023-05-10,"[['Noever', 'David', ''], ['Ciolino', 'Matt', '']]",0,1,2023-05-07,1,2,2,1,0,1,5cbd3c6a70cf4f1a29634c23b28af5101db882a4,258564417.0,https://www.semanticscholar.org/paper/5cbd3c6a70cf4f1a29634c23b28af5101db882a4,Software Engineering Advances,2023.0,53.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46787948', 'name': 'David Noever'}, {'authorId': '1866333313', 'name': 'Matt Ciolino'}]",['PeopleTec (United States)'],['United States'],2023-05,['industrial']
2305.05576,Pratyush Kumar,Pratyush Kumar,Large Language Models Humanize Technology,,,,,cs.CY cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have made rapid progress in recent months and weeks, garnering significant public attention. This has sparked concerns about aligning these models with human values, their impact on labor markets, and the potential need for regulation in further research and development. However, the discourse often lacks a focus on the imperative to widely diffuse the societal benefits of LLMs. To qualify this societal benefit, we assert that LLMs exhibit emergent abilities to humanize technology more effectively than previous technologies, and for people across language, occupation, and accessibility divides. We argue that they do so by addressing three mechanizing bottlenecks in today's computing technologies: creating diverse and accessible content, learning complex digital tools, and personalizing machine learning algorithms. We adopt a case-based approach and illustrate each bottleneck with two examples where current technology imposes bottlenecks that LLMs demonstrate the ability to address. Given this opportunity to humanize technology widely, we advocate for more widespread understanding of LLMs, tools and methods to simplify use of LLMs, and cross-cutting institutional capacity. ","[{'version': 'v1', 'created': 'Tue, 9 May 2023 16:05:36 GMT'}]",2023-05-10,"[['Kumar', 'Pratyush', '']]",0,0,2023-05-09,1,1,2,0,0,0,2c0ed20784dff5ed224ebee9cd2d66c4e598a679,258564298.0,https://www.semanticscholar.org/paper/2c0ed20784dff5ed224ebee9cd2d66c4e598a679,arXiv.org,2023.0,1.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '38724234', 'name': 'Pratyush Kumar'}]",['Microsoft'],['India'],2023-05,['industrial']
2305.05811,Boris Almonacid Dr,Boris Almonacid,Towards an Automatic Optimisation Model Generator Assisted with Generative Pre-trained Transformer,,,,,cs.NE cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article presents a framework for generating optimisation models using a pre-trained generative transformer. The framework involves specifying the features that the optimisation model should have and using a language model to generate an initial version of the model. The model is then tested and validated, and if it contains build errors, an automatic edition process is triggered. An experiment was performed using MiniZinc as the target language and two GPT-3.5 language models for generation and debugging. The results show that the use of language models for the generation of optimisation models is feasible, with some models satisfying the requested specifications, while others require further refinement. The study provides promising evidence for the use of language models in the modelling of optimisation problems and suggests avenues for future research. ","[{'version': 'v1', 'created': 'Tue, 9 May 2023 23:51:14 GMT'}]",2023-05-11,"[['Almonacid', 'Boris', '']]",0,1,2023-05-09,1,1,2,1,0,1,16b7265b7cde1b5aa1325cedb07fdcf3677c5412,258587815.0,https://www.semanticscholar.org/paper/16b7265b7cde1b5aa1325cedb07fdcf3677c5412,arXiv.org,2023.0,5.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2703472', 'name': 'B. Almonacid'}]","['Global Change Science Puerto Varas, Chile']",['Chile'],2023-05,['industrial']
2305.06087,Antonello Ceravola,"Frank Joublin, Antonello Ceravola, Joerg Deigmoeller, Michael Gienger,
  Mathias Franzius, Julian Eggert",A Glimpse in ChatGPT Capabilities and its impact for AI research,,,,,cs.AI cs.CL cs.HC cs.LG cs.RO,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have recently become a popular topic in the field of Artificial Intelligence (AI) research, with companies such as Google, Amazon, Facebook, Amazon, Tesla, and Apple (GAFA) investing heavily in their development. These models are trained on massive amounts of data and can be used for a wide range of tasks, including language translation, text generation, and question answering. However, the computational resources required to train and run these models are substantial, and the cost of hardware and electricity can be prohibitive for research labs that do not have the funding and resources of the GAFA. In this paper, we will examine the impact of LLMs on AI research. The pace at which such models are generated as well as the range of domains covered is an indication of the trend which not only the public but also the scientific community is currently experiencing. We give some examples on how to use such models in research by focusing on GPT3.5/ChatGPT3.4 and ChatGPT4 at the current state and show that such a range of capabilities in a single system is a strong sign of approaching general intelligence. Innovations integrating such models will also expand along the maturation of such AI systems and exhibit unforeseeable applications that will have important impacts on several aspects of our societies. ","[{'version': 'v1', 'created': 'Wed, 10 May 2023 12:10:51 GMT'}]",2023-05-11,"[['Joublin', 'Frank', ''], ['Ceravola', 'Antonello', ''], ['Deigmoeller', 'Joerg', ''], ['Gienger', 'Michael', ''], ['Franzius', 'Mathias', ''], ['Eggert', 'Julian', '']]",1,1,2023-05-10,1,6,5,2,0,2,6cec825e32b1790a69893a5b2506818241506217,258588014.0,https://www.semanticscholar.org/paper/6cec825e32b1790a69893a5b2506818241506217,arXiv.org,2023.0,73.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1759554', 'name': 'F. Joublin'}, {'authorId': '2832005', 'name': 'A. Ceravola'}, {'authorId': '2187928830', 'name': 'Joerg Deigmoeller'}, {'authorId': '1713430', 'name': 'M. Gienger'}, {'authorId': '3149655', 'name': 'M. Franzius'}, {'authorId': '2216720120', 'name': 'Julian Eggert'}]",['Honda Research Institute Europe'],['Germany'],2023-05,['industrial']
2305.06404,Wen-Yu Hua,Wen-Yu Hua and Brian Williams and Davood Shamsi,LACoS-BLOOM: Low-rank Adaptation with Contrastive objective on 8 bits Siamese-BLOOM,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text embeddings are useful features for several NLP applications, such as sentence similarity, text clustering, and semantic search. In this paper, we present a Low-rank Adaptation with a Contrastive objective on top of 8-bit Siamese-BLOOM, a multilingual large language model optimized to produce semantically meaningful word embeddings. The innovation is threefold. First, we cast BLOOM weights to 8-bit values. Second, we fine-tune BLOOM with a scalable adapter (LoRA) and 8-bit Adam optimizer for sentence similarity classification. Third, we apply a Siamese architecture on BLOOM model with a contrastive objective to ease the multi-lingual labeled data scarcity. The experiment results show the quality of learned embeddings from LACoS-BLOOM is proportional to the number of model parameters and the amount of unlabeled training data. With the parameter efficient fine-tuning design, we are able to run BLOOM 7.1 billion parameters end-to-end on a single GPU machine with 32GB memory. Compared to previous solution Sentence-BERT, we achieve significant improvement on both English and multi-lingual STS tasks. ","[{'version': 'v1', 'created': 'Wed, 10 May 2023 18:26:42 GMT'}]",2023-05-12,"[['Hua', 'Wen-Yu', ''], ['Williams', 'Brian', ''], ['Shamsi', 'Davood', '']]",0,0,2023-05-10,1,3,2,1,1,0,516631db8d75b3f223ae66260a3e048d6d8eae72,258615538.0,https://www.semanticscholar.org/paper/516631db8d75b3f223ae66260a3e048d6d8eae72,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2159745010', 'name': 'Wenhui Hua'}, {'authorId': '2156936261', 'name': 'Brian Williams'}, {'authorId': '2156932931', 'name': 'Davood Shamsi'}]",['Apple'],['United States'],2023-05,['industrial']
2305.06474,Wang-Cheng Kang,"Wang-Cheng Kang, Jianmo Ni, Nikhil Mehta, Maheswaran Sathiamoorthy,
  Lichan Hong, Ed Chi, Derek Zhiyuan Cheng",Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction,,,,,cs.IR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have demonstrated exceptional capabilities in generalizing to new tasks in a zero-shot or few-shot manner. However, the extent to which LLMs can comprehend user preferences based on their previous behavior remains an emerging and still unclear research question. Traditionally, Collaborative Filtering (CF) has been the most effective method for these tasks, predominantly relying on the extensive volume of rating data. In contrast, LLMs typically demand considerably less data while maintaining an exhaustive world knowledge about each item, such as movies or products. In this paper, we conduct a thorough examination of both CF and LLMs within the classic task of user rating prediction, which involves predicting a user's rating for a candidate item based on their past ratings. We investigate various LLMs in different sizes, ranging from 250M to 540B parameters and evaluate their performance in zero-shot, few-shot, and fine-tuning scenarios. We conduct comprehensive analysis to compare between LLMs and strong CF methods, and find that zero-shot LLMs lag behind traditional recommender models that have the access to user interaction data, indicating the importance of user interaction data. However, through fine-tuning, LLMs achieve comparable or even better performance with only a small fraction of the training data, demonstrating their potential through data efficiency. ","[{'version': 'v1', 'created': 'Wed, 10 May 2023 21:43:42 GMT'}]",2023-05-12,"[['Kang', 'Wang-Cheng', ''], ['Ni', 'Jianmo', ''], ['Mehta', 'Nikhil', ''], ['Sathiamoorthy', 'Maheswaran', ''], ['Hong', 'Lichan', ''], ['Chi', 'Ed', ''], ['Cheng', 'Derek Zhiyuan', '']]",0,0,2023-05-10,1,7,2,0,0,0,ed8832466a4295a6c110eb6beec9531d54b5aede,258615591.0,https://www.semanticscholar.org/paper/ed8832466a4295a6c110eb6beec9531d54b5aede,arXiv.org,2023.0,40.0,31.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2741053', 'name': 'Wang-Cheng Kang'}, {'authorId': '2148023', 'name': 'Jianmo Ni'}, {'authorId': None, 'name': 'Nikhil Mehta'}, {'authorId': '3221924', 'name': 'M. Sathiamoorthy'}, {'authorId': '2217278', 'name': 'Lichan Hong'}, {'authorId': '2226805', 'name': 'Ed H. Chi'}, {'authorId': '48573272', 'name': 'D. Cheng'}]",['Google'],['United States'],2023-05,['industrial']
2305.07141,Melanie Mitchell,"Arseny Moskvichev, Victor Vikram Odouard, and Melanie Mitchell",The ConceptARC Benchmark: Evaluating Understanding and Generalization in the ARC Domain,,"Transactions on Machine Learning Research, 8/2023",,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The abilities to form and abstract concepts is key to human intelligence, but such abilities remain lacking in state-of-the-art AI systems. There has been substantial research on conceptual abstraction in AI, particularly using idealized domains such as Raven's Progressive Matrices and Bongard problems, but even when AI systems succeed on such problems, the systems are rarely evaluated in depth to see if they have actually grasped the concepts they are meant to capture.   In this paper we describe an in-depth evaluation benchmark for the Abstraction and Reasoning Corpus (ARC), a collection of few-shot abstraction and analogy problems developed by Chollet [2019]. In particular, we describe ConceptARC, a new, publicly available benchmark in the ARC domain that systematically assesses abstraction and generalization abilities on a number of basic spatial and semantic concepts. ConceptARC differs from the original ARC dataset in that it is specifically organized around ""concept groups"" -- sets of problems that focus on specific concepts and that are vary in complexity and level of abstraction. We report results on testing humans on this benchmark as well as three machine solvers: the top two programs from a 2021 ARC competition and OpenAI's GPT-4. Our results show that humans substantially outperform the machine solvers on this benchmark, showing abilities to abstract and generalize concepts that are not yet captured by AI systems. We believe that this benchmark will spur improvements in the development of AI systems for conceptual abstraction and in the effective evaluation of such systems. ","[{'version': 'v1', 'created': 'Thu, 11 May 2023 21:06:39 GMT'}]",2023-08-09,"[['Moskvichev', 'Arseny', ''], ['Odouard', 'Victor Vikram', ''], ['Mitchell', 'Melanie', '']]",0,1,2023-05-11,1,3,2,1,0,1,0febeb46b8216f12337b448ac81ac505c28782c1,258676355.0,https://www.semanticscholar.org/paper/0febeb46b8216f12337b448ac81ac505c28782c1,arXiv.org,2023.0,41.0,11.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '116808291', 'name': 'A. Moskvichev'}, {'authorId': '2146694505', 'name': 'Victor Vikram Odouard'}, {'authorId': '152905883', 'name': 'Melanie Mitchell'}]",['Santa Fe Institute'],['United States'],2023-05,['industrial']
2305.07157,Soham Parikh,"Soham Parikh, Quaizar Vohra, Prashil Tumbade, Mitul Tiwari",Exploring Zero and Few-shot Techniques for Intent Classification,"ACL 2023 Industry Track. 8 pages, 2 figures, 5 tables",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Conversational NLU providers often need to scale to thousands of intent-classification models where new customers often face the cold-start problem. Scaling to so many customers puts a constraint on storage space as well. In this paper, we explore four different zero and few-shot intent classification approaches with this low-resource constraint: 1) domain adaptation, 2) data augmentation, 3) zero-shot intent classification using descriptions large language models (LLMs), and 4) parameter-efficient fine-tuning of instruction-finetuned language models. Our results show that all these approaches are effective to different degrees in low-resource settings. Parameter-efficient fine-tuning using T-few recipe (Liu et al., 2022) on Flan-T5 (Chang et al., 2022) yields the best performance even with just one sample per intent. We also show that the zero-shot method of prompting LLMs using intent descriptions ","[{'version': 'v1', 'created': 'Thu, 11 May 2023 22:07:27 GMT'}]",2023-05-15,"[['Parikh', 'Soham', ''], ['Vohra', 'Quaizar', ''], ['Tumbade', 'Prashil', ''], ['Tiwari', 'Mitul', '']]",0,0,2023-05-11,1,4,2,3,2,1,53657b9f7bc5c54f6dff119974f4881a4a8c6898,258676495.0,https://www.semanticscholar.org/paper/53657b9f7bc5c54f6dff119974f4881a4a8c6898,Annual Meeting of the Association for Computational Linguistics,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51056069', 'name': 'S. Parikh'}, {'authorId': '29773517', 'name': 'Quaizar Vohra'}, {'authorId': '2217191289', 'name': 'Prashil Tumbade'}, {'authorId': '40118098', 'name': 'Mitul Tiwari'}]",['ServiceNow Inc'],,2023-05,['industrial']
2305.07605,Bill Cope,"Anastasia Olga (Olnancy) Tzirides, Akash Saini, Gabriela Zapata, Duane
  Searsmith, Bill Cope, Mary Kalantzis, Vania Castro, Theodora Kourkoulou, John
  Jones, Rodrigo Abrantes da Silva, Jen Whiting, Nikoleta Polyxeni Kastania",Generative AI: Implications and Applications for Education,34 pages,,,,cs.CY cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The launch of ChatGPT in November 2022 precipitated a panic among some educators while prompting qualified enthusiasm from others. Under the umbrella term Generative AI, ChatGPT is an example of a range of technologies for the delivery of computer-generated text, image, and other digitized media. This paper examines the implications for education of one generative AI technology, chatbots responding from large language models, or C-LLM. It reports on an application of a C-LLM to AI review and assessment of complex student work. In a concluding discussion, the paper explores the intrinsic limits of generative AI, bound as it is to language corpora and their textual representation through binary notation. Within these limits, we suggest the range of emerging and potential applications of Generative AI in education. ","[{'version': 'v1', 'created': 'Fri, 12 May 2023 16:52:38 GMT'}, {'version': 'v2', 'created': 'Mon, 15 May 2023 01:50:07 GMT'}, {'version': 'v3', 'created': 'Mon, 22 May 2023 11:42:19 GMT'}]",2023-05-23,"[['Olga', 'Anastasia', '', 'Olnancy'], ['Tzirides', '', ''], ['Saini', 'Akash', ''], ['Zapata', 'Gabriela', ''], ['Searsmith', 'Duane', ''], ['Cope', 'Bill', ''], ['Kalantzis', 'Mary', ''], ['Castro', 'Vania', ''], ['Kourkoulou', 'Theodora', ''], ['Jones', 'John', ''], ['da Silva', 'Rodrigo Abrantes', ''], ['Whiting', 'Jen', ''], ['Kastania', 'Nikoleta Polyxeni', '']]",1,1,2023-05-12,3,13,2,1,0,1,ebae6e48eedf456de10b7e4cf70eab467731fd73,258676570.0,https://www.semanticscholar.org/paper/ebae6e48eedf456de10b7e4cf70eab467731fd73,arXiv.org,2023.0,62.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51163131', 'name': 'A. Tzirides'}, {'authorId': '153204470', 'name': 'A. Saini'}, {'authorId': '144788868', 'name': 'Gabriela C. Zapata'}, {'authorId': '2693295', 'name': 'Duane Searsmith'}, {'authorId': '33955451', 'name': 'B. Cope'}, {'authorId': '2334862', 'name': 'M. Kalantzis'}, {'authorId': '2217098260', 'name': 'Vania Castro'}, {'authorId': '2217190604', 'name': 'Theodora Kourkoulou'}, {'authorId': '2217236433', 'name': 'John Jones'}, {'authorId': '2217680716', 'name': 'Rodrigo Abrantes da Silva'}, {'authorId': '13199118', 'name': 'Jennifer K. Whiting'}, {'authorId': '2217225866', 'name': 'Nikoleta Polyxeni Kastania'}]","['Nikoleta Polyxeni Kastania', 'Silva']",['France'],2023-05,"['industrial', 'industrial']"
2305.07759,Yuanzhi Li,Ronen Eldan and Yuanzhi Li,TinyStories: How Small Can Language Models Be and Still Speak Coherent English?,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models (LMs) are powerful tools for natural language processing, but they often struggle to produce coherent and fluent text when they are small. Models with around 125M parameters such as GPT-Neo (small) or GPT-2 (small) can rarely generate coherent and consistent English text beyond a few words even after extensive training. This raises the question of whether the emergence of the ability to produce coherent English text only occurs at larger scales (with hundreds of millions of parameters or more) and complex architectures (with many layers of global attention).   In this work, we introduce TinyStories, a synthetic dataset of short stories that only contain words that a typical 3 to 4-year-olds usually understand, generated by GPT-3.5 and GPT-4. We show that TinyStories can be used to train and evaluate LMs that are much smaller than the state-of-the-art models (below 10 million total parameters), or have much simpler architectures (with only one transformer block), yet still produce fluent and consistent stories with several paragraphs that are diverse and have almost perfect grammar, and demonstrate reasoning capabilities.   We also introduce a new paradigm for the evaluation of language models: We suggest a framework which uses GPT-4 to grade the content generated by these models as if those were stories written by students and graded by a (human) teacher. This new paradigm overcomes the flaws of standard benchmarks which often requires the model's output to be very structures, and moreover provides a multidimensional score for the model, providing scores for different capabilities such as grammar, creativity and consistency.   We hope that TinyStories can facilitate the development, analysis and research of LMs, especially for low-resource or specialized domains, and shed light on the emergence of language capabilities in LMs. ","[{'version': 'v1', 'created': 'Fri, 12 May 2023 20:56:48 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 23:30:43 GMT'}]",2023-05-26,"[['Eldan', 'Ronen', ''], ['Li', 'Yuanzhi', '']]",0,1,2023-05-12,2,2,3,3,1,2,28085f480ce456a376ebace9b899e3bc93dbc048,258686446.0,https://www.semanticscholar.org/paper/28085f480ce456a376ebace9b899e3bc93dbc048,arXiv.org,2023.0,36.0,31.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2315830', 'name': 'Ronen Eldan'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}]",['Microsoft'],['India'],2023-05,['industrial']
2305.07882,Alexei Grinbaum,Alexei Grinbaum and Laurynas Adomaitis,Dual Use Concerns of Generative AI and Large Language Models,,,,,cs.CY cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We suggest the implementation of the Dual Use Research of Concern (DURC) framework, originally designed for life sciences, to the domain of generative AI, with a specific focus on Large Language Models (LLMs). With its demonstrated advantages and drawbacks in biological research, we believe the DURC criteria can be effectively redefined for LLMs, potentially contributing to improved AI governance. Acknowledging the balance that must be struck when employing the DURC framework, we highlight its crucial political role in enhancing societal awareness of the impact of generative AI. As a final point, we offer a series of specific recommendations for applying the DURC approach to LLM research. ","[{'version': 'v1', 'created': 'Sat, 13 May 2023 10:08:57 GMT'}]",2023-05-16,"[['Grinbaum', 'Alexei', ''], ['Adomaitis', 'Laurynas', '']]",0,0,2023-05-13,1,2,2,0,0,0,10a08160be0b42d5785b80ec4f5ccf8aeb61780d,258686553.0,https://www.semanticscholar.org/paper/10a08160be0b42d5785b80ec4f5ccf8aeb61780d,arXiv.org,2023.0,71.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40371965', 'name': 'A. Grinbaum'}, {'authorId': '108814448', 'name': 'Laurynas Adomaitis'}]",['CEA Saclay'],['France'],2023-05,['industrial']
2305.09617,Shekoofeh Azizi,"Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le
  Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, Mike
  Schaekermann, Amy Wang, Mohamed Amin, Sami Lachgar, Philip Mansfield, Sushant
  Prakash, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, Nenad Tomasev,
  Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle Barral,
  Dale Webster, Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan
  Karthikesalingam, Vivek Natarajan",Towards Expert-Level Medical Question Answering with Large Language Models,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Recent artificial intelligence (AI) systems have reached milestones in ""grand challenges"" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge.   Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a ""passing"" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach.   Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM by over 19% and setting a new state-of-the-art. We also observed performance approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU clinical topics datasets.   We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions, physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p < 0.001). We also observed significant improvements compared to Med-PaLM on every evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form ""adversarial"" questions to probe LLM limitations.   While further studies are necessary to validate the efficacy of these models in real-world settings, these results highlight rapid progress towards physician-level performance in medical question answering. ","[{'version': 'v1', 'created': 'Tue, 16 May 2023 17:11:29 GMT'}]",2023-05-17,"[['Singhal', 'Karan', ''], ['Tu', 'Tao', ''], ['Gottweis', 'Juraj', ''], ['Sayres', 'Rory', ''], ['Wulczyn', 'Ellery', ''], ['Hou', 'Le', ''], ['Clark', 'Kevin', ''], ['Pfohl', 'Stephen', ''], ['Cole-Lewis', 'Heather', ''], ['Neal', 'Darlene', ''], ['Schaekermann', 'Mike', ''], ['Wang', 'Amy', ''], ['Amin', 'Mohamed', ''], ['Lachgar', 'Sami', ''], ['Mansfield', 'Philip', ''], ['Prakash', 'Sushant', ''], ['Green', 'Bradley', ''], ['Dominowska', 'Ewa', ''], ['Arcas', 'Blaise Aguera y', ''], ['Tomasev', 'Nenad', ''], ['Liu', 'Yun', ''], ['Wong', 'Renee', ''], ['Semturs', 'Christopher', ''], ['Mahdavi', 'S. Sara', ''], ['Barral', 'Joelle', ''], ['Webster', 'Dale', ''], ['Corrado', 'Greg S.', ''], ['Matias', 'Yossi', ''], ['Azizi', 'Shekoofeh', ''], ['Karthikesalingam', 'Alan', ''], ['Natarajan', 'Vivek', '']]",0,0,2023-05-16,1,31,3,1,0,1,7ed0faa6720cd176d57badbc0455af31a03f080c,258715226.0,https://www.semanticscholar.org/paper/7ed0faa6720cd176d57badbc0455af31a03f080c,arXiv.org,2023.0,51.0,100.0,12.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '122902793', 'name': 'K. Singhal'}, {'authorId': '2069132732', 'name': 'Tao Tu'}, {'authorId': '2051681709', 'name': 'Juraj Gottweis'}, {'authorId': '144042306', 'name': 'R. Sayres'}, {'authorId': '2618745', 'name': 'Ellery Wulczyn'}, {'authorId': '2153400663', 'name': 'Le Hou'}, {'authorId': '144358401', 'name': 'Kevin Clark'}, {'authorId': '7790917', 'name': 'S. Pfohl'}, {'authorId': '1396212229', 'name': 'H. Cole-Lewis'}, {'authorId': '2217366399', 'name': 'Darlene Neal'}, {'authorId': '10685155', 'name': 'M. Schaekermann'}, {'authorId': '2217861514', 'name': 'Amy Wang'}, {'authorId': '2113278036', 'name': 'Mohamed Amin'}, {'authorId': '12088502', 'name': 'S. Lachgar'}, {'authorId': '40390773', 'name': 'P. A. Mansfield'}, {'authorId': '28612243', 'name': 'Sushant Prakash'}, {'authorId': '2056722536', 'name': 'Bradley Green'}, {'authorId': '1896724', 'name': 'Ewa Dominowska'}, {'authorId': '2661025', 'name': 'B. A. Y. Arcas'}, {'authorId': '2213266', 'name': 'Nenad Tomašev'}, {'authorId': '2118113191', 'name': 'Yun Liu'}, {'authorId': '122418469', 'name': 'Renee C Wong'}, {'authorId': '52326632', 'name': 'Christopher Semturs'}, {'authorId': '1982213', 'name': 'S. S. Mahdavi'}, {'authorId': '3658427', 'name': 'J. Barral'}, {'authorId': '47191829', 'name': 'D. Webster'}, {'authorId': '102388768', 'name': 'G. Corrado'}, {'authorId': '1745572', 'name': 'Yossi Matias'}, {'authorId': '40151244', 'name': 'Shekoofeh Azizi'}, {'authorId': '2213433382', 'name': 'A. Karthikesalingam'}, {'authorId': '144223091', 'name': 'Vivek Natarajan'}]","['Google', 'Google DeepMind']","['United States', 'United Kingdom']",2023-05,"['industrial', 'industrial']"
2305.09858,Xiaohan Li,"Jiao Chen, Luyi Ma, Xiaohan Li, Nikhil Thakurdesai, Jianpeng Xu, Jason
  H.D. Cho, Kaushiki Nag, Evren Korpeoglu, Sushant Kumar, Kannan Achan",Knowledge Graph Completion Models are Few-shot Learners: An Empirical Study of Relation Labeling in E-commerce with LLMs,,,,,cs.IR cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge Graphs (KGs) play a crucial role in enhancing e-commerce system performance by providing structured information about entities and their relationships, such as complementary or substitutable relations between products or product types, which can be utilized in recommender systems. However, relation labeling in KGs remains a challenging task due to the dynamic nature of e-commerce domains and the associated cost of human labor. Recently, breakthroughs in Large Language Models (LLMs) have shown surprising results in numerous natural language processing tasks. In this paper, we conduct an empirical study of LLMs for relation labeling in e-commerce KGs, investigating their powerful learning capabilities in natural language and effectiveness in predicting relations between product types with limited labeled data. We evaluate various LLMs, including PaLM and GPT-3.5, on benchmark datasets, demonstrating their ability to achieve competitive performance compared to humans on relation labeling tasks using just 1 to 5 labeled examples per relation. Additionally, we experiment with different prompt engineering techniques to examine their impact on model performance. Our results show that LLMs significantly outperform existing KG completion models in relation labeling for e-commerce KGs and exhibit performance strong enough to replace human labeling. ","[{'version': 'v1', 'created': 'Wed, 17 May 2023 00:08:36 GMT'}]",2023-05-18,"[['Chen', 'Jiao', ''], ['Ma', 'Luyi', ''], ['Li', 'Xiaohan', ''], ['Thakurdesai', 'Nikhil', ''], ['Xu', 'Jianpeng', ''], ['Cho', 'Jason H. D.', ''], ['Nag', 'Kaushiki', ''], ['Korpeoglu', 'Evren', ''], ['Kumar', 'Sushant', ''], ['Achan', 'Kannan', '']]",0,1,2023-05-17,1,10,4,2,0,2,5e8dd82419f78025093acbec3ba2e345fff85d11,258741227.0,https://www.semanticscholar.org/paper/5e8dd82419f78025093acbec3ba2e345fff85d11,arXiv.org,2023.0,40.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2157074190', 'name': 'Jiaoayan Chen'}, {'authorId': '1504996823', 'name': 'Luyi Ma'}, {'authorId': '1597361643', 'name': 'Xiaohan Li'}, {'authorId': '66526063', 'name': 'Nikhil Thakurdesai'}, {'authorId': '2139102391', 'name': 'Jianpeng Xu'}, {'authorId': '2511173', 'name': 'Jason H. D. Cho'}, {'authorId': '2190948143', 'name': 'Kaushiki Nag'}, {'authorId': '81014296', 'name': 'Evren Korpeoglu'}, {'authorId': '152663193', 'name': 'Sushant Kumar'}, {'authorId': '2120209935', 'name': 'Kannan Achan'}]","['DESA', 'XIAOHAN LI * , Walmart Global Tech, USA', 'KANNAN ACHAN, Walmart Global Tech, USA', 'EVREN KORPEOGLU, Walmart Global Tech, USA', 'SUSHANT KUMAR, Walmart Global Tech, USA', 'Walmart Global Tech, USA', 'Numerical Algorithms Group (United Kingdom)']","['United States', 'United Kingdom']",2023-05,"['industrial', 'industrial', 'industrial', 'industrial', 'industrial', 'industrial', 'industrial']"
2305.09993,Weijia Xu,"Weijia Xu, Andrzej Banburski-Fahey, Nebojsa Jojic",Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling,,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce Reprompting, an iterative sampling algorithm that searches for the Chain-of-Thought (CoT) recipes for a given task without human intervention. Through Gibbs sampling, we infer CoT recipes that work consistently well for a set of training samples. Our method iteratively samples new recipes using previously sampled solutions as parent prompts to solve other training problems. On five Big-Bench Hard tasks that require multi-step reasoning, Reprompting achieves consistently better performance than the zero-shot, few-shot, and human-written CoT baselines. Reprompting can also facilitate transfer of knowledge from a stronger model to a weaker model leading to substantially improved performance of the weaker model. Overall, Reprompting brings up to +17 point improvements over the previous state-of-the-art method that uses human-written CoT prompts. ","[{'version': 'v1', 'created': 'Wed, 17 May 2023 06:35:43 GMT'}]",2023-05-18,"[['Xu', 'Weijia', ''], ['Banburski-Fahey', 'Andrzej', ''], ['Jojic', 'Nebojsa', '']]",0,0,2023-05-17,1,3,3,0,0,0,7eaaa5aec72ffb95cf538462ed205fa4d4faef9c,258741364.0,https://www.semanticscholar.org/paper/7eaaa5aec72ffb95cf538462ed205fa4d4faef9c,arXiv.org,2023.0,33.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '47210642', 'name': 'Weijia Xu'}, {'authorId': '2168558581', 'name': 'Andrzej Banburski-Fahey'}, {'authorId': '1698689', 'name': 'N. Jojic'}]",['Microsoft'],['United States'],2023-05,['industrial']
2305.10196,Longyue Wang,"Longyue Wang, Siyou Liu, Mingzhou Xu, Linfeng Song, Shuming Shi,
  Zhaopeng Tu",A Survey on Zero Pronoun Translation,"ACL2023 Main Conference Long Paper. Longyue Wang and Siyou Liu
  contributed equally to this work",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Zero pronouns (ZPs) are frequently omitted in pro-drop languages (e.g. Chinese, Hungarian, and Hindi), but should be recalled in non-pro-drop languages (e.g. English). This phenomenon has been studied extensively in machine translation (MT), as it poses a significant challenge for MT systems due to the difficulty in determining the correct antecedent for the pronoun. This survey paper highlights the major works that have been undertaken in zero pronoun translation (ZPT) after the neural revolution, so that researchers can recognise the current state and future directions of this field. We provide an organisation of the literature based on evolution, dataset, method and evaluation. In addition, we compare and analyze competing models and evaluation metrics on different benchmarks. We uncover a number of insightful findings such as: 1) ZPT is in line with the development trend of large language model; 2) data limitation causes learning bias in languages and domains; 3) performance improvements are often reported on single benchmarks, but advanced methods are still far from real-world use; 4) general-purpose metrics are not reliable on nuances and complexities of ZPT, emphasizing the necessity of targeted metrics; 5) apart from commonly-cited errors, ZPs will cause risks of gender bias. ","[{'version': 'v1', 'created': 'Wed, 17 May 2023 13:19:01 GMT'}]",2023-05-18,"[['Wang', 'Longyue', ''], ['Liu', 'Siyou', ''], ['Xu', 'Mingzhou', ''], ['Song', 'Linfeng', ''], ['Shi', 'Shuming', ''], ['Tu', 'Zhaopeng', '']]",0,0,2023-05-17,1,6,2,0,0,0,8fa265a8ca46c9c0ad35d2c5b519a86e2a092dfe,258740687.0,https://www.semanticscholar.org/paper/8fa265a8ca46c9c0ad35d2c5b519a86e2a092dfe,Annual Meeting of the Association for Computational Linguistics,2023.0,77.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1800190', 'name': 'Longyue Wang'}, {'authorId': '3417566', 'name': 'Siyou Liu'}, {'authorId': '97375395', 'name': 'Mingzhou Xu'}, {'authorId': '1748796', 'name': 'Linfeng Song'}, {'authorId': '2072684668', 'name': 'Shuming Shi'}, {'authorId': '2909321', 'name': 'Zhaopeng Tu'}]",['Tencent'],['China'],2023-05,['industrial']
2305.11014,Tom Silver,"Tom Silver, Soham Dan, Kavitha Srinivas, Joshua B. Tenenbaum, Leslie
  Pack Kaelbling, Michael Katz",Generalized Planning in PDDL Domains with Pretrained Large Language Models,,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Recent work has considered whether large language models (LLMs) can function as planners: given a task, generate a plan. We investigate whether LLMs can serve as generalized planners: given a domain and training tasks, generate a program that efficiently produces plans for other tasks in the domain. In particular, we consider PDDL domains and use GPT-4 to synthesize Python programs. We also consider (1) Chain-of-Thought (CoT) summarization, where the LLM is prompted to summarize the domain and propose a strategy in words before synthesizing the program; and (2) automated debugging, where the program is validated with respect to the training tasks, and in case of errors, the LLM is re-prompted with four types of feedback. We evaluate this approach in seven PDDL domains and compare it to four ablations and four baselines. Overall, we find that GPT-4 is a surprisingly powerful generalized planner. We also conclude that automated debugging is very important, that CoT summarization has non-uniform impact, that GPT-4 is far superior to GPT-3.5, and that just two training tasks are often sufficient for strong generalization. ","[{'version': 'v1', 'created': 'Thu, 18 May 2023 14:48:20 GMT'}]",2023-05-19,"[['Silver', 'Tom', ''], ['Dan', 'Soham', ''], ['Srinivas', 'Kavitha', ''], ['Tenenbaum', 'Joshua B.', ''], ['Kaelbling', 'Leslie Pack', ''], ['Katz', 'Michael', '']]",0,1,2023-05-18,1,6,1,2,0,2,b3bba15f000000a6d3b5808f798a9fe7629fa499,258762760.0,https://www.semanticscholar.org/paper/b3bba15f000000a6d3b5808f798a9fe7629fa499,arXiv.org,2023.0,58.0,14.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '39047272', 'name': 'Tom Silver'}, {'authorId': '3420683', 'name': 'Soham Dan'}, {'authorId': '145993352', 'name': 'Kavitha Srinivas'}, {'authorId': '1763295', 'name': 'J. Tenenbaum'}, {'authorId': '1709512', 'name': 'L. Kaelbling'}, {'authorId': '144801999', 'name': 'Michael Katz'}]","['IBM Research - China', 'MIT Computer Science and Artificial Intelligence Laboratory;']",['China'],2023-05,"['industrial', 'industrial']"
2305.12487,C\'edric Colas,"C\'edric Colas, Laetitia Teodorescu, Pierre-Yves Oudeyer, Xingdi Yuan,
  Marc-Alexandre C\^ot\'e",Augmenting Autotelic Agents with Large Language Models,,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Humans learn to master open-ended repertoires of skills by imagining and practicing their own goals. This autotelic learning process, literally the pursuit of self-generated (auto) goals (telos), becomes more and more open-ended as the goals become more diverse, abstract and creative. The resulting exploration of the space of possible skills is supported by an inter-individual exploration: goal representations are culturally evolved and transmitted across individuals, in particular using language. Current artificial agents mostly rely on predefined goal representations corresponding to goal spaces that are either bounded (e.g. list of instructions), or unbounded (e.g. the space of possible visual inputs) but are rarely endowed with the ability to reshape their goal representations, to form new abstractions or to imagine creative goals. In this paper, we introduce a language model augmented autotelic agent (LMA3) that leverages a pretrained language model (LM) to support the representation, generation and learning of diverse, abstract, human-relevant goals. The LM is used as an imperfect model of human cultural transmission; an attempt to capture aspects of humans' common-sense, intuitive physics and overall interests. Specifically, it supports three key components of the autotelic architecture: 1)~a relabeler that describes the goals achieved in the agent's trajectories, 2)~a goal generator that suggests new high-level goals along with their decomposition into subgoals the agent already masters, and 3)~reward functions for each of these goals. Without relying on any hand-coded goal representations, reward functions or curriculum, we show that LMA3 agents learn to master a large diversity of skills in a task-agnostic text-based environment. ","[{'version': 'v1', 'created': 'Sun, 21 May 2023 15:42:41 GMT'}]",2023-05-23,"[['Colas', 'Cédric', ''], ['Teodorescu', 'Laetitia', ''], ['Oudeyer', 'Pierre-Yves', ''], ['Yuan', 'Xingdi', ''], ['Côté', 'Marc-Alexandre', '']]",0,0,2023-05-21,1,5,3,0,0,0,98c328c9a48b2a404e2704c1d73f2daef3da854e,258832563.0,https://www.semanticscholar.org/paper/98c328c9a48b2a404e2704c1d73f2daef3da854e,arXiv.org,2023.0,60.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '102281182', 'name': 'Cédric Colas'}, {'authorId': '1585810093', 'name': 'Laetitia Teodorescu'}, {'authorId': '1720664', 'name': 'Pierre-Yves Oudeyer'}, {'authorId': '2854297', 'name': 'Xingdi Yuan'}, {'authorId': '40638665', 'name': 'Marc-Alexandre Côté'}]",['Microsoft'],['India'],2023-05,['industrial']
2305.12987,Magnus Sahlgren,"Ariel Ekgren, Amaru Cuba Gyllensten, Felix Stollenwerk, Joey \""Ohman,
  Tim Isbister, Evangelia Gogoulou, Fredrik Carlsson, Alice Heiman, Judit
  Casademont, Magnus Sahlgren",GPT-SW3: An Autoregressive Language Model for the Nordic Languages,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper details the process of developing the first native large generative language model for the Nordic languages, GPT-SW3. We cover all parts of the development process, from data collection and processing, training configuration and instruction finetuning, to evaluation and considerations for release strategies. We hope that this paper can serve as a guide and reference for other researchers that undertake the development of large generative models for smaller languages. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 12:47:48 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 06:59:16 GMT'}]",2023-05-24,"[['Ekgren', 'Ariel', ''], ['Gyllensten', 'Amaru Cuba', ''], ['Stollenwerk', 'Felix', ''], ['Öhman', 'Joey', ''], ['Isbister', 'Tim', ''], ['Gogoulou', 'Evangelia', ''], ['Carlsson', 'Fredrik', ''], ['Heiman', 'Alice', ''], ['Casademont', 'Judit', ''], ['Sahlgren', 'Magnus', '']]",0,1,2023-05-22,2,10,2,0,0,0,66e53ba87f201a2ba8bcf09966f16ae068933e77,258832435.0,https://www.semanticscholar.org/paper/66e53ba87f201a2ba8bcf09966f16ae068933e77,arXiv.org,2023.0,35.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1926146', 'name': 'Ariel Ekgren'}, {'authorId': '2701223', 'name': 'Amaru Cuba Gyllensten'}, {'authorId': '102551585', 'name': 'F. Stollenwerk'}, {'authorId': '1582211914', 'name': 'Joey Öhman'}, {'authorId': '32168146', 'name': 'T. Isbister'}, {'authorId': '2029654671', 'name': 'Evangelia Gogoulou'}, {'authorId': '49715476', 'name': 'F. Carlsson'}, {'authorId': '2185525871', 'name': 'Alice Heiman'}, {'authorId': '2218270024', 'name': 'Judit Casademont'}, {'authorId': '2068514641', 'name': 'Magnus Sahlgren'}]","['RISE Research Institutes of Sweden', 'AI Sweden']",['Sweden'],2023-05,"['industrial', 'industrial']"
2305.13016,Jiaxi Yang,"Jiaxi Yang, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, Yongbin Li",Iterative Forward Tuning Boosts In-context Learning in Language Models,"14 pages, 5 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have exhibited an emergent in-context learning (ICL) ability. However, the ICL models that can solve ordinary cases are hardly extended to solve more complex tasks by processing the demonstration examples once. This single-turn ICL is incoordinate with the decision making process of humans by learning from analogy. In this paper, we propose an effective and efficient two-stage framework to boost ICL in LLMs by exploiting a dual form between Transformer attention and gradient descent-based optimization. Concretely, we divide the ICL process into ""Deep-Thinking"" and inference stages. The ""Deep-Thinking"" stage performs iterative forward optimization of demonstrations, which is expected to boost the reasoning abilities of LLMs at test time by ""thinking"" demonstrations multiple times. It produces accumulated meta-gradients by manipulating the Key-Value matrices in the self-attention modules of the Transformer. Then, the inference stage only takes the test query as input without concatenating demonstrations and applies the learned meta-gradients through attention for output prediction. In this way, demonstrations are not required during the inference stage since they are already learned and stored in the definitive meta-gradients. LLMs can be effectively and efficiently adapted to downstream tasks. Extensive experiments on ten classification and multiple-choice datasets show that our method achieves substantially better performance than standard ICL in terms of both accuracy and efficiency. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 13:18:17 GMT'}, {'version': 'v2', 'created': 'Tue, 30 May 2023 05:47:19 GMT'}]",2023-05-31,"[['Yang', 'Jiaxi', ''], ['Hui', 'Binyuan', ''], ['Yang', 'Min', ''], ['Li', 'Binhua', ''], ['Huang', 'Fei', ''], ['Li', 'Yongbin', '']]",0,0,2023-05-22,2,6,1,0,0,0,43ffae1c1c6a7371dfe89ac84ae45f3456fdc5a0,258832340.0,https://www.semanticscholar.org/paper/43ffae1c1c6a7371dfe89ac84ae45f3456fdc5a0,arXiv.org,2023.0,42.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2135964855', 'name': 'Jiaxi Yang'}, {'authorId': '151471590', 'name': 'Binyuan Hui'}, {'authorId': '2144399900', 'name': 'Min Yang'}, {'authorId': '66200440', 'name': 'Binhua Li'}, {'authorId': '2087380523', 'name': 'Fei Huang'}, {'authorId': '1527090216', 'name': 'Yongbin Li'}]","['Alibaba', 'Shenzhen Institutes of Advanced Technology']",['China'],2023-05,"['industrial', 'industrial']"
2305.13083,Ruochen Xu,"Yichong Xu, Ruochen Xu, Dan Iter, Yang Liu, Shuohang Wang, Chenguang
  Zhu, Michael Zeng","InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT",work in progress,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  While large models such as GPT-3 demonstrate exceptional performance in zeroshot and fewshot summarization tasks, their extensive serving and fine-tuning costs hinder their utilization in various applications. Conversely, previous studies have found that although automatic metrics tend to favor smaller fine-tuned models, the quality of the summaries they generate is inferior to that of larger models like GPT-3 when assessed by human evaluators. To address this issue, we propose InheritSumm, a versatile and compact summarization model derived from GPT-3.5 through distillation. InheritSumm not only exhibits comparable zeroshot and fewshot summarization capabilities to GPT-3.5 but is also sufficiently compact for fine-tuning purposes. Experimental results demonstrate that InheritSumm achieves similar or superior performance to GPT-3.5 in zeroshot and fewshot settings. Furthermore, it outperforms the previously established best small models in both prefix-tuning and full-data fine-tuning scenarios. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 14:52:32 GMT'}]",2023-05-23,"[['Xu', 'Yichong', ''], ['Xu', 'Ruochen', ''], ['Iter', 'Dan', ''], ['Liu', 'Yang', ''], ['Wang', 'Shuohang', ''], ['Zhu', 'Chenguang', ''], ['Zeng', 'Michael', '']]",0,1,2023-05-22,1,7,1,1,0,1,9591e76f296afe9589a42e899266e1c6a355d9ba,258833086.0,https://www.semanticscholar.org/paper/9591e76f296afe9589a42e899266e1c6a355d9ba,arXiv.org,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2110197273', 'name': 'Yichong Xu'}, {'authorId': '8233965', 'name': 'Ruochen Xu'}, {'authorId': '3310951', 'name': 'Dan Iter'}, {'authorId': '2152797401', 'name': 'Yang Liu'}, {'authorId': '2146294891', 'name': 'Shuo Wang'}, {'authorId': '8652308', 'name': 'Chenguang Zhu'}, {'authorId': '48262024', 'name': 'Michael Zeng'}]",['Microsoft'],['United States'],2023-05,['industrial']
2305.13085,Ratish Puduppully,"Ratish Puduppully, Raj Dabre, Ai Ti Aw, Nancy F. Chen",Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models,work-in-progress,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study investigates machine translation between related languages i.e., languages within the same family that share similar linguistic traits such as word order and lexical similarity. Machine translation through few-shot prompting leverages a small set of translation pair examples to generate translations for test sentences. This requires the model to learn how to generate translations while simultaneously ensuring that token ordering is maintained to produce a fluent and accurate translation. We propose that for related languages, the task of machine translation can be simplified by leveraging the monotonic alignment characteristic of such languages. We introduce a novel approach of few-shot prompting that decomposes the translation process into a sequence of word chunk translations. Through evaluations conducted on multiple related language pairs across various language families, we demonstrate that our novel approach of decomposed prompting surpasses multiple established few-shot baseline models, thereby verifying its effectiveness. For example, our model outperforms the strong few-shot prompting BLOOM model with an average improvement of 4.2 chrF++ scores across the examined languages. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 14:52:47 GMT'}]",2023-05-23,"[['Puduppully', 'Ratish', ''], ['Dabre', 'Raj', ''], ['Aw', 'Ai Ti', ''], ['Chen', 'Nancy F.', '']]",0,0,2023-05-22,1,4,1,1,1,0,b6e5855b6a4e425ba251a93516f2bccffe5ba403,258833688.0,https://www.semanticscholar.org/paper/b6e5855b6a4e425ba251a93516f2bccffe5ba403,arXiv.org,2023.0,36.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2990638', 'name': 'Ratish Puduppully'}, {'authorId': '3209719', 'name': 'Raj Dabre'}, {'authorId': '2113601787', 'name': 'A. Aw'}, {'authorId': '2118768398', 'name': 'Nancy F. Chen'}]","['French National Centre for Scientific Research', 'National Institute of Information and Communications Technology', 'Microsoft', 'Institute for Infocomm Research']","['India', 'Japan', 'Singapore', 'France']",2023-05,"['industrial', 'industrial', 'industrial', 'industrial']"
2305.13102,Sumit Soman,"Sumit Soman, Ranjani H G",Observations on LLMs for Telecom Domain: Capabilities and Limitations,"11 pages, 2 figures, 8 tables",,,,cs.HC cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The landscape for building conversational interfaces (chatbots) has witnessed a paradigm shift with recent developments in generative Artificial Intelligence (AI) based Large Language Models (LLMs), such as ChatGPT by OpenAI (GPT3.5 and GPT4), Google's Bard, Large Language Model Meta AI (LLaMA), among others. In this paper, we analyze capabilities and limitations of incorporating such models in conversational interfaces for the telecommunication domain, specifically for enterprise wireless products and services. Using Cradlepoint's publicly available data for our experiments, we present a comparative analysis of the responses from such models for multiple use-cases including domain adaptation for terminology and product taxonomy, context continuity, robustness to input perturbations and errors. We believe this evaluation would provide useful insights to data scientists engaged in building customized conversational interfaces for domain-specific requirements. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 15:04:16 GMT'}]",2023-05-23,"[['Soman', 'Sumit', ''], ['G', 'Ranjani H', '']]",1,1,2023-05-22,1,2,4,4,1,3,506f571f4c3ef3c5c52761cd6b99400acd22ebd6,258833510.0,https://www.semanticscholar.org/paper/506f571f4c3ef3c5c52761cd6b99400acd22ebd6,arXiv.org,2023.0,19.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3336244', 'name': 'Sumit Soman'}, {'authorId': '1410704775', 'name': 'G. RanjaniH.'}]","['Ranjani H G Global AI Accelerator Ericsson Bangalore, India', 'Ericsson']",['India'],2023-05,"['industrial', 'industrial']"
2305.13304,Wangchunshu Zhou,"Wangchunshu Zhou, Yuchen Eleanor Jiang, Peng Cui, Tiannan Wang,
  Zhenxin Xiao, Yifan Hou, Ryan Cotterell, Mrinmaya Sachan",RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text,Under review,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The fixed-size context of Transformer makes GPT models incapable of generating arbitrarily long text. In this paper, we introduce RecurrentGPT, a language-based simulacrum of the recurrence mechanism in RNNs. RecurrentGPT is built upon a large language model (LLM) such as ChatGPT and uses natural language to simulate the Long Short-Term Memory mechanism in an LSTM. At each timestep, RecurrentGPT generates a paragraph of text and updates its language-based long-short term memory stored on the hard drive and the prompt, respectively. This recurrence mechanism enables RecurrentGPT to generate texts of arbitrary length without forgetting. Since human users can easily observe and edit the natural language memories, RecurrentGPT is interpretable and enables interactive generation of long text. RecurrentGPT is an initial step towards next-generation computer-assisted writing systems beyond local editing suggestions. In addition to producing AI-generated content (AIGC), we also demonstrate the possibility of using RecurrentGPT as an interactive fiction that directly interacts with consumers. We call this usage of generative models by ``AI As Contents'' (AIAC), which we believe is the next form of conventional AIGC. We further demonstrate the possibility of using RecurrentGPT to create personalized interactive fiction that directly interacts with readers instead of interacting with writers. More broadly, RecurrentGPT demonstrates the utility of borrowing ideas from popular model designs in cognitive science and deep learning for prompting LLMs. Our code is available at https://github.com/aiwaves-cn/RecurrentGPT and an online demo is available at https://www.aiwaves.org/recurrentgpt. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 17:58:10 GMT'}]",2023-05-23,"[['Zhou', 'Wangchunshu', ''], ['Jiang', 'Yuchen Eleanor', ''], ['Cui', 'Peng', ''], ['Wang', 'Tiannan', ''], ['Xiao', 'Zhenxin', ''], ['Hou', 'Yifan', ''], ['Cotterell', 'Ryan', ''], ['Sachan', 'Mrinmaya', '']]",1,1,2023-05-22,1,8,2,1,0,1,d9964ab436eefd21f923a4bc833c6b66692c7f00,258832617.0,https://www.semanticscholar.org/paper/d9964ab436eefd21f923a4bc833c6b66692c7f00,arXiv.org,2023.0,37.0,10.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150341221', 'name': 'Wangchunshu Zhou'}, {'authorId': '2134457930', 'name': 'Yuchen Jiang'}, {'authorId': '2153522384', 'name': 'Peng Cui'}, {'authorId': '2118916175', 'name': 'Tiannan Wang'}, {'authorId': '123034558', 'name': 'Zhenxin Xiao'}, {'authorId': '2088768581', 'name': 'Yifan Hou'}, {'authorId': '2070989574', 'name': 'Ryan Cotterell'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]","['ETH Zurich', 'Equal Contribution Preprint. Work In Progress.']",['Switzerland'],2023-05,"['industrial', 'industrial']"
2305.13338,Marcin Joachimiak,"Marcin P. Joachimiak, J. Harry Caufield, Nomi L. Harris, Hyeongsik
  Kim, Christopher J. Mungall",Gene Set Summarization using Large Language Models,,,,,q-bio.GN cs.AI cs.CL q-bio.QM,http://creativecommons.org/publicdomain/zero/1.0/,"  Molecular biologists frequently interpret gene lists derived from high-throughput experiments and computational analysis. This is typically done as a statistical enrichment analysis that measures the over- or under-representation of biological function terms associated with genes or their properties, based on curated assertions from a knowledge base (KB) such as the Gene Ontology (GO). Interpreting gene lists can also be framed as a textual summarization task, enabling the use of Large Language Models (LLMs), potentially utilizing scientific texts directly and avoiding reliance on a KB.   We developed SPINDOCTOR (Structured Prompt Interpolation of Natural Language Descriptions of Controlled Terms for Ontology Reporting), a method that uses GPT models to perform gene set function summarization as a complement to standard enrichment analysis. This method can use different sources of gene functional information: (1) structured text derived from curated ontological KB annotations, (2) ontology-free narrative gene summaries, or (3) direct model retrieval.   We demonstrate that these methods are able to generate plausible and biologically valid summary GO term lists for gene sets. However, GPT-based approaches are unable to deliver reliable scores or p-values and often return terms that are not statistically significant. Crucially, these methods were rarely able to recapitulate the most precise and informative term from standard enrichment, likely due to an inability to generalize and reason using an ontology. Results are highly nondeterministic, with minor variations in prompt resulting in radically different term lists. Our results show that at this point, LLM-based methods are unsuitable as a replacement for standard term enrichment analysis and that manual curation of ontological assertions remains necessary. ","[{'version': 'v1', 'created': 'Sun, 21 May 2023 02:06:33 GMT'}, {'version': 'v2', 'created': 'Thu, 25 May 2023 19:10:13 GMT'}]",2023-05-29,"[['Joachimiak', 'Marcin P.', ''], ['Caufield', 'J. Harry', ''], ['Harris', 'Nomi L.', ''], ['Kim', 'Hyeongsik', ''], ['Mungall', 'Christopher J.', '']]",0,1,2023-05-21,2,5,4,0,0,0,21c3343148290cf3f3d7739ca6d6f191fc66f613,258841613.0,https://www.semanticscholar.org/paper/21c3343148290cf3f3d7739ca6d6f191fc66f613,arXiv.org,2023.0,25.0,0.0,0.0,True,"['Computer Science', 'Medicine', 'Biology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2111638', 'name': 'marcin p. joachimiak'}, {'authorId': '145710797', 'name': 'J. Caufield'}, {'authorId': '40404712', 'name': 'N. Harris'}, {'authorId': '52038267', 'name': 'C. Mungall'}]","['Robert Bosch (United States)', 'Lawrence Berkeley National Laboratory']",['United States'],2023-05,"['industrial', 'industrial']"
2305.13386,Nadir Durrani Dr,"Basel Mousi, Nadir Durrani, Fahim Dalvi",Can LLMs facilitate interpretation of pre-trained language models?,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Work done to uncover the knowledge encoded within pre-trained language models, rely on annotated corpora or human-in-the-loop methods. However, these approaches are limited in terms of scalability and the scope of interpretation. We propose using a large language model, ChatGPT, as an annotator to enable fine-grained interpretation analysis of pre-trained language models. We discover latent concepts within pre-trained language models by applying hierarchical clustering over contextualized representations and then annotate these concepts using GPT annotations. Our findings demonstrate that ChatGPT produces accurate and semantically richer annotations compared to human-annotated concepts. Additionally, we showcase how GPT-based annotations empower interpretation analysis methodologies of which we demonstrate two: probing framework and neuron interpretation. To facilitate further exploration and experimentation in this field, we have made available a substantial ConceptNet dataset comprising 39,000 annotated latent concepts. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 18:03:13 GMT'}]",2023-05-24,"[['Mousi', 'Basel', ''], ['Durrani', 'Nadir', ''], ['Dalvi', 'Fahim', '']]",1,1,2023-05-22,1,3,1,1,0,1,6c340ff334beac9524629d19f84544ed2bb29e85,258841771.0,https://www.semanticscholar.org/paper/6c340ff334beac9524629d19f84544ed2bb29e85,arXiv.org,2023.0,54.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2171367840', 'name': 'Basel Mousi'}, {'authorId': '145938140', 'name': 'Nadir Durrani'}, {'authorId': '6415321', 'name': 'Fahim Dalvi'}]",['Qatar Computing Research Institute'],['Qatar'],2023-05,['industrial']
2305.13514,Giorgos Vernikos,"Giorgos Vernikos, Arthur Bra\v{z}inskas, Jakub Adamek, Jonathan
  Mallinson, Aliaksei Severyn, Eric Malmi",Small Language Models Improve Giants by Rewriting Their Outputs,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated impressive few-shot learning capabilities, but they often underperform compared to fine-tuned models on challenging tasks. Furthermore, their large size and restricted access only through APIs make task-specific fine-tuning impractical. Moreover, LLMs are sensitive to different aspects of prompts (e.g., the selection and order of demonstrations) and can thus require time-consuming prompt engineering. In this light, we propose a method to correct LLM outputs without relying on their weights. First, we generate a pool of candidates by few-shot prompting an LLM. Second, we refine the LLM-generated outputs using a smaller model, the LM-corrector (LMCor), which is trained to rank, combine and rewrite the candidates to produce the final target output. Our experiments demonstrate that even a small LMCor model (250M) substantially improves the few-shot performance of LLMs (62B) across diverse tasks. Moreover, we illustrate that the LMCor exhibits robustness against different prompts, thereby minimizing the need for extensive prompt engineering. Finally, we showcase that the LMCor can be seamlessly integrated with different LLMs at inference time, serving as a plug-and-play module to improve their performance. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 22:07:50 GMT'}]",2023-05-24,"[['Vernikos', 'Giorgos', ''], ['Bražinskas', 'Arthur', ''], ['Adamek', 'Jakub', ''], ['Mallinson', 'Jonathan', ''], ['Severyn', 'Aliaksei', ''], ['Malmi', 'Eric', '']]",0,0,2023-05-22,1,6,2,0,0,0,a21de70160c91dcf9b1e7a93fbb32f4b2687860a,258841388.0,https://www.semanticscholar.org/paper/a21de70160c91dcf9b1e7a93fbb32f4b2687860a,arXiv.org,2023.0,51.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1972392392', 'name': 'Giorgos Vernikos'}, {'authorId': '1992923983', 'name': 'Arthur Bravzinskas'}, {'authorId': '50290651', 'name': 'Jakub Adamek'}, {'authorId': '1931758', 'name': 'Jonathan Mallinson'}, {'authorId': '3091861', 'name': 'Aliaksei Severyn'}, {'authorId': '3288074', 'name': 'Eric Malmi'}]",['Google'],['United States'],2023-05,['industrial']
2305.13821,Chaoran Chen,"Chaoran Chen, Tanja Stadler",GenSpectrum Chat: Data Exploration in Public Health Using Large Language Models,,,,,q-bio.GN cs.AI cs.IR,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Introduction: The COVID-19 pandemic highlighted the importance of making epidemiological data and scientific insights easily accessible and explorable for public health agencies, the general public, and researchers. State-of-the-art approaches for sharing data and insights included regularly updated reports and web dashboards. However, they face a trade-off between the simplicity and flexibility of data exploration. With the capabilities of recent large language models (LLMs) such as GPT-4, this trade-off can be overcome.   Results: We developed the chatbot ""GenSpectrum Chat"" (https://cov-spectrum.org/chat) which uses GPT-4 as the underlying large language model (LLM) to explore SARS-CoV-2 genomic sequencing data. Out of 500 inputs from real-world users, the chatbot provided a correct answer for 453 prompts; an incorrect answer for 13 prompts, and no answer although the question was within scope for 34 prompts. We also tested the chatbot with inputs from 10 different languages, and despite being provided solely with English instructions and examples, it successfully processed prompts in all tested languages.   Conclusion: LLMs enable new ways of interacting with information systems. In the field of public health, GenSpectrum Chat can facilitate the analysis of real-time pathogen genomic data. With our chatbot supporting interactive exploration in different languages, we envision quick and direct access to the latest evidence for policymakers around the world. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 08:43:43 GMT'}]",2023-05-24,"[['Chen', 'Chaoran', ''], ['Stadler', 'Tanja', '']]",0,1,2023-05-23,1,2,3,1,0,1,4c6a4f29f65f63ad438e7ef6bc844b3b0f301f0f,258841387.0,https://www.semanticscholar.org/paper/4c6a4f29f65f63ad438e7ef6bc844b3b0f301f0f,arXiv.org,2023.0,49.0,0.0,0.0,True,"['Biology', 'Computer Science']","[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2145765023', 'name': 'C. Chen'}, {'authorId': '2580290', 'name': 'T. Stadler'}]","['ETH Zurich', 'SIB Swiss Institute of Bioinformatics']",['Switzerland'],2023-05,"['industrial', 'industrial']"
2305.13863,Alexandre Pasquiou,"Alexandre Pasquiou, Yair Lakretz, Bertrand Thirion, Christophe Pallier",Probing Brain Context-Sensitivity with Masked-Attention Generation,"2 pages, 2 figures, CCN 2023",CCN 2023,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Two fundamental questions in neurolinguistics concerns the brain regions that integrate information beyond the lexical level, and the size of their window of integration. To address these questions we introduce a new approach named masked-attention generation. It uses GPT-2 transformers to generate word embeddings that capture a fixed amount of contextual information. We then tested whether these embeddings could predict fMRI brain activity in humans listening to naturalistic text. The results showed that most of the cortex within the language network is sensitive to contextual information, and that the right hemisphere is more sensitive to longer contexts than the left. Masked-attention generation supports previous analyses of context-sensitivity in the brain, and complements them by quantifying the window size of context integration per voxel. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 09:36:21 GMT'}]",2023-05-24,"[['Pasquiou', 'Alexandre', ''], ['Lakretz', 'Yair', ''], ['Thirion', 'Bertrand', ''], ['Pallier', 'Christophe', '']]",0,1,2023-05-23,1,4,1,1,1,0,5ee7bf90583bff5eb96812964da462114bd318f5,258841107.0,https://www.semanticscholar.org/paper/5ee7bf90583bff5eb96812964da462114bd318f5,2023 Conference on Cognitive Computational Neuroscience,2023.0,15.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2175249740', 'name': 'Alexandre Pasquiou'}, {'authorId': '3051598', 'name': 'Yair Lakretz'}, {'authorId': '8493461', 'name': 'B. Thirion'}, {'authorId': '7892142', 'name': 'Christophe Pallier'}]","['Cognitive Neuroimaging Lab', 'French Institute for Research in Computer Science and Automation']",['France'],2023-05,"['industrial', 'industrial']"
2305.14332,Benjamin Muller,"Benjamin Muller, John Wieting, Jonathan H. Clark, Tom Kwiatkowski,
  Sebastian Ruder, Livio Baldini Soares, Roee Aharoni, Jonathan Herzig, Xinyi
  Wang",Evaluating and Modeling Attribution for Cross-Lingual Question Answering,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Trustworthy answer content is abundant in many high-resource languages and is instantly accessible through question answering systems, yet this content can be hard to access for those that do not speak these languages. The leap forward in cross-lingual modeling quality offered by generative language models offers much promise, yet their raw generations often fall short in factuality. To improve trustworthiness in these systems, a promising direction is to attribute the answer to a retrieved source, possibly in a content-rich language different from the query. Our work is the first to study attribution for cross-lingual question answering. First, we collect data in 5 languages to assess the attribution level of a state-of-the-art cross-lingual QA system. To our surprise, we find that a substantial portion of the answers is not attributable to any retrieved passages (up to 50% of answers exactly matching a gold reference) despite the system being able to attend directly to the retrieved text. Second, to address this poor attribution level, we experiment with a wide range of attribution detection techniques. We find that Natural Language Inference models and PaLM 2 fine-tuned on a very small amount of attribution data can accurately detect attribution. Based on these models, we improve the attribution level of a cross-lingual question-answering system. Overall, we show that current academic generative cross-lingual QA systems have substantial shortcomings in attribution and we build tooling to mitigate these issues. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 17:57:46 GMT'}]",2023-05-24,"[['Muller', 'Benjamin', ''], ['Wieting', 'John', ''], ['Clark', 'Jonathan H.', ''], ['Kwiatkowski', 'Tom', ''], ['Ruder', 'Sebastian', ''], ['Soares', 'Livio Baldini', ''], ['Aharoni', 'Roee', ''], ['Herzig', 'Jonathan', ''], ['Wang', 'Xinyi', '']]",0,0,2023-05-23,1,9,1,1,0,1,bb45c524eaed36604599a07ade72b1f641d0ddee,258841427.0,https://www.semanticscholar.org/paper/bb45c524eaed36604599a07ade72b1f641d0ddee,arXiv.org,2023.0,46.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150045488', 'name': 'Benjamin Muller'}, {'authorId': '1771118', 'name': 'J. Wieting'}, {'authorId': '144797264', 'name': 'J. Clark'}, {'authorId': '15652489', 'name': 'T. Kwiatkowski'}, {'authorId': '2124014463', 'name': 'Sebastian Ruder'}, {'authorId': '7353832', 'name': 'Livio Baldini Soares'}, {'authorId': '2335771', 'name': 'Roee Aharoni'}, {'authorId': '47426264', 'name': 'Jonathan Herzig'}, {'authorId': '3277494', 'name': 'Xinyi Wang'}]",['Google'],['United States'],2023-05,['industrial']
2305.14449,Zheng Chen,"Zheng Chen, Ziyan Jiang, Fan Yang, Eunah Cho, Xing Fan, Xiaojiang
  Huang, Yanbin Lu, Aram Galstyan",Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding,,,,,cs.AI cs.IR cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Conversational AI systems such as Alexa need to understand defective queries to ensure robust conversational understanding and reduce user friction. These defective queries often arise from user ambiguities, mistakes, or errors in automatic speech recognition (ASR) and natural language understanding (NLU).   Personalized query rewriting is an approach that focuses on reducing defects in queries by taking into account the user's individual behavior and preferences. It typically relies on an index of past successful user interactions with the conversational AI. However, unseen interactions within the user's history present additional challenges for personalized query rewriting. This paper presents our ""Collaborative Query Rewriting"" approach, which specifically addresses the task of rewriting new user interactions that have not been previously observed in the user's history. This approach builds a ""User Feedback Interaction Graph"" (FIG) of historical user-entity interactions and leverages multi-hop graph traversal to enrich each user's index to cover future unseen defective queries. The enriched user index is called a Collaborative User Index and contains hundreds of additional entries. To counteract precision degradation from the enlarged index, we add additional transformer layers to the L1 retrieval model and incorporate graph-based and guardrail features into the L2 ranking model.   Since the user index can be pre-computed, we further investigate the utilization of a Large Language Model (LLM) to enhance the FIG for user-entity link prediction in the Video/Music domains. Specifically, this paper investigates the Dolly-V2 7B model. We found that the user index augmented by the fine-tuned Dolly-V2 generation significantly enhanced the coverage of future unseen user interactions, thereby boosting QR performance on unseen queries compared with the graph traversal only approach. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 18:15:29 GMT'}, {'version': 'v2', 'created': 'Sat, 3 Jun 2023 12:42:45 GMT'}, {'version': 'v3', 'created': 'Mon, 19 Jun 2023 15:48:29 GMT'}]",2023-06-21,"[['Chen', 'Zheng', ''], ['Jiang', 'Ziyan', ''], ['Yang', 'Fan', ''], ['Cho', 'Eunah', ''], ['Fan', 'Xing', ''], ['Huang', 'Xiaojiang', ''], ['Lu', 'Yanbin', ''], ['Galstyan', 'Aram', '']]",0,0,2023-05-23,3,8,3,0,0,0,95ca86a2d7ae29e28b9187148d79742775233054,258865388.0,https://www.semanticscholar.org/paper/95ca86a2d7ae29e28b9187148d79742775233054,arXiv.org,2023.0,31.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2141144864', 'name': 'Zheng Chen'}, {'authorId': '2112347577', 'name': 'Ziyan Jiang'}, {'authorId': '47829900', 'name': 'Fan Yang'}]",['Amazon'],['United States'],2023-05,['industrial']
2305.14453,Subba Reddy Oota,"Pavan Kalyan Reddy Neerudu, Subba Reddy Oota, Mounika Marreddy,
  Venkateswara Rao Kagita, Manish Gupta",On Robustness of Finetuned Transformer-based NLP Models,"16 pages, 8 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transformer-based pretrained models like BERT, GPT-2 and T5 have been finetuned for a large number of natural language processing (NLP) tasks, and have been shown to be very effective. However, while finetuning, what changes across layers in these models with respect to pretrained checkpoints is under-studied. Further, how robust are these models to perturbations in input text? Does the robustness vary depending on the NLP task for which the models have been finetuned? While there exists some work on studying robustness of BERT finetuned for a few NLP tasks, there is no rigorous study which compares this robustness across encoder only, decoder only and encoder-decoder models.   In this paper, we study the robustness of three language models (BERT, GPT-2 and T5) with eight different text perturbations on the General Language Understanding Evaluation (GLUE) benchmark. Also, we use two metrics (CKA and STIR) to quantify changes between pretrained and finetuned language model representations across layers. GPT-2 representations are more robust than BERT and T5 across multiple types of input perturbation. Although models exhibit good robustness broadly, dropping nouns, verbs or changing characters are the most impactful. Overall, this study provides valuable insights into perturbation-specific weaknesses of popular Transformer-based models which should be kept in mind when passing inputs. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 18:25:18 GMT'}]",2023-05-25,"[['Neerudu', 'Pavan Kalyan Reddy', ''], ['Oota', 'Subba Reddy', ''], ['Marreddy', 'Mounika', ''], ['Kagita', 'Venkateswara Rao', ''], ['Gupta', 'Manish', '']]",0,1,2023-05-23,1,5,1,2,2,0,a2007c352e2051475844aa8ff95f63202b728e79,258865491.0,https://www.semanticscholar.org/paper/a2007c352e2051475844aa8ff95f63202b728e79,arXiv.org,2023.0,43.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218867355', 'name': 'Pavan Kalyan Reddy Neerudu'}, {'authorId': '8307724', 'name': 'S. Oota'}, {'authorId': '25910248', 'name': 'Mounika Marreddy'}, {'authorId': '2366818', 'name': 'Venkateswara Rao Kagita'}, {'authorId': '2152950492', 'name': 'Manish Gupta'}]","['International Institute of Information Technology, Hyderabad', 'French Institute for Research in Computer Science and Automation', 'Microsoft']","['India', 'France']",2023-05,"['industrial', 'industrial', 'industrial']"
2305.14536,Jakub Macina,"Jakub Macina, Nico Daheim, Sankalan Pal Chowdhury, Tanmay Sinha, Manu
  Kapur, Iryna Gurevych, Mrinmaya Sachan",MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems,"Jakub Macina, Nico Daheim, and Sankalan Pal Chowdhury contributed
  equally to this work. Code and dataset available:
  https://github.com/eth-nlped/mathdial",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Although automatic dialogue tutors hold great potential in making education personalized and more accessible, research on such systems has been hampered by a lack of sufficiently large and high-quality datasets. However, collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this problem, we propose a framework to semi-synthetically generate such dialogues by pairing real teachers with a large language model (LLM) scaffolded to represent common student errors. In this paper, we describe our ongoing efforts to use this framework to collect MathDial, a dataset of currently ca. 1.5k tutoring dialogues grounded in multi-step math word problems. We show that our dataset exhibits rich pedagogical properties, focusing on guiding students using sense-making questions to let them explore problems. Moreover, we outline that MathDial and its grounding annotations can be used to finetune language models to be more effective tutors (and not just solvers) and highlight remaining challenges that need to be addressed by the research community. We will release our dataset publicly to foster research in this socially important area of NLP. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 21:44:56 GMT'}]",2023-05-25,"[['Macina', 'Jakub', ''], ['Daheim', 'Nico', ''], ['Chowdhury', 'Sankalan Pal', ''], ['Sinha', 'Tanmay', ''], ['Kapur', 'Manu', ''], ['Gurevych', 'Iryna', ''], ['Sachan', 'Mrinmaya', '']]",0,0,2023-05-23,1,7,1,0,0,0,6cd26d124ffeb6ce301ef351aada27fa0852f81b,258865403.0,https://www.semanticscholar.org/paper/6cd26d124ffeb6ce301ef351aada27fa0852f81b,arXiv.org,2023.0,72.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '23126830', 'name': 'Jakub Macina'}, {'authorId': '2048028927', 'name': 'Nico Daheim'}, {'authorId': '2105636395', 'name': 'Sankalan Pal Chowdhury'}, {'authorId': '145679048', 'name': 'Tanmay Sinha'}, {'authorId': '2465316', 'name': 'Manu Kapur'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]",['ETH Zurich'],['Switzerland'],2023-05,['industrial']
2305.14726,Dan Iter,"Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, Yichong
  Xu, Chenguang Zhu",In-Context Demonstration Selection with Cross Entropy Difference,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) can use in-context demonstrations to improve performance on zero-shot tasks. However, selecting the best in-context examples is challenging because model performance can vary widely depending on the selected examples. We present a cross-entropy difference (CED) method for selecting in-context demonstrations. Our method is based on the observation that the effectiveness of in-context demonstrations negatively correlates with the perplexity of the test example by a language model that was finetuned on that demonstration. We utilize parameter efficient finetuning to train small models on training data that are used for computing the cross-entropy difference between a test example and every candidate in-context demonstration. This metric is used to rank and select in-context demonstrations independently for each test input. We evaluate our method on a mix-domain dataset that combines 8 benchmarks, representing 4 text generation tasks, showing that CED for in-context demonstration selection can improve performance for a variety of LLMs. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 05:04:00 GMT'}]",2023-05-25,"[['Iter', 'Dan', ''], ['Pryzant', 'Reid', ''], ['Xu', 'Ruochen', ''], ['Wang', 'Shuohang', ''], ['Liu', 'Yang', ''], ['Xu', 'Yichong', ''], ['Zhu', 'Chenguang', '']]",0,0,2023-05-24,1,7,2,0,0,0,bfef29e0b88a45b3b6d8018b37d6272d0f32efe2,258865520.0,https://www.semanticscholar.org/paper/bfef29e0b88a45b3b6d8018b37d6272d0f32efe2,arXiv.org,2023.0,33.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3310951', 'name': 'Dan Iter'}, {'authorId': '4099006', 'name': 'Reid Pryzant'}, {'authorId': '8233965', 'name': 'Ruochen Xu'}, {'authorId': '2146294891', 'name': 'Shuo Wang'}, {'authorId': '2152797401', 'name': 'Yang Liu'}, {'authorId': '2110197273', 'name': 'Yichong Xu'}, {'authorId': '8652308', 'name': 'Chenguang Zhu'}]",['Microsoft'],['United States'],2023-05,['industrial']
2305.14878,Vikas Raunak,"Vikas Raunak, Amr Sharaf, Hany Hassan Awadallah, Arul Menezes",Leveraging GPT-4 for Automatic Translation Post-Editing,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  While Neural Machine Translation (NMT) represents the leading approach to Machine Translation (MT), the outputs of NMT models still require translation post-editing to rectify errors and enhance quality, particularly under critical settings. In this work, we formalize the task of translation post-editing with Large Language Models (LLMs) and explore the use of GPT-4 to automatically post-edit NMT outputs across several language pairs. Our results demonstrate that GPT-4 is adept at translation post-editing and produces meaningful edits even when the target language is not English. Notably, we achieve state-of-the-art performance on WMT-22 English-Chinese, English-German, Chinese-English and German-English language pairs using GPT-4 based post-editing, as evaluated by state-of-the-art MT quality metrics. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 08:30:05 GMT'}]",2023-05-25,"[['Raunak', 'Vikas', ''], ['Sharaf', 'Amr', ''], ['Awadallah', 'Hany Hassan', ''], ['Menezes', 'Arul', '']]",0,1,2023-05-24,1,4,2,1,0,1,0476eaae29c0337c1498637ad99931e4d9d1c5df,258865299.0,https://www.semanticscholar.org/paper/0476eaae29c0337c1498637ad99931e4d9d1c5df,arXiv.org,2023.0,50.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '24025563', 'name': 'Vikas Raunak'}, {'authorId': '143816740', 'name': 'Amr Sharaf'}, {'authorId': '2218489849', 'name': 'Hany Hassan Awadallah'}, {'authorId': '145280401', 'name': 'Arul Menezes'}]",['Microsoft'],['United States'],2023-05,['industrial']
2305.14982,Firoj Alam,"Ahmed Abdelali, Hamdy Mubarak, Shammur Absar Chowdhury, Maram
  Hasanain, Basel Mousi, Sabri Boughorbel, Yassine El Kheir, Daniel Izham,
  Fahim Dalvi, Majd Hawasly, Nizi Nazar, Yousseif Elshahawy, Ahmed Ali, Nadir
  Durrani, Natasa Milic-Frayling, Firoj Alam",Benchmarking Arabic AI with Large Language Models,"Foundation Models, Large Language Models, Arabic NLP, Arabic Speech,
  Arabic AI, , CHatGPT Evaluation, USM Evaluation, Whisper Evaluation",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  With large Foundation Models (FMs), language technologies (AI in general) are entering a new paradigm: eliminating the need for developing large-scale task-specific datasets and supporting a variety of tasks through set-ups ranging from zero-shot to few-shot learning. However, understanding FMs capabilities requires a systematic benchmarking effort by comparing FMs performance with the state-of-the-art (SOTA) task-specific models. With that goal, past work focused on the English language and included a few efforts with multiple languages. Our study contributes to ongoing research by evaluating FMs performance for standard Arabic NLP and Speech processing, including a range of tasks from sequence tagging to content classification across diverse domains. We start with zero-shot learning using GPT-3.5-turbo, Whisper, and USM, addressing 33 unique tasks using 59 publicly available datasets resulting in 96 test setups. For a few tasks, FMs performs on par or exceeds the performance of the SOTA models but for the majority it under-performs. Given the importance of prompt for the FMs performance, we discuss our prompt strategies in detail and elaborate on our findings. Our future work on Arabic AI will explore few-shot prompting, expand the range of tasks, and investigate additional open-source models. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 10:16:16 GMT'}]",2023-05-25,"[['Abdelali', 'Ahmed', ''], ['Mubarak', 'Hamdy', ''], ['Chowdhury', 'Shammur Absar', ''], ['Hasanain', 'Maram', ''], ['Mousi', 'Basel', ''], ['Boughorbel', 'Sabri', ''], ['Kheir', 'Yassine El', ''], ['Izham', 'Daniel', ''], ['Dalvi', 'Fahim', ''], ['Hawasly', 'Majd', ''], ['Nazar', 'Nizi', ''], ['Elshahawy', 'Yousseif', ''], ['Ali', 'Ahmed', ''], ['Durrani', 'Nadir', ''], ['Milic-Frayling', 'Natasa', ''], ['Alam', 'Firoj', '']]",0,1,2023-05-24,1,16,2,1,0,1,c5fa70db839fd05b1111f3586a601d8a93e78d0c,258865657.0,https://www.semanticscholar.org/paper/c5fa70db839fd05b1111f3586a601d8a93e78d0c,arXiv.org,2023.0,125.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1683403', 'name': 'Ahmed Abdelali'}, {'authorId': '143779235', 'name': 'Hamdy Mubarak'}, {'authorId': '1725417821', 'name': 'Shammur A. Chowdhury'}, {'authorId': '2905745', 'name': 'Maram Hasanain'}, {'authorId': '2171367840', 'name': 'Basel Mousi'}, {'authorId': '2466162', 'name': 'S. Boughorbel'}, {'authorId': '2189476655', 'name': 'Yassine El Kheir'}, {'authorId': '2177436744', 'name': 'Daniel Izham'}, {'authorId': '6415321', 'name': 'Fahim Dalvi'}, {'authorId': '2762811', 'name': 'Majd Hawasly'}, {'authorId': '2218353460', 'name': 'Nizi Nazar'}, {'authorId': '2218145245', 'name': 'Yousseif Elshahawy'}, {'authorId': '2109102523', 'name': 'Ahmed M. Ali'}, {'authorId': '145938140', 'name': 'Nadir Durrani'}, {'authorId': '1398136050', 'name': 'Natasa Milic-Frayling'}, {'authorId': '37784060', 'name': 'Firoj Alam'}]","['Kanari AI, Doha, Qatar', 'Qatar Computing Research Institute']",['Qatar'],2023-05,"['industrial', 'industrial']"
2305.15065,Ximing Lu,"Ximing Lu, Faeze Brahman, Peter West, Jaehun Jang, Khyathi Chandu,
  Abhilasha Ravichander, Lianhui Qin, Prithviraj Ammanabrolu, Liwei Jiang,
  Sahana Ramnath, Nouha Dziri, Jillian Fisher, Bill Yuchen Lin, Skyler
  Hallinan, Xiang Ren, Sean Welleck, Yejin Choi",Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models excel at a variety of language tasks when prompted with examples or instructions. Yet controlling these models through prompting alone is limited. Tailoring language models through fine-tuning (e.g., via reinforcement learning) can be effective, but it is expensive and requires model access.   We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adaptor trained to optimize an arbitrary user objective with reinforcement learning.   On five challenging text generation tasks, such as toxicity reduction and open-domain generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT- 3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 11:52:55 GMT'}]",2023-05-25,"[['Lu', 'Ximing', ''], ['Brahman', 'Faeze', ''], ['West', 'Peter', ''], ['Jang', 'Jaehun', ''], ['Chandu', 'Khyathi', ''], ['Ravichander', 'Abhilasha', ''], ['Qin', 'Lianhui', ''], ['Ammanabrolu', 'Prithviraj', ''], ['Jiang', 'Liwei', ''], ['Ramnath', 'Sahana', ''], ['Dziri', 'Nouha', ''], ['Fisher', 'Jillian', ''], ['Lin', 'Bill Yuchen', ''], ['Hallinan', 'Skyler', ''], ['Ren', 'Xiang', ''], ['Welleck', 'Sean', ''], ['Choi', 'Yejin', '']]",0,1,2023-05-24,1,17,1,3,1,2,ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2,258865629.0,https://www.semanticscholar.org/paper/ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2,arXiv.org,2023.0,100.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '9252833', 'name': 'Faeze Brahman'}, {'authorId': '119659229', 'name': 'Peter West'}, {'authorId': '2148334242', 'name': 'Jaehun Jang'}, {'authorId': '37619618', 'name': 'Khyathi Raghavi Chandu'}, {'authorId': '3023068', 'name': 'Abhilasha Ravichander'}, {'authorId': '3444092', 'name': 'Lianhui Qin'}, {'authorId': '19179135', 'name': 'Prithviraj Ammanabrolu'}, {'authorId': '2112504145', 'name': 'Liwei Jiang'}, {'authorId': '1399403094', 'name': 'Sahana Ramnath'}, {'authorId': '46217681', 'name': 'Nouha Dziri'}, {'authorId': '33772445', 'name': 'Jillian R. Fisher'}, {'authorId': '51583409', 'name': 'Bill Yuchen Lin'}, {'authorId': '1474550731', 'name': 'Skyler Hallinan'}, {'authorId': '1384550891', 'name': 'Xiang Ren'}, {'authorId': '2129663', 'name': 'S. Welleck'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]",['Allen Institute for Artificial Intelligence'],['United States'],2023-05,['industrial']
2305.15068,Lingyu Gao,"Xiaomeng Ma, Lingyu Gao, Qihui Xu",ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind,work in progress,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Theory of Mind (ToM), the capacity to comprehend the mental states of distinct individuals, is essential for numerous practical applications. With the development of large language models, there is a heated debate about whether they are able to perform ToM tasks. Previous studies have used different tasks and prompts to test the ToM on large language models and the results are inconsistent: some studies asserted these models are capable of exhibiting ToM, while others suggest the opposite. In this study, We present ToMChallenges, a dataset for comprehensively evaluating Theory of Mind based on Sally-Anne and Smarties tests. We created 30 variations of each test (e.g., changing the person's name, location, and items). For each variation, we test the model's understanding of different aspects: reality, belief, 1st order belief, and 2nd order belief. We adapt our data for various tasks by creating unique prompts tailored for each task category: Fill-in-the-Blank, Multiple Choice, True/False, Chain-of-Thought True/False, Question Answering, and Text Completion. If the model has a robust ToM, it should be able to achieve good performance for different prompts across different tests. We evaluated two GPT-3.5 models, text-davinci-003 and gpt-3.5-turbo-0301, with our datasets. Our results indicate that consistent performance in ToM tasks remains a challenge. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 11:54:07 GMT'}]",2023-05-25,"[['Ma', 'Xiaomeng', ''], ['Gao', 'Lingyu', ''], ['Xu', 'Qihui', '']]",0,1,2023-05-24,1,3,2,1,0,1,4d002ebf47e70b862075b83df28e5122a49cc382,258865295.0,https://www.semanticscholar.org/paper/4d002ebf47e70b862075b83df28e5122a49cc382,arXiv.org,2023.0,40.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109028622', 'name': 'Xiaomeng Ma'}, {'authorId': '13382973', 'name': 'Lingyu Gao'}, {'authorId': '2110320939', 'name': 'Qihui Xu'}]","['Basque Center on Cognition, Brain and Language', 'Toyota Technological Institute at Chicago', 'The Graduate Center, CUNY']","['United States', 'Spain']",2023-05,"['industrial', 'industrial', 'industrial']"
2305.15334,Shishir G. Patil,"Shishir G. Patil, Tianjun Zhang, Xin Wang, Joseph E. Gonzalez",Gorilla: Large Language Model Connected with Massive APIs,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis. However, their potential to effectively use tools via API calls remains unfulfilled. This is a challenging task even for today's state-of-the-art LLMs such as GPT-4, largely due to their inability to generate accurate input arguments and their tendency to hallucinate the wrong usage of an API call. We release Gorilla, a finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls. When combined with a document retriever, Gorilla demonstrates a strong capability to adapt to test-time document changes, enabling flexible user updates or version changes. It also substantially mitigates the issue of hallucination, commonly encountered when prompting LLMs directly. To evaluate the model's ability, we introduce APIBench, a comprehensive dataset consisting of HuggingFace, TorchHub, and TensorHub APIs. The successful integration of the retrieval system with Gorilla demonstrates the potential for LLMs to use tools more accurately, keep up with frequently updated documentation, and consequently increase the reliability and applicability of their outputs. Gorilla's code, model, data, and demo are available at https://gorilla.cs.berkeley.edu ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 16:48:11 GMT'}]",2023-05-25,"[['Patil', 'Shishir G.', ''], ['Zhang', 'Tianjun', ''], ['Wang', 'Xin', ''], ['Gonzalez', 'Joseph E.', '']]",0,1,2023-05-24,1,4,2,2,1,1,7d8905a1fd288068f12c8347caeabefd36d0dd6c,258865184.0,https://www.semanticscholar.org/paper/7d8905a1fd288068f12c8347caeabefd36d0dd6c,arXiv.org,2023.0,48.0,64.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '80887461', 'name': 'Shishir G. Patil'}, {'authorId': '1993655237', 'name': 'Tianjun Zhang'}, {'authorId': '2153692009', 'name': 'Xin Wang'}, {'authorId': '49988044', 'name': 'Joseph E. Gonzalez'}]",['Microsoft'],['India'],2023-05,['industrial']
2305.15498,Konstantina Christakopoulou,"Konstantina Christakopoulou, Alberto Lalama, Cj Adams, Iris Qu, Yifat
  Amir, Samer Chucri, Pierce Vollucci, Fabio Soldo, Dina Bseiso, Sarah Scodel,
  Lucas Dixon, Ed H. Chi, Minmin Chen",Large Language Models for User Interest Journeys,,,,,cs.CL cs.AI cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have shown impressive capabilities in natural language understanding and generation. Their potential for deeper user understanding and improved personalized user experience on recommendation platforms is, however, largely untapped. This paper aims to address this gap. Recommender systems today capture users' interests through encoding their historical activities on the platforms. The generated user representations are hard to examine or interpret. On the other hand, if we were to ask people about interests they pursue in their life, they might talk about their hobbies, like I just started learning the ukulele, or their relaxation routines, e.g., I like to watch Saturday Night Live, or I want to plant a vertical garden. We argue, and demonstrate through extensive experiments, that LLMs as foundation models can reason through user activities, and describe their interests in nuanced and interesting ways, similar to how a human would.   We define interest journeys as the persistent and overarching user interests, in other words, the non-transient ones. These are the interests that we believe will benefit most from the nuanced and personalized descriptions. We introduce a framework in which we first perform personalized extraction of interest journeys, and then summarize the extracted journeys via LLMs, using techniques like few-shot prompting, prompt-tuning and fine-tuning. Together, our results in prompting LLMs to name extracted user journeys in a large-scale industrial platform demonstrate great potential of these models in providing deeper, more interpretable, and controllable user understanding. We believe LLM powered user understanding can be a stepping stone to entirely new user experiences on recommendation platforms that are journey-aware, assistive, and enabling frictionless conversation down the line. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 18:40:43 GMT'}]",2023-05-26,"[['Christakopoulou', 'Konstantina', ''], ['Lalama', 'Alberto', ''], ['Adams', 'Cj', ''], ['Qu', 'Iris', ''], ['Amir', 'Yifat', ''], ['Chucri', 'Samer', ''], ['Vollucci', 'Pierce', ''], ['Soldo', 'Fabio', ''], ['Bseiso', 'Dina', ''], ['Scodel', 'Sarah', ''], ['Dixon', 'Lucas', ''], ['Chi', 'Ed H.', ''], ['Chen', 'Minmin', '']]",0,0,2023-05-24,1,13,3,0,0,0,f834aed32f5531bfa426faab71878c549572500e,258887654.0,https://www.semanticscholar.org/paper/f834aed32f5531bfa426faab71878c549572500e,arXiv.org,2023.0,60.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2192607', 'name': 'Konstantina Christakopoulou'}, {'authorId': '2219036905', 'name': 'Alberto Lalama'}, {'authorId': '2218367521', 'name': 'Cj Adams'}, {'authorId': '2219036653', 'name': 'Iris Qu'}, {'authorId': '35536940', 'name': 'Yifat Amir'}, {'authorId': '69872017', 'name': 'S. Chucri'}, {'authorId': '72141955', 'name': 'Pierce Vollucci'}, {'authorId': '2219036346', 'name': 'Fabio Soldo'}, {'authorId': '2219036338', 'name': 'Dina Bseiso'}, {'authorId': '2219030374', 'name': 'Sarah Scodel'}, {'authorId': '2065639113', 'name': 'Lucas Dixon'}, {'authorId': '2226805', 'name': 'Ed H. Chi'}, {'authorId': '1743082', 'name': 'Minmin Chen'}]","['Sarah Scodel; Lucas Dixon; Ed H. Chi; Minmin Chen,', 'Google']",['United States'],2023-05,"['industrial', 'industrial']"
2305.15525,Xin Liu,"Xin Liu, Daniel McDuff, Geza Kovacs, Isaac Galatzer-Levy, Jacob
  Sunshine, Jiening Zhan, Ming-Zher Poh, Shun Liao, Paolo Di Achille, Shwetak
  Patel",Large Language Models are Few-Shot Health Learners,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) can capture rich representations of concepts that are useful for real-world tasks. However, language alone is limited. While existing LLMs excel at text-based inferences, health applications require that models be grounded in numerical data (e.g., vital signs, laboratory values in clinical domains; steps, movement in the wellness domain) that is not easily or readily expressed as text in existing training corpus. We demonstrate that with only few-shot tuning, a large language model is capable of grounding various physiological and behavioral time-series data and making meaningful inferences on numerous health tasks for both clinical and wellness contexts. Using data from wearable and medical sensor recordings, we evaluate these capabilities on the tasks of cardiac signal analysis, physical activity recognition, metabolic calculation (e.g., calories burned), and estimation of stress reports and mental health screeners. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 19:25:16 GMT'}]",2023-05-26,"[['Liu', 'Xin', ''], ['McDuff', 'Daniel', ''], ['Kovacs', 'Geza', ''], ['Galatzer-Levy', 'Isaac', ''], ['Sunshine', 'Jacob', ''], ['Zhan', 'Jiening', ''], ['Poh', 'Ming-Zher', ''], ['Liao', 'Shun', ''], ['Di Achille', 'Paolo', ''], ['Patel', 'Shwetak', '']]",0,0,2023-05-24,1,10,2,0,0,0,6dd44624ac912fb50c21c691806ee52d27e73abb,258888248.0,https://www.semanticscholar.org/paper/6dd44624ac912fb50c21c691806ee52d27e73abb,arXiv.org,2023.0,29.0,13.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2120101568', 'name': 'Xin Liu'}, {'authorId': '1801452', 'name': 'Daniel J. McDuff'}, {'authorId': '2064565683', 'name': 'G. Kovács'}, {'authorId': '1382495709', 'name': 'I. Galatzer-Levy'}, {'authorId': '2219035823', 'name': 'Jacob Sunshine'}, {'authorId': '40465145', 'name': 'Jiening Zhan'}, {'authorId': '145910256', 'name': 'M. Poh'}, {'authorId': '145657522', 'name': 'Shun Liao'}, {'authorId': '4330124', 'name': 'P. Achille'}, {'authorId': '2152110626', 'name': 'Shwetak N. Patel'}]",['Health Research'],['United States'],2023-05,['industrial']
2305.15685,Lei Shu,"Lei Shu, Liangchen Luo, Jayakumar Hoskere, Yun Zhu, Canoee Liu, Simon
  Tong, Jindong Chen, Lei Meng",RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have demonstrated impressive zero-shot capabilities in long-form text generation tasks expressed through natural language instructions. However, user expectations for long-form text rewriting is high, and unintended rewrites (''hallucinations'') produced by the model can negatively impact its overall performance. Existing evaluation benchmarks primarily focus on limited rewriting styles and sentence-level rewriting rather than long-form open-ended rewriting.We introduce OpenRewriteEval, a novel benchmark that covers a wide variety of rewriting types expressed through natural language instructions. It is specifically designed to facilitate the evaluation of open-ended rewriting of long-form texts. In addition, we propose a strong baseline model, RewriteLM, an instruction-tuned large language model for long-form text rewriting. We develop new strategies that facilitate the generation of diverse instructions and preference data with minimal human intervention. We conduct empirical experiments and demonstrate that our model outperforms the current state-of-the-art LLMs in text rewriting. Specifically, it excels in preserving the essential content and meaning of the source text, minimizing the generation of ''hallucinated'' content, while showcasing the ability to generate rewrites with diverse wording and structures. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 03:26:26 GMT'}]",2023-05-26,"[['Shu', 'Lei', ''], ['Luo', 'Liangchen', ''], ['Hoskere', 'Jayakumar', ''], ['Zhu', 'Yun', ''], ['Liu', 'Canoee', ''], ['Tong', 'Simon', ''], ['Chen', 'Jindong', ''], ['Meng', 'Lei', '']]",0,0,2023-05-25,1,8,2,0,0,0,58e2acdd805d9cc48c7fdde0c9c09280f9f6c4e0,258887805.0,https://www.semanticscholar.org/paper/58e2acdd805d9cc48c7fdde0c9c09280f9f6c4e0,arXiv.org,2023.0,56.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145142456', 'name': 'Lei Shu'}, {'authorId': '51225788', 'name': 'Liangchen Luo'}, {'authorId': '151051505', 'name': 'Jayakumar Hoskere'}, {'authorId': '100896506', 'name': 'Yun Zhu'}, {'authorId': '2218423887', 'name': 'Canoee Liu'}, {'authorId': '2058178029', 'name': 'Simon Tong'}, {'authorId': '47740493', 'name': 'Jindong Chen'}, {'authorId': '2218226973', 'name': 'Lei Meng'}]",['Google'],['United States'],2023-05,['industrial']
2305.15809,Heiko Koziolek,"Heiko Koziolek, Sten Gruener, Virendra Ashiwal",ChatGPT for PLC/DCS Control Logic Generation,"8 pages, 6 figures",,,,cs.SE cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) providing generative AI have become popular to support software engineers in creating, summarizing, optimizing, and documenting source code. It is still unknown how LLMs can support control engineers using typical control programming languages in programming tasks. Researchers have explored GitHub CoPilot or DeepMind AlphaCode for source code generation but did not yet tackle control logic programming. The contribution of this paper is an exploratory study, for which we created 100 LLM prompts in 10 representative categories to analyze control logic generation for of PLCs and DCS from natural language. We tested the prompts by generating answers with ChatGPT using the GPT-4 LLM. It generated syntactically correct IEC 61131-3 Structured Text code in many cases and demonstrated useful reasoning skills that could boost control engineer productivity. Our prompt collection is the basis for a more formal LLM benchmark to test and compare such models for control logic generation. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 07:46:53 GMT'}]",2023-05-26,"[['Koziolek', 'Heiko', ''], ['Gruener', 'Sten', ''], ['Ashiwal', 'Virendra', '']]",1,1,2023-05-25,1,3,2,3,0,3,1c1b83df13de4334e48a4c2039bc7ddfa374c486,258887360.0,https://www.semanticscholar.org/paper/1c1b83df13de4334e48a4c2039bc7ddfa374c486,IEEE International Conference on Emerging Technologies and Factory Automation,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","[{'authorId': '2566995', 'name': 'H. Koziolek'}, {'authorId': '2154315802', 'name': 'Sten Gruener'}, {'authorId': '2142749704', 'name': 'Virendra Ashiwal'}]","['ABB Research, Ladenburg, Germany']",['Germany'],2023-05,['industrial']
2305.15852,Jingxuan He,"Niels M\""undler, Jingxuan He, Slobodan Jenko, Martin Vechev","Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation",,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (large LMs) are susceptible to producing text that contains hallucinated content. An important instance of this problem is self-contradiction, where the LM generates two contradictory sentences within the same context. In this work, we present a comprehensive investigation into self-contradiction for various instruction-tuned LMs, covering evaluation, detection, and mitigation. Our analysis reveals the prevalence of self-contradictions when LMs generate text for open-domain topics, e.g., in 17.7% of all sentences produced by ChatGPT. Self-contradiction also complements retrieval-based methods, as a large portion of them (e.g., 35.8% for ChatGPT) cannot be verified using Wikipedia. We then propose a novel prompting-based framework designed to effectively detect and mitigate self-contradictions. Our detector achieves high accuracy, e.g., around 80% F1 score when prompting ChatGPT. The mitigation algorithm iteratively refines the generated text to remove contradictory information while preserving text fluency and informativeness. Importantly, our entire framework is applicable to black-box LMs and does not require external grounded knowledge. Our approach is practically effective and has been released as a push-button tool to benefit the public, available at https://chatprotect.ai/. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 08:43:46 GMT'}, {'version': 'v2', 'created': 'Sun, 1 Oct 2023 07:22:39 GMT'}]",2023-10-03,"[['Mündler', 'Niels', ''], ['He', 'Jingxuan', ''], ['Jenko', 'Slobodan', ''], ['Vechev', 'Martin', '']]",1,1,2023-05-25,2,4,3,1,0,1,c26689282088f7e20c91f29658dc83c7ae9b1929,258887694.0,https://www.semanticscholar.org/paper/c26689282088f7e20c91f29658dc83c7ae9b1929,arXiv.org,2023.0,85.0,24.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151351924', 'name': 'Niels Mündler'}, {'authorId': '8516542', 'name': 'Jingxuan He'}, {'authorId': '2219029757', 'name': 'Slobodan Jenko'}, {'authorId': '1736447', 'name': 'Martin T. Vechev'}]",['ETH Zurich'],['Switzerland'],2023-05,['industrial']
2305.16334,Yuanzhen Xie,"Yuanzhen Xie, Tao Xie, Mingxiong Lin, WenTao Wei, Chenglin Li, Beibei
  Kong, Lei Chen, Chengxiang Zhuo, Bo Hu, Zang Li",OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In most current research, large language models (LLMs) are able to perform reasoning tasks by generating chains of thought through the guidance of specific prompts. However, there still exists a significant discrepancy between their capability in solving complex reasoning problems and that of humans. At present, most approaches focus on chains of thought (COT) and tool use, without considering the adoption and application of human cognitive frameworks. It is well-known that when confronting complex reasoning challenges, humans typically employ various cognitive abilities, and necessitate interaction with all aspects of tools, knowledge, and the external environment information to accomplish intricate tasks. This paper introduces a novel intelligent framework, referred to as OlaGPT. OlaGPT carefully studied a cognitive architecture framework, and propose to simulate certain aspects of human cognition. The framework involves approximating different cognitive modules, including attention, memory, reasoning, learning, and corresponding scheduling and decision-making mechanisms. Inspired by the active learning mechanism of human beings, it proposes a learning unit to record previous mistakes and expert opinions, and dynamically refer to them to strengthen their ability to solve similar problems. The paper also outlines common effective reasoning frameworks for human problem-solving and designs Chain-of-Thought (COT) templates accordingly. A comprehensive decision-making mechanism is also proposed to maximize model accuracy. The efficacy of OlaGPT has been stringently evaluated on multiple reasoning datasets, and the experimental outcomes reveal that OlaGPT surpasses state-of-the-art benchmarks, demonstrating its superior performance. Our implementation of OlaGPT is available on GitHub: \url{https://github.com/oladata-team/OlaGPT}. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 09:36:51 GMT'}]",2023-05-29,"[['Xie', 'Yuanzhen', ''], ['Xie', 'Tao', ''], ['Lin', 'Mingxiong', ''], ['Wei', 'WenTao', ''], ['Li', 'Chenglin', ''], ['Kong', 'Beibei', ''], ['Chen', 'Lei', ''], ['Zhuo', 'Chengxiang', ''], ['Hu', 'Bo', ''], ['Li', 'Zang', '']]",0,1,2023-05-23,1,10,2,0,0,0,aee79d072d627939ce1382c0af8a085ed96c5269,258947120.0,https://www.semanticscholar.org/paper/aee79d072d627939ce1382c0af8a085ed96c5269,arXiv.org,2023.0,35.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1563754185', 'name': 'Yuanzhen Xie'}, {'authorId': '2218515877', 'name': 'Tao Xie'}, {'authorId': '2218721138', 'name': 'Mingxiong Lin'}, {'authorId': '2212773394', 'name': 'Wen-Ke Wei'}, {'authorId': '2128672010', 'name': 'Chenglin Li'}, {'authorId': '2056613156', 'name': 'Beibei Kong'}, {'authorId': '2214406355', 'name': 'Lei Chen'}, {'authorId': '51053175', 'name': 'Chengxiang Zhuo'}, {'authorId': '2118094683', 'name': 'Bo Hu'}, {'authorId': '2109614297', 'name': 'Zang Li'}]",['Tencent'],['China'],2023-05,['industrial']
2305.16504,Qiantong Xu,"Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, Jian Zhang",On the Tool Manipulation Capability of Open-source Large Language Models,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Recent studies on software tool manipulation with large language models (LLMs) mostly rely on closed model APIs. The industrial adoption of these models is substantially constrained due to the security and robustness risks in exposing information to closed LLM API services. In this paper, we ask can we enhance open-source LLMs to be competitive to leading closed LLM APIs in tool manipulation, with practical amount of human supervision. By analyzing common tool manipulation failures, we first demonstrate that open-source LLMs may require training with usage examples, in-context demonstration and generation style regulation to resolve failures. These insights motivate us to revisit classical methods in LLM literature, and demonstrate that we can adapt them as model alignment with programmatic data generation, system prompts and in-context demonstration retrievers to enhance open-source LLMs for tool manipulation. To evaluate these techniques, we create the ToolBench, a tool manipulation benchmark consisting of diverse software tools for real-world tasks. We demonstrate that our techniques can boost leading open-source LLMs by up to 90% success rate, showing capabilities competitive to OpenAI GPT-4 in 4 out of 8 ToolBench tasks. We show that such enhancement typically requires about one developer day to curate data for each tool, rendering a recipe with practical amount of human supervision. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 22:10:20 GMT'}]",2023-05-29,"[['Xu', 'Qiantong', ''], ['Hong', 'Fenglu', ''], ['Li', 'Bo', ''], ['Hu', 'Changran', ''], ['Chen', 'Zhengyu', ''], ['Zhang', 'Jian', '']]",0,1,2023-05-25,1,6,3,1,0,1,f0888b9c0ef63e68c7758e6aec2370961c0eede9,258947425.0,https://www.semanticscholar.org/paper/f0888b9c0ef63e68c7758e6aec2370961c0eede9,arXiv.org,2023.0,66.0,15.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '17872416', 'name': 'Qiantong Xu'}, {'authorId': '2161682335', 'name': 'Fenglu Hong'}, {'authorId': '48218911', 'name': 'B. Li'}, {'authorId': '32820907', 'name': 'Changran Hu'}, {'authorId': '2144321539', 'name': 'Zhe Chen'}, {'authorId': '2151812937', 'name': 'Jian Zhang'}]","['SambaNova Systems, Inc. Palo Alto, CA, USA']",['United States'],2023-05,['industrial']
2305.16626,Shinhyeok Oh,"Shinhyeok Oh, Hyojun Go, Hyeongdon Moon, Yunsung Lee, Myeongho Jeong,
  Hyun Seung Lee and Seungtaek Choi",Evaluation of Question Generation Needs More References,Accepted to Findings of ACL2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Question generation (QG) is the task of generating a valid and fluent question based on a given context and the target answer. According to various purposes, even given the same context, instructors can ask questions about different concepts, and even the same concept can be written in different ways. However, the evaluation for QG usually depends on single reference-based similarity metrics, such as n-gram-based metric or learned metric, which is not sufficient to fully evaluate the potential of QG methods. To this end, we propose to paraphrase the reference question for a more robust QG evaluation. Using large language models such as GPT-3, we created semantically and syntactically diverse questions, then adopt the simple aggregation of the popular evaluation metrics as the final scores. Through our experiments, we found that using multiple (pseudo) references is more effective for QG evaluation while showing a higher correlation with human evaluations than evaluation with a single reference. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 04:40:56 GMT'}]",2023-05-29,"[['Oh', 'Shinhyeok', ''], ['Go', 'Hyojun', ''], ['Moon', 'Hyeongdon', ''], ['Lee', 'Yunsung', ''], ['Jeong', 'Myeongho', ''], ['Lee', 'Hyun Seung', ''], ['Choi', 'Seungtaek', '']]",0,1,2023-05-26,1,7,2,1,0,1,0e2de9e58069fc43d6bcdd458c72b68d6ee434d3,258947413.0,https://www.semanticscholar.org/paper/0e2de9e58069fc43d6bcdd458c72b68d6ee434d3,Annual Meeting of the Association for Computational Linguistics,2023.0,39.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1390597717', 'name': 'Shinhyeok Oh'}, {'authorId': '2046341996', 'name': 'Hyojun Go'}, {'authorId': '2157044837', 'name': 'Hyeongdon Moon'}, {'authorId': '46357976', 'name': 'Yunsung Lee'}, {'authorId': '98089930', 'name': 'Myeongho Jeong'}, {'authorId': '2185049627', 'name': 'Hyun Seung Lee'}, {'authorId': '5841595', 'name': 'Seungtaek Choi'}]",['Riiid AI Research'],,2023-05,['industrial']
2305.16635,Jaehun Jung,"Jaehun Jung, Peter West, Liwei Jiang, Faeze Brahman, Ximing Lu,
  Jillian Fisher, Taylor Sorensen, Yejin Choi",Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing,"22 pages, 6 figures",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  It is commonly perceived that the strongest language models (LMs) rely on a combination of massive scale, instruction data, and human feedback to perform specialized tasks -- e.g. summarization and paraphrasing, without supervision. In this paper, we propose that language models can learn to summarize and paraphrase sentences, with none of these 3 factors. We present Impossible Distillation, a framework that distills a task-specific dataset directly from an off-the-shelf LM, even when it is impossible for the LM itself to reliably solve the task. By training a student model on the generated dataset and amplifying its capability through self-distillation, our method yields a high-quality model and dataset from a low-quality teacher model, without the need for scale or supervision. Using Impossible Distillation, we are able to distill an order of magnitude smaller model (with only 770M parameters) that outperforms 175B parameter GPT-3, in both quality and controllability, as confirmed by automatic and human evaluations. Furthermore, as a useful byproduct of our approach, we obtain DIMSUM+, a high-quality dataset with 3.4M sentence summaries and paraphrases. Our analyses show that this dataset, as a purely LM-generated corpus, is more diverse and more effective for generalization to unseen domains than all human-authored datasets -- including Gigaword with 4M samples. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 05:19:24 GMT'}]",2023-05-29,"[['Jung', 'Jaehun', ''], ['West', 'Peter', ''], ['Jiang', 'Liwei', ''], ['Brahman', 'Faeze', ''], ['Lu', 'Ximing', ''], ['Fisher', 'Jillian', ''], ['Sorensen', 'Taylor', ''], ['Choi', 'Yejin', '']]",0,1,2023-05-26,1,8,3,1,0,1,ac9d5e5cd77a4f36d9bfd4ee9d4c8089f89990a0,258947505.0,https://www.semanticscholar.org/paper/ac9d5e5cd77a4f36d9bfd4ee9d4c8089f89990a0,arXiv.org,2023.0,82.0,13.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2122355046', 'name': 'Jaehun Jung'}, {'authorId': '119659229', 'name': 'Peter West'}, {'authorId': '2112504145', 'name': 'Liwei Jiang'}, {'authorId': '9252833', 'name': 'Faeze Brahman'}, {'authorId': '50085131', 'name': 'Ximing Lu'}, {'authorId': '33772445', 'name': 'Jillian R. Fisher'}, {'authorId': '122436831', 'name': 'Taylor Sorensen'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]",['Allen Institute for Artificial Intelligence'],['United States'],2023-05,['industrial']
2305.16755,Hiba Arnaout,"Hiba Arnaout, Simon Razniewski",Can large language models generate salient negative statements?,"For data, see
  https://www.mpi-inf.mpg.de/fileadmin/inf/d5/research/negation_in_KBs/data.csv",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 09:13:59 GMT'}, {'version': 'v2', 'created': 'Thu, 21 Sep 2023 13:36:03 GMT'}]",2023-09-22,"[['Arnaout', 'Hiba', ''], ['Razniewski', 'Simon', '']]",0,0,2023-05-26,2,2,2,0,0,0,524a781fba2fc08fbfcd58262064ad9f37164b40,258947467.0,https://www.semanticscholar.org/paper/524a781fba2fc08fbfcd58262064ad9f37164b40,arXiv.org,2023.0,18.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40434178', 'name': 'Hiba Arnaout'}, {'authorId': '2066327465', 'name': 'S. Razniewski'}]","['Max Planck Institute for Informatics', 'Robert Bosch (Taiwan)']","['Germany', 'Taiwan']",2023-05,"['industrial', 'industrial']"
2305.16806,Vikas Raunak,"Vikas Raunak, Arul Menezes, Matt Post, Hany Hassan Awadalla",Do GPTs Produce Less Literal Translations?,ACL 2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose language models capable of addressing many natural language generation or understanding tasks. On the task of Machine Translation (MT), multiple works have investigated few-shot prompting mechanisms to elicit better translations from LLMs. However, there has been relatively little investigation on how such translations differ qualitatively from the translations generated by standard Neural Machine Translation (NMT) models. In this work, we investigate these differences in terms of the literalness of translations produced by the two systems. Using literalness measures involving word alignment and monotonicity, we find that translations out of English (E-X) from GPTs tend to be less literal, while exhibiting similar or better scores on MT quality metrics. We demonstrate that this finding is borne out in human evaluations as well. We then show that these differences are especially pronounced when translating sentences that contain idiomatic expressions. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 10:38:31 GMT'}, {'version': 'v2', 'created': 'Tue, 30 May 2023 00:08:25 GMT'}, {'version': 'v3', 'created': 'Wed, 31 May 2023 02:07:27 GMT'}, {'version': 'v4', 'created': 'Tue, 6 Jun 2023 03:15:43 GMT'}]",2023-06-07,"[['Raunak', 'Vikas', ''], ['Menezes', 'Arul', ''], ['Post', 'Matt', ''], ['Awadalla', 'Hany Hassan', '']]",0,1,2023-05-26,4,4,2,1,0,1,b4170009de40c1c46adea6a314734434ecd4b0dc,258947102.0,https://www.semanticscholar.org/paper/b4170009de40c1c46adea6a314734434ecd4b0dc,Annual Meeting of the Association for Computational Linguistics,2023.0,38.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '24025563', 'name': 'Vikas Raunak'}, {'authorId': '145280401', 'name': 'Arul Menezes'}, {'authorId': '38842528', 'name': 'Matt Post'}, {'authorId': '2218489849', 'name': 'Hany Hassan Awadallah'}]",['Microsoft'],['United States'],2023-05,['industrial']
2305.16837,Giriprasad Sridhara,Giriprasad Sridhara and Ranjani H.G. and Sourav Mazumdar,ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks,,,,,cs.SE cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot launched by OpenAI on November 30, 2022. OpenAI's GPT-3 family of large language models serve as the foundation for ChatGPT. ChatGPT is fine-tuned with both supervised and reinforcement learning techniques and has received widespread attention for its articulate responses across diverse domains of knowledge. In this study, we explore how ChatGPT can be used to help with common software engineering tasks. Many of the ubiquitous tasks covering the breadth of software engineering such as ambiguity resolution in software requirements, method name suggestion, test case prioritization, code review, log summarization can potentially be performed using ChatGPT. In this study, we explore fifteen common software engineering tasks using ChatGPT. We juxtapose and analyze ChatGPT's answers with the respective state of the art outputs (where available) and/or human expert ground truth. Our experiments suggest that for many tasks, ChatGPT does perform credibly and the response from it is detailed and often better than the human expert output or the state of the art output. However, for a few other tasks, ChatGPT in its present form provides incorrect answers and hence is not suited for such tasks. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 11:29:06 GMT'}]",2023-05-29,"[['Sridhara', 'Giriprasad', ''], ['G.', 'Ranjani H.', ''], ['Mazumdar', 'Sourav', '']]",1,1,2023-05-26,1,3,3,2,0,2,49f8a40aea0e945bd8b15019a3e4b1bb1c9279ea,258947110.0,https://www.semanticscholar.org/paper/49f8a40aea0e945bd8b15019a3e4b1bb1c9279ea,arXiv.org,2023.0,41.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3023667', 'name': 'G. Sridhara'}, {'authorId': '1652016160', 'name': 'Ranjani H.G.'}, {'authorId': '3315501', 'name': 'Sourav Mazumdar'}]","['Global AI Accelerator (GAIA) Ericsson Bangalore, India']",['India'],2023-05,['industrial']
2305.17116,Brandon Higgs,"David Soong, Sriram Sridhar, Han Si, Jan-Samuel Wagner, Ana Caroline
  Costa S\'a, Christina Y Yu, Kubra Karagoz, Meijian Guan, Hisham Hamadeh,
  Brandon W Higgs",Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have made significant advancements in natural language processing (NLP). Broad corpora capture diverse patterns but can introduce irrelevance, while focused corpora enhance reliability by reducing misleading information. Training LLMs on focused corpora poses computational challenges. An alternative approach is to use a retrieval-augmentation (RetA) method tested in a specific domain.   To evaluate LLM performance, OpenAI's GPT-3, GPT-4, Bing's Prometheus, and a custom RetA model were compared using 19 questions on diffuse large B-cell lymphoma (DLBCL) disease. Eight independent reviewers assessed responses based on accuracy, relevance, and readability (rated 1-3).   The RetA model performed best in accuracy (12/19 3-point scores, total=47) and relevance (13/19, 50), followed by GPT-4 (8/19, 43; 11/19, 49). GPT-4 received the highest readability scores (17/19, 55), followed by GPT-3 (15/19, 53) and the RetA model (11/19, 47). Prometheus underperformed in accuracy (34), relevance (32), and readability (38).   Both GPT-3.5 and GPT-4 had more hallucinations in all 19 responses compared to the RetA model and Prometheus. Hallucinations were mostly associated with non-existent references or fabricated efficacy data.   These findings suggest that RetA models, supplemented with domain-specific corpora, may outperform general-purpose LLMs in accuracy and relevance within specific domains. However, this evaluation was limited to specific questions and metrics and may not capture challenges in semantic search and other NLP tasks. Further research will explore different LLM architectures, RetA methodologies, and evaluation methods to assess strengths and limitations more comprehensively. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 17:33:05 GMT'}, {'version': 'v2', 'created': 'Tue, 30 May 2023 15:37:45 GMT'}]",2023-05-31,"[['Soong', 'David', ''], ['Sridhar', 'Sriram', ''], ['Si', 'Han', ''], ['Wagner', 'Jan-Samuel', ''], ['Sá', 'Ana Caroline Costa', ''], ['Yu', 'Christina Y', ''], ['Karagoz', 'Kubra', ''], ['Guan', 'Meijian', ''], ['Hamadeh', 'Hisham', ''], ['Higgs', 'Brandon W', '']]",0,1,2023-05-26,2,10,2,2,0,2,51b169701290cd129e0781fc9f3a9918604c89b5,258947604.0,https://www.semanticscholar.org/paper/51b169701290cd129e0781fc9f3a9918604c89b5,arXiv.org,2023.0,54.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144506027', 'name': 'D. Soong'}, {'authorId': '8797188', 'name': 'S. Sridhar'}, {'authorId': '2170635354', 'name': 'Han Si'}, {'authorId': '108082794', 'name': 'J. Wagner'}, {'authorId': '2218489452', 'name': ""Ana Caroline Costa S'a""}, {'authorId': '46756088', 'name': 'Christina Y. Yu'}, {'authorId': '2407846', 'name': 'Kubra Karagoz'}, {'authorId': '5182735', 'name': 'Meijian Guan'}, {'authorId': '2085075720', 'name': 'Hisham K Hamadeh'}, {'authorId': '2139794738', 'name': 'Brandon Higgs'}]",['Genmab (United States)'],['United States'],2023-05,['industrial']
2305.17888,Zechun Liu,"Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock,
  Yashar Mehdad, Yangyang Shi, Raghuraman Krishnamoorthi, Vikas Chandra",LLM-QAT: Data-Free Quantization Aware Training for Large Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Several post-training quantization methods have been applied to large language models (LLMs), and have been shown to perform well down to 8-bits. We find that these methods break down at lower bit precision, and investigate quantization aware training for LLMs (LLM-QAT) to push quantization levels even further. We propose a data-free distillation method that leverages generations produced by the pre-trained model, which better preserves the original output distribution and allows quantizing any generative model independent of its training data, similar to post-training quantization methods. In addition to quantizing weights and activations, we also quantize the KV cache, which is critical for increasing throughput and support long sequence dependencies at current model sizes. We experiment with LLaMA models of sizes 7B, 13B, and 30B, at quantization levels down to 4-bits. We observe large improvements over training-free methods, especially in the low-bit settings. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 05:22:11 GMT'}]",2023-05-30,"[['Liu', 'Zechun', ''], ['Oguz', 'Barlas', ''], ['Zhao', 'Changsheng', ''], ['Chang', 'Ernie', ''], ['Stock', 'Pierre', ''], ['Mehdad', 'Yashar', ''], ['Shi', 'Yangyang', ''], ['Krishnamoorthi', 'Raghuraman', ''], ['Chandra', 'Vikas', '']]",0,0,2023-05-29,1,9,1,1,1,0,6bd3ee1ca608bc66a490f63f2fb107d79b44f3e2,258959117.0,https://www.semanticscholar.org/paper/6bd3ee1ca608bc66a490f63f2fb107d79b44f3e2,arXiv.org,2023.0,44.0,26.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109370860', 'name': 'Zechun Liu'}, {'authorId': '9185192', 'name': 'Barlas Oğuz'}, {'authorId': '2112729504', 'name': 'Changsheng Zhao'}, {'authorId': '48025720', 'name': 'Ernie Chang'}, {'authorId': '37502184', 'name': 'Pierre Stock'}, {'authorId': '2121361882', 'name': 'Yashar Mehdad'}, {'authorId': '152345059', 'name': 'Yangyang Shi'}, {'authorId': '2065915235', 'name': 'Raghuraman Krishnamoorthi'}, {'authorId': '144137037', 'name': 'Vikas Chandra'}]",['Meta'],['United States'],2023-05,['industrial']
2305.18125,Andrew Katz,"Andrew Katz, Umair Shakir, Ben Chambers",The Utility of Large Language Models and Generative AI for Education Research,"3 figures, 10 tables",,,,cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The use of natural language processing (NLP) techniques in engineering education can provide valuable insights into the underlying processes involved in generating text. While accessing these insights can be labor-intensive if done manually, recent advances in NLP and large language models have made it a realistic option for individuals. This study explores and evaluates a combination of clustering, summarization, and prompting techniques to analyze over 1,000 student essays in which students discussed their career interests. The specific assignment prompted students to define and explain their career goals as engineers. Using text embedding representations of student responses, we clustered the responses together to identify thematically similar statements from students. The clustered responses were then summarized to quickly identify career interest themes. We also used a set of a priori codes about career satisfaction and sectors to demonstrate an alternative approach to using these generative text models to analyze student writing. The results of this study demonstrate the feasibility and usefulness of NLP techniques in engineering education research. By automating the initial analysis of student essays, researchers and educators can more efficiently and accurately identify key themes and patterns in student writing. The methods presented in this paper have broader applications for engineering education and research purposes beyond analyzing student essays. By explaining these methods to the engineering education community, readers can utilize them in their own contexts. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 14:42:28 GMT'}]",2023-05-30,"[['Katz', 'Andrew', ''], ['Shakir', 'Umair', ''], ['Chambers', 'Ben', '']]",0,0,2023-05-29,1,3,1,0,0,0,1fc0e5b30bfede1b78389d00f8c41bacd29ecd7f,258959485.0,https://www.semanticscholar.org/paper/1fc0e5b30bfede1b78389d00f8c41bacd29ecd7f,arXiv.org,2023.0,80.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2061197384', 'name': 'Andrew Katz'}, {'authorId': '2045051185', 'name': 'Umair Shakir'}, {'authorId': '2064419692', 'name': 'B. Chambers'}]",['Virginia Tech'],['United States'],2023-05,['industrial']
2305.18342,Adish Singla,"Victor-Alexandru P\u{a}durean, Georgios Tzannetos, Adish Singla",Neural Task Synthesis for Visual Programming,,,,,cs.LG cs.AI cs.CL cs.CY cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative neural models hold great promise in enhancing programming education by synthesizing new content for students. We seek to design neural models that can automatically generate programming tasks for a given specification in the context of visual programming domains. Despite the recent successes of large generative models like GPT-4, our initial results show that these models are ineffective in synthesizing visual programming tasks and struggle with logical and spatial reasoning. We propose a novel neuro-symbolic technique, NeurTaskSyn, that can synthesize programming tasks for a specification given in the form of desired programming concepts exercised by its solution code and constraints on the visual task. NeurTaskSyn has two components: the first component is trained via imitation learning procedure to generate possible solution codes, and the second component is trained via reinforcement learning procedure to guide an underlying symbolic execution engine that generates visual tasks for these codes. We demonstrate the effectiveness of NeurTaskSyn through an extensive empirical evaluation and a qualitative study on reference tasks taken from the Hour of Code: Classic Maze challenge by Code-dot-org and the Intro to Programming with Karel course by CodeHS-dot-com. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 01:08:18 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Jun 2023 14:05:10 GMT'}]",2023-06-02,"[['Pădurean', 'Victor-Alexandru', ''], ['Tzannetos', 'Georgios', ''], ['Singla', 'Adish', '']]",0,1,2023-05-26,2,3,5,1,0,1,59a4a5db0a913b99b7afe1c6b2bf6e24f0d31857,258968122.0,https://www.semanticscholar.org/paper/59a4a5db0a913b99b7afe1c6b2bf6e24f0d31857,arXiv.org,2023.0,60.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2086749177', 'name': 'Victor-Alexandru Pădurean'}, {'authorId': '2215269869', 'name': 'Georgios Tzannetos'}, {'authorId': '1703727', 'name': 'A. Singla'}]",['Max Planck Institute for Software Systems'],['Germany'],2023-05,['industrial']
2305.18638,Su Youn Yoon Ms,Su-Youn Yoon,Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model,"7 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this study, we developed an automated short answer grading (ASAG) model that provided both analytic scores and final holistic scores. Short answer items typically consist of multiple sub-questions, and providing an analytic score and the text span relevant to each sub-question can increase the interpretability of the automated scores. Furthermore, they can be used to generate actionable feedback for students. Despite these advantages, most studies have focused on predicting only holistic scores due to the difficulty in constructing dataset with manual annotations. To address this difficulty, we used large language model (LLM)-based one-shot prompting and a text similarity scoring model with domain adaptation using small manually annotated dataset. The accuracy and quadratic weighted kappa of our model were 0.67 and 0.71 on a subset of the publicly available ASAG dataset. The model achieved a substantial improvement over the majority baseline. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 22:05:29 GMT'}]",2023-05-31,"[['Yoon', 'Su-Youn', '']]",0,0,2023-05-29,1,1,1,0,0,0,d1aa858644154af50e36860e6761ae52ae655bd3,258967783.0,https://www.semanticscholar.org/paper/d1aa858644154af50e36860e6761ae52ae655bd3,arXiv.org,2023.0,17.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2669255', 'name': 'Su-Youn Yoon'}]","['EduLab, Inc., Shibuya city, Tokyo, Japan']",['Japan'],2023-05,['industrial']
2305.19352,Artem Lykov,Artem Lykov and Dzmitry Tsetserukou,LLM-BRAIn: AI-driven Fast Generation of Robot Behaviour Tree based on Large Language Model,"10 pages, 5 figures",,,,cs.RO,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This paper presents a novel approach in autonomous robot control, named LLM-BRAIn, that makes possible robot behavior generation, based on operator's commands. LLM-BRAIn is a transformer-based Large Language Model (LLM) fine-tuned from Stanford Alpaca 7B model to generate robot behavior tree (BT) from the text description. We train the LLM-BRAIn on 8,5k instruction-following demonstrations, generated in the style of self-instruct using text-davinchi-003. The developed model accurately builds complex robot behavior while remaining small enough to be run on the robot's onboard microcomputer. The model gives structural and logical correct BTs and can successfully manage instructions that were not presented in training set. The experiment did not reveal any significant subjective differences between BTs generated by LLM-BRAIn and those created by humans (on average, participants were able to correctly distinguish between LLM-BRAIn generated BTs and human-created BTs in only 4.53 out of 10 cases, indicating that their performance was close to random chance). The proposed approach potentially can be applied to mobile robotics, drone operation, robot manipulator systems and Industry 4.0. ","[{'version': 'v1', 'created': 'Tue, 30 May 2023 18:28:54 GMT'}]",2023-06-01,"[['Lykov', 'Artem', ''], ['Tsetserukou', 'Dzmitry', '']]",0,0,2023-05-30,1,2,1,1,0,1,73b2dee720ebc9014dfe57d9b73da60ca7645c86,258987995.0,https://www.semanticscholar.org/paper/73b2dee720ebc9014dfe57d9b73da60ca7645c86,arXiv.org,2023.0,23.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2189477580', 'name': 'Artem Lykov'}, {'authorId': '48470616', 'name': 'D. Tsetserukou'}]",['Skolkovo Institute of Science and Technology'],['Russia'],2023-05,['industrial']
2306.00024,Chandan Singh,"Zelalem Gero, Chandan Singh, Hao Cheng, Tristan Naumann, Michel
  Galley, Jianfeng Gao, Hoifung Poon",Self-Verification Improves Few-Shot Clinical Information Extraction,,IMLH 2023,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Extracting patient information from unstructured text is a critical task in health decision-support and clinical research. Large language models (LLMs) have shown the potential to accelerate clinical curation via few-shot in-context learning, in contrast to supervised learning which requires much more costly human annotations. However, despite drastic advances in modern LLMs such as GPT-4, they still struggle with issues regarding accuracy and interpretability, especially in mission-critical domains such as health. Here, we explore a general mitigation framework using self-verification, which leverages the LLM to provide provenance for its own extraction and check its own outputs. This is made possible by the asymmetry between verification and generation, where the latter is often much easier than the former. Experimental results show that our method consistently improves accuracy for various LLMs in standard clinical information extraction tasks. Additionally, self-verification yields interpretations in the form of a short text span corresponding to each output, which makes it very efficient for human experts to audit the results, paving the way towards trustworthy extraction of clinical information in resource-constrained scenarios. To facilitate future research in this direction, we release our code and prompts. ","[{'version': 'v1', 'created': 'Tue, 30 May 2023 22:05:11 GMT'}]",2023-06-21,"[['Gero', 'Zelalem', ''], ['Singh', 'Chandan', ''], ['Cheng', 'Hao', ''], ['Naumann', 'Tristan', ''], ['Galley', 'Michel', ''], ['Gao', 'Jianfeng', ''], ['Poon', 'Hoifung', '']]",0,1,2023-05-30,1,7,2,1,0,1,34e1a8a75bf6f35084ac6d714a136f39d02c649e,258999642.0,https://www.semanticscholar.org/paper/34e1a8a75bf6f35084ac6d714a136f39d02c649e,arXiv.org,2023.0,43.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1395101702', 'name': 'Zelalem Gero'}, {'authorId': '145229121', 'name': 'Chandan Singh'}, {'authorId': '47413820', 'name': 'Hao Cheng'}, {'authorId': '40466858', 'name': 'Tristan Naumann'}, {'authorId': '1947267', 'name': 'Michel Galley'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}, {'authorId': '1759772', 'name': 'Hoifung Poon'}]",['Microsoft'],['China'],2023-05,['industrial']
2306.00029,Nghi D. Q. Bui,"Nghi D. Q. Bui, Hung Le, Yue Wang, Junnan Li, Akhilesh Deepak Gotmare,
  Steven C. H. Hoi",CodeTF: One-stop Transformer Library for State-of-the-art Code LLM,Ongoing work - Draft Preview,,,,cs.SE cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Code intelligence plays a key role in transforming modern software engineering. Recently, deep learning-based models, especially Transformer-based large language models (LLMs), have demonstrated remarkable potential in tackling these tasks by leveraging massive open-source code data and programming language features. However, the development and deployment of such models often require expertise in both machine learning and software engineering, creating a barrier for the model adoption. In this paper, we present CodeTF, an open-source Transformer-based library for state-of-the-art Code LLMs and code intelligence. Following the principles of modular design and extensible framework, we design CodeTF with a unified interface to enable rapid access and development across different types of models, datasets and tasks. Our library supports a collection of pretrained Code LLM models and popular code benchmarks, including a standardized interface to train and serve code LLMs efficiently, and data features such as language-specific parsers and utility functions for extracting code attributes. In this paper, we describe the design principles, the architecture, key modules and components, and compare with other related library tools. Finally, we hope CodeTF is able to bridge the gap between machine learning/generative AI and software engineering, providing a comprehensive open-source solution for developers, researchers, and practitioners. ","[{'version': 'v1', 'created': 'Wed, 31 May 2023 05:24:48 GMT'}]",2023-06-02,"[['Bui', 'Nghi D. Q.', ''], ['Le', 'Hung', ''], ['Wang', 'Yue', ''], ['Li', 'Junnan', ''], ['Gotmare', 'Akhilesh Deepak', ''], ['Hoi', 'Steven C. H.', '']]",0,0,2023-05-31,1,6,2,0,0,0,f924315bad64452dfd1edd80f932fc1dc871b176,258999746.0,https://www.semanticscholar.org/paper/f924315bad64452dfd1edd80f932fc1dc871b176,arXiv.org,2023.0,58.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '26910508', 'name': 'Nghi D. Q. Bui'}, {'authorId': '2064728738', 'name': 'Hung Le'}, {'authorId': '49416727', 'name': 'Yue Wang'}, {'authorId': '49299019', 'name': 'Junnan Li'}, {'authorId': '144049726', 'name': 'Akhilesh Deepak Gotmare'}, {'authorId': '2184854289', 'name': 'Steven C. H. Hoi'}]",['Salesforce AI Research'],,2023-05,['industrial']
2306.00317,Jeonghoon Kim,"Jung Hyun Lee, Jeonghoon Kim, Se Jung Kwon, Dongsoo Lee",FlexRound: Learnable Rounding based on Element-wise Division for Post-Training Quantization,Accepted to ICML 2023,,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Post-training quantization (PTQ) has been gaining popularity for the deployment of deep neural networks on resource-limited devices since unlike quantization-aware training, neither a full training dataset nor end-to-end training is required at all. As PTQ schemes based on reconstructing each layer or block output turn out to be effective to enhance quantized model performance, recent works have developed algorithms to devise and learn a new weight-rounding scheme so as to better reconstruct each layer or block output. In this work, we propose a simple yet effective new weight-rounding mechanism for PTQ, coined FlexRound, based on element-wise division instead of typical element-wise addition such that FlexRound enables jointly learning a common quantization grid size as well as a different scale for each pre-trained weight. Thanks to the reciprocal rule of derivatives induced by element-wise division, FlexRound is inherently able to exploit pre-trained weights when updating their corresponding scales, and thus, flexibly quantize pre-trained weights depending on their magnitudes. We empirically validate the efficacy of FlexRound on a wide range of models and tasks. To the best of our knowledge, our work is the first to carry out comprehensive experiments on not only image classification and natural language understanding but also natural language generation, assuming a per-tensor uniform PTQ setting. Moreover, we demonstrate, for the first time, that large language models can be efficiently quantized, with only a negligible impact on performance compared to half-precision baselines, achieved by reconstructing the output in a block-by-block manner. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 03:31:12 GMT'}]",2023-06-02,"[['Lee', 'Jung Hyun', ''], ['Kim', 'Jeonghoon', ''], ['Kwon', 'Se Jung', ''], ['Lee', 'Dongsoo', '']]",0,0,2023-06-01,1,4,2,0,0,0,1b31882e60aaae3ac696e4f24f5cd93275c591f7,258999931.0,https://www.semanticscholar.org/paper/1b31882e60aaae3ac696e4f24f5cd93275c591f7,International Conference on Machine Learning,2023.0,59.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2119171752', 'name': 'J. H. Lee'}, {'authorId': '2144193082', 'name': 'Jeonghoon Kim'}, {'authorId': '12693169', 'name': 'Se Jung Kwon'}, {'authorId': '122808525', 'name': 'Dongsoo Lee'}]","['NAVER', 'Knowledge Innovation Market']","['South Korea', 'Spain']",2023-06,"['industrial', 'industrial']"
2306.00597,Antonello Ceravola,"Ahmed R. Sadik, Antonello Ceravola, Frank Joublin, Jibesh Patra",Analysis of ChatGPT on Source Code,"40 pages, examples provided for each experiment. arXiv admin note:
  text overlap with arXiv:2107.03374 by other authors",,,,cs.SE cs.AI cs.PL,http://creativecommons.org/licenses/by/4.0/,"  This paper explores the use of Large Language Models (LLMs) and in particular ChatGPT in programming, source code analysis, and code generation. LLMs and ChatGPT are built using machine learning and artificial intelligence techniques, and they offer several benefits to developers and programmers. While these models can save time and provide highly accurate results, they are not yet advanced enough to replace human programmers entirely. The paper investigates the potential applications of LLMs and ChatGPT in various areas, such as code creation, code documentation, bug detection, refactoring, and more. The paper also suggests that the usage of LLMs and ChatGPT is expected to increase in the future as they offer unparalleled benefits to the programming community. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 12:12:59 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Jun 2023 09:49:36 GMT'}]",2023-06-12,"[['Sadik', 'Ahmed R.', ''], ['Ceravola', 'Antonello', ''], ['Joublin', 'Frank', ''], ['Patra', 'Jibesh', '']]",1,1,2023-06-01,2,4,3,1,0,1,4775ba882c4bddf9e7c656a12fcf78b674af439a,258999138.0,https://www.semanticscholar.org/paper/4775ba882c4bddf9e7c656a12fcf78b674af439a,arXiv.org,2023.0,16.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '39719279', 'name': 'Ahmed R. Sadik'}, {'authorId': '2832005', 'name': 'A. Ceravola'}, {'authorId': '1759554', 'name': 'F. Joublin'}, {'authorId': '1954023', 'name': 'Jibesh Patra'}]",['Honda Research Institute Europe'],['Germany'],2023-06,['industrial']
2306.00739,Ruoxi Sun,"Ruoxi Sun, Sercan O. Arik, Hootan Nakhost, Hanjun Dai, Rajarishi
  Sinha, Pengcheng Yin, Tomas Pfister",SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL,16 pages,,,,cs.CL cs.AI cs.DB,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  One impressive emergent capability of large language models (LLMs) is generation of code, including Structured Query Language (SQL) for databases. For the task of converting natural language text to SQL queries, Text-to-SQL, adaptation of LLMs is of paramount importance, both in in-context learning and fine-tuning settings, depending on the amount of adaptation data used. In this paper, we propose an LLM-based Text-to-SQL model SQL-PaLM, leveraging on PaLM-2, that pushes the state-of-the-art in both settings. Few-shot SQL-PaLM is based on an execution-based self-consistency prompting approach designed for Text-to-SQL, and achieves 77.3% in test-suite accuracy on Spider, which to our best knowledge is the first to outperform previous state-of-the-art with fine-tuning by a significant margin, 4%. Furthermore, we demonstrate that the fine-tuned SQL-PALM outperforms it further by another 1%. Towards applying SQL-PaLM to real-world scenarios we further evaluate its robustness on other challenging variants of Spider and demonstrate the superior generalization capability of SQL-PaLM. In addition, via extensive case studies, we demonstrate the impressive intelligent capabilities and various success enablers of LLM-based Text-to-SQL. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 21:39:05 GMT'}, {'version': 'v2', 'created': 'Wed, 7 Jun 2023 07:23:56 GMT'}, {'version': 'v3', 'created': 'Sun, 25 Jun 2023 06:44:48 GMT'}]",2023-06-27,"[['Sun', 'Ruoxi', ''], ['Arik', 'Sercan O.', ''], ['Nakhost', 'Hootan', ''], ['Dai', 'Hanjun', ''], ['Sinha', 'Rajarishi', ''], ['Yin', 'Pengcheng', ''], ['Pfister', 'Tomas', '']]",0,0,2023-05-26,3,7,3,1,0,1,e0e1fcdbc5b41fcd1cd15001b4861a738411c910,258999853.0,https://www.semanticscholar.org/paper/e0e1fcdbc5b41fcd1cd15001b4861a738411c910,arXiv.org,2023.0,33.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2068169921', 'name': 'Ruoxi Sun'}, {'authorId': '2676352', 'name': 'Sercan Ö. Arik'}, {'authorId': '3346298', 'name': 'Hootan Nakhost'}, {'authorId': '2791430', 'name': 'H. Dai'}, {'authorId': '2446118', 'name': 'Rajarishi Sinha'}, {'authorId': '38253388', 'name': 'Pengcheng Yin'}, {'authorId': '1945962', 'name': 'Tomas Pfister'}]","['Google', 'Team Industrial Services (United States)']","['United States', 'United Kingdom']",2023-05,"['industrial', 'industrial']"
2306.00802,Alberto Bietti,"Alberto Bietti, Vivien Cabannes, Diane Bouchacourt, Herve Jegou, Leon
  Bottou",Birth of a Transformer: A Memory Viewpoint,,,,,stat.ML cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models based on transformers have achieved great empirical successes. However, as they are deployed more widely, there is a growing need to better understand their internal mechanisms in order to make them more reliable. These models appear to store vast amounts of knowledge from their training data, and to adapt quickly to new information provided in their context or prompt. We study how transformers balance these two types of knowledge by considering a synthetic setup where tokens are generated from either global or context-specific bigram distributions. By a careful empirical analysis of the training process on a simplified two-layer transformer, we illustrate the fast learning of global bigrams and the slower development of an ""induction head"" mechanism for the in-context bigrams. We highlight the role of weight matrices as associative memories, provide theoretical insights on how gradients enable their learning during training, and study the role of data-distributional properties. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 15:30:33 GMT'}]",2023-06-02,"[['Bietti', 'Alberto', ''], ['Cabannes', 'Vivien', ''], ['Bouchacourt', 'Diane', ''], ['Jegou', 'Herve', ''], ['Bottou', 'Leon', '']]",0,0,2023-06-01,1,5,3,0,0,0,11ae58636a5daf0ea1297f1c4ee94042fcebefa8,258999187.0,https://www.semanticscholar.org/paper/11ae58636a5daf0ea1297f1c4ee94042fcebefa8,arXiv.org,2023.0,53.0,8.0,1.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2269602', 'name': 'A. Bietti'}, {'authorId': '1387995815', 'name': 'Vivien A. Cabannes'}, {'authorId': '3365029', 'name': 'Diane Bouchacourt'}, {'authorId': '1681054', 'name': 'H. Jégou'}, {'authorId': '52184096', 'name': 'L. Bottou'}]",['Meta'],['United States'],2023-06,['industrial']
2306.01217,Matthew Hong,"Matthew K. Hong, Shabnam Hakimi, Yan-Ying Chen, Heishiro Toyoda,
  Charlene Wu, Matt Klenk",Generative AI for Product Design: Getting the Right Design and the Design Right,,,,,cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Generative AI (GenAI) models excel in their ability to recognize patterns in existing data and generate new and unexpected content. Recent advances have motivated applications of GenAI tools (e.g., Stable Diffusion, ChatGPT) to professional practice across industries, including product design. While these generative capabilities may seem enticing on the surface, certain barriers limit their practical application for real-world use in industry settings. In this position paper, we articulate and situate these barriers within two phases of the product design process, namely ""getting the right design"" and ""getting the design right,"" and propose a research agenda to stimulate discussions around opportunities for realizing the full potential of GenAI tools in product design. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 00:48:50 GMT'}]",2023-06-05,"[['Hong', 'Matthew K.', ''], ['Hakimi', 'Shabnam', ''], ['Chen', 'Yan-Ying', ''], ['Toyoda', 'Heishiro', ''], ['Wu', 'Charlene', ''], ['Klenk', 'Matt', '']]",1,1,2023-06-02,1,6,1,1,0,1,5f21b8d3a127896cb6ffeee46aed7a68e62de35b,259064372.0,https://www.semanticscholar.org/paper/5f21b8d3a127896cb6ffeee46aed7a68e62de35b,arXiv.org,2023.0,15.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '47099832', 'name': 'Matthew K. Hong'}, {'authorId': '2218796163', 'name': 'Shabnam Hakimi'}, {'authorId': '2218896429', 'name': 'Yan-Ying Chen'}, {'authorId': '31248346', 'name': 'Heishiro Toyoda'}, {'authorId': '2157341494', 'name': 'Charlene C. Wu'}, {'authorId': '1811545', 'name': 'M. Klenk'}]","['Toyota Research Institute Los Altos, CA, USA']",['United States'],2023-06,['industrial']
2306.01242,Zhizheng Zhang,"Zhizheng Zhang, Xiaoyi Zhang, Wenxuan Xie, Yan Lu",Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators,,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recent success of Large Language Models (LLMs) signifies an impressive stride towards artificial general intelligence. They have shown a promising prospect in automatically completing tasks upon user instructions, functioning as brain-like coordinators. The associated risks will be revealed as we delegate an increasing number of tasks to machines for automated completion. A big question emerges: how can we make machines behave responsibly when helping humans automate tasks as personal copilots? In this paper, we explore this question in depth from the perspectives of feasibility, completeness and security. In specific, we present Responsible Task Automation (ResponsibleTA) as a fundamental framework to facilitate responsible collaboration between LLM-based coordinators and executors for task automation with three empowered capabilities: 1) predicting the feasibility of the commands for executors; 2) verifying the completeness of executors; 3) enhancing the security (e.g., the protection of users' privacy). We further propose and compare two paradigms for implementing the first two capabilities. One is to leverage the generic knowledge of LLMs themselves via prompt engineering while the other is to adopt domain-specific learnable models. Moreover, we introduce a local memory mechanism for achieving the third capability. We evaluate our proposed ResponsibleTA on UI task automation and hope it could bring more attentions to ensuring LLMs more responsible in diverse scenarios. The research project homepage is at https://task-automation-research.github.io/responsible_task_automation. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 02:42:58 GMT'}]",2023-06-05,"[['Zhang', 'Zhizheng', ''], ['Zhang', 'Xiaoyi', ''], ['Xie', 'Wenxuan', ''], ['Lu', 'Yan', '']]",0,0,2023-06-02,1,4,2,0,0,0,615962d8969c8e0ffe43319689dce6c50cbf1f29,259063857.0,https://www.semanticscholar.org/paper/615962d8969c8e0ffe43319689dce6c50cbf1f29,arXiv.org,2023.0,46.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1486397342', 'name': 'Zhizheng Zhang'}, {'authorId': '46446933', 'name': 'Xiaoyi Zhang'}, {'authorId': '2675648', 'name': 'Wenxuan Xie'}, {'authorId': '2198169719', 'name': 'Yan Lu'}]",['Microsoft'],['China'],2023-06,['industrial']
2306.01545,Javier Rando,Javier Rando and Fernando Perez-Cruz and Briland Hitaj,PassGPT: Password Modeling and (Guided) Generation with Large Language Models,,,,,cs.CL cs.AI cs.CR,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large language models (LLMs) successfully model natural language from vast amounts of text without the need for explicit supervision. In this paper, we investigate the efficacy of LLMs in modeling passwords. We present PassGPT, a LLM trained on password leaks for password generation. PassGPT outperforms existing methods based on generative adversarial networks (GAN) by guessing twice as many previously unseen passwords. Furthermore, we introduce the concept of guided password generation, where we leverage PassGPT sampling procedure to generate passwords matching arbitrary constraints, a feat lacking in current GAN-based strategies. Lastly, we conduct an in-depth analysis of the entropy and probability distribution that PassGPT defines over passwords and discuss their use in enhancing existing password strength estimators. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 13:49:53 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Jun 2023 22:45:28 GMT'}]",2023-06-16,"[['Rando', 'Javier', ''], ['Perez-Cruz', 'Fernando', ''], ['Hitaj', 'Briland', '']]",0,1,2023-06-02,2,3,3,0,0,0,1701d2568c95b8b3a0dcd8036243a64df63938ac,259064205.0,https://www.semanticscholar.org/paper/1701d2568c95b8b3a0dcd8036243a64df63938ac,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2099715241', 'name': 'Javier Rando'}, {'authorId': '2171756401', 'name': 'F. Pérez-Cruz'}, {'authorId': '1997436', 'name': 'B. Hitaj'}]","['SRI International', 'ETH Zurich', 'Swiss Data Science Center']","['United States', 'Switzerland']",2023-06,"['industrial', 'industrial', 'industrial']"
2306.01941,Q.Vera Liao,Q. Vera Liao and Jennifer Wortman Vaughan,AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap,,,,,cs.HC cs.AI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The rise of powerful large language models (LLMs) brings about tremendous opportunities for innovation but also looming risks for individuals and society at large. We have reached a pivotal moment for ensuring that LLMs and LLM-infused applications are developed and deployed responsibly. However, a central pillar of responsible AI -- transparency -- is largely missing from the current discourse around LLMs. It is paramount to pursue new approaches to provide transparency for LLMs, and years of research at the intersection of AI and human-computer interaction (HCI) highlight that we must do so with a human-centered perspective: Transparency is fundamentally about supporting appropriate human understanding, and this understanding is sought by different stakeholders with different goals in different contexts. In this new era of LLMs, we must develop and design approaches to transparency by considering the needs of stakeholders in the emerging LLM ecosystem, the novel types of LLM-infused applications being built, and the new usage patterns and challenges around LLMs, all while building on lessons learned about how people process, interact with, and make use of information. We reflect on the unique challenges that arise in providing transparency for LLMs, along with lessons learned from HCI and responsible AI research that has taken a human-centered perspective on AI transparency. We then lay out four common approaches that the community has taken to achieve transparency -- model reporting, publishing evaluation results, providing explanations, and communicating uncertainty -- and call out open questions around how these approaches may or may not be applied to LLMs. We hope this provides a starting point for discussion and a useful roadmap for future research. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 22:51:26 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Aug 2023 01:41:22 GMT'}]",2023-08-09,"[['Liao', 'Q. Vera', ''], ['Vaughan', 'Jennifer Wortman', '']]",0,0,2023-06-02,2,2,3,0,0,0,3dcf2db20082b480c6c091eea025465cc4fe57a6,259075521.0,https://www.semanticscholar.org/paper/3dcf2db20082b480c6c091eea025465cc4fe57a6,arXiv.org,2023.0,208.0,14.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144921048', 'name': 'Q. Liao'}, {'authorId': '144950416', 'name': 'J. Vaughan'}]",['Microsoft'],['India'],2023-06,['industrial']
2306.02224,Hui Yang,"Hui Yang, Sifu Yue, Yunzhong He",Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions,,,,,cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Auto-GPT is an autonomous agent that leverages recent advancements in adapting Large Language Models (LLMs) for decision-making tasks. While there has been a growing interest in Auto-GPT stypled agents, questions remain regarding the effectiveness and flexibility of Auto-GPT in solving real-world decision-making tasks. Its limited capability for real-world engagement and the absence of benchmarks contribute to these uncertainties. In this paper, we present a comprehensive benchmark study of Auto-GPT styled agents in decision-making tasks that simulate real-world scenarios. Our aim is to gain deeper insights into this problem and understand the adaptability of GPT-based agents. We compare the performance of popular LLMs such as GPT-4, GPT-3.5, Claude, and Vicuna in Auto-GPT styled decision-making tasks. Furthermore, we introduce the Additional Opinions algorithm, an easy and effective method that incorporates supervised/imitation-based learners into the Auto-GPT scheme. This approach enables lightweight supervised learning without requiring fine-tuning of the foundational LLMs. We demonstrate through careful baseline comparisons and ablation studies that the Additional Opinions algorithm significantly enhances performance in online decision-making benchmarks, including WebShop and ALFWorld. ","[{'version': 'v1', 'created': 'Sun, 4 Jun 2023 01:07:20 GMT'}]",2023-06-06,"[['Yang', 'Hui', ''], ['Yue', 'Sifu', ''], ['He', 'Yunzhong', '']]",0,1,2023-06-04,1,3,2,4,1,3,3b8871e4c25d3aaca2bee6606c07bc870337253c,259075577.0,https://www.semanticscholar.org/paper/3b8871e4c25d3aaca2bee6606c07bc870337253c,arXiv.org,2023.0,30.0,12.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2156110830', 'name': 'Hui Yang'}, {'authorId': '2219548768', 'name': 'Sifu Yue'}, {'authorId': '7737839', 'name': 'Yunzhong He'}]",['Amazon'],['United States'],2023-06,['industrial']
2306.02697,Viktoriia Chekalina,"Viktoriia Chekalina, Georgii Novikov, Julia Gusak, Ivan Oseledets,
  Alexander Panchenko",Efficient GPT Model Pre-training using Tensor Train Matrix Representation,,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large-scale transformer models have shown remarkable performance in language modelling tasks. However, such models feature billions of parameters, leading to difficulties in their deployment and prohibitive training costs from scratch. To reduce the number of the parameters in the GPT-2 architecture, we replace the matrices of fully-connected layers with the corresponding Tensor Train Matrix~(TTM) structure. Finally, we customize forward and backward operations through the TTM-based layer for simplicity and the stableness of further training. % The resulting GPT-2-based model stores up to 40% fewer parameters, showing the perplexity comparable to the original model. On the downstream tasks, including language understanding and text summarization, the model performs similarly to the original GPT-2 model. The proposed tensorized layers could be used to efficiently pre-training other Transformer models. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 08:38:25 GMT'}]",2023-06-06,"[['Chekalina', 'Viktoriia', ''], ['Novikov', 'Georgii', ''], ['Gusak', 'Julia', ''], ['Oseledets', 'Ivan', ''], ['Panchenko', 'Alexander', '']]",0,1,2023-06-05,1,5,1,1,1,0,cf59882f25cacb1b688388ca46e6d306dd9fbd41,259075112.0,https://www.semanticscholar.org/paper/cf59882f25cacb1b688388ca46e6d306dd9fbd41,arXiv.org,2023.0,18.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '95677025', 'name': 'V. Chekalina'}, {'authorId': '2122345733', 'name': 'Georgii Sergeevich Novikov'}, {'authorId': '3397802', 'name': 'Julia Gusak'}, {'authorId': '1738205', 'name': 'I. Oseledets'}, {'authorId': '2027664756', 'name': 'A. Panchenko'}]",['Skolkovo Institute of Science and Technology'],['Russia'],2023-06,['industrial']
2306.02707,Arindam Mitra,"Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal,
  Hamid Palangi, Ahmed Awadallah",Orca: Progressive Learning from Complex Explanation Traces of GPT-4,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Recent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small model's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at https://aka.ms/orca-lm), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 08:58:39 GMT'}]",2023-06-06,"[['Mukherjee', 'Subhabrata', ''], ['Mitra', 'Arindam', ''], ['Jawahar', 'Ganesh', ''], ['Agarwal', 'Sahaj', ''], ['Palangi', 'Hamid', ''], ['Awadallah', 'Ahmed', '']]",1,1,2023-06-05,1,6,2,4,2,2,0244aeb7c6927e2fb0c2e668687e160a00737dbe,259075316.0,https://www.semanticscholar.org/paper/0244aeb7c6927e2fb0c2e668687e160a00737dbe,arXiv.org,2023.0,32.0,60.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153292652', 'name': 'Subhabrata Mukherjee'}, {'authorId': '2146720788', 'name': 'Arindam Mitra'}, {'authorId': '2065043351', 'name': 'Ganesh Jawahar'}, {'authorId': '2211923024', 'name': 'Sahaj Agarwal'}, {'authorId': '2542427', 'name': 'H. Palangi'}, {'authorId': '2072795428', 'name': 'A. Awadallah'}]",['Microsoft'],['India'],2023-06,['industrial']
2306.02858,Hang Zhang,"Hang Zhang, Xin Li, Lidong Bing",Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding,"Technical Report; Code, Pretrained Model, and Dataset:
  https://github.com/DAMO-NLP-SG/Video-LLaMA",,,,cs.CL cs.CV cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  We present Video-LLaMA, a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA bootstraps cross-modal training from the frozen pre-trained visual & audio encoders and the frozen LLMs. Unlike previous vision-LLMs that focus on static image comprehensions such as MiniGPT-4 and LLaVA, Video-LLaMA mainly tackles two challenges in video understanding: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals. To counter the first challenge, we propose a Video Q-former to assemble the pre-trained image encoder into our video encoder and introduce a video-to-text generation task to learn video-language correspondence. For the second challenge, we leverage ImageBind, a universal embedding model aligning multiple modalities as the pre-trained audio encoder, and introduce an Audio Q-former on top of ImageBind to learn reasonable auditory query embeddings for the LLM module. To align the output of both visual & audio encoders with LLM's embedding space, we train Video-LLaMA on massive video/image-caption pairs as well as visual-instruction-tuning datasets of moderate amount but higher quality. We found Video-LLaMA showcases the ability to perceive and comprehend video content, generating meaningful responses that are grounded in the visual and auditory information presented in the videos. This highlights the potential of Video-LLaMA as a promising prototype for audio-visual AI assistants. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 13:17:27 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Jun 2023 12:28:37 GMT'}, {'version': 'v3', 'created': 'Mon, 12 Jun 2023 02:28:57 GMT'}]",2023-06-13,"[['Zhang', 'Hang', ''], ['Li', 'Xin', ''], ['Bing', 'Lidong', '']]",0,1,2023-06-05,3,3,4,1,1,0,5d321194696f1f75cf9da045e6022b2f20ba5b9c,259075356.0,https://www.semanticscholar.org/paper/5d321194696f1f75cf9da045e6022b2f20ba5b9c,arXiv.org,2023.0,42.0,65.0,8.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2119077859', 'name': 'Hang Zhang'}, {'authorId': '40613621', 'name': 'Xin Li'}, {'authorId': '1996394', 'name': 'Lidong Bing'}]","['Alibaba', 'Hupan Lab, 310023, Hangzhou, China']",['China'],2023-06,"['industrial', 'industrial']"
2306.03197,"Martin Schr\""oder",Martin Schroder,AutoScrum: Automating Project Planning Using Large Language Models,"25 pages, 3 figures, demo: https://github.com/autoscrum/autoscrum",,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Recent advancements in the field of large language models have made it possible to use language models for advanced reasoning. In this paper we leverage this ability for designing complex project plans based only on knowing the current state and the desired state. Two approaches are demonstrated - a scrum based approach and a shortcut plan approach. The scrum based approach executes an automated process of requirements gathering, user story mapping, feature identification, task decomposition and finally generates questions and search terms for seeking out domain specific information to assist with task completion. The shortcut approach looks at most recent snapshot of the current and desired state and generates the next most reasonable task to do in order to get to the desired state as quickly as possible. In this paper we automate everything using a novel concept of ""Language Programs"". These are programs written in natural language designed to process input data through the language model. Guidance language is used for all LLM programs. All demo source code for this paper is available at https://github.com/autoscrum/autoscrum ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 19:16:37 GMT'}]",2023-06-07,"[['Schroder', 'Martin', '']]",0,0,2023-06-05,1,1,2,0,0,0,3782aa1aa68786af5132304a5fc580b5b89ff4af,259089349.0,https://www.semanticscholar.org/paper/3782aa1aa68786af5132304a5fc580b5b89ff4af,,2023.0,36.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219025727', 'name': 'Martin Schroder'}]",['LinkedIn: martinschroder Swedish Embedded Consulting Group Research'],,2023-06,['industrial']
2306.03203,Hantian Ding,"Hantian Ding, Varun Kumar, Yuchen Tian, Zijian Wang, Rob Kwiatkowski,
  Xiaopeng Li, Murali Krishna Ramanathan, Baishakhi Ray, Parminder Bhatia,
  Sudipta Sengupta, Dan Roth, Bing Xiang",A Static Evaluation of Code Completion by Large Language Models,Accepted by ACL 2023 industry track,,,,cs.CL cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Large language models trained on code have shown great potential to increase productivity of software developers. Several execution-based benchmarks have been proposed to evaluate functional correctness of model-generated code on simple programming problems. Nevertheless, it is expensive to perform the same evaluation on complex real-world projects considering the execution cost. On the contrary, static analysis tools such as linters, which can detect errors without running the program, haven't been well explored for evaluating code generation models. In this work, we propose a static evaluation framework to quantify static errors in Python code completions, by leveraging Abstract Syntax Trees. Compared with execution-based evaluation, our method is not only more efficient, but also applicable to code in the wild. For experiments, we collect code context from open source repos to generate one million function bodies using public models. Our static analysis reveals that Undefined Name and Unused Variable are the most common errors among others made by language models. Through extensive studies, we also show the impact of sampling temperature, model size, and context on static errors in code completions. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 19:23:34 GMT'}]",2023-06-07,"[['Ding', 'Hantian', ''], ['Kumar', 'Varun', ''], ['Tian', 'Yuchen', ''], ['Wang', 'Zijian', ''], ['Kwiatkowski', 'Rob', ''], ['Li', 'Xiaopeng', ''], ['Ramanathan', 'Murali Krishna', ''], ['Ray', 'Baishakhi', ''], ['Bhatia', 'Parminder', ''], ['Sengupta', 'Sudipta', ''], ['Roth', 'Dan', ''], ['Xiang', 'Bing', '']]",0,0,2023-06-05,1,12,2,0,0,0,8395c95b2b4d0e4fbd345affcba242fe6776f23c,259088657.0,https://www.semanticscholar.org/paper/8395c95b2b4d0e4fbd345affcba242fe6776f23c,Annual Meeting of the Association for Computational Linguistics,2023.0,31.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2113455281', 'name': 'Hantian Ding'}, {'authorId': '40574366', 'name': 'Varun Kumar'}, {'authorId': '2152947965', 'name': 'Yuchen Tian'}, {'authorId': '50219006', 'name': 'Zijian Wang'}, {'authorId': '1420209643', 'name': 'Robert Kwiatkowski'}, {'authorId': '2187045812', 'name': 'Xiaopeng Li'}, {'authorId': '30315161', 'name': 'M. Ramanathan'}, {'authorId': '31631000', 'name': 'Baishakhi Ray'}, {'authorId': '50339091', 'name': 'Parminder Bhatia'}, {'authorId': '2072419570', 'name': 'Sudipta Sengupta'}, {'authorId': '144590225', 'name': 'D. Roth'}, {'authorId': '144028698', 'name': 'Bing Xiang'}]",['Amazon'],['United States'],2023-06,['industrial']
2306.03208,Jean-Philippe Corbeil,Jean-Michel Attendu and Jean-Philippe Corbeil,NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification Tasks,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Finetuning large language models inflates the costs of NLU applications and remains the bottleneck of development cycles. Recent works in computer vision use data pruning to reduce training time. Pruned data selection with static methods is based on a score calculated for each training example prior to finetuning, which involves important computational overhead. Moreover, the score may not necessarily be representative of sample importance throughout the entire training duration. We propose to address these issues with a refined version of dynamic data pruning, a curriculum which periodically scores and discards unimportant examples during finetuning. Our method leverages an EL2N metric that we extend to the joint intent and slot classification task, and an initial finetuning phase on the full train set. Our results on the GLUE benchmark and four joint NLU datasets show a better time-accuracy trade-off compared to static methods. Our method preserves full accuracy while training on 50% of the data points and reduces computational times by up to 41%. If we tolerate instead a minor drop of accuracy of 1%, we can prune 80% of the training examples for a reduction in finetuning time reaching 66%. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 19:30:41 GMT'}]",2023-06-07,"[['Attendu', 'Jean-Michel', ''], ['Corbeil', 'Jean-Philippe', '']]",0,0,2023-06-05,1,2,2,0,0,0,b26b07597645522782e919c32f3f84c54a4b7cbf,259088773.0,https://www.semanticscholar.org/paper/b26b07597645522782e919c32f3f84c54a4b7cbf,SUSTAINLP,2023.0,47.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3456369', 'name': 'Jean-Michel Attendu'}, {'authorId': '65755323', 'name': 'Jean-Philippe Corbeil'}]",['Nuance Communications (United States)'],['United States'],2023-06,['industrial']
2306.03264,Sanjeev Kumar Karn,"Sanjeev Kumar Karn, Rikhiya Ghosh, Kusuma P and Oladimeji Farri",shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned LLMs for Radiology Report Impression Generation,1st Place in Task 1B: Radiology Report Summarization at BioNLP 2023,"BioNLP 2023, Co-located with ACL 2023",,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Instruction-tuned generative Large language models (LLMs) like ChatGPT and Bloomz possess excellent generalization abilities, but they face limitations in understanding radiology reports, particularly in the task of generating the IMPRESSIONS section from the FINDINGS section. They tend to generate either verbose or incomplete IMPRESSIONS, mainly due to insufficient exposure to medical text data during training. We present a system which leverages large-scale medical text data for domain-adaptive pre-training of instruction-tuned LLMs to enhance its medical knowledge and performance on specific medical tasks. We show that this system performs better in a zero-shot setting than a number of pretrain-and-finetune adaptation methods on the IMPRESSIONS generation task, and ranks 1st among participating systems in Task 1B: Radiology Report Summarization at the BioNLP 2023 workshop. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 21:33:04 GMT'}]",2023-06-07,"[['Karn', 'Sanjeev Kumar', ''], ['Ghosh', 'Rikhiya', ''], ['P', 'Kusuma', ''], ['Farri', 'Oladimeji', '']]",1,1,2023-06-05,1,4,1,2,1,1,f63a02601c7c3fdabcfff118d98e815697c42e0f,259089323.0,https://www.semanticscholar.org/paper/f63a02601c7c3fdabcfff118d98e815697c42e0f,Workshop on Biomedical Natural Language Processing,2023.0,31.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '34112357', 'name': 'Sanjeev Kumar Karn'}, {'authorId': '2555257', 'name': 'Rikhiya Ghosh'}, {'authorId': '2071432082', 'name': 'P. Kusuma'}, {'authorId': '2211973', 'name': 'Oladimeji Farri'}]",['Siemens Healthcare (Germany)'],['Germany'],2023-06,['industrial']
2306.03917,Marcel Binz,"Marcel Binz, Eric Schulz",Turning large language models into cognitive models,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models are powerful systems that excel at many tasks, ranging from translation to mathematical reasoning. Yet, at the same time, these models often show unhuman-like characteristics. In the present paper, we address this gap and ask whether large language models can be turned into cognitive models. We find that -- after finetuning them on data from psychological experiments -- these models offer accurate representations of human behavior, even outperforming traditional cognitive models in two decision-making domains. In addition, we show that their representations contain the information necessary to model behavior on the level of individual subjects. Finally, we demonstrate that finetuning on multiple tasks enables large language models to predict human behavior in a previously unseen task. Taken together, these results suggest that large, pre-trained models can be adapted to become generalist cognitive models, thereby opening up new research directions that could transform cognitive psychology and the behavioral sciences as a whole. ","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 18:00:01 GMT'}]",2023-06-08,"[['Binz', 'Marcel', ''], ['Schulz', 'Eric', '']]",0,0,2023-06-06,1,2,3,0,0,0,56caaf598c1bf36a24385f30ca775b94cf215b6b,259095948.0,https://www.semanticscholar.org/paper/56caaf598c1bf36a24385f30ca775b94cf215b6b,arXiv.org,2023.0,40.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '32354733', 'name': 'Marcel Binz'}, {'authorId': '49427184', 'name': 'Eric Schulz'}]",['Max Planck Institute for Biological Cybernetics'],['Germany'],2023-06,['industrial']
2306.03959,Julia White,Julia White and Arushi Raghuvanshi and Yada Pruksachatkun,Leveraging Explicit Procedural Instructions for Data-Efficient Action Prediction,,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Task-oriented dialogues often require agents to enact complex, multi-step procedures in order to meet user requests. While large language models have found success automating these dialogues in constrained environments, their widespread deployment is limited by the substantial quantities of task-specific data required for training. The following paper presents a data-efficient solution to constructing dialogue systems, leveraging explicit instructions derived from agent guidelines, such as company policies or customer service manuals. Our proposed Knowledge-Augmented Dialogue System (KADS) combines a large language model with a knowledge retrieval module that pulls documents outlining relevant procedures from a predefined set of policies, given a user-agent interaction. To train this system, we introduce a semi-supervised pre-training scheme that employs dialogue-document matching and action-oriented masked language modeling with partial parameter freezing. We evaluate the effectiveness of our approach on prominent task-oriented dialogue datasets, Action-Based Conversations Dataset and Schema-Guided Dialogue, for two dialogue tasks: action state tracking and workflow discovery. Our results demonstrate that procedural knowledge augmentation improves accuracy predicting in- and out-of-distribution actions while preserving high performance in settings with low or sparse data. ","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 18:42:08 GMT'}]",2023-06-08,"[['White', 'Julia', ''], ['Raghuvanshi', 'Arushi', ''], ['Pruksachatkun', 'Yada', '']]",0,0,2023-06-06,1,3,2,0,0,0,6fe900420a1f83ced66205b8d3886ae78ab9d3a5,259095501.0,https://www.semanticscholar.org/paper/6fe900420a1f83ced66205b8d3886ae78ab9d3a5,Annual Meeting of the Association for Computational Linguistics,2023.0,11.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2111231581', 'name': 'Julia White'}, {'authorId': '2938503', 'name': 'Arushi Raghuvanshi'}, {'authorId': '100984698', 'name': 'Yada Pruksachatkun'}]","['Infinitus Systems, Inc.']",,2023-06,['industrial']
2306.04362,Qinghao Ye,"Haiyang Xu, Qinghao Ye, Xuan Wu, Ming Yan, Yuan Miao, Jiabo Ye, Guohai
  Xu, Anwen Hu, Yaya Shi, Guangwei Xu, Chenliang Li, Qi Qian, Maofei Que, Ji
  Zhang, Xiao Zeng, Fei Huang",Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks,Working in progress,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  To promote the development of Vision-Language Pre-training (VLP) and multimodal Large Language Model (LLM) in the Chinese community, we firstly release the largest public Chinese high-quality video-language dataset named Youku-mPLUG, which is collected from Youku, a well-known Chinese video-sharing website, with strict criteria of safety, diversity, and quality. Youku-mPLUG contains 10 million Chinese video-text pairs filtered from 400 million raw videos across a wide range of 45 diverse categories for large-scale pre-training. In addition, to facilitate a comprehensive evaluation of video-language models, we carefully build the largest human-annotated Chinese benchmarks covering three popular video-language tasks of cross-modal retrieval, video captioning, and video category classification. Youku-mPLUG can enable researchers to conduct more in-depth multimodal research and develop better applications in the future. Furthermore, we release popular video-language pre-training models, ALPRO and mPLUG-2, and our proposed modularized decoder-only model mPLUG-video pre-trained on Youku-mPLUG. Experiments show that models pre-trained on Youku-mPLUG gain up to 23.1% improvement in video category classification. Besides, mPLUG-video achieves a new state-of-the-art result on these benchmarks with 80.5% top-1 accuracy in video category classification and 68.9 CIDEr score in video captioning, respectively. Finally, we scale up mPLUG-video based on the frozen Bloomz with only 1.7% trainable parameters as Chinese multimodal LLM, and demonstrate impressive instruction and video understanding ability. The zero-shot instruction understanding experiment indicates that pretraining with Youku-mPLUG can enhance the ability to comprehend overall and detailed visual semantics, recognize scene text, and leverage open-domain knowledge. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 11:52:36 GMT'}]",2023-06-08,"[['Xu', 'Haiyang', ''], ['Ye', 'Qinghao', ''], ['Wu', 'Xuan', ''], ['Yan', 'Ming', ''], ['Miao', 'Yuan', ''], ['Ye', 'Jiabo', ''], ['Xu', 'Guohai', ''], ['Hu', 'Anwen', ''], ['Shi', 'Yaya', ''], ['Xu', 'Guangwei', ''], ['Li', 'Chenliang', ''], ['Qian', 'Qi', ''], ['Que', 'Maofei', ''], ['Zhang', 'Ji', ''], ['Zeng', 'Xiao', ''], ['Huang', 'Fei', '']]",0,0,2023-06-07,1,16,2,1,1,0,d7a4b09a0e2c2d7b118144cf09895c640896da7b,259095579.0,https://www.semanticscholar.org/paper/d7a4b09a0e2c2d7b118144cf09895c640896da7b,arXiv.org,2023.0,44.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '153194420', 'name': 'Haiyang Xu'}, {'authorId': '2199011713', 'name': 'Qinghao Ye'}, {'authorId': '2145345189', 'name': 'Xuan-Wei Wu'}, {'authorId': '2114009661', 'name': 'Mingshi Yan'}, {'authorId': '2219274454', 'name': 'Yuan Miao'}, {'authorId': '2153258288', 'name': 'Jiabo Ye'}, {'authorId': '2115723816', 'name': 'Guohai Xu'}, {'authorId': '120897486', 'name': 'Anwen Hu'}, {'authorId': '37198550', 'name': 'Yaya Shi'}, {'authorId': '2149131512', 'name': 'Guangwei Xu'}, {'authorId': '2829009', 'name': 'Chenliang Li'}, {'authorId': '2177336921', 'name': 'Qingfang Qian'}, {'authorId': '1949860790', 'name': 'Maofei Que'}, {'authorId': '2116921824', 'name': 'Ji Zhang'}, {'authorId': '2111552792', 'name': 'Xiaoyan Zeng'}, {'authorId': '2194508991', 'name': 'Feiyan Huang'}]",['Alibaba'],['China'],2023-06,['industrial']
2306.04384,Xavier Fontaine,"Xavier Fontaine, F\'elix Gaschi, Parisa Rastin and Yannick Toussaint",Multilingual Clinical NER: Translation or Cross-lingual Transfer?,"23 pages, Proceedings of the 5th Clinical Natural Language Processing
  Workshop",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language tasks like Named Entity Recognition (NER) in the clinical domain on non-English texts can be very time-consuming and expensive due to the lack of annotated data. Cross-lingual transfer (CLT) is a way to circumvent this issue thanks to the ability of multilingual large language models to be fine-tuned on a specific task in one language and to provide high accuracy for the same task in another language. However, other methods leveraging translation models can be used to perform NER without annotated data in the target language, by either translating the training set or test set. This paper compares cross-lingual transfer with these two alternative methods, to perform clinical NER in French and in German without any training data in those languages. To this end, we release MedNERF a medical NER test set extracted from French drug prescriptions and annotated with the same guidelines as an English dataset. Through extensive experiments on this dataset and on a German medical dataset (Frei and Kramer, 2021), we show that translation-based methods can achieve similar performance to CLT but require more care in their design. And while they can take advantage of monolingual clinical language models, those do not guarantee better results than large general-purpose multilingual models, whether with cross-lingual transfer or translation. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 12:31:07 GMT'}]",2023-06-08,"[['Fontaine', 'Xavier', ''], ['Gaschi', 'Félix', ''], ['Rastin', 'Parisa', ''], ['Toussaint', 'Yannick', '']]",0,0,2023-06-07,1,4,3,0,0,0,d7879de2cad2f69d6361ac46baa3f83e88ae6613,259095791.0,https://www.semanticscholar.org/paper/d7879de2cad2f69d6361ac46baa3f83e88ae6613,Clinical Natural Language Processing Workshop,2023.0,47.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50026293', 'name': 'X. Fontaine'}, {'authorId': '2145326851', 'name': 'Félix Gaschi'}, {'authorId': '3109851', 'name': 'Parisa Rastin'}, {'authorId': '1802166', 'name': 'Y. Toussaint'}]","['Soil Agro and Hydrosystems Spatialization', 'Lorraine Research Laboratory in Computer Science and its Applications']",['France'],2023-06,"['industrial', 'industrial']"
2306.04891,Kabir Ahuja,"Kabir Ahuja, Madhur Panwar, Navin Goyal",In-Context Learning through the Bayesian Prism,,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In-context learning is one of the surprising and useful features of large language models. How it works is an active area of research. Recently, stylized meta-learning-like setups have been devised that train these models on a sequence of input-output pairs $(x, f(x))$ from a function class using the language modeling loss and observe generalization to unseen functions from the same class. One of the main discoveries in this line of research has been that for several problems such as linear regression, trained transformers learn algorithms for learning functions in context. However, the inductive biases of these models resulting in this behavior are not clearly understood. A model with unlimited training data and compute is a Bayesian predictor: it learns the pretraining distribution. It has been shown that high-capacity transformers mimic the Bayesian predictor for linear regression. In this paper, we show empirical evidence of transformers exhibiting the behavior of this ideal learner across different linear and non-linear function classes. We also extend the previous setups to work in the multitask setting and verify that transformers can do in-context learning in this setup as well and the Bayesian perspective sheds light on this setting also. Finally, via the example of learning Fourier series, we study the inductive bias for in-context learning. We find that in-context learning may or may not have simplicity bias depending on the pretraining data distribution. ","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 02:38:23 GMT'}]",2023-06-09,"[['Ahuja', 'Kabir', ''], ['Panwar', 'Madhur', ''], ['Goyal', 'Navin', '']]",0,0,2023-06-08,1,3,2,0,0,0,f4d543ff431359947bf41152ac01233b8062221f,259108565.0,https://www.semanticscholar.org/paper/f4d543ff431359947bf41152ac01233b8062221f,arXiv.org,2023.0,51.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '52154863', 'name': 'Kabir Ahuja'}, {'authorId': '48248617', 'name': 'Madhuri Panwar'}, {'authorId': '144260125', 'name': 'Navin Goyal'}]",['Microsoft'],['India'],2023-06,['industrial']
2306.06101,Konstantin Mishchenko,"Konstantin Mishchenko, Aaron Defazio",Prodigy: An Expeditiously Adaptive Parameter-Free Learner,,,,,cs.LG cs.AI math.OC stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 17:59:35 GMT'}, {'version': 'v2', 'created': 'Thu, 21 Sep 2023 16:29:31 GMT'}]",2023-09-22,"[['Mishchenko', 'Konstantin', ''], ['Defazio', 'Aaron', '']]",0,1,2023-06-09,2,2,4,0,0,0,c82a7de327bf43c83c668aa8dab28a86a8f03f09,259129271.0,https://www.semanticscholar.org/paper/c82a7de327bf43c83c668aa8dab28a86a8f03f09,arXiv.org,2023.0,35.0,1.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144950781', 'name': 'Konstantin Mishchenko'}, {'authorId': '34597877', 'name': 'Aaron Defazio'}]","['Samsung', 'Meta']","['South Korea', 'United States']",2023-06,"['industrial', 'industrial']"
2306.06264,Pouya Pezeshkpour,Pouya Pezeshkpour,Measuring and Modifying Factual Knowledge in Large Language Models,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) store an extensive amount of factual knowledge obtained from vast collections of text. To effectively utilize these models for downstream tasks, it is crucial to have reliable methods for measuring their knowledge. However, existing approaches for knowledge measurement have certain limitations, and despite recent efforts, they fail to provide accurate measurements and the necessary insights for modifying the knowledge within LLMs. In this work, we employ information theory-based measurements to provide a framework estimating the factual knowledge contained within large language models. More specifically, we measure knowledge by analyzing the LLM's prediction probability distribution before and after instilling the target knowledge, employing metrics such as entropy and KL-divergence. Introducing our metrics, we first assess their accuracy in comparison to previous ranking-based methods, surpassing them by over $35\%$ in a synthetic experiment. Then, we explore two prominent methods of knowledge instillation, discovering that LLMs exhibit limitations in capturing new knowledge under specific circumstances for one of these methods. Lastly, we demonstrate the applicability of our methods in extracting unlearned and mislearned facts in LLMs through their application to in-context learning. We make code and data for all methods and experiments in this paper publicly available. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 21:25:48 GMT'}]",2023-06-13,"[['Pezeshkpour', 'Pouya', '']]",0,0,2023-06-09,1,1,2,0,0,0,5e096f65139e789fd3aa41de7e11bc9c04da79d5,259138387.0,https://www.semanticscholar.org/paper/5e096f65139e789fd3aa41de7e11bc9c04da79d5,arXiv.org,2023.0,22.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1713436', 'name': 'Pouya Pezeshkpour'}]",['Laboratori Guglielmo Marconi (Italy)'],['Italy'],2023-06,['industrial']
2306.07377,Dhanaraj Thakur,Gabriel Nicholas and Aliya Bhatia,Lost in Translation: Large Language Models in Non-English Content Analysis,"50 pages, 4 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa, Google's PaLM) have become the dominant approach for building AI systems to analyze and generate language online. However, the automated systems that increasingly mediate our interactions online -- such as chatbots, content moderation systems, and search engines -- are primarily designed for and work far more effectively in English than in the world's other 7,000 languages. Recently, researchers and technology companies have attempted to extend the capabilities of large language models into languages other than English by building what are called multilingual language models.   In this paper, we explain how these multilingual language models work and explore their capabilities and limits. Part I provides a simple technical explanation of how large language models work, why there is a gap in available data between English and other languages, and how multilingual language models attempt to bridge that gap. Part II accounts for the challenges of doing content analysis with large language models in general and multilingual language models in particular. Part III offers recommendations for companies, researchers, and policymakers to keep in mind when considering researching, developing and deploying large and multilingual language models. ","[{'version': 'v1', 'created': 'Mon, 12 Jun 2023 19:10:47 GMT'}]",2023-06-14,"[['Nicholas', 'Gabriel', ''], ['Bhatia', 'Aliya', '']]",0,1,2023-06-12,1,2,2,3,1,2,2d1197b3a0d9f9e4c366638e131a9cc8ae9fe1af,259145355.0,https://www.semanticscholar.org/paper/2d1197b3a0d9f9e4c366638e131a9cc8ae9fe1af,arXiv.org,2023.0,148.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1741424950', 'name': 'Gabriel Nicholas'}, {'authorId': '146023784', 'name': 'Aliya Bhatia'}]","['Center for Democracy & Technology.', 'Research Fellow at the Center for Democracy & Technology.']",,2023-06,"['industrial', 'industrial']"
2306.07486,Minghan Wang,"Hao Yang, Min Zhang, Shimin Tao, Minghan Wang, Daimeng Wei, Yanfei
  Jiang",Knowledge-Prompted Estimator: A Novel Approach to Explainable Machine Translation Assessment,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Cross-lingual Machine Translation (MT) quality estimation plays a crucial role in evaluating translation performance. GEMBA, the first MT quality assessment metric based on Large Language Models (LLMs), employs one-step prompting to achieve state-of-the-art (SOTA) in system-level MT quality estimation; however, it lacks segment-level analysis. In contrast, Chain-of-Thought (CoT) prompting outperforms one-step prompting by offering improved reasoning and explainability. In this paper, we introduce Knowledge-Prompted Estimator (KPE), a CoT prompting method that combines three one-step prompting techniques, including perplexity, token-level similarity, and sentence-level similarity. This method attains enhanced performance for segment-level estimation compared with previous deep learning models and one-step prompting approaches. Furthermore, supplementary experiments on word-level visualized alignment demonstrate that our KPE method significantly improves token alignment compared with earlier models and provides better interpretability for MT quality estimation. Code will be released upon publication. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 01:18:32 GMT'}]",2023-06-14,"[['Yang', 'Hao', ''], ['Zhang', 'Min', ''], ['Tao', 'Shimin', ''], ['Wang', 'Minghan', ''], ['Wei', 'Daimeng', ''], ['Jiang', 'Yanfei', '']]",0,0,2023-06-13,1,6,1,0,0,0,d1bd7ae97588eccfbcd31ffce4fc924d12a5de4d,259145071.0,https://www.semanticscholar.org/paper/d1bd7ae97588eccfbcd31ffce4fc924d12a5de4d,arXiv.org,2023.0,20.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2115537856', 'name': 'Hao Yang'}, {'authorId': '40093418', 'name': 'Min Zhang'}, {'authorId': '1978838820', 'name': 'Shimin Tao'}, {'authorId': '1628331115', 'name': 'Minghan Wang'}, {'authorId': '8884457', 'name': 'Daimeng Wei'}, {'authorId': '2203256236', 'name': 'Yanfei Jiang'}]",['Laboratori Guglielmo Marconi (Italy)'],['Italy'],2023-06,['industrial']
2306.07567,Fabien Roger,Fabien Roger,Large Language Models Sometimes Generate Purely Negatively-Reinforced Text,"6 pages, 5 figures, LaTeX; added a related work section",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  When using adversarial training, it is common practice to train against the most egregious failures. However, this might imply using examples with sensitive information (such as leaked passwords or security vulnerabilities) as training data. One might assume that language models trained with gradient descent never generate text snippets which were only present in examples associated with the lowest possible reward. In this paper, we show that this assumption is wrong: in some situations, large language models do learn from such negatively-reinforced examples. We present a specific training setup that enables Pythia-160M to guess passwords 13% more often than it would by guessing randomly, despite only showing it these passwords on examples where the model is incentivized to not output these passwords. Our code is available at www.github.com/FabienRoger/Learning-From-Negative-Examples ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 06:40:37 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Jun 2023 16:23:21 GMT'}]",2023-06-19,"[['Roger', 'Fabien', '']]",0,0,2023-06-13,2,1,2,1,1,0,75ecb661565c899f0341a21ecbff96dc72f06430,259145195.0,https://www.semanticscholar.org/paper/75ecb661565c899f0341a21ecbff96dc72f06430,arXiv.org,2023.0,12.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2197780120', 'name': 'Fabien Roger'}]",['Redwood Research'],,2023-06,['industrial']
2306.07933,Lina Bariah,"Lina Bariah and Hang Zou and Qiyang Zhao and Belkacem Mouhouche and
  Faouzi Bader and Merouane Debbah",Understanding Telecom Language Through Large Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the 3rd Generation Partnership Project (3GPP) standard working groups. We consider training the selected models on 3GPP technical documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP working groups. The distilled BERT model with around 50% less parameters achieves similar performance as others. This corroborates that fine-tuning pretrained LLM can effectively identify the categories of Telecom language. The developed framework shows a stepping stone towards realizing intent-driven and self-evolving wireless networks from Telecom languages, and paves the way for the implementation of generative AI in the Telecom domain. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 15:44:41 GMT'}]",2023-06-14,"[['Bariah', 'Lina', ''], ['Zou', 'Hang', ''], ['Zhao', 'Qiyang', ''], ['Mouhouche', 'Belkacem', ''], ['Bader', 'Faouzi', ''], ['Debbah', 'Merouane', '']]",0,1,2023-06-09,1,6,2,1,1,0,6a3ed569d47b4ea08aca4f69ec7da5e8d87734b0,259145106.0,https://www.semanticscholar.org/paper/6a3ed569d47b4ea08aca4f69ec7da5e8d87734b0,arXiv.org,2023.0,22.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2579970', 'name': 'Lina Bariah'}, {'authorId': '2180261014', 'name': 'Han Zou'}, {'authorId': '40538512', 'name': 'Qiyang Zhao'}, {'authorId': '1968720', 'name': 'B. Mouhouche'}, {'authorId': '1691061', 'name': 'F. Bader'}, {'authorId': '145118318', 'name': 'M. Debbah'}]",['Technology Innovation Institute'],['United Arab Emirates'],2023-06,['industrial']
2306.08161,Arno Candel,"Arno Candel, Jon McKinney, Philipp Singer, Pascal Pfeiffer, Maximilian
  Jeblick, Prithvi Prabhu, Jeff Gambera, Mark Landry, Shivam Bansal, Ryan
  Chesler, Chun Ming Lee, Marcos V. Conde, Pasha Stetsenko, Olivier Grellier,
  SriSatish Ambati",h2oGPT: Democratizing Large Language Models,"Work in progress by H2O.ai, Inc",,,,cs.CL cs.AI cs.HC cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Applications built on top of Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their human-level capabilities in natural language processing. However, they also pose many significant risks such as the presence of biased, private, or harmful text, and the unauthorized inclusion of copyrighted material.   We introduce h2oGPT, a suite of open-source code repositories for the creation and use of LLMs based on Generative Pretrained Transformers (GPTs). The goal of this project is to create the world's best truly open-source alternative to closed-source approaches. In collaboration with and as part of the incredible and unstoppable open-source community, we open-source several fine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for commercial use under fully permissive Apache 2.0 licenses. Included in our release is 100\% private document search using natural language.   Open-source language models help boost AI development and make it more accessible and trustworthy. They lower entry hurdles, allowing people and groups to tailor these models to their needs. This openness increases innovation, transparency, and fairness. An open-source strategy is needed to share AI benefits fairly, and H2O.ai will continue to democratize AI and LLMs. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 22:19:53 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Jun 2023 17:48:22 GMT'}]",2023-06-19,"[['Candel', 'Arno', ''], ['McKinney', 'Jon', ''], ['Singer', 'Philipp', ''], ['Pfeiffer', 'Pascal', ''], ['Jeblick', 'Maximilian', ''], ['Prabhu', 'Prithvi', ''], ['Gambera', 'Jeff', ''], ['Landry', 'Mark', ''], ['Bansal', 'Shivam', ''], ['Chesler', 'Ryan', ''], ['Lee', 'Chun Ming', ''], ['Conde', 'Marcos V.', ''], ['Stetsenko', 'Pasha', ''], ['Grellier', 'Olivier', ''], ['Ambati', 'SriSatish', '']]",0,1,2023-06-13,2,15,5,1,0,1,4eeefda3d7cc40d51183a1066200dae6a545874d,259164816.0,https://www.semanticscholar.org/paper/4eeefda3d7cc40d51183a1066200dae6a545874d,arXiv.org,2023.0,4.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2077983', 'name': 'A. Candel'}, {'authorId': '2220096517', 'name': 'Jon McKinney'}, {'authorId': '2047331906', 'name': 'Philipp Singer'}, {'authorId': '2068387941', 'name': 'Pascal Pfeiffer'}, {'authorId': '102259977', 'name': 'Maximilian Jeblick'}, {'authorId': '2097394130', 'name': 'Prithvi Prabhu'}, {'authorId': '2220096884', 'name': 'Jeff Gambera'}, {'authorId': '1751578038', 'name': 'Mark Landry'}, {'authorId': '40917739', 'name': 'Shivam Bansal'}, {'authorId': '2220099634', 'name': 'Ryan Chesler'}, {'authorId': '2220667090', 'name': 'Chun Ming Lee'}, {'authorId': '1411880229', 'name': 'Marcos V. Conde'}, {'authorId': '2220096880', 'name': 'Pasha Stetsenko'}, {'authorId': '1843852', 'name': 'O. Grellier'}, {'authorId': '1825793083', 'name': 'SriSatish Ambati'}]","['H2O.ai, Inc. Mountain View, CA']",,2023-06,['industrial']
2306.08647,Wenhao Yu,"Wenhao Yu, Nimrod Gileadi, Chuyuan Fu, Sean Kirmani, Kuang-Huei Lee,
  Montse Gonzalez Arenas, Hao-Tien Lewis Chiang, Tom Erez, Leonard Hasenclever,
  Jan Humplik, Brian Ichter, Ted Xiao, Peng Xu, Andy Zeng, Tingnan Zhang,
  Nicolas Heess, Dorsa Sadigh, Jie Tan, Yuval Tassa, Fei Xia",Language to Rewards for Robotic Skill Synthesis,https://language-to-reward.github.io/,,,,cs.RO cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated exciting progress in acquiring diverse new capabilities through in-context learning, ranging from logical reasoning to code-writing. Robotics researchers have also explored using LLMs to advance the capabilities of robotic control. However, since low-level robot actions are hardware-dependent and underrepresented in LLM training corpora, existing efforts in applying LLMs to robotics have largely treated LLMs as semantic planners or relied on human-engineered control primitives to interface with the robot. On the other hand, reward functions are shown to be flexible representations that can be optimized for control policies to achieve diverse tasks, while their semantic richness makes them suitable to be specified by LLMs. In this work, we introduce a new paradigm that harnesses this realization by utilizing LLMs to define reward parameters that can be optimized and accomplish variety of robotic tasks. Using reward as the intermediate interface generated by LLMs, we can effectively bridge the gap between high-level language instructions or corrections to low-level robot actions. Meanwhile, combining this with a real-time optimizer, MuJoCo MPC, empowers an interactive behavior creation experience where users can immediately observe the results and provide feedback to the system. To systematically evaluate the performance of our proposed method, we designed a total of 17 tasks for a simulated quadruped robot and a dexterous manipulator robot. We demonstrate that our proposed method reliably tackles 90% of the designed tasks, while a baseline using primitive skills as the interface with Code-as-policies achieves 50% of the tasks. We further validated our method on a real robot arm where complex manipulation skills such as non-prehensile pushing emerge through our interactive system. ","[{'version': 'v1', 'created': 'Wed, 14 Jun 2023 17:27:10 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Jun 2023 23:02:21 GMT'}]",2023-06-21,"[['Yu', 'Wenhao', ''], ['Gileadi', 'Nimrod', ''], ['Fu', 'Chuyuan', ''], ['Kirmani', 'Sean', ''], ['Lee', 'Kuang-Huei', ''], ['Arenas', 'Montse Gonzalez', ''], ['Chiang', 'Hao-Tien Lewis', ''], ['Erez', 'Tom', ''], ['Hasenclever', 'Leonard', ''], ['Humplik', 'Jan', ''], ['Ichter', 'Brian', ''], ['Xiao', 'Ted', ''], ['Xu', 'Peng', ''], ['Zeng', 'Andy', ''], ['Zhang', 'Tingnan', ''], ['Heess', 'Nicolas', ''], ['Sadigh', 'Dorsa', ''], ['Tan', 'Jie', ''], ['Tassa', 'Yuval', ''], ['Xia', 'Fei', '']]",0,0,2023-06-14,2,20,3,0,0,0,94bcf0390d5acb1b92323bd15cc1dc311314122c,259164906.0,https://www.semanticscholar.org/paper/94bcf0390d5acb1b92323bd15cc1dc311314122c,arXiv.org,2023.0,79.0,32.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '70461341', 'name': 'Wenhao Yu'}, {'authorId': '52090101', 'name': 'Nimrod Gileadi'}, {'authorId': '3430433', 'name': 'Chuyuan Fu'}, {'authorId': '51881277', 'name': 'Sean Kirmani'}, {'authorId': '2145145412', 'name': 'Kuang-Huei Lee'}, {'authorId': '153134021', 'name': 'Montse Gonzalez Arenas'}, {'authorId': '20509892', 'name': 'H. Chiang'}, {'authorId': '1968210', 'name': 'Tom Erez'}, {'authorId': '40401956', 'name': 'Leonard Hasenclever'}, {'authorId': '2066450521', 'name': 'Jan Humplik'}, {'authorId': '2704814', 'name': 'Brian Ichter'}, {'authorId': '9961095', 'name': 'Ted Xiao'}, {'authorId': '2153917744', 'name': 'Peng Xu'}, {'authorId': '38591293', 'name': 'Andy Zeng'}, {'authorId': '28292148', 'name': 'Tingnan Zhang'}, {'authorId': '2801204', 'name': 'N. Heess'}, {'authorId': '1779671', 'name': 'Dorsa Sadigh'}, {'authorId': '1739176520', 'name': 'Jie Tan'}, {'authorId': '2109481', 'name': 'Yuval Tassa'}, {'authorId': '144956443', 'name': 'F. Xia'}]","['Nicolas Heess, Dorsa Sadigh, Jie Tan,', 'Google']",['United States'],2023-06,"['industrial', 'industrial']"
2306.08871,Yanshen Sun,"Yanshen Sun, Jianfeng He, Shuo Lei, Limeng Cui, Chang-Tien Lu",Med-MMHL: A Multi-Modal Dataset for Detecting Human- and LLM-Generated Misinformation in the Medical Domain,,,,,cs.SI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The pervasive influence of misinformation has far-reaching and detrimental effects on both individuals and society. The COVID-19 pandemic has witnessed an alarming surge in the dissemination of medical misinformation. However, existing datasets pertaining to misinformation predominantly focus on textual information, neglecting the inclusion of visual elements, and tend to center solely on COVID-19-related misinformation, overlooking misinformation surrounding other diseases. Furthermore, the potential of Large Language Models (LLMs), such as the ChatGPT developed in late 2022, in generating misinformation has been overlooked in previous works. To overcome these limitations, we present Med-MMHL, a novel multi-modal misinformation detection dataset in a general medical domain encompassing multiple diseases. Med-MMHL not only incorporates human-generated misinformation but also includes misinformation generated by LLMs like ChatGPT. Our dataset aims to facilitate comprehensive research and development of methodologies for detecting misinformation across diverse diseases and various scenarios, including human and LLM-generated misinformation detection at the sentence, document, and multi-modal levels. To access our dataset and code, visit our GitHub repository: \url{https://github.com/styxsys0927/Med-MMHL}. ","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 05:59:11 GMT'}]",2023-06-16,"[['Sun', 'Yanshen', ''], ['He', 'Jianfeng', ''], ['Lei', 'Shuo', ''], ['Cui', 'Limeng', ''], ['Lu', 'Chang-Tien', '']]",1,1,2023-06-15,1,5,2,1,0,1,141341edd9dae0f3d8c3c0555cb2fe7624fc9053,259164947.0,https://www.semanticscholar.org/paper/141341edd9dae0f3d8c3c0555cb2fe7624fc9053,arXiv.org,2023.0,44.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1966961', 'name': 'Yanshen Sun'}, {'authorId': '47752577', 'name': 'Jianfeng He'}, {'authorId': '3433489', 'name': 'Shuo Lei'}, {'authorId': '3122003', 'name': 'Limeng Cui'}, {'authorId': '2110142089', 'name': 'Chang-Tien Lu'}]","['Virginia Tech', ""Conference acronym 'XX, June 03-05, 2018, Woodstock, NY"", 'Palo Alto Research Center']",['United States'],2023-06,"['industrial', 'industrial', 'industrial']"
2306.09313,Rohit Paturi,"Rohit Paturi, Sundararajan Srinivasan, Xiang Li",Lexical Speaker Error Correction: Leveraging Language Models for Speaker Diarization Error Correction,Accepted at INTERSPEECH 2023,,,,eess.AS cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Speaker diarization (SD) is typically used with an automatic speech recognition (ASR) system to ascribe speaker labels to recognized words. The conventional approach reconciles outputs from independently optimized ASR and SD systems, where the SD system typically uses only acoustic information to identify the speakers in the audio stream. This approach can lead to speaker errors especially around speaker turns and regions of speaker overlap. In this paper, we propose a novel second-pass speaker error correction system using lexical information, leveraging the power of modern language models (LMs). Our experiments across multiple telephony datasets show that our approach is both effective and robust. Training and tuning only on the Fisher dataset, this error correction approach leads to relative word-level diarization error rate (WDER) reductions of 15-30% on three telephony datasets: RT03-CTS, Callhome American English and held-out portions of Fisher. ","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 17:47:41 GMT'}]",2023-06-20,"[['Paturi', 'Rohit', ''], ['Srinivasan', 'Sundararajan', ''], ['Li', 'Xiang', '']]",0,0,2023-06-15,1,3,4,0,0,0,99da5ada1b6244f2caafad55e8f61fe8e6dc1e49,259171762.0,https://www.semanticscholar.org/paper/99da5ada1b6244f2caafad55e8f61fe8e6dc1e49,Interspeech,2023.0,34.0,4.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40561966', 'name': 'Rohit Paturi'}, {'authorId': '2369352', 'name': 'S. Srinivasan'}, {'authorId': '2144440743', 'name': 'Xiang Li'}]",['Amazon'],['United States'],2023-06,['industrial']
2306.09983,Daniel Paleka,"Lukas Fluri, Daniel Paleka, Florian Tram\`er",Evaluating Superhuman Models with Consistency Checks,"31 pages, 15 figures. Under review. Code and data are available at
  https://github.com/ethz-spylab/superhuman-ai-consistency",,,,cs.LG cs.AI cs.CR stat.ML,http://creativecommons.org/licenses/by/4.0/,"  If machine learning models were to achieve superhuman abilities at various reasoning or decision-making tasks, how would we go about evaluating such models, given that humans would necessarily be poor proxies for ground truth? In this paper, we propose a framework for evaluating superhuman models via consistency checks. Our premise is that while the correctness of superhuman decisions may be impossible to evaluate, we can still surface mistakes if the model's decisions fail to satisfy certain logical, human-interpretable rules. We instantiate our framework on three tasks where correctness of decisions is hard to evaluate due to either superhuman model abilities, or to otherwise missing ground truth: evaluating chess positions, forecasting future events, and making legal judgments. We show that regardless of a model's (possibly superhuman) performance on these tasks, we can discover logical inconsistencies in decision making. For example: a chess engine assigning opposing valuations to semantically identical boards; GPT-4 forecasting that sports records will evolve non-monotonically over time; or an AI judge assigning bail to a defendant only after we add a felony to their criminal record. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 17:26:38 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Jun 2023 18:03:48 GMT'}]",2023-06-21,"[['Fluri', 'Lukas', ''], ['Paleka', 'Daniel', ''], ['Tramèr', 'Florian', '']]",0,1,2023-06-16,2,3,4,1,0,1,c18c544adc6c3f78843ac0d25473b9b94bc426b6,259188084.0,https://www.semanticscholar.org/paper/c18c544adc6c3f78843ac0d25473b9b94bc426b6,arXiv.org,2023.0,95.0,7.0,2.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2220217917', 'name': 'Lukas Fluri'}, {'authorId': '2175557610', 'name': 'Daniel Paleka'}, {'authorId': '2444919', 'name': 'Florian Tramèr'}]",['ETH Zurich'],['Switzerland'],2023-06,['industrial']
2306.10067,Kevin Yager,Kevin G. Yager,Domain-specific ChatBots for Science using Embeddings,"14 pages, 6 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have emerged as powerful machine-learning systems capable of handling a myriad of tasks. Tuned versions of these systems have been turned into chatbots that can respond to user queries on a vast diversity of topics, providing informative and creative replies. However, their application to physical science research remains limited owing to their incomplete knowledge in these areas, contrasted with the needs of rigor and sourcing in science domains. Here, we demonstrate how existing methods and software tools can be easily combined to yield a domain-specific chatbot. The system ingests scientific documents in existing formats, and uses text embedding lookup to provide the LLM with domain-specific contextual information when composing its reply. We similarly demonstrate that existing image embedding methods can be used for search and retrieval across publication figures. These results confirm that LLMs are already suitable for use by physical scientists in accelerating their research efforts. ","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 15:26:20 GMT'}, {'version': 'v2', 'created': 'Thu, 24 Aug 2023 20:24:13 GMT'}]",2023-08-28,"[['Yager', 'Kevin G.', '']]",0,0,2023-06-15,2,1,2,0,0,0,d39cb3de408a4efabae396c7375d287e7235f6b0,259204080.0,https://www.semanticscholar.org/paper/d39cb3de408a4efabae396c7375d287e7235f6b0,Digital Discovery,2023.0,69.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2065832745', 'name': 'Kevin G. Yager'}]",['Center for Functional Nanomaterials'],['United States'],2023-06,['industrial']
2306.10196,Tristan Vanderbruggen,"Tristan Vanderbruggen, Chunhua Liao, Peter Pirkelbauer, Pei-Hung Lin",Structured Thoughts Automaton: First Formalized Execution Model for Auto-Regressive Language Models,Submitted to CGO-24,,,,cs.CL cs.AI cs.FL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In recent months, Language Models (LMs) have become a part of daily discourse, with focus on OpenAI and the potential of Artificial General Intelligence (AGI). Furthermore, the leaking of LLama's weights to the public has led to an influx of innovations demonstrating the impressive capabilities of generative LMs. While we believe that AGI is still a distant goal, we recognize the potential of LMs in solving tasks such as searching complex documents, compiling reports with basic analysis, and providing assistance in problem-solving. In this paper, we propose formalizing the execution model of language models. We investigate current execution models, to find that this formalism has received little attention, and present our contribution: the first formalized execution model for LMs. We introduce a new algorithm for sampling the predictions of LMs, which we use to build a reliable and inspectable execution model. We introduce a low-level language to write ""cognitive program"" for this execution model. We hope to shed light on the need for execution models for LMs and encourage further research in this area. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 22:04:50 GMT'}]",2023-06-21,"[['Vanderbruggen', 'Tristan', ''], ['Liao', 'Chunhua', ''], ['Pirkelbauer', 'Peter', ''], ['Lin', 'Pei-Hung', '']]",0,0,2023-06-16,1,4,4,1,1,0,cc1723cf8a6cecb2295360ba01a01da90452403e,259202713.0,https://www.semanticscholar.org/paper/cc1723cf8a6cecb2295360ba01a01da90452403e,arXiv.org,2023.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1922222', 'name': 'T. Vanderbruggen'}, {'authorId': '7604095', 'name': 'C. Liao'}, {'authorId': '1707965', 'name': 'P. Pirkelbauer'}, {'authorId': '1905021', 'name': 'Pei-Hung Lin'}]",['Lawrence Livermore National Laboratory'],['United States'],2023-06,['industrial']
2306.10354,Yunlong Tang,"Yunlong Tang, Jinrui Zhang, Xiangchen Wang, Teng Wang, Feng Zheng",LLMVA-GEBC: Large Language Model with Video Adapter for Generic Event Boundary Captioning,"Winner solution to Generic Event Boundary Captioning task in LOVEU
  Challenge (CVPR 2023 workshop)",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our winning entry for the CVPR 2023 Generic Event Boundary Captioning (GEBC) competition is detailed in this paper. Unlike conventional video captioning tasks, GEBC demands that the captioning model possess an understanding of immediate changes in status around the designated video boundary, making it a difficult task. This paper proposes an effective model LLMVA-GEBC (Large Language Model with Video Adapter for Generic Event Boundary Captioning): (1) We utilize a pretrained LLM for generating human-like captions with high quality. (2) To adapt the model to the GEBC task, we take the video Q-former as an adapter and train it with the frozen visual feature extractors and LLM. Our proposed method achieved a 76.14 score on the test set and won the first place in the challenge. Our code is available at https://github.com/zjr2000/LLMVA-GEBC . ","[{'version': 'v1', 'created': 'Sat, 17 Jun 2023 13:55:54 GMT'}]",2023-06-21,"[['Tang', 'Yunlong', ''], ['Zhang', 'Jinrui', ''], ['Wang', 'Xiangchen', ''], ['Wang', 'Teng', ''], ['Zheng', 'Feng', '']]",0,0,2023-06-17,1,5,2,0,0,0,454850fcb311faf1de3f4028a312cfeb781857b4,259202917.0,https://www.semanticscholar.org/paper/454850fcb311faf1de3f4028a312cfeb781857b4,arXiv.org,2023.0,13.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2119309562', 'name': 'Yunlong Tang'}, {'authorId': '2175053912', 'name': 'Jinrui Zhang'}, {'authorId': '2220662041', 'name': 'Xiangchen Wang'}, {'authorId': '2116581959', 'name': 'Teng Wang'}, {'authorId': '2146483847', 'name': 'Feng Zheng'}]","['Xiangchen Wang, Teng Wang, Feng Zheng SUSTech VIP Lab']",,2023-06,['industrial']
2306.10985,Julien Perez,Julien Perez and Denys Proux and Claude Roux and Michael Niemaz,"LARG, Language-based Automatic Reward and Goal Generation",,,,,cs.CL cs.LG cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Goal-conditioned and Multi-Task Reinforcement Learning (GCRL and MTRL) address numerous problems related to robot learning, including locomotion, navigation, and manipulation scenarios. Recent works focusing on language-defined robotic manipulation tasks have led to the tedious production of massive human annotations to create dataset of textual descriptions associated with trajectories. To leverage reinforcement learning with text-based task descriptions, we need to produce reward functions associated with individual tasks in a scalable manner. In this paper, we leverage recent capabilities of Large Language Models (LLMs) and introduce \larg, Language-based Automatic Reward and Goal Generation, an approach that converts a text-based task description into its corresponding reward and goal-generation functions We evaluate our approach for robotic manipulation and demonstrate its ability to train and execute policies in a scalable manner, without the need for handcrafted reward functions. ","[{'version': 'v1', 'created': 'Mon, 19 Jun 2023 14:52:39 GMT'}]",2023-06-21,"[['Perez', 'Julien', ''], ['Proux', 'Denys', ''], ['Roux', 'Claude', ''], ['Niemaz', 'Michael', '']]",0,0,2023-06-19,1,4,3,0,0,0,5d35d6cbc406a379e8b043eb135b6752df5c45f1,259203128.0,https://www.semanticscholar.org/paper/5d35d6cbc406a379e8b043eb135b6752df5c45f1,arXiv.org,2023.0,30.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '121436310', 'name': 'Julien Perez'}, {'authorId': '2220287228', 'name': 'Denys Proux'}, {'authorId': '2069598214', 'name': 'Claude Roux'}, {'authorId': '69408539', 'name': 'Michael Niemaz'}]",['NAVER'],['France'],2023-06,['industrial']
2306.11644,Suriya Gunasekar,"Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C\'esar Teodoro Mendes,
  Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo
  de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin
  Wang, S\'ebastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee,
  Yuanzhi Li",Textbooks Are All You Need,"26 pages; changed color scheme of plot. fixed minor typos and added
  couple clarifications",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook quality"" data from the web (6B tokens) and synthetically generated textbooks and exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains pass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays surprising emergent properties compared to phi-1-base, our model before our finetuning stage on a dataset of coding exercises, and phi-1-small, a smaller model with 350M parameters trained with the same pipeline as phi-1 that still achieves 45% on HumanEval. ","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 16:14:25 GMT'}, {'version': 'v2', 'created': 'Mon, 2 Oct 2023 06:12:30 GMT'}]",2023-10-03,"[['Gunasekar', 'Suriya', ''], ['Zhang', 'Yi', ''], ['Aneja', 'Jyoti', ''], ['Mendes', 'Caio César Teodoro', ''], ['Del Giorno', 'Allie', ''], ['Gopi', 'Sivakanth', ''], ['Javaheripi', 'Mojan', ''], ['Kauffmann', 'Piero', ''], ['de Rosa', 'Gustavo', ''], ['Saarikivi', 'Olli', ''], ['Salim', 'Adil', ''], ['Shah', 'Shital', ''], ['Behl', 'Harkirat Singh', ''], ['Wang', 'Xin', ''], ['Bubeck', 'Sébastien', ''], ['Eldan', 'Ronen', ''], ['Kalai', 'Adam Tauman', ''], ['Lee', 'Yin Tat', ''], ['Li', 'Yuanzhi', '']]",0,1,2023-06-20,2,19,3,1,0,1,2922768fd451ecdb45f48c1a83eb57f54a91221b,259203998.0,https://www.semanticscholar.org/paper/2922768fd451ecdb45f48c1a83eb57f54a91221b,arXiv.org,2023.0,41.0,41.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3317356', 'name': 'Suriya Gunasekar'}, {'authorId': '2153910714', 'name': 'Yi Zhang'}, {'authorId': '29956361', 'name': 'J. Aneja'}, {'authorId': '2157424631', 'name': 'C. C. T. Mendes'}, {'authorId': '50672277', 'name': 'Allison Del Giorno'}, {'authorId': '40528805', 'name': 'Sivakanth Gopi'}, {'authorId': '51900416', 'name': 'Mojan Javaheripi'}, {'authorId': '2160340819', 'name': 'Piero C. Kauffmann'}, {'authorId': '144977605', 'name': 'Gustavo de Rosa'}, {'authorId': '2347792', 'name': 'Olli Saarikivi'}, {'authorId': '24929535', 'name': 'A. Salim'}, {'authorId': '47973411', 'name': 'S. Shah'}, {'authorId': '145560551', 'name': 'Harkirat Singh Behl'}, {'authorId': '2153689937', 'name': 'Xin Wang'}, {'authorId': '121645690', 'name': 'Sébastien Bubeck'}, {'authorId': '2315830', 'name': 'Ronen Eldan'}, {'authorId': '2186481', 'name': 'A. Kalai'}, {'authorId': '2109308930', 'name': 'Y. Lee'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}]",['Microsoft'],['India'],2023-06,['industrial']
2306.11748,Louis Rosenberg PhD,Louis Rosenberg,The Manipulation Problem: Conversational AI as a Threat to Epistemic Agency,"5 pages, 2 figures",,,,cs.HC cs.AI cs.CY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The technology of Conversational AI has made significant advancements over the last eighteen months. As a consequence, conversational agents are likely to be deployed in the near future that are designed to pursue targeted influence objectives. Sometimes referred to as the ""AI Manipulation Problem,"" the emerging risk is that consumers will unwittingly engage in real-time dialog with predatory AI agents that can skillfully persuade them to buy particular products, believe particular pieces of misinformation, or fool them into revealing sensitive personal data. For many users, current systems like ChatGPT and LaMDA feel safe because they are primarily text-based, but the industry is already shifting towards real-time voice and photorealistic digital personas that look, move, and express like real people. This will enable the deployment of agenda-driven Virtual Spokespeople (VSPs) that will be highly persuasive through real-time adaptive influence. This paper explores the manipulative tactics that are likely to be deployed through conversational AI agents, the unique threats such agents pose to the epistemic agency of human users, and the emerging need for policymakers to protect against the most likely predatory practices. ","[{'version': 'v1', 'created': 'Mon, 19 Jun 2023 04:09:16 GMT'}]",2023-06-22,"[['Rosenberg', 'Louis', '']]",1,1,2023-06-19,1,1,3,2,0,2,e5e47c368317b903908e0b326bb6b785c458ce2c,259179989.0,https://www.semanticscholar.org/paper/e5e47c368317b903908e0b326bb6b785c458ce2c,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","[{'authorId': '35701584', 'name': 'Louis B. Rosenberg'}]",['Unanimous AI'],,2023-06,['industrial']
2306.11932,Christopher Small,"Christopher T. Small, Ivan Vendrov, Esin Durmus, Hadjar Homaei,
  Elizabeth Barry, Julien Cornebise, Ted Suzman, Deep Ganguli, and Colin Megill",Opportunities and Risks of LLMs for Scalable Deliberation with Polis,"31 pages (main body; 45 with Bibliography and Appendix), 6 figures",,,,cs.SI cs.CL cs.CY cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Polis is a platform that leverages machine intelligence to scale up deliberative processes. In this paper, we explore the opportunities and risks associated with applying Large Language Models (LLMs) towards challenges with facilitating, moderating and summarizing the results of Polis engagements. In particular, we demonstrate with pilot experiments using Anthropic's Claude that LLMs can indeed augment human intelligence to help more efficiently run Polis conversations. In particular, we find that summarization capabilities enable categorically new methods with immense promise to empower the public in collective meaning-making exercises. And notably, LLM context limitations have a significant impact on insight and quality of these results.   However, these opportunities come with risks. We discuss some of these risks, as well as principles and techniques for characterizing and mitigating them, and the implications for other deliberative or political systems that may employ LLMs. Finally, we conclude with several open future research directions for augmenting tools like Polis with LLMs. ","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 22:52:51 GMT'}]",2023-06-22,"[['Small', 'Christopher T.', ''], ['Vendrov', 'Ivan', ''], ['Durmus', 'Esin', ''], ['Homaei', 'Hadjar', ''], ['Barry', 'Elizabeth', ''], ['Cornebise', 'Julien', ''], ['Suzman', 'Ted', ''], ['Ganguli', 'Deep', ''], ['Megill', 'Colin', '']]",0,0,2023-06-20,1,9,4,2,0,2,ede87ffc69414d3ca86c5e57b96757d0245eab82,259211996.0,https://www.semanticscholar.org/paper/ede87ffc69414d3ca86c5e57b96757d0245eab82,arXiv.org,2023.0,87.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2191897342', 'name': 'Christopher T. Small'}, {'authorId': '2210865', 'name': 'Ivan Vendrov'}, {'authorId': '41152329', 'name': 'Esin Durmus'}, {'authorId': '24370487', 'name': 'Hadjar Homaei'}, {'authorId': '2191896099', 'name': 'Elizabeth Barry'}, {'authorId': '46875891', 'name': 'Julien Cornebise'}, {'authorId': '2220346828', 'name': 'Ted Suzman'}, {'authorId': '2081806483', 'name': 'Deep Ganguli'}, {'authorId': '41151584', 'name': 'Colin Megill'}]","['Anthropic', 'The Computational Democracy Project']",['United States'],2023-06,"['industrial', 'industrial']"
2306.12146,Robin Chan,"Robin Chan, Afra Amini, Mennatallah El-Assady",Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals,"7 pages, Accepted at ACL 2023: System Demonstrations",,,,cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a human-in-the-loop dashboard tailored to diagnosing potential spurious features that NLI models rely on for predictions. The dashboard enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions. Additionally, users can receive feedback from a trained NLI model on how challenging the newly created example is and make refinements based on the feedback. Through our investigation, we discover several categories of spurious correlations that impact the reasoning of NLI models, which we group into three categories: Semantic Relevance, Logical Fallacies, and Bias. Based on our findings, we identify and describe various research opportunities, including diversifying training data and assessing NLI models' robustness by creating adversarial test suites. ","[{'version': 'v1', 'created': 'Wed, 21 Jun 2023 09:50:48 GMT'}]",2023-06-22,"[['Chan', 'Robin', ''], ['Amini', 'Afra', ''], ['El-Assady', 'Mennatallah', '']]",0,1,2023-06-21,1,3,2,1,0,1,7cf2a34fb971441dcc77c905fe2fe1741ef1837f,259211856.0,https://www.semanticscholar.org/paper/7cf2a34fb971441dcc77c905fe2fe1741ef1837f,Annual Meeting of the Association for Computational Linguistics,2023.0,18.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '4253866', 'name': 'Robin Chan'}, {'authorId': '1820796225', 'name': 'Afra Amini'}, {'authorId': '1401917601', 'name': 'Mennatallah El-Assady'}]",['Qu & Co. (Netherlands)'],['Netherlands'],2023-06,['industrial']
2306.12925,Paul Rubenstein,"Paul K. Rubenstein, Chulayuth Asawaroengchai, Duc Dung Nguyen, Ankur
  Bapna, Zal\'an Borsos, F\'elix de Chaumont Quitry, Peter Chen, Dalia El
  Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, Dirk Padfield, James
  Qin, Danny Rozenberg, Tara Sainath, Johan Schalkwyk, Matt Sharifi, Michelle
  Tadmor Ramanovich, Marco Tagliasacchi, Alexandru Tudor, Mihajlo
  Velimirovi\'c, Damien Vincent, Jiahui Yu, Yongqiang Wang, Vicky Zayats, Neil
  Zeghidour, Yu Zhang, Zhishuai Zhang, Lukas Zilka, Christian Frank",AudioPaLM: A Large Language Model That Can Speak and Listen,Technical report,,,,cs.CL cs.AI cs.SD eess.AS stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce AudioPaLM, a large language model for speech understanding and generation. AudioPaLM fuses text-based and speech-based language models, PaLM-2 [Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unified multimodal architecture that can process and generate text and speech with applications including speech recognition and speech-to-speech translation. AudioPaLM inherits the capability to preserve paralinguistic information such as speaker identity and intonation from AudioLM and the linguistic knowledge present only in text large language models such as PaLM-2. We demonstrate that initializing AudioPaLM with the weights of a text-only large language model improves speech processing, successfully leveraging the larger quantity of text training data used in pretraining to assist with the speech tasks. The resulting model significantly outperforms existing systems for speech translation tasks and has the ability to perform zero-shot speech-to-text translation for many languages for which input/target language combinations were not seen in training. AudioPaLM also demonstrates features of audio language models, such as transferring a voice across languages based on a short spoken prompt. We release examples of our method at https://google-research.github.io/seanet/audiopalm/examples ","[{'version': 'v1', 'created': 'Thu, 22 Jun 2023 14:37:54 GMT'}]",2023-06-23,"[['Rubenstein', 'Paul K.', ''], ['Asawaroengchai', 'Chulayuth', ''], ['Nguyen', 'Duc Dung', ''], ['Bapna', 'Ankur', ''], ['Borsos', 'Zalán', ''], ['Quitry', 'Félix de Chaumont', ''], ['Chen', 'Peter', ''], ['Badawy', 'Dalia El', ''], ['Han', 'Wei', ''], ['Kharitonov', 'Eugene', ''], ['Muckenhirn', 'Hannah', ''], ['Padfield', 'Dirk', ''], ['Qin', 'James', ''], ['Rozenberg', 'Danny', ''], ['Sainath', 'Tara', ''], ['Schalkwyk', 'Johan', ''], ['Sharifi', 'Matt', ''], ['Ramanovich', 'Michelle Tadmor', ''], ['Tagliasacchi', 'Marco', ''], ['Tudor', 'Alexandru', ''], ['Velimirović', 'Mihajlo', ''], ['Vincent', 'Damien', ''], ['Yu', 'Jiahui', ''], ['Wang', 'Yongqiang', ''], ['Zayats', 'Vicky', ''], ['Zeghidour', 'Neil', ''], ['Zhang', 'Yu', ''], ['Zhang', 'Zhishuai', ''], ['Zilka', 'Lukas', ''], ['Frank', 'Christian', '']]",0,0,2023-06-22,1,30,5,1,0,1,3efb81de24eb88017d6dbcf22cb4215084223fd8,259224345.0,https://www.semanticscholar.org/paper/3efb81de24eb88017d6dbcf22cb4215084223fd8,arXiv.org,2023.0,79.0,41.0,2.0,True,"['Computer Science', 'Engineering', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48159426', 'name': 'Paul K. Rubenstein'}, {'authorId': '50844587', 'name': 'Chulayuth Asawaroengchai'}, {'authorId': '2149981', 'name': 'D. Nguyen'}, {'authorId': '12295226', 'name': 'Ankur Bapna'}, {'authorId': '144494941', 'name': 'Zalán Borsos'}, {'authorId': '123721125', 'name': 'F. D. C. Quitry'}, {'authorId': '2120245658', 'name': 'Peter Chen'}, {'authorId': '2489672', 'name': 'Dalia El Badawy'}, {'authorId': '72549949', 'name': 'Wei Han'}, {'authorId': '144875326', 'name': 'E. Kharitonov'}, {'authorId': '4563878', 'name': 'Hannah Muckenhirn'}, {'authorId': '1745683', 'name': 'D. Padfield'}, {'authorId': '47901308', 'name': 'James Qin'}, {'authorId': '18439314', 'name': 'Daniel Rozenberg'}, {'authorId': '1784851', 'name': 'Tara N. Sainath'}, {'authorId': '1698491', 'name': 'J. Schalkwyk'}, {'authorId': '2112139582', 'name': 'Matthew Sharifi'}, {'authorId': '4122989', 'name': 'Michelle D. Tadmor'}, {'authorId': '2220407386', 'name': 'Ramanovich'}, {'authorId': '1749128', 'name': 'M. Tagliasacchi'}, {'authorId': '50205505', 'name': 'A. Tudor'}, {'authorId': '2220407384', 'name': ""Mihajlo Velimirovi'c""}, {'authorId': '2055932105', 'name': 'Damien Vincent'}, {'authorId': '150167366', 'name': 'Jiahui Yu'}, {'authorId': '2108220460', 'name': 'Yongqiang Wang'}, {'authorId': '143689491', 'name': 'V. Zayats'}, {'authorId': '3404556', 'name': 'Neil Zeghidour'}, {'authorId': '2153632494', 'name': 'Yu Zhang'}, {'authorId': '2144459658', 'name': 'Zhishuai Zhang'}, {'authorId': '1780245', 'name': 'Lukás Zilka'}, {'authorId': '152871063', 'name': 'C. Frank'}]",['FELIX Laboratory'],['Netherlands'],2023-06,['industrial']
2306.12929,Yelysei Bondarenko,"Yelysei Bondarenko, Markus Nagel, Tijmen Blankevoort",Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing,,,,,cs.LG cs.AI cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Transformer models have been widely adopted in various domains over the last years, and especially large language models have advanced the field of AI significantly. Due to their size, the capability of these networks has increased tremendously, but this has come at the cost of a significant increase in necessary compute. Quantization is one of the most effective ways to reduce the computational time and memory consumption of neural networks. Many studies have shown, however, that modern transformer models tend to learn strong outliers in their activations, making them difficult to quantize. To retain acceptable performance, the existence of these outliers requires activations to be in higher bitwidth or the use of different numeric formats, extra fine-tuning, or other workarounds. We show that strong outliers are related to very specific behavior of attention heads that try to learn a ""no-op"" or just a partial update of the residual. To achieve the exact zeros needed in the attention matrix for a no-update, the input to the softmax is pushed to be larger and larger during training, causing outliers in other parts of the network. Based on these observations, we propose two simple (independent) modifications to the attention mechanism - clipped softmax and gated attention. We empirically show that models pre-trained using our methods learn significantly smaller outliers while maintaining and sometimes even improving the floating-point task performance. This enables us to quantize transformers to full INT8 quantization of the activations without any additional effort. We demonstrate the effectiveness of our methods on both language models (BERT, OPT) and vision transformers. ","[{'version': 'v1', 'created': 'Thu, 22 Jun 2023 14:39:04 GMT'}]",2023-06-23,"[['Bondarenko', 'Yelysei', ''], ['Nagel', 'Markus', ''], ['Blankevoort', 'Tijmen', '']]",0,0,2023-06-22,1,3,4,1,1,0,d193675b92fbfbf22ed82fda35cd2e73587e33bd,259224568.0,https://www.semanticscholar.org/paper/d193675b92fbfbf22ed82fda35cd2e73587e33bd,arXiv.org,2023.0,80.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112207572', 'name': 'Yelysei Bondarenko'}, {'authorId': '41229153', 'name': 'Markus Nagel'}, {'authorId': '83133279', 'name': 'Tijmen Blankevoort'}]","['Qualcomm', 'Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc. 37th Conference on Neural Information Processing Systems (NeurIPS 2023).']",['Netherlands'],2023-06,"['industrial', 'industrial']"
2306.13298,Didar Zowghi,"Muneera Bano, Didar Zowghi, Jon Whittle",Exploring Qualitative Research Using LLMs,,,,,cs.SE cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The advent of AI driven large language models (LLMs) have stirred discussions about their role in qualitative research. Some view these as tools to enrich human understanding, while others perceive them as threats to the core values of the discipline. This study aimed to compare and contrast the comprehension capabilities of humans and LLMs. We conducted an experiment with small sample of Alexa app reviews, initially classified by a human analyst. LLMs were then asked to classify these reviews and provide the reasoning behind each classification. We compared the results with human classification and reasoning. The research indicated a significant alignment between human and ChatGPT 3.5 classifications in one third of cases, and a slightly lower alignment with GPT4 in over a quarter of cases. The two AI models showed a higher alignment, observed in more than half of the instances. However, a consensus across all three methods was seen only in about one fifth of the classifications. In the comparison of human and LLMs reasoning, it appears that human analysts lean heavily on their individual experiences. As expected, LLMs, on the other hand, base their reasoning on the specific word choices found in app reviews and the functional components of the app itself. Our results highlight the potential for effective human LLM collaboration, suggesting a synergistic rather than competitive relationship. Researchers must continuously evaluate LLMs role in their work, thereby fostering a future where AI and humans jointly enrich qualitative research. ","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 05:21:36 GMT'}]",2023-06-26,"[['Bano', 'Muneera', ''], ['Zowghi', 'Didar', ''], ['Whittle', 'Jon', '']]",1,1,2023-06-23,1,3,2,2,0,2,bbfcc31b79110c28047b2ba03ee55335acc8e47c,259243589.0,https://www.semanticscholar.org/paper/bbfcc31b79110c28047b2ba03ee55335acc8e47c,arXiv.org,2023.0,48.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2514873', 'name': 'Muneera Bano'}, {'authorId': '1740931', 'name': 'D. Zowghi'}, {'authorId': '2193085367', 'name': 'Jon Whittle'}]",['Data61'],['Australia'],2023-06,['industrial']
2306.13671,Xiao Zhan,"Xiao Zhan, Yifan Xu, Stefan Sarkadi",Deceptive AI Ecosystems: The Case of ChatGPT,"6 pages, To appear in the Proceedings of the 2023 ACM conference on
  Conversational User Interfaces (CUI 23)",,10.1145/3571884.3603754,,cs.CY cs.AI cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT, an AI chatbot, has gained popularity for its capability in generating human-like responses. However, this feature carries several risks, most notably due to its deceptive behaviour such as offering users misleading or fabricated information that could further cause ethical issues. To better understand the impact of ChatGPT on our social, cultural, economic, and political interactions, it is crucial to investigate how ChatGPT operates in the real world where various societal pressures influence its development and deployment. This paper emphasizes the need to study ChatGPT ""in the wild"", as part of the ecosystem it is embedded in, with a strong focus on user involvement. We examine the ethical challenges stemming from ChatGPT's deceptive human-like interactions and propose a roadmap for developing more transparent and trustworthy chatbots. Central to our approach is the importance of proactive risk assessment and user participation in shaping the future of chatbot technology. ","[{'version': 'v1', 'created': 'Sun, 18 Jun 2023 10:36:19 GMT'}]",2023-06-27,"[['Zhan', 'Xiao', ''], ['Xu', 'Yifan', ''], ['Sarkadi', 'Stefan', '']]",1,1,2023-06-18,1,3,3,1,0,1,2910b51022362c3d0f207c09972da737fac47f9a,259251738.0,https://www.semanticscholar.org/paper/2910b51022362c3d0f207c09972da737fac47f9a,International Conference on Conversational User Interfaces,2023.0,81.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2089532795', 'name': 'Xiao Zhan'}, {'authorId': '2138973537', 'name': 'Yifan Xu'}, {'authorId': '51055720', 'name': 'Ş. Sarkadi'}]",['Saudi Aramco (United States)'],['United States'],2023-06,['industrial']
2306.14096,Yinyu Lan,"Yinyu Lan, Yanru Wu, Wang Xu, Weiqiang Feng, Youhao Zhang",Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models,"Accepted by (FinLLM 2023)@IJCAI 2023,
  https://finllm.github.io/workshop/#/fcb",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity-level fine-grained sentiment analysis in the financial domain is a crucial subtask of sentiment analysis and currently faces numerous challenges. The primary challenge stems from the lack of high-quality and large-scale annotated corpora specifically designed for financial text sentiment analysis, which in turn limits the availability of data necessary for developing effective text processing techniques. Recent advancements in large language models (LLMs) have yielded remarkable performance in natural language processing tasks, primarily centered around language pattern matching. In this paper, we propose a novel and extensive Chinese fine-grained financial sentiment analysis dataset, FinChina SA, for enterprise early warning. We thoroughly evaluate and experiment with well-known existing open-source LLMs using our dataset. We firmly believe that our dataset will serve as a valuable resource to advance the exploration of real-world financial sentiment analysis tasks, which should be the focus of future research. The FinChina SA dataset is publicly available at https://github.com/YerayL/FinChina-SA ","[{'version': 'v1', 'created': 'Sun, 25 Jun 2023 02:24:30 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Jul 2023 05:14:39 GMT'}, {'version': 'v3', 'created': 'Fri, 21 Jul 2023 08:57:38 GMT'}, {'version': 'v4', 'created': 'Mon, 24 Jul 2023 00:58:11 GMT'}, {'version': 'v5', 'created': 'Fri, 15 Sep 2023 08:19:44 GMT'}]",2023-09-18,"[['Lan', 'Yinyu', ''], ['Wu', 'Yanru', ''], ['Xu', 'Wang', ''], ['Feng', 'Weiqiang', ''], ['Zhang', 'Youhao', '']]",0,0,2023-06-25,5,5,2,0,0,0,7991ed80c9309477c1e49f8ad78e97c0704fa74e,259251651.0,https://www.semanticscholar.org/paper/7991ed80c9309477c1e49f8ad78e97c0704fa74e,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2105841076', 'name': 'Yinyu Lan'}, {'authorId': '2216550412', 'name': 'Yanru Wu'}, {'authorId': '2220598146', 'name': 'Wang Xu'}, {'authorId': '2220538178', 'name': 'Weiqiang Feng'}, {'authorId': '13584407', 'name': 'Youhao Zhang'}]",['FinChina AI Research'],['China'],2023-06,['industrial']
2306.14238,Xiang Zhang,"Xiang Zhang, Zichun Zhou, Chen Ming, Yi-Yang Sun",GPT-assisted learning of structure-property relationships by graph neural networks: Application to rare-earth doped phosphors,"12 pages, 4 figures",,,,cond-mat.mtrl-sci,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Applications of machine learning techniques in materials science are often based on two key ingredients, a set of empirical descriptors and a database of a particular material property of interest. The advent of graph neural networks, such as the Crystal Graph Convolutional Neural Network (CGCNN), demonstrates the possibility of directly mapping the relationship between material structures and properties without employing empirical descriptors. Another exciting recent advancement is in large language models such as OpenAI's GPT-4, which demonstrates competency at reading comprehension tasks and holds great promise for accelerating the acquisition of databases on material properties. Here, we utilize the combination of GPT-4 and CGCNN to develop rare-earth doped phosphors for solid-state lighting. GPT-4 is applied to data-mine chemical formulas and emission wavelengths of 264 Eu(II)-doped phosphors from 274 papers. A CGCNN model is trained on the acquired dataset, achieving a test $R^2$ of 0.77. The model is then used to screen over 40,000 inorganic materials to make predictions on the emission wavelengths. We also demonstrate the possibility of leveraging transfer learning to fine-tune a bandgap-predicting CGCNN model towards the prediction of phosphor emission wavelengths. The workflow requires minimal human supervision, little domain knowledge about phosphors, and is generalizable to other material properties. ","[{'version': 'v1', 'created': 'Sun, 25 Jun 2023 13:17:44 GMT'}]",2023-06-27,"[['Zhang', 'Xiang', ''], ['Zhou', 'Zichun', ''], ['Ming', 'Chen', ''], ['Sun', 'Yi-Yang', '']]",0,1,2023-06-25,1,4,1,1,0,1,24a58b1917136d696867071c94c013d7ccd06a12,259252016.0,https://www.semanticscholar.org/paper/24a58b1917136d696867071c94c013d7ccd06a12,,2023.0,56.0,0.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48505793', 'name': 'Xiang Zhang'}, {'authorId': '2220572227', 'name': 'Zichun Zhou'}, {'authorId': '2059272243', 'name': 'Chen Ming'}, {'authorId': '2212322374', 'name': 'Yi Sun'}]",['Shanghai Institute of Ceramics'],['China'],2023-06,['industrial']
2306.14263,Mohamed Amine Ferrag,"Mohamed Amine Ferrag, Mthandazo Ndhlovu, Norbert Tihanyi, Lucas C.
  Cordeiro, Merouane Debbah, Thierry Lestable",Revolutionizing Cyber Threat Detection with Large Language Models,,,,,cs.CR cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Natural Language Processing (NLP) domain is experiencing a revolution due to the capabilities of Pre-trained Large Language Models ( LLMs), fueled by ground-breaking Transformers architecture, resulting into unprecedented advancements. Their exceptional aptitude for assessing probability distributions of text sequences is the primary catalyst for outstanding improvement of both the precision and efficiency of NLP models. This paper introduces for the first time SecurityLLM, a pre-trained language model designed for cybersecurity threats detection. The SecurityLLM model is articulated around two key generative elements: SecurityBERT and FalconLLM. SecurityBERT operates as a cyber threat detection mechanism, while FalconLLM is an incident response and recovery system. To the best of our knowledge, SecurityBERT represents the inaugural application of BERT in cyber threat detection. Despite the unique nature of the input data and features, such as the reduced significance of syntactic structures in content classification, the suitability of BERT for this duty demonstrates unexpected potential, thanks to our pioneering study. We reveal that a simple classification model, created from scratch, and consolidated with LLMs, exceeds the performance of established traditional Machine Learning (ML) and Deep Learning (DL) methods in cyber threat detection, like Convolutional Neural Networks (CNN) or Recurrent Neural Networks (RNN). The experimental analysis, conducted using a collected cybersecurity dataset, proves that our SecurityLLM model can identify fourteen (14) different types of attacks with an overall accuracy of 98% ","[{'version': 'v1', 'created': 'Sun, 25 Jun 2023 15:04:21 GMT'}]",2023-06-27,"[['Ferrag', 'Mohamed Amine', ''], ['Ndhlovu', 'Mthandazo', ''], ['Tihanyi', 'Norbert', ''], ['Cordeiro', 'Lucas C.', ''], ['Debbah', 'Merouane', ''], ['Lestable', 'Thierry', '']]",0,0,2023-06-25,1,6,2,0,0,0,e9ba0c90b199ed83c5cce46a6548e174f8599b97,259251697.0,https://www.semanticscholar.org/paper/e9ba0c90b199ed83c5cce46a6548e174f8599b97,arXiv.org,2023.0,27.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2864573', 'name': 'M. Ferrag'}, {'authorId': '2208105921', 'name': 'Mthandazo Ndhlovu'}, {'authorId': '2752349', 'name': 'Norbert Tihanyi'}, {'authorId': '2163521113', 'name': 'Lucas C. Cordeiro'}, {'authorId': '2065834880', 'name': 'M. Debbah'}, {'authorId': '2266737', 'name': 'T. Lestable'}]","['Merouane Debbah, and Thierry Lestable Technology Innovation Institute, 9639 Masdar City, Abu Dhabi, UAE']",,2023-06,['industrial']
2306.14824,Li Dong,"Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming
  Ma, Furu Wei",Kosmos-2: Grounding Multimodal Large Language Models to the World,20 pages,,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new capabilities of perceiving object descriptions (e.g., bounding boxes) and grounding text to the visual world. Specifically, we represent refer expressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where object descriptions are sequences of location tokens. Together with multimodal corpora, we construct large-scale data of grounded image-text pairs (called GrIT) to train the model. In addition to the existing capabilities of MLLMs (e.g., perceiving general modalities, following instructions, and performing in-context learning), Kosmos-2 integrates the grounding capability into downstream applications. We evaluate Kosmos-2 on a wide range of tasks, including (i) multimodal grounding, such as referring expression comprehension, and phrase grounding, (ii) multimodal referring, such as referring expression generation, (iii) perception-language tasks, and (iv) language understanding and generation. This work lays out the foundation for the development of Embodiment AI and sheds light on the big convergence of language, multimodal perception, action, and world modeling, which is a key step toward artificial general intelligence. Code and pretrained models are available at https://aka.ms/kosmos-2. ","[{'version': 'v1', 'created': 'Mon, 26 Jun 2023 16:32:47 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Jun 2023 09:11:34 GMT'}, {'version': 'v3', 'created': 'Thu, 13 Jul 2023 05:41:34 GMT'}]",2023-07-14,"[['Peng', 'Zhiliang', ''], ['Wang', 'Wenhui', ''], ['Dong', 'Li', ''], ['Hao', 'Yaru', ''], ['Huang', 'Shaohan', ''], ['Ma', 'Shuming', ''], ['Wei', 'Furu', '']]",0,0,2023-06-26,3,7,2,0,0,0,3b6179c293df29e31d31cea46476f104ab6950f2,259262263.0,https://www.semanticscholar.org/paper/3b6179c293df29e31d31cea46476f104ab6950f2,arXiv.org,2023.0,42.0,73.0,11.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2087004998', 'name': 'Zhiliang Peng'}, {'authorId': '51456429', 'name': 'Wenhui Wang'}, {'authorId': '145307652', 'name': 'Li Dong'}, {'authorId': '34128716', 'name': 'Y. Hao'}, {'authorId': '3110003', 'name': 'Shaohan Huang'}, {'authorId': '2118866998', 'name': 'Shuming Ma'}, {'authorId': '49807919', 'name': 'Furu Wei'}]",['Microsoft'],['China'],2023-06,['industrial']
2306.14895,Chunyuan Li,Chunyuan Li,Large Multimodal Models: Notes on CVPR 2023 Tutorial,"27 pages, 24 figures; Tutorial website:
  https://vlp-tutorial.github.io/",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  This tutorial note summarizes the presentation on ``Large Multimodal Models: Towards Building and Surpassing Multimodal GPT-4'', a part of CVPR 2023 tutorial on ``Recent Advances in Vision Foundation Models''. The tutorial consists of three parts. We first introduce the background on recent GPT-like large models for vision-and-language modeling to motivate the research in instruction-tuned large multimodal models (LMMs). As a pre-requisite, we describe the basics of instruction-tuning in large language models, which is further extended to the multimodal space. Lastly, we illustrate how to build the minimum prototype of multimodal GPT-4 like models with the open-source resource, and review the recently emerged topics. ","[{'version': 'v1', 'created': 'Mon, 26 Jun 2023 17:59:31 GMT'}]",2023-06-27,"[['Li', 'Chunyuan', '']]",0,1,2023-06-26,1,1,1,1,0,1,cde934546bbdb19094d8a53cc047d002c827f884,259262448.0,https://www.semanticscholar.org/paper/cde934546bbdb19094d8a53cc047d002c827f884,arXiv.org,2023.0,65.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109737569', 'name': 'Chunyuan Li'}]",['Microsoft'],['United States'],2023-06,['industrial']
2306.14924,Rob Chew,"Robert Chew, John Bollenbacher, Michael Wenger, Jessica Speer, Annice
  Kim",LLM-Assisted Content Analysis: Using Large Language Models to Support Deductive Coding,,,,,cs.CL cs.AI cs.LG stat.AP,http://creativecommons.org/licenses/by/4.0/,"  Deductive coding is a widely used qualitative research method for determining the prevalence of themes across documents. While useful, deductive coding is often burdensome and time consuming since it requires researchers to read, interpret, and reliably categorize a large body of unstructured text documents. Large language models (LLMs), like ChatGPT, are a class of quickly evolving AI tools that can perform a range of natural language processing and reasoning tasks. In this study, we explore the use of LLMs to reduce the time it takes for deductive coding while retaining the flexibility of a traditional content analysis. We outline the proposed approach, called LLM-assisted content analysis (LACA), along with an in-depth case study using GPT-3.5 for LACA on a publicly available deductive coding data set. Additionally, we conduct an empirical benchmark using LACA on 4 publicly available data sets to assess the broader question of how well GPT-3.5 performs across a range of deductive coding tasks. Overall, we find that GPT-3.5 can often perform deductive coding at levels of agreement comparable to human coders. Additionally, we demonstrate that LACA can help refine prompts for deductive coding, identify codes for which an LLM is randomly guessing, and help assess when to use LLMs vs. human coders for deductive coding. We conclude with several implications for future practice of deductive coding and related research methods. ","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 20:57:32 GMT'}]",2023-06-28,"[['Chew', 'Robert', ''], ['Bollenbacher', 'John', ''], ['Wenger', 'Michael', ''], ['Speer', 'Jessica', ''], ['Kim', 'Annice', '']]",1,1,2023-06-23,1,5,4,2,0,2,08154f2b0534c525bad888d6aaa0bb67c8e27861,259262004.0,https://www.semanticscholar.org/paper/08154f2b0534c525bad888d6aaa0bb67c8e27861,arXiv.org,2023.0,49.0,2.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '19227625', 'name': 'Robert F. Chew'}, {'authorId': '38831423', 'name': 'John Bollenbacher'}, {'authorId': '7459748', 'name': 'Michael Wenger'}, {'authorId': '2220631559', 'name': 'Jessica Speer'}, {'authorId': '2080286599', 'name': 'Annice Kim'}]",['RTI International'],['United States'],2023-06,['industrial']
2306.15121,William Godoy,"William F. Godoy, Pedro Valero-Lara, Keita Teranishi, Prasanna
  Balaprakash, Jeffrey S. Vetter",Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation,"Accepted at the Sixteenth International Workshop on Parallel
  Programming Models and Systems Software for High-End Computing (P2S2), 2023
  to be held in conjunction with ICPP 2023: The 52nd International Conference
  on Parallel Processing. 10 pages, 6 figures, 5 tables",,10.1145/3605731.3605886,,cs.AI cs.ET cs.PL,http://creativecommons.org/licenses/by/4.0/,"  We evaluate AI-assisted generative capabilities on fundamental numerical kernels in high-performance computing (HPC), including AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG. We test the generated kernel codes for a variety of language-supported programming models, including (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numba, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). We use the GitHub Copilot capabilities powered by OpenAI Codex available in Visual Studio Code as of April 2023 to generate a vast amount of implementations given simple <kernel> + <programming model> + <optional hints> prompt variants. To quantify and compare the results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. Results suggest that the OpenAI Codex outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general-purpose Python can benefit from adding code keywords, while Julia prompts perform acceptably well for its mature programming models (e.g., Threads and CUDA.jl). We expect for these benchmarks to provide a point of reference for each programming model's community. Overall, understanding the convergence of large language models, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human-computer interactions. ","[{'version': 'v1', 'created': 'Tue, 27 Jun 2023 00:11:31 GMT'}]",2023-09-20,"[['Godoy', 'William F.', ''], ['Valero-Lara', 'Pedro', ''], ['Teranishi', 'Keita', ''], ['Balaprakash', 'Prasanna', ''], ['Vetter', 'Jeffrey S.', '']]",0,0,2023-06-27,1,5,3,1,0,1,9f12bcdf681b6e29439885ed9fcdd649d7202bff,259262310.0,https://www.semanticscholar.org/paper/9f12bcdf681b6e29439885ed9fcdd649d7202bff,ICPP Workshops,2023.0,53.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '39097972', 'name': 'William F. Godoy'}, {'authorId': '1398969746', 'name': 'Pedro Valero-Lara'}, {'authorId': '34465837', 'name': 'K. Teranishi'}, {'authorId': '69372472', 'name': 'Prasanna Balaprakash'}, {'authorId': '7553591', 'name': 'J. Vetter'}]",['Oak Ridge National Laboratory'],['United States'],2023-06,['industrial']
2306.15595,Yuandong Tian,"Shouyuan Chen, Sherman Wong, Liangjian Chen, Yuandong Tian",Extending Context Window of Large Language Models via Positional Interpolation,Fix template issues,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We present Position Interpolation (PI) that extends the context window sizes of RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal fine-tuning (within 1000 steps), while demonstrating strong empirical results on various tasks that require long context, including passkey retrieval, language modeling, and long document summarization from LLaMA 7B to 65B. Meanwhile, the extended model by Position Interpolation preserve quality relatively well on tasks within its original context window. To achieve this goal, Position Interpolation linearly down-scales the input position indices to match the original context window size, rather than extrapolating beyond the trained context length which may lead to catastrophically high attention scores that completely ruin the self-attention mechanism. Our theoretical study shows that the upper bound of interpolation is at least $\sim 600 \times$ smaller than that of extrapolation, further demonstrating its stability. Models extended via Position Interpolation retain its original architecture and can reuse most pre-existing optimization and infrastructure. ","[{'version': 'v1', 'created': 'Tue, 27 Jun 2023 16:26:26 GMT'}, {'version': 'v2', 'created': 'Wed, 28 Jun 2023 04:26:05 GMT'}]",2023-06-29,"[['Chen', 'Shouyuan', ''], ['Wong', 'Sherman', ''], ['Chen', 'Liangjian', ''], ['Tian', 'Yuandong', '']]",0,0,2023-06-27,2,4,3,1,1,0,f5afaccfe90268485a9961c5771ec5e71e9b806c,259262376.0,https://www.semanticscholar.org/paper/f5afaccfe90268485a9961c5771ec5e71e9b806c,arXiv.org,2023.0,48.0,56.0,10.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2107977873', 'name': 'Shouyuan Chen'}, {'authorId': '2125872141', 'name': 'Sherman Wong'}, {'authorId': '49330599', 'name': 'Liangjian Chen'}, {'authorId': '1932187449', 'name': 'Yuandong Tian'}]",['Meta'],['United States'],2023-06,['industrial']
2306.15687,Matthew Le,"Matthew Le, Apoorv Vyas, Bowen Shi, Brian Karrer, Leda Sari, Rashel
  Moritz, Mary Williamson, Vimal Manohar, Yossi Adi, Jay Mahadeokar, Wei-Ning
  Hsu",Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale,,,,,eess.AS cs.CL cs.LG cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale generative models such as GPT and DALL-E have revolutionized natural language processing and computer vision research. These models not only generate high fidelity text or image outputs, but are also generalists which can solve tasks not explicitly taught. In contrast, speech generative models are still primitive in terms of scale and task generalization. In this paper, we present Voicebox, the most versatile text-guided generative model for speech at scale. Voicebox is a non-autoregressive flow-matching model trained to infill speech, given audio context and text, trained on over 50K hours of speech that are neither filtered nor enhanced. Similar to GPT, Voicebox can perform many different tasks through in-context learning, but is more flexible as it can also condition on future context. Voicebox can be used for mono or cross-lingual zero-shot text-to-speech synthesis, noise removal, content editing, style conversion, and diverse sample generation. In particular, Voicebox outperforms the state-of-the-art zero-shot TTS model VALL-E on both intelligibility (5.9% vs 1.9% word error rates) and audio similarity (0.580 vs 0.681) while being up to 20 times faster. See voicebox.metademolab.com for a demo of the model. ","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 16:23:24 GMT'}]",2023-06-29,"[['Le', 'Matthew', ''], ['Vyas', 'Apoorv', ''], ['Shi', 'Bowen', ''], ['Karrer', 'Brian', ''], ['Sari', 'Leda', ''], ['Moritz', 'Rashel', ''], ['Williamson', 'Mary', ''], ['Manohar', 'Vimal', ''], ['Adi', 'Yossi', ''], ['Mahadeokar', 'Jay', ''], ['Hsu', 'Wei-Ning', '']]",0,1,2023-06-23,1,11,4,0,0,0,a9e00c216ce69325a15fd139da0624978e54058a,259275061.0,https://www.semanticscholar.org/paper/a9e00c216ce69325a15fd139da0624978e54058a,arXiv.org,2023.0,81.0,24.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '123542315', 'name': 'Matt Le'}, {'authorId': '2992087', 'name': 'Apoorv Vyas'}, {'authorId': '1633532182', 'name': 'Bowen Shi'}, {'authorId': '2796576', 'name': 'B. Karrer'}, {'authorId': '2769735', 'name': 'Leda Sari'}, {'authorId': '2219692579', 'name': 'Rashel Moritz'}, {'authorId': '2066769956', 'name': 'Mary Williamson'}, {'authorId': '3316615', 'name': 'Vimal Manohar'}, {'authorId': '2727584', 'name': 'Yossi Adi'}, {'authorId': '3222225', 'name': 'Jay Mahadeokar'}, {'authorId': '2957796', 'name': 'Wei-Ning Hsu'}]","['Health Affairs', 'Meta']",['United States'],2023-06,"['industrial', 'industrial']"
2306.15766,Parikshit Bansal,"Parikshit Bansal, Amit Sharma",Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data. As an approximation to collecting ground-truth labels for the specific domain, we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models. Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular active learning strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference in prediction scores between the base model and the finetuned NLP model, utilizing the fact that most NLP models are finetuned from a base model. Experiments with classification (semantic similarity) and ranking (semantic search) tasks show that our sampling strategy leads to significant gains in accuracy for both the training and target domains. ","[{'version': 'v1', 'created': 'Tue, 27 Jun 2023 19:29:55 GMT'}]",2023-06-29,"[['Bansal', 'Parikshit', ''], ['Sharma', 'Amit', '']]",0,0,2023-06-27,1,2,2,0,0,0,2af358b4771d7bffe491077466fc4d225a16a74b,259274939.0,https://www.semanticscholar.org/paper/2af358b4771d7bffe491077466fc4d225a16a74b,arXiv.org,2023.0,37.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48691300', 'name': 'Parikshit Bansal'}, {'authorId': '2143678801', 'name': 'Amit Sharma'}]",['Microsoft'],['India'],2023-06,['industrial']
2306.16636,Tianwen Wei,"Tianwen Wei, Jian Luan, Wei Liu, Shuang Dong, Bin Wang",CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We present the Chinese Elementary School Math Word Problems (CMATH) dataset, comprising 1.7k elementary school-level math word problems with detailed annotations, source from actual Chinese workbooks and exams. This dataset aims to provide a benchmark tool for assessing the following question: to what grade level of elementary school math do the abilities of popular large language models (LLMs) correspond? We evaluate a variety of popular LLMs, including both commercial and open-source options, and discover that only GPT-4 achieves success (accuracy $\geq$ 60\%) across all six elementary school grades, while other models falter at different grade levels. Furthermore, we assess the robustness of several top-performing LLMs by augmenting the original problems in the CMATH dataset with distracting information. Our findings reveal that GPT-4 is able to maintains robustness, while other model fail. We anticipate that our study will expose limitations in LLMs' arithmetic and reasoning capabilities, and promote their ongoing development and advancement. ","[{'version': 'v1', 'created': 'Thu, 29 Jun 2023 02:19:50 GMT'}]",2023-06-30,"[['Wei', 'Tianwen', ''], ['Luan', 'Jian', ''], ['Liu', 'Wei', ''], ['Dong', 'Shuang', ''], ['Wang', 'Bin', '']]",0,1,2023-06-29,1,5,3,1,0,1,5efec343015f9329c5cd56e2259f68f03c2ef8b5,259287423.0,https://www.semanticscholar.org/paper/5efec343015f9329c5cd56e2259f68f03c2ef8b5,arXiv.org,2023.0,24.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '40364172', 'name': 'Tianwen Wei'}, {'authorId': '2067705842', 'name': 'Jian Luan'}, {'authorId': '46641573', 'name': 'W. Liu'}, {'authorId': '2220828668', 'name': 'Shuang Dong'}, {'authorId': '39682612', 'name': 'B. Wang'}]",['Xiaomi AI Lab'],,2023-06,['industrial']
2306.17077,Spandan Garg,"Spandan Garg, Roshanak Zilouchian Moghaddam, Neel Sundaresan",RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot,,,,,cs.SE cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  Performance bugs are non-functional bugs that can even manifest in well-tested commercial products. Fixing these performance bugs is an important yet challenging problem. In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction. It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix. We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing. Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers. ","[{'version': 'v1', 'created': 'Thu, 29 Jun 2023 16:28:34 GMT'}]",2023-06-30,"[['Garg', 'Spandan', ''], ['Moghaddam', 'Roshanak Zilouchian', ''], ['Sundaresan', 'Neel', '']]",0,0,2023-06-29,1,3,2,1,0,1,186b15df6d30749fc198606a1f865a405449a611,259286881.0,https://www.semanticscholar.org/paper/186b15df6d30749fc198606a1f865a405449a611,arXiv.org,2023.0,40.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2113364164', 'name': 'Spandan Garg'}, {'authorId': '1680427', 'name': 'Roshanak Zilouchian Moghaddam'}, {'authorId': '145507437', 'name': 'Neel Sundaresan'}]",['Redmond Fire Department'],['United States'],2023-06,['industrial']
2306.17519,Pawan Kumar Rajpoot,"Pawan Kumar Rajpoot, Ankur Parikh",GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models,arXiv admin note: text overlap with arXiv:2305.02105 by other authors,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Relation extraction (RE) is a crucial task in natural language processing (NLP) that aims to identify and classify relationships between entities mentioned in text. In the financial domain, relation extraction plays a vital role in extracting valuable information from financial documents, such as news articles, earnings reports, and company filings. This paper describes our solution to relation extraction on one such dataset REFinD. The dataset was released along with shared task as a part of the Fourth Workshop on Knowledge Discovery from Unstructured Data in Financial Services, co-located with SIGIR 2023. In this paper, we employed OpenAI models under the framework of in-context learning (ICL). We utilized two retrieval strategies to find top K relevant in-context learning demonstrations / examples from training data for a given test example. The first retrieval mechanism, we employed, is a learning-free dense retriever and the other system is a learning-based retriever. We were able to achieve 3rd rank overall. Our best F1-score is 0.718. ","[{'version': 'v1', 'created': 'Fri, 30 Jun 2023 10:12:30 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Jul 2023 06:57:49 GMT'}]",2023-07-24,"[['Rajpoot', 'Pawan Kumar', ''], ['Parikh', 'Ankur', '']]",0,1,2023-06-30,2,2,1,0,0,0,5bb69bb7eadf1344b3cb8849855b23ddf28a1528,259309148.0,https://www.semanticscholar.org/paper/5bb69bb7eadf1344b3cb8849855b23ddf28a1528,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143241321', 'name': 'P. Rajpoot'}, {'authorId': '2113810668', 'name': 'Ankur Parikh'}]","['MUST Research Bangalore, Karnataka, India', 'UtilizeAI Research Bangalore, Karnataka, India']",['India'],2023-06,"['industrial', 'industrial']"
2306.17582,Sai Vemprala,"Sai Vemprala, Rogerio Bonatti, Arthur Bucker, Ashish Kapoor",ChatGPT for Robotics: Design Principles and Model Abilities,,,,,cs.AI cs.CL cs.HC cs.LG cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents an experimental study regarding the use of OpenAI's ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT's ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing users to interact with it primarily via natural language instructions. In addition to these studies, we introduce an open-sourced research tool called PromptCraft, which contains a platform where researchers can collaboratively upload and vote on examples of good prompting schemes for robotics applications, as well as a sample robotics simulator with ChatGPT integration, making it easier for users to get started with using ChatGPT for robotics. ","[{'version': 'v1', 'created': 'Mon, 20 Feb 2023 06:39:06 GMT'}, {'version': 'v2', 'created': 'Wed, 19 Jul 2023 19:30:28 GMT'}]",2023-07-21,"[['Vemprala', 'Sai', ''], ['Bonatti', 'Rogerio', ''], ['Bucker', 'Arthur', ''], ['Kapoor', 'Ashish', '']]",1,1,2023-02-20,2,4,5,1,0,1,0ba581718f294db1d7b3dbc159cc3d3380f74606,259141622.0,https://www.semanticscholar.org/paper/0ba581718f294db1d7b3dbc159cc3d3380f74606,arXiv.org,2023.0,48.0,122.0,8.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","[{'authorId': '8355354', 'name': 'Sai Vemprala'}, {'authorId': '3444893', 'name': 'Rogerio Bonatti'}, {'authorId': '2008679488', 'name': 'A. Bucker'}, {'authorId': '2189118', 'name': 'Ashish Kapoor'}]","['Scaled Foundations,', 'Microsoft']",['United States'],2023-02,"['industrial', 'industrial']"
2306.17778,Apratim Bhattacharyya,"Apratim Bhattacharyya, Sunny Panchal, Mingu Lee, Reza Pourreza, Pulkit
  Madan, Roland Memisevic","Look, Remember and Reason: Visual Reasoning with Grounded Rationales",,,,,cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models have recently shown human level performance on a variety of reasoning tasks. However, the ability of these models to perform complex visual reasoning has not been studied in detail yet. A key challenge in many visual reasoning tasks is that the visual information needs to be tightly integrated in the reasoning process. We propose to address this challenge by drawing inspiration from human visual problem solving which depends on a variety of low-level visual capabilities. It can often be cast as the three step-process of ``Look, Remember, Reason'': visual information is incrementally extracted using low-level visual routines in a step-by-step fashion until a final answer is reached. We follow the same paradigm to enable existing large language models, with minimal changes to the architecture, to solve visual reasoning problems. To this end, we introduce rationales over the visual input that allow us to integrate low-level visual capabilities, such as object recognition and tracking, as surrogate tasks. We show competitive performance on diverse visual reasoning tasks from the CLEVR, CATER, and ACRE datasets over state-of-the-art models designed specifically for these tasks. ","[{'version': 'v1', 'created': 'Fri, 30 Jun 2023 16:31:14 GMT'}]",2023-07-03,"[['Bhattacharyya', 'Apratim', ''], ['Panchal', 'Sunny', ''], ['Lee', 'Mingu', ''], ['Pourreza', 'Reza', ''], ['Madan', 'Pulkit', ''], ['Memisevic', 'Roland', '']]",0,0,2023-06-30,1,6,2,0,0,0,72160b3c0f73c968fcb903db71817d1bed695f4d,259308884.0,https://www.semanticscholar.org/paper/72160b3c0f73c968fcb903db71817d1bed695f4d,arXiv.org,2023.0,78.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '3407762', 'name': 'Apratim Bhattacharyya'}, {'authorId': '2193388695', 'name': 'Sunny Panchal'}, {'authorId': '2108721816', 'name': 'Mingu Lee'}, {'authorId': '2300332', 'name': 'R. Pourreza'}, {'authorId': '2220960963', 'name': 'Pulkit Madan'}, {'authorId': '1710604', 'name': 'R. Memisevic'}]","['Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc.']",,2023-06,['industrial']
2307.01139,Sameera Horawalavithana,"Sameera Horawalavithana, Sai Munikoti, Ian Stewart, Henry Kvinge",SCITUNE: Aligning Large Language Models with Scientific Multimodal Instructions,Preprint. Work in progress,,,,cs.CV cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Instruction finetuning is a popular paradigm to align large language models (LLM) with human intent. Despite its popularity, this idea is less explored in improving the LLMs to align existing foundation models with scientific disciplines, concepts and goals. In this work, we present SciTune as a tuning framework to improve the ability of LLMs to follow scientific multimodal instructions. To test our methodology, we use a human-generated scientific instruction tuning dataset and train a large multimodal model LLaMA-SciTune that connects a vision encoder and LLM for science-focused visual and language understanding. In comparison to the models that are finetuned with machine generated data only, LLaMA-SciTune surpasses human performance on average and in many sub-categories on the ScienceQA benchmark. ","[{'version': 'v1', 'created': 'Mon, 3 Jul 2023 16:25:49 GMT'}]",2023-07-04,"[['Horawalavithana', 'Sameera', ''], ['Munikoti', 'Sai', ''], ['Stewart', 'Ian', ''], ['Kvinge', 'Henry', '']]",0,0,2023-07-03,1,4,4,1,1,0,da08e9f21ef361e0e1242f8849a18a4ea1a3d27e,259316643.0,https://www.semanticscholar.org/paper/da08e9f21ef361e0e1242f8849a18a4ea1a3d27e,arXiv.org,2023.0,38.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '24029613', 'name': 'Sameera Horawalavithana'}, {'authorId': '89057296', 'name': 'Sai Munikoti'}, {'authorId': '144925592', 'name': 'Ian Stewart'}, {'authorId': '51042250', 'name': 'Henry Kvinge'}]",['Pacific Northwest National Laboratory'],['United States'],2023-07,['industrial']
2307.02443,Leon Moonen,Max Hort and Anastasiia Grishina and Leon Moonen,An Exploratory Literature Study on Sharing and Energy Use of Language Models for Source Code,"Accepted for publication in the 17th ACM/IEEE International Symposium
  on Empirical Software Engineering and Measurement (ESEM 2023)",,,,cs.SE cs.AI cs.CL cs.LG cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Large language models trained on source code can support a variety of software development tasks, such as code recommendation and program repair. Large amounts of data for training such models benefit the models' performance. However, the size of the data and models results in long training times and high energy consumption. While publishing source code allows for replicability, users need to repeat the expensive training process if models are not shared. The main goal of the study is to investigate if publications that trained language models for software engineering (SE) tasks share source code and trained artifacts. The second goal is to analyze the transparency on training energy usage. We perform a snowballing-based literature search to find publications on language models for source code, and analyze their reusability from a sustainability standpoint.   From 494 unique publications, we identified 293 relevant publications that use language models to address code-related tasks. Among them, 27% (79 out of 293) make artifacts available for reuse. This can be in the form of tools or IDE plugins designed for specific tasks or task-agnostic models that can be fine-tuned for a variety of downstream tasks. Moreover, we collect insights on the hardware used for model training, as well as training time, which together determine the energy consumption of the development process. We find that there are deficiencies in the sharing of information and artifacts for current studies on source code models for software engineering tasks, with 40% of the surveyed papers not sharing source code or trained artifacts. We recommend the sharing of source code as well as trained artifacts, to enable sustainable reproducibility. Moreover, comprehensive information on training times and hardware configurations should be shared for transparency on a model's carbon footprint. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 17:13:00 GMT'}]",2023-07-06,"[['Hort', 'Max', ''], ['Grishina', 'Anastasiia', ''], ['Moonen', 'Leon', '']]",0,0,2023-07-05,1,3,5,0,0,0,b531ec9810a1c913df2d76c75b167b55211e8a85,259342301.0,https://www.semanticscholar.org/paper/b531ec9810a1c913df2d76c75b167b55211e8a85,International Symposium on Empirical Software Engineering and Measurement,2023.0,129.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2091097171', 'name': 'Max Hort'}, {'authorId': '73569689', 'name': 'Anastasiia Grishina'}, {'authorId': '1762006', 'name': 'L. Moonen'}]",['Simula Research Laboratory'],['Norway'],2023-07,['industrial']
2307.02499,Anwen Hu,"Jiabo Ye, Anwen Hu, Haiyang Xu, Qinghao Ye, Ming Yan, Yuhao Dan,
  Chenlin Zhao, Guohai Xu, Chenliang Li, Junfeng Tian, Qian Qi, Ji Zhang, Fei
  Huang",mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding,"10 pages, 8 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Document understanding refers to automatically extract, analyze and comprehend information from various types of digital documents, such as a web page. Existing Multi-model Large Language Models (MLLMs), including mPLUG-Owl, have demonstrated promising zero-shot capabilities in shallow OCR-free text recognition, indicating their potential for OCR-free document understanding. Nevertheless, without in-domain training, these models tend to ignore fine-grained OCR features, such as sophisticated tables or large blocks of text, which are essential for OCR-free document understanding. In this paper, we propose mPLUG-DocOwl based on mPLUG-Owl for OCR-free document understanding. Specifically, we first construct a instruction tuning dataset featuring a wide range of visual-text understanding tasks. Then, we strengthen the OCR-free document understanding ability by jointly train the model on language-only, general vision-and-language, and document instruction tuning dataset with our unified instruction tuning strategy. We also build an OCR-free document instruction understanding evaluation set LLMDoc to better compare models' capabilities on instruct compliance and document understanding. Experimental results show that our model outperforms existing multi-modal models, demonstrating its strong ability of document understanding. Besides, without specific fine-tuning, mPLUG-DocOwl generalizes well on various downstream tasks. Our code, models, training data and evaluation set are available at https://github.com/X-PLUG/mPLUG-DocOwl. ","[{'version': 'v1', 'created': 'Tue, 4 Jul 2023 11:28:07 GMT'}]",2023-07-07,"[['Ye', 'Jiabo', ''], ['Hu', 'Anwen', ''], ['Xu', 'Haiyang', ''], ['Ye', 'Qinghao', ''], ['Yan', 'Ming', ''], ['Dan', 'Yuhao', ''], ['Zhao', 'Chenlin', ''], ['Xu', 'Guohai', ''], ['Li', 'Chenliang', ''], ['Tian', 'Junfeng', ''], ['Qi', 'Qian', ''], ['Zhang', 'Ji', ''], ['Huang', 'Fei', '']]",0,0,2023-07-04,1,13,2,0,0,0,ea566f87f6253bb2d32cf7b61cd3e2535a0c3f42,259360848.0,https://www.semanticscholar.org/paper/ea566f87f6253bb2d32cf7b61cd3e2535a0c3f42,arXiv.org,2023.0,37.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153258288', 'name': 'Jiabo Ye'}, {'authorId': '120897486', 'name': 'Anwen Hu'}, {'authorId': '153194420', 'name': 'Haiyang Xu'}, {'authorId': '2199011713', 'name': 'Qinghao Ye'}, {'authorId': '2114009661', 'name': 'Mingshi Yan'}, {'authorId': '2115610557', 'name': 'Yuhao Dan'}, {'authorId': '2232751254', 'name': 'Chenlin Zhao'}, {'authorId': '2115723816', 'name': 'Guohai Xu'}, {'authorId': '143971529', 'name': 'Chenliang Li'}, {'authorId': '2122989639', 'name': 'Junfeng Tian'}, {'authorId': '50480206', 'name': 'Qiang Qi'}, {'authorId': '2116921824', 'name': 'Ji Zhang'}, {'authorId': '2194508991', 'name': 'Feiyan Huang'}]",['Alibaba'],['China'],2023-07,['industrial']
2307.02628,Luciano Del Corro,"Luciano Del Corro, Allie Del Giorno, Sahaj Agarwal, Bin Yu, Ahmed
  Awadallah, Subhabrata Mukherjee",SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Autoregressive large language models (LLMs) have made remarkable progress in various natural language generation tasks. However, they incur high computation cost and latency resulting from the autoregressive token-by-token generation. To address this issue, several approaches have been proposed to reduce computational cost using early-exit strategies. These strategies enable faster text generation using reduced computation without applying the full computation graph to each token. While existing token-level early exit methods show promising results for online inference, they cannot be readily applied for batch inferencing and Key-Value caching. This is because they have to wait until the last token in a batch exits before they can stop computing. This severely limits the practical application of such techniques. In this paper, we propose a simple and effective token-level early exit method, SkipDecode, designed to work seamlessly with batch inferencing and KV caching. It overcomes prior constraints by setting up a singular exit point for every token in a batch at each sequence position. It also guarantees a monotonic decrease in exit points, thereby eliminating the need to recompute KV Caches for preceding tokens. Rather than terminating computation prematurely as in prior works, our approach bypasses lower to middle layers, devoting most of the computational resources to upper layers, allowing later tokens to benefit from the compute expenditure by earlier tokens. Our experimental results show that SkipDecode can obtain 2x to 5x inference speedups with negligible regression across a variety of tasks. This is achieved using OPT models of 1.3 billion and 6.7 billion parameters, all the while being directly compatible with batching and KV caching optimization techniques. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 19:59:09 GMT'}]",2023-07-07,"[['Del Corro', 'Luciano', ''], ['Del Giorno', 'Allie', ''], ['Agarwal', 'Sahaj', ''], ['Yu', 'Bin', ''], ['Awadallah', 'Ahmed', ''], ['Mukherjee', 'Subhabrata', '']]",0,0,2023-07-05,1,6,1,1,1,0,ce9435c82dc9b576f2037aa2f4357a520be9b2aa,259360560.0,https://www.semanticscholar.org/paper/ce9435c82dc9b576f2037aa2f4357a520be9b2aa,arXiv.org,2023.0,26.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1875906', 'name': 'Luciano Del Corro'}, {'authorId': '50672277', 'name': 'Allison Del Giorno'}, {'authorId': '2211923024', 'name': 'Sahaj Agarwal'}, {'authorId': '46806278', 'name': 'Ting Yu'}, {'authorId': '2072795428', 'name': 'A. Awadallah'}, {'authorId': '2153292652', 'name': 'Subhabrata Mukherjee'}]",['Microsoft'],['India'],2023-07,['industrial']
2307.03539,Benjamin Clavi\'e,Benjamin Clavi\'e and Guillaume Souli\'e,Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers,,Recsys in HR @ Recsys 2023,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Understanding labour market dynamics requires accurately identifying the skills required for and possessed by the workforce. Automation techniques are increasingly being developed to support this effort. However, automatically extracting skills from job postings is challenging due to the vast number of existing skills. The ESCO (European Skills, Competences, Qualifications and Occupations) framework provides a useful reference, listing over 13,000 individual skills. However, skills extraction remains difficult and accurately matching job posts to the ESCO taxonomy is an open problem. In this work, we propose an end-to-end zero-shot system for skills extraction from job descriptions based on large language models (LLMs). We generate synthetic training data for the entirety of ESCO skills and train a classifier to extract skill mentions from job posts. We also employ a similarity retriever to generate skill candidates which are then re-ranked using a second LLM. Using synthetic data achieves an RP@10 score 10 points higher than previous distant supervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22 points over previous methods. We also show that Framing the task as mock programming when prompting the LLM can lead to better performance than natural language prompts, especially with weaker LLMs. We demonstrate the potential of integrating large language models at both ends of skills matching pipelines. Our approach requires no human annotations and achieve extremely promising results on skills extraction against ESCO. ","[{'version': 'v1', 'created': 'Fri, 7 Jul 2023 12:04:12 GMT'}]",2023-08-31,"[['Clavié', 'Benjamin', ''], ['Soulié', 'Guillaume', '']]",0,1,2023-07-07,1,2,2,1,0,1,c4f9f0cc8c138047a61bdb11b1a352e3d1aed035,259375557.0,https://www.semanticscholar.org/paper/c4f9f0cc8c138047a61bdb11b1a352e3d1aed035,HR@RecSys,2023.0,44.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31430199', 'name': 'Benjamin Clavié'}, {'authorId': '2211430897', 'name': ""Guillaume Souli'e""}]","['Bright Network Ltd., Edinburgh, UK']",,2023-07,['industrial']
2307.03712,Lakshmi Nair,"Lakshmi Nair, Mikhail Bernadskiy, Arulselvan Madhavan, Craig Chan,
  Ayon Basumallik, Darius Bunandar",INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers,"This report is supplementary material to the open-source code
  available at: https://github.com/lightmatter-ai/INT-FP-QSim",,,,cs.LG cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The recent rise of large language models (LLMs) has resulted in increased efforts towards running LLMs at reduced precision. Running LLMs at lower precision supports resource constraints and furthers their democratization, enabling users to run billion-parameter LLMs on their personal devices. To supplement this ongoing effort, we propose INT-FP-QSim: an open-source simulator that enables flexible evaluation of LLMs and vision transformers at various numerical precisions and formats. INT-FP-QSim leverages existing open-source repositories such as TensorRT, QPytorch and AIMET for a combined simulator that supports various floating point and integer formats. With the help of our simulator, we survey the impact of different numerical formats on the performance of LLMs and vision transformers at 4-bit weights and 4-bit or 8-bit activations. We also compare recently proposed methods like Adaptive Block Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We hope INT-FP-QSim will enable researchers to flexibly simulate models at various precisions to support further research in quantization of LLMs and vision transformers. ","[{'version': 'v1', 'created': 'Fri, 7 Jul 2023 16:54:53 GMT'}]",2023-07-10,"[['Nair', 'Lakshmi', ''], ['Bernadskiy', 'Mikhail', ''], ['Madhavan', 'Arulselvan', ''], ['Chan', 'Craig', ''], ['Basumallik', 'Ayon', ''], ['Bunandar', 'Darius', '']]",0,1,2023-07-07,1,6,3,0,0,0,3bade55fb2ebe46fd1140c89e31f52b6a508463c,259375692.0,https://www.semanticscholar.org/paper/3bade55fb2ebe46fd1140c89e31f52b6a508463c,arXiv.org,2023.0,14.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2165311966', 'name': 'Lakshmi Nair'}, {'authorId': '2221314448', 'name': 'Mikhail Bernadskiy'}, {'authorId': '2221314471', 'name': 'Arulselvan Madhavan'}, {'authorId': '2222279523', 'name': 'Craig Chan'}, {'authorId': '1998651', 'name': 'Ayon Basumallik'}, {'authorId': '51034522', 'name': 'D. Bunandar'}]",['Lightmatter (United States)'],['United States'],2023-07,['industrial']
2307.03744,Jake Hofman,"Sofia Eleni Spatharioti, David M. Rothschild, Daniel G. Goldstein,
  Jake M. Hofman",Comparing Traditional and LLM-based Search for Consumer Choice: A Randomized Experiment,,,,,cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advances in the development of large language models are rapidly changing how online applications function. LLM-based search tools, for instance, offer a natural language interface that can accommodate complex queries and provide detailed, direct responses. At the same time, there have been concerns about the veracity of the information provided by LLM-based tools due to potential mistakes or fabrications that can arise in algorithmically generated text. In a set of online experiments we investigate how LLM-based search changes people's behavior relative to traditional search, and what can be done to mitigate overreliance on LLM-based output. Participants in our experiments were asked to solve a series of decision tasks that involved researching and comparing different products, and were randomly assigned to do so with either an LLM-based search tool or a traditional search engine. In our first experiment, we find that participants using the LLM-based tool were able to complete their tasks more quickly, using fewer but more complex queries than those who used traditional search. Moreover, these participants reported a more satisfying experience with the LLM-based search tool. When the information presented by the LLM was reliable, participants using the tool made decisions with a comparable level of accuracy to those using traditional search, however we observed overreliance on incorrect information when the LLM erred. Our second experiment further investigated this issue by randomly assigning some users to see a simple color-coded highlighting scheme to alert them to potentially incorrect or misleading information in the LLM responses. Overall we find that this confidence-based highlighting substantially increases the rate at which users spot incorrect information, improving the accuracy of their overall decisions while leaving most other measures unaffected. ","[{'version': 'v1', 'created': 'Fri, 7 Jul 2023 17:53:07 GMT'}]",2023-07-10,"[['Spatharioti', 'Sofia Eleni', ''], ['Rothschild', 'David M.', ''], ['Goldstein', 'Daniel G.', ''], ['Hofman', 'Jake M.', '']]",0,0,2023-07-07,1,4,1,0,0,0,6c28d6c3eddf63e7bc096361d1ab14b4637181af,259375527.0,https://www.semanticscholar.org/paper/6c28d6c3eddf63e7bc096361d1ab14b4637181af,arXiv.org,2023.0,29.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '79320234', 'name': 'Sofia Eleni Spatharioti'}, {'authorId': '145792941', 'name': 'David M. Rothschild'}, {'authorId': '2463533', 'name': 'D. Goldstein'}, {'authorId': '40368603', 'name': 'J. Hofman'}]",['Microsoft'],['United States'],2023-07,['industrial']
2307.03875,Beibin Li,"Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan Pathuri, Ishai Menache",Large Language Models for Supply Chain Optimization,,,,,cs.AI cs.CL cs.DM cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Supply chain operations traditionally involve a variety of complex decision making problems. Over the last few decades, supply chains greatly benefited from advances in computation, which allowed the transition from manual processing to automation and cost-effective optimization. Nonetheless, business operators still need to spend substantial efforts in explaining and interpreting the optimization outcomes to stakeholders. Motivated by the recent advances in Large Language Models (LLMs), we study how this disruptive technology can help bridge the gap between supply chain automation and human comprehension and trust thereof. We design OptiGuide -- a framework that accepts as input queries in plain text, and outputs insights about the underlying optimization outcomes. Our framework does not forgo the state-of-the-art combinatorial optimization technology, but rather leverages it to quantitatively answer what-if scenarios (e.g., how would the cost change if we used supplier B instead of supplier A for a given demand?). Importantly, our design does not require sending proprietary data over to LLMs, which can be a privacy concern in some circumstances. We demonstrate the effectiveness of our framework on a real server placement scenario within Microsoft's cloud supply chain. Along the way, we develop a general evaluation benchmark, which can be used to evaluate the accuracy of the LLM output in other scenarios. ","[{'version': 'v1', 'created': 'Sat, 8 Jul 2023 01:42:22 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Jul 2023 17:29:48 GMT'}]",2023-07-14,"[['Li', 'Beibin', ''], ['Mellou', 'Konstantina', ''], ['Zhang', 'Bo', ''], ['Pathuri', 'Jeevan', ''], ['Menache', 'Ishai', '']]",0,0,2023-07-08,2,5,4,0,0,0,bbe2f0a73e8bac09457ea17d3b6276dc97f170df,259501087.0,https://www.semanticscholar.org/paper/bbe2f0a73e8bac09457ea17d3b6276dc97f170df,arXiv.org,2023.0,63.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3369602', 'name': 'Beibin Li'}, {'authorId': '1453737193', 'name': 'Konstantina Mellou'}, {'authorId': '2000450964', 'name': 'Bo-qing Zhang'}, {'authorId': '2740008', 'name': 'Jeevan Pathuri'}, {'authorId': '1684547', 'name': 'Ishai Menache'}]",['Microsoft'],['United States'],2023-07,['industrial']
2307.03917,Zhuo Chen,"Jian Wu, Yashesh Gaur, Zhuo Chen, Long Zhou, Yimeng Zhu, Tianrui Wang,
  Jinyu Li, Shujie Liu, Bo Ren, Linquan Liu, Yu Wu",On decoder-only architecture for speech-to-text and large language model integration,,,,,eess.AS cs.CL cs.SD,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have achieved remarkable success in the field of natural language processing, enabling better human-computer interaction using natural language. However, the seamless integration of speech signals into LLMs has not been explored well. The ""decoder-only"" architecture has also not been well studied for speech processing tasks. In this research, we introduce Speech-LLaMA, a novel approach that effectively incorporates acoustic information into text-based large language models. Our method leverages Connectionist Temporal Classification and a simple audio encoder to map the compressed acoustic features to the continuous semantic space of the LLM. In addition, we further probe the decoder-only architecture for speech-to-text tasks by training a smaller scale randomly initialized speech-LLaMA model from speech-text paired data alone. We conduct experiments on multilingual speech-to-text translation tasks and demonstrate a significant improvement over strong baselines, highlighting the potential advantages of decoder-only models for speech-to-text conversion. ","[{'version': 'v1', 'created': 'Sat, 8 Jul 2023 06:47:58 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Jul 2023 23:37:43 GMT'}, {'version': 'v3', 'created': 'Mon, 2 Oct 2023 06:57:19 GMT'}]",2023-10-03,"[['Wu', 'Jian', ''], ['Gaur', 'Yashesh', ''], ['Chen', 'Zhuo', ''], ['Zhou', 'Long', ''], ['Zhu', 'Yimeng', ''], ['Wang', 'Tianrui', ''], ['Li', 'Jinyu', ''], ['Liu', 'Shujie', ''], ['Ren', 'Bo', ''], ['Liu', 'Linquan', ''], ['Wu', 'Yu', '']]",0,0,2023-07-08,3,11,3,1,1,0,8e1868f84091272544cb4209c4ccaad7cc88af27,259501685.0,https://www.semanticscholar.org/paper/8e1868f84091272544cb4209c4ccaad7cc88af27,arXiv.org,2023.0,41.0,15.0,1.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '97569165', 'name': 'Jian Wu'}, {'authorId': '2334648', 'name': 'Yashesh Gaur'}, {'authorId': '145718850', 'name': 'Zhuo Chen'}, {'authorId': '2135918679', 'name': 'Long Zhou'}, {'authorId': '2117870253', 'name': 'Yilun Zhu'}, {'authorId': '2118915113', 'name': 'Tianrui Wang'}, {'authorId': '152319568', 'name': 'Jinyu Li'}, {'authorId': '2107983441', 'name': 'Shujie Liu'}, {'authorId': '2121381699', 'name': 'Bo Ren'}, {'authorId': '2049319', 'name': 'Linquan Liu'}, {'authorId': '49176273', 'name': 'Yu Wu'}]",['Microsoft'],['United States'],2023-07,['industrial']
2307.04964,Songyang Gao,"Rui Zheng, Shihan Dou, Songyang Gao, Yuan Hua, Wei Shen, Binghai Wang,
  Yan Liu, Senjie Jin, Qin Liu, Yuhao Zhou, Limao Xiong, Lu Chen, Zhiheng Xi,
  Nuo Xu, Wenbin Lai, Minghao Zhu, Cheng Chang, Zhangyue Yin, Rongxiang Weng,
  Wensen Cheng, Haoran Huang, Tianxiang Sun, Hang Yan, Tao Gui, Qi Zhang,
  Xipeng Qiu, Xuanjing Huang",Secrets of RLHF in Large Language Models Part I: PPO,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have formulated a blueprint for the advancement of artificial general intelligence. Its primary objective is to function as a human-centric (helpful, honest, and harmless) assistant. Alignment with humans assumes paramount significance, and reinforcement learning with human feedback (RLHF) emerges as the pivotal technological paradigm underpinning this pursuit. Current technical routes usually include \textbf{reward models} to measure human preferences, \textbf{Proximal Policy Optimization} (PPO) to optimize policy model outputs, and \textbf{process supervision} to improve step-by-step reasoning capabilities. However, due to the challenges of reward design, environment interaction, and agent training, coupled with huge trial and error cost of large language models, there is a significant barrier for AI researchers to motivate the development of technical alignment and safe landing of LLMs. The stable training of RLHF has still been a puzzle. In the first report, we dissect the framework of RLHF, re-evaluate the inner workings of PPO, and explore how the parts comprising PPO algorithms impact policy agent training. We identify policy constraints being the key factor for the effective implementation of the PPO algorithm. Therefore, we explore the PPO-max, an advanced version of PPO algorithm, to efficiently improve the training stability of the policy model. Based on our main results, we perform a comprehensive analysis of RLHF abilities compared with SFT models and ChatGPT. The absence of open-source implementations has posed significant challenges to the investigation of LLMs alignment. Therefore, we are eager to release technical reports, reward models and PPO codes, aiming to make modest contributions to the advancement of LLMs. ","[{'version': 'v1', 'created': 'Tue, 11 Jul 2023 01:55:24 GMT'}, {'version': 'v2', 'created': 'Tue, 18 Jul 2023 08:44:47 GMT'}]",2023-07-19,"[['Zheng', 'Rui', ''], ['Dou', 'Shihan', ''], ['Gao', 'Songyang', ''], ['Hua', 'Yuan', ''], ['Shen', 'Wei', ''], ['Wang', 'Binghai', ''], ['Liu', 'Yan', ''], ['Jin', 'Senjie', ''], ['Liu', 'Qin', ''], ['Zhou', 'Yuhao', ''], ['Xiong', 'Limao', ''], ['Chen', 'Lu', ''], ['Xi', 'Zhiheng', ''], ['Xu', 'Nuo', ''], ['Lai', 'Wenbin', ''], ['Zhu', 'Minghao', ''], ['Chang', 'Cheng', ''], ['Yin', 'Zhangyue', ''], ['Weng', 'Rongxiang', ''], ['Cheng', 'Wensen', ''], ['Huang', 'Haoran', ''], ['Sun', 'Tianxiang', ''], ['Yan', 'Hang', ''], ['Gui', 'Tao', ''], ['Zhang', 'Qi', ''], ['Qiu', 'Xipeng', ''], ['Huang', 'Xuanjing', '']]",1,1,2023-07-11,2,27,3,1,0,1,548278897d46a54958909bb23bcaecf63e24fadf,259766568.0,https://www.semanticscholar.org/paper/548278897d46a54958909bb23bcaecf63e24fadf,arXiv.org,2023.0,45.0,16.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2058585152', 'name': 'Rui Zheng'}, {'authorId': '2042683163', 'name': 'Shihan Dou'}, {'authorId': '2181306462', 'name': 'Songyang Gao'}, {'authorId': '2248291262', 'name': 'Wei Shen'}, {'authorId': '2117227865', 'name': 'Wei-Yuan Shen'}, {'authorId': '2188630983', 'name': 'Bing Wang'}, {'authorId': '2156649786', 'name': 'Yan Liu'}, {'authorId': '2219131195', 'name': 'Senjie Jin'}, {'authorId': '2109185819', 'name': 'Qin Liu'}, {'authorId': '2222630539', 'name': 'Limao Xiong'}, {'authorId': '2115386043', 'name': 'Luyao Chen'}, {'authorId': '2190751523', 'name': 'Zhiheng Xi'}, {'authorId': '2212175381', 'name': 'Yuhao Zhou'}, {'authorId': '2072805812', 'name': 'Nuo Xu'}, {'authorId': '2153857410', 'name': 'Wen-De Lai'}, {'authorId': '40587747', 'name': 'Minghao Zhu'}, {'authorId': '24009282', 'name': 'Rongxiang Weng'}, {'authorId': '2227418', 'name': 'Wen-Chun Cheng'}, {'authorId': '2152341000', 'name': 'Cheng Chang'}, {'authorId': '2155273086', 'name': 'Zhangyue Yin'}, {'authorId': '152738167', 'name': 'Yuan Hua'}, {'authorId': '2039788', 'name': 'Haoran Huang'}, {'authorId': '153345698', 'name': 'Tianxiang Sun'}, {'authorId': '146948229', 'name': 'Hang Yan'}, {'authorId': '2067331064', 'name': 'Tao Gui'}, {'authorId': '47835189', 'name': 'Qi Zhang'}, {'authorId': '1767521', 'name': 'Xipeng Qiu'}, {'authorId': '1790227', 'name': 'Xuanjing Huang'}]",['ByteDance'],['China'],2023-07,['industrial']
2307.04986,Navid Ghaffarzadegan,"Ross Williams, Niyousha Hosseinichimeh, Aritra Majumdar, Navid
  Ghaffarzadegan",Epidemic Modeling with Generative Agents,,,,,cs.AI cs.MA econ.GN nlin.AO physics.soc-ph q-fin.EC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This study offers a new paradigm of individual-level modeling to address the grand challenge of incorporating human behavior in epidemic models. Using generative artificial intelligence in an agent-based epidemic model, each agent is empowered to make its own reasonings and decisions via connecting to a large language model such as ChatGPT. Through various simulation experiments, we present compelling evidence that generative agents mimic real-world behaviors such as quarantining when sick and self-isolation when cases rise. Collectively, the agents demonstrate patterns akin to multiple waves observed in recent pandemics followed by an endemic period. Moreover, the agents successfully flatten the epidemic curve. This study creates potential to improve dynamic system modeling by offering a way to represent human brain, reasoning, and decision making. ","[{'version': 'v1', 'created': 'Tue, 11 Jul 2023 02:52:32 GMT'}]",2023-07-12,"[['Williams', 'Ross', ''], ['Hosseinichimeh', 'Niyousha', ''], ['Majumdar', 'Aritra', ''], ['Ghaffarzadegan', 'Navid', '']]",1,1,2023-07-11,1,4,6,1,0,1,c49a45927d1f81efe5026dbfc139b7b13817933d,259766713.0,https://www.semanticscholar.org/paper/c49a45927d1f81efe5026dbfc139b7b13817933d,arXiv.org,2023.0,26.0,4.0,0.0,True,"['Computer Science', 'Economics', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '2157888330', 'name': 'Ross Williams'}, {'authorId': '3565384', 'name': 'Niyousha Hosseinichimeh'}, {'authorId': '116905981', 'name': 'A. Majumdar'}, {'authorId': '3225275', 'name': 'Navid Ghaffarzadegan'}]",['Virginia Tech'],['United States'],2023-07,['industrial']
2307.05492,Zachary Robertson,Zachary Robertson,GPT4 is Slightly Helpful for Peer-Review Assistance: A Pilot Study,15 pages,,,,cs.HC cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this pilot study, we investigate the use of GPT4 to assist in the peer-review process. Our key hypothesis was that GPT-generated reviews could achieve comparable helpfulness to human reviewers. By comparing reviews generated by both human reviewers and GPT models for academic papers submitted to a major machine learning conference, we provide initial evidence that artificial intelligence can contribute effectively to the peer-review process. We also perform robustness experiments with inserted errors to understand which parts of the paper the model tends to focus on. Our findings open new avenues for leveraging machine learning tools to address resource constraints in peer review. The results also shed light on potential enhancements to the review process and lay the groundwork for further research on scaling oversight in a domain where human-feedback is increasingly a scarce resource. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 23:11:06 GMT'}]",2023-07-13,"[['Robertson', 'Zachary', '']]",0,1,2023-06-16,1,1,3,1,0,1,9ae09574e5765b7e92c205188dac7c77bd3d001e,259837446.0,https://www.semanticscholar.org/paper/9ae09574e5765b7e92c205188dac7c77bd3d001e,arXiv.org,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1854303398', 'name': 'Zachary Robertson'}]",['Institute of Computer Science'],['Poland'],2023-06,['industrial']
2307.05532,Andreas Liesenfeld,"Andreas Liesenfeld, Alianda Lopez, Mark Dingemanse","Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators",,,10.1145/3571884.3604316,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI's ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as 'open source', many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment. ","[{'version': 'v1', 'created': 'Sat, 8 Jul 2023 07:08:20 GMT'}]",2023-07-13,"[['Liesenfeld', 'Andreas', ''], ['Lopez', 'Alianda', ''], ['Dingemanse', 'Mark', '']]",1,1,2023-07-08,1,3,1,1,0,1,9b2a802cccdbba0cee4d98ee9fd32301c298d0d7,259837343.0,https://www.semanticscholar.org/paper/9b2a802cccdbba0cee4d98ee9fd32301c298d0d7,International Conference on Conversational User Interfaces,2023.0,64.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '41126345', 'name': 'Andreas Liesenfeld'}, {'authorId': '2184169857', 'name': 'Alianda Lopez'}, {'authorId': '3096471', 'name': 'Mark Dingemanse'}]","['for , The']",,2023-07,['industrial']
2307.06439,Yu Gu,"Yu Gu, Sheng Zhang, Naoto Usuyama, Yonas Woldesenbet, Cliff Wong,
  Praneeth Sanapathi, Mu Wei, Naveen Valluri, Erika Strandberg, Tristan
  Naumann, Hoifung Poon",Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs), such as GPT-4, have demonstrated remarkable capabilities across a wide range of tasks, including health applications. In this paper, we study how LLMs can be used to scale biomedical knowledge curation. We find that while LLMs already possess decent competency in structuring biomedical text, by distillation into a task-specific student model through self-supervised learning, substantial gains can be attained over out-of-box LLMs, with additional advantages such as cost, efficiency, and white-box model access.   We conduct a case study on adverse drug event (ADE) extraction, which is an important area for improving care. On standard ADE extraction evaluation, a GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised state-of-the-art models without using any labeled data. Despite being over 1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by over 6 absolute points in F1 and GPT-4 by over 5 absolute points.   Ablation studies on distillation model choice (e.g., PubMedBERT vs BioGPT) and ADE extraction architecture shed light on best practice for biomedical knowledge extraction. Similar gains were attained by distillation for other standard biomedical knowledge extraction tasks such as gene-disease associations and protected health information, further illustrating the promise of this approach. ","[{'version': 'v1', 'created': 'Wed, 12 Jul 2023 20:08:48 GMT'}]",2023-07-14,"[['Gu', 'Yu', ''], ['Zhang', 'Sheng', ''], ['Usuyama', 'Naoto', ''], ['Woldesenbet', 'Yonas', ''], ['Wong', 'Cliff', ''], ['Sanapathi', 'Praneeth', ''], ['Wei', 'Mu', ''], ['Valluri', 'Naveen', ''], ['Strandberg', 'Erika', ''], ['Naumann', 'Tristan', ''], ['Poon', 'Hoifung', '']]",0,1,2023-07-12,1,11,2,2,0,2,6c12769939dd75bd681d37ea17cce7e6a57f5c6e,259847622.0,https://www.semanticscholar.org/paper/6c12769939dd75bd681d37ea17cce7e6a57f5c6e,arXiv.org,2023.0,25.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112677245', 'name': 'Yu Gu'}, {'authorId': '41209309', 'name': 'Sheng Zhang'}, {'authorId': '2637252', 'name': 'Naoto Usuyama'}, {'authorId': '3310870', 'name': 'Yonas G. Woldesenbet'}, {'authorId': '2109566188', 'name': 'Cliff Wong'}, {'authorId': '2223542076', 'name': 'Praneeth Sanapathi'}, {'authorId': '2072847758', 'name': 'Mu-Hsin Wei'}, {'authorId': '48269128', 'name': 'Naveen Valluri'}, {'authorId': '35009788', 'name': 'Erika Strandberg'}, {'authorId': '40466858', 'name': 'Tristan Naumann'}, {'authorId': '1759772', 'name': 'Hoifung Poon'}]",['Microsoft'],['India'],2023-07,['industrial']
2307.06857,Siddhartha Jain,"Siddhartha Jain, Xiaofei Ma, Anoop Deoras, Bing Xiang",Self-consistency for open-ended generations,,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Large Language Models (LLMs) can exhibit considerable variation in the quality of their sampled outputs. Reranking and selecting the best generation from the sampled set is a popular way of obtaining strong gains in generation quality. In this paper, we present a novel approach for reranking LLM generations. Unlike other techniques that might involve additional inferences or training a specialized reranker, our approach relies on easy to compute pairwise statistics between the generations that have minimal compute overhead. We show that our approach can be formalized as an extension of self-consistency and analyze its performance in that framework, theoretically as well as via simulations. We show strong improvements for selecting the best $k$ generations for code generation tasks as well as robust improvements for best generation for the tasks of autoformalization, and summarization. While our approach only assumes black-box access to LLMs, we show that additional access to token probabilities can improve performance even further. ","[{'version': 'v1', 'created': 'Tue, 11 Jul 2023 17:51:48 GMT'}, {'version': 'v2', 'created': 'Wed, 23 Aug 2023 07:06:53 GMT'}]",2023-08-24,"[['Jain', 'Siddhartha', ''], ['Ma', 'Xiaofei', ''], ['Deoras', 'Anoop', ''], ['Xiang', 'Bing', '']]",0,0,2023-07-11,2,4,3,0,0,0,a95744db58504323b36160e33f232dd89003e769,259847428.0,https://www.semanticscholar.org/paper/a95744db58504323b36160e33f232dd89003e769,arXiv.org,2023.0,27.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1971171', 'name': 'Siddhartha Jain'}, {'authorId': '47646605', 'name': 'Xiaofei Ma'}, {'authorId': '1713801', 'name': 'Anoop Deoras'}, {'authorId': '144028698', 'name': 'Bing Xiang'}]",['Amazon'],['United States'],2023-07,['industrial']
2307.07164,Liang Wang,"Liang Wang, Nan Yang, Furu Wei",Learning to Retrieve In-Context Examples for Large Language Models,16 pages,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated their ability to learn in-context, allowing them to perform various tasks based on a few input-output examples. However, the effectiveness of in-context learning is heavily reliant on the quality of the selected examples. In this paper, we propose a novel framework to iteratively train dense retrievers that can identify high-quality in-context examples for LLMs. Our framework initially trains a reward model based on LLM feedback to evaluate the quality of candidate examples, followed by knowledge distillation to train a bi-encoder based dense retriever. Our experiments on a suite of 30 tasks demonstrate that our framework significantly enhances in-context learning performance. Furthermore, we show the generalization ability of our framework to unseen tasks during training. An in-depth analysis reveals that our model improves performance by retrieving examples with similar patterns, and the gains are consistent across LLMs of varying sizes. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 05:23:08 GMT'}]",2023-07-17,"[['Wang', 'Liang', ''], ['Yang', 'Nan', ''], ['Wei', 'Furu', '']]",0,0,2023-07-14,1,3,2,0,0,0,ae22f7c57916562e2729a1a7f34298e4220b77a7,259924840.0,https://www.semanticscholar.org/paper/ae22f7c57916562e2729a1a7f34298e4220b77a7,arXiv.org,2023.0,55.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145769448', 'name': 'Liang Wang'}, {'authorId': '144610884', 'name': 'Nan Yang'}, {'authorId': '49807919', 'name': 'Furu Wei'}]",['Microsoft'],['United States'],2023-07,['industrial']
2307.07415,Xue Li,"Hong Sun, Xue Li, Yinchuan Xu, Youkow Homma, Qi Cao, Min Wu, Jian
  Jiao, Denis Charles",AutoHint: Automatic Prompt Optimization with Hint Generation,"KDD 2023: Foundations and Applications in Large-scale AI
  Models-Pre-training, Fine-tuning, and Prompt-based Learning workshop",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper presents AutoHint, a novel framework for automatic prompt engineering and optimization for Large Language Models (LLM). While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts. Thus we propose a framework to inherit the merits of both in-context learning and zero-shot learning by incorporating enriched instructions derived from input-output demonstrations to optimize original prompt. We refer to the enrichment as the hint and propose a framework to automatically generate the hint from labeled data. More concretely, starting from an initial prompt, our method first instructs a LLM to deduce new hints for selected samples from incorrect predictions, and then summarizes from per-sample hints and adds the results back to the initial prompt to form a new, enriched instruction. The proposed method is evaluated on the BIG-Bench Instruction Induction dataset for both zero-shot and few-short prompts, where experiments demonstrate our method is able to significantly boost accuracy for multiple tasks. ","[{'version': 'v1', 'created': 'Thu, 13 Jul 2023 00:49:27 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Aug 2023 21:26:53 GMT'}]",2023-08-10,"[['Sun', 'Hong', ''], ['Li', 'Xue', ''], ['Xu', 'Yinchuan', ''], ['Homma', 'Youkow', ''], ['Cao', 'Qi', ''], ['Wu', 'Min', ''], ['Jiao', 'Jian', ''], ['Charles', 'Denis', '']]",0,0,2023-07-13,2,8,2,0,0,0,838e1317454724a9bb758d05d97e6058e11a8251,259924936.0,https://www.semanticscholar.org/paper/838e1317454724a9bb758d05d97e6058e11a8251,arXiv.org,2023.0,23.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152993452', 'name': 'Hong Sun'}, {'authorId': '2222903511', 'name': 'Xue Li'}, {'authorId': '2110289374', 'name': 'Yi Xu'}, {'authorId': '4133298', 'name': 'Youkow Homma'}, {'authorId': '2209217758', 'name': 'Qinhao Cao'}, {'authorId': '2133852132', 'name': 'Min-man Wu'}, {'authorId': '2143968416', 'name': 'Jian Jiao'}, {'authorId': '36730993', 'name': 'Denis Xavier Charles'}]",['Microsoft'],['United States'],2023-07,['industrial']
2307.08041,Yuying Ge,"Yuying Ge, Yixiao Ge, Ziyun Zeng, Xintao Wang and Ying Shan",Planting a SEED of Vision in Large Language Model,"Technical Report; Project released at:
  https://github.com/AILab-CVC/SEED",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  We present SEED, an elaborate image tokenizer that empowers Large Language Models (LLMs) with the emergent ability to SEE and Draw at the same time. Research on image tokenizers has previously reached an impasse, as frameworks employing quantized visual tokens have lost prominence due to subpar performance and convergence in multimodal comprehension (compared to BLIP-2, etc.) or generation (compared to Stable Diffusion, etc.). Despite the limitations, we remain confident in its natural capacity to unify visual and textual representations, facilitating scalable multimodal training with LLM's original recipe. In this study, we identify two crucial principles for the architecture and training of SEED that effectively ease subsequent alignment with LLMs. (1) Image tokens should be independent of 2D physical patch positions and instead be produced with a 1D causal dependency, exhibiting intrinsic interdependence that aligns with the left-to-right autoregressive prediction mechanism in LLMs. (2) Image tokens should capture high-level semantics consistent with the degree of semantic abstraction in words, and be optimized for both discriminativeness and reconstruction during the tokenizer training phase. As a result, the off-the-shelf LLM is able to perform both image-to-text and text-to-image generation by incorporating our SEED through efficient LoRA tuning. Comprehensive multimodal pretraining and instruction tuning, which may yield improved results, are reserved for future investigation. This version of SEED was trained in 5.7 days using only 64 V100 GPUs and 5M publicly available image-text pairs. Our preliminary study emphasizes the great potential of discrete visual tokens in versatile multimodal LLMs and the importance of proper image tokenizers in broader research. ","[{'version': 'v1', 'created': 'Sun, 16 Jul 2023 13:41:39 GMT'}, {'version': 'v2', 'created': 'Sat, 12 Aug 2023 04:42:29 GMT'}]",2023-08-15,"[['Ge', 'Yuying', ''], ['Ge', 'Yixiao', ''], ['Zeng', 'Ziyun', ''], ['Wang', 'Xintao', ''], ['Shan', 'Ying', '']]",0,0,2023-07-16,2,5,1,0,0,0,40298b8d50109c52fc10763eddc64a07cf8acb31,259937351.0,https://www.semanticscholar.org/paper/40298b8d50109c52fc10763eddc64a07cf8acb31,arXiv.org,2023.0,31.0,11.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51123495', 'name': 'Yuying Ge'}, {'authorId': '152988335', 'name': 'Yixiao Ge'}, {'authorId': '2150468893', 'name': 'Ziyun Zeng'}, {'authorId': '47119707', 'name': 'Xintao Wang'}, {'authorId': '1387190008', 'name': 'Ying Shan'}]",['Tencent'],['China'],2023-07,['industrial']
2307.08074,Longyue Wang,"Longyue Wang, Zefeng Du, Donghuai Liu, Deng Cai, Dian Yu, Haiyun
  Jiang, Yan Wang, Leyang Cui, Shuming Shi, Zhaopeng Tu",Disco-Bench: A Discourse-Aware Evaluation Benchmark for Language Modelling,Zhaopeng Tu is the corresponding author,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Modeling discourse -- the linguistic phenomena that go beyond individual sentences, is a fundamental yet challenging aspect of natural language processing (NLP). However, existing evaluation benchmarks primarily focus on the evaluation of inter-sentence properties and overlook critical discourse phenomena that cross sentences. To bridge the gap, we propose Disco-Bench, a benchmark that can evaluate intra-sentence discourse properties across a diverse set of NLP tasks, covering understanding, translation, and generation. Disco-Bench consists of 9 document-level testsets in the literature domain, which contain rich discourse phenomena (e.g. cohesion and coherence) in Chinese and/or English. For linguistic analysis, we also design a diagnostic test suite that can examine whether the target models learn discourse knowledge. We totally evaluate 20 general-, in-domain and commercial models based on Transformer, advanced pretraining architectures and large language models (LLMs). Our results show (1) the challenge and necessity of our evaluation benchmark; (2) fine-grained pretraining based on literary document-level training data consistently improves the modeling of discourse information. We will release the datasets, pretrained models, and leaderboard, which we hope can significantly facilitate research in this field: https://github.com/longyuewangdcu/Disco-Bench. ","[{'version': 'v1', 'created': 'Sun, 16 Jul 2023 15:18:25 GMT'}, {'version': 'v2', 'created': 'Sat, 22 Jul 2023 00:11:24 GMT'}]",2023-07-25,"[['Wang', 'Longyue', ''], ['Du', 'Zefeng', ''], ['Liu', 'Donghuai', ''], ['Cai', 'Deng', ''], ['Yu', 'Dian', ''], ['Jiang', 'Haiyun', ''], ['Wang', 'Yan', ''], ['Cui', 'Leyang', ''], ['Shi', 'Shuming', ''], ['Tu', 'Zhaopeng', '']]",0,0,2023-07-16,2,10,2,0,0,0,e1c957e0cb6098304deffb01e4428eb368f8e1ff,259937062.0,https://www.semanticscholar.org/paper/e1c957e0cb6098304deffb01e4428eb368f8e1ff,arXiv.org,2023.0,86.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1800190', 'name': 'Longyue Wang'}, {'authorId': '2112455515', 'name': 'Zefeng Du'}, {'authorId': '2152510456', 'name': 'Donghua Liu'}, {'authorId': '2223597668', 'name': 'Cai Deng'}, {'authorId': '150978762', 'name': 'Dian Yu'}, {'authorId': '48579460', 'name': 'Haiyun Jiang'}, {'authorId': '2159128007', 'name': 'Yan Wang'}, {'authorId': '152496687', 'name': 'Leyang Cui'}, {'authorId': '2072684668', 'name': 'Shuming Shi'}, {'authorId': '2909321', 'name': 'Zhaopeng Tu'}]","['Tencent', 'Viseen Building, Gaoxin 10th South Road, Nanshan District, Shenzhen, China.']",['China'],2023-07,"['industrial', 'industrial']"
2307.08813,Gilchan Park,"Gilchan Park, Byung-Jun Yoon, Xihaier Luo, Vanessa L\'opez-Marrero,
  Patrick Johnstone, Shinjae Yoo, Francis J. Alexander",Comparative Performance Evaluation of Large Language Models for Extracting Molecular Interactions and Pathway Knowledge,"10 pages, 3 figures",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Understanding protein interactions and pathway knowledge is crucial for unraveling the complexities of living systems and investigating the underlying mechanisms of biological functions and complex diseases. While existing databases provide curated biological data from literature and other sources, they are often incomplete and their maintenance is labor-intensive, necessitating alternative approaches. In this study, we propose to harness the capabilities of large language models to address these issues by automatically extracting such knowledge from the relevant scientific literature. Toward this goal, in this work, we investigate the effectiveness of different large language models in tasks that involve recognizing protein interactions, pathways, and gene regulatory relations. We thoroughly evaluate the performance of various models, highlight the significant findings, and discuss both the future opportunities and the remaining challenges associated with this approach. The code and data are available at: https://github.com/boxorange/BioIE-LLM ","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 20:01:11 GMT'}]",2023-07-19,"[['Park', 'Gilchan', ''], ['Yoon', 'Byung-Jun', ''], ['Luo', 'Xihaier', ''], ['López-Marrero', 'Vanessa', ''], ['Johnstone', 'Patrick', ''], ['Yoo', 'Shinjae', ''], ['Alexander', 'Francis J.', '']]",0,0,2023-07-17,1,7,2,0,0,0,a42200d76d2dcc136332125efcd28da68bd65d12,259951333.0,https://www.semanticscholar.org/paper/a42200d76d2dcc136332125efcd28da68bd65d12,arXiv.org,2023.0,39.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1430738869', 'name': 'Gilchan Park'}, {'authorId': '1736594', 'name': 'Byung-Jun Yoon'}, {'authorId': '145628558', 'name': 'Xihaier Luo'}, {'authorId': '2223762658', 'name': ""Vanessa L'opez-Marrero""}, {'authorId': '21671829', 'name': 'Patrick Johnstone'}, {'authorId': '2282774', 'name': 'Shinjae Yoo'}, {'authorId': '2068866955', 'name': 'Francis J. Alexander'}]",['Brookhaven National Laboratory'],['United States'],2023-07,['industrial']
2307.08823,Jonas Schuett,"Leonie Koessler, Jonas Schuett",Risk assessment at AGI companies: A review of popular risk assessment techniques from other safety-critical industries,"44 pages, 13 figures, 9 tables",,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Companies like OpenAI, Google DeepMind, and Anthropic have the stated goal of building artificial general intelligence (AGI) - AI systems that perform as well as or better than humans on a wide variety of cognitive tasks. However, there are increasing concerns that AGI would pose catastrophic risks. In light of this, AGI companies need to drastically improve their risk management practices. To support such efforts, this paper reviews popular risk assessment techniques from other safety-critical industries and suggests ways in which AGI companies could use them to assess catastrophic risks from AI. The paper discusses three risk identification techniques (scenario analysis, fishbone method, and risk typologies and taxonomies), five risk analysis techniques (causal mapping, Delphi technique, cross-impact analysis, bow tie analysis, and system-theoretic process analysis), and two risk evaluation techniques (checklists and risk matrices). For each of them, the paper explains how they work, suggests ways in which AGI companies could use them, discusses their benefits and limitations, and makes recommendations. Finally, the paper discusses when to conduct risk assessments, when to use which technique, and how to use any of them. The reviewed techniques will be obvious to risk management professionals in other industries. And they will not be sufficient to assess catastrophic risks from AI. However, AGI companies should not skip the straightforward step of reviewing best practices from other industries. ","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 20:36:51 GMT'}]",2023-07-19,"[['Koessler', 'Leonie', ''], ['Schuett', 'Jonas', '']]",0,0,2023-07-17,1,2,1,1,0,1,3270d292aa0ce0c01ca4fadfc0f355ff1d45d754,259951436.0,https://www.semanticscholar.org/paper/3270d292aa0ce0c01ca4fadfc0f355ff1d45d754,arXiv.org,2023.0,188.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2148827272', 'name': 'Leonie Koessler'}, {'authorId': '1388301316', 'name': 'Jonas Schuett'}]",['Centre for the Governance of AI'],['United Kingdom'],2023-07,['industrial']
2307.08876,Ted Selker PhD,Ted Selker,AI for the Generation and Testing of Ideas Towards an AI Supported Knowledge Development Environment,"8 pages, 21 references",,,,cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  New systems employ Machine Learning to sift through large knowledge sources, creating flexible Large Language Models. These models discern context and predict sequential information in various communication forms. Generative AI, leveraging Transformers, generates textual or visual outputs mimicking human responses. It proposes one or multiple contextually feasible solutions for a user to contemplate. However, generative AI does not currently support traceability of ideas, a useful feature provided by search engines indicating origin of information. The narrative style of generative AI has gained positive reception. People learn from stories. Yet, early ChatGPT efforts had difficulty with truth, reference, calculations, and aspects like accurate maps. Current capabilities of referencing locations and linking to apps seem to be better catered by the link-centric search methods we've used for two decades. Deploying truly believable solutions extends beyond simulating contextual relevance as done by generative AI. Combining the creativity of generative AI with the provenance of internet sources in hybrid scenarios could enhance internet usage. Generative AI, viewed as drafts, stimulates thinking, offering alternative ideas for final versions or actions. Scenarios for information requests are considered. We discuss how generative AI can boost idea generation by eliminating human bias. We also describe how search can verify facts, logic, and context. The user evaluates these generated ideas for selection and usage. This paper introduces a system for knowledge workers, Generate And Search Test, enabling individuals to efficiently create solutions previously requiring top collaborations of experts. ","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 22:17:40 GMT'}]",2023-07-19,"[['Selker', 'Ted', '']]",1,1,2023-07-17,1,1,1,1,0,1,55118c071a675b428e25c33a5c1638215b6bc3fc,259951560.0,https://www.semanticscholar.org/paper/55118c071a675b428e25c33a5c1638215b6bc3fc,arXiv.org,2023.0,46.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2329375', 'name': 'T. Selker'}]",['Selker Design Research Palo Alto CA USA'],['United States'],2023-07,['industrial']
2307.08962,Rithesh Murthy,"Rithesh Murthy, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Le
  Xue, Weiran Yao, Yihao Feng, Zeyuan Chen, Akash Gokul, Devansh Arpit, Ran Xu,
  Phil Mui, Huan Wang, Caiming Xiong, Silvio Savarese",REX: Rapid Exploration and eXploitation for AI Agents,,,,,cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose an enhanced approach for Rapid Exploration and eXploitation for AI Agents called REX. Existing AutoGPT-style techniques have inherent limitations, such as a heavy reliance on precise descriptions for decision-making, and the lack of a systematic approach to leverage try-and-fail procedures akin to traditional Reinforcement Learning (RL). REX introduces an additional layer of rewards and integrates concepts similar to Upper Confidence Bound (UCB) scores, leading to more robust and efficient AI agent performance. This approach has the advantage of enabling the utilization of offline behaviors from logs and allowing seamless integration with existing foundation models while it does not require any model fine-tuning. Through comparative analysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA Planning(RAP), REX-based methods demonstrate comparable performance and, in certain cases, even surpass the results achieved by these existing techniques. Notably, REX-based methods exhibit remarkable reductions in execution time, enhancing their practical applicability across a diverse set of scenarios. ","[{'version': 'v1', 'created': 'Tue, 18 Jul 2023 04:26:33 GMT'}]",2023-07-19,"[['Murthy', 'Rithesh', ''], ['Heinecke', 'Shelby', ''], ['Niebles', 'Juan Carlos', ''], ['Liu', 'Zhiwei', ''], ['Xue', 'Le', ''], ['Yao', 'Weiran', ''], ['Feng', 'Yihao', ''], ['Chen', 'Zeyuan', ''], ['Gokul', 'Akash', ''], ['Arpit', 'Devansh', ''], ['Xu', 'Ran', ''], ['Mui', 'Phil', ''], ['Wang', 'Huan', ''], ['Xiong', 'Caiming', ''], ['Savarese', 'Silvio', '']]",0,1,2023-07-18,1,15,2,0,0,0,4c7fbfdd777b67d70ae203ef9c8a6a64a7faf26a,259951406.0,https://www.semanticscholar.org/paper/4c7fbfdd777b67d70ae203ef9c8a6a64a7faf26a,arXiv.org,2023.0,16.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2223748790', 'name': 'Rithesh Murthy'}, {'authorId': '71926704', 'name': 'Shelby Heinecke'}, {'authorId': '9200530', 'name': 'Juan Carlos Niebles'}, {'authorId': '2223887365', 'name': 'Zhiwei Liu'}, {'authorId': '2147380988', 'name': 'Le Xue'}, {'authorId': '2087699735', 'name': 'Weiran Yao'}, {'authorId': '22758695', 'name': 'Yihao Feng'}, {'authorId': '5478513', 'name': 'Zeyuan Chen'}, {'authorId': '1752893100', 'name': 'Akash Gokul'}, {'authorId': '2309967', 'name': 'Devansh Arpit'}, {'authorId': '2115800155', 'name': 'Ran Xu'}, {'authorId': '2122258484', 'name': 'P. Mùi'}, {'authorId': '46507194', 'name': 'Haiquan Wang'}, {'authorId': '2054594326', 'name': 'Caiming Xiong'}, {'authorId': '1702137', 'name': 'S. Savarese'}]","['Salesforce', 'Salesforce Research']",['United States'],2023-07,"['industrial', 'industrial']"
2307.09018,Anastasiya Belyaeva,"Anastasiya Belyaeva, Justin Cosentino, Farhad Hormozdiari, Krish
  Eswaran, Shravya Shetty, Greg Corrado, Andrew Carroll, Cory Y. McLean,
  Nicholas A. Furlotte",Multimodal LLMs for health grounded in individual-specific data,,,,,q-bio.QM cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Foundation large language models (LLMs) have shown an impressive ability to solve tasks across a wide range of fields including health. To effectively solve personalized health tasks, LLMs need the ability to ingest a diversity of data modalities that are relevant to an individual's health status. In this paper, we take a step towards creating multimodal LLMs for health that are grounded in individual-specific data by developing a framework (HeLM: Health Large Language Model for Multimodal Understanding) that enables LLMs to use high-dimensional clinical modalities to estimate underlying disease risk. HeLM encodes complex data modalities by learning an encoder that maps them into the LLM's token embedding space and for simple modalities like tabular data by serializing the data into text. Using data from the UK Biobank, we show that HeLM can effectively use demographic and clinical features in addition to high-dimensional time-series data to estimate disease risk. For example, HeLM achieves an AUROC of 0.75 for asthma prediction when combining tabular and spirogram data modalities compared with 0.49 when only using tabular data. Overall, we find that HeLM outperforms or performs at parity with classical machine learning approaches across a selection of eight binary traits. Furthermore, we investigate the downstream uses of this model such as its generalizability to out-of-distribution traits and its ability to power conversations around individual health and wellness. ","[{'version': 'v1', 'created': 'Tue, 18 Jul 2023 07:12:46 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Jul 2023 06:35:34 GMT'}]",2023-07-21,"[['Belyaeva', 'Anastasiya', ''], ['Cosentino', 'Justin', ''], ['Hormozdiari', 'Farhad', ''], ['Eswaran', 'Krish', ''], ['Shetty', 'Shravya', ''], ['Corrado', 'Greg', ''], ['Carroll', 'Andrew', ''], ['McLean', 'Cory Y.', ''], ['Furlotte', 'Nicholas A.', '']]",0,0,2023-07-18,2,9,2,0,0,0,8ab6174791a0299e779804300142237d1669c743,259951115.0,https://www.semanticscholar.org/paper/8ab6174791a0299e779804300142237d1669c743,arXiv.org,2023.0,40.0,6.0,1.0,True,"['Computer Science', 'Biology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144140638', 'name': 'A. Belyaeva'}, {'authorId': '1388784597', 'name': 'J. Cosentino'}, {'authorId': '2420527', 'name': 'F. Hormozdiari'}, {'authorId': '1442214202', 'name': 'K. Eswaran'}, {'authorId': '2894170', 'name': 'S. Shetty'}, {'authorId': '1472894007', 'name': 'Greg C. Corrado'}, {'authorId': '51023969', 'name': 'A. Carroll'}, {'authorId': '6322777', 'name': 'C. McLean'}, {'authorId': '3238315', 'name': 'N. Furlotte'}]",['Google'],['United States'],2023-07,['industrial']
2307.09683,Qiao Jin,"Qiao Jin, Robert Leaman, Zhiyong Lu",PubMed and Beyond: Biomedical Literature Search in the Age of Artificial Intelligence,"27 pages, 6 figures, 36 tools",,,,cs.IR cs.AI cs.DL,http://creativecommons.org/licenses/by/4.0/,"  Biomedical research yields a wealth of information, much of which is only accessible through the literature. Consequently, literature search is an essential tool for building on prior knowledge in clinical and biomedical research. Although recent improvements in artificial intelligence have expanded functionality beyond keyword-based search, these advances may be unfamiliar to clinicians and researchers. In response, we present a survey of literature search tools tailored to both general and specific information needs in biomedicine, with the objective of helping readers efficiently fulfill their information needs. We first examine the widely used PubMed search engine, discussing recent improvements and continued challenges. We then describe literature search tools catering to five specific information needs: 1. Identifying high-quality clinical research for evidence-based medicine. 2. Retrieving gene-related information for precision medicine and genomics. 3. Searching by meaning, including natural language questions. 4. Locating related articles with literature recommendation. 5. Mining literature to discover associations between concepts such as diseases and genetic variants. Additionally, we cover practical considerations and best practices for choosing and using these tools. Finally, we provide a perspective on the future of literature search engines, considering recent breakthroughs in large language models such as ChatGPT. In summary, our survey provides a comprehensive view of biomedical literature search functionalities with 36 publicly available tools. ","[{'version': 'v1', 'created': 'Tue, 18 Jul 2023 23:35:53 GMT'}, {'version': 'v2', 'created': 'Mon, 24 Jul 2023 15:41:03 GMT'}, {'version': 'v3', 'created': 'Thu, 21 Sep 2023 13:55:48 GMT'}]",2023-09-22,"[['Jin', 'Qiao', ''], ['Leaman', 'Robert', ''], ['Lu', 'Zhiyong', '']]",1,1,2023-07-18,3,3,3,1,0,1,55f83b1cfba60639ead5273e074933ef69b6007b,262084452.0,https://www.semanticscholar.org/paper/55f83b1cfba60639ead5273e074933ef69b6007b,,2023.0,94.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144255060', 'name': 'Qiao Jin'}, {'authorId': '2139764362', 'name': 'Robert Leaman'}, {'authorId': '2237094367', 'name': 'Zhiyong Lu'}]",['National Center for Biotechnology Information'],['United States'],2023-07,['industrial']
2307.09702,Brandon T. Willard,Brandon T. Willard and R\'emi Louf,Efficient Guided Generation for Large Language Models,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this article we show how the problem of neural text generation can be constructively reformulated in terms of transitions between the states of a finite-state machine. This framework leads to an efficient approach to guiding text generation with regular expressions and context-free grammars by allowing the construction of an index over a language model's vocabulary. The approach is model agnostic, allows one to enforce domain-specific knowledge and constraints, and enables the construction of reliable interfaces by guaranteeing the structure of the generated text. It adds little overhead to the token sequence generation process and significantly outperforms existing solutions. An implementation is provided in the open source Python library Outlines ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 01:14:49 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Jul 2023 00:40:41 GMT'}, {'version': 'v3', 'created': 'Sat, 12 Aug 2023 21:09:44 GMT'}, {'version': 'v4', 'created': 'Sat, 19 Aug 2023 21:27:51 GMT'}]",2023-08-22,"[['Willard', 'Brandon T.', ''], ['Louf', 'Rémi', '']]",0,0,2023-07-19,4,2,2,0,0,0,172ce3f37c0f1eb38040b3ee90f527eaac9f97f6,260278488.0,https://www.semanticscholar.org/paper/172ce3f37c0f1eb38040b3ee90f527eaac9f97f6,arXiv.org,2023.0,21.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '39153647', 'name': 'Brandon T. Willard'}, {'authorId': '2185329', 'name': 'Rémi Louf'}]","['Normal Computing 2023-07-14', 'Normal Computing']",,2023-07,"['industrial', 'industrial']"
2307.10022,Konstantinos Pitas,Konstantinos Pitas,Europepolls: A Dataset of Country-Level Opinion Polling Data for the European Union and the UK,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  I propose an open dataset of country-level historical opinion polling data for the European Union and the UK. The dataset aims to fill a gap in available opinion polling data for the European Union. Some existing datasets are restricted to the past five years, limiting research opportunities. At the same time, some larger proprietary datasets exist but are available only in a visual preprocessed time series format. Finally, while other large datasets for individual countries might exist, these could be inaccessible due to language barriers. The data was gathered from Wikipedia, and preprocessed using the pandas library. Both the raw and the preprocessed data are in the .csv format. I hope that given the recent advances in LLMs and deep learning in general, this large dataset will enable researchers to uncover complex interactions between multimodal data (news articles, economic indicators, social media) and voting behavior. The raw data, the preprocessed data, and the preprocessing scripts are available on GitHub. ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 15:05:55 GMT'}]",2023-07-20,"[['Pitas', 'Konstantinos', '']]",0,0,2023-07-19,1,1,1,0,0,0,746780e7a54978a5849a8ce890c938500afda99f,259982969.0,https://www.semanticscholar.org/paper/746780e7a54978a5849a8ce890c938500afda99f,arXiv.org,2023.0,16.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3208802', 'name': 'Konstantinos Pitas'}]",['Inria Grenoble - Rhône-Alpes research centre'],['France'],2023-07,['industrial']
2307.10188,Manoj Chandrasekharan,"Saurabh Pahune, Manoj Chandrasekharan",Several categories of Large Language Models (LLMs): A Short Survey,,,10.22214/ijraset.2023.54677,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models(LLMs)have become effective tools for natural language processing and have been used in many different fields. This essay offers a succinct summary of various LLM subcategories. The survey emphasizes recent developments and efforts made for various LLM kinds, including task-based financial LLMs, multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models. The survey gives a general summary of the methods, attributes, datasets, transformer models, and comparison metrics applied in each category of LLMs. Furthermore, it highlights unresolved problems in the field of developing chatbots and virtual assistants, such as boosting natural language processing, enhancing chatbot intelligence, and resolving moral and legal dilemmas. The purpose of this study is to provide readers, developers, academics, and users interested in LLM-based chatbots and virtual intelligent assistant technologies with useful information and future directions. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 18:18:23 GMT'}]",2023-07-21,"[['Pahune', 'Saurabh', ''], ['Chandrasekharan', 'Manoj', '']]",0,0,2023-07-05,1,2,2,0,0,0,1e3ef48abeef882e12f9553a1baf8944f3782c88,259879569.0,https://www.semanticscholar.org/paper/1e3ef48abeef882e12f9553a1baf8944f3782c88,International Journal for Research in Applied Science and Engineering Technology,2023.0,139.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2222525872', 'name': 'Saurabh Pahune'}, {'authorId': '2223291433', 'name': 'Manoj Chandrasekharan'}]",['Cardinal Health (United States)'],['United States'],2023-07,['industrial']
2307.10214,Davide Sanvito,"Giuseppe Siracusano, Davide Sanvito, Roberto Gonzalez, Manikantan
  Srinivasan, Sivakaman Kamatchi, Wataru Takahashi, Masaru Kawakita, Takahiro
  Kakumaru, Roberto Bifulco",Time for aCTIon: Automated Analysis of Cyber Threat Intelligence in the Wild,,,,,cs.CR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cyber Threat Intelligence (CTI) plays a crucial role in assessing risks and enhancing security for organizations. However, the process of extracting relevant information from unstructured text sources can be expensive and time-consuming. Our empirical experience shows that existing tools for automated structured CTI extraction have performance limitations. Furthermore, the community lacks a common benchmark to quantitatively assess their performance. We fill these gaps providing a new large open benchmark dataset and aCTIon, a structured CTI information extraction tool. The dataset includes 204 real-world publicly available reports and their corresponding structured CTI information in STIX format. Our team curated the dataset involving three independent groups of CTI analysts working over the course of several months. To the best of our knowledge, this dataset is two orders of magnitude larger than previously released open source datasets. We then design aCTIon, leveraging recently introduced large language models (GPT3.5) in the context of two custom information extraction pipelines. We compare our method with 10 solutions presented in previous work, for which we develop our own implementations when open-source implementations were lacking. Our results show that aCTIon outperforms previous work for structured CTI extraction with an improvement of the F1-score from 10%points to 50%points across all tasks. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 13:43:16 GMT'}]",2023-07-21,"[['Siracusano', 'Giuseppe', ''], ['Sanvito', 'Davide', ''], ['Gonzalez', 'Roberto', ''], ['Srinivasan', 'Manikantan', ''], ['Kamatchi', 'Sivakaman', ''], ['Takahashi', 'Wataru', ''], ['Kawakita', 'Masaru', ''], ['Kakumaru', 'Takahiro', ''], ['Bifulco', 'Roberto', '']]",0,1,2023-07-14,1,9,2,1,0,1,116fe7bbb1910f506ca52874352b7c99b4b1488a,259991762.0,https://www.semanticscholar.org/paper/116fe7bbb1910f506ca52874352b7c99b4b1488a,arXiv.org,2023.0,63.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48710117', 'name': 'G. Siracusano'}, {'authorId': '3109801', 'name': 'D. Sanvito'}, {'authorId': '2109141737', 'name': 'Roberto González'}, {'authorId': '2540412', 'name': 'Manikantan Srinivasan'}, {'authorId': '2215650893', 'name': 'S. Kamatchi'}, {'authorId': '2059695503', 'name': 'Wataru Takahashi'}, {'authorId': '31990183', 'name': 'Masaru Kawakita'}, {'authorId': '3277863', 'name': 'Takahiro Kakumaru'}, {'authorId': '1707367', 'name': 'R. Bifulco'}]","['NEC Corporation India', 'NEC Laboratories Europe']",['India'],2023-07,"['industrial', 'industrial']"
2307.13383,Michele Tufano,"Michele Tufano, Shubham Chandel, Anisha Agarwal, Neel Sundaresan,
  Colin Clement",Predicting Code Coverage without Execution,,,,,cs.SE cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Code coverage is a widely used metric for quantifying the extent to which program elements, such as statements or branches, are executed during testing. Calculating code coverage is resource-intensive, requiring code building and execution with additional overhead for the instrumentation. Furthermore, computing coverage of any snippet of code requires the whole program context. Using Machine Learning to amortize this expensive process could lower the cost of code coverage by requiring only the source code context, and the task of code coverage prediction can be a novel benchmark for judging the ability of models to understand code. We propose a novel benchmark task called Code Coverage Prediction for Large Language Models (LLMs). We formalize this task to evaluate the capability of LLMs in understanding code execution by determining which lines of a method are executed by a given test case and inputs. We curate and release a dataset we call COVERAGEEVAL by executing tests and code from the HumanEval dataset and collecting code coverage information. We report the performance of four state-of-the-art LLMs used for code-related tasks, including OpenAI's GPT-4 and GPT-3.5-Turbo, Google's BARD, and Anthropic's Claude, on the Code Coverage Prediction task. Finally, we argue that code coverage as a metric and pre-training data source are valuable for overall LLM performance on software engineering tasks. ","[{'version': 'v1', 'created': 'Tue, 25 Jul 2023 10:07:02 GMT'}]",2023-07-26,"[['Tufano', 'Michele', ''], ['Chandel', 'Shubham', ''], ['Agarwal', 'Anisha', ''], ['Sundaresan', 'Neel', ''], ['Clement', 'Colin', '']]",0,1,2023-07-25,1,5,2,4,0,4,2b80a368755c4d2ac941d912ba54d5bff5c90904,260154969.0,https://www.semanticscholar.org/paper/2b80a368755c4d2ac941d912ba54d5bff5c90904,arXiv.org,2023.0,15.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40626221', 'name': 'Michele Tufano'}, {'authorId': '145536500', 'name': 'Shubham Chandel'}, {'authorId': '2224761282', 'name': 'Anisha Agarwal'}, {'authorId': '145507437', 'name': 'Neel Sundaresan'}, {'authorId': '2064509404', 'name': 'Colin B. Clement'}]","['Redmond, WA, USA']",['United States'],2023-07,['industrial']
2307.13779,Ala Nekouvaght Tak,Ala N. Tak and Jonathan Gratch,Is GPT a Computational Model of Emotion? Detailed Analysis,,,,,cs.CL cs.AI cs.CY cs.HC,http://creativecommons.org/licenses/by/4.0/,"  This paper investigates the emotional reasoning abilities of the GPT family of large language models via a component perspective. The paper first examines how the model reasons about autobiographical memories. Second, it systematically varies aspects of situations to impact emotion intensity and coping tendencies. Even without the use of prompt engineering, it is shown that GPT's predictions align significantly with human-provided appraisals and emotional labels. However, GPT faces difficulties predicting emotion intensity and coping responses. GPT-4 showed the highest performance in the initial study but fell short in the second, despite providing superior results after minor prompt engineering. This assessment brings up questions on how to effectively employ the strong points and address the weak areas of these models, particularly concerning response variability. These studies underscore the merits of evaluating models from a componential perspective. ","[{'version': 'v1', 'created': 'Tue, 25 Jul 2023 19:34:44 GMT'}]",2023-07-27,"[['Tak', 'Ala N.', ''], ['Gratch', 'Jonathan', '']]",0,1,2023-07-25,1,2,4,1,0,1,4dd461b2392a6983d36618744d2384349c4170f9,260164676.0,https://www.semanticscholar.org/paper/4dd461b2392a6983d36618744d2384349c4170f9,arXiv.org,2023.0,8.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '1658812302', 'name': 'Ala Nekouvaght Tak'}, {'authorId': '145438097', 'name': 'J. Gratch'}]",['USC Institute for Creative Technologies'],['United States'],2023-07,['industrial']
2308.10168,Kai Sun,"Kai Sun, Yifan Ethan Xu, Hanwen Zha, Yue Liu, Xin Luna Dong",Head-to-Tail: How Knowledgeable are Large Language Models (LLM)? A.K.A. Will LLMs Replace Knowledge Graphs?,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Since the recent prosperity of Large Language Models (LLMs), there have been interleaved discussions regarding how to reduce hallucinations from LLM responses, how to increase the factuality of LLMs, and whether Knowledge Graphs (KGs), which store the world knowledge in a symbolic form, will be replaced with LLMs. In this paper, we try to answer these questions from a new angle: How knowledgeable are LLMs?   To answer this question, we constructed Head-to-Tail, a benchmark that consists of 18K question-answer (QA) pairs regarding head, torso, and tail facts in terms of popularity. We designed an automated evaluation method and a set of metrics that closely approximate the knowledge an LLM confidently internalizes. Through a comprehensive evaluation of 14 publicly available LLMs, we show that existing LLMs are still far from being perfect in terms of their grasp of factual knowledge, especially for facts of torso-to-tail entities. ","[{'version': 'v1', 'created': 'Sun, 20 Aug 2023 05:31:03 GMT'}]",2023-08-22,"[['Sun', 'Kai', ''], ['Xu', 'Yifan Ethan', ''], ['Zha', 'Hanwen', ''], ['Liu', 'Yue', ''], ['Dong', 'Xin Luna', '']]",0,0,2023-08-20,1,5,1,0,0,0,fb00016c1e048b9373803add001c1ec7e877cb23,261048922.0,https://www.semanticscholar.org/paper/fb00016c1e048b9373803add001c1ec7e877cb23,arXiv.org,2023.0,46.0,22.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","[{'authorId': '49871029', 'name': 'Kai Sun'}, {'authorId': '15574937', 'name': 'Y. Xu'}, {'authorId': '47291370', 'name': 'Hanwen Zha'}, {'authorId': '2229372676', 'name': 'Yue Liu'}, {'authorId': '2152050780', 'name': 'Xinhsuai Dong'}]",['Meta'],['United States'],2023-08,['industrial']
2308.10345,David Noever,David Noever,Can Large Language Models Find And Fix Vulnerable Software?,,,,,cs.SE cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this study, we evaluated the capability of Large Language Models (LLMs), particularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing their performance against traditional static code analyzers like Snyk and Fortify. Our analysis covered numerous repositories, including those from NASA and the Department of Defense. GPT-4 identified approximately four times the vulnerabilities than its counterparts. Furthermore, it provided viable fixes for each vulnerability, demonstrating a low rate of false positives. Our tests encompassed 129 code samples across eight programming languages, revealing the highest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to a 90% reduction in vulnerabilities, requiring only an 11% increase in code lines. A critical insight was LLMs' ability to self-audit, suggesting fixes for their identified vulnerabilities and underscoring their precision. Future research should explore system-level vulnerabilities and integrate multiple static code analyzers for a holistic perspective on LLMs' potential. ","[{'version': 'v1', 'created': 'Sun, 20 Aug 2023 19:33:12 GMT'}]",2023-08-22,"[['Noever', 'David', '']]",0,1,2023-08-20,1,1,2,1,0,1,eb9246a8cb8b53b157fdb863a41958041cc50258,261049051.0,https://www.semanticscholar.org/paper/eb9246a8cb8b53b157fdb863a41958041cc50258,arXiv.org,2023.0,36.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46787948', 'name': 'David Noever'}]","['4901-D Corporate Drive, Huntsville, AL, USA, 35805']",['United States'],2023-08,['industrial']
2308.10379,Bilgehan Sel,"Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Ruoxi Jia, Ming Jin",Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Current literature, aiming to surpass the ""Chain-of-Thought"" approach, often resorts to an external modus operandi involving halting, modifying, and then resuming the generation process to boost Large Language Models' (LLMs) reasoning capacities. This mode escalates the number of query requests, leading to increased costs, memory, and computational overheads. Addressing this, we propose the Algorithm of Thoughts -- a novel strategy that propels LLMs through algorithmic reasoning pathways, pioneering a new mode of in-context learning. By employing algorithmic examples, we exploit the innate recurrence dynamics of LLMs, expanding their idea exploration with merely one or a few queries. Our technique outperforms earlier single-query methods and stands on par with a recent multi-query strategy that employs an extensive tree search algorithm. Intriguingly, our results suggest that instructing an LLM using an algorithm can lead to performance surpassing that of the algorithm itself, hinting at LLM's inherent ability to weave its intuition into optimized searches. We probe into the underpinnings of our method's efficacy and its nuances in application. ","[{'version': 'v1', 'created': 'Sun, 20 Aug 2023 22:36:23 GMT'}, {'version': 'v2', 'created': 'Thu, 28 Sep 2023 11:28:24 GMT'}]",2023-09-29,"[['Sel', 'Bilgehan', ''], ['Al-Tawaha', 'Ahmad', ''], ['Khattar', 'Vanshaj', ''], ['Jia', 'Ruoxi', ''], ['Jin', 'Ming', '']]",0,0,2023-08-20,2,5,2,0,0,0,fca92fe287c44c9ec79ca1f2762b0bf2e5e8df2b,261049794.0,https://www.semanticscholar.org/paper/fca92fe287c44c9ec79ca1f2762b0bf2e5e8df2b,arXiv.org,2023.0,48.0,11.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2090055589', 'name': 'Bilgehan Sel'}, {'authorId': '2121379922', 'name': 'Ahmad S. Al-Tawaha'}, {'authorId': '1515859806', 'name': 'Vanshaj Khattar'}, {'authorId': '2153518376', 'name': 'Lucy Wang'}, {'authorId': '39823639', 'name': 'R. Jia'}, {'authorId': '2072905592', 'name': 'Ming Jin'}]",['Virginia Tech'],['United States'],2023-08,['industrial']
2308.10633,Yasuto Hoshi,"Yasuto Hoshi, Daisuke Miyashita, Youyang Ng, Kento Tatsuno, Yasuhiro
  Morioka, Osamu Torii, Jun Deguchi",RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models,"18 pages, 2 figures, see https://youtu.be/JYbm75qnfTg for the
  demonstration screencast",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Retrieval-augmented large language models (R-LLMs) combine pre-trained large language models (LLMs) with information retrieval systems to improve the accuracy of factual question-answering. However, current libraries for building R-LLMs provide high-level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation. To address this gap, we present RaLLe, an open-source framework designed to facilitate the development, evaluation, and optimization of R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily develop and evaluate R-LLMs, improving hand-crafted prompts, assessing individual inference processes, and objectively measuring overall system performance quantitatively. By leveraging these features, developers can enhance the performance and accuracy of their R-LLMs in knowledge-intensive generation tasks. We open-source our code at https://github.com/yhoshi3/RaLLe. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 11:08:16 GMT'}]",2023-08-22,"[['Hoshi', 'Yasuto', ''], ['Miyashita', 'Daisuke', ''], ['Ng', 'Youyang', ''], ['Tatsuno', 'Kento', ''], ['Morioka', 'Yasuhiro', ''], ['Torii', 'Osamu', ''], ['Deguchi', 'Jun', '']]",0,0,2023-08-21,1,7,2,0,0,0,c055baf5e8586edace51d1a7720de3c4ed345d72,261049520.0,https://www.semanticscholar.org/paper/c055baf5e8586edace51d1a7720de3c4ed345d72,arXiv.org,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2211101536', 'name': 'Yasuto Hoshi'}, {'authorId': '2441156', 'name': 'D. Miyashita'}, {'authorId': '20556792', 'name': 'Youyang Ng'}, {'authorId': '2232784235', 'name': 'Kento Tatsuno'}, {'authorId': '51194024', 'name': 'Yasuhiro Morioka'}, {'authorId': '2422593', 'name': 'Osamu Torii'}, {'authorId': '49192096', 'name': 'J. Deguchi'}]","['Kioxia Corporation, Japan']",['Japan'],2023-08,['industrial']
2308.10755,Bin Wang,"Conghui He, Zhenjiang Jin, Chao Xu, Jiantao Qiu, Bin Wang, Wei Li,
  Hang Yan, Jiaqi Wang, Dahua Lin",WanJuan: A Comprehensive Multimodal Dataset for Advancing English and Chinese Large Models,Technical Report,,,,cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The rise in popularity of ChatGPT and GPT-4 has significantly accelerated the development of large models, leading to the creation of numerous impressive large language models(LLMs) and multimodal large language models (MLLMs). These cutting-edge models owe their remarkable performance to high-quality data. However, the details of the training data used in leading paradigms are often kept confidential. This lack of transparency, coupled with the scarcity of open-source data, impedes further developments within the community. As a response, this paper presents ""Wan Juan"", a large-scale multimodal dataset composed of both Chinese and English data, collected from a wide range of web sources. The dataset incorporates text, image-text, and video modalities, with a total volume exceeding 2TB. It was utilized in the training of InternLM, a model that demonstrated significant advantages in multi-dimensional evaluations when compared to models of a similar scale. All data can be accessed at https://opendatalab.org.cn/WanJuan1.0. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 14:40:48 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Aug 2023 02:57:45 GMT'}, {'version': 'v3', 'created': 'Fri, 15 Sep 2023 09:52:14 GMT'}]",2023-09-18,"[['He', 'Conghui', ''], ['Jin', 'Zhenjiang', ''], ['Xu', 'Chao', ''], ['Qiu', 'Jiantao', ''], ['Wang', 'Bin', ''], ['Li', 'Wei', ''], ['Yan', 'Hang', ''], ['Wang', 'Jiaqi', ''], ['Lin', 'Dahua', '']]",1,1,2023-08-21,3,9,2,2,0,2,afb39ed837db8750dd1c3b2a54ad442372c106b2,261049100.0,https://www.semanticscholar.org/paper/afb39ed837db8750dd1c3b2a54ad442372c106b2,arXiv.org,2023.0,18.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3486481', 'name': 'Conghui He'}, {'authorId': '2232929856', 'name': 'Zhenjiang Jin'}, {'authorId': '46200183', 'name': 'Chaoxi Xu'}, {'authorId': '1848503', 'name': 'Jiantao Qiu'}, {'authorId': '2256857728', 'name': 'Bin Wang'}, {'authorId': '2256598803', 'name': 'Wei Li'}, {'authorId': '146948229', 'name': 'Hang Yan'}, {'authorId': '2143074003', 'name': 'Jiaqi Wang'}, {'authorId': '2116442295', 'name': 'Da Lin'}]",['Shanghai Artificial Intelligence Laboratory'],['China'],2023-08,['industrial']
2308.11483,Pouya Pezeshkpour,"Pouya Pezeshkpour, Estevam Hruschka",Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have demonstrated remarkable capabilities in various NLP tasks. However, previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models. As these models become more powerful, it becomes imperative to understand and address these limitations. In this paper, we focus on LLMs robustness on the task of multiple-choice questions -- commonly adopted task to study reasoning and fact-retrieving capability of LLMs. Investigating the sensitivity of LLMs towards the order of options in multiple-choice questions, we demonstrate a considerable performance gap of approximately 13% to 75% in LLMs on different benchmarks, when answer options are reordered, even when using demonstrations in a few-shot setting. Through a detailed analysis, we conjecture that this sensitivity arises when LLMs are uncertain about the prediction between the top-2/3 choices, and specific options placements may favor certain prediction between those top choices depending on the question caused by positional bias. We also identify patterns in top-2 choices that amplify or mitigate the model's bias toward option placement. We found that for amplifying bias, the optimal strategy involves positioning the top two choices as the first and last options. Conversely, to mitigate bias, we recommend placing these choices among the adjacent options. To validate our conjecture, we conduct various experiments and adopt two approaches to calibrate LLMs' predictions, leading to up to 8 percentage points improvement across different models and benchmarks. ","[{'version': 'v1', 'created': 'Tue, 22 Aug 2023 14:54:59 GMT'}]",2023-08-23,"[['Pezeshkpour', 'Pouya', ''], ['Hruschka', 'Estevam', '']]",0,0,2023-08-22,1,2,3,0,0,0,fd81018bc72b030545a2d3f3010f3758ec4d48c3,261064970.0,https://www.semanticscholar.org/paper/fd81018bc72b030545a2d3f3010f3758ec4d48c3,arXiv.org,2023.0,24.0,13.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '1713436', 'name': 'Pouya Pezeshkpour'}, {'authorId': '1842532', 'name': 'Estevam Hruschka'}]",['Laboratori Guglielmo Marconi (Italy)'],['Italy'],2023-08,['industrial']
2308.11526,Pranjal Gupta,"Pranjal Gupta and Harshit Kumar and Debanjana Kar and Karan Bhukar and
  Pooja Aggarwal and Prateeti Mohapatra",Learning Representations on Logs for AIOps,"11 pages, 2023 IEEE 16th International Conference on Cloud Computing
  (CLOUD)",,,,cs.CL cs.AI cs.SE,http://creativecommons.org/licenses/by/4.0/,"  AI for IT Operations (AIOps) is a powerful platform that Site Reliability Engineers (SREs) use to automate and streamline operational workflows with minimal human intervention. Automated log analysis is a critical task in AIOps as it provides key insights for SREs to identify and address ongoing faults. Tasks such as log format detection, log classification, and log parsing are key components of automated log analysis. Most of these tasks require supervised learning; however, there are multiple challenges due to limited labelled log data and the diverse nature of log data. Large Language Models (LLMs) such as BERT and GPT3 are trained using self-supervision on a vast amount of unlabeled data. These models provide generalized representations that can be effectively used for various downstream tasks with limited labelled data. Motivated by the success of LLMs in specific domains like science and biology, this paper introduces a LLM for log data which is trained on public and proprietary log data. The results of our experiments demonstrate that the proposed LLM outperforms existing models on multiple downstream tasks. In summary, AIOps powered by LLMs offers an efficient and effective solution for automating log analysis tasks and enabling SREs to focus on higher-level tasks. Our proposed LLM, trained on public and proprietary log data, offers superior performance on multiple downstream tasks, making it a valuable addition to the AIOps platform. ","[{'version': 'v1', 'created': 'Fri, 18 Aug 2023 20:34:46 GMT'}]",2023-08-23,"[['Gupta', 'Pranjal', ''], ['Kumar', 'Harshit', ''], ['Kar', 'Debanjana', ''], ['Bhukar', 'Karan', ''], ['Aggarwal', 'Pooja', ''], ['Mohapatra', 'Prateeti', '']]",0,1,2023-08-18,1,6,3,1,0,1,f6974a11315fa698dc584e9f09316d61f414e952,261064771.0,https://www.semanticscholar.org/paper/f6974a11315fa698dc584e9f09316d61f414e952,IEEE International Conference on Cloud Computing,2023.0,45.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2042299842', 'name': 'Pranjal Gupta'}, {'authorId': '145369847', 'name': 'Harshit Kumar'}, {'authorId': '29850167', 'name': 'Debanjana Kar'}, {'authorId': '2111874424', 'name': 'Karan Bhukar'}, {'authorId': '2070039961', 'name': 'Pooja Aggarwal'}, {'authorId': '39700099', 'name': 'P. Mohapatra'}]",['IBM Research - India'],['India'],2023-08,['industrial']
2308.11767,Ahmed Abdeen Hamed Ph.D,Ahmed Abdeen Hamed and Xindong Wu,Improving Detection of ChatGPT-Generated Fake Science Using Real Publication Text: Introducing xFakeBibs a Supervised-Learning Network Algorithm,"14 pages, 6 figures, 4 tables, 2 algorithms",,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  ChatGPT is becoming a new reality. In this paper, we show how to distinguish ChatGPT-generated publications from counterparts produced by scientists. Using a newly designed supervised Machine Learning algorithm, we demonstrate how to detect machine-generated publications from those produced by scientists. The algorithm was trained using 100 real publication abstracts, followed by a 10-fold calibration approach to establish a lower-upper bound range of acceptance. In the comparison with ChatGPT content, it was evident that ChatGPT contributed merely 23\% of the bigram content, which is less than 50\% of any of the other 10 calibrating folds. This analysis highlights a significant disparity in technical terms where ChatGPT fell short of matching real science. When categorizing the individual articles, the xFakeBibs algorithm accurately identified 98 out of 100 publications as fake, with 2 articles incorrectly classified as real publications. Though this work introduced an algorithmic approach that detected the ChatGPT-generated fake science with a high degree of accuracy, it remains challenging to detect all fake records. This work is indeed a step in the right direction to counter fake science and misinformation. ","[{'version': 'v1', 'created': 'Tue, 15 Aug 2023 23:22:37 GMT'}]",2023-08-24,"[['Hamed', 'Ahmed Abdeen', ''], ['Wu', 'Xindong', '']]",1,1,2023-08-15,1,2,2,1,0,1,dc118b205135647abf20630001f49953c39f9cd7,261076066.0,https://www.semanticscholar.org/paper/dc118b205135647abf20630001f49953c39f9cd7,arXiv.org,2023.0,40.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2851243', 'name': 'A. Hamed'}, {'authorId': '145739804', 'name': 'Xin Wu'}]","['Zhejiang Lab', 'Sano Centre for Computational Medicine, Clinical Data Science, Cracow, 30-072, Poland']","['China', 'Poland']",2023-08,"['industrial', 'industrial']"
2308.11827,Saba Rahimi,"Saba Rahimi, Tucker Balch, Manuela Veloso",Exploring the Effectiveness of GPT Models in Test-Taking: A Case Study of the Driver's License Knowledge Test,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models such as Open AI's Generative Pre-trained Transformer (GPT) models are proficient at answering questions, but their knowledge is confined to the information present in their training data. This limitation renders them ineffective when confronted with questions about recent developments or non-public documents. Our research proposes a method that enables GPT models to answer questions by employing context from an information source not previously included in their training data. The methodology includes preprocessing of contextual information, the embedding of contexts and queries, constructing prompt through the integration of context embeddings, and generating answers using GPT models. We applied this method in a controlled test scenario using the California Driver's Handbook as the information source. The GPT-3 model achieved a 96% passing score on a set of 50 sample driving knowledge test questions. In contrast, without context, the model's passing score fell to 82%. However, the model still fails to answer some questions correctly even with providing library of context, highlighting room for improvement. The research also examined the impact of prompt length and context format, on the model's performance. Overall, the study provides insights into the limitations and potential improvements for GPT models in question-answering tasks. ","[{'version': 'v1', 'created': 'Tue, 22 Aug 2023 23:18:53 GMT'}]",2023-08-24,"[['Rahimi', 'Saba', ''], ['Balch', 'Tucker', ''], ['Veloso', 'Manuela', '']]",0,1,2023-08-22,1,3,3,1,0,1,9a4f817e5302301c96e4e56389ead41b12658b01,261076160.0,https://www.semanticscholar.org/paper/9a4f817e5302301c96e4e56389ead41b12658b01,arXiv.org,2023.0,21.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2045687939', 'name': 'Saba Rahimi'}, {'authorId': '50412755', 'name': 'T. Balch'}, {'authorId': '2058284590', 'name': 'M. Veloso'}]","['AI Research, New York, NY, USA']",['United States'],2023-08,['industrial']
2308.12028,Hao Chen,"Chen hao, Xie Runfeng, Cui Xiangyang, Yan Zhou, Wang Xin, Xuan
  Zhanwei, Zhang Kai",LKPNR: LLM and KG for Personalized News Recommendation Framework,,,,,cs.IR cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Accurately recommending candidate news articles to users is a basic challenge faced by personalized news recommendation systems. Traditional methods are usually difficult to grasp the complex semantic information in news texts, resulting in unsatisfactory recommendation results. Besides, these traditional methods are more friendly to active users with rich historical behaviors. However, they can not effectively solve the ""long tail problem"" of inactive users. To address these issues, this research presents a novel general framework that combines Large Language Models (LLM) and Knowledge Graphs (KG) into semantic representations of traditional methods. In order to improve semantic understanding in complex news texts, we use LLMs' powerful text understanding ability to generate news representations containing rich semantic information. In addition, our method combines the information about news entities and mines high-order structural information through multiple hops in KG, thus alleviating the challenge of long tail distribution. Experimental results demonstrate that compared with various traditional models, the framework significantly improves the recommendation effect. The successful integration of LLM and KG in our framework has established a feasible path for achieving more accurate personalized recommendations in the news field. Our code is available at https://github.com/Xuan-ZW/LKPNR. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 09:39:18 GMT'}]",2023-08-24,"[['hao', 'Chen', ''], ['Runfeng', 'Xie', ''], ['Xiangyang', 'Cui', ''], ['Zhou', 'Yan', ''], ['Xin', 'Wang', ''], ['Zhanwei', 'Xuan', ''], ['Kai', 'Zhang', '']]",0,0,2023-08-23,1,7,2,0,0,0,b034b79a61513439ce3e2bca4cb90c55757af81e,261076481.0,https://www.semanticscholar.org/paper/b034b79a61513439ce3e2bca4cb90c55757af81e,arXiv.org,2023.0,36.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2257354591', 'name': 'Hao Chen'}, {'authorId': '116067006', 'name': 'Runfeng Xie'}, {'authorId': '2444361', 'name': 'Xia Cui'}, {'authorId': '2110096616', 'name': 'Zhou Yan'}, {'authorId': None, 'name': 'Xin Wang'}, {'authorId': '2233088576', 'name': 'Zhanwei Xuan'}, {'authorId': '2158520757', 'name': 'Kai Zhang'}]","[""State Key Laboratory of Communication Content Cognition, People's Daily Online, Beijing 100733, China""]",['China'],2023-08,['industrial']
2308.12097,Yijin Liu,"Yijin Liu, Xianfeng Zeng, Fandong Meng, Jie Zhou",Instruction Position Matters in Sequence Generation with Large Language Models,"Codes and results are at
  https://github.com/Adaxry/Post-Instruction/tree/main",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) are capable of performing conditional sequence generation tasks, such as translation or summarization, through instruction fine-tuning. The fine-tuning data is generally sequentially concatenated from a specific task instruction, an input sentence, and the corresponding response. Considering the locality modeled by the self-attention mechanism of LLMs, these models face the risk of instruction forgetting when generating responses for long input sentences. To mitigate this issue, we propose enhancing the instruction-following capability of LLMs by shifting the position of task instructions after the input sentences. Theoretical analysis suggests that our straightforward method can alter the model's learning focus, thereby emphasizing the training of instruction-following capabilities. Concurrently, experimental results demonstrate that our approach consistently outperforms traditional settings across various model scales (1B / 7B / 13B) and different sequence generation tasks (translation and summarization), without any additional data or annotation costs. Notably, our method significantly improves the zero-shot performance on conditional sequence generation, e.g., up to 9.7 BLEU points on WMT zero-shot translation tasks. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 12:36:57 GMT'}]",2023-08-24,"[['Liu', 'Yijin', ''], ['Zeng', 'Xianfeng', ''], ['Meng', 'Fandong', ''], ['Zhou', 'Jie', '']]",0,0,2023-08-23,1,4,1,0,0,0,639928ed560350e2700cd582057a675e86707ddb,261076308.0,https://www.semanticscholar.org/paper/639928ed560350e2700cd582057a675e86707ddb,arXiv.org,2023.0,45.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46398775', 'name': 'Yanjun Liu'}, {'authorId': '2152293624', 'name': 'Xianfeng Zeng'}, {'authorId': '33427918', 'name': 'Fandong Meng'}, {'authorId': '48128428', 'name': 'Jie Zhou'}]",['Tencent'],['China'],2023-08,['industrial']
2308.12129,Oluwatosin Ogundare,"Oluwatosin Ogundare, Gustavo Quiros Araya, Ioannis Akrotirianakis,
  Ankit Shukla",Resiliency Analysis of LLM generated models for Industrial Automation,"8 Pages, Conference Manuscript",,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  This paper proposes a study of the resilience and efficiency of automatically generated industrial automation and control systems using Large Language Models (LLMs). The approach involves modeling the system using percolation theory to estimate its resilience and formulating the design problem as an optimization problem subject to constraints. Techniques from stochastic optimization and regret analysis are used to find a near-optimal solution with provable regret bounds. The study aims to provide insights into the effectiveness and reliability of automatically generated systems in industrial automation and control, and to identify potential areas for improvement in their design and implementation. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 13:35:36 GMT'}]",2023-08-24,"[['Ogundare', 'Oluwatosin', ''], ['Araya', 'Gustavo Quiros', ''], ['Akrotirianakis', 'Ioannis', ''], ['Shukla', 'Ankit', '']]",0,0,2023-08-23,1,4,1,0,0,0,eb696bcb7220289ab42c6fd37f2352aaab5a6c20,261076147.0,https://www.semanticscholar.org/paper/eb696bcb7220289ab42c6fd37f2352aaab5a6c20,arXiv.org,2023.0,10.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '65966853', 'name': 'O. Ogundare'}, {'authorId': '70508674', 'name': 'Gustavo Quiros Araya'}, {'authorId': '1904256', 'name': 'I. Akrotirianakis'}, {'authorId': '2186055750', 'name': 'Ankit Shukla'}]","['Siemens Technology, Princeton, NJ']",,2023-08,['industrial']
2308.12157,Anirudh Mittal,"Anirudh Mittal, Timo Schick, Mikel Artetxe, Jane Dwivedi-Yu",Evaluation of Faithfulness Using the Longest Supported Subsequence,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As increasingly sophisticated language models emerge, their trustworthiness becomes a pivotal issue, especially in tasks such as summarization and question-answering. Ensuring their responses are contextually grounded and faithful is challenging due to the linguistic diversity and the myriad of possible answers. In this paper, we introduce a novel approach to evaluate faithfulness of machine-generated text by computing the longest noncontinuous substring of the claim that is supported by the context, which we refer to as the Longest Supported Subsequence (LSS). Using a new human-annotated dataset, we finetune a model to generate LSS. We introduce a new method of evaluation and demonstrate that these metrics correlate better with human ratings when LSS is employed, as opposed to when it is not. Our proposed metric demonstrates an 18% enhancement over the prevailing state-of-the-art metric for faithfulness on our dataset. Our metric consistently outperforms other metrics on a summarization dataset across six different models. Finally, we compare several popular Large Language Models (LLMs) for faithfulness using this metric. We release the human-annotated dataset built for predicting LSS and our fine-tuned model for evaluating faithfulness. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 14:18:44 GMT'}]",2023-08-24,"[['Mittal', 'Anirudh', ''], ['Schick', 'Timo', ''], ['Artetxe', 'Mikel', ''], ['Dwivedi-Yu', 'Jane', '']]",0,0,2023-08-23,1,4,2,0,0,0,7677eee978adeac88478e43189e2e9e31e276058,261076241.0,https://www.semanticscholar.org/paper/7677eee978adeac88478e43189e2e9e31e276058,arXiv.org,2023.0,46.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '26965176', 'name': 'Anirudh Mittal'}, {'authorId': '32246932', 'name': 'Timo Schick'}, {'authorId': '2347956', 'name': 'Mikel Artetxe'}, {'authorId': '2173509991', 'name': 'Jane Dwivedi-Yu'}]",['Reka AI'],,2023-08,['industrial']
2308.12284,Kushal Tirumala,"Kushal Tirumala, Daniel Simig, Armen Aghajanyan, Ari S. Morcos",D4: Improving LLM Pretraining via Document De-Duplication and Diversification,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scale web corpora. While training on ever-larger portions of the internet leads to consistent performance improvements, the size of these improvements diminishes with scale, and there has been little work exploring the effect of data selection on pre-training and downstream performance beyond simple de-duplication methods such as MinHash. Here, we show that careful data selection (on top of de-duplicated data) via pre-trained model embeddings can speed up training (20% efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up to 2%) at the 6.7B model scale. Furthermore, we show that repeating data intelligently consistently outperforms baseline training (while repeating random data performs worse than baseline training). Our results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving our models past the limits of randomly sampling web data. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 17:58:14 GMT'}]",2023-08-24,"[['Tirumala', 'Kushal', ''], ['Simig', 'Daniel', ''], ['Aghajanyan', 'Armen', ''], ['Morcos', 'Ari S.', '']]",0,0,2023-08-23,1,4,3,0,0,0,11cf88dce827bd67cbfa60400306318022e736d5,261076313.0,https://www.semanticscholar.org/paper/11cf88dce827bd67cbfa60400306318022e736d5,arXiv.org,2023.0,65.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2551387', 'name': 'Kushal Tirumala'}, {'authorId': '2257241733', 'name': 'Daniel Simig'}, {'authorId': '2201435', 'name': 'Armen Aghajanyan'}, {'authorId': '4690624', 'name': 'Ari S. Morcos'}]",['Meta'],['United States'],2023-08,['industrial']
2308.12415,Daniel Rodriguez-Cardenas,"Daniel Rodriguez-Cardenas, David N. Palacio, Dipin Khati, Henry Burke,
  Denys Poshyvanyk",Benchmarking Causal Study to Interpret Large Language Models for Source Code,"6 pages, 4 tables, 3 figures, accepted to ICSME 2023",,,,cs.SE cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  One of the most common solutions adopted by software researchers to address code generation is by training Large Language Models (LLMs) on massive amounts of source code. Although a number of studies have shown that LLMs have been effectively evaluated on popular accuracy metrics (e.g., BLEU, CodeBleu), previous research has largely overlooked the role of Causal Inference as a fundamental component of the interpretability of LLMs' performance. Existing benchmarks and datasets are meant to highlight the difference between the expected and the generated outcome, but do not take into account confounding variables (e.g., lines of code, prompt size) that equally influence the accuracy metrics. The fact remains that, when dealing with generative software tasks by LLMs, no benchmark is available to tell researchers how to quantify neither the causal effect of SE-based treatments nor the correlation of confounders to the model's performance. In an effort to bring statistical rigor to the evaluation of LLMs, this paper introduces a benchmarking strategy named Galeras comprised of curated testbeds for three SE tasks (i.e., code completion, code summarization, and commit generation) to help aid the interpretation of LLMs' performance. We illustrate the insights of our benchmarking strategy by conducting a case study on the performance of ChatGPT under distinct prompt engineering methods. The results of the case study demonstrate the positive causal influence of prompt semantics on ChatGPT's generative performance by an average treatment effect of $\approx 3\%$. Moreover, it was found that confounders such as prompt size are highly correlated with accuracy metrics ($\approx 0.412\%$). The end result of our case study is to showcase causal inference evaluations, in practice, to reduce confounding bias. By reducing the bias, we offer an interpretable solution for the accuracy metric under analysis. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 20:32:12 GMT'}]",2023-08-25,"[['Rodriguez-Cardenas', 'Daniel', ''], ['Palacio', 'David N.', ''], ['Khati', 'Dipin', ''], ['Burke', 'Henry', ''], ['Poshyvanyk', 'Denys', '']]",1,1,2023-08-23,1,5,2,1,0,1,3352d4bb5756a8a6bfcc1cde169b6aa9fd94497d,261100898.0,https://www.semanticscholar.org/paper/3352d4bb5756a8a6bfcc1cde169b6aa9fd94497d,arXiv.org,2023.0,49.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1404672972', 'name': 'Daniel Rodríguez-Cárdenas'}, {'authorId': '1411692492', 'name': 'David N. Palacio'}, {'authorId': '2233292243', 'name': 'Dipin Khati'}, {'authorId': '2233293530', 'name': 'Henry Burke'}, {'authorId': '1697757', 'name': 'D. Poshyvanyk'}]",['William & Mary'],['United States'],2023-08,['industrial']
2308.12908,Pratyush Patel,"Pratyush Patel, Esha Choukse, Chaojie Zhang, \'I\~nigo Goiri, Brijesh
  Warrier, Nithish Mahalingam, Ricardo Bianchini",POLCA: Power Oversubscription in LLM Cloud Providers,,,,,cs.DC cs.AR cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recent innovation in large language models (LLMs), and their myriad use-cases have rapidly driven up the compute capacity demand for datacenter GPUs. Several cloud providers and other enterprises have made substantial plans of growth in their datacenters to support these new workloads. One of the key bottleneck resources in datacenters is power, and given the increasing model sizes of LLMs, they are becoming increasingly power intensive. In this paper, we show that there is a significant opportunity to oversubscribe power in LLM clusters. Power oversubscription improves the power efficiency of these datacenters, allowing more deployable servers per datacenter, and reduces the deployment time, since building new datacenters is slow.   We extensively characterize the power consumption patterns of a variety of LLMs and their configurations. We identify the differences between the inference and training power consumption patterns. Based on our analysis of these LLMs, we claim that the average and peak power utilization in LLM clusters for inference should not be very high. Our deductions align with the data from production LLM clusters, revealing that inference workloads offer substantial headroom for power oversubscription. However, the stringent set of telemetry and controls that GPUs offer in a virtualized environment, makes it challenging to have a reliable and robust power oversubscription mechanism.   We propose POLCA, our framework for power oversubscription that is robust, reliable, and readily deployable for GPU clusters. Using open-source models to replicate the power patterns observed in production, we simulate POLCA and demonstrate that we can deploy 30% more servers in the same GPU cluster for inference, with minimal performance loss ","[{'version': 'v1', 'created': 'Thu, 24 Aug 2023 16:32:34 GMT'}]",2023-08-25,"[['Patel', 'Pratyush', ''], ['Choukse', 'Esha', ''], ['Zhang', 'Chaojie', ''], ['Goiri', 'Íñigo', ''], ['Warrier', 'Brijesh', ''], ['Mahalingam', 'Nithish', ''], ['Bianchini', 'Ricardo', '']]",0,0,2023-08-24,1,7,3,0,0,0,d21bc77589484c76a2beadeba1578715089b9929,261100925.0,https://www.semanticscholar.org/paper/d21bc77589484c76a2beadeba1578715089b9929,arXiv.org,2023.0,52.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '15800665', 'name': 'Pratyush Patel'}, {'authorId': '3449187', 'name': 'Esha Choukse'}, {'authorId': '2256775267', 'name': 'Chaojie Zhang'}, {'authorId': '2495308', 'name': 'Íñigo Goiri'}, {'authorId': '2088938375', 'name': 'Brijesh Warrier'}, {'authorId': '147685223', 'name': 'Nithish Mahalingam'}, {'authorId': '2118138', 'name': 'R. Bianchini'}]",['Microsoft'],['United States'],2023-08,['industrial']
2308.13142,Tianyi Zhang,"Tianyi Zhang, Zheng Wang, Jing Huang, Mohiuddin Muhammad Tasnim, Wei
  Shi",A Survey of Diffusion Based Image Generation Models: Issues and Their Solutions,,,,,cs.CV cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  Recently, there has been significant progress in the development of large models. Following the success of ChatGPT, numerous language models have been introduced, demonstrating remarkable performance. Similar advancements have also been observed in image generation models, such as Google's Imagen model, OpenAI's DALL-E 2, and stable diffusion models, which have exhibited impressive capabilities in generating images. However, similar to large language models, these models still encounter unresolved challenges. Fortunately, the availability of open-source stable diffusion models and their underlying mathematical principles has enabled the academic community to extensively analyze the performance of current image generation models and make improvements based on this stable diffusion framework. This survey aims to examine the existing issues and the current solutions pertaining to image generation models. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 02:35:54 GMT'}]",2023-08-28,"[['Zhang', 'Tianyi', ''], ['Wang', 'Zheng', ''], ['Huang', 'Jing', ''], ['Tasnim', 'Mohiuddin Muhammad', ''], ['Shi', 'Wei', '']]",1,1,2023-08-25,1,5,2,1,0,1,49faa5c9bf6459a256f68872fb3b51df6b0a2dd8,261214460.0,https://www.semanticscholar.org/paper/49faa5c9bf6459a256f68872fb3b51df6b0a2dd8,arXiv.org,2023.0,84.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146334570', 'name': 'Tianyi Zhang'}, {'authorId': '50219447', 'name': 'Zheng Wang'}, {'authorId': '2210525127', 'name': 'Jin Huang'}, {'authorId': '104349231', 'name': 'M. M. Tasnim'}, {'authorId': '2199629455', 'name': 'Wei Shi'}]",['Huawei Technologies (Singapore)'],['Singapore'],2023-08,['industrial']
2308.13207,Anmol Nayak,Anmol Nayak and Hari Prasad Timmapathini,LLM2KB: Constructing Knowledge Bases using instruction tuned context aware Large Language Models,"16 pages, 1 figure, LM-KBC 2023 Challenge at International Semantic
  Web Conference 2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The advent of Large Language Models (LLM) has revolutionized the field of natural language processing, enabling significant progress in various applications. One key area of interest is the construction of Knowledge Bases (KB) using these powerful models. Knowledge bases serve as repositories of structured information, facilitating information retrieval and inference tasks. Our paper proposes LLM2KB, a system for constructing knowledge bases using large language models, with a focus on the Llama 2 architecture and the Wikipedia dataset. We perform parameter efficient instruction tuning for Llama-2-13b-chat and StableBeluga-13B by training small injection models that have only 0.05 % of the parameters of the base models using the Low Rank Adaptation (LoRA) technique. These injection models have been trained with prompts that are engineered to utilize Wikipedia page contexts of subject entities fetched using a Dense Passage Retrieval (DPR) algorithm, to answer relevant object entities for a given subject entity and relation. Our best performing model achieved an average F1 score of 0.6185 across 21 relations in the LM-KBC challenge held at the ISWC 2023 conference. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 07:04:16 GMT'}]",2023-08-28,"[['Nayak', 'Anmol', ''], ['Timmapathini', 'Hari Prasad', '']]",0,0,2023-08-25,1,2,1,1,1,0,4a9d0f0e68742b95b0dc778be0e3405f704f49a2,261214545.0,https://www.semanticscholar.org/paper/4a9d0f0e68742b95b0dc778be0e3405f704f49a2,arXiv.org,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46364598', 'name': 'Anmol Nayak'}, {'authorId': '2008210594', 'name': 'Hariprasad Timmapathini'}]",['Robert Bosch (India)'],['India'],2023-08,['industrial']
2308.13566,Bin Wang,"Zhiyuan Zhao, Linke Ouyang, Bin Wang, Siyuan Huang, Pan Zhang, Xiaoyi
  Dong, Jiaqi Wang, Conghui He",MLLM-DataEngine: An Iterative Refinement Approach for MLLM,"Code and models are available at
  https://github.com/opendatalab/MLLM-DataEngine",,,,cs.LG cs.AI cs.CL cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the great advance of Multimodal Large Language Models (MLLMs) in both instruction dataset building and benchmarking, the independence of training and evaluation makes current MLLMs hard to further improve their capability under the guidance of evaluation results with a relatively low human cost. In this paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data generation, model training, and evaluation. Within each loop iteration, the MLLM-DataEngine first analyze the weakness of the model based on the evaluation results, then generate a proper incremental dataset for the next training iteration and enhance the model capability iteratively. Compared with previous data collection methods which are separate from the benchmarking, the data generated by MLLM-DataEngine shows better targeting, quality, and correctness. For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts the ratio of different types of data within each incremental dataset based on the benchmarking results. For quality, we resort to GPT-4 to generate high-quality data with each given data type. For correctness, prompt design is critical for the data generation results. Rather than previous hand-crafted prompt, we propose an Interactive Prompt Optimization strategy, which optimizes the prompt with the multi-round interaction between human and GPT, and improve the correctness of generated data greatly. Through extensive experiments, we find our MLLM-DataEngine could boost the MLLM capability in a targeted and automatic manner, with only a few human participation. We hope it could be a general solution for the following MLLMs building. The MLLM-DataEngine has been open-sourced and is now available at https://github.com/opendatalab/MLLM-DataEngine. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 01:41:04 GMT'}, {'version': 'v2', 'created': 'Mon, 11 Sep 2023 08:28:40 GMT'}]",2023-09-12,"[['Zhao', 'Zhiyuan', ''], ['Ouyang', 'Linke', ''], ['Wang', 'Bin', ''], ['Huang', 'Siyuan', ''], ['Zhang', 'Pan', ''], ['Dong', 'Xiaoyi', ''], ['Wang', 'Jiaqi', ''], ['He', 'Conghui', '']]",0,1,2023-08-25,2,8,4,1,0,1,58a282c89864f35bff1741f5ab439222da6bb3ec,261245210.0,https://www.semanticscholar.org/paper/58a282c89864f35bff1741f5ab439222da6bb3ec,arXiv.org,2023.0,33.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146631014', 'name': 'Zhiyuan Zhao'}, {'authorId': '2161162356', 'name': 'Linke Ouyang'}, {'authorId': '2256857728', 'name': 'Bin Wang'}, {'authorId': '2110059550', 'name': 'Siyuan Huang'}, {'authorId': '2213750400', 'name': 'Pan Zhang'}, {'authorId': '2118187561', 'name': 'Xiao-wen Dong'}, {'authorId': '2156546701', 'name': 'Jiaqi Wang'}, {'authorId': '3486481', 'name': 'Conghui He'}]",['Shanghai Artificial Intelligence Laboratory'],['China'],2023-08,['industrial']
2308.13576,Shrutendra Harsola,Sourav Prosad and Viswa Datha Polavarapu and Shrutendra Harsola,An Ensemble Approach to Personalized Real Time Predictive Writing for Experts,"ACM SIGKDD Workshop on Machine Learning in Finance, 2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Completing a sentence, phrase or word after typing few words / characters is very helpful for Intuit financial experts, while taking notes or having a live chat with users, since they need to write complex financial concepts more efficiently and accurately many times in a day. In this paper, we tie together different approaches like large language models, traditional Markov Models and char level models to create an end-to-end system to provide personalised sentence/word auto-complete suggestions to experts, under strict latency constraints. Proposed system can auto-complete sentences, phrases or words while writing with personalisation and can be trained with very less data and resources with good efficiency. Our proposed system is not only efficient and personalized but also robust as it leverages multiple machine learning techniques along with transfer learning approach to fine tune large language model with Intuit specific data. This ensures that even in cases of rare or unusual phrases, the system can provide relevant auto-complete suggestions in near real time. Survey has showed that this system saves expert note-taking time and boosts expert confidence in their communication with teammates and clients. Since enabling this predictive writing feature for QBLive experts, more than a million keystrokes have been saved based on these suggestions. We have done comparative study for our ensemble choice. Moreover this feature can be integrated with any product which has writing facility within a very short period of time. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 12:45:46 GMT'}]",2023-08-29,"[['Prosad', 'Sourav', ''], ['Polavarapu', 'Viswa Datha', ''], ['Harsola', 'Shrutendra', '']]",0,0,2023-08-25,1,3,1,0,0,0,847e087ba2461350975b9de834c744dff0935a31,261242510.0,https://www.semanticscholar.org/paper/847e087ba2461350975b9de834c744dff0935a31,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2234342517', 'name': 'Sourav Prosad'}, {'authorId': '2234344345', 'name': 'Viswa Datha Polavarapu'}, {'authorId': '35429622', 'name': 'Shrutendra Harsola'}]","['Intuit AI, Bengaluru India']",['India'],2023-08,['industrial']
2308.13676,Pouya Pezeshkpour,"Vishwas Mruthyunjaya, Pouya Pezeshkpour, Estevam Hruschka, Nikita
  Bhutani",Rethinking Language Models as Symbolic Knowledge Graphs,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Symbolic knowledge graphs (KGs) play a pivotal role in knowledge-centric applications such as search, question answering and recommendation. As contemporary language models (LMs) trained on extensive textual data have gained prominence, researchers have extensively explored whether the parametric knowledge within these models can match up to that present in knowledge graphs. Various methodologies have indicated that enhancing the size of the model or the volume of training data enhances its capacity to retrieve symbolic knowledge, often with minimal or no human supervision. Despite these advancements, there is a void in comprehensively evaluating whether LMs can encompass the intricate topological and semantic attributes of KGs, attributes crucial for reasoning processes. In this work, we provide an exhaustive evaluation of language models of varying sizes and capabilities. We construct nine qualitative benchmarks that encompass a spectrum of attributes including symmetry, asymmetry, hierarchy, bidirectionality, compositionality, paths, entity-centricity, bias and ambiguity. Additionally, we propose novel evaluation metrics tailored for each of these attributes. Our extensive evaluation of various LMs shows that while these models exhibit considerable potential in recalling factual information, their ability to capture intricate topological and semantic traits of KGs remains significantly constrained. We note that our proposed evaluation metrics are more reliable in evaluating these abilities than the existing metrics. Lastly, some of our benchmarks challenge the common notion that larger LMs (e.g., GPT-4) universally outshine their smaller counterparts (e.g., BERT). ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 21:25:08 GMT'}]",2023-08-29,"[['Mruthyunjaya', 'Vishwas', ''], ['Pezeshkpour', 'Pouya', ''], ['Hruschka', 'Estevam', ''], ['Bhutani', 'Nikita', '']]",0,1,2023-08-25,1,4,3,1,0,1,ec101a7eff56e2a90bc0143f734fb282be757a5f,261242776.0,https://www.semanticscholar.org/paper/ec101a7eff56e2a90bc0143f734fb282be757a5f,arXiv.org,2023.0,35.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51035076', 'name': 'Vishwas Mruthyunjaya'}, {'authorId': '1713436', 'name': 'Pouya Pezeshkpour'}, {'authorId': '1842532', 'name': 'Estevam Hruschka'}, {'authorId': '29995869', 'name': 'Nikita Bhutani'}]","['Megagon Labs Mountain View, CA, USA']",['United States'],2023-08,['industrial']
2308.13785,Minheng Ni,"Minheng Ni, Chenfei Wu, Xiaodong Wang, Shengming Yin, Lijuan Wang,
  Zicheng Liu, Nan Duan",ORES: Open-vocabulary Responsible Visual Synthesis,,,,,cs.CV,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Avoiding synthesizing specific visual concepts is an essential challenge in responsible visual synthesis. However, the visual concept that needs to be avoided for responsible visual synthesis tends to be diverse, depending on the region, context, and usage scenarios. In this work, we formalize a new task, Open-vocabulary Responsible Visual Synthesis (ORES), where the synthesis model is able to avoid forbidden visual concepts while allowing users to input any desired content. To address this problem, we present a Two-stage Intervention (TIN) framework. By introducing 1) rewriting with learnable instruction through a large-scale language model (LLM) and 2) synthesizing with prompt intervention on a diffusion synthesis model, it can effectively synthesize images avoiding any concepts but following the user's query as much as possible. To evaluate on ORES, we provide a publicly available dataset, baseline models, and benchmark. Experimental results demonstrate the effectiveness of our method in reducing risks of image generation. Our work highlights the potential of LLMs in responsible visual synthesis. Our code and dataset is public available. ","[{'version': 'v1', 'created': 'Sat, 26 Aug 2023 06:47:34 GMT'}]",2023-08-29,"[['Ni', 'Minheng', ''], ['Wu', 'Chenfei', ''], ['Wang', 'Xiaodong', ''], ['Yin', 'Shengming', ''], ['Wang', 'Lijuan', ''], ['Liu', 'Zicheng', ''], ['Duan', 'Nan', '']]",0,0,2023-08-26,1,7,1,0,0,0,95be6a38f9b3ca3b7a9d81215e52cdcf545d554a,261243073.0,https://www.semanticscholar.org/paper/95be6a38f9b3ca3b7a9d81215e52cdcf545d554a,arXiv.org,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1576502392', 'name': 'Minheng Ni'}, {'authorId': '2151101534', 'name': 'Chenfei Wu'}, {'authorId': '2211071131', 'name': 'Xiaodong Wang'}, {'authorId': '2008158083', 'name': 'Sheng-Siang Yin'}, {'authorId': '29957038', 'name': 'Lijuan Wang'}, {'authorId': '2145253136', 'name': 'Zicheng Liu'}, {'authorId': '2072609829', 'name': 'Nan Duan'}]",['Microsoft'],"['China', 'United States']",2023-08,['industrial']
2308.14448,Yicheng Zhong,"Yicheng Zhong, Huawei Wei, Peiji Yang, Zhisheng Wang",ExpCLIP: Bridging Text and Facial Expressions via Semantic Alignment,,,,,cs.CV cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The objective of stylized speech-driven facial animation is to create animations that encapsulate specific emotional expressions. Existing methods often depend on pre-established emotional labels or facial expression templates, which may limit the necessary flexibility for accurately conveying user intent. In this research, we introduce a technique that enables the control of arbitrary styles by leveraging natural language as emotion prompts. This technique presents benefits in terms of both flexibility and user-friendliness. To realize this objective, we initially construct a Text-Expression Alignment Dataset (TEAD), wherein each facial expression is paired with several prompt-like descriptions.We propose an innovative automatic annotation method, supported by Large Language Models (LLMs), to expedite the dataset construction, thereby eliminating the substantial expense of manual annotation. Following this, we utilize TEAD to train a CLIP-based model, termed ExpCLIP, which encodes text and facial expressions into semantically aligned style embeddings. The embeddings are subsequently integrated into the facial animation generator to yield expressive and controllable facial animations. Given the limited diversity of facial emotions in existing speech-driven facial animation training data, we further introduce an effective Expression Prompt Augmentation (EPA) mechanism to enable the animation generator to support unprecedented richness in style control. Comprehensive experiments illustrate that our method accomplishes expressive facial animation generation and offers enhanced flexibility in effectively conveying the desired style. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 09:35:13 GMT'}, {'version': 'v2', 'created': 'Mon, 11 Sep 2023 08:56:32 GMT'}]",2023-09-12,"[['Zhong', 'Yicheng', ''], ['Wei', 'Huawei', ''], ['Yang', 'Peiji', ''], ['Wang', 'Zhisheng', '']]",0,0,2023-08-28,2,4,2,0,0,0,68159fc73e3b9d289d0b72137b1e3357d50ce2fe,261243936.0,https://www.semanticscholar.org/paper/68159fc73e3b9d289d0b72137b1e3357d50ce2fe,arXiv.org,2023.0,42.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2088676959', 'name': 'Yicheng Zhong'}, {'authorId': '48056150', 'name': 'Huawei Wei'}, {'authorId': '2119185269', 'name': 'Pei-Yin Yang'}, {'authorId': '2108086267', 'name': 'Zhisheng Wang'}]",['Tencent'],['China'],2023-08,['industrial']
2308.14608,Vahid Ghafouri,"Vahid Ghafouri, Vibhor Agarwal, Yong Zhang, Nishanth Sastry, Jose
  Such, Guillermo Suarez-Tangil",AI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models vs. Human Answers in Controversial Topics,,,10.1145/3583780.3614777,,cs.LG cs.CL cs.CY cs.SI,http://creativecommons.org/licenses/by/4.0/,"  The introduction of ChatGPT and the subsequent improvement of Large Language Models (LLMs) have prompted more and more individuals to turn to the use of ChatBots, both for information and assistance with decision-making. However, the information the user is after is often not formulated by these ChatBots objectively enough to be provided with a definite, globally accepted answer.   Controversial topics, such as ""religion"", ""gender identity"", ""freedom of speech"", and ""equality"", among others, can be a source of conflict as partisan or biased answers can reinforce preconceived notions or promote disinformation. By exposing ChatGPT to such debatable questions, we aim to understand its level of awareness and if existing models are subject to socio-political and/or economic biases. We also aim to explore how AI-generated answers compare to human ones. For exploring this, we use a dataset of a social media platform created for the purpose of debating human-generated claims on polemic subjects among users, dubbed Kialo.   Our results show that while previous versions of ChatGPT have had important issues with controversial topics, more recent versions of ChatGPT (gpt-3.5-turbo) are no longer manifesting significant explicit biases in several knowledge areas. In particular, it is well-moderated regarding economic aspects. However, it still maintains degrees of implicit libertarian leaning toward right-winged ideals which suggest the need for increased moderation from the socio-political point of view. In terms of domain knowledge on controversial topics, with the exception of the ""Philosophical"" category, ChatGPT is performing well in keeping up with the collective human level of knowledge. Finally, we see that sources of Bing AI have slightly more tendency to the center when compared to human answers. All the analyses we make are generalizable to other types of biases and domains. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 14:23:04 GMT'}]",2023-08-30,"[['Ghafouri', 'Vahid', ''], ['Agarwal', 'Vibhor', ''], ['Zhang', 'Yong', ''], ['Sastry', 'Nishanth', ''], ['Such', 'Jose', ''], ['Suarez-Tangil', 'Guillermo', '']]",1,1,2023-08-28,1,6,4,2,0,2,71de59804d41f3e4d8d9010f8f55eac2ea1a64dd,261243997.0,https://www.semanticscholar.org/paper/71de59804d41f3e4d8d9010f8f55eac2ea1a64dd,International Conference on Information and Knowledge Management,2023.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '92922961', 'name': 'V. Ghafouri'}, {'authorId': '153758068', 'name': 'Vibhor Agarwal'}, {'authorId': '2145068576', 'name': 'Yong Zhang'}, {'authorId': '2118998743', 'name': 'N. Sastry'}, {'authorId': '2065128099', 'name': 'Jose Such'}, {'authorId': '2192290656', 'name': 'Guillermo Suarez-Tangil'}]","["", , de , , of , , of , , of , , 's , , , -""]",,2023-08,['industrial']
2308.15143,Lei Han,"Lei Han, Qingxu Zhu, Jiapeng Sheng, Chong Zhang, Tingguang Li, Yizheng
  Zhang, He Zhang, Yuzhen Liu, Cheng Zhou, Rui Zhao, Jie Li, Yufeng Zhang, Rui
  Wang, Wanchao Chi, Xiong Li, Yonghui Zhu, Lingzhu Xiang, Xiao Teng, Zhengyou
  Zhang",Lifelike Agility and Play on Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models,,,,,cs.RO cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Summarizing knowledge from animals and human beings inspires robotic innovations. In this work, we propose a framework for driving legged robots act like real animals with lifelike agility and strategy in complex environments. Inspired by large pre-trained models witnessed with impressive performance in language and image understanding, we introduce the power of advanced deep generative models to produce motor control signals stimulating legged robots to act like real animals. Unlike conventional controllers and end-to-end RL methods that are task-specific, we propose to pre-train generative models over animal motion datasets to preserve expressive knowledge of animal behavior. The pre-trained model holds sufficient primitive-level knowledge yet is environment-agnostic. It is then reused for a successive stage of learning to align with the environments by traversing a number of challenging obstacles that are rarely considered in previous approaches, including creeping through narrow spaces, jumping over hurdles, freerunning over scattered blocks, etc. Finally, a task-specific controller is trained to solve complex downstream tasks by reusing the knowledge from previous stages. Enriching the knowledge regarding each stage does not affect the usage of other levels of knowledge. This flexible framework offers the possibility of continual knowledge accumulation at different levels. We successfully apply the trained multi-level controllers to the MAX robot, a quadrupedal robot developed in-house, to mimic animals, traverse complex obstacles, and play in a designed challenging multi-agent Chase Tag Game, where lifelike agility and strategy emerge on the robots. The present research pushes the frontier of robot control with new insights on reusing multi-level pre-trained knowledge and solving highly complex downstream tasks in the real world. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 09:22:12 GMT'}]",2023-08-30,"[['Han', 'Lei', ''], ['Zhu', 'Qingxu', ''], ['Sheng', 'Jiapeng', ''], ['Zhang', 'Chong', ''], ['Li', 'Tingguang', ''], ['Zhang', 'Yizheng', ''], ['Zhang', 'He', ''], ['Liu', 'Yuzhen', ''], ['Zhou', 'Cheng', ''], ['Zhao', 'Rui', ''], ['Li', 'Jie', ''], ['Zhang', 'Yufeng', ''], ['Wang', 'Rui', ''], ['Chi', 'Wanchao', ''], ['Li', 'Xiong', ''], ['Zhu', 'Yonghui', ''], ['Xiang', 'Lingzhu', ''], ['Teng', 'Xiao', ''], ['Zhang', 'Zhengyou', '']]",0,1,2023-08-29,1,19,2,0,0,0,15669c70376e6d4734881fe501b3b12306ff55e0,261276656.0,https://www.semanticscholar.org/paper/15669c70376e6d4734881fe501b3b12306ff55e0,arXiv.org,2023.0,46.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112661118', 'name': 'Lei Han'}, {'authorId': '2152208973', 'name': 'Qing Zhu'}, {'authorId': '2166150288', 'name': 'Jiapeng Sheng'}, {'authorId': '2144016094', 'name': 'Chong Zhang'}, {'authorId': '30720137', 'name': 'Tingguang Li'}, {'authorId': '1591122785', 'name': 'Yizheng Zhang'}, {'authorId': '2153528235', 'name': 'He Zhang'}, {'authorId': '2224381214', 'name': 'Yuzhen Liu'}, {'authorId': '2111168222', 'name': 'Cheng Zhou'}, {'authorId': '2198455188', 'name': 'Rui Zhao'}, {'authorId': '49298718', 'name': 'Jie Li'}, {'authorId': '2108298468', 'name': 'Yufeng Zhang'}, {'authorId': '2151037873', 'name': 'Rui Wang'}, {'authorId': '2066297735', 'name': 'Wanchao Chi'}, {'authorId': '2235248190', 'name': 'Xiong Li'}, {'authorId': '2159072214', 'name': 'Y. Zhu'}, {'authorId': '2977581', 'name': 'Lingzhu Xiang'}, {'authorId': '2224133142', 'name': 'Xiao Teng'}, {'authorId': '2148905709', 'name': 'Zhengyou Zhang'}]","['Tencent', 'Equal contribution.']",['China'],2023-08,"['industrial', 'industrial']"
2308.15363,Dawei Gao,"Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun, Yichen Qian, Bolin
  Ding, Jingren Zhou",Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation,We have released code on https://github.com/BeachWang/DAIL-SQL,,,,cs.DB cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborate their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6% execution accuracy and sets a new bar. To explore the potential of open-source LLM, we investigate them in various scenarios, and further enhance their performance with supervised fine-tuning. Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well as the advantages and disadvantages of the supervised fine-tuning. Additionally, towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. We hope that our work provides a deeper understanding of Text-to-SQL with LLMs, and inspires further investigations and broad applications. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 14:59:54 GMT'}, {'version': 'v2', 'created': 'Fri, 8 Sep 2023 10:13:16 GMT'}, {'version': 'v3', 'created': 'Wed, 20 Sep 2023 04:16:31 GMT'}]",2023-09-21,"[['Gao', 'Dawei', ''], ['Wang', 'Haibin', ''], ['Li', 'Yaliang', ''], ['Sun', 'Xiuyu', ''], ['Qian', 'Yichen', ''], ['Ding', 'Bolin', ''], ['Zhou', 'Jingren', '']]",0,0,2023-08-29,3,7,3,0,0,0,1fc89ce338b94f6a46e41b9a13aa99366a762eea,261276437.0,https://www.semanticscholar.org/paper/1fc89ce338b94f6a46e41b9a13aa99366a762eea,arXiv.org,2023.0,53.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2162036220', 'name': 'Dawei Gao'}, {'authorId': '2159088201', 'name': 'Haibin Wang'}, {'authorId': '2110479359', 'name': 'Yaliang Li'}, {'authorId': '2109166067', 'name': 'Xiuyu Sun'}, {'authorId': '2087074114', 'name': 'Yichen Qian'}, {'authorId': '1696332', 'name': 'Bolin Ding'}, {'authorId': '1709595', 'name': 'Jingren Zhou'}]",['Alibaba'],['China'],2023-08,['industrial']
2308.15605,Fabien Roger,"Fabien Roger, Ryan Greenblatt, Max Nadeau, Buck Shlegeris, Nate Thomas",Benchmarks for Detecting Measurement Tampering,"Edits: extended and improved appendices, fixed references, figures,
  and typos",,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  When training powerful AI systems to perform complex tasks, it may be challenging to provide training signals which are robust to optimization. One concern is \textit{measurement tampering}, where the AI system manipulates multiple measurements to create the illusion of good results instead of achieving the desired outcome. In this work, we build four new text-based datasets to evaluate measurement tampering detection techniques on large language models. Concretely, given sets of text inputs and measurements aimed at determining if some outcome occurred, as well as a base model able to accurately predict measurements, the goal is to determine if examples where all measurements indicate the outcome occurred actually had the outcome occur, or if this was caused by measurement tampering. We demonstrate techniques that outperform simple baselines on most datasets, but don't achieve maximum performance. We believe there is significant room for improvement for both techniques and datasets, and we are excited for future work tackling measurement tampering. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 19:54:37 GMT'}, {'version': 'v2', 'created': 'Tue, 5 Sep 2023 16:49:18 GMT'}, {'version': 'v3', 'created': 'Wed, 6 Sep 2023 09:32:50 GMT'}, {'version': 'v4', 'created': 'Thu, 7 Sep 2023 20:35:58 GMT'}, {'version': 'v5', 'created': 'Fri, 29 Sep 2023 15:53:36 GMT'}]",2023-10-02,"[['Roger', 'Fabien', ''], ['Greenblatt', 'Ryan', ''], ['Nadeau', 'Max', ''], ['Shlegeris', 'Buck', ''], ['Thomas', 'Nate', '']]",0,0,2023-08-29,5,5,1,0,0,0,6e71e407c6e628416b1eba4fcca441f45af47c28,261340652.0,https://www.semanticscholar.org/paper/6e71e407c6e628416b1eba4fcca441f45af47c28,,2023.0,33.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2197780120', 'name': 'Fabien Roger'}, {'authorId': '2235839536', 'name': 'Ryan Greenblatt'}, {'authorId': '2131005702', 'name': 'Max Nadeau'}, {'authorId': '79384063', 'name': 'Buck Shlegeris'}, {'authorId': '2164091765', 'name': 'Nate Thomas'}]",['Redwood Research'],,2023-08,['industrial']
2308.16763,Kairui Hu Mr,"Kairui Hu, Ming Yan, Joey Tianyi Zhou, Ivor W. Tsang, Wen Haw Chong,
  Yong Keong Yap",Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection,"5 pages, 2 figures, 2 tables",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Stance detection aims to identify the attitude expressed in a document towards a given target. Techniques such as Chain-of-Thought (CoT) prompting have advanced this task, enhancing a model's reasoning capabilities through the derivation of intermediate rationales. However, CoT relies primarily on a model's pre-trained internal knowledge during reasoning, thereby neglecting the valuable external information that is previously unknown to the model. This omission, especially within the unsupervised reasoning process, can affect the model's overall performance. Moreover, while CoT enhances Large Language Models (LLMs), smaller LMs, though efficient operationally, face challenges in delivering nuanced reasoning. In response to these identified gaps, we introduce the Ladder-of-Thought (LoT) for the stance detection task. Constructed through a dual-phase Progressive Optimization Framework, LoT directs the small LMs to assimilate high-quality external knowledge, refining the intermediate rationales produced. These bolstered rationales subsequently serve as the foundation for more precise predictions - akin to how a ladder facilitates reaching elevated goals. LoT achieves a balance between efficiency and performance. Our empirical evaluations underscore LoT's efficacy, marking a 16% improvement over GPT-3.5 and a 10% enhancement compared to GPT-3.5 with CoT on stance detection task. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 14:31:48 GMT'}, {'version': 'v2', 'created': 'Thu, 7 Sep 2023 09:15:24 GMT'}]",2023-09-08,"[['Hu', 'Kairui', ''], ['Yan', 'Ming', ''], ['Zhou', 'Joey Tianyi', ''], ['Tsang', 'Ivor W.', ''], ['Chong', 'Wen Haw', ''], ['Yap', 'Yong Keong', '']]",0,1,2023-08-31,2,6,2,1,0,1,9059dfa3406af7bb1d1a94bd778eef42f0449dff,261395606.0,https://www.semanticscholar.org/paper/9059dfa3406af7bb1d1a94bd778eef42f0449dff,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2236645169', 'name': 'Kairui Hu'}, {'authorId': '2047087220', 'name': 'Ming Yan'}, {'authorId': '10638646', 'name': 'Joey Tianyi Zhou'}, {'authorId': '1807998', 'name': 'I. Tsang'}, {'authorId': '2223253', 'name': 'Wen-Haw Chong'}, {'authorId': '1742123174', 'name': 'Yong Keong Yap'}]","['Institute of High Performance Computing', 'Agency for Science, Technology and Research', 'DSO National Laboratories']",['Singapore'],2023-08,"['industrial', 'industrial', 'industrial']"
2309.00208,Junwon Sung,"Junwon Sung, Woojin Heo, Yunkyung Byun, Youngsam Kim",Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea's Top 50 KOSPI Companies,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In the rapidly advancing domain of artificial intelligence, state-of-the-art language models such as OpenAI's GPT-3.5-turbo and GPT-4 offer unprecedented opportunities for automating complex tasks. This research paper delves into the capabilities of these models for semantically analyzing corporate disclosures in the Korean context, specifically for timely disclosure. The study focuses on the top 50 publicly traded companies listed on the Korean KOSPI, based on market capitalization, and scrutinizes their monthly disclosure summaries over a period of 17 months. Each summary was assigned a sentiment rating on a scale ranging from 1(very negative) to 5(very positive). To gauge the effectiveness of the language models, their sentiment ratings were compared with those generated by human experts. Our findings reveal a notable performance disparity between GPT-3.5-turbo and GPT-4, with the latter demonstrating significant accuracy in human evaluation tests. The Spearman correlation coefficient was registered at 0.61, while the simple concordance rate was recorded at 0.82. This research contributes valuable insights into the evaluative characteristics of GPT models, thereby laying the groundwork for future innovations in the field of automated semantic monitoring. ","[{'version': 'v1', 'created': 'Fri, 1 Sep 2023 01:51:28 GMT'}]",2023-09-04,"[['Sung', 'Junwon', ''], ['Heo', 'Woojin', ''], ['Byun', 'Yunkyung', ''], ['Kim', 'Youngsam', '']]",0,1,2023-09-01,1,4,2,2,0,2,07d54560e2819a2c44b607a837fc48e7412b4356,261494279.0,https://www.semanticscholar.org/paper/07d54560e2819a2c44b607a837fc48e7412b4356,arXiv.org,2023.0,12.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2237426883', 'name': 'Junwon Sung'}, {'authorId': '2237426788', 'name': 'Woojin Heo'}, {'authorId': '2237426562', 'name': 'Yunkyung Byun'}, {'authorId': '2237601748', 'name': 'Youngsam Kim'}]","['EG Asset Pricing, Republic of Korea']",,2023-09,['industrial']
2309.00363,Yaliang Li,"Weirui Kuang, Bingchen Qian, Zitao Li, Daoyuan Chen, Dawei Gao, Xuchen
  Pan, Yuexiang Xie, Yaliang Li, Bolin Ding, Jingren Zhou",FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning,Source code: https://github.com/alibaba/FederatedScope/tree/llm,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  LLMs have demonstrated great capabilities in various NLP tasks. Different entities can further improve the performance of those LLMs on their specific downstream tasks by fine-tuning LLMs. When several entities have similar interested tasks, but their data cannot be shared because of privacy concerns regulations, federated learning (FL) is a mainstream solution to leverage the data of different entities. However, fine-tuning LLMs in federated learning settings still lacks adequate support from existing FL frameworks because it has to deal with optimizing the consumption of significant communication and computational resources, data preparation for different tasks, and distinct information protection demands. This paper first discusses these challenges of federated fine-tuning LLMs, and introduces our package FS-LLM as a main contribution, which consists of the following components: (1) we build an end-to-end benchmarking pipeline, automizing the processes of dataset preprocessing, federated fine-tuning execution, and performance evaluation on federated LLM fine-tuning; (2) we provide comprehensive federated parameter-efficient fine-tuning algorithm implementations and versatile programming interfaces for future extension in FL scenarios with low communication and computation costs, even without accessing the full model; (3) we adopt several accelerating and resource-efficient operators for fine-tuning LLMs with limited resources and the flexible pluggable sub-routines for interdisciplinary study. We conduct extensive experiments to validate the effectiveness of FS-LLM and benchmark advanced LLMs with state-of-the-art parameter-efficient fine-tuning algorithms in FL settings, which also yields valuable insights into federated fine-tuning LLMs for the research community. To facilitate further research and adoption, we release FS-LLM at https://github.com/alibaba/FederatedScope/tree/llm. ","[{'version': 'v1', 'created': 'Fri, 1 Sep 2023 09:40:36 GMT'}]",2023-09-04,"[['Kuang', 'Weirui', ''], ['Qian', 'Bingchen', ''], ['Li', 'Zitao', ''], ['Chen', 'Daoyuan', ''], ['Gao', 'Dawei', ''], ['Pan', 'Xuchen', ''], ['Xie', 'Yuexiang', ''], ['Li', 'Yaliang', ''], ['Ding', 'Bolin', ''], ['Zhou', 'Jingren', '']]",0,0,2023-09-01,1,10,1,0,0,0,529ff7d6441d244212cf2becafd12a7e67ac56d9,261494317.0,https://www.semanticscholar.org/paper/529ff7d6441d244212cf2becafd12a7e67ac56d9,arXiv.org,2023.0,93.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2162042348', 'name': 'Weirui Kuang'}, {'authorId': '2237427279', 'name': 'Bingchen Qian'}, {'authorId': '2007553615', 'name': 'Zitao Li'}, {'authorId': '49025612', 'name': 'Daoyuan Chen'}, {'authorId': '2162036220', 'name': 'Dawei Gao'}, {'authorId': '2211993531', 'name': 'Xuchen Pan'}, {'authorId': '52133762', 'name': 'Yuexiang Xie'}, {'authorId': '2237607166', 'name': 'Yaliang Li'}, {'authorId': '1696332', 'name': 'Bolin Ding'}, {'authorId': '2237499232', 'name': 'Jingren Zhou'}]",['Alibaba'],['China'],2023-09,['industrial']
2309.00986,Chenliang Li,"Chenliang Li, Hehong Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai
  Wu, Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng, Hongzhu Shi, Ji
  Zhang, Fei Huang, Jingren Zhou",ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have recently demonstrated remarkable capabilities to comprehend human intentions, engage in reasoning, and design planning-like behavior. To further unleash the power of LLMs to accomplish complex tasks, there is a growing trend to build agent framework that equips LLMs, such as ChatGPT, with tool-use abilities to connect with massive external APIs. In this work, we introduce ModelScope-Agent, a general and customizable agent framework for real-world applications, based on open-source LLMs as controllers. It provides a user-friendly system library, with customizable engine design to support model training on multiple open-source LLMs, while also enabling seamless integration with both model APIs and common APIs in a unified way. To equip the LLMs with tool-use abilities, a comprehensive framework has been proposed spanning over tool-use data collection, tool retrieval, tool registration, memory control, customized model training, and evaluation for practical real-world applications. Finally, we showcase ModelScopeGPT, a real-world intelligent assistant of ModelScope Community based on the ModelScope-Agent framework, which is able to connect open-source LLMs with more than 1000 public AI models and localized community knowledge in ModelScope. The ModelScope-Agent library\footnote{https://github.com/modelscope/modelscope-agent} and online demo\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now publicly available. ","[{'version': 'v1', 'created': 'Sat, 2 Sep 2023 16:50:30 GMT'}]",2023-09-06,"[['Li', 'Chenliang', ''], ['Chen', 'Hehong', ''], ['Yan', 'Ming', ''], ['Shen', 'Weizhou', ''], ['Xu', 'Haiyang', ''], ['Wu', 'Zhikai', ''], ['Zhang', 'Zhicheng', ''], ['Zhou', 'Wenmeng', ''], ['Chen', 'Yingda', ''], ['Cheng', 'Chen', ''], ['Shi', 'Hongzhu', ''], ['Zhang', 'Ji', ''], ['Huang', 'Fei', ''], ['Zhou', 'Jingren', '']]",1,1,2023-09-02,1,14,1,1,0,1,e2f1f04f648a8863d11439aa4c80ee65d6caccda,261531214.0,https://www.semanticscholar.org/paper/e2f1f04f648a8863d11439aa4c80ee65d6caccda,arXiv.org,2023.0,25.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2829009', 'name': 'Chenliang Li'}, {'authorId': '123655156', 'name': 'Hehong Chen'}, {'authorId': '2114009661', 'name': 'Mingshi Yan'}, {'authorId': '2237809880', 'name': 'Weizhou Shen'}, {'authorId': '153194420', 'name': 'Haiyang Xu'}, {'authorId': '2238047773', 'name': 'Zhikai Wu'}, {'authorId': '2237946970', 'name': 'Zhicheng Zhang'}, {'authorId': '2237956023', 'name': 'Wenmeng Zhou'}, {'authorId': '2237827934', 'name': 'Yingda Chen'}, {'authorId': '2237996616', 'name': 'Chen Cheng'}, {'authorId': '2238549612', 'name': 'Hongzhu Shi'}, {'authorId': '2116921824', 'name': 'Ji Zhang'}, {'authorId': '143857288', 'name': 'Fei Huang'}, {'authorId': '2237981776', 'name': 'Jingren Zhou'}]",['Alibaba'],['China'],2023-09,['industrial']
2309.01105,Cheonsu Jeong Dr,Cheonsu Jeong,A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture,,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model. A comprehensive analysis of these steps is undertaken, emphasizing their significance in addressing the scarcity of data. The study highlights the efficacy of the proposed method, showcasing its applicability through illustrative instances. By implementing the RAG model for information storage and retrieval, the research not only contributes to a deeper comprehension of generative AI technology but also facilitates its practical usability within enterprises utilizing LLMs. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services within corporate settings. ","[{'version': 'v1', 'created': 'Sun, 3 Sep 2023 07:03:17 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Sep 2023 11:36:50 GMT'}]",2023-09-19,"[['Jeong', 'Cheonsu', '']]",0,0,2023-09-03,2,1,2,0,0,0,dcf2e723ee9c3270c98ff768b139cca75d29242e,261531346.0,https://www.semanticscholar.org/paper/dcf2e723ee9c3270c98ff768b139cca75d29242e,arXiv.org,2023.0,34.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '98037302', 'name': 'Cheon-Su Jeong'}]",['Samsung'],['South Korea'],2023-09,['industrial']
2309.01247,John Bj{\o}rnar Bremnes,"John Bj{\o}rnar Bremnes, Thomas N. Nipen, Ivar A. Seierstad",Evaluation of forecasts by a global data-driven weather model with and without probabilistic post-processing at Norwegian stations,"9 pages, 5 figures",,,,physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  During the last two years, tremendous progress in global data-driven weather models trained on numerical weather prediction (NWP) re-analysis data has been made. The most recent models trained on the ERA5 at 0.25{\deg} resolution demonstrate forecast quality on par with ECMWF's high-resolution model with respect to a wide selection of verification metrics. In this study, one of these models, the Pangu-Weather, is compared to several NWP models with and without probabilistic post-processing for 2-meter temperature and 10-meter wind speed forecasting at 183 Norwegian SYNOP stations up to +60 hours ahead. The NWP models included are the ECMWF HRES, ECMWF ENS and the Harmonie-AROME ensemble model MEPS with 2.5 km spatial resolution. Results show that the performances of the global models are on the same level with Pangu-Weather being slightly better than the ECMWF models for temperature and slightly worse for wind speed. The MEPS model clearly provided the best forecasts for both parameters. The post-processing improved the forecast quality considerably for all models, but to a larger extent for the coarse-resolution global models due to stronger systematic deficiencies in these. Apart from this, the main characteristics in the scores were more or less the same with and without post-processing. Our results thus confirm the conclusions from other studies that global data-driven models are promising for operational weather forecasting. ","[{'version': 'v1', 'created': 'Sun, 3 Sep 2023 19:20:24 GMT'}]",2023-09-06,"[['Bremnes', 'John Bjørnar', ''], ['Nipen', 'Thomas N.', ''], ['Seierstad', 'Ivar A.', '']]",0,0,2023-09-03,1,3,1,0,0,0,2029a29bec902d78ee2969739cd467e14586f945,261530794.0,https://www.semanticscholar.org/paper/2029a29bec902d78ee2969739cd467e14586f945,,2023.0,21.0,0.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","[{'authorId': '2449273', 'name': 'J. B. Bremnes'}, {'authorId': '70190922', 'name': 'T. Nipen'}, {'authorId': '103637926', 'name': 'I. Seierstad'}]",['Norwegian Meteorological Institute'],['Norway'],2023-09,['industrial']
2309.02285,Yichong Leng,"Yichong Leng, Zhifang Guo, Kai Shen, Xu Tan, Zeqian Ju, Yanqing Liu,
  Yufei Liu, Dongchao Yang, Leying Zhang, Kaitao Song, Lei He, Xiang-Yang Li,
  Sheng Zhao, Tao Qin, Jiang Bian",PromptTTS 2: Describing and Generating Voices with Text Prompt,Demo page: https://speechresearch.github.io/prompttts2,,,,eess.AS cs.CL cs.LG cs.SD,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Speech conveys more information than just text, as the same word can be uttered in various voices to convey diverse information. Compared to traditional text-to-speech (TTS) methods relying on speech prompts (reference speech) for voice variability, using text prompts (descriptions) is more user-friendly since speech prompts can be hard to find or may not exist at all. TTS approaches based on the text prompt face two challenges: 1) the one-to-many problem, where not all details about voice variability can be described in the text prompt, and 2) the limited availability of text prompt datasets, where vendors and large cost of data labeling are required to write text prompt for speech. In this work, we introduce PromptTTS 2 to address these challenges with a variation network to provide variability information of voice not captured by text prompts, and a prompt generation pipeline to utilize the large language models (LLM) to compose high quality text prompts. Specifically, the variation network predicts the representation extracted from the reference speech (which contains full information about voice) based on the text prompt representation. For the prompt generation pipeline, it generates text prompts for speech with a speech understanding model to recognize voice attributes (e.g., gender, speed) from speech and a large language model to formulate text prompt based on the recognition results. Experiments on a large-scale (44K hours) speech dataset demonstrate that compared to the previous works, PromptTTS 2 generates voices more consistent with text prompts and supports the sampling of diverse voice variability, thereby offering users more choices on voice generation. Additionally, the prompt generation pipeline produces high-quality prompts, eliminating the large labeling cost. The demo page of PromptTTS 2 is available online\footnote{https://speechresearch.github.io/prompttts2}. ","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 14:45:27 GMT'}]",2023-09-06,"[['Leng', 'Yichong', ''], ['Guo', 'Zhifang', ''], ['Shen', 'Kai', ''], ['Tan', 'Xu', ''], ['Ju', 'Zeqian', ''], ['Liu', 'Yanqing', ''], ['Liu', 'Yufei', ''], ['Yang', 'Dongchao', ''], ['Zhang', 'Leying', ''], ['Song', 'Kaitao', ''], ['He', 'Lei', ''], ['Li', 'Xiang-Yang', ''], ['Zhao', 'Sheng', ''], ['Qin', 'Tao', ''], ['Bian', 'Jiang', '']]",0,0,2023-09-05,1,15,4,0,0,0,e33a8f49a46321fb7c1a89d4b759a00a6880fd3d,261557296.0,https://www.semanticscholar.org/paper/e33a8f49a46321fb7c1a89d4b759a00a6880fd3d,arXiv.org,2023.0,57.0,1.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '148398655', 'name': 'Yichong Leng'}, {'authorId': '2238215402', 'name': 'Zhifang Guo'}, {'authorId': '2237989965', 'name': 'Kai Shen'}, {'authorId': '48391466', 'name': 'Xu Tan'}, {'authorId': '1613055688', 'name': 'Zeqian Ju'}, {'authorId': '2108086973', 'name': 'Yanqing Liu'}, {'authorId': '2238126539', 'name': 'Yufei Liu'}, {'authorId': '2238138795', 'name': 'Dongchao Yang'}, {'authorId': '2238127115', 'name': 'Leying Zhang'}, {'authorId': '50982078', 'name': 'Kaitao Song'}, {'authorId': '145836234', 'name': 'Lei He'}, {'authorId': '2108750136', 'name': 'Xiang-Yang Li'}, {'authorId': '47601191', 'name': 'Sheng Zhao'}, {'authorId': '2237988703', 'name': 'Tao Qin'}, {'authorId': '2192822005', 'name': 'Jiang Bian'}]",['Microsoft'],['India'],2023-09,['industrial']
2309.02301,Hongyu Hu,"Hongyu Hu, Jiyuan Zhang, Minyi Zhao, Zhenbang Sun",CIEM: Contrastive Instruction Evaluation Method for Better Instruction Tuning,,,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Nowadays, the research on Large Vision-Language Models (LVLMs) has been significantly promoted thanks to the success of Large Language Models (LLM). Nevertheless, these Vision-Language Models (VLMs) are suffering from the drawback of hallucination -- due to insufficient understanding of vision and language modalities, VLMs may generate incorrect perception information when doing downstream applications, for example, captioning a non-existent entity. To address the hallucination phenomenon, on the one hand, we introduce a Contrastive Instruction Evaluation Method (CIEM), which is an automatic pipeline that leverages an annotated image-text dataset coupled with an LLM to generate factual/contrastive question-answer pairs for the evaluation of the hallucination of VLMs. On the other hand, based on CIEM, we further propose a new instruction tuning method called CIT (the abbreviation of Contrastive Instruction Tuning) to alleviate the hallucination of VLMs by automatically producing high-quality factual/contrastive question-answer pairs and corresponding justifications for model tuning. Through extensive experiments on CIEM and CIT, we pinpoint the hallucination issues commonly present in existing VLMs, the disability of the current instruction-tuning dataset to handle the hallucination phenomenon and the superiority of CIT-tuned VLMs over both CIEM and public datasets. ","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 15:06:37 GMT'}]",2023-09-06,"[['Hu', 'Hongyu', ''], ['Zhang', 'Jiyuan', ''], ['Zhao', 'Minyi', ''], ['Sun', 'Zhenbang', '']]",0,0,2023-09-05,1,4,1,0,0,0,73814a52609a9ee4c8f1b115e376b6a300ab6a57,261557047.0,https://www.semanticscholar.org/paper/73814a52609a9ee4c8f1b115e376b6a300ab6a57,arXiv.org,2023.0,28.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238158720', 'name': 'Hongyu Hu'}, {'authorId': '2238121882', 'name': 'Jiyuan Zhang'}, {'authorId': '2238258246', 'name': 'Minyi Zhao'}, {'authorId': '2238143153', 'name': 'Zhenbang Sun'}]",['ByteDance'],['China'],2023-09,['industrial']
2309.02553,Javier Ferrando,"Javier Ferrando, Matthias Sperber, Hendra Setiawan, Dominic Telaar,
  Sa\v{s}a Hasan",Automating Behavioral Testing in Machine Translation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Behavioral testing in NLP allows fine-grained evaluation of systems by examining their linguistic capabilities through the analysis of input-output behavior. Unfortunately, existing work on behavioral testing in Machine Translation (MT) is currently restricted to largely handcrafted tests covering a limited range of capabilities and languages. To address this limitation, we propose to use Large Language Models (LLMs) to generate a diverse set of source sentences tailored to test the behavior of MT models in a range of situations. We can then verify whether the MT model exhibits the expected behavior through matching candidate sets that are also generated using LLMs. Our approach aims to make behavioral testing of MT systems practical while requiring only minimal human effort. In our experiments, we apply our proposed evaluation framework to assess multiple available MT systems, revealing that while in general pass-rates follow the trends observable from traditional accuracy-based metrics, our method was able to uncover several important differences and potential bugs that go unnoticed when relying only on accuracy. ","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 19:40:45 GMT'}, {'version': 'v2', 'created': 'Thu, 7 Sep 2023 00:23:34 GMT'}]",2023-09-08,"[['Ferrando', 'Javier', ''], ['Sperber', 'Matthias', ''], ['Setiawan', 'Hendra', ''], ['Telaar', 'Dominic', ''], ['Hasan', 'Saša', '']]",0,0,2023-09-05,2,5,2,0,0,0,6b3a205b08f10320c17abdeb5681df447683c661,261556930.0,https://www.semanticscholar.org/paper/6b3a205b08f10320c17abdeb5681df447683c661,arXiv.org,2023.0,38.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1751450782', 'name': 'Javier Ferrando'}, {'authorId': '3011998', 'name': 'Matthias Sperber'}, {'authorId': '2237986609', 'name': 'Hendra Setiawan'}, {'authorId': '2237986093', 'name': 'Dominic Telaar'}, {'authorId': '2237987545', 'name': 'Savsa Hasan'}]",['Universitat Politècnica de Catalunya'],['Spain'],2023-09,['industrial']
2309.03224,Haotian Xu,Haotian Xu,No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function,still in progress,,,,cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) demonstrate impressive language understanding and contextual learning abilities, making them suitable for natural language processing (NLP) tasks and complex mathematical reasoning. However, when applied to mathematical reasoning tasks, LLMs often struggle to generate correct reasoning steps and answers despite having high probabilities for the solutions. To overcome this limitation and enhance the mathematical reasoning capabilities of fine-tuned LLMs without additional fine-tuning steps, we propose a method that incorporates Monte Carlo Tree Search (MCTS) and a lightweight energy function to rank decision steps and enable immediate reaction and precise reasoning. Specifically, we re-formulate the fine-tuned LLMs into a Residual-based Energy Model (Residual-EBM) and employ noise contrastive estimation to estimate the energy function's parameters. We then utilize MCTS with the energy function as a path verifier to search the output space and evaluate the reasoning path. Through extensive experiments on two mathematical reasoning benchmarks, GSM8k and AQUA-RAT, we demonstrate the exceptional capabilities of our method, which significantly improves the pass@1 metric of the fine-tuned model without requiring additional fine-tuning or reinforcement learning with human feedback alignment. ","[{'version': 'v1', 'created': 'Fri, 1 Sep 2023 13:10:54 GMT'}, {'version': 'v2', 'created': 'Mon, 11 Sep 2023 12:50:49 GMT'}, {'version': 'v3', 'created': 'Tue, 12 Sep 2023 03:03:00 GMT'}]",2023-09-13,"[['Xu', 'Haotian', '']]",0,0,2023-09-01,3,1,2,0,0,0,537335d9aad0ddbaef93e7f88b0db096671ef6ec,261582366.0,https://www.semanticscholar.org/paper/537335d9aad0ddbaef93e7f88b0db096671ef6ec,arXiv.org,2023.0,45.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238243665', 'name': 'Haotian Xu'}]",['Independent Researcher'],,2023-09,['industrial']
2309.03978,Josh Belanich,"Taesik Gong, Josh Belanich, Krishna Somandepalli, Arsha Nagrani, Brian
  Eoff, Brendan Jou",LanSER: Language-Model Supported Speech Emotion Recognition,Presented at INTERSPEECH 2023,INTERSPEECH (2023) 2408-2412,10.21437/Interspeech.2023-1832,,cs.CL cs.LG cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech emotion recognition (SER) models typically rely on costly human-labeled data for training, making scaling methods to large speech datasets and nuanced emotion taxonomies difficult. We present LanSER, a method that enables the use of unlabeled data by inferring weak emotion labels via pre-trained large language models through weakly-supervised learning. For inferring weak labels constrained to a taxonomy, we use a textual entailment approach that selects an emotion label with the highest entailment score for a speech transcript extracted via automatic speech recognition. Our experimental results show that models pre-trained on large datasets with this weak supervision outperform other baseline models on standard SER datasets when fine-tuned, and show improved label efficiency. Despite being pre-trained on labels derived only from text, we show that the resulting representations appear to model the prosodic content of speech. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 19:21:08 GMT'}]",2023-09-11,"[['Gong', 'Taesik', ''], ['Belanich', 'Josh', ''], ['Somandepalli', 'Krishna', ''], ['Nagrani', 'Arsha', ''], ['Eoff', 'Brian', ''], ['Jou', 'Brendan', '']]",0,0,2023-09-07,1,6,4,0,0,0,74381622d5931fb073deccf758d37cf45e41820f,260910822.0,https://www.semanticscholar.org/paper/74381622d5931fb073deccf758d37cf45e41820f,Interspeech,2023.0,31.0,1.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '25171015', 'name': 'Taesik Gong'}, {'authorId': '2280622', 'name': 'Joshua Belanich'}, {'authorId': '6079502', 'name': 'Krishna Somandepalli'}, {'authorId': '2140304926', 'name': 'Arsha Nagrani'}, {'authorId': '2130169', 'name': 'B. Eoff'}, {'authorId': '2447185', 'name': 'Brendan Jou'}]",['Google'],['United States'],2023-09,['industrial']
2309.04031,Takuma Udagawa,"Takuma Udagawa, Masayuki Suzuki, Gakuto Kurata, Masayasu Muraoka,
  George Saon",Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems,Submitted to ICASSP 2024,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transferring the knowledge of large language models (LLMs) is a promising technique to incorporate linguistic knowledge into end-to-end automatic speech recognition (ASR) systems. However, existing works only transfer a single representation of LLM (e.g. the last layer of pretrained BERT), while the representation of a text is inherently non-unique and can be obtained variously from different layers, contexts and models. In this work, we explore a wide range of techniques to obtain and transfer multiple representations of LLMs into a transducer-based ASR system. While being conceptually simple, we show that transferring multiple representations of LLMs can be an effective alternative to transferring only a single representation. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 21:57:39 GMT'}]",2023-09-11,"[['Udagawa', 'Takuma', ''], ['Suzuki', 'Masayuki', ''], ['Kurata', 'Gakuto', ''], ['Muraoka', 'Masayasu', ''], ['Saon', 'George', '']]",0,0,2023-09-07,1,5,3,0,0,0,e9e97240f1d3b0a4d505695e07a92b6ab0c0fff4,261660222.0,https://www.semanticscholar.org/paper/e9e97240f1d3b0a4d505695e07a92b6ab0c0fff4,arXiv.org,2023.0,39.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '80927455', 'name': 'Takuma Udagawa'}, {'authorId': '2238914088', 'name': 'Masayuki Suzuki'}, {'authorId': '1787226', 'name': 'Gakuto Kurata'}, {'authorId': '37438942', 'name': 'Masayasu Muraoka'}, {'authorId': '1698208', 'name': 'G. Saon'}]",['IBM (United States)'],['United States'],2023-09,['industrial']
2309.04372,Sijia Li,"Sijia Li, Chen Chen, Haonan Lu",MoEController: Instruction-based Arbitrary Image Manipulation with Mixture-of-Expert Controllers,"5 pages,6 figures",,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Diffusion-model-based text-guided image generation has recently made astounding progress, producing fascinating results in open-domain image manipulation tasks. Few models, however, currently have complete zero-shot capabilities for both global and local image editing due to the complexity and diversity of image manipulation tasks. In this work, we propose a method with a mixture-of-expert (MOE) controllers to align the text-guided capacity of diffusion models with different kinds of human instructions, enabling our model to handle various open-domain image manipulation tasks with natural language instructions. First, we use large language models (ChatGPT) and conditional image synthesis models (ControlNet) to generate a large number of global image transfer dataset in addition to the instruction-based local image editing dataset. Then, using an MOE technique and task-specific adaptation training on a large-scale dataset, our conditional diffusion model can edit images globally and locally. Extensive experiments demonstrate that our approach performs surprisingly well on various image manipulation tasks when dealing with open-domain images and arbitrary human instructions. Please refer to our project page: [https://oppo-mente-lab.github.io/moe_controller/] ","[{'version': 'v1', 'created': 'Fri, 8 Sep 2023 15:06:05 GMT'}]",2023-09-11,"[['Li', 'Sijia', ''], ['Chen', 'Chen', ''], ['Lu', 'Haonan', '']]",1,1,2023-09-08,1,3,2,1,0,1,6deb76b8ac8d35dded7dd76d768a245bb69ffe91,261660692.0,https://www.semanticscholar.org/paper/6deb76b8ac8d35dded7dd76d768a245bb69ffe91,arXiv.org,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238948430', 'name': 'Sijia Li'}, {'authorId': '2141809694', 'name': 'Chen Chen'}, {'authorId': '2130373', 'name': 'H. Lu'}]",['OPPO'],['China'],2023-09,['industrial']
2309.04827,Elena Voita,"Elena Voita, Javier Ferrando, Christoforos Nalmpantis","Neurons in Large Language Models: Dead, N-gram, Positional",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the network is sparse and represents many discrete features. Here, many neurons (more than 70% in some layers of the 66b model) are ""dead"", i.e. they never activate on a large collection of diverse data. At the same time, many of the alive neurons are reserved for discrete features and act as token and n-gram detectors. Interestingly, their corresponding FFN updates not only promote next token candidates as could be expected, but also explicitly focus on removing the information about triggering them tokens, i.e., current input. To the best of our knowledge, this is the first example of mechanisms specialized at removing (rather than adding) information from the residual stream. With scale, models become more sparse in a sense that they have more dead neurons and token detectors. Finally, some neurons are positional: them being activated or not depends largely (or solely) on position and less so (or not at all) on textual data. We find that smaller models have sets of neurons acting as position range indicators while larger models operate in a less explicit manner. ","[{'version': 'v1', 'created': 'Sat, 9 Sep 2023 15:51:36 GMT'}]",2023-09-12,"[['Voita', 'Elena', ''], ['Ferrando', 'Javier', ''], ['Nalmpantis', 'Christoforos', '']]",0,0,2023-09-09,1,3,1,1,1,0,110804428354df709b3693f9efc81946a9036ebf,261682169.0,https://www.semanticscholar.org/paper/110804428354df709b3693f9efc81946a9036ebf,arXiv.org,2023.0,53.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46235299', 'name': 'Elena Voita'}, {'authorId': '1751450782', 'name': 'Javier Ferrando'}, {'authorId': '31434304', 'name': 'Christoforos Nalmpantis'}]",['Universitat Politècnica de Catalunya'],['Spain'],2023-09,['industrial']
2309.05248,Taejin Park,"Tae Jin Park, Kunal Dhawan, Nithin Koluguri, Jagadeesh Balam",Enhancing Speaker Diarization with Large Language Models: A Contextual Beam Search Approach,"4 pages 1 reference page, ICASSP format",,,,eess.AS cs.SD,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have shown great promise for capturing contextual information in natural language processing tasks. We propose a novel approach to speaker diarization that incorporates the prowess of LLMs to exploit contextual cues in human dialogues. Our method builds upon an acoustic-based speaker diarization system by adding lexical information from an LLM in the inference stage. We model the multi-modal decoding process probabilistically and perform joint acoustic and lexical beam search to incorporate cues from both modalities: audio and text. Our experiments demonstrate that infusing lexical knowledge from the LLM into an acoustics-only diarization system improves overall speaker-attributed word error rate (SA-WER). The experimental results show that LLMs can provide complementary information to acoustic models for the speaker diarization task via proposed beam search decoding approach showing up to 39.8% relative delta-SA-WER improvement from the baseline system. Thus, we substantiate that the proposed technique is able to exploit contextual information that is inaccessible to acoustics-only systems which is represented by speaker embeddings. In addition, these findings point to the potential of using LLMs to improve speaker diarization and other speech processing tasks by capturing semantic and contextual cues. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 05:47:56 GMT'}, {'version': 'v2', 'created': 'Wed, 13 Sep 2023 16:16:16 GMT'}, {'version': 'v3', 'created': 'Thu, 14 Sep 2023 01:08:08 GMT'}]",2023-09-15,"[['Park', 'Tae Jin', ''], ['Dhawan', 'Kunal', ''], ['Koluguri', 'Nithin', ''], ['Balam', 'Jagadeesh', '']]",0,0,2023-09-11,3,4,2,0,0,0,d1b53b0cab29eae561cae8d5929a5a68761ccaed,261681807.0,https://www.semanticscholar.org/paper/d1b53b0cab29eae561cae8d5929a5a68761ccaed,arXiv.org,2023.0,38.0,0.0,0.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238951921', 'name': 'Tae Jin Park'}, {'authorId': '79303130', 'name': 'Kunal Dhawan'}, {'authorId': '17909597', 'name': 'N. Koluguri'}, {'authorId': '2494510', 'name': 'J. Balam'}]",['Nvidia (United States)'],['United States'],2023-09,['industrial']
2309.05463,Suriya Gunasekar,"Yuanzhi Li, S\'ebastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya
  Gunasekar, Yin Tat Lee",Textbooks Are All You Need II: phi-1.5 technical report,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We continue the investigation into the power of smaller Transformer-based language models as initiated by \textbf{TinyStories} -- a 10 million parameter model that can produce coherent English -- and the follow-up work on \textbf{phi-1}, a 1.3 billion parameter model with Python coding performance close to the state-of-the-art. The latter work proposed to use existing Large Language Models (LLMs) to generate ``textbook quality"" data as a way to enhance the learning process compared to traditional web data. We follow the ``Textbooks Are All You Need"" approach, focusing this time on common sense reasoning in natural language, and create a new 1.3 billion parameter model named \textbf{phi-1.5}, with performance on natural language tasks comparable to models 5x larger, and surpassing most non-frontier LLMs on more complex reasoning tasks such as grade-school mathematics and basic coding. More generally, \textbf{phi-1.5} exhibits many of the traits of much larger LLMs, both good -- such as the ability to ``think step by step"" or perform some rudimentary in-context learning -- and bad, including hallucinations and the potential for toxic and biased generations -- encouragingly though, we are seeing improvement on that front thanks to the absence of web data. We open-source \textbf{phi-1.5} to promote further research on these urgent topics. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 14:01:45 GMT'}]",2023-09-12,"[['Li', 'Yuanzhi', ''], ['Bubeck', 'Sébastien', ''], ['Eldan', 'Ronen', ''], ['Del Giorno', 'Allie', ''], ['Gunasekar', 'Suriya', ''], ['Lee', 'Yin Tat', '']]",0,0,2023-09-11,1,6,2,0,0,0,e26888285436bc7998e5c95102a9beb60144be5e,261696657.0,https://www.semanticscholar.org/paper/e26888285436bc7998e5c95102a9beb60144be5e,arXiv.org,2023.0,39.0,21.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '152244300', 'name': 'Yuan-Fang Li'}, {'authorId': '1815542', 'name': 'Sébastien Bubeck'}, {'authorId': '2315830', 'name': 'Ronen Eldan'}, {'authorId': '50672277', 'name': 'Allison Del Giorno'}, {'authorId': '3317356', 'name': 'Suriya Gunasekar'}, {'authorId': '2239163839', 'name': 'Yin Tat Lee'}]",['Microsoft'],['India'],2023-09,['industrial']
2309.05858,Johannes Von Oswald Jvo,"Johannes von Oswald, Eyvind Niklasson, Maximilian Schlegel, Seijin
  Kobayashi, Nicolas Zucchet, Nino Scherrer, Nolan Miller, Mark Sandler, Blaise
  Ag\""uera y Arcas, Max Vladymyrov, Razvan Pascanu, Jo\~ao Sacramento",Uncovering mesa-optimization algorithms in Transformers,,,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transformers have become the dominant model in deep learning, but the reason for their superior performance is poorly understood. Here, we hypothesize that the strong performance of Transformers stems from an architectural bias towards mesa-optimization, a learned process running within the forward pass of a model consisting of the following two steps: (i) the construction of an internal learning objective, and (ii) its corresponding solution found through optimization. To test this hypothesis, we reverse-engineer a series of autoregressive Transformers trained on simple sequence modeling tasks, uncovering underlying gradient-based mesa-optimization algorithms driving the generation of predictions. Moreover, we show that the learned forward-pass optimization algorithm can be immediately repurposed to solve supervised few-shot tasks, suggesting that mesa-optimization might underlie the in-context learning capabilities of large language models. Finally, we propose a novel self-attention layer, the mesa-layer, that explicitly and efficiently solves optimization problems specified in context. We find that this layer can lead to improved performance in synthetic and preliminary language modeling experiments, adding weight to our hypothesis that mesa-optimization is an important operation hidden within the weights of trained Transformers. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 22:42:50 GMT'}]",2023-09-13,"[['von Oswald', 'Johannes', ''], ['Niklasson', 'Eyvind', ''], ['Schlegel', 'Maximilian', ''], ['Kobayashi', 'Seijin', ''], ['Zucchet', 'Nicolas', ''], ['Scherrer', 'Nino', ''], ['Miller', 'Nolan', ''], ['Sandler', 'Mark', ''], ['Arcas', 'Blaise Agüera y', ''], ['Vladymyrov', 'Max', ''], ['Pascanu', 'Razvan', ''], ['Sacramento', 'João', '']]",0,0,2023-09-11,1,12,2,0,0,0,9bb3deca32af8d632e0d916c587cca6c185a6576,261696852.0,https://www.semanticscholar.org/paper/9bb3deca32af8d632e0d916c587cca6c185a6576,arXiv.org,2023.0,78.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145167136', 'name': 'J. Oswald'}, {'authorId': '51440033', 'name': 'Eyvind Niklasson'}, {'authorId': '2239102711', 'name': 'Maximilian Schlegel'}, {'authorId': '51194506', 'name': 'Seijin Kobayashi'}, {'authorId': '1729494470', 'name': 'Nicolas Zucchet'}, {'authorId': '1742339548', 'name': 'Nino Scherrer'}, {'authorId': '2072802717', 'name': 'Nolan Miller'}, {'authorId': '2239103735', 'name': 'Mark Sandler'}, {'authorId': '2661025', 'name': 'B. A. Y. Arcas'}, {'authorId': '3316311', 'name': 'Max Vladymyrov'}, {'authorId': '1996134', 'name': 'Razvan Pascanu'}, {'authorId': '3105061', 'name': 'J. Sacramento'}]","['Google', 'ETH Zurich']","['United States', 'Switzerland']",2023-09,"['industrial', 'industrial']"
2309.06112,Sharath Srivatsa,"Sharath Srivatsa, Srinath Srinivasa",Characterizing Latent Perspectives of Media Houses Towards Public Figures,,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Media houses reporting on public figures, often come with their own biases stemming from their respective worldviews. A characterization of these underlying patterns helps us in better understanding and interpreting news stories. For this, we need diverse or subjective summarizations, which may not be amenable for classifying into predefined class labels. This work proposes a zero-shot approach for non-extractive or generative characterizations of person entities from a corpus using GPT-2. We use well-articulated articles from several well-known news media houses as a corpus to build a sound argument for this approach. First, we fine-tune a GPT-2 pre-trained language model with a corpus where specific person entities are characterized. Second, we further fine-tune this with demonstrations of person entity characterizations, created from a corpus of programmatically constructed characterizations. This twice fine-tuned model is primed with manual prompts consisting of entity names that were not previously encountered in the second fine-tuning, to generate a simple sentence about the entity. The results were encouraging, when compared against actual characterizations from the corpus. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 10:27:39 GMT'}]",2023-09-13,"[['Srivatsa', 'Sharath', ''], ['Srinivasa', 'Srinath', '']]",0,1,2023-09-12,1,2,2,1,1,0,4b8b45a1ecc8a69ed2285629d47aaa1589387023,261696989.0,https://www.semanticscholar.org/paper/4b8b45a1ecc8a69ed2285629d47aaa1589387023,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1870621', 'name': 'S. Srivatsa'}, {'authorId': '144427922', 'name': 'S. Srinivasa'}]",['International Institute of Information Technology Bangalore'],['India'],2023-09,['industrial']
2309.06236,Dimitris Spathis,"Dimitris Spathis, Fahim Kawsar",The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models,"Accepted at the Generative AI for Pervasive Computing Symposium
  (GenAI4PC) at UbiComp 2023",,,,cs.LG cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large Language Models (LLMs) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines. Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records. LLMs employ tokenizers in their input that break down text into smaller units. However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships. Here, we discuss recent works that employ LLMs for human-centric tasks such as in mobile health sensing and present a case study showing that popular LLMs tokenize temporal data incorrectly. To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that can help bridge this ""modality gap"". While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper underscores the fact that their outputs cannot be meaningful if they stumble over input nuances. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 13:51:29 GMT'}]",2023-09-13,"[['Spathis', 'Dimitris', ''], ['Kawsar', 'Fahim', '']]",0,0,2023-09-12,1,2,2,0,0,0,0b778079946764292de3771a489d5ce9e1868a8b,261697232.0,https://www.semanticscholar.org/paper/0b778079946764292de3771a489d5ce9e1868a8b,arXiv.org,2023.0,39.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143996434', 'name': 'Dimitris Spathis'}, {'authorId': '1776175', 'name': 'F. Kawsar'}]","['Nokia Bell Labs Cambridge, UK']",,2023-09,['industrial']
2309.06275,Chongyang Tao,"Xiaohan Xu, Chongyang Tao, Tao Shen, Can Xu, Hongbo Xu, Guodong Long,
  Jian-guang Lou",Re-Reading Improves Reasoning in Language Models,25 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Reasoning presents a significant and challenging issue for Large Language Models (LLMs). The predominant focus of research has revolved around developing diverse prompting strategies to guide and structure the reasoning processes of LLMs. However, these approaches based on decoder-only causal language models often operate the input question in a single forward pass, potentially missing the rich, back-and-forth interactions inherent in human reasoning. Scant attention has been paid to a critical dimension, i.e., the input question itself embedded within the prompts. In response, we introduce a deceptively simple yet highly effective prompting strategy, termed question ""re-reading"". Drawing inspiration from human learning and problem-solving, re-reading entails revisiting the question information embedded within input prompts. This approach aligns seamlessly with the cognitive principle of reinforcement, enabling LLMs to extract deeper insights, identify intricate patterns, establish more nuanced connections, and ultimately enhance their reasoning capabilities across various tasks. Experiments conducted on a series of reasoning benchmarks serve to underscore the effectiveness and generality of our method. Moreover, our findings demonstrate that our approach seamlessly integrates with various language models, though-eliciting prompting methods, and ensemble techniques, further underscoring its versatility and compatibility in the realm of LLMs. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 14:36:23 GMT'}]",2023-09-13,"[['Xu', 'Xiaohan', ''], ['Tao', 'Chongyang', ''], ['Shen', 'Tao', ''], ['Xu', 'Can', ''], ['Xu', 'Hongbo', ''], ['Long', 'Guodong', ''], ['Lou', 'Jian-guang', '']]",0,0,2023-09-12,1,7,1,0,0,0,e7c85d7d58d4b1fde4be8a8f166e46c995dc0f1b,261696483.0,https://www.semanticscholar.org/paper/e7c85d7d58d4b1fde4be8a8f166e46c995dc0f1b,arXiv.org,2023.0,72.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2188774115', 'name': 'Xiaohan Xu'}, {'authorId': '8801869', 'name': 'Chongyang Tao'}, {'authorId': '143681703', 'name': 'Tao Shen'}, {'authorId': '46747953', 'name': 'Can Xu'}, {'authorId': '2239160918', 'name': 'Hongbo Xu'}, {'authorId': '2062835', 'name': 'Guodong Long'}, {'authorId': '4648762', 'name': 'Jian-Guang Lou'}]",['Institute of Information Engineering'],['China'],2023-09,['industrial']
2309.06342,Changjie Wang,"Changjie Wang, Mariano Scazzariello, Alireza Farshin, Dejan Kostic and
  Marco Chiesa",Making Network Configuration Human Friendly,"6 pages,3 figures",,,,cs.NI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices and minimizing errors. We examine the effectiveness of these models in translating high-level policies and requirements (i.e., specified in natural language) into low-level network APIs, which requires understanding the hardware and protocols. More specifically, we propose NETBUDDY for generating network configurations from scratch and modifying them at runtime. NETBUDDY splits the generation of network configurations into fine-grained steps and relies on self-healing code-generation approaches to better take advantage of the full potential of LLMs. We first thoroughly examine the challenges of using these models to produce a fully functional & correct configuration, and then evaluate the feasibility of realizing NETBUDDY by building a proof-of-concept solution using GPT-4 to translate a set of high-level requirements into P4 and BGP configurations and run them using the Kathar\'a network emulator. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 16:02:07 GMT'}]",2023-09-13,"[['Wang', 'Changjie', ''], ['Scazzariello', 'Mariano', ''], ['Farshin', 'Alireza', ''], ['Kostic', 'Dejan', ''], ['Chiesa', 'Marco', '']]",0,1,2023-09-12,1,5,1,1,0,1,5ba398a4e64c688de82c5b8f26583d86269a3781,261696620.0,https://www.semanticscholar.org/paper/5ba398a4e64c688de82c5b8f26583d86269a3781,arXiv.org,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2239168925', 'name': 'Changjie Wang'}, {'authorId': '2239098972', 'name': 'Mariano Scazzariello'}, {'authorId': '9601220', 'name': 'Alireza Farshin'}, {'authorId': '144914281', 'name': 'Dejan Kostic'}, {'authorId': '2239100004', 'name': 'Marco Chiesa'}]",['RISE Research Institutes of Sweden'],['Sweden'],2023-09,['industrial']
2309.06557,Adam Lehavi,"Adam M. Lehavi, William McCormack, Noah Kornfeld and Solomon Glazer",Unsupervised Bias Detection in College Student Newspapers,"7 pages, 5 figures, 3 tables, submitted to AAAI2024",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This paper presents a pipeline with minimal human influence for scraping and detecting bias on college newspaper archives. This paper introduces a framework for scraping complex archive sites that automated tools fail to grab data from, and subsequently generates a dataset of 14 student papers with 23,154 entries. This data can also then be queried by keyword to calculate bias by comparing the sentiment of a large language model summary to the original article. The advantages of this approach are that it is less comparative than reconstruction bias and requires less labelled data than generating keyword sentiment. Results are calculated on politically charged words as well as control words to show how conclusions can be drawn. The complete method facilitates the extraction of nuanced insights with minimal assumptions and categorizations, paving the way for a more objective understanding of bias within student newspaper sources. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 06:51:09 GMT'}]",2023-09-14,"[['Lehavi', 'Adam M.', ''], ['McCormack', 'William', ''], ['Kornfeld', 'Noah', ''], ['Glazer', 'Solomon', '']]",0,0,2023-09-11,1,4,3,0,0,0,5ce8d9b68421ce071f4c30071a3d1867b773c1d5,261705833.0,https://www.semanticscholar.org/paper/5ce8d9b68421ce071f4c30071a3d1867b773c1d5,arXiv.org,2023.0,19.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2212526557', 'name': 'Adam Lehavi'}, {'authorId': '2239198334', 'name': 'William McCormack'}, {'authorId': '2239198352', 'name': 'Noah Kornfeld'}, {'authorId': '2239199967', 'name': 'Solomon Glazer'}]",['Social Media Climate Initiative'],,2023-09,['industrial']
2309.06759,Ting Hu,"Ting Hu, Christoph Meinel, Haojin Yang",Scaled Prompt-Tuning for Few-Shot Natural Language Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The increasingly Large Language Models (LLMs) demonstrate stronger language understanding and generation capabilities, while the memory demand and computation cost of fine-tuning LLMs on downstream tasks are non-negligible. Besides, fine-tuning generally requires a certain amount of data from individual tasks whilst data collection cost is another issue to consider in real-world applications. In this work, we focus on Parameter-Efficient Fine-Tuning (PEFT) methods for few-shot Natural Language Generation (NLG), which freeze most parameters in LLMs and tune a small subset of parameters in few-shot cases so that memory footprint, training cost, and labeling cost are reduced while maintaining or even improving the performance. We propose a Scaled Prompt-Tuning (SPT) method which surpasses conventional PT with better performance and generalization ability but without an obvious increase in training cost. Further study on intermediate SPT suggests the superior transferability of SPT in few-shot scenarios, providing a recipe for data-deficient and computation-limited circumstances. Moreover, a comprehensive comparison of existing PEFT methods reveals that certain approaches exhibiting decent performance with modest training cost such as Prefix-Tuning in prior study could struggle in few-shot NLG tasks, especially on challenging datasets. ","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 07:12:31 GMT'}]",2023-09-14,"[['Hu', 'Ting', ''], ['Meinel', 'Christoph', ''], ['Yang', 'Haojin', '']]",0,0,2023-09-13,1,3,1,0,0,0,ed4cfe818d18092b3fe0ca3c43de28728e2f0d2e,261705827.0,https://www.semanticscholar.org/paper/ed4cfe818d18092b3fe0ca3c43de28728e2f0d2e,arXiv.org,2023.0,22.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1811091645', 'name': 'Ting Hu'}, {'authorId': '2239199657', 'name': 'Christoph Meinel'}, {'authorId': '1688587', 'name': 'Haojin Yang'}]",['Hasso Plattner Institute'],['Germany'],2023-09,['industrial']
2309.07207,Michael Smith,"Michael J. Smith, Luke Fleming and James E. Geach",EarthPT: a foundation model for Earth Observation,"7 pages, 4 figures, submitted to NeurIPS CCAI workshop",,,,cs.LG physics.geo-ph,http://creativecommons.org/licenses/by-sa/4.0/,"  We introduce EarthPT -- an Earth Observation (EO) pretrained transformer. EarthPT is a 700 million parameter decoding transformer foundation model trained in an autoregressive self-supervised manner and developed specifically with EO use-cases in mind. We demonstrate that EarthPT is an effective forecaster that can accurately predict future pixel-level surface reflectances across the 400-2300 nm range well into the future. For example, forecasts of the evolution of the Normalised Difference Vegetation Index (NDVI) have a typical error of approximately 0.05 (over a natural range of -1 -> 1) at the pixel level over a five month test set horizon, out-performing simple phase-folded models based on historical averaging. We also demonstrate that embeddings learnt by EarthPT hold semantically meaningful information and could be exploited for downstream tasks such as highly granular, dynamic land use classification. Excitingly, we note that the abundance of EO data provides us with -- in theory -- quadrillions of training tokens. Therefore, if we assume that EarthPT follows neural scaling laws akin to those derived for Large Language Models (LLMs), there is currently no data-imposed limit to scaling EarthPT and other similar `Large Observation Models.' ","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 18:00:00 GMT'}]",2023-09-15,"[['Smith', 'Michael J.', ''], ['Fleming', 'Luke', ''], ['Geach', 'James E.', '']]",0,0,2023-09-13,1,3,2,0,0,0,6483a6f2038cd8583ad5b6678602bc904459a7f7,261822778.0,https://www.semanticscholar.org/paper/6483a6f2038cd8583ad5b6678602bc904459a7f7,arXiv.org,2023.0,30.0,0.0,0.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}, {'category': 'Geology', 'source': 's2-fos-model'}]","[{'authorId': '145618949', 'name': 'Michael J. Smith'}, {'authorId': '2240522321', 'name': 'Luke Fleming'}, {'authorId': '2308961', 'name': 'J. Geach'}]","['Aspia Space Ltd., Cornwall, UK']",,2023-09,['industrial']
2309.07414,Xiaoyu Yang,"Xiaoyu Yang, Wei Kang, Zengwei Yao, Yifan Yang, Liyong Guo, Fangjun
  Kuang, Long Lin, Daniel Povey",PromptASR for contextualized ASR with controllable style,Submitted to ICASSP2024,,,,eess.AS cs.CL cs.SD,http://creativecommons.org/licenses/by/4.0/,"  Prompts are crucial to large language models as they provide context information such as topic or logical relationships. Inspired by this, we propose PromptASR, a framework that integrates prompts in end-to-end automatic speech recognition (E2E ASR) systems to achieve contextualized ASR with controllable style of transcriptions. Specifically, a dedicated text encoder encodes the text prompts and the encodings are injected into the speech encoder by cross-attending the features from two modalities. When using the ground truth text from preceding utterances as content prompt, the proposed system achieves 21.9% and 6.8% relative word error rate reductions on a book reading dataset and an in-house dataset compared to a baseline ASR system. The system can also take word-level biasing lists as prompt to improve recognition accuracy on rare words. An additional style prompt can be given to the text encoder and guide the ASR system to output different styles of transcriptions. The code is available at icefall. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 03:43:07 GMT'}, {'version': 'v2', 'created': 'Wed, 20 Sep 2023 09:13:11 GMT'}]",2023-09-21,"[['Yang', 'Xiaoyu', ''], ['Kang', 'Wei', ''], ['Yao', 'Zengwei', ''], ['Yang', 'Yifan', ''], ['Guo', 'Liyong', ''], ['Kuang', 'Fangjun', ''], ['Lin', 'Long', ''], ['Povey', 'Daniel', '']]",0,0,2023-09-14,2,8,3,0,0,0,17e172a2f4072bd79642ec2b2a57213d6dad17b6,261816860.0,https://www.semanticscholar.org/paper/17e172a2f4072bd79642ec2b2a57213d6dad17b6,arXiv.org,2023.0,23.0,0.0,0.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2240481720', 'name': 'Xiaoyu Yang'}, {'authorId': '2173705674', 'name': 'Wei Kang'}, {'authorId': '134909283', 'name': 'Zengwei Yao'}, {'authorId': '2240498753', 'name': 'Yifan Yang'}, {'authorId': '2110520397', 'name': 'Liyong Guo'}, {'authorId': '2173755887', 'name': 'Fangjun Kuang'}, {'authorId': '2173759681', 'name': 'Long Lin'}, {'authorId': '2240534673', 'name': 'Daniel Povey'}]","['Xiaomi Corp. Beijing, China']",['China'],2023-09,['industrial']
2309.07462,Rishav Hada,"Rishav Hada, Varun Gumma, Adrian de Wynter, Harshita Diddee, Mohamed
  Ahmed, Monojit Choudhury, Kalika Bali, Sunayana Sitaram",Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have demonstrated impressive performance on Natural Language Processing (NLP) tasks, such as Question Answering, Summarization, and Classification. The use of LLMs as evaluators, that can rank or score the output of other models (usually LLMs) has become increasingly popular, due to the limitations of current evaluation techniques including the lack of appropriate benchmarks, metrics, cost, and access to human annotators. While LLMs are capable of handling approximately 100 languages, the majority of languages beyond the top 20 lack systematic evaluation across various tasks, metrics, and benchmarks. This creates an urgent need to scale up multilingual evaluation to ensure a precise understanding of LLM performance across diverse languages. LLM-based evaluators seem like the perfect solution to this problem, as they do not require human annotators, human-created references, or benchmarks and can theoretically be used to evaluate any language covered by the LLM. In this paper, we investigate whether LLM-based evaluators can help scale up multilingual evaluation. Specifically, we calibrate LLM-based evaluation against 20k human judgments of five metrics across three text-generation tasks in eight languages. Our findings indicate that LLM-based evaluators may exhibit bias towards higher scores and should be used with caution and should always be calibrated with a dataset of native speaker judgments, particularly in low-resource and non-Latin script languages. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 06:41:58 GMT'}]",2023-09-15,"[['Hada', 'Rishav', ''], ['Gumma', 'Varun', ''], ['de Wynter', 'Adrian', ''], ['Diddee', 'Harshita', ''], ['Ahmed', 'Mohamed', ''], ['Choudhury', 'Monojit', ''], ['Bali', 'Kalika', ''], ['Sitaram', 'Sunayana', '']]",0,0,2023-09-14,1,8,1,0,0,0,37cbf656ca8b76f29684c37c2ee43118d5bd8a8c,261822638.0,https://www.semanticscholar.org/paper/37cbf656ca8b76f29684c37c2ee43118d5bd8a8c,arXiv.org,2023.0,35.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35831406', 'name': 'Rishav Hada'}, {'authorId': '2140408530', 'name': 'Varun Gumma'}, {'authorId': '1388060354', 'name': 'Adrian de Wynter'}, {'authorId': '2135014756', 'name': 'Harshita Diddee'}, {'authorId': '2241140429', 'name': 'Mohamed Ahmed'}, {'authorId': '143990839', 'name': 'M. Choudhury'}, {'authorId': '3086996', 'name': 'Kalika Bali'}, {'authorId': '3010457', 'name': 'Sunayana Sitaram'}]",['Microsoft'],['United States'],2023-09,['industrial']
2309.07544,Mingjie Liu,"Mingjie Liu, Nathaniel Pinckney, Brucek Khailany and Haoxing Ren",VerilogEval: Evaluating Large Language Models for Verilog Code Generation,ICCAD 2023 Invited Paper,,,,cs.LG cs.SE,http://creativecommons.org/licenses/by/4.0/,"  The increasing popularity of large language models (LLMs) has paved the way for their application in diverse domains. This paper proposes a benchmarking framework tailored specifically for evaluating LLM performance in the context of Verilog code generation for hardware design and verification. We present a comprehensive evaluation dataset consisting of 156 problems from the Verilog instructional website HDLBits. The evaluation set consists of a diverse set of Verilog code generation tasks, ranging from simple combinational circuits to complex finite state machines. The Verilog code completions can be automatically tested for functional correctness by comparing the transient simulation outputs of the generated design with a golden solution. We also demonstrate that the Verilog code generation capability of pretrained language models could be improved with supervised fine-tuning by bootstrapping with LLM generated synthetic problem-code pairs. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 09:15:34 GMT'}]",2023-09-15,"[['Liu', 'Mingjie', ''], ['Pinckney', 'Nathaniel', ''], ['Khailany', 'Brucek', ''], ['Ren', 'Haoxing', '']]",0,0,2023-09-14,1,4,2,0,0,0,cbd81507197e2d32b6f6c8ac99039f3a607ee8f1,261822682.0,https://www.semanticscholar.org/paper/cbd81507197e2d32b6f6c8ac99039f3a607ee8f1,arXiv.org,2023.0,34.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2264029479', 'name': 'Mingjie Liu'}, {'authorId': '1787005', 'name': 'N. Pinckney'}, {'authorId': '2125244', 'name': 'Brucek Khailany'}, {'authorId': '40046703', 'name': 'Haoxing Ren'}]",['Nvidia (United States)'],['United States'],2023-09,['industrial']
2309.07683,Ann Speed,Ann Speed,Assessing the nature of large language models: A caution against anthropocentrism,"30 pages, 6 figures",,,,cs.AI cs.CL cs.CY cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Generative AI models garnered a large amount of public attention and speculation with the release of OpenAIs chatbot, ChatGPT. At least two opinion camps exist: one excited about possibilities these models offer for fundamental changes to human tasks, and another highly concerned about power these models seem to have. To address these concerns, we assessed GPT3.5 using standard, normed, and validated cognitive and personality measures. For this seedling project, we developed a battery of tests that allowed us to estimate the boundaries of some of these models capabilities, how stable those capabilities are over a short period of time, and how they compare to humans.   Our results indicate that GPT 3.5 is unlikely to have developed sentience, although its ability to respond to personality inventories is interesting. It did display large variability in both cognitive and personality measures over repeated observations, which is not expected if it had a human-like personality. Variability notwithstanding, GPT3.5 displays what in a human would be considered poor mental health, including low self-esteem and marked dissociation from reality despite upbeat and helpful responses. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 12:58:30 GMT'}]",2023-09-15,"[['Speed', 'Ann', '']]",1,1,2023-09-14,1,1,4,2,0,2,f9b2286929521b54d47746d02e0fba2bb2122800,261824086.0,https://www.semanticscholar.org/paper/f9b2286929521b54d47746d02e0fba2bb2122800,arXiv.org,2023.0,67.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2240556299', 'name': 'Ann Speed'}]",['Sandia National Laboratories'],['United States'],2023-09,['industrial']
2309.07755,Harika Abburi,"Harika Abburi, Michael Suesserman, Nirmala Pudota, Balaji Veeramani,
  Edward Bowen, Sanmitra Bhattacharya",Generative AI Text Classification using Ensemble LLM Approaches,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large Language Models (LLMs) have shown impressive performance across a variety of Artificial Intelligence (AI) and natural language processing tasks, such as content creation, report generation, etc. However, unregulated malign application of these models can create undesirable consequences such as generation of fake news, plagiarism, etc. As a result, accurate detection of AI-generated language can be crucial in responsible usage of LLMs. In this work, we explore 1) whether a certain body of text is AI generated or written by human, and 2) attribution of a specific language model in generating a body of text. Texts in both English and Spanish are considered. The datasets used in this study are provided as part of the Automated Text Identification (AuTexTification) shared task. For each of the research objectives stated above, we propose an ensemble neural model that generates probabilities from different pre-trained LLMs which are used as features to a Traditional Machine Learning (TML) classifier following it. For the first task of distinguishing between AI and human generated text, our model ranked in fifth and thirteenth place (with macro $F1$ scores of 0.733 and 0.649) for English and Spanish texts, respectively. For the second task on model attribution, our model ranked in first place with macro $F1$ scores of 0.625 and 0.653 for English and Spanish texts, respectively. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 14:41:46 GMT'}]",2023-09-15,"[['Abburi', 'Harika', ''], ['Suesserman', 'Michael', ''], ['Pudota', 'Nirmala', ''], ['Veeramani', 'Balaji', ''], ['Bowen', 'Edward', ''], ['Bhattacharya', 'Sanmitra', '']]",0,0,2023-09-14,1,6,2,0,0,0,7c629ca898fb8c87dd363a16d43f29f6ed44dfa8,261822935.0,https://www.semanticscholar.org/paper/7c629ca898fb8c87dd363a16d43f29f6ed44dfa8,arXiv.org,2023.0,39.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3442296', 'name': 'Harika Abburi'}, {'authorId': '2220825339', 'name': 'Michael Suesserman'}, {'authorId': '3168335', 'name': 'Nirmala Pudota'}, {'authorId': '2187682029', 'name': 'Balaji Veeramani'}, {'authorId': '2240528415', 'name': 'Edward Bowen'}, {'authorId': '3106278', 'name': 'Sanmitra Bhattacharya'}]","['Deloitte & Touche Assurance & Enterprise Risk Services India Private Limited, India', 'Deloitte & Touche LLP, USA']","['India', 'United States']",2023-09,"['industrial', 'industrial']"
2309.07864,Zhiheng Xi,"Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong,
  Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao
  Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou,
  Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi
  Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, Tao Gui",The Rise and Potential of Large Language Model Based Agents: A Survey,"86 pages, 12 figures",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many researchers have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. In this paper, we perform a comprehensive survey on LLM-based agents. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for agents. Building upon this, we present a general framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored for different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge from an agent society, and the insights they offer for human society. Finally, we discuss several key topics and open problems within the field. A repository for the related papers at https://github.com/WooooDyy/LLM-Agent-Paper-List. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 17:12:03 GMT'}, {'version': 'v2', 'created': 'Fri, 15 Sep 2023 01:46:36 GMT'}, {'version': 'v3', 'created': 'Tue, 19 Sep 2023 08:29:18 GMT'}]",2023-09-20,"[['Xi', 'Zhiheng', ''], ['Chen', 'Wenxiang', ''], ['Guo', 'Xin', ''], ['He', 'Wei', ''], ['Ding', 'Yiwen', ''], ['Hong', 'Boyang', ''], ['Zhang', 'Ming', ''], ['Wang', 'Junzhe', ''], ['Jin', 'Senjie', ''], ['Zhou', 'Enyu', ''], ['Zheng', 'Rui', ''], ['Fan', 'Xiaoran', ''], ['Wang', 'Xiao', ''], ['Xiong', 'Limao', ''], ['Zhou', 'Yuhao', ''], ['Wang', 'Weiran', ''], ['Jiang', 'Changhao', ''], ['Zou', 'Yicheng', ''], ['Liu', 'Xiangyang', ''], ['Yin', 'Zhangyue', ''], ['Dou', 'Shihan', ''], ['Weng', 'Rongxiang', ''], ['Cheng', 'Wensen', ''], ['Zhang', 'Qi', ''], ['Qin', 'Wenjuan', ''], ['Zheng', 'Yongyan', ''], ['Qiu', 'Xipeng', ''], ['Huang', 'Xuanjing', ''], ['Gui', 'Tao', '']]",0,0,2023-09-14,3,29,2,0,0,0,0c72450890a54b68d63baa99376131fda8f06cf9,261817592.0,https://www.semanticscholar.org/paper/0c72450890a54b68d63baa99376131fda8f06cf9,arXiv.org,2023.0,0.0,36.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2190751523', 'name': 'Zhiheng Xi'}, {'authorId': '2240538633', 'name': 'Wenxiang Chen'}, {'authorId': '2240675422', 'name': 'Xin Guo'}, {'authorId': '2241408708', 'name': 'Wei He'}, {'authorId': '2240473116', 'name': 'Yiwen Ding'}, {'authorId': '2240450431', 'name': 'Boyang Hong'}, {'authorId': '2240574799', 'name': 'Ming Zhang'}, {'authorId': '2240465418', 'name': 'Junzhe Wang'}, {'authorId': '2219131195', 'name': 'Senjie Jin'}, {'authorId': '2240446306', 'name': 'Enyu Zhou'}, {'authorId': '2058585152', 'name': 'Rui Zheng'}, {'authorId': '2241140630', 'name': 'Xiaoran Fan'}, {'authorId': '2118451107', 'name': 'Xiao Wang'}, {'authorId': '2222630539', 'name': 'Limao Xiong'}, {'authorId': '2109185819', 'name': 'Qin Liu'}, {'authorId': '2212175381', 'name': 'Yuhao Zhou'}, {'authorId': '2240703461', 'name': 'Weiran Wang'}, {'authorId': '2240482661', 'name': 'Changhao Jiang'}, {'authorId': '51192034', 'name': 'Yicheng Zou'}, {'authorId': '2144226697', 'name': 'Xiangyang Liu'}, {'authorId': '2155273086', 'name': 'Zhangyue Yin'}, {'authorId': '2042683163', 'name': 'Shihan Dou'}, {'authorId': '24009282', 'name': 'Rongxiang Weng'}, {'authorId': '2211998291', 'name': 'Wensen Cheng'}, {'authorId': '2256972399', 'name': 'Qi Zhang'}, {'authorId': '2240455955', 'name': 'Wenjuan Qin'}, {'authorId': '2240450583', 'name': 'Yongyan Zheng'}, {'authorId': '1767521', 'name': 'Xipeng Qiu'}, {'authorId': '2240462620', 'name': 'Xuanjing Huan'}, {'authorId': '2067331064', 'name': 'Tao Gui'}]",['Fudan NLP Group'],,2023-09,['industrial']
2309.07938,Priyanka Mudgal,"Priyanka Mudgal, Rita Wouhaybi",An Assessment of ChatGPT on Log Data,Accepeted at AIGC 2023,,,,cs.SE cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Recent development of large language models (LLMs), such as ChatGPT has been widely applied to a wide range of software engineering tasks. Many papers have reported their analysis on the potential advantages and limitations of ChatGPT for writing code, summarization, text generation, etc. However, the analysis of the current state of ChatGPT for log processing has received little attention. Logs generated by large-scale software systems are complex and hard to understand. Despite their complexity, they provide crucial information for subject matter experts to understand the system status and diagnose problems of the systems. In this paper, we investigate the current capabilities of ChatGPT to perform several interesting tasks on log data, while also trying to identify its main shortcomings. Our findings show that the performance of the current version of ChatGPT for log processing is limited, with a lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role of LLMs in the log processing discipline and possible next steps to improve the current capabilities of ChatGPT and the future LLMs in this area. We believe our work can contribute to future academic research to address the identified issues. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 04:09:27 GMT'}]",2023-09-18,"[['Mudgal', 'Priyanka', ''], ['Wouhaybi', 'Rita', '']]",1,1,2023-09-14,1,2,2,1,0,1,34f721457b92155a5f5ccaf5201c1a9f0f6f99be,261875672.0,https://www.semanticscholar.org/paper/34f721457b92155a5f5ccaf5201c1a9f0f6f99be,arXiv.org,2023.0,95.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2241205628', 'name': 'Priyanka Mudgal'}, {'authorId': '2241203982', 'name': 'Rita Wouhaybi'}]",['Intel'],['United States'],2023-09,['industrial']
2309.08172,Kaixin Ma,"Kaixin Ma, Hongming Zhang, Hongwei Wang, Xiaoman Pan, Dong Yu",LASER: LLM Agent with State-Space Exploration for Web Navigation,"6 pages, 4 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have been successfully adapted for interactive decision-making tasks like web navigation. While achieving decent performance, previous methods implicitly assume a forward-only execution mode for the model, where they only provide oracle trajectories as in-context examples to teach the model how to reason in the interactive environment. Consequently, the model could not handle more challenging scenarios not covered in the in-context examples, e.g., mistakes, leading to sub-optimal performance. To address this issue, we propose to model the interactive task as state space exploration, where the LLM agent transitions among a pre-defined set of states by performing actions to complete the task. This formulation enables flexible back-tracking, allowing the model to easily recover from errors. We evaluate our proposed LLM Agent with State-Space ExploRation (LASER) on the WebShop task. Experimental results show that our LASER agent significantly outperforms previous methods and closes the gap with human performance on the web navigation task. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 05:44:08 GMT'}]",2023-09-18,"[['Ma', 'Kaixin', ''], ['Zhang', 'Hongming', ''], ['Wang', 'Hongwei', ''], ['Pan', 'Xiaoman', ''], ['Yu', 'Dong', '']]",0,0,2023-09-15,1,5,1,0,0,0,c115984c2b28e0d17d722c55a132459a87224ccf,262012476.0,https://www.semanticscholar.org/paper/c115984c2b28e0d17d722c55a132459a87224ccf,arXiv.org,2023.0,22.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '22244290', 'name': 'Kaixin Ma'}, {'authorId': '49723569', 'name': 'Hongming Zhang'}, {'authorId': '49527724', 'name': 'Hongwei Wang'}, {'authorId': '2243367575', 'name': 'Xiaoman Pan'}, {'authorId': '144580027', 'name': 'Dong Yu'}]",['Tencent'],['United States'],2023-09,['industrial']
2309.08448,Chan-Jan Hsu,"Chan-Jan Hsu, Chang-Le Liu, Feng-Ting Liao, Po-Chun Hsu, Yi-Chang
  Chen, Da-shan Shiu",Advancing the Evaluation of Traditional Chinese Language Models: Towards a Comprehensive Benchmark Suite,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The evaluation of large language models is an essential task in the field of language understanding and generation. As language models continue to advance, the need for effective benchmarks to assess their performance has become imperative. In the context of Traditional Chinese, there is a scarcity of comprehensive and diverse benchmarks to evaluate the capabilities of language models, despite the existence of certain benchmarks such as DRCD, TTQA, CMDQA, and FGC dataset. To address this gap, we propose a novel set of benchmarks that leverage existing English datasets and are tailored to evaluate language models in Traditional Chinese. These benchmarks encompass a wide range of tasks, including contextual question-answering, summarization, classification, and table understanding. The proposed benchmarks offer a comprehensive evaluation framework, enabling the assessment of language models' capabilities across different tasks. In this paper, we evaluate the performance of GPT-3.5, Taiwan-LLaMa-v1.0, and Model 7-C, our proprietary model, on these benchmarks. The evaluation results highlight that our model, Model 7-C, achieves performance comparable to GPT-3.5 with respect to a part of the evaluated capabilities. In an effort to advance the evaluation of language models in Traditional Chinese and stimulate further research in this field, we have open-sourced our benchmark and opened the model for trial. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 14:52:23 GMT'}, {'version': 'v2', 'created': 'Mon, 2 Oct 2023 15:22:42 GMT'}]",2023-10-03,"[['Hsu', 'Chan-Jan', ''], ['Liu', 'Chang-Le', ''], ['Liao', 'Feng-Ting', ''], ['Hsu', 'Po-Chun', ''], ['Chen', 'Yi-Chang', ''], ['Shiu', 'Da-shan', '']]",0,1,2023-09-15,2,6,1,2,1,1,16c42a500bff0af731ee505aae23aa4d2937fc91,262013507.0,https://www.semanticscholar.org/paper/16c42a500bff0af731ee505aae23aa4d2937fc91,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2148295431', 'name': 'Chan-Jan Hsu'}, {'authorId': '2211001638', 'name': 'Chang-Le Liu'}, {'authorId': '2242711123', 'name': 'Feng-Ting Liao'}, {'authorId': '2242906301', 'name': 'Po-Chun Hsu'}, {'authorId': '2242778881', 'name': 'Yi-Chang Chen'}, {'authorId': '2027686', 'name': 'D. Shiu'}]",['MediaTek (China)'],['China'],2023-09,['industrial']
2309.08473,Massimo Bonavita,Massimo Bonavita,On the limitations of data-driven weather forecasting models,,,,,stat.ML cs.LG physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  As in many other areas of engineering and applied science, Machine Learning (ML) is having a profound impact in the domain of Weather and Climate Prediction. A very recent development in this area has been the emergence of fully data-driven ML prediction models which routinely claim superior performance to that of traditional physics-based models. In this work, we examine some aspects of the forecasts produced by an exemplar of the current generation of ML models, Pangu-Weather, with a focus on the fidelity and physical consistency of those forecasts and how these characteristics relate to perceived forecast performance. The main conclusion is that Pangu-Weather forecasts, and by extension those of similar ML models, do not have the fidelity and physical consistency of physics-based models and their advantage in accuracy on traditional deterministic metrics of forecast skill can be attributed, to a large extent, to these peculiarities. Similarly to other current post-processing technologies, ML models appear to be able to add value to standard NWP outputs for specific forecast applications and combined with their extremely low computational cost during deployment, will likely provide an additional, useful source of forecast information. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 15:21:57 GMT'}]",2023-09-18,"[['Bonavita', 'Massimo', '']]",0,0,2023-09-15,1,1,3,0,0,0,744673e2d8de075584cff1dedb78b3ac49bfb1ed,262013237.0,https://www.semanticscholar.org/paper/744673e2d8de075584cff1dedb78b3ac49bfb1ed,arXiv.org,2023.0,26.0,0.0,0.0,True,"['Computer Science', 'Mathematics', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","[{'authorId': '2242549528', 'name': 'Massimo Bonavita'}]",['European Centre for Medium-Range Weather Forecasts'],['United Kingdom'],2023-09,['industrial']
2309.08626,Juntae Kim,"Juntae Kim, Minkyu Lim, and Seokjin Hong","Improving Robustness of Neural Inverse Text Normalization via Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method",submitted to ICASSP 2024,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Inverse text normalization (ITN) is crucial for converting spoken-form into written-form, especially in the context of automatic speech recognition (ASR). While most downstream tasks of ASR rely on written-form, ASR systems often output spoken-form, highlighting the necessity for robust ITN in product-level ASR-based applications. Although neural ITN methods have shown promise, they still encounter performance challenges, particularly when dealing with ASR-generated spoken text. These challenges arise from the out-of-domain problem between training data and ASR-generated text. To address this, we propose a direct training approach that utilizes ASR-generated written or spoken text, with pairs augmented through ASR linguistic context emulation and a semi-supervised learning method enhanced by a large language model, respectively. Additionally, we introduce a post-aligning method to manage unpredictable errors, thereby enhancing the reliability of ITN. Our experiments show that our proposed methods remarkably improved ITN performance in various ASR scenarios. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 06:05:57 GMT'}]",2023-09-19,"[['Kim', 'Juntae', ''], ['Lim', 'Minkyu', ''], ['Hong', 'Seokjin', '']]",0,0,2023-09-12,1,3,1,0,0,0,b7a56d21ca23a2ba06fa54d43faec0cec075fdf2,262045639.0,https://www.semanticscholar.org/paper/b7a56d21ca23a2ba06fa54d43faec0cec075fdf2,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243365482', 'name': 'Juntae Kim'}, {'authorId': '40561499', 'name': 'Minkyu Lim'}, {'authorId': '2243371111', 'name': 'Seokjin Hong'}]","['SK Telecom, Seoul, Republic of Korea']",,2023-09,['industrial']
2309.08648,Yonchanok Khaokaew,"Yonchanok Khaokaew, Hao Xue, Flora D. Salim",MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Despite the rapid advancement of mobile applications, predicting app usage remains a formidable challenge due to intricate user behaviours and ever-evolving contexts. To address these issues, this paper introduces the Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model. This innovative approach utilizes Large Language Models (LLMs) to predict app usage accurately. Rigorous testing on two public datasets highlights MAPLE's capability to decipher intricate patterns and comprehend user contexts. These robust results confirm MAPLE's versatility and resilience across various scenarios. While its primary design caters to app prediction, the outcomes also emphasize the broader applicability of LLMs in different domains. Through this research, we emphasize the potential of LLMs in app usage prediction and suggest their transformative capacity in modelling human behaviours across diverse fields. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 13:15:54 GMT'}]",2023-09-19,"[['Khaokaew', 'Yonchanok', ''], ['Xue', 'Hao', ''], ['Salim', 'Flora D.', '']]",0,0,2023-09-15,1,3,2,0,0,0,59fc922aac0f177a517d5656868c9c4334d863ef,262044117.0,https://www.semanticscholar.org/paper/59fc922aac0f177a517d5656868c9c4334d863ef,arXiv.org,2023.0,37.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1900284', 'name': 'Yonchanok Khaokaew'}, {'authorId': '1560895396', 'name': 'Hao Xue'}, {'authorId': '144954586', 'name': 'Flora D. Salim'}]","['Flora D. Salim', 'UNSW Sydney']",['Australia'],2023-09,"['industrial', 'industrial']"
2309.08939,Xichen Ding,"Yuqi Gong, Xichen Ding, Yehui Su, Kaiming Shen, Zhongyi Liu, Guannan
  Zhang",An Unified Search and Recommendation Foundation Model for Cold-Start Scenario,"CIKM 2023,6 pages",,10.1145/3583780.3614657,,cs.IR cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In modern commercial search engines and recommendation systems, data from multiple domains is available to jointly train the multi-domain model. Traditional methods train multi-domain models in the multi-task setting, with shared parameters to learn the similarity of multiple tasks, and task-specific parameters to learn the divergence of features, labels, and sample distributions of individual tasks. With the development of large language models, LLM can extract global domain-invariant text features that serve both search and recommendation tasks. We propose a novel framework called S\&R Multi-Domain Foundation, which uses LLM to extract domain invariant features, and Aspect Gating Fusion to merge the ID feature, domain invariant text features and task-specific heterogeneous sparse features to obtain the representations of query and item. Additionally, samples from multiple search and recommendation scenarios are trained jointly with Domain Adaptive Multi-Task module to obtain the multi-domain foundation model. We apply the S\&R Multi-Domain foundation model to cold start scenarios in the pretrain-finetune manner, which achieves better performance than other SOTA transfer learning methods. The S\&R Multi-Domain Foundation model has been successfully deployed in Alipay Mobile Application's online services, such as content query recommendation and service card recommendation, etc. ","[{'version': 'v1', 'created': 'Sat, 16 Sep 2023 10:00:02 GMT'}]",2023-09-19,"[['Gong', 'Yuqi', ''], ['Ding', 'Xichen', ''], ['Su', 'Yehui', ''], ['Shen', 'Kaiming', ''], ['Liu', 'Zhongyi', ''], ['Zhang', 'Guannan', '']]",0,0,2023-09-16,1,6,2,0,0,0,e54c34d1d4b108a85c11bc68251cf2f215d953e7,262045057.0,https://www.semanticscholar.org/paper/e54c34d1d4b108a85c11bc68251cf2f215d953e7,International Conference on Information and Knowledge Management,2023.0,27.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243273769', 'name': 'Yuqi Gong'}, {'authorId': '2243923570', 'name': 'Xichen Ding'}, {'authorId': '2243315594', 'name': 'Yehui Su'}, {'authorId': '2242792959', 'name': 'Kaiming Shen'}, {'authorId': '2243372613', 'name': 'Zhongyi Liu'}, {'authorId': '119557985', 'name': 'Guannan Zhang'}]",['Alibaba'],['China'],2023-09,['industrial']
2309.09338,Gerd Kortemeyer,Gerd Kortemeyer,Performance of the Pre-Trained Large Language Model GPT-4 on Automated Short Answer Grading,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Automated Short Answer Grading (ASAG) has been an active area of machine-learning research for over a decade. It promises to let educators grade and give feedback on free-form responses in large-enrollment courses in spite of limited availability of human graders. Over the years, carefully trained models have achieved increasingly higher levels of performance. More recently, pre-trained Large Language Models (LLMs) emerged as a commodity, and an intriguing question is how a general-purpose tool without additional training compares to specialized models. We studied the performance of GPT-4 on the standard benchmark 2-way and 3-way datasets SciEntsBank and Beetle, where in addition to the standard task of grading the alignment of the student answer with a reference answer, we also investigated withholding the reference answer. We found that overall, the performance of the pre-trained general-purpose GPT-4 LLM is comparable to hand-engineered models, but worse than pre-trained LLMs that had specialized training. ","[{'version': 'v1', 'created': 'Sun, 17 Sep 2023 18:04:34 GMT'}]",2023-09-19,"[['Kortemeyer', 'Gerd', '']]",0,1,2023-09-17,1,1,1,1,0,1,6c16ffcdd208f0dbbbb30bfb518d9214befe6804,262045158.0,https://www.semanticscholar.org/paper/6c16ffcdd208f0dbbbb30bfb518d9214befe6804,arXiv.org,2023.0,19.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243196001', 'name': 'Gerd Kortemeyer'}]",['ETH Zurich'],['Switzerland'],2023-09,['industrial']
2309.09495,Mohit Jain,"Pradyumna YM, Vinod Ganesan, Dinesh Kumar Arumugam, Meghna Gupta,
  Nischith Shadagopan, Tanay Dixit, Sameer Segal, Pratyush Kumar, Mohit Jain,
  Sriram Rajamani",PwR: Exploring the Role of Representations in Conversational Programming,"23 pages, 3 figures, 2 tables, under submission for ACM CHI 2024",,,,cs.HC cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have revolutionized programming and software engineering. AI programming assistants such as GitHub Copilot X enable conversational programming, narrowing the gap between human intent and code generation. However, prior literature has identified a key challenge--there is a gap between user's mental model of the system's understanding after a sequence of natural language utterances, and the AI system's actual understanding. To address this, we introduce Programming with Representations (PwR), an approach that uses representations to convey the system's understanding back to the user in natural language. We conducted an in-lab task-centered study with 14 users of varying programming proficiency and found that representations significantly improve understandability, and instilled a sense of agency among our participants. Expert programmers use them for verification, while intermediate programmers benefit from confirmation. Natural language-based development with LLMs, coupled with representations, promises to transform software development, making it more accessible and efficient. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 05:38:23 GMT'}]",2023-09-19,"[['YM', 'Pradyumna', ''], ['Ganesan', 'Vinod', ''], ['Arumugam', 'Dinesh Kumar', ''], ['Gupta', 'Meghna', ''], ['Shadagopan', 'Nischith', ''], ['Dixit', 'Tanay', ''], ['Segal', 'Sameer', ''], ['Kumar', 'Pratyush', ''], ['Jain', 'Mohit', ''], ['Rajamani', 'Sriram', '']]",0,0,2023-09-18,1,10,2,0,0,0,05c6d102b7e37f1f03c938729ceffd43f9fc1725,262045156.0,https://www.semanticscholar.org/paper/05c6d102b7e37f1f03c938729ceffd43f9fc1725,arXiv.org,2023.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2160630928', 'name': 'YM Pradyumna'}, {'authorId': '145743088', 'name': 'Vinod Ganesan'}, {'authorId': '2137866430', 'name': 'D. Arumugam'}, {'authorId': '2242822458', 'name': 'Meghna Gupta'}, {'authorId': '2206705630', 'name': 'Nischith Shadagopan'}, {'authorId': '2126503480', 'name': 'Tanay Dixit'}, {'authorId': '2242814985', 'name': 'Sameer Segal'}, {'authorId': '38724234', 'name': 'Pratyush Kumar'}, {'authorId': '2243125175', 'name': 'Mohit Jain'}, {'authorId': '1685546', 'name': 'S. Rajamani'}]",['Microsoft'],['India'],2023-09,['industrial']
2309.09552,Yuang Li,"Yuang Li, Yinglu Li, Min Zhang, Chang Su, Mengyao Piao, Xiaosong Qiao,
  Jiawei Yu, Miaomiao Ma, Yanqing Zhao, Hao Yang",CB-Whisper: Contextual Biasing Whisper using TTS-based Keyword Spotting,"10 pages, 4 figures",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  End-to-end automatic speech recognition (ASR) systems often struggle to recognize rare name entities, such as personal names, organizations, or technical terms that are not frequently encountered in the training data. This paper presents Contextual Biasing Whisper (CB-Whisper), a novel ASR system based on OpenAI's Whisper model that performs keyword-spotting (KWS) before the decoder. The KWS module leverages text-to-speech (TTS) techniques and a convolutional neural network (CNN) classifier to match the features between the entities and the utterances. Experiments demonstrate that by incorporating predicted entities into a carefully designed spoken form prompt, the mixed-error-rate (MER) and entity recall of the Whisper model is significantly improved on three internal datasets and two open-sourced datasets that cover English-only, Chinese-only, and code-switching scenarios. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 08:03:54 GMT'}]",2023-09-19,"[['Li', 'Yuang', ''], ['Li', 'Yinglu', ''], ['Zhang', 'Min', ''], ['Su', 'Chang', ''], ['Piao', 'Mengyao', ''], ['Qiao', 'Xiaosong', ''], ['Yu', 'Jiawei', ''], ['Ma', 'Miaomiao', ''], ['Zhao', 'Yanqing', ''], ['Yang', 'Hao', '']]",0,0,2023-09-18,1,10,2,0,0,0,7d7b9e31298cbe20c7dac20db690d04f826314e5,262045119.0,https://www.semanticscholar.org/paper/7d7b9e31298cbe20c7dac20db690d04f826314e5,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243955116', 'name': 'Yuang Li'}, {'authorId': '2194427215', 'name': 'Yinglu Li'}, {'authorId': '40093418', 'name': 'Min Zhang'}, {'authorId': '2152082190', 'name': 'Chang Su'}, {'authorId': '2242967066', 'name': 'Mengyao Piao'}, {'authorId': '2165227179', 'name': 'Xiaosong Qiao'}, {'authorId': '2242886635', 'name': 'Jiawei Yu'}, {'authorId': '2178632208', 'name': 'Miaomiao Ma'}, {'authorId': '2132737', 'name': 'Yanqing Zhao'}, {'authorId': '2257352836', 'name': 'Hao Yang'}]",['Huawei Technologies (China)'],['China'],2023-09,['industrial']
2309.09971,Ran Gong,"Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke
  Noda, Zilong Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, Jianfeng
  Gao",MindAgent: Emergent Gaming Interaction,The first three authors contributed equally. 28 pages,,,,cs.AI cs.HC cs.MA,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have the capacity of performing complex scheduling in a multi-agent system and can coordinate these agents into completing sophisticated tasks that require extensive collaboration. However, despite the introduction of numerous gaming frameworks, the community has insufficient benchmarks towards building general multi-agents collaboration infrastructure that encompass both LLM and human-NPCs collaborations. In this work, we propose a novel infrastructure - MindAgent - to evaluate planning and coordination emergent capabilities for gaming interaction. In particular, our infrastructure leverages existing gaming framework, to i) require understanding of the coordinator for a multi-agent system, ii) collaborate with human players via un-finetuned proper instructions, and iii) establish an in-context learning on few-shot prompt with feedback. Furthermore, we introduce CUISINEWORLD, a new gaming scenario and related benchmark that dispatch a multi-agent collaboration efficiency and supervise multiple agents playing the game simultaneously. We conduct comprehensive evaluations with new auto-metric CoS for calculating the collaboration efficiency. Finally, our infrastructure can be deployed into real-world gaming scenarios in a customized VR version of CUISINEWORLD and adapted in existing broader Minecraft gaming domain. We hope our findings on LLMs and the new infrastructure for general-purpose scheduling and coordination can help shed light on how such skills can be obtained by learning from large language corpora. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 17:52:22 GMT'}, {'version': 'v2', 'created': 'Tue, 19 Sep 2023 14:36:53 GMT'}]",2023-09-20,"[['Gong', 'Ran', ''], ['Huang', 'Qiuyuan', ''], ['Ma', 'Xiaojian', ''], ['Vo', 'Hoi', ''], ['Durante', 'Zane', ''], ['Noda', 'Yusuke', ''], ['Zheng', 'Zilong', ''], ['Zhu', 'Song-Chun', ''], ['Terzopoulos', 'Demetri', ''], ['Fei-Fei', 'Li', ''], ['Gao', 'Jianfeng', '']]",0,0,2023-09-18,2,11,3,0,0,0,9c01786f8195d53ad3902fc8d0872784b059adf3,261898118.0,https://www.semanticscholar.org/paper/9c01786f8195d53ad3902fc8d0872784b059adf3,arXiv.org,2023.0,45.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48096046', 'name': 'Ran Gong'}, {'authorId': '2242393161', 'name': 'Qiuyuan Huang'}, {'authorId': '2242178224', 'name': 'Xiaojian Ma'}, {'authorId': '2241542412', 'name': 'Hoi Vo'}, {'authorId': '80726083', 'name': 'Zane Durante'}, {'authorId': '2241619720', 'name': 'Yusuke Noda'}, {'authorId': '49774254', 'name': 'Zilong Zheng'}, {'authorId': '145380991', 'name': 'Song-Chun Zhu'}, {'authorId': '1750924', 'name': 'Demetri Terzopoulos'}, {'authorId': '2241788459', 'name': 'Fei-Fei Li'}, {'authorId': '2242125740', 'name': 'Jianfeng Gao'}]",['Microsoft'],['United States'],2023-09,['industrial']
2309.10202,Baolin Peng,"Baolin Peng and Linfeng Song and Ye Tian and Lifeng Jin and Haitao Mi
  and Dong Yu",Stabilizing RLHF through Advantage Model and Selective Rehearsal,"9 pages, working in progress",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have revolutionized natural language processing, yet aligning these models with human values and preferences using RLHF remains a significant challenge. This challenge is characterized by various instabilities, such as reward hacking and catastrophic forgetting. In this technical report, we propose two innovations to stabilize RLHF training: 1) Advantage Model, which directly models advantage score i.e., extra reward compared to the expected rewards and regulates score distributions across tasks to prevent reward hacking. 2) Selective Rehearsal, which mitigates catastrophic forgetting by strategically selecting data for PPO training and knowledge rehearsing. Our experimental analysis on public and proprietary datasets reveals that the proposed methods not only increase stability in RLHF training but also achieve higher reward scores and win rates. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 23:06:32 GMT'}]",2023-09-20,"[['Peng', 'Baolin', ''], ['Song', 'Linfeng', ''], ['Tian', 'Ye', ''], ['Jin', 'Lifeng', ''], ['Mi', 'Haitao', ''], ['Yu', 'Dong', '']]",0,0,2023-09-18,1,6,2,0,0,0,0fb61be60088e80e565b84f44e49ba30630b6126,262054217.0,https://www.semanticscholar.org/paper/0fb61be60088e80e565b84f44e49ba30630b6126,arXiv.org,2023.0,35.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1780690', 'name': 'Baolin Peng'}, {'authorId': '1748796', 'name': 'Linfeng Song'}, {'authorId': '2243391254', 'name': 'Ye Tian'}, {'authorId': '2936180', 'name': 'Lifeng Jin'}, {'authorId': '2013337', 'name': 'Haitao Mi'}, {'authorId': '2239076081', 'name': 'Dong Yu'}]",['Tencent'],['China'],2023-09,['industrial']
2309.10305,Bingning Wang Dr.,"Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin,
  Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng
  Liu, Guangwei Ai, Guosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda
  Zhang, Hui Liu, Jiaming Ji, Jian Xie, JunTao Dai, Kun Fang, Lei Su, Liang
  Song, Lifeng Liu, Liyun Ru, Luyao Ma, Mang Wang, Mickel Liu, MingAn Lin,
  Nuolan Nie, Peidong Guo, Ruiyang Sun, Tao Zhang, Tianpeng Li, Tianyu Li, Wei
  Cheng, Weipeng Chen, Xiangrong Zeng, Xiaochuan Wang, Xiaoxi Chen, Xin Men,
  Xin Yu, Xuehai Pan, Yanjun Shen, Yiding Wang, Yiyu Li, Youxin Jiang, Yuchen
  Gao, Yupeng Zhang, Zenan Zhou, Zhiying Wu",Baichuan 2: Open Large-scale Language Models,"Baichuan 2 technical report. Github:
  https://github.com/baichuan-inc/Baichuan2",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering. However, most powerful LLMs are closed-source or limited in their capability for languages other than English. In this technical report, we present Baichuan 2, a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens. Baichuan 2 matches or outperforms other open-source models of similar size on public benchmarks like MMLU, CMMLU, GSM8K, and HumanEval. Furthermore, Baichuan 2 excels in vertical domains such as medicine and law. We will release all pre-training model checkpoints to benefit the research community in better understanding the training dynamics of Baichuan 2. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 04:13:22 GMT'}, {'version': 'v2', 'created': 'Wed, 20 Sep 2023 04:06:06 GMT'}]",2023-09-21,"[['Yang', 'Aiyuan', ''], ['Xiao', 'Bin', ''], ['Wang', 'Bingning', ''], ['Zhang', 'Borong', ''], ['Bian', 'Ce', ''], ['Yin', 'Chao', ''], ['Lv', 'Chenxu', ''], ['Pan', 'Da', ''], ['Wang', 'Dian', ''], ['Yan', 'Dong', ''], ['Yang', 'Fan', ''], ['Deng', 'Fei', ''], ['Wang', 'Feng', ''], ['Liu', 'Feng', ''], ['Ai', 'Guangwei', ''], ['Dong', 'Guosheng', ''], ['Zhao', 'Haizhou', ''], ['Xu', 'Hang', ''], ['Sun', 'Haoze', ''], ['Zhang', 'Hongda', ''], ['Liu', 'Hui', ''], ['Ji', 'Jiaming', ''], ['Xie', 'Jian', ''], ['Dai', 'JunTao', ''], ['Fang', 'Kun', ''], ['Su', 'Lei', ''], ['Song', 'Liang', ''], ['Liu', 'Lifeng', ''], ['Ru', 'Liyun', ''], ['Ma', 'Luyao', ''], ['Wang', 'Mang', ''], ['Liu', 'Mickel', ''], ['Lin', 'MingAn', ''], ['Nie', 'Nuolan', ''], ['Guo', 'Peidong', ''], ['Sun', 'Ruiyang', ''], ['Zhang', 'Tao', ''], ['Li', 'Tianpeng', ''], ['Li', 'Tianyu', ''], ['Cheng', 'Wei', ''], ['Chen', 'Weipeng', ''], ['Zeng', 'Xiangrong', ''], ['Wang', 'Xiaochuan', ''], ['Chen', 'Xiaoxi', ''], ['Men', 'Xin', ''], ['Yu', 'Xin', ''], ['Pan', 'Xuehai', ''], ['Shen', 'Yanjun', ''], ['Wang', 'Yiding', ''], ['Li', 'Yiyu', ''], ['Jiang', 'Youxin', ''], ['Gao', 'Yuchen', ''], ['Zhang', 'Yupeng', ''], ['Zhou', 'Zenan', ''], ['Wu', 'Zhiying', '']]",0,0,2023-09-19,2,55,1,0,0,0,c96297261467b5daa2d01227496a70d444602434,261951743.0,https://www.semanticscholar.org/paper/c96297261467b5daa2d01227496a70d444602434,arXiv.org,2023.0,81.0,37.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2208290330', 'name': 'Ai Ming Yang'}, {'authorId': '2264098855', 'name': 'Bin Xiao'}, {'authorId': '2242351985', 'name': 'Bingning Wang'}, {'authorId': '152705071', 'name': 'Borong Zhang'}, {'authorId': '2221566410', 'name': 'Ce Bian'}, {'authorId': '2242126323', 'name': 'Chao Yin'}, {'authorId': '2242124793', 'name': 'Chenxu Lv'}, {'authorId': '2242124866', 'name': 'Da Pan'}, {'authorId': '2243393517', 'name': 'Dian Wang'}, {'authorId': '2242126799', 'name': 'Dong Yan'}, {'authorId': '47829900', 'name': 'Fan Yang'}, {'authorId': '2242124540', 'name': 'Fei Deng'}, {'authorId': '2242730297', 'name': 'Feng Wang'}, {'authorId': '2242207666', 'name': 'Feng Liu'}, {'authorId': '2242123567', 'name': 'Guangwei Ai'}, {'authorId': '2242124536', 'name': 'Guosheng Dong'}, {'authorId': '47941144', 'name': 'Hai Zhao'}, {'authorId': '2116309368', 'name': 'Hang Xu'}, {'authorId': '2118181226', 'name': 'Hao-Lun Sun'}, {'authorId': '2242180178', 'name': 'Hongda Zhang'}, {'authorId': '2242276762', 'name': 'Hui Liu'}, {'authorId': '2154630502', 'name': 'Jiaming Ji'}, {'authorId': '2242192116', 'name': 'Jian Xie'}, {'authorId': '14548852', 'name': 'Juntao Dai'}, {'authorId': '144669461', 'name': 'Kuncheng Fang'}, {'authorId': '2242130652', 'name': 'Lei Su'}, {'authorId': '2238154661', 'name': 'Liang Song'}, {'authorId': '2242309097', 'name': 'Lifeng Liu'}, {'authorId': '2242124220', 'name': 'Liyun Ru'}, {'authorId': '2242280004', 'name': 'Luyao Ma'}, {'authorId': '2242171637', 'name': 'Mang Wang'}, {'authorId': '2210950163', 'name': 'Mickel Liu'}, {'authorId': '2244046109', 'name': 'MingAn Lin'}, {'authorId': '2242123471', 'name': 'Nuolan Nie'}, {'authorId': '2197287293', 'name': 'Pei Guo'}, {'authorId': '2217316509', 'name': 'Ruiyang Sun'}, {'authorId': '1689115', 'name': 'Zhang Tao'}, {'authorId': '2242788322', 'name': 'Tianpeng Li'}, {'authorId': None, 'name': 'Tianyu Li'}, {'authorId': '145859270', 'name': 'Wei Cheng'}, {'authorId': '2144305331', 'name': 'Weipeng Chen'}, {'authorId': '2441459', 'name': 'Xiangrong Zeng'}, {'authorId': '2242180212', 'name': 'Xiaochuan Wang'}, {'authorId': '2242278442', 'name': 'Xiaoxi Chen'}, {'authorId': '2242124145', 'name': 'Xin Men'}, {'authorId': '2242135086', 'name': 'Xin Yu'}, {'authorId': '2190800297', 'name': 'Xuehai Pan'}, {'authorId': '2178403464', 'name': 'Yan-Bin Shen'}, {'authorId': '2242155514', 'name': 'Yiding Wang'}, {'authorId': '2242175361', 'name': 'Yiyu Li'}, {'authorId': '2242171277', 'name': 'Youxin Jiang'}, {'authorId': '2244143098', 'name': 'Yuchen Gao'}, {'authorId': '2242155612', 'name': 'Yupeng Zhang'}, {'authorId': '2183768304', 'name': 'Zenan Zhou'}, {'authorId': '2242279152', 'name': 'Zhiying Wu'}]",['Baichuan Inc.'],,2023-09,['industrial']
2309.10371,Benjamin Goertzel,Ben Goertzel,Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs,,,,,cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A moderately detailed consideration of interactive LLMs as cognitive systems is given, focusing on LLMs circa mid-2023 such as ChatGPT, GPT-4, Bard, Llama, etc.. Cognitive strengths of these systems are reviewed, and then careful attention is paid to the substantial differences between the sort of cognitive system these LLMs are, and the sort of cognitive systems human beings are. It is found that many of the practical weaknesses of these AI systems can be tied specifically to lacks in the basic cognitive architectures according to which these systems are built. It is argued that incremental improvement of such LLMs is not a viable approach to working toward human-level AGI, in practical terms given realizable amounts of compute resources. This does not imply there is nothing to learn about human-level AGI from studying and experimenting with LLMs, nor that LLMs cannot form significant parts of human-level AGI architectures that also incorporate other ideas. Social and ethical matters regarding LLMs are very briefly touched from this perspective, which implies that while care should be taken regarding misinformation and other issues, and economic upheavals will need their own social remedies based on their unpredictable course as with any powerfully impactful technology, overall the sort of policy needed as regards modern LLMs is quite different than would be the case if a more credible approximation to human-level AGI were at hand. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 07:12:55 GMT'}]",2023-09-20,"[['Goertzel', 'Ben', '']]",1,1,2023-09-19,1,1,1,3,1,2,d79e6b919f0cdc89c933883d9847c5ded38e994e,262054850.0,https://www.semanticscholar.org/paper/d79e6b919f0cdc89c933883d9847c5ded38e994e,arXiv.org,2023.0,102.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2243240346', 'name': 'Ben Goertzel'}]","['SingularityNET, TrueAGI, OpenCog']",,2023-09,['industrial']
2309.10563,Nishchal Prasad,"Nishchal Prasad, Mohand Boughanem, Taoufik Dkaki",A Hierarchical Neural Framework for Classification and its Explanation in Large Unstructured Legal Documents,,,,,cs.IR cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Automatic legal judgment prediction and its explanation suffer from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents and extracting their explanation becomes a challenging task, more so on documents with no structural annotation. We define this problem as ""scarce annotated legal documents"" and explore their lack of structural information and their long lengths with a deep-learning-based classification framework which we call MESc; ""Multi-stage Encoder-based Supervised with-clustering""; for judgment prediction. We explore the adaptability of LLMs with multi-billion parameters (GPT-Neo, and GPT-J) to legal texts and their intra-domain(legal) transfer learning capacity. Alongside this, we compare their performance and adaptability with MESc and the impact of combining embeddings from their last layers. For such hierarchical models, we also propose an explanation extraction algorithm named ORSE; Occlusion sensitivity-based Relevant Sentence Extractor; based on the input-occlusion sensitivity of the model, to explain the predictions with the most relevant sentences from the document. We explore these methods and test their effectiveness with extensive experiments and ablation studies on legal documents from India, the European Union, and the United States with the ILDC dataset and a subset of the LexGLUE dataset. MESc achieves a minimum total performance gain of approximately 2 points over previous state-of-the-art proposed methods, while ORSE applied on MESc achieves a total average gain of 50% over the baseline explainability scores. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 12:18:28 GMT'}, {'version': 'v2', 'created': 'Mon, 25 Sep 2023 15:10:37 GMT'}]",2023-09-26,"[['Prasad', 'Nishchal', ''], ['Boughanem', 'Mohand', ''], ['Dkaki', 'Taoufik', '']]",0,1,2023-09-19,2,3,2,0,0,0,ba5afd33db5d86bec96cd0ea4555a2dd09a9b08d,262054187.0,https://www.semanticscholar.org/paper/ba5afd33db5d86bec96cd0ea4555a2dd09a9b08d,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2128323637', 'name': 'Nishchal Prasad'}, {'authorId': '47506168', 'name': 'M. Boughanem'}, {'authorId': '2243238642', 'name': 'Taoufik Dkaki'}]",['Toulouse Institute of Computer Science Research'],['France'],2023-09,['industrial']
2309.10621,Bhaskar Mitra,"Paul Thomas, Seth Spielman, Nick Craswell and Bhaskar Mitra",Large language models can accurately predict searcher preferences,,,,,cs.IR cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems. The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels. Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs. To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring. This paper introduces an alternate approach for improving label quality. It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that can be derived, and develops an large language model prompt that agrees with that data.   We present ideas and observations from deploying language models for large-scale relevance labelling at Bing, and illustrate with data from TREC. We have found large language models can be effective, with accuracy as good as human labellers and similar capability to pick the hardest queries, best runs, and best groups. Systematic changes to the prompts make a difference in accuracy, but so too do simple paraphrases. To measure agreement with real searchers needs high-quality ``gold'' labels, but with these we find that models produce better labels than third-party workers, for a fraction of the cost, and these labels let us train notably better rankers. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 13:55:39 GMT'}]",2023-09-20,"[['Thomas', 'Paul', ''], ['Spielman', 'Seth', ''], ['Craswell', 'Nick', ''], ['Mitra', 'Bhaskar', '']]",0,0,2023-09-19,1,4,4,0,0,0,68838aba1cc6e20028f9703b96e3517b01972277,262054847.0,https://www.semanticscholar.org/paper/68838aba1cc6e20028f9703b96e3517b01972277,arXiv.org,2023.0,53.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '41202995', 'name': 'Paul Thomas'}, {'authorId': '2227547996', 'name': 'S. Spielman'}, {'authorId': '1703980', 'name': 'Nick Craswell'}, {'authorId': '116506812', 'name': 'Bhaskar Mitra'}]",['Microsoft'],['Canada'],2023-09,['industrial']
2309.10929,Ruiqi Xu,"Ruiqi Xu, Yongfeng Huang, Xin Chen, Lin Zhang",Specializing Small Language Models towards Complex Style Transfer via Latent Attribute Pre-Training,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this work, we introduce the concept of complex text style transfer tasks, and constructed complex text datasets based on two widely applicable scenarios. Our dataset is the first large-scale data set of its kind, with 700 rephrased sentences and 1,000 sentences from the game Genshin Impact. While large language models (LLM) have shown promise in complex text style transfer, they have drawbacks such as data privacy concerns, network instability, and high deployment costs. To address these issues, we explore the effectiveness of small models (less than T5-3B) with implicit style pre-training through contrastive learning. We also propose a method for automated evaluation of text generation quality based on alignment with human evaluations using ChatGPT. Finally, we compare our approach with existing methods and show that our model achieves state-of-art performances of few-shot text style transfer models. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 21:01:40 GMT'}]",2023-09-21,"[['Xu', 'Ruiqi', ''], ['Huang', 'Yongfeng', ''], ['Chen', 'Xin', ''], ['Zhang', 'Lin', '']]",1,1,2023-09-19,1,4,1,2,1,1,02f17e5918e4a803f81410901c1375fc323eccd2,262064711.0,https://www.semanticscholar.org/paper/02f17e5918e4a803f81410901c1375fc323eccd2,European Conference on Artificial Intelligence,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243405915', 'name': 'Ruiqi Xu'}, {'authorId': '2192183418', 'name': 'Y. Huang'}, {'authorId': '48283677', 'name': 'Xin Chen'}, {'authorId': '2243033035', 'name': 'Lin Zhang'}]","['Symbiotic Matrix', 'ORCID', 'Platinum AI Inc., China']","['China', 'United States']",2023-09,"['industrial', 'industrial', 'industrial']"
2309.11285,Areg Mikael Sarvazyan,"Areg Mikael Sarvazyan, Jos\'e \'Angel Gonz\'alez, Marc
  Franco-Salvador, Francisco Rangel, Berta Chulvi, Paolo Rosso",Overview of AuTexTification at IberLEF 2023: Detection and Attribution of Machine-Generated Text in Multiple Domains,Accepted at SEPLN 2023,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper presents the overview of the AuTexTification shared task as part of the IberLEF 2023 Workshop in Iberian Languages Evaluation Forum, within the framework of the SEPLN 2023 conference. AuTexTification consists of two subtasks: for Subtask 1, participants had to determine whether a text is human-authored or has been generated by a large language model. For Subtask 2, participants had to attribute a machine-generated text to one of six different text generation models. Our AuTexTification 2023 dataset contains more than 160.000 texts across two languages (English and Spanish) and five domains (tweets, reviews, news, legal, and how-to articles). A total of 114 teams signed up to participate, of which 36 sent 175 runs, and 20 of them sent their working notes. In this overview, we present the AuTexTification dataset and task, the submitted participating systems, and the results. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 13:10:06 GMT'}]",2023-09-21,"[['Sarvazyan', 'Areg Mikael', ''], ['González', 'José Ángel', ''], ['Franco-Salvador', 'Marc', ''], ['Rangel', 'Francisco', ''], ['Chulvi', 'Berta', ''], ['Rosso', 'Paolo', '']]",0,0,2023-09-20,1,6,3,0,0,0,c3b09dde03c65f53e046f8cce5201de6a6f17dbe,262055483.0,https://www.semanticscholar.org/paper/c3b09dde03c65f53e046f8cce5201de6a6f17dbe,Proces. del Leng. Natural,2023.0,66.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2241540449', 'name': 'A. Sarvazyan'}, {'authorId': '2242065237', 'name': 'José Ángel González'}, {'authorId': '1403862010', 'name': 'Marc Franco-Salvador'}, {'authorId': '133975199', 'name': 'Francisco Rangel'}, {'authorId': '4696191', 'name': 'Berta Chulvi'}, {'authorId': '143752702', 'name': 'Paolo Rosso'}]","['Symanto Research, Valencia, Spain', 'Universitat Politècnica de València']",['Spain'],2023-09,"['industrial', 'industrial']"
2309.11427,Sewoong Lee,"Sewoong Lee, JinKyou Choi and Min Su Kim",Generative Pre-Training of Time-Series Data for Unsupervised Fault Detection in Semiconductor Manufacturing,,,,,cs.LG cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper introduces TRACE-GPT, which stands for Time-seRies Anomaly-detection with Convolutional Embedding and Generative Pre-trained Transformers. TRACE-GPT is designed to pre-train univariate time-series sensor data and detect faults on unlabeled datasets in semiconductor manufacturing. In semiconductor industry, classifying abnormal time-series sensor data from normal data is important because it is directly related to wafer defect. However, small, unlabeled, and even mixed training data without enough anomalies make classification tasks difficult. In this research, we capture features of time-series data with temporal convolutional embedding and Generative Pre-trained Transformer (GPT) to classify abnormal sequences from normal sequences using cross entropy loss. We prove that our model shows better performance than previous unsupervised models with both an open dataset, the University of California Riverside (UCR) time-series classification archive, and the process log of our Chemical Vapor Deposition (CVD) equipment. Our model has the highest F1 score at Equal Error Rate (EER) across all datasets and is only 0.026 below the supervised state-of-the-art baseline on the open dataset. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 16:01:45 GMT'}]",2023-09-21,"[['Lee', 'Sewoong', ''], ['Choi', 'JinKyou', ''], ['Kim', 'Min Su', '']]",0,1,2023-09-20,1,3,2,0,0,0,2e3d41b82671e4aefe0e30b8f97cea0fc2de0415,262063918.0,https://www.semanticscholar.org/paper/2e3d41b82671e4aefe0e30b8f97cea0fc2de0415,arXiv.org,2023.0,65.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243280279', 'name': 'Sewoong Lee'}, {'authorId': '2243944402', 'name': 'JinKyou Choi'}, {'authorId': '2242863673', 'name': 'Min Su Kim'}]",['Samsung'],['South Korea'],2023-09,['industrial']
2309.11456,Navid Ghaffarzadegan,"Navid Ghaffarzadegan, Aritra Majumdar, Ross Williams, Niyousha
  Hosseinichimeh",Generative Agent-Based Modeling: Unveiling Social System Dynamics through Coupling Mechanistic Models with Generative Artificial Intelligence,,,,,cs.AI cs.LG cs.MA nlin.AO physics.soc-ph,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  We discuss the emerging new opportunity for building feedback-rich computational models of social systems using generative artificial intelligence. Referred to as Generative Agent-Based Models (GABMs), such individual-level models utilize large language models such as ChatGPT to represent human decision-making in social settings. We provide a GABM case in which human behavior can be incorporated in simulation models by coupling a mechanistic model of human interactions with a pre-trained large language model. This is achieved by introducing a simple GABM of social norm diffusion in an organization. For educational purposes, the model is intentionally kept simple. We examine a wide range of scenarios and the sensitivity of the results to several changes in the prompt. We hope the article and the model serve as a guide for building useful diffusion models that include realistic human reasoning and decision-making. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 16:43:05 GMT'}]",2023-09-21,"[['Ghaffarzadegan', 'Navid', ''], ['Majumdar', 'Aritra', ''], ['Williams', 'Ross', ''], ['Hosseinichimeh', 'Niyousha', '']]",1,1,2023-09-20,1,4,5,1,0,1,3325706ab41ee91958f5c2e0a28994e5eb094cb6,262063524.0,https://www.semanticscholar.org/paper/3325706ab41ee91958f5c2e0a28994e5eb094cb6,arXiv.org,2023.0,51.0,2.0,0.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '3225275', 'name': 'Navid Ghaffarzadegan'}, {'authorId': '116905981', 'name': 'A. Majumdar'}, {'authorId': '2157888330', 'name': 'Ross Williams'}, {'authorId': '3565384', 'name': 'Niyousha Hosseinichimeh'}]","['Department of Industrial and Systems Engineering, Virginia Tech, Falls Church, VA']",,2023-09,['industrial']
2309.11495,Jason  Weston,"Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian
  Li, Asli Celikyilmaz, Jason Weston",Chain-of-Verification Reduces Hallucination in Large Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 17:50:55 GMT'}, {'version': 'v2', 'created': 'Mon, 25 Sep 2023 15:25:49 GMT'}]",2023-09-26,"[['Dhuliawala', 'Shehzaad', ''], ['Komeili', 'Mojtaba', ''], ['Xu', 'Jing', ''], ['Raileanu', 'Roberta', ''], ['Li', 'Xian', ''], ['Celikyilmaz', 'Asli', ''], ['Weston', 'Jason', '']]",0,0,2023-09-20,2,7,2,0,0,0,4b0b56be0ae9479d2bd5c2f0943db1906343c10f,262062565.0,https://www.semanticscholar.org/paper/4b0b56be0ae9479d2bd5c2f0943db1906343c10f,arXiv.org,2023.0,47.0,16.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3448411', 'name': 'S. Dhuliawala'}, {'authorId': '100653935', 'name': 'M. Komeili'}, {'authorId': '2243898547', 'name': 'Jing Xu'}, {'authorId': '48647153', 'name': 'Roberta Raileanu'}, {'authorId': '2243015223', 'name': 'Xian Li'}, {'authorId': '1709797', 'name': 'Asli Celikyilmaz'}, {'authorId': '2243265350', 'name': 'Jason Weston'}]","['ETH Zurich', 'Meta']","['United States', 'Switzerland']",2023-09,"['industrial', 'industrial']"
2309.11838,Norbert Braunschweiler,"Norbert Braunschweiler and Rama Doddipatla and Simon Keizer and
  Svetlana Stoyanchev",Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues,10 pages,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this paper, we investigate the use of large language models (LLMs) like ChatGPT for document-grounded response generation in the context of information-seeking dialogues. For evaluation, we use the MultiDoc2Dial corpus of task-oriented dialogues in four social service domains previously used in the DialDoc 2022 Shared Task. Information-seeking dialogue turns are grounded in multiple documents providing relevant information. We generate dialogue completion responses by prompting a ChatGPT model, using two methods: Chat-Completion and LlamaIndex. ChatCompletion uses knowledge from ChatGPT model pretraining while LlamaIndex also extracts relevant information from documents. Observing that document-grounded response generation via LLMs cannot be adequately assessed by automatic evaluation metrics as they are significantly more verbose, we perform a human evaluation where annotators rate the output of the shared task winning system, the two Chat-GPT variants outputs, and human responses. While both ChatGPT variants are more likely to include information not present in the relevant segments, possibly including a presence of hallucinations, they are rated higher than both the shared task winning system and human responses. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 07:28:03 GMT'}]",2023-09-22,"[['Braunschweiler', 'Norbert', ''], ['Doddipatla', 'Rama', ''], ['Keizer', 'Simon', ''], ['Stoyanchev', 'Svetlana', '']]",1,1,2023-09-21,1,4,2,1,0,1,608a985e0cfb73aeca5e5e80bde5473bea1070dd,262084173.0,https://www.semanticscholar.org/paper/608a985e0cfb73aeca5e5e80bde5473bea1070dd,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2784449', 'name': 'N. Braunschweiler'}, {'authorId': '2538575', 'name': 'R. Doddipatla'}, {'authorId': '1796426', 'name': 'Simon Keizer'}, {'authorId': '2346574', 'name': 'Svetlana Stoyanchev'}]","['Toshiba Europe Limited Cambridge Research Laboratory, 208 Cambridge Science Park Cambridge, UK']",,2023-09,['industrial']
2309.11981,Pedro Moya,"Patricio Vera, Pedro Moya and Lisa Barraza",Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics,"14 pages, 1 table, 2 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 11:34:52 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Sep 2023 03:33:58 GMT'}, {'version': 'v3', 'created': 'Thu, 5 Oct 2023 02:58:52 GMT'}]",2023-10-06,"[['Vera', 'Patricio', ''], ['Moya', 'Pedro', ''], ['Barraza', 'Lisa', '']]",0,0,2023-09-21,3,3,2,0,0,0,33c3b99d9c05aadeff992e65aeb1c086c7ef5ba8,262084375.0,https://www.semanticscholar.org/paper/33c3b99d9c05aadeff992e65aeb1c086c7ef5ba8,arXiv.org,2023.0,151.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243336975', 'name': 'Patricio Vera'}, {'authorId': '2243335072', 'name': 'Pedro Moya'}, {'authorId': '2243335641', 'name': 'Lisa Barraza'}]","['Neurocreaciones, Las Condes, Santiago, Chile.']",['Chile'],2023-09,['industrial']
2309.12485,Nicolas Yax,"Nicolas Yax, Hernan Anll\'o, Stefano Palminteri",Studying and improving reasoning in humans and machines,"The paper is split in 4 parts : main text (pages 2-27), methods
  (pages 28-34), technical appendix (pages 35-45) and supplementary methods
  (pages 46-125)",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In the present study, we investigate and compare reasoning in large language models (LLM) and humans using a selection of cognitive psychology tools traditionally dedicated to the study of (bounded) rationality. To do so, we presented to human participants and an array of pretrained LLMs new variants of classical cognitive experiments, and cross-compared their performances. Our results showed that most of the included models presented reasoning errors akin to those frequently ascribed to error-prone, heuristic-based human reasoning. Notwithstanding this superficial similarity, an in-depth comparison between humans and LLMs indicated important differences with human-like reasoning, with models limitations disappearing almost entirely in more recent LLMs releases. Moreover, we show that while it is possible to devise strategies to induce better performance, humans and machines are not equally-responsive to the same prompting schemes. We conclude by discussing the epistemological implications and challenges of comparing human and machine behavior for both artificial intelligence and cognitive psychology. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 21:02:05 GMT'}]",2023-09-25,"[['Yax', 'Nicolas', ''], ['Anlló', 'Hernan', ''], ['Palminteri', 'Stefano', '']]",0,0,2023-09-21,1,3,3,0,0,0,ff4acf33aeafcbe7d12afdc6bb9ca26537219658,262217235.0,https://www.semanticscholar.org/paper/ff4acf33aeafcbe7d12afdc6bb9ca26537219658,arXiv.org,2023.0,0.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2238327629', 'name': 'Nicolas Yax'}, {'authorId': '2244622476', 'name': ""Hernan Anll'o""}, {'authorId': '6286029', 'name': 'Stefano Palminteri'}]","["") Département d'études cognitives, Ecole normale supérieure, Paris, France"", 'Inserm']",['France'],2023-09,"['industrial', 'industrial']"
2309.12499,Ramakrishna Bairi,"Ramakrishna Bairi, Atharv Sonwane, Aditya Kanade, Vageesh D C, Arun
  Iyer, Suresh Parthasarathy, Sriram Rajamani, B. Ashok, Shashank Shet",CodePlan: Repository-level Coding using LLMs and Planning,,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Software engineering activities such as package migration, fixing errors reports from static analysis or testing, and adding type annotations or other specifications to a codebase, involve pervasively editing the entire repository of code. We formulate these activities as repository-level coding tasks.   Recent tools like GitHub Copilot, which are powered by Large Language Models (LLMs), have succeeded in offering high-quality solutions to localized coding problems. Repository-level coding tasks are more involved and cannot be solved directly using LLMs, since code within a repository is inter-dependent and the entire repository may be too large to fit into the prompt. We frame repository-level coding as a planning problem and present a task-agnostic framework, called CodePlan to solve it. CodePlan synthesizes a multi-step chain of edits (plan), where each step results in a call to an LLM on a code location with context derived from the entire repository, previous code changes and task-specific instructions. CodePlan is based on a novel combination of an incremental dependency analysis, a change may-impact analysis and an adaptive planning algorithm.   We evaluate the effectiveness of CodePlan on two repository-level tasks: package migration (C#) and temporal code edits (Python). Each task is evaluated on multiple code repositories, each of which requires inter-dependent changes to many files (between 2-97 files). Coding tasks of this level of complexity have not been automated using LLMs before. Our results show that CodePlan has better match with the ground truth compared to baselines. CodePlan is able to get 5/6 repositories to pass the validity checks (e.g., to build without errors and make correct code edits) whereas the baselines (without planning but with the same type of contextual information as CodePlan) cannot get any of the repositories to pass them. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 21:45:17 GMT'}]",2023-09-25,"[['Bairi', 'Ramakrishna', ''], ['Sonwane', 'Atharv', ''], ['Kanade', 'Aditya', ''], ['C', 'Vageesh D', ''], ['Iyer', 'Arun', ''], ['Parthasarathy', 'Suresh', ''], ['Rajamani', 'Sriram', ''], ['Ashok', 'B.', ''], ['Shet', 'Shashank', '']]",0,0,2023-09-21,1,9,1,0,0,0,f81a1b4510631d14b5b565c4701ee056f8d5c72f,262217135.0,https://www.semanticscholar.org/paper/f81a1b4510631d14b5b565c4701ee056f8d5c72f,arXiv.org,2023.0,88.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1823210', 'name': 'Ramakrishna Bairi'}, {'authorId': '2133345604', 'name': 'Atharv Sonwane'}, {'authorId': '2244618470', 'name': 'Aditya Kanade'}, {'authorId': '2244619725', 'name': 'C. VageeshD'}, {'authorId': '2397529', 'name': 'Arun Shankar Iyer'}, {'authorId': '145022639', 'name': 'Suresh Parthasarathy'}, {'authorId': '1685546', 'name': 'S. Rajamani'}, {'authorId': '2244620879', 'name': 'B. Ashok'}, {'authorId': '2215149902', 'name': 'Shashank P. Shet'}]",['Microsoft'],['India'],2023-09,['industrial']
2309.12731,Dave Raggett,Dave Raggett,Defeasible Reasoning with Knowledge Graphs,"Accepted for: Knowledge Graph and Semantic Web Conference
  (KGSWC-2023), 13-15 September, 2023, Zaragoza, Spain",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Human knowledge is subject to uncertainties, imprecision, incompleteness and inconsistencies. Moreover, the meaning of many everyday terms is dependent on the context. That poses a huge challenge for the Semantic Web. This paper introduces work on an intuitive notation and model for defeasible reasoning with imperfect knowledge, and relates it to previous work on argumentation theory. PKN is to N3 as defeasible reasoning is to deductive logic. Further work is needed on an intuitive syntax for describing reasoning strategies and tactics in declarative terms, drawing upon the AIF ontology for inspiration. The paper closes with observations on symbolic approaches in the era of large language models. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 09:27:26 GMT'}]",2023-09-25,"[['Raggett', 'Dave', '']]",0,0,2023-09-22,1,1,1,0,0,0,c64d514bfe26e5617f4c65664b3c136d5fd8ec89,262217168.0,https://www.semanticscholar.org/paper/c64d514bfe26e5617f4c65664b3c136d5fd8ec89,Iberoamerican Conference on Knowledge Graphs and Semantic Web,2023.0,15.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244620860', 'name': 'Dave Raggett'}]",['European Research Consortium for Informatics and Mathematics'],['France'],2023-09,['industrial']
2309.12813,Hasan Ferit Eniser,"Hasan Ferit Eniser, Valentin W\""ustholz, Maria Christakis",Automatically Testing Functional Properties of Code Translation Models,13 pages including appendix and references,,,,cs.SE cs.LG cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models are becoming increasingly practical for translating code across programming languages, a process known as $transpiling$. Even though automated transpilation significantly boosts developer productivity, a key concern is whether the generated code is correct. Existing work initially used manually crafted test suites to test the translations of a small corpus of programs; these test suites were later automated. In contrast, we devise the first approach for automated, functional, property-based testing of code translation models. Our general, user-provided specifications about the transpiled code capture a range of properties, from purely syntactic to purely semantic ones. As shown by our experiments, this approach is very effective in detecting property violations in popular code translation models, and therefore, in evaluating model quality with respect to given properties. We also go a step further and explore the usage scenario where a user simply aims to obtain a correct translation of some code with respect to certain properties without necessarily being concerned about the overall quality of the model. To this purpose, we develop the first property-guided search procedure for code translation models, where a model is repeatedly queried with slightly different parameters to produce alternative and potentially more correct translations. Our results show that this search procedure helps to obtain significantly better code translations. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 11:00:15 GMT'}]",2023-09-25,"[['Eniser', 'Hasan Ferit', ''], ['Wüstholz', 'Valentin', ''], ['Christakis', 'Maria', '']]",0,0,2023-09-07,1,3,3,0,0,0,033b934bafa666b21d02047de5af6d00b9e983e1,262217299.0,https://www.semanticscholar.org/paper/033b934bafa666b21d02047de5af6d00b9e983e1,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2113090', 'name': 'Hasan Ferit Eniser'}, {'authorId': '2021178', 'name': 'Valentin Wüstholz'}, {'authorId': '2606785', 'name': 'M. Christakis'}]","['ConsenSys, Austria', 'TU Wien', 'Max Planck Institute for Software Systems']","['Germany', 'Austria']",2023-09,"['industrial', 'industrial', 'industrial']"
2309.12938,Nalin Wadhwa,"Nalin Wadhwa, Jui Pradhan, Atharv Sonwane, Surya Prakash Sahu,
  Nagarajan Natarajan, Aditya Kanade, Suresh Parthasarathy, Sriram Rajamani",Frustrated with Code Quality Issues? LLMs can Help!,,,,,cs.AI cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues. We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The \emph{proposer LLM} of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, the LLM may introduce subtle, unintended functionality changes which may go un-detected by the static analysis. The \emph{ranker LLM} evaluates the changes made by the proposer using a rubric that closely follows the acceptance criteria that a developer would enforce. CORE uses the scores assigned by the ranker LLM to rank the candidate revisions before presenting them to the developer. CORE could revise 59.2% Python files (across 52 quality checks) so that they pass scrutiny by both a tool and a human reviewer. The ranker LLM is able to reduce false positives by 25.8% in these cases. CORE produced revisions that passed the static analysis tool in 76.8% Java files (across 10 quality checks) comparable to 78.3% of a specialized program repair tool, with significantly much less engineering efforts. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 15:37:07 GMT'}]",2023-09-25,"[['Wadhwa', 'Nalin', ''], ['Pradhan', 'Jui', ''], ['Sonwane', 'Atharv', ''], ['Sahu', 'Surya Prakash', ''], ['Natarajan', 'Nagarajan', ''], ['Kanade', 'Aditya', ''], ['Parthasarathy', 'Suresh', ''], ['Rajamani', 'Sriram', '']]",0,0,2023-09-22,1,8,2,0,0,0,87c8a1540993f8a99138a112d2a68bebfe62d0c6,262216950.0,https://www.semanticscholar.org/paper/87c8a1540993f8a99138a112d2a68bebfe62d0c6,arXiv.org,2023.0,52.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244618408', 'name': 'Nalin Wadhwa'}, {'authorId': '2244618531', 'name': 'Jui Pradhan'}, {'authorId': '2133345604', 'name': 'Atharv Sonwane'}, {'authorId': '2185411106', 'name': 'Surya Prakash Sahu'}, {'authorId': '2244618406', 'name': 'Nagarajan Natarajan'}, {'authorId': '2244618470', 'name': 'Aditya Kanade'}, {'authorId': '145022639', 'name': 'Suresh Parthasarathy'}, {'authorId': '1685546', 'name': 'S. Rajamani'}]",['Microsoft'],['India'],2023-09,['industrial']
2309.13079,Fukai Shang,"Yidong Liu, FuKai Shang, Fang Wang, Rui Xu, Jun Wang, Wei Li, Yao Li,
  Conghui He",MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models,"4 pages,2 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  With the advancement of deep learning technologies, general-purpose large models such as GPT-4 have demonstrated exceptional capabilities across various domains. Nevertheless, there remains a demand for high-quality, domain-specific outputs in areas like healthcare, law, and finance. This paper first evaluates the existing large models for specialized domains and discusses their limitations. To cater to the specific needs of certain domains, we introduce the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and governmental sectors. The dataset, sourced from publicly available internet data from 2022, underwent multiple rounds of cleansing and processing to ensure high quality and reliable origins, with provisions for consistent and stable updates. This dataset not only supports the pre-training of large models for Chinese vertical domains but also aids in propelling deep learning research and applications in related fields. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 09:02:28 GMT'}, {'version': 'v2', 'created': 'Tue, 26 Sep 2023 10:38:19 GMT'}]",2023-09-27,"[['Liu', 'Yidong', ''], ['Shang', 'FuKai', ''], ['Wang', 'Fang', ''], ['Xu', 'Rui', ''], ['Wang', 'Jun', ''], ['Li', 'Wei', ''], ['Li', 'Yao', ''], ['He', 'Conghui', '']]",0,1,2023-09-21,2,8,2,1,0,1,b2ea7690230be22f7781b33bede69b49f7ea5191,262466089.0,https://www.semanticscholar.org/paper/b2ea7690230be22f7781b33bede69b49f7ea5191,arXiv.org,2023.0,12.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2186736278', 'name': 'Yidong Liu'}, {'authorId': '3486481', 'name': 'Conghui He'}, {'authorId': '2256598803', 'name': 'Wei Li'}, {'authorId': '2227474613', 'name': 'Fu-De Shang'}, {'authorId': '66063792', 'name': 'J. Wang'}, {'authorId': '2110976037', 'name': 'Yaoxin Li'}, {'authorId': '2115802652', 'name': 'Rui Xu'}]","['Shanghai Artificial Intelligence Laboratory', 'Shanghai Midu Technology Co., Ltd']",['China'],2023-09,"['industrial', 'industrial']"
2309.13322,Wissam Antoun,"Wissam Antoun, Beno\^it Sagot, Djam\'e Seddah",From Text to Source: Results in Detecting Large Language Model-Generated Content,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  The widespread use of Large Language Models (LLMs), celebrated for their ability to generate human-like text, has raised concerns about misinformation and ethical implications. Addressing these concerns necessitates the development of robust methods to detect and attribute text generated by LLMs. This paper investigates ""Cross-Model Detection,"" evaluating whether a classifier trained to distinguish between source LLM-generated and human-written text can also detect text from a target LLM without further training. The study comprehensively explores various LLM sizes and families, and assesses the impact of conversational fine-tuning techniques on classifier generalization. The research also delves into Model Attribution, encompassing source model identification, model family classification, and model size classification. Our results reveal several key findings: a clear inverse relationship between classifier effectiveness and model size, with larger LLMs being more challenging to detect, especially when the classifier is trained on data from smaller models. Training on data from similarly sized LLMs can improve detection performance from larger models but may lead to decreased performance when dealing with smaller models. Additionally, model attribution experiments show promising results in identifying source models and model families, highlighting detectable signatures in LLM-generated text. Overall, our study contributes valuable insights into the interplay of model size, family, and training data in LLM detection and attribution. ","[{'version': 'v1', 'created': 'Sat, 23 Sep 2023 09:51:37 GMT'}]",2023-09-26,"[['Antoun', 'Wissam', ''], ['Sagot', 'Benoît', ''], ['Seddah', 'Djamé', '']]",0,0,2023-09-23,1,3,1,0,0,0,a0012cf12186fde248dde4cccdccb74e83624ac3,262465111.0,https://www.semanticscholar.org/paper/a0012cf12186fde248dde4cccdccb74e83624ac3,arXiv.org,2023.0,46.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51040671', 'name': 'Wissam Antoun'}, {'authorId': '68990982', 'name': 'Benoît Sagot'}, {'authorId': '1679170', 'name': 'Djamé Seddah'}]","['Inria, Paris']",,2023-09,['industrial']
2309.13701,Hosein Hasanbeig,"Hosein Hasanbeig and Hiteshi Sharma and Leo Betthauser and Felipe
  Vieira Frujeri and Ida Momennejad",ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning,,,,,cs.CL cs.AI cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  From grading papers to summarizing medical documents, large language models (LLMs) are evermore used for evaluation of text generated by humans and AI alike. However, despite their extensive utility, LLMs exhibit distinct failure modes, necessitating a thorough audit and improvement of their text evaluation capabilities. Here we introduce ALLURE, a systematic approach to Auditing Large Language Models Understanding and Reasoning Errors. ALLURE involves comparing LLM-generated evaluations with annotated data, and iteratively incorporating instances of significant deviation into the evaluator, which leverages in-context learning (ICL) to enhance and improve robust evaluation of text by LLMs. Through this iterative process, we refine the performance of the evaluator LLM, ultimately reducing reliance on human annotators in the evaluation process. We anticipate ALLURE to serve diverse applications of LLMs in various domains related to evaluation of textual data, such as medical summarization, education, and and productivity. ","[{'version': 'v1', 'created': 'Sun, 24 Sep 2023 17:15:58 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Sep 2023 00:26:08 GMT'}]",2023-09-28,"[['Hasanbeig', 'Hosein', ''], ['Sharma', 'Hiteshi', ''], ['Betthauser', 'Leo', ''], ['Frujeri', 'Felipe Vieira', ''], ['Momennejad', 'Ida', '']]",0,0,2023-09-24,2,5,3,0,0,0,fa4ea8b773ffd6706ba5cf427f9671f81b04dcdd,262464455.0,https://www.semanticscholar.org/paper/fa4ea8b773ffd6706ba5cf427f9671f81b04dcdd,arXiv.org,2023.0,66.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2245381886', 'name': 'Hosein Hasanbeig'}, {'authorId': '20013278', 'name': 'Hiteshi Sharma'}, {'authorId': '15449757', 'name': 'Leo Betthauser'}, {'authorId': '1844283112', 'name': 'F. Frujeri'}, {'authorId': '1990422', 'name': 'I. Momennejad'}]",['Microsoft'],['United States'],2023-09,['industrial']
2309.13905,Jianwei Yu,"Jianwei Yu, Hangting Chen, Yanyao Bian, Xiang Li, Yi Luo, Jinchuan
  Tian, Mengyang Liu, Jiayi Jiang, Shuai Wang",AutoPrep: An Automatic Preprocessing Framework for In-the-Wild Speech Data,,,,,eess.AS cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, the utilization of extensive open-sourced text data has significantly advanced the performance of text-based large language models (LLMs). However, the use of in-the-wild large-scale speech data in the speech technology community remains constrained. One reason for this limitation is that a considerable amount of the publicly available speech data is compromised by background noise, speech overlapping, lack of speech segmentation information, missing speaker labels, and incomplete transcriptions, which can largely hinder their usefulness. On the other hand, human annotation of speech data is both time-consuming and costly. To address this issue, we introduce an automatic in-the-wild speech data preprocessing framework (AutoPrep) in this paper, which is designed to enhance speech quality, generate speaker labels, and produce transcriptions automatically. The proposed AutoPrep framework comprises six components: speech enhancement, speech segmentation, speaker clustering, target speech extraction, quality filtering and automatic speech recognition. Experiments conducted on the open-sourced WenetSpeech and our self-collected AutoPrepWild corpora demonstrate that the proposed AutoPrep framework can generate preprocessed data with similar DNSMOS and PDNSMOS scores compared to several open-sourced TTS datasets. The corresponding TTS system can achieve up to 0.68 in-domain speaker similarity. ","[{'version': 'v1', 'created': 'Mon, 25 Sep 2023 07:01:10 GMT'}]",2023-09-26,"[['Yu', 'Jianwei', ''], ['Chen', 'Hangting', ''], ['Bian', 'Yanyao', ''], ['Li', 'Xiang', ''], ['Luo', 'Yi', ''], ['Tian', 'Jinchuan', ''], ['Liu', 'Mengyang', ''], ['Jiang', 'Jiayi', ''], ['Wang', 'Shuai', '']]",0,0,2023-09-25,1,9,2,0,0,0,98c7bb8f9a8048d8098f3c03fa0187644b248d3c,262480519.0,https://www.semanticscholar.org/paper/98c7bb8f9a8048d8098f3c03fa0187644b248d3c,arXiv.org,2023.0,31.0,0.0,0.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2161264092', 'name': 'Jianwei Yu'}, {'authorId': '2118023944', 'name': 'Hangting Chen'}, {'authorId': '51110739', 'name': 'Yanyao Bian'}, {'authorId': '47057383', 'name': 'Xiang Li'}, {'authorId': '49513614', 'name': 'Yimin Luo'}, {'authorId': '2087131860', 'name': 'Jinchuan Tian'}, {'authorId': '2152970727', 'name': 'Mengyang Liu'}, {'authorId': '1914623206', 'name': 'Jiayi Jiang'}, {'authorId': '2155449067', 'name': 'Shuai Wang'}]","['Tencent', 'Shenzhen Research Institute of Big Data']",['China'],2023-09,"['industrial', 'industrial']"
2309.14509,Sam Ade Jacobs,"Sam Ade Jacobs, Masahiro Tanaka, Chengming Zhang, Minjia Zhang,
  Shuaiwen Leon Song, Samyam Rajbhandari, Yuxiong He",DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models,,,,,cs.LG cs.CL cs.DC,http://creativecommons.org/licenses/by/4.0/,"  Computation in a typical Transformer-based large language model (LLM) can be characterized by batch size, hidden dimension, number of layers, and sequence length. Until now, system works for accelerating LLM training have focused on the first three dimensions: data parallelism for batch size, tensor parallelism for hidden size and pipeline parallelism for model depth or layers. These widely studied forms of parallelism are not targeted or optimized for long sequence Transformer models. Given practical application needs for long sequence LLM, renewed attentions are being drawn to sequence parallelism. However, existing works in sequence parallelism are constrained by memory-communication inefficiency, limiting their scalability to long sequence large models. In this work, we introduce DeepSpeed-Ulysses, a novel, portable and effective methodology for enabling highly efficient and scalable LLM training with extremely long sequence length. DeepSpeed-Ulysses at its core partitions input data along the sequence dimension and employs an efficient all-to-all collective communication for attention computation. Theoretical communication analysis shows that whereas other methods incur communication overhead as sequence length increases, DeepSpeed-Ulysses maintains constant communication volume when sequence length and compute devices are increased proportionally. Furthermore, experimental evaluations show that DeepSpeed-Ulysses trains 2.5x faster with 4x longer sequence length than the existing method SOTA baseline. ","[{'version': 'v1', 'created': 'Mon, 25 Sep 2023 20:15:57 GMT'}, {'version': 'v2', 'created': 'Wed, 4 Oct 2023 16:51:13 GMT'}]",2023-10-05,"[['Jacobs', 'Sam Ade', ''], ['Tanaka', 'Masahiro', ''], ['Zhang', 'Chengming', ''], ['Zhang', 'Minjia', ''], ['Song', 'Shuaiwen Leon', ''], ['Rajbhandari', 'Samyam', ''], ['He', 'Yuxiong', '']]",0,0,2023-09-25,2,7,3,0,0,0,a51ac7a5e8f6454268ac16ecdc52ecac98ce54d9,262826014.0,https://www.semanticscholar.org/paper/a51ac7a5e8f6454268ac16ecdc52ecac98ce54d9,arXiv.org,2023.0,31.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1683824', 'name': 'S. A. Jacobs'}, {'authorId': '2118817779', 'name': 'Masahiro Tanaka'}, {'authorId': '2248958850', 'name': 'Chengming Zhang'}, {'authorId': '67016465', 'name': 'Minjia Zhang'}, {'authorId': '2145202945', 'name': 'L. Song'}, {'authorId': '32817044', 'name': 'Samyam Rajbhandari'}, {'authorId': '2145020341', 'name': 'Yuxiong He'}]",['Microsoft'],['United States'],2023-09,['industrial']
2309.14525,Sheng Shen,"Zhiqing Sun, Sheng Shen, Shengcao Cao, Haotian Liu, Chunyuan Li,
  Yikang Shen, Chuang Gan, Liang-Yan Gui, Yu-Xiong Wang, Yiming Yang, Kurt
  Keutzer, Trevor Darrell",Aligning Large Multimodal Models with Factually Augmented RLHF,Preprint,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in ""hallucination"", generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement Learning from Human Feedback (RLHF) from the text domain to the task of vision-language alignment, where human annotators are asked to compare two responses and pinpoint the more hallucinated one, and the vision-language model is trained to maximize the simulated human rewards. We propose a new alignment algorithm called Factually Augmented RLHF that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance. We also enhance the GPT-4-generated training data (for vision instruction tuning) with previously available human-written image-text pairs to improve the general capabilities of our model. To evaluate the proposed approach in real-world scenarios, we develop a new evaluation benchmark MMHAL-BENCH with a special focus on penalizing hallucinations. As the first LMM trained with RLHF, our approach achieves remarkable improvement on the LLaVA-Bench dataset with the 94% performance level of the text-only GPT-4 (while previous best methods can only achieve the 87% level), and an improvement by 60% on MMHAL-BENCH over other baselines. We opensource our code, model, data at https://llava-rlhf.github.io. ","[{'version': 'v1', 'created': 'Mon, 25 Sep 2023 20:59:33 GMT'}]",2023-09-27,"[['Sun', 'Zhiqing', ''], ['Shen', 'Sheng', ''], ['Cao', 'Shengcao', ''], ['Liu', 'Haotian', ''], ['Li', 'Chunyuan', ''], ['Shen', 'Yikang', ''], ['Gan', 'Chuang', ''], ['Gui', 'Liang-Yan', ''], ['Wang', 'Yu-Xiong', ''], ['Yang', 'Yiming', ''], ['Keutzer', 'Kurt', ''], ['Darrell', 'Trevor', '']]",0,1,2023-09-25,1,12,2,1,0,1,844bb298d49ef4a07b5d4929dfdfd170f6a1d5f5,262824780.0,https://www.semanticscholar.org/paper/844bb298d49ef4a07b5d4929dfdfd170f6a1d5f5,arXiv.org,2023.0,72.0,15.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48064856', 'name': 'Zhiqing Sun'}, {'authorId': '2191455', 'name': 'Sheng Shen'}, {'authorId': '31136675', 'name': 'Shengcao Cao'}, {'authorId': '2143856368', 'name': 'Haotian Liu'}, {'authorId': '2243126534', 'name': 'Chunyuan Li'}, {'authorId': '2714199', 'name': 'Yikang Shen'}, {'authorId': '144158271', 'name': 'Chuang Gan'}, {'authorId': '2587808', 'name': 'Liangyan Gui'}, {'authorId': '2302062', 'name': 'Yu-Xiong Wang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '1732330', 'name': 'K. Keutzer'}, {'authorId': '1753210', 'name': 'Trevor Darrell'}]",['MIT-IBM Watson AI Lab'],['United States'],2023-09,['industrial']
2309.14717,Yuhui Xu,"Yuhui Xu, Lingxi Xie, Xiaotao Gu, Xin Chen, Heng Chang, Hengheng
  Zhang, Zhensu Chen, Xiaopeng Zhang, Qi Tian",QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models,16 pages,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently years have witnessed a rapid development of large language models (LLMs). Despite the strong ability in many language-understanding tasks, the heavy computational burden largely restricts the application of LLMs especially when one needs to deploy them onto edge devices. In this paper, we propose a quantization-aware low-rank adaptation (QA-LoRA) algorithm. The motivation lies in the imbalanced degrees of freedom of quantization and adaptation, and the solution is to use group-wise operators which increase the degree of freedom of quantization meanwhile decreasing that of adaptation. QA-LoRA is easily implemented with a few lines of code, and it equips the original LoRA with two-fold abilities: (i) during fine-tuning, the LLM's weights are quantized (e.g., into INT4) to reduce time and memory usage; (ii) after fine-tuning, the LLM and auxiliary weights are naturally integrated into a quantized model without loss of accuracy. We apply QA-LoRA to the LLaMA and LLaMA2 model families and validate its effectiveness in different fine-tuning datasets and downstream scenarios. Code will be made available at https://github.com/yuhuixu1993/qa-lora. ","[{'version': 'v1', 'created': 'Tue, 26 Sep 2023 07:22:23 GMT'}]",2023-09-28,"[['Xu', 'Yuhui', ''], ['Xie', 'Lingxi', ''], ['Gu', 'Xiaotao', ''], ['Chen', 'Xin', ''], ['Chang', 'Heng', ''], ['Zhang', 'Hengheng', ''], ['Chen', 'Zhensu', ''], ['Zhang', 'Xiaopeng', ''], ['Tian', 'Qi', '']]",0,0,2023-09-26,1,9,2,1,1,0,945db0077b6d19b720f5998b3f61300013c4f885,262825568.0,https://www.semanticscholar.org/paper/945db0077b6d19b720f5998b3f61300013c4f885,arXiv.org,2023.0,64.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48615640', 'name': 'Yuhui Xu'}, {'authorId': '3041937', 'name': 'Lingxi Xie'}, {'authorId': '7787721', 'name': 'Xiaotao Gu'}, {'authorId': '2145229597', 'name': 'Xin Chen'}, {'authorId': '144188238', 'name': 'Heng Chang'}, {'authorId': '1983351', 'name': 'Hengheng Zhang'}, {'authorId': '2249294812', 'name': 'Zhensu Chen'}, {'authorId': '21458018', 'name': 'Xiaopeng Zhang'}, {'authorId': '2106415186', 'name': 'Qi Tian'}]",['Huawei Technologies (China)'],['China'],2023-09,['industrial']
2309.15129,Ida Momennejad,"Ida Momennejad, Hosein Hasanbeig, Felipe Vieira, Hiteshi Sharma,
  Robert Osazuwa Ness, Nebojsa Jojic, Hamid Palangi, Jonathan Larson",Evaluating Cognitive Maps and Planning in Large Language Models with CogEval,,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recently an influx of studies claim emergent cognitive abilities in large language models (LLMs). Yet, most rely on anecdotes, overlook contamination of training sets, or lack systematic Evaluation involving multiple tasks, control conditions, multiple iterations, and statistical robustness tests. Here we make two major contributions. First, we propose CogEval, a cognitive science-inspired protocol for the systematic evaluation of cognitive capacities in Large Language Models. The CogEval protocol can be followed for the evaluation of various abilities. Second, here we follow CogEval to systematically evaluate cognitive maps and planning ability across eight LLMs (OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard, Cohere-xlarge-52.4B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base our task prompts on human experiments, which offer both established construct validity for evaluating planning, and are absent from LLM training sets. We find that, while LLMs show apparent competence in a few planning tasks with simpler structures, systematic evaluation reveals striking failure modes in planning tasks, including hallucinations of invalid trajectories and getting trapped in loops. These findings do not support the idea of emergent out-of-the-box planning ability in LLMs. This could be because LLMs do not understand the latent relational structures underlying planning problems, known as cognitive maps, and fail at unrolling goal-directed trajectories based on the underlying structure. Implications for application and future directions are discussed. ","[{'version': 'v1', 'created': 'Mon, 25 Sep 2023 01:20:13 GMT'}]",2023-09-28,"[['Momennejad', 'Ida', ''], ['Hasanbeig', 'Hosein', ''], ['Vieira', 'Felipe', ''], ['Sharma', 'Hiteshi', ''], ['Ness', 'Robert Osazuwa', ''], ['Jojic', 'Nebojsa', ''], ['Palangi', 'Hamid', ''], ['Larson', 'Jonathan', '']]",0,1,2023-09-25,1,8,3,7,1,6,9977fee41d9cce1b2ed924da966140ac8120762b,263152832.0,https://www.semanticscholar.org/paper/9977fee41d9cce1b2ed924da966140ac8120762b,arXiv.org,2023.0,66.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2248289111', 'name': 'Ida Momennejad'}, {'authorId': '2245381886', 'name': 'Hosein Hasanbeig'}, {'authorId': '1844283112', 'name': 'F. Frujeri'}, {'authorId': '2248286708', 'name': 'Hiteshi Sharma'}, {'authorId': '36670968', 'name': 'R. Ness'}, {'authorId': '2235694378', 'name': 'Nebojsa Jojic'}, {'authorId': '2247662718', 'name': 'Hamid Palangi'}, {'authorId': '2248259058', 'name': 'Jonathan Larson'}]",['Microsoft'],['United States'],2023-09,['industrial']
2309.15337,Philippe Laban,"Philippe Laban, Jesse Vig, Marti A. Hearst, Caiming Xiong, Chien-Sheng
  Wu",Beyond the Chat: Executable and Verifiable Text-Editing with LLMs,,,,,cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conversational interfaces powered by Large Language Models (LLMs) have recently become a popular way to obtain feedback during document editing. However, standard chat-based conversational interfaces do not support transparency and verifiability of the editing changes that they suggest. To give the author more agency when editing with an LLM, we present InkSync, an editing interface that suggests executable edits directly within the document being edited. Because LLMs are known to introduce factual errors, Inksync also supports a 3-stage approach to mitigate this risk: Warn authors when a suggested edit introduces new information, help authors Verify the new information's accuracy through external search, and allow an auditor to perform an a-posteriori verification by Auditing the document via a trace of all auto-generated content. Two usability studies confirm the effectiveness of InkSync's components when compared to standard LLM-based chat interfaces, leading to more accurate, more efficient editing, and improved user experience. ","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 00:56:17 GMT'}]",2023-09-28,"[['Laban', 'Philippe', ''], ['Vig', 'Jesse', ''], ['Hearst', 'Marti A.', ''], ['Xiong', 'Caiming', ''], ['Wu', 'Chien-Sheng', '']]",0,0,2023-09-27,1,5,2,0,0,0,ffe99f36269e6ff3f765954b62774ae6d48747c0,262938226.0,https://www.semanticscholar.org/paper/ffe99f36269e6ff3f765954b62774ae6d48747c0,arXiv.org,2023.0,74.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46180754', 'name': 'Philippe Laban'}, {'authorId': '2238207712', 'name': 'Jesse Vig'}, {'authorId': '1716902', 'name': 'Marti A. Hearst'}, {'authorId': '2054594326', 'name': 'Caiming Xiong'}, {'authorId': '30340989', 'name': 'Chien-Sheng Wu'}]","['CAIMING XIONG, Salesforce AI Research, United States', 'CHIEN-SHENG WU, Salesforce AI Research, United States', 'Salesforce AI Research, United States JESSE VIG, Salesforce AI Research, United States', 'Lawrence Berkeley National Laboratory']",['United States'],2023-09,"['industrial', 'industrial', 'industrial', 'industrial']"
2309.15577,Anthony Cohn,Anthony G Cohn,An Evaluation of ChatGPT-4's Qualitative Spatial Reasoning Capabilities in RCC-8,"10 figures. 8 pages. Accepted for presentation at 36th International
  Workshop on Qualitative Reasoning (QR-23), in conjunction with ECAI2023 in
  Krakow, Poland",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Qualitative Spatial Reasoning (QSR) is well explored area of Commonsense Reasoning and has multiple applications ranging from Geographical Information Systems to Robotics and Computer Vision. Recently many claims have been made for the capabilities of Large Language Models (LLMs). In this paper we investigate the extent to which one particular LLM can perform classical qualitative spatial reasoning tasks on the mereotopological calculus, RCC-8. ","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 11:23:15 GMT'}]",2023-09-28,"[['Cohn', 'Anthony G', '']]",1,1,2023-09-27,1,1,1,1,0,1,b5a0430d99d33bd83464504a6ba15af24ac225eb,263152389.0,https://www.semanticscholar.org/paper/b5a0430d99d33bd83464504a6ba15af24ac225eb,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2248060864', 'name': 'Anthony G Cohn'}]",['The Alan Turing Institute'],['United Kingdom'],2023-09,['industrial']
2309.16414,Jan Metzen,"Jan Hendrik Metzen, Piyapat Saranrittichai, Chaithanya Kumar Mummadi",AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models,,,,,cs.CV cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Classifiers built upon vision-language models such as CLIP have shown remarkable zero-shot performance across a broad range of image classification tasks. Prior work has studied different ways of automatically creating descriptor sets for every class based on prompt templates, ranging from manually engineered templates over templates obtained from a large language model to templates built from random words and characters. Up until now, deriving zero-shot classifiers from the respective encoded class descriptors has remained nearly unchanged, i.e., classify to the class that maximizes cosine similarity between its averaged encoded class descriptors and the image encoding. However, weighing all class descriptors equally can be suboptimal when certain descriptors match visual clues on a given image better than others. In this work, we propose AutoCLIP, a method for auto-tuning zero-shot classifiers. AutoCLIP tunes per-image weights to each prompt template at inference time, based on statistics of class descriptor-image similarities. AutoCLIP is fully unsupervised, has very low computational overhead, and can be easily implemented in few lines of code. We show that AutoCLIP outperforms baselines across a broad range of vision-language models, datasets, and prompt templates consistently and by up to 3 percent point accuracy. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 13:08:08 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Sep 2023 08:24:13 GMT'}]",2023-10-02,"[['Metzen', 'Jan Hendrik', ''], ['Saranrittichai', 'Piyapat', ''], ['Mummadi', 'Chaithanya Kumar', '']]",0,0,2023-09-28,2,3,3,0,0,0,99bd3e04b6b65abf3f03de69654059c3710d03e8,263142957.0,https://www.semanticscholar.org/paper/99bd3e04b6b65abf3f03de69654059c3710d03e8,arXiv.org,2023.0,27.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2708564', 'name': 'J. H. Metzen'}, {'authorId': '9359914', 'name': 'Piyapat Saranrittichai'}, {'authorId': '29359383', 'name': 'Chaithanya Kumar Mummadi'}]",['Robert Bosch (India)'],['India'],2023-09,['industrial']
2309.16656,Neelesh Kumar,"Neelesh Kumar, Oya Aran, Venugopal Vasudevan",Visual In-Context Learning for Few-Shot Eczema Segmentation,,,,,cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Automated diagnosis of eczema from digital camera images is crucial for developing applications that allow patients to self-monitor their recovery. An important component of this is the segmentation of eczema region from such images. Current methods for eczema segmentation rely on deep neural networks such as convolutional (CNN)-based U-Net or transformer-based Swin U-Net. While effective, these methods require high volume of annotated data, which can be difficult to obtain. Here, we investigate the capabilities of visual in-context learning that can perform few-shot eczema segmentation with just a handful of examples and without any need for retraining models. Specifically, we propose a strategy for applying in-context learning for eczema segmentation with a generalist vision model called SegGPT. When benchmarked on a dataset of annotated eczema images, we show that SegGPT with just 2 representative example images from the training dataset performs better (mIoU: 36.69) than a CNN U-Net trained on 428 images (mIoU: 32.60). We also discover that using more number of examples for SegGPT may in fact be harmful to its performance. Our result highlights the importance of visual in-context learning in developing faster and better solutions to skin imaging tasks. Our result also paves the way for developing inclusive solutions that can cater to minorities in the demographics who are typically heavily under-represented in the training data. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 17:55:24 GMT'}]",2023-09-29,"[['Kumar', 'Neelesh', ''], ['Aran', 'Oya', ''], ['Vasudevan', 'Venugopal', '']]",0,1,2023-09-28,1,3,2,0,0,0,14795c7f2e8129f6bd6994b9c8c04bb23b23c483,263135621.0,https://www.semanticscholar.org/paper/14795c7f2e8129f6bd6994b9c8c04bb23b23c483,arXiv.org,2023.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2249214473', 'name': 'Neelesh Kumar'}, {'authorId': '2248189864', 'name': 'Oya Aran'}, {'authorId': '2248203732', 'name': 'Venugopal Vasudevan'}]",['Procter & Gamble (United States)'],['United States'],2023-09,['industrial']
2309.16721,Xiaokai Qin,"Xiaokai Qin, Mingda Song, Yangguan Chen, Zhehong Ai, Jing Jiang",GPT-Lab: Next Generation Of Optimal Chemistry Discovery By GPT Driven Robotic Lab,,,,,cs.AI cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The integration of robots in chemical experiments has enhanced experimental efficiency, but lacking the human intelligence to comprehend literature, they seldom provide assistance in experimental design. Therefore, achieving full-process autonomy from experiment design to validation in self-driven laboratories (SDL) remains a challenge. The introduction of Generative Pre-trained Transformers (GPT), particularly GPT-4, into robotic experimentation offers a solution. We introduce GPT-Lab, a paradigm that employs GPT models to give robots human-like intelligence. With our robotic experimentation platform, GPT-Lab mines literature for materials and methods and validates findings through high-throughput synthesis. As a demonstration, GPT-Lab analyzed 500 articles, identified 18 potential reagents, and successfully produced an accurate humidity colorimetric sensor with a root mean square error (RMSE) of 2.68%. This showcases the rapid materials discovery and validation potential of our system. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 10:51:21 GMT'}]",2023-10-02,"[['Qin', 'Xiaokai', ''], ['Song', 'Mingda', ''], ['Chen', 'Yangguan', ''], ['Ai', 'Zhehong', ''], ['Jiang', 'Jing', '']]",0,1,2023-09-15,1,5,2,1,0,1,91b68391df0b16d22bffbbf4d0c09f13dee36561,263310436.0,https://www.semanticscholar.org/paper/91b68391df0b16d22bffbbf4d0c09f13dee36561,arXiv.org,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2249728784', 'name': 'Xiaokai Qin'}, {'authorId': '2249576510', 'name': 'Mingda Song'}, {'authorId': '2249556346', 'name': 'Yangguan Chen'}, {'authorId': '2176580121', 'name': 'Zhehong Ai'}, {'authorId': '2249716397', 'name': 'Jing Jiang'}]",['Zhejiang Lab'],['China'],2023-09,['industrial']
2309.17234,Sahar Abdelnabi,"Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Sch\""onherr, Mario
  Fritz",LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games,,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There is a growing interest in using Large Language Models (LLMs) as agents to tackle real-world tasks that may require assessing complex situations. Yet, we have a limited understanding of LLMs' reasoning and decision-making capabilities, partly stemming from a lack of dedicated evaluation benchmarks. As negotiating and compromising are key aspects of our everyday communication and collaboration, we propose using scorable negotiation games as a new evaluation framework for LLMs. We create a testbed of diverse text-based, multi-agent, multi-issue, semantically rich negotiation games, with easily tunable difficulty. To solve the challenge, agents need to have strong arithmetic, inference, exploration, and planning capabilities, while seamlessly integrating them. Via a systematic zero-shot Chain-of-Thought prompting (CoT), we show that agents can negotiate and consistently reach successful deals. We quantify the performance with multiple metrics and observe a large gap between GPT-4 and earlier models. Importantly, we test the generalization to new games and setups. Finally, we show that these games can help evaluate other critical aspects, such as the interaction dynamics between agents in the presence of greedy and adversarial players. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 13:33:06 GMT'}]",2023-10-02,"[['Abdelnabi', 'Sahar', ''], ['Gomaa', 'Amr', ''], ['Sivaprasad', 'Sarath', ''], ['Schönherr', 'Lea', ''], ['Fritz', 'Mario', '']]",0,1,2023-09-29,1,5,3,1,0,1,f3bcb9395d8b912361cc534f00e837c832000150,263310628.0,https://www.semanticscholar.org/paper/f3bcb9395d8b912361cc534f00e837c832000150,arXiv.org,2023.0,68.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1383113350', 'name': 'Sahar Abdelnabi'}, {'authorId': '2249532110', 'name': 'Amr Gomaa'}, {'authorId': '31215717', 'name': 'S. Sivaprasad'}, {'authorId': '2249532086', 'name': 'Lea Schonherr'}, {'authorId': '2249532235', 'name': 'Mario Fritz'}]","['Helmholtz Center for Information Security', 'German Research Centre for Artificial Intelligence']",['Germany'],2023-09,"['industrial', 'industrial']"
2310.00328,Joe O'Brien,"Joe O'Brien, Shaun Ee, Zoe Williams",Deployment Corrections: An incident response framework for frontier AI models,53 pages; 1 figure; 1 table,,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  A comprehensive approach to addressing catastrophic risks from AI models should cover the full model lifecycle. This paper explores contingency plans for cases where pre-deployment risk management falls short: where either very dangerous models are deployed, or deployed models become very dangerous.   Informed by incident response practices from industries including cybersecurity, we describe a toolkit of deployment corrections that AI developers can use to respond to dangerous capabilities, behaviors, or use cases of AI models that develop or are detected after deployment. We also provide a framework for AI developers to prepare and implement this toolkit.   We conclude by recommending that frontier AI developers should (1) maintain control over model access, (2) establish or grow dedicated teams to design and maintain processes for deployment corrections, including incident response plans, and (3) establish these deployment corrections as allowable actions with downstream users. We also recommend frontier AI developers, standard-setting organizations, and regulators should collaborate to define a standardized industry-wide approach to the use of deployment corrections in incident response.   Caveat: This work applies to frontier AI models that are made available through interfaces (e.g., API) that provide the AI developer or another upstream party means of maintaining control over access (e.g., GPT-4 or Claude). It does not apply to management of catastrophic risk from open-source models (e.g., BLOOM or Llama-2), for which the restrictions we discuss are largely unenforceable. ","[{'version': 'v1', 'created': 'Sat, 30 Sep 2023 10:07:39 GMT'}]",2023-10-03,"[[""O'Brien"", 'Joe', ''], ['Ee', 'Shaun', ''], ['Williams', 'Zoe', '']]",0,1,2023-09-30,1,3,1,4,2,2,69773e5a978b94ad50fb4bb5d977e7b4c7c8d8f2,263333974.0,https://www.semanticscholar.org/paper/69773e5a978b94ad50fb4bb5d977e7b4c7c8d8f2,arXiv.org,2023.0,67.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2249761215', 'name': ""Joe O'Brien""}, {'authorId': '2249763223', 'name': 'Shaun Ee'}, {'authorId': '2249763041', 'name': 'Zoe Williams'}]",['Zoe Williams -Research Manager'],,2023-09,['industrial']
2310.01425,L\'eon Bottou,"L\'eon Bottou and Bernhard Sch\""olkopf",Borges and AI,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Many believe that Large Language Models (LLMs) open the era of Artificial Intelligence (AI). Some see opportunities while others see dangers. Yet both proponents and opponents grasp AI through the imagery popularised by science fiction. Will the machine become sentient and rebel against its creators? Will we experience a paperclip apocalypse? Before answering such questions, we should first ask whether this mental imagery provides a good description of the phenomenon at hand. Understanding weather patterns through the moods of the gods only goes so far. The present paper instead advocates understanding LLMs and their connection to AI through the imagery of Jorge Luis Borges, a master of 20th century literature, forerunner of magical realism, and precursor to postmodern literature. This exercise leads to a new perspective that illuminates the relation between language modelling and artificial intelligence. ","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 16:15:34 GMT'}, {'version': 'v2', 'created': 'Wed, 4 Oct 2023 18:10:30 GMT'}]",2023-10-06,"[['Bottou', 'Léon', ''], ['Schölkopf', 'Bernhard', '']]",0,0,2023-09-27,2,2,3,0,0,0,22dc601ca9c70a676052ec36326ecc32c6c35761,263609216.0,https://www.semanticscholar.org/paper/22dc601ca9c70a676052ec36326ecc32c6c35761,arXiv.org,2023.0,10.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","[{'authorId': '2253589498', 'name': 'Léon Bottou'}, {'authorId': '2237290631', 'name': 'Bernhard Schölkopf'}]","['Meta', 'Max Planck Institute for Intelligent Systems']","['Germany', 'United States']",2023-09,"['industrial', 'industrial']"
2310.01429,Eren Unlu Ph. D.,Eren Unlu,Chatmap : Large Language Model Interaction with Cartographic Data,"9 pages, 4 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The swift advancement and widespread availability of foundational Large Language Models (LLMs), complemented by robust fine-tuning methodologies, have catalyzed their adaptation for innovative and industrious applications. Enabling LLMs to recognize and interpret geospatial data, while offering a linguistic access to vast cartographic datasets, is of significant importance. OpenStreetMap (OSM) is the most ambitious open-source global initiative offering detailed urban and rural geographic data, curated by a community of over 10 million contributors, which constitutes a great potential for LLM applications. In this study, we demonstrate the proof of concept and details of the process of fine-tuning a relatively small scale (1B parameters) LLM with a relatively small artificial dataset curated by a more capable teacher model, in order to provide a linguistic interface to the OSM data of an arbitrary urban region. Through this interface, users can inquire about a location's attributes, covering a wide spectrum of concepts, such as its touristic appeal or the potential profitability of various businesses in that vicinity. The study aims to provide an initial guideline for such generative artificial intelligence (AI) adaptations and demonstrate early signs of useful emerging abilities in this context even in minimal computational settings. The embeddings of artificially curated prompts including OSM data are also investigated in detail, which might be instrumental for potential geospatially aware urban Retrieval Augmented Generation (RAG) applications. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 15:32:36 GMT'}]",2023-10-04,"[['Unlu', 'Eren', '']]",0,0,2023-09-28,1,1,2,0,0,0,ec0ca7eb1f365a8ee74247b9724e190651483706,263608305.0,https://www.semanticscholar.org/paper/ec0ca7eb1f365a8ee74247b9724e190651483706,arXiv.org,2023.0,17.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Geography', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '34669076', 'name': 'Eren Unlu'}]","['Datategy SAS Paris, France']",['France'],2023-09,['industrial']
2310.01434,Tom\'as Marques,"Samuel Carreira, Tom\'as Marques, Jos\'e Ribeiro, Carlos Grilo",Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The field of Artificial Intelligence has witnessed remarkable progress in recent years, especially with the emergence of powerful large language models (LLMs) based on the transformer architecture. Cloud-based LLMs, such as OpenAI's ChatGPT, offer impressive capabilities but come with concerns regarding latency and privacy due to network dependencies. This article presents an innovative approach to LLM inference, envisioning a future where LLMs with billions of parameters can be executed directly on mobile devices without network connectivity. The article showcases a fine-tuned GPT LLM with 3 billion parameters that can operate smoothly on devices with as low as 4GB of memory. Through the integration of native code and model quantization techniques, the application not only serves as a general-purpose assistant but also facilitates seamless mobile interactions with text-to-actions features. The article provides insights into the training pipeline, implementation details, test results, and future directions of on-device LLM inference. This breakthrough technology opens up possibilities for empowering users with sophisticated AI capabilities while preserving their privacy and eliminating latency concerns. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 16:30:49 GMT'}]",2023-10-04,"[['Carreira', 'Samuel', ''], ['Marques', 'Tomás', ''], ['Ribeiro', 'José', ''], ['Grilo', 'Carlos', '']]",1,1,2023-09-29,1,4,3,1,0,1,e22048955c6648201f0d708e8b0688d3b1be741d,263609154.0,https://www.semanticscholar.org/paper/e22048955c6648201f0d708e8b0688d3b1be741d,arXiv.org,2023.0,13.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2253468900', 'name': 'Samuel Carreira'}, {'authorId': '2253587452', 'name': ""Tom'as Marques""}, {'authorId': '2195198570', 'name': 'J. Ribeiro'}, {'authorId': '2253468800', 'name': 'Carlos Grilo'}]",['Instituto Politécnico de Leiria'],['Portugal'],2023-09,['industrial']
