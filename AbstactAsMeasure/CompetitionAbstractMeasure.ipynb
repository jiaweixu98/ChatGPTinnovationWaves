{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to measure competition?\n",
    "\n",
    "        pure open: \n",
    "\n",
    "        pure closed: \n",
    "\n",
    "        open plus closed: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:21<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# preparation ...\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "# we can not find 'PanGU-Σ', 'Luminous' in close Source index, cannot find 'Galatica', 'YaLM', 'PanGu-α' in open source list , so delete them.\n",
    "openSourceList = ['T5', 'mT5', 'CPM-2','T0','GPT-NeoX-20B','CodeGen','Tk-Instruct','UL2','OPT','NLLB','BLOOM','GLM','Flan-T5','mT0','BLOOMZ','OPT-IML','Pythia','LLaMA','Llama','Vicuna','ChatGLM','CodeGeeX','Koala','GPT-2','GPT2','GPT 2']\n",
    "closeSourceList = ['GShard','GPT-3','GPT 3', 'GPT3','LaMDA','HyperCLOVA','Codex','ERNIE 3','Jurassic-1','FLAN','MT-NLG','Yuan 1.0','Anthropic','WebGPT','Gopher','ERNIE 3.0 Titan','GLaM','InstructGPT','ChatGPT','AlphaCode','Chinchilla','PaLM','Cohere','AlexaTM','Sparrow','WeLM','U-PaLM','Flan-PaLM','Flan-U-PaLM','Alpaca','GPT-4' ,'GPT 4', 'GPT4','Claude']\n",
    "\n",
    "readfile = \"/data/jx4237data/DataForChatGPTinnovationWaves/\"\n",
    "df = pd.read_csv(readfile + 'LLM09enhanced.csv',dtype=object)\n",
    "# some paper we need to delete:\n",
    "# “fake” palm paper 1909.02134\n",
    "# fake openai 1506.04006\n",
    "delete_list = ['1506.04006','1909.02134']\n",
    "df = df[~df['id'].isin(delete_list)]\n",
    "# model2paper\n",
    "model2paper = {}\n",
    "for model in tqdm(openSourceList+closeSourceList):\n",
    "    if model in model2paper:\n",
    "        print('error')\n",
    "    model2paper[model] = set()\n",
    "    for paper in df[df['abstract'].str.contains(\"\\\\b%s\\\\b\"%model) | df['abstract'].str.lower().str.contains(\"\\\\b%s\\\\b\"%model.lower())  | df['title'].str.contains(\"\\\\b%s\\\\b\"%model) | df['title'].str.lower().str.contains(\"\\\\b%s\\\\b\"%model.lower())]['id']  :\n",
    "        model2paper[model].add(paper)\n",
    "\n",
    "for i in model2paper['GPT 4']:\n",
    "    model2paper['GPT-4'].add(i)\n",
    "for i in model2paper['GPT4']:\n",
    "    model2paper['GPT-4'].add(i)\n",
    "for i in model2paper['GPT 3']:\n",
    "    model2paper['GPT-3'].add(i)\n",
    "for i in model2paper['GPT3']:\n",
    "    model2paper['GPT-3'].add(i)\n",
    "for i in model2paper['GPT2']:\n",
    "    model2paper['GPT-2'].add(i)\n",
    "for i in model2paper['GPT 2']:\n",
    "    model2paper['GPT-2'].add(i)\n",
    "for i in model2paper['Llama']:\n",
    "    model2paper['LLaMA'].add(i)\n",
    "del model2paper['GPT 4']\n",
    "del model2paper['GPT4']\n",
    "del model2paper['GPT3']\n",
    "del model2paper['GPT 3']\n",
    "del model2paper['GPT2']\n",
    "del model2paper['GPT 2']\n",
    "del model2paper['Llama']\n",
    "\n",
    "# paper2model\n",
    "paper2model = {}\n",
    "for model, paperSet in model2paper.items():\n",
    "    for paper in paperSet:\n",
    "        if paper not in paper2model:\n",
    "            paper2model[paper] =[model]\n",
    "        else:\n",
    "            paper2model[paper].append(model)\n",
    "\n",
    "openPaperSet = set()\n",
    "closePaperSet = set()\n",
    "for k,v in model2paper.items():\n",
    "    if k in closeSourceList:\n",
    "        for paper in v:\n",
    "            closePaperSet.add(paper)\n",
    "    if k in openSourceList:\n",
    "        for paper in v:\n",
    "            openPaperSet.add(paper)\n",
    "pureOpen = openPaperSet - closePaperSet\n",
    "pureClose = closePaperSet - openPaperSet\n",
    "mixed = openPaperSet & closePaperSet\n",
    "all = openPaperSet | closePaperSet\n",
    "\n",
    "paper2pubdate = {}\n",
    "for i in range(len(df)):\n",
    "    paper2pubdate[list(df['id'])[i]] = list(df['update_date'])[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════════════╤════════╕\n",
      "│ item                  │   freq │\n",
      "╞═══════════════════════╪════════╡\n",
      "│ total papers          │   6676 │\n",
      "├───────────────────────┼────────┤\n",
      "│ papers containing LLM │   3228 │\n",
      "├───────────────────────┼────────┤\n",
      "│ only open models      │    881 │\n",
      "├───────────────────────┼────────┤\n",
      "│ only closed models    │   2264 │\n",
      "├───────────────────────┼────────┤\n",
      "│ mixed                 │    409 │\n",
      "╘═══════════════════════╧════════╛\n"
     ]
    }
   ],
   "source": [
    "# number of papers\n",
    "from tabulate import tabulate\n",
    "temp = [{'item':'total papers','freq':len(df)},{'item':'papers containing LLM','freq':3228},{'item':'only open models','freq':len(pureOpen)},{'item':'only closed models','freq':len(pureClose)},{'item':'mixed','freq':len(mixed)},]\n",
    "print(tabulate(temp, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "propotion of each mentioned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models:\n",
      "╒════════╤═════════════════╤═════════════╤════════╤═════════════════╤══════════╤══════════╤══════════╤═════════════╤═══════════════════════╤═════════════╕\n",
      "│   Rank │ Model           │   Mentioned │ Type   │ % of open-ack   │   single │   double │   triple │   quadruple │   % of single mention │   % of 3228 │\n",
      "╞════════╪═════════════════╪═════════════╪════════╪═════════════════╪══════════╪══════════╪══════════╪═════════════╪═══════════════════════╪═════════════╡\n",
      "│      1 │ ChatGPT         │        1264 │ closed │ 0.262           │      854 │      271 │       98 │          24 │                 0.676 │       0.392 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      2 │ GPT-3           │        1027 │ closed │ 0.336           │      542 │      322 │      107 │          35 │                 0.528 │       0.318 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      3 │ GPT-4           │         636 │ closed │ 0.237           │      245 │      249 │       89 │          31 │                 0.385 │       0.197 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      4 │ GPT-2           │         552 │ open   │ 0.458           │      461 │       67 │       15 │           6 │                 0.835 │       0.171 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      5 │ T5              │         307 │ open   │ 0.39            │      150 │       80 │       34 │          19 │                 0.489 │       0.095 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      6 │ LLaMA           │         246 │ open   │ 0.31            │       79 │       76 │       45 │          28 │                 0.321 │       0.076 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      7 │ Codex           │         127 │ closed │ 0.291           │       55 │       51 │       14 │           5 │                 0.433 │       0.039 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      8 │ OPT             │          93 │ open   │ 0.583           │       32 │       26 │       12 │          12 │                 0.344 │       0.029 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      9 │ PaLM            │          87 │ closed │ 0.286           │       27 │       26 │       17 │           7 │                 0.31  │       0.027 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     10 │ FLAN            │          78 │ closed │ 0.645           │        0 │        5 │       27 │          21 │                 0     │       0.024 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     11 │ BLOOM           │          74 │ open   │ 0.564           │       26 │       19 │       10 │           9 │                 0.351 │       0.023 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     12 │ Flan-T5         │          57 │ open   │ 0.446           │        0 │        0 │       19 │          17 │                 0     │       0.018 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     13 │ Alpaca          │          55 │ closed │ 0.538           │        9 │       15 │       14 │           6 │                 0.164 │       0.017 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     14 │ InstructGPT     │          54 │ closed │ 0.293           │       11 │       21 │       12 │           5 │                 0.204 │       0.017 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     15 │ Vicuna          │          51 │ open   │ 0.365           │        6 │       10 │       16 │          10 │                 0.118 │       0.016 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     16 │ Claude          │          37 │ closed │ 0.234           │        2 │       14 │        7 │          10 │                 0.054 │       0.011 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     17 │ CodeGen         │          27 │ open   │ 0.115           │       11 │        9 │        5 │           1 │                 0.407 │       0.008 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     18 │ mT5             │          24 │ open   │ 0.75            │       13 │        7 │        3 │           1 │                 0.542 │       0.007 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     19 │ T0              │          20 │ open   │ 0.5             │        9 │        6 │        0 │           3 │                 0.45  │       0.006 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     20 │ BLOOMZ          │          19 │ open   │ 0.422           │        2 │        6 │        1 │           4 │                 0.105 │       0.006 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     21 │ Pythia          │          15 │ open   │ 0.684           │        7 │        3 │        1 │           2 │                 0.467 │       0.005 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     22 │ GLM             │          13 │ open   │ 0.632           │        3 │        6 │        0 │           3 │                 0.231 │       0.004 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     23 │ Anthropic       │          11 │ closed │ 0.048           │        3 │        2 │        2 │           3 │                 0.273 │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     24 │ LaMDA           │          10 │ closed │ 0.2             │        4 │        4 │        1 │           0 │                 0.4   │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     25 │ ChatGLM         │           9 │ open   │ 0.353           │        1 │        3 │        3 │           1 │                 0.111 │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     26 │ AlphaCode       │           9 │ closed │ 0.125           │        3 │        4 │        2 │           0 │                 0.333 │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     27 │ Chinchilla      │           9 │ closed │ 0.273           │        5 │        1 │        0 │           2 │                 0.556 │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     28 │ UL2             │           8 │ open   │ 0.24            │        1 │        0 │        2 │           3 │                 0.125 │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     29 │ NLLB            │           8 │ open   │ 0.571           │        4 │        2 │        1 │           1 │                 0.5   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     30 │ Flan-PaLM       │           7 │ closed │ 0.192           │        0 │        0 │        3 │           0 │                 0     │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     31 │ Tk-Instruct     │           6 │ open   │ 0.5             │        1 │        4 │        0 │           0 │                 0.167 │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     32 │ GShard          │           6 │ closed │ 0.8             │        3 │        1 │        2 │           0 │                 0.5   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     33 │ GLaM            │           6 │ closed │ 0.5             │        4 │        1 │        0 │           1 │                 0.667 │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     34 │ Koala           │           5 │ open   │ 0.538           │        0 │        1 │        1 │           2 │                 0     │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     35 │ HyperCLOVA      │           5 │ closed │ 0.0             │        1 │        4 │        0 │           0 │                 0.2   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     36 │ WebGPT          │           5 │ closed │ 0.333           │        2 │        3 │        0 │           0 │                 0.4   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     37 │ Gopher          │           5 │ closed │ 0.0             │        1 │        3 │        0 │           1 │                 0.2   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     38 │ Jurassic-1      │           4 │ closed │ 0.0             │        1 │        2 │        0 │           1 │                 0.25  │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     39 │ Cohere          │           4 │ closed │ 0.231           │        0 │        2 │        0 │           0 │                 0     │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     40 │ U-PaLM          │           4 │ closed │ 0.286           │        0 │        0 │        1 │           1 │                 0     │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     41 │ GPT-NeoX-20B    │           3 │ open   │ 0.333           │        0 │        1 │        1 │           1 │                 0     │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     42 │ mT0             │           3 │ open   │ 0.833           │        1 │        0 │        0 │           2 │                 0.333 │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     43 │ ERNIE 3         │           3 │ closed │ 0.25            │        1 │        0 │        2 │           0 │                 0.333 │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     44 │ MT-NLG          │           3 │ closed │ 1.0             │        2 │        0 │        0 │           0 │                 0.667 │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     45 │ AlexaTM         │           3 │ closed │ 0.0             │        2 │        0 │        1 │           0 │                 0.667 │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     46 │ Sparrow         │           2 │ closed │ 0.0             │        1 │        0 │        0 │           1 │                 0.5   │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     47 │ Flan-U-PaLM     │           2 │ closed │ 0.143           │        0 │        0 │        0 │           1 │                 0     │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     48 │ CPM-2           │           1 │ open   │ 1.0             │        0 │        1 │        0 │           0 │                 0     │       0     │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     49 │ OPT-IML         │           1 │ open   │ 0.5             │        0 │        0 │        1 │           0 │                 0     │       0     │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     50 │ CodeGeeX        │           1 │ open   │ 0.0             │        0 │        1 │        0 │           0 │                 0     │       0     │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     51 │ Yuan 1.0        │           1 │ closed │ 0.0             │        0 │        1 │        0 │           0 │                 0     │       0     │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     52 │ ERNIE 3.0 Titan │           1 │ closed │ 0.0             │        0 │        0 │        1 │           0 │                 0     │       0     │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     53 │ WeLM            │           1 │ closed │ NA              │        1 │        0 │        0 │           0 │                 1     │       0     │\n",
      "╘════════╧═════════════════╧═════════════╧════════╧═════════════════╧══════════╧══════════╧══════════╧═════════════╧═══════════════════════╧═════════════╛\n",
      "Open models:\n",
      "╒════════╤══════════════╤═════════════╤════════╤═════════════════╤══════════╤══════════╤══════════╤═════════════╤═══════════════════════╤═════════════╕\n",
      "│   Rank │ Model        │   Mentioned │ Type   │   % of open-ack │   single │   double │   triple │   quadruple │   % of single mention │   % of 3228 │\n",
      "╞════════╪══════════════╪═════════════╪════════╪═════════════════╪══════════╪══════════╪══════════╪═════════════╪═══════════════════════╪═════════════╡\n",
      "│      1 │ GPT-2        │         552 │ open   │           0.458 │      461 │       67 │       15 │           6 │                 0.835 │       0.171 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      2 │ T5           │         307 │ open   │           0.39  │      150 │       80 │       34 │          19 │                 0.489 │       0.095 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      3 │ LLaMA        │         246 │ open   │           0.31  │       79 │       76 │       45 │          28 │                 0.321 │       0.076 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      4 │ OPT          │          93 │ open   │           0.583 │       32 │       26 │       12 │          12 │                 0.344 │       0.029 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      5 │ BLOOM        │          74 │ open   │           0.564 │       26 │       19 │       10 │           9 │                 0.351 │       0.023 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      6 │ Flan-T5      │          57 │ open   │           0.446 │        0 │        0 │       19 │          17 │                 0     │       0.018 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      7 │ Vicuna       │          51 │ open   │           0.365 │        6 │       10 │       16 │          10 │                 0.118 │       0.016 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      8 │ CodeGen      │          27 │ open   │           0.115 │       11 │        9 │        5 │           1 │                 0.407 │       0.008 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      9 │ mT5          │          24 │ open   │           0.75  │       13 │        7 │        3 │           1 │                 0.542 │       0.007 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     10 │ T0           │          20 │ open   │           0.5   │        9 │        6 │        0 │           3 │                 0.45  │       0.006 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     11 │ BLOOMZ       │          19 │ open   │           0.422 │        2 │        6 │        1 │           4 │                 0.105 │       0.006 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     12 │ Pythia       │          15 │ open   │           0.684 │        7 │        3 │        1 │           2 │                 0.467 │       0.005 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     13 │ GLM          │          13 │ open   │           0.632 │        3 │        6 │        0 │           3 │                 0.231 │       0.004 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     14 │ ChatGLM      │           9 │ open   │           0.353 │        1 │        3 │        3 │           1 │                 0.111 │       0.003 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     15 │ UL2          │           8 │ open   │           0.24  │        1 │        0 │        2 │           3 │                 0.125 │       0.002 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     16 │ NLLB         │           8 │ open   │           0.571 │        4 │        2 │        1 │           1 │                 0.5   │       0.002 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     17 │ Tk-Instruct  │           6 │ open   │           0.5   │        1 │        4 │        0 │           0 │                 0.167 │       0.002 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     18 │ Koala        │           5 │ open   │           0.538 │        0 │        1 │        1 │           2 │                 0     │       0.002 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     19 │ GPT-NeoX-20B │           3 │ open   │           0.333 │        0 │        1 │        1 │           1 │                 0     │       0.001 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     20 │ mT0          │           3 │ open   │           0.833 │        1 │        0 │        0 │           2 │                 0.333 │       0.001 │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     21 │ CPM-2        │           1 │ open   │           1     │        0 │        1 │        0 │           0 │                 0     │       0     │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     22 │ OPT-IML      │           1 │ open   │           0.5   │        0 │        0 │        1 │           0 │                 0     │       0     │\n",
      "├────────┼──────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     23 │ CodeGeeX     │           1 │ open   │           0     │        0 │        1 │        0 │           0 │                 0     │       0     │\n",
      "╘════════╧══════════════╧═════════════╧════════╧═════════════════╧══════════╧══════════╧══════════╧═════════════╧═══════════════════════╧═════════════╛\n",
      "Closed models:\n",
      "╒════════╤═════════════════╤═════════════╤════════╤═════════════════╤══════════╤══════════╤══════════╤═════════════╤═══════════════════════╤═════════════╕\n",
      "│   Rank │ Model           │   Mentioned │ Type   │ % of open-ack   │   single │   double │   triple │   quadruple │   % of single mention │   % of 3228 │\n",
      "╞════════╪═════════════════╪═════════════╪════════╪═════════════════╪══════════╪══════════╪══════════╪═════════════╪═══════════════════════╪═════════════╡\n",
      "│      1 │ ChatGPT         │        1264 │ closed │ 0.262           │      854 │      271 │       98 │          24 │                 0.676 │       0.392 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      2 │ GPT-3           │        1027 │ closed │ 0.336           │      542 │      322 │      107 │          35 │                 0.528 │       0.318 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      3 │ GPT-4           │         636 │ closed │ 0.237           │      245 │      249 │       89 │          31 │                 0.385 │       0.197 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      4 │ Codex           │         127 │ closed │ 0.291           │       55 │       51 │       14 │           5 │                 0.433 │       0.039 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      5 │ PaLM            │          87 │ closed │ 0.286           │       27 │       26 │       17 │           7 │                 0.31  │       0.027 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      6 │ FLAN            │          78 │ closed │ 0.645           │        0 │        5 │       27 │          21 │                 0     │       0.024 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      7 │ Alpaca          │          55 │ closed │ 0.538           │        9 │       15 │       14 │           6 │                 0.164 │       0.017 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      8 │ InstructGPT     │          54 │ closed │ 0.293           │       11 │       21 │       12 │           5 │                 0.204 │       0.017 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│      9 │ Claude          │          37 │ closed │ 0.234           │        2 │       14 │        7 │          10 │                 0.054 │       0.011 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     10 │ Anthropic       │          11 │ closed │ 0.048           │        3 │        2 │        2 │           3 │                 0.273 │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     11 │ LaMDA           │          10 │ closed │ 0.2             │        4 │        4 │        1 │           0 │                 0.4   │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     12 │ AlphaCode       │           9 │ closed │ 0.125           │        3 │        4 │        2 │           0 │                 0.333 │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     13 │ Chinchilla      │           9 │ closed │ 0.273           │        5 │        1 │        0 │           2 │                 0.556 │       0.003 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     14 │ Flan-PaLM       │           7 │ closed │ 0.192           │        0 │        0 │        3 │           0 │                 0     │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     15 │ GShard          │           6 │ closed │ 0.8             │        3 │        1 │        2 │           0 │                 0.5   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     16 │ GLaM            │           6 │ closed │ 0.5             │        4 │        1 │        0 │           1 │                 0.667 │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     17 │ HyperCLOVA      │           5 │ closed │ 0.0             │        1 │        4 │        0 │           0 │                 0.2   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     18 │ WebGPT          │           5 │ closed │ 0.333           │        2 │        3 │        0 │           0 │                 0.4   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     19 │ Gopher          │           5 │ closed │ 0.0             │        1 │        3 │        0 │           1 │                 0.2   │       0.002 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     20 │ Jurassic-1      │           4 │ closed │ 0.0             │        1 │        2 │        0 │           1 │                 0.25  │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     21 │ Cohere          │           4 │ closed │ 0.231           │        0 │        2 │        0 │           0 │                 0     │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     22 │ U-PaLM          │           4 │ closed │ 0.286           │        0 │        0 │        1 │           1 │                 0     │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     23 │ ERNIE 3         │           3 │ closed │ 0.25            │        1 │        0 │        2 │           0 │                 0.333 │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     24 │ MT-NLG          │           3 │ closed │ 1.0             │        2 │        0 │        0 │           0 │                 0.667 │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     25 │ AlexaTM         │           3 │ closed │ 0.0             │        2 │        0 │        1 │           0 │                 0.667 │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     26 │ Sparrow         │           2 │ closed │ 0.0             │        1 │        0 │        0 │           1 │                 0.5   │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     27 │ Flan-U-PaLM     │           2 │ closed │ 0.143           │        0 │        0 │        0 │           1 │                 0     │       0.001 │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     28 │ Yuan 1.0        │           1 │ closed │ 0.0             │        0 │        1 │        0 │           0 │                 0     │       0     │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     29 │ ERNIE 3.0 Titan │           1 │ closed │ 0.0             │        0 │        0 │        1 │           0 │                 0     │       0     │\n",
      "├────────┼─────────────────┼─────────────┼────────┼─────────────────┼──────────┼──────────┼──────────┼─────────────┼───────────────────────┼─────────────┤\n",
      "│     30 │ WeLM            │           1 │ closed │ NA              │        1 │        0 │        0 │           0 │                 1     │       0     │\n",
      "╘════════╧═════════════════╧═════════════╧════════╧═════════════════╧══════════╧══════════╧══════════╧═════════════╧═══════════════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name_list = list(model2paper.keys())\n",
    "\n",
    "# 总共共现出现的次数\n",
    "ackTotalCounter = Counter()\n",
    "for k,v in paper2model.items():\n",
    "    if len(v) > 1:\n",
    "        for model in v:\n",
    "            ackTotalCounter[model] += (len(v)-1)\n",
    "\n",
    "# open出现的数量\n",
    "ackOpenCounter = Counter()\n",
    "for k,v in paper2model.items():\n",
    "    if len(v) > 1:\n",
    "        for model in v:\n",
    "            for other_model in v:\n",
    "                if other_model == model:\n",
    "                    continue\n",
    "                elif other_model in openSourceList:\n",
    "                    ackOpenCounter[model] += 1\n",
    "\n",
    "singleNameCounter = Counter()\n",
    "for k,v in paper2model.items():\n",
    "    if len(v) == 1:\n",
    "        for model in v:\n",
    "            singleNameCounter[model] += 1\n",
    "\n",
    "doubleNameCounter = Counter()\n",
    "for k,v in paper2model.items():\n",
    "    if len(v) == 2:\n",
    "        for model in v:\n",
    "            doubleNameCounter[model] += 1\n",
    "\n",
    "tripleNameCounter = Counter()\n",
    "for k,v in paper2model.items():\n",
    "    if len(v) == 3:\n",
    "        for model in v:\n",
    "            tripleNameCounter[model] += 1\n",
    "\n",
    "quadrupleNameCounter = Counter()\n",
    "for k,v in paper2model.items():\n",
    "    if len(v) == 4:\n",
    "        for model in v:\n",
    "            quadrupleNameCounter[model] += 1\n",
    "\n",
    "print('All models:')\n",
    "rank = 1\n",
    "modelMentionTimes4tableList = []\n",
    "for k,v in sorted(model2paper.items(), key= lambda x:-len(x[1])):\n",
    "    modelMentionTimes4tableList.append({'Rank':rank,'Model':k,'Mentioned':len(v), 'Type':'open' if k in openSourceList else 'closed','% of open-ack':round(ackOpenCounter[k]/ackTotalCounter[k],3) if ackTotalCounter[k]!=0 else 'NA' ,'single':singleNameCounter[k],'double':doubleNameCounter[k],'triple':tripleNameCounter[k], 'quadruple':quadrupleNameCounter[k],'% of single mention':round(singleNameCounter[k]/len(v), 3),'% of 3228':round(len(v)/3228, 3)})\n",
    "    rank += 1\n",
    "print(tabulate(modelMentionTimes4tableList, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "print('Open models:')\n",
    "rank = 1\n",
    "modelMentionTimes4tableList = []\n",
    "for k,v in sorted(model2paper.items(), key= lambda x:-len(x[1])):\n",
    "    if k in closeSourceList:\n",
    "        continue\n",
    "    modelMentionTimes4tableList.append({'Rank':rank,'Model':k,'Mentioned':len(v), 'Type':'open' if k in openSourceList else 'closed','% of open-ack':round(ackOpenCounter[k]/ackTotalCounter[k],3) if ackTotalCounter[k]!=0 else 'NA' ,'single':singleNameCounter[k],'double':doubleNameCounter[k],'triple':tripleNameCounter[k], 'quadruple':quadrupleNameCounter[k],'% of single mention':round(singleNameCounter[k]/len(v), 3),'% of 3228':round(len(v)/3228, 3)})\n",
    "    rank += 1\n",
    "print(tabulate(modelMentionTimes4tableList, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "print('Closed models:')\n",
    "rank = 1\n",
    "modelMentionTimes4tableList = []\n",
    "for k,v in sorted(model2paper.items(), key= lambda x:-len(x[1])):\n",
    "    if k in openSourceList:\n",
    "        continue\n",
    "    modelMentionTimes4tableList.append({'Rank':rank,'Model':k,'Mentioned':len(v), 'Type':'open' if k in openSourceList else 'closed','% of open-ack':round(ackOpenCounter[k]/ackTotalCounter[k],3) if ackTotalCounter[k]!=0 else 'NA' ,'single':singleNameCounter[k],'double':doubleNameCounter[k],'triple':tripleNameCounter[k], 'quadruple':quadrupleNameCounter[k],'% of single mention':round(singleNameCounter[k]/len(v), 3),'% of 3228':round(len(v)/3228, 3)})\n",
    "    rank += 1\n",
    "print(tabulate(modelMentionTimes4tableList, headers=\"keys\", tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distribution of # models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════════════════╤════════╕\n",
      "│   Number of models a paper has │   freq │\n",
      "╞════════════════════════════════╪════════╡\n",
      "│                              1 │   2586 │\n",
      "├────────────────────────────────┼────────┤\n",
      "│                              2 │    665 │\n",
      "├────────────────────────────────┼────────┤\n",
      "│                              3 │    190 │\n",
      "├────────────────────────────────┼────────┤\n",
      "│                              4 │     70 │\n",
      "├────────────────────────────────┼────────┤\n",
      "│                              5 │     24 │\n",
      "├────────────────────────────────┼────────┤\n",
      "│                              6 │     13 │\n",
      "├────────────────────────────────┼────────┤\n",
      "│                              7 │      4 │\n",
      "├────────────────────────────────┼────────┤\n",
      "│                              8 │      1 │\n",
      "├────────────────────────────────┼────────┤\n",
      "│                              9 │      1 │\n",
      "╘════════════════════════════════╧════════╛\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3554"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "modelDistribution = Counter()\n",
    "for k,v in paper2model.items():\n",
    "    modelDistribution[len(v)] += 1\n",
    "modelDistributionlist = []\n",
    "for k,v in sorted(modelDistribution.items()):\n",
    "    modelDistributionlist.append({'Number of models a paper has':k,'freq':v})\n",
    "\n",
    "print(tabulate(modelDistributionlist, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "sum(modelDistribution.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╒═══════════════════════════╤════════╕\n",
      "│ Model Combination         │   freq │\n",
      "╞═══════════════════════════╪════════╡\n",
      "│ ChatGPT - GPT-4           │    212 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - GPT-4             │    176 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - GPT-3           │    155 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - T5                │     69 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - T5                 │     61 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - LLaMA             │     59 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - LLaMA           │     58 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - Flan-T5            │     57 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - T5              │     57 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - LLaMA             │     48 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - GPT-3             │     46 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - GPT-3             │     39 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - PaLM              │     30 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - LLaMA            │     26 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - T5                │     25 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - GPT-3              │     25 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - Vicuna            │     25 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - Vicuna          │     22 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - T5              │     20 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - Vicuna            │     20 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - OPT               │     20 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - GPT-4            │     20 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - OPT               │     19 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - InstructGPT       │     19 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - OPT               │     19 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - PaLM              │     19 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - GPT-3           │     17 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - GPT-3             │     17 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - ChatGPT          │     16 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - GPT-4            │     16 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - Codex           │     16 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - InstructGPT     │     15 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - Claude          │     15 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - GPT-4              │     14 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - T5                │     14 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - LLaMA             │     14 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - PaLM              │     13 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - FLAN            │     12 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ CodeGen - Codex           │     12 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - ChatGPT           │     11 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - T5                │     11 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - LLaMA            │     11 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - GPT-4           │     10 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - Flan-T5         │     10 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - LLaMA             │     10 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - OPT               │     10 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - GPT-4             │     10 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - PaLM               │      9 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - ChatGPT          │      9 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - Vicuna            │      9 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - GPT-3            │      9 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - OPT                │      8 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ OPT - T5                  │      8 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - LLaMA              │      8 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - GPT-2           │      8 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - OPT             │      8 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Anthropic - Claude        │      8 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ PaLM - T5                 │      7 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - InstructGPT        │      7 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - OPT             │      7 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - Vicuna           │      7 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - LLaMA           │      7 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - Flan-PaLM          │      7 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - PaLM          │      7 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - GPT-3            │      7 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - FLAN              │      6 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - T5                │      6 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - GPT-4             │      6 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - T0                │      6 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - OPT              │      6 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - GPT-4            │      6 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGLM - ChatGPT         │      6 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - Flan-T5           │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ InstructGPT - T5          │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T5 - mT5                  │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - FLAN             │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - Flan-T5          │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - T5               │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - UL2                │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - GPT-2             │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ CodeGen - GPT-3           │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ AlphaCode - Codex         │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - InstructGPT       │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - PaLM              │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - InstructGPT      │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - PaLM            │      5 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ PaLM - U-PaLM             │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ InstructGPT - OPT         │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T5 - Vicuna               │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - OPT               │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - T5                │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - BLOOMZ            │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - InstructGPT       │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - OPT               │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLM - OPT                 │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLM - LLaMA               │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - LLaMA            │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - BLOOMZ           │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGLM - GPT-4           │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - LaMDA           │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - Pythia            │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - Vicuna           │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Koala - Vicuna            │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - HyperCLOVA        │      4 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - U-PaLM             │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - InstructGPT     │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Cohere - GPT-3            │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GShard - T5               │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - T0                 │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - Vicuna             │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - Vicuna          │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T0 - T5                   │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - GPT-3         │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ PaLM - UL2                │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ OPT - T0                  │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ OPT - PaLM                │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - Pythia            │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - PaLM              │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Chinchilla - GPT-3        │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - GLM               │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGLM - LLaMA           │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Anthropic - GPT-3         │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Anthropic - GPT-4         │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - PaLM             │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ InstructGPT - LLaMA       │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - Gopher            │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - Jurassic-1        │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Anthropic - ChatGPT       │      3 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - Flan-U-PaLM        │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-U-PaLM - PaLM        │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-U-PaLM - U-PaLM      │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T5 - U-PaLM               │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Cohere - GPT-4            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ERNIE 3 - GPT-3           │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - Tk-Instruct     │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T5 - Tk-Instruct          │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T5 - UL2                  │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - T5            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - FLAN             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - Flan-T5          │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - T5               │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - BLOOM            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - GPT-2              │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - GPT-2           │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - UL2               │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - mT5               │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - Codex             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - mT5               │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - mT5             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - mT0              │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - T0                │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - GPT-NeoX-20B      │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - CodeGen         │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - CodeGen           │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ CodeGen - GPT-4           │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - UL2               │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ InstructGPT - UL2         │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - Vicuna            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ OPT - Vicuna              │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ OPT - Pythia              │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - Pythia            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Chinchilla - PaLM         │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLM - GPT-3               │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - NLLB              │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - Pythia            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - GPT-3            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGLM - Vicuna          │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - LaMDA             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - LaMDA             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - Pythia          │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Pythia - Vicuna           │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - PaLM              │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - LLaMA             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - Claude           │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - Koala            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - Koala             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Koala - LLaMA             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ InstructGPT - Vicuna      │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ InstructGPT - PaLM        │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - WebGPT            │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Chinchilla - Gopher       │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - GPT-4             │      2 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-U-PaLM - T5          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - InstructGPT       │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Cohere - FLAN             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Cohere - Flan-T5          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Cohere - T5               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - GShard            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - T0               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - T0              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T0 - Vicuna               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - Vicuna            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ERNIE 3 - T5              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LaMDA - T5                │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - Tk-Instruct      │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - UL2              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - UL2             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - Tk-Instruct        │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - Tk-Instruct     │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - UL2             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Tk-Instruct - UL2         │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - Flan-T5       │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - U-PaLM        │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - PaLM            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - U-PaLM          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - GLaM               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-T5 - GLaM            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLaM - T5                 │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - T0                │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - GPT-2            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - T0            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - UL2           │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ PaLM - T0                 │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T0 - UL2                  │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - GShard            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLM - T5                  │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - mT5               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - mT5               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ CPM-2 - mT5               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - mT0               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - mT5              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ mT0 - mT5                 │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - T0                │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ T0 - Tk-Instruct          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - GPT-NeoX-20B      │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-NeoX-20B - LLaMA      │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - GPT-2             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - GPT-NeoX-20B      │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-2 - GPT-NeoX-20B      │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ CodeGen - InstructGPT     │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ AlphaCode - CodeGen       │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ CodeGen - OPT             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ InstructGPT - Tk-Instruct │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ U-PaLM - UL2              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - UL2               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ OPT - UL2                 │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Koala - OPT               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - OPT-IML            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ OPT - OPT-IML             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - NLLB             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - OPT              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - NLLB            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ NLLB - OPT                │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - GLM              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - Chinchilla        │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Chinchilla - OPT          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - MT-NLG            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLM - MT-NLG              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - MT-NLG            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ MT-NLG - OPT              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-4 - NLLB              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - NLLB              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOM - Claude            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ FLAN - GLM                │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLM - GPT-4               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLM - WebGPT              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - mT0              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ LLaMA - mT0               │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - PaLM             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - PaLM             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - InstructGPT      │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - ChatGLM          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - Vicuna           │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGLM - GPT-3           │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ BLOOMZ - LaMDA            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - Pythia           │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ PaLM - Pythia             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - Anthropic        │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Alpaca - Cohere           │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Anthropic - Cohere        │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Anthropic - LLaMA         │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - Cohere           │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Cohere - LLaMA            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Chinchilla - LLaMA        │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - Koala            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ PaLM - Vicuna             │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ InstructGPT - Koala       │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ CodeGeeX - Codex          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ AlexaTM - GPT-3           │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ AlexaTM - PaLM            │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - FLAN              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Codex - Flan-PaLM         │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - InstructGPT   │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Flan-PaLM - GPT-4         │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GLaM - GPT-3              │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ GPT-3 - Yuan 1.0          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ERNIE 3 - ERNIE 3.0 Titan │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ERNIE 3.0 Titan - GPT-3   │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Chinchilla - Jurassic-1   │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Gopher - Jurassic-1       │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Anthropic - Sparrow       │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - Sparrow         │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ Claude - Sparrow          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ ChatGPT - Cohere          │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ AlphaCode - ChatGPT       │      1 │\n",
      "├───────────────────────────┼────────┤\n",
      "│ AlphaCode - GPT-4         │      1 │\n",
      "╘═══════════════════════════╧════════╛\n"
     ]
    }
   ],
   "source": [
    "# overall\n",
    "def gen_pair(input_list):\n",
    "    output_list = []\n",
    "    for each_pair in list(itertools.combinations(sorted(input_list), 2)):\n",
    "\n",
    "        output_list.append(' - '.join(each_pair))\n",
    "\n",
    "    return output_list\n",
    "\n",
    "double_counter = Counter()\n",
    "\n",
    "for k,v in paper2model.items():\n",
    "    if len(v) > 1:\n",
    "        for combination in gen_pair(v):\n",
    "            double_counter[combination] += 1\n",
    "\n",
    "CombineList = []\n",
    "for k,v in sorted(double_counter.items(), key=lambda x  : -x[1]):\n",
    "    CombineList.append({'Model Combination':k,'freq':v})\n",
    "print('')\n",
    "print(tabulate(CombineList, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t5, flan-t5, and mt5\n",
    "\n",
    "\n",
    "t5 (https://huggingface.co/docs/transformers/v4.32.1/en/model_doc/t5#overview\n",
    "): 2020-6, T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. T5 works well on a variety of tasks out-of-the-box by prepending a different prefix to the input corresponding to each task, e.g., for translation: translate English to German: …, for summarization: summarize: ….\n",
    "\n",
    "T5 comes in different sizes:\n",
    "\n",
    "    t5-small\n",
    "    t5-base\n",
    "    t5-large\n",
    "    t5-3b\n",
    "    t5-11b\n",
    "\n",
    "Based on the original T5 model, Google has released some follow-up works:\n",
    "\n",
    "\n",
    "    mT5: mT5 is a multilingual T5 model. It is pre-trained on the mC4 corpus, which includes 101 languages\n",
    "\n",
    "    UL2: UL2 is a T5 like model pretrained on various denoising objectives\n",
    "\n",
    "    Flan-T5: Flan is a pretraining methods that is based on prompting. The Flan-T5 are T5 models trained on the Flan collection of datasets which include: taskmaster2, djaym7/wiki_dialog, deepmind/code_contests, lambada, gsm8k, aqua_rat, esnli, quasc and qed.\n",
    "\n",
    "    FLan-UL2 : the UL2 model finetuned using the “Flan” prompt tuning and dataset collection.\n",
    "\n",
    "    UMT5: UmT5 is a multilingual T5 model trained on an improved and refreshed mC4 multilingual corpus, 29 trillion characters across 107 language, using a new sampling method, UniMax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╒══════════════════════════╤════════╕\n",
      "│ Open Model Combination   │   freq │\n",
      "╞══════════════════════════╪════════╡\n",
      "│ GPT-2 - T5               │     20 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ LLaMA - OPT              │      9 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ GPT-2 - OPT              │      9 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - OPT              │      6 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ T5 - mT5                 │      5 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - LLaMA            │      5 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ GPT-2 - LLaMA            │      5 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - BLOOMZ           │      4 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ LLaMA - Vicuna           │      4 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ LLaMA - T5               │      3 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ OPT - T0                 │      2 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ OPT - Vicuna             │      2 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ OPT - Pythia             │      2 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - GPT-2            │      2 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ GPT-2 - Pythia           │      2 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - T5               │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ T5 - Tk-Instruct         │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ GPT-2 - mT5              │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ GLM - T5                 │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ CPM-2 - mT5              │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - mT0              │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - mT5              │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOMZ - mT0             │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOMZ - mT5             │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ mT0 - mT5                │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - T0               │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ LLaMA - T0               │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ T0 - Tk-Instruct         │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - CodeGen          │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ GPT-2 - Vicuna           │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ GLM - OPT                │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ Koala - OPT              │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOM - Pythia           │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ LLaMA - NLLB             │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ BLOOMZ - LLaMA           │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ GLM - LLaMA              │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ LLaMA - Pythia           │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ ChatGLM - LLaMA          │      1 │\n",
      "├──────────────────────────┼────────┤\n",
      "│ ChatGLM - Vicuna         │      1 │\n",
      "╘══════════════════════════╧════════╛\n"
     ]
    }
   ],
   "source": [
    "# open  models\n",
    "double_counter = Counter()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "for k,v in paper2model.items():\n",
    "    if k in pureOpen and len(v) > 1:\n",
    "        for combination in gen_pair(v):\n",
    "            double_counter[combination] += 1\n",
    "        # if 'GPT-2' in v and 'OPT' in v:\n",
    "        #     print(df[df['id'] == k][['publish_date_v1','title','abstract']].iloc[0].values)\n",
    "\n",
    "CombineList = []\n",
    "for k,v in sorted(double_counter.items(), key=lambda x  : -x[1]):\n",
    "    CombineList.append({'Open Model Combination':k,'freq':v})\n",
    "print('')\n",
    "print(tabulate(CombineList, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bloom-t5:\n",
    "\n",
    "both are large open source models: OPT-175B and BLOOM-176B\n",
    "\n",
    "With the release of BLOOM-176B and OPT-175B, everyone can download pretrained models of this scale.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bloom (https://huggingface.co/bigscience/bloom)**\n",
    "\n",
    "BigScience Large Open-science Open-access Multilingual Language Model (paper: 9 Nov 2022; model: july, 2021)\n",
    "\n",
    "Current Checkpoint: Training Iteration 95000\n",
    "\n",
    "Total seen tokens: 366B\n",
    "\n",
    "BLOOM is an autoregressive Large Language Model (LLM), trained to continue text from a prompt on vast amounts of text data using industrial-scale computational resources. As such, it is able to output coherent text in 46 languages and 13 programming languages that is hardly distinguishable from text written by humans. BLOOM can also be instructed to perform text tasks it hasn't been explicitly trained for, by casting them as text generation tasks.\n",
    "\n",
    "Funded by:\n",
    "\n",
    "    The French government.\n",
    "\n",
    "    Hugging Face (website)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPT (https://huggingface.co/facebook/opt-2.7b)**\n",
    "\n",
    "OPT : Open Pre-trained Transformer Language Models\n",
    "OPT was first introduced in Open Pre-trained Transformer Language Models and first released in metaseq's repository on May 3rd 2022 by **Meta AI**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╒════════════════════════════╤════════╕\n",
      "│ Closed Model Combination   │   freq │\n",
      "╞════════════════════════════╪════════╡\n",
      "│ ChatGPT - GPT-4            │    177 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - GPT-4              │    136 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - GPT-3            │    132 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - GPT-3              │     32 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - PaLM               │     17 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - InstructGPT        │     14 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Codex            │     13 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - InstructGPT      │     12 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - PaLM               │     10 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Claude           │     10 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - GPT-4             │      9 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - GPT-4             │      7 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - Claude         │      7 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - PaLM                │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - ChatGPT           │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - Flan-PaLM           │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - PaLM           │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - PaLM               │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - GPT-3               │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - HyperCLOVA         │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - PaLM             │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ AlphaCode - Codex          │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - InstructGPT        │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - Gopher             │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - GPT-3             │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - GPT-3             │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - Jurassic-1         │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - LaMDA            │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - ChatGPT        │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - InstructGPT         │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - GPT-3          │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ InstructGPT - PaLM         │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - WebGPT             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - GPT-4               │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - GPT-3          │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Chinchilla - Gopher        │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - GPT-4          │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - GPT-4              │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - FLAN             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - InstructGPT        │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ AlexaTM - GPT-3            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ AlexaTM - PaLM             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - FLAN               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - Flan-PaLM          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - InstructGPT    │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - GPT-4          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Cohere - GPT-3             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GLaM - GPT-3               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - Yuan 1.0           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ERNIE 3 - ERNIE 3.0 Titan  │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ERNIE 3 - GPT-3            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ERNIE 3.0 Titan - GPT-3    │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - LaMDA              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Chinchilla - GPT-3         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Chinchilla - Jurassic-1    │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Gopher - Jurassic-1        │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - LaMDA              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - Flan-U-PaLM         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - U-PaLM              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-U-PaLM - PaLM         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-U-PaLM - U-PaLM       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ PaLM - U-PaLM              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - Sparrow        │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Sparrow          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - Sparrow           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - InstructGPT       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Cohere           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - Claude            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ AlphaCode - ChatGPT        │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ AlphaCode - GPT-4          │      1 │\n",
      "╘════════════════════════════╧════════╛\n"
     ]
    }
   ],
   "source": [
    "# open  models\n",
    "double_counter = Counter()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "for k,v in paper2model.items():\n",
    "    if k in pureClose and len(v) > 1:\n",
    "        for combination in gen_pair(v):\n",
    "            double_counter[combination] += 1\n",
    "        # if 'LLaMA' in v and 'OPT' in v:\n",
    "        #     print(df[df['id'] == k][['publish_date_v1','title','abstract']].iloc[0].values)\n",
    "\n",
    "CombineList = []\n",
    "for k,v in sorted(double_counter.items(), key=lambda x  : -x[1]):\n",
    "    CombineList.append({'Closed Model Combination':k,'freq':v})\n",
    "print('')\n",
    "print(tabulate(CombineList, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╒════════════════════════════╤════════╕\n",
      "│ Closed Model Combination   │   freq │\n",
      "╞════════════════════════════╪════════╡\n",
      "│ GPT-3 - T5                 │     69 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - T5                  │     61 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - LLaMA              │     59 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - LLaMA            │     58 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - Flan-T5             │     57 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - T5               │     57 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - LLaMA              │     48 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - GPT-3              │     46 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - GPT-4              │     40 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - GPT-4            │     35 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - LLaMA             │     26 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - Vicuna             │     25 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - GPT-3            │     23 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Vicuna           │     22 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - GPT-3               │     21 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - T5               │     20 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - OPT                │     19 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - GPT-3            │     17 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - GPT-3              │     17 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LLaMA - Vicuna             │     16 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - T5                 │     14 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - OPT                │     13 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - PaLM               │     13 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LLaMA - PaLM               │     13 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - GPT-4               │     12 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ CodeGen - Codex            │     12 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - ChatGPT            │     11 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LLaMA - OPT                │     11 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - GPT-4             │     11 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - LLaMA             │     11 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - GPT-4            │     10 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - FLAN             │     10 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Flan-T5          │     10 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - ChatGPT           │     10 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - GPT-4              │     10 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - LLaMA              │      9 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - ChatGPT           │      9 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - GPT-4             │      9 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - PaLM               │      9 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - Vicuna             │      9 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - OPT                 │      8 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ OPT - T5                   │      8 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - LLaMA               │      8 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LLaMA - T5                 │      8 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - GPT-2            │      8 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - OPT              │      8 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ PaLM - T5                  │      7 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - OPT              │      7 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - Vicuna            │      7 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - LLaMA            │      7 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - GPT-3              │      7 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - FLAN               │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - GPT-4              │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - T0                 │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - OPT               │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - GPT-4             │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGLM - ChatGPT          │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - GPT-3             │      6 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - Flan-T5            │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - T5                 │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - InstructGPT         │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ InstructGPT - T5           │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - InstructGPT        │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - T5                 │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - FLAN              │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - Flan-T5           │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - T5                │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - UL2                 │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - LLaMA              │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ CodeGen - GPT-3            │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Claude           │      5 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ InstructGPT - OPT          │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ T5 - Vicuna                │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - OPT                │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - T5                 │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - GPT-3             │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - OPT                │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - BLOOMZ            │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - InstructGPT       │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGLM - GPT-4            │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - Vicuna            │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Koala - Vicuna             │      4 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - PaLM                │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ PaLM - U-PaLM              │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - InstructGPT      │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GShard - T5                │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - T0                  │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - Vicuna              │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - Vicuna           │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ T0 - T5                    │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - GPT-2              │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ PaLM - UL2                 │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - InstructGPT      │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Codex            │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - InstructGPT        │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ OPT - PaLM                 │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GLM - LLaMA                │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GLM - OPT                  │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - PaLM               │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - GLM                │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - LLaMA             │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LLaMA - Pythia             │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - PaLM              │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ InstructGPT - LLaMA        │      3 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - U-PaLM              │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ T5 - U-PaLM                │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Cohere - GPT-3             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Cohere - GPT-4             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Tk-Instruct      │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ T5 - UL2                   │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - Flan-PaLM           │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - PaLM           │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - T5             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - FLAN              │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - Flan-T5           │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - T5                │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - BLOOM             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - GPT-2               │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - GPT-2            │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - UL2                │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - Codex              │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - mT5              │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - GPT-NeoX-20B       │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - CodeGen          │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ CodeGen - GPT-4            │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - UL2                │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ InstructGPT - UL2          │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Chinchilla - GPT-3         │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Chinchilla - PaLM          │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GLM - GPT-3                │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - Pythia             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - GPT-3             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - Pythia           │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Pythia - Vicuna            │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - PaLM               │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - LLaMA              │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGLM - LLaMA            │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - Koala             │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - Koala              │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Koala - LLaMA              │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ InstructGPT - Vicuna       │      2 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - Flan-U-PaLM         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-U-PaLM - PaLM         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-U-PaLM - T5           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-U-PaLM - U-PaLM       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - InstructGPT        │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Cohere - FLAN              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Cohere - Flan-T5           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Cohere - T5                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - GShard             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - T0                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - T0               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ T0 - Vicuna                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - Vicuna             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ERNIE 3 - GPT-3            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ERNIE 3 - T5               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LaMDA - T5                 │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - Tk-Instruct       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - UL2               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - UL2              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - Tk-Instruct         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - Tk-Instruct      │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - UL2              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ T5 - Tk-Instruct           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Tk-Instruct - UL2          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - Flan-T5        │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - U-PaLM         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - PaLM             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - U-PaLM           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - GLaM                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-T5 - GLaM             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GLaM - T5                  │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - T0                 │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - GPT-2             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - OPT                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - GPT-3          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - T0             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Flan-PaLM - UL2            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ PaLM - T0                  │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ T0 - UL2                   │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - GShard             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - mT5                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - mT5                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - mT5                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - mT5                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - T0                 │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ OPT - T0                   │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - GPT-NeoX-20B       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-NeoX-20B - LLaMA       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - GPT-2              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - GPT-NeoX-20B       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - GPT-NeoX-20B       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ CodeGen - InstructGPT      │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - InstructGPT        │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ AlphaCode - CodeGen        │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ AlphaCode - Codex          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - CodeGen            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ CodeGen - OPT              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ InstructGPT - Tk-Instruct  │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ U-PaLM - UL2               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - PaLM               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Codex - UL2                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ OPT - UL2                  │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - OPT-IML             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ OPT - OPT-IML              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - NLLB              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - OPT               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - NLLB             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ NLLB - OPT                 │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - GLM               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - Chinchilla         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Chinchilla - OPT           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - MT-NLG             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GLM - MT-NLG               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LLaMA - MT-NLG             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ MT-NLG - OPT               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - NLLB               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - NLLB               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LLaMA - NLLB               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - Claude             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ FLAN - GLM                 │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOM - Pythia             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GLM - GPT-4                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GLM - WebGPT               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - mT0               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - mT0               │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ LLaMA - mT0                │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - PaLM              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - PaLM              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - InstructGPT       │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - ChatGLM           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - Vicuna            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGLM - GPT-3            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGLM - Vicuna           │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ BLOOMZ - LaMDA             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - LaMDA            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-3 - LaMDA              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-4 - LaMDA              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - Pythia            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - Pythia             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ PaLM - Pythia              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - Anthropic         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - Claude            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Alpaca - Cohere            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - Claude         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - Cohere         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - GPT-3          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - GPT-4          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Anthropic - LLaMA          │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - Cohere            │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Cohere - LLaMA             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ ChatGPT - PaLM             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Chinchilla - LLaMA         │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ Claude - Koala             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ PaLM - Vicuna              │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ GPT-2 - Vicuna             │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ InstructGPT - Koala        │      1 │\n",
      "├────────────────────────────┼────────┤\n",
      "│ CodeGeeX - Codex           │      1 │\n",
      "╘════════════════════════════╧════════╛\n"
     ]
    }
   ],
   "source": [
    "# open  models\n",
    "double_counter = Counter()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "for k,v in paper2model.items():\n",
    "    if k in mixed and len(v) > 1:\n",
    "        for combination in gen_pair(v):\n",
    "            double_counter[combination] += 1\n",
    "        # if 'LLaMA' in v and 'OPT' in v:\n",
    "        #     print(df[df['id'] == k][['publish_date_v1','title','abstract']].iloc[0].values)\n",
    "\n",
    "CombineList = []\n",
    "for k,v in sorted(double_counter.items(), key=lambda x  : -x[1]):\n",
    "    CombineList.append({'Closed Model Combination':k,'freq':v})\n",
    "print('')\n",
    "print(tabulate(CombineList, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
