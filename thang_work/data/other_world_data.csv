id_x,submitter,authors_x,title,comments,journal-ref,doi,report-no,categories,license,abstract,versions,update_date,authors_parsed,ContainChatGPT,ContainGPT,publish_date_v1,versionsNumber,authorNumber,categoryNumber,modelNumber,OpenModelNumber,CloseModelNumber,id_y,corpusId,url,venue,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy,s2FieldsOfStudy,authors_y,Institute,Country,month_year
1903.09295,'Stephen' Zhen Gou,"Stephen Zhen Gou, Yuyang Liu",DQN with model-based exploration: efficient learning on environments with sparse rewards,,,,,cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose Deep Q-Networks (DQN) with model-based exploration, an algorithm combining both model-free and model-based approaches that explores better and learns environments with sparse rewards more efficiently. DQN is a general-purpose, model-free algorithm and has been proven to perform well in a variety of tasks including Atari 2600 games since it's first proposed by Minh et el. However, like many other reinforcement learning (RL) algorithms, DQN suffers from poor sample efficiency when rewards are sparse in an environment. As a result, most of the transitions stored in the replay memory have no informative reward signal, and provide limited value to the convergence and training of the Q-Network. However, one insight is that these transitions can be used to learn the dynamics of the environment as a supervised learning problem. The transitions also provide information of the distribution of visited states. Our algorithm utilizes these two observations to perform a one-step planning during exploration to pick an action that leads to states least likely to be seen, thus improving the performance of exploration. We demonstrate our agent's performance in two classic environments with sparse rewards in OpenAI gym: Mountain Car and Lunar Lander. ","[{'version': 'v1', 'created': 'Fri, 22 Mar 2019 01:41:50 GMT'}]",2019-03-25,"[['Gou', 'Stephen Zhen', ''], ['Liu', 'Yuyang', '']]",0,0,2019-03-22,1,2,2,0,0,0,5d05577df903b59cdea9faa541f33298a803a9af,85459608.0,https://www.semanticscholar.org/paper/5d05577df903b59cdea9faa541f33298a803a9af,arXiv.org,2019.0,11.0,7.0,2.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '117387024', 'name': 'Stephen Gou'}, {'authorId': '2116382754', 'name': 'Yuyang Liu'}]",['University of Toronto'],['Canada'],2019-03
1903.11437,Franck Burlot,Franck Burlot and Fran\c{c}ois Yvon,Using Monolingual Data in Neural Machine Translation: a Systematic Study,"Published in the Proceedings of the Third Conference on Machine
  Translation (Research Papers), 2018",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural Machine Translation (MT) has radically changed the way systems are developed. A major difference with the previous generation (Phrase-Based MT) is the way monolingual target data, which often abounds, is used in these two paradigms. While Phrase-Based MT can seamlessly integrate very large language models trained on billions of sentences, the best option for Neural MT developers seems to be the generation of artificial parallel data through \textsl{back-translation} - a technique that fails to fully take advantage of existing datasets. In this paper, we conduct a systematic study of back-translation, comparing alternative uses of monolingual data, as well as multiple data generation procedures. Our findings confirm that back-translation is very effective and give new explanations as to why this is the case. We also introduce new data simulation techniques that are almost as effective, yet much cheaper to implement. ","[{'version': 'v1', 'created': 'Wed, 27 Mar 2019 14:11:18 GMT'}]",2019-03-28,"[['Burlot', 'Franck', ''], ['Yvon', 'François', '']]",0,0,2019-03-27,1,2,1,0,0,0,e6deb7f451931b28bc6936d5fa703bc392c4cf4c,53222583.0,https://www.semanticscholar.org/paper/e6deb7f451931b28bc6936d5fa703bc392c4cf4c,Conference on Machine Translation,2018.0,40.0,85.0,8.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '3456893', 'name': 'Franck Burlot'}, {'authorId': '1846431', 'name': 'François Yvon'}]","['Lingua Custodia 1, Place Charles de Gaulle 78180 Montigny-le-Bretonneux', 'French National Centre for Scientific Research']",['France'],2019-03
1904.05152,Alessandro Seganti,"Alessandro Seganti, Helena Sobol, Iryna Orlova, Hannam Kim, Jakub
  Staniszewski, Tymoteusz Krumholc, Krystian Koziel",NLPR@SRPOL at SemEval-2019 Task 6 and Task 5: Linguistically enhanced deep learning offensive sentence classifier,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The paper presents a system developed for the SemEval-2019 competition Task 5 hat-Eval Basile et al. (2019) (team name: LU Team) and Task 6 OffensEval Zampieri et al. (2019b) (team name: NLPR@SRPOL), where we achieved 2nd position in Subtask C. The system combines in an ensemble several models (LSTM, Transformer, OpenAI's GPT, Random forest, SVM) with various embeddings (custom, ELMo, fastText, Universal Encoder) together with additional linguistic features (number of blacklisted words, special characters, etc.). The system works with a multi-tier blacklist and a large corpus of crawled data, annotated for general offensiveness. In the paper we do an extensive analysis of our results and show how the combination of features and embedding affect the performance of the models. ","[{'version': 'v1', 'created': 'Wed, 10 Apr 2019 12:56:50 GMT'}]",2019-04-11,"[['Seganti', 'Alessandro', ''], ['Sobol', 'Helena', ''], ['Orlova', 'Iryna', ''], ['Kim', 'Hannam', ''], ['Staniszewski', 'Jakub', ''], ['Krumholc', 'Tymoteusz', ''], ['Koziel', 'Krystian', '']]",0,1,2019-04-10,1,7,1,0,0,0,0aacc3d2af7eb6e50dbc83949ee056096379055e,131773893.0,https://www.semanticscholar.org/paper/0aacc3d2af7eb6e50dbc83949ee056096379055e,International Workshop on Semantic Evaluation,2019.0,39.0,18.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46539208', 'name': 'Alessandro Seganti'}, {'authorId': '108527573', 'name': 'Helena Sobol'}, {'authorId': '2065377788', 'name': 'Iryna Orlova'}, {'authorId': '107928214', 'name': 'Hannam Kim'}, {'authorId': '103958013', 'name': 'J. Staniszewski'}, {'authorId': '108284000', 'name': 'Tymoteusz Krumholc'}, {'authorId': '2066149234', 'name': 'Krystian Koziel'}]",['Samsung'],"['South Korea', 'Poland']",2019-04
1906.00131,Arsh Javed Rehman,"Arsh Javed Rehman, Pradeep Tomar",Decision-Making in Reinforcement Learning,"4 pages, 1 figure",,10.13140/RG.2.2.12367.33443,,cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this research work, probabilistic decision-making approaches are studied, e.g. Bayesian and Boltzmann strategies, along with various deterministic exploration strategies, e.g. greedy, epsilon-Greedy and random approaches. In this research work, a comparative study has been done between probabilistic and deterministic decision-making approaches, the experiments are performed in OpenAI gym environment, solving Cart Pole problem. This research work discusses about the Bayesian approach to decision-making in deep reinforcement learning, and about dropout, how it can reduce the computational cost. All the exploration approaches are compared. It also discusses about the importance of exploration in deep reinforcement learning, and how improving exploration strategies may help in science and technology. This research work shows how probabilistic decision-making approaches are better in the long run as compared to the deterministic approaches. When there is uncertainty, Bayesian dropout approach proved to be better than all other approaches in this research work. ","[{'version': 'v1', 'created': 'Sat, 1 Jun 2019 02:36:42 GMT'}]",2019-06-04,"[['Rehman', 'Arsh Javed', ''], ['Tomar', 'Pradeep', '']]",0,0,2019-06-01,1,2,1,0,0,0,6bb98574f2b903907a92f2a604fa9c5f8281e7d0,173990479.0,https://www.semanticscholar.org/paper/6bb98574f2b903907a92f2a604fa9c5f8281e7d0,arXiv.org,2019.0,4.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145379338', 'name': 'A. Rehman'}, {'authorId': '144330395', 'name': 'P. Tomar'}]",['Gautam Buddha University'],['India'],2019-06
1906.03088,"Marc H\""ubner","Christoph Alt, Marc H\""ubner, Leonhard Hennig",Improving Relation Extraction by Pre-trained Language Representations,Code and models available at: https://github.com/DFKI-NLP/TRE,Proceedings of AKBC 2019,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current state-of-the-art relation extraction methods typically rely on a set of lexical, syntactic, and semantic features, explicitly computed in a pre-processing step. Training feature extraction models requires additional annotated language resources, which severely restricts the applicability and portability of relation extraction to novel languages. Similarly, pre-processing introduces an additional source of error. To address these limitations, we introduce TRE, a Transformer for Relation Extraction, extending the OpenAI Generative Pre-trained Transformer [Radford et al., 2018]. Unlike previous relation extraction models, TRE uses pre-trained deep language representations instead of explicit linguistic features to inform the relation classification and combines it with the self-attentive Transformer architecture to effectively model long-range dependencies between entity mentions. TRE allows us to learn implicit linguistic features solely from plain text corpora by unsupervised pre-training, before fine-tuning the learned language representations on the relation extraction task. TRE obtains a new state-of-the-art result on the TACRED and SemEval 2010 Task 8 datasets, achieving a test F1 of 67.4 and 87.1, respectively. Furthermore, we observe a significant increase in sample efficiency. With only 20% of the training examples, TRE matches the performance of our baselines and our model trained from scratch on 100% of the TACRED dataset. We open-source our trained models, experiments, and source code. ","[{'version': 'v1', 'created': 'Fri, 7 Jun 2019 13:31:09 GMT'}]",2019-06-10,"[['Alt', 'Christoph', ''], ['Hübner', 'Marc', ''], ['Hennig', 'Leonhard', '']]",0,1,2019-06-07,1,3,1,0,0,0,28f3a20ebd5e2f3afa871b1784076cf7004415b8,54023707.0,https://www.semanticscholar.org/paper/28f3a20ebd5e2f3afa871b1784076cf7004415b8,Conference on Automated Knowledge Base Construction,2019.0,34.0,71.0,9.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3413117', 'name': 'Christoph Alt'}, {'authorId': '143914106', 'name': 'Marc Hübner'}, {'authorId': '36943315', 'name': 'Leonhard Hennig'}]",['German Research Centre for Artificial Intelligence'],['Germany'],2019-06
1906.08646,Christoph Alt,"Christoph Alt, Marc H\""ubner, Leonhard Hennig",Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction,"To appear in Proceedings of ACL 2019 (11 pages). arXiv admin note:
  text overlap with arXiv:1906.03088",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Distantly supervised relation extraction is widely used to extract relational facts from text, but suffers from noisy labels. Current relation extraction methods try to alleviate the noise by multi-instance learning and by providing supporting linguistic and contextual information to more efficiently guide the relation classification. While achieving state-of-the-art results, we observed these models to be biased towards recognizing a limited set of relations with high precision, while ignoring those in the long tail. To address this gap, we utilize a pre-trained language model, the OpenAI Generative Pre-trained Transformer (GPT) [Radford et al., 2018]. The GPT and similar models have been shown to capture semantic and syntactic features, and also a notable amount of ""common-sense"" knowledge, which we hypothesize are important features for recognizing a more diverse set of relations. By extending the GPT to the distantly supervised setting, and fine-tuning it on the NYT10 dataset, we show that it predicts a larger set of distinct relation types with high confidence. Manual and automated evaluation of our model shows that it achieves a state-of-the-art AUC score of 0.422 on the NYT10 dataset, and performs especially well at higher recall levels. ","[{'version': 'v1', 'created': 'Wed, 19 Jun 2019 11:04:51 GMT'}]",2019-06-21,"[['Alt', 'Christoph', ''], ['Hübner', 'Marc', ''], ['Hennig', 'Leonhard', '']]",0,1,2019-06-19,1,3,1,0,0,0,68e686817f2c33cd09ba3805fa082348f18affd9,195218574.0,https://www.semanticscholar.org/paper/68e686817f2c33cd09ba3805fa082348f18affd9,Annual Meeting of the Association for Computational Linguistics,2019.0,46.0,101.0,24.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3413117', 'name': 'Christoph Alt'}, {'authorId': '143914106', 'name': 'Marc Hübner'}, {'authorId': '36943315', 'name': 'Leonhard Hennig'}]",['German Research Centre for Artificial Intelligence'],['Germany'],2019-06
1906.09807,Cristian Bodnar,"Cristian Bodnar, Ben Day, Pietro Li\'o",Proximal Distilled Evolutionary Reinforcement Learning,"Camera-ready version for AAAI-20. Contains 10 pages, 11 figures","Vol 34 No 04: AAAI 2020 Technical Track on Machine Learning
  3283-3290",10.1609/aaai.v34i04.5728,,cs.LG cs.NE stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reinforcement Learning (RL) has achieved impressive performance in many complex environments due to the integration with Deep Neural Networks (DNNs). At the same time, Genetic Algorithms (GAs), often seen as a competing approach to RL, had limited success in scaling up to the DNNs required to solve challenging tasks. Contrary to this dichotomic view, in the physical world, evolution and learning are complementary processes that continuously interact. The recently proposed Evolutionary Reinforcement Learning (ERL) framework has demonstrated mutual benefits to performance when combining the two methods. However, ERL has not fully addressed the scalability problem of GAs. In this paper, we show that this problem is rooted in an unfortunate combination of a simple genetic encoding for DNNs and the use of traditional biologically-inspired variation operators. When applied to these encodings, the standard operators are destructive and cause catastrophic forgetting of the traits the networks acquired. We propose a novel algorithm called Proximal Distilled Evolutionary Reinforcement Learning (PDERL) that is characterised by a hierarchical integration between evolution and learning. The main innovation of PDERL is the use of learning-based variation operators that compensate for the simplicity of the genetic representation. Unlike traditional operators, our proposals meet the functional requirements of variation operators when applied on directly-encoded DNNs. We evaluate PDERL in five robot locomotion settings from the OpenAI gym. Our method outperforms ERL, as well as two state-of-the-art RL algorithms, PPO and TD3, in all tested environments. ","[{'version': 'v1', 'created': 'Mon, 24 Jun 2019 09:31:09 GMT'}, {'version': 'v2', 'created': 'Sat, 21 Sep 2019 23:22:47 GMT'}, {'version': 'v3', 'created': 'Thu, 28 Nov 2019 21:19:53 GMT'}, {'version': 'v4', 'created': 'Tue, 7 Jul 2020 10:29:57 GMT'}]",2020-07-08,"[['Bodnar', 'Cristian', ''], ['Day', 'Ben', ''], ['Lió', 'Pietro', '']]",0,0,2019-06-24,4,3,3,0,0,0,50ba129bb69e4560d57c412e85d14bb43555abf4,195345282.0,https://www.semanticscholar.org/paper/50ba129bb69e4560d57c412e85d14bb43555abf4,AAAI Conference on Artificial Intelligence,2019.0,29.0,43.0,11.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46195895', 'name': 'Cristian Bodnar'}, {'authorId': '80740711', 'name': 'Ben Day'}, {'authorId': '144269589', 'name': 'P. Lio’'}]",['University of Cambridge'],['United Kingdom'],2019-06
1907.02581,Derek Howard,"Derek Howard, Marta Maslej, Justin Lee, Jacob Ritchie, Geoffrey
  Woollard, Leon French",Transfer Learning for Risk Classification of Social Media Posts: Model Evaluation Study,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Mental illness affects a significant portion of the worldwide population. Online mental health forums can provide a supportive environment for those afflicted and also generate a large amount of data which can be mined to predict mental health states using machine learning methods. We benchmark multiple methods of text feature representation for social media posts and compare their downstream use with automated machine learning (AutoML) tools to triage content for moderator attention. We used 1588 labeled posts from the CLPsych 2017 shared task collected from the Reachout.com forum (Milne et al., 2019). Posts were represented using lexicon based tools including VADER, Empath, LIWC and also used pre-trained artificial neural network models including DeepMoji, Universal Sentence Encoder, and GPT-1. We used TPOT and auto-sklearn as AutoML tools to generate classifiers to triage the posts. The top-performing system used features derived from the GPT-1 model, which was finetuned on over 150,000 unlabeled posts from Reachout.com. Our top system had a macro averaged F1 score of 0.572, providing a new state-of-the-art result on the CLPsych 2017 task. This was achieved without additional information from meta-data or preceding posts. Error analyses revealed that this top system often misses expressions of hopelessness. We additionally present visualizations that aid understanding of the learned classifiers. We show that transfer learning is an effective strategy for predicting risk with relatively little labeled data. We note that finetuning of pretrained language models provides further gains when large amounts of unlabeled text is available. ","[{'version': 'v1', 'created': 'Thu, 4 Jul 2019 20:37:44 GMT'}, {'version': 'v2', 'created': 'Wed, 10 Jul 2019 21:09:43 GMT'}]",2019-07-12,"[['Howard', 'Derek', ''], ['Maslej', 'Marta', ''], ['Lee', 'Justin', ''], ['Ritchie', 'Jacob', ''], ['Woollard', 'Geoffrey', ''], ['French', 'Leon', '']]",0,1,2019-07-04,2,6,1,0,0,0,70d533b698639896a764fb8a3237d1a667651803,195886504.0,https://www.semanticscholar.org/paper/70d533b698639896a764fb8a3237d1a667651803,Journal of Medical Internet Research,2019.0,56.0,19.0,1.0,True,"['Computer Science', 'Medicine']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '82560218', 'name': 'Derek Howard'}, {'authorId': '50518529', 'name': 'M. Maslej'}, {'authorId': '2140081132', 'name': 'Justin Lee'}, {'authorId': '153065258', 'name': 'Jacob Ritchie'}, {'authorId': '50530870', 'name': 'G. Woollard'}, {'authorId': '143840989', 'name': 'L. French'}]","['University of Toronto', 'Centre for Addiction and Mental Health', 'Princess Margaret Cancer Centre']",['Canada'],2019-07
1907.03876,Beren Millidge Mr,Beren Millidge,Deep Active Inference as Variational Policy Gradients,,,,,cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Active Inference is a theory of action arising from neuroscience which casts action and planning as a bayesian inference problem to be solved by minimizing a single quantity - the variational free energy. Active Inference promises a unifying account of action and perception coupled with a biologically plausible process theory. Despite these potential advantages, current implementations of Active Inference can only handle small, discrete policy and state-spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm which approximates key densities using deep neural networks as flexible function approximators, which enables Active Inference to scale to significantly larger and more complex tasks. We demonstrate our approach on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm shows similarities with maximum entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning. ","[{'version': 'v1', 'created': 'Mon, 8 Jul 2019 21:14:29 GMT'}]",2019-07-10,"[['Millidge', 'Beren', '']]",0,0,2019-07-08,1,1,2,0,0,0,def8207fb6457f3c2656bac9f2bbf954de1d7de1,195848019.0,https://www.semanticscholar.org/paper/def8207fb6457f3c2656bac9f2bbf954de1d7de1,Journal of Mathematical Psychology,2019.0,103.0,84.0,8.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150045277', 'name': 'Beren Millidge'}]",['University of Edinburgh'],['United Kingdom'],2019-07
1908.09591,Jieh-Sheng Lee,Jieh-Sheng Lee and Jieh Hsiang,Measuring Patent Claim Generation by Span Relevancy,"10 pages, 2 figures, 2 tables. To be published in the Proceedings of
  the Thirteenth International Workshop on Juris-informatics (JURISIN 2019),
  hosted by JSAI-isAI2019",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our goal of patent claim generation is to realize ""augmented inventing"" for inventors by leveraging latest Deep Learning techniques. We envision the possibility of building an ""auto-complete"" function for inventors to conceive better inventions in the era of artificial intelligence. In order to generate patent claims with good quality, a fundamental question is how to measure it. We tackle the problem from a perspective of claim span relevancy. Patent claim language was rarely explored in the NLP field. It is unique in its own way and contains rich explicit and implicit human annotations. In this work, we propose a span-based approach and a generic framework to measure patent claim generation quantitatively. In order to study the effectiveness of patent claim generation, we define a metric to measure whether two consecutive spans in a generated patent claims are relevant. We treat such relevancy measurement as a span-pair classification problem, following the concept of natural language inference. Technically, the span-pair classifier is implemented by fine-tuning a pre-trained language model. The patent claim generation is implemented by fine-tuning the other pre-trained model. Specifically, we fine-tune a pre-trained Google BERT model to measure the patent claim spans generated by a fine-tuned OpenAI GPT-2 model. In this way, we re-use two of the state-of-the-art pre-trained models in the NLP field. Our result shows the effectiveness of the span-pair classifier after fine-tuning the pre-trained model. It further validates the quantitative metric of span relevancy in patent claim generation. Particularly, we found that the span relevancy ratio measured by BERT becomes lower when the diversity in GPT-2 text generation becomes higher. ","[{'version': 'v1', 'created': 'Mon, 26 Aug 2019 10:59:55 GMT'}, {'version': 'v2', 'created': 'Mon, 2 Dec 2019 12:20:49 GMT'}]",2019-12-03,"[['Lee', 'Jieh-Sheng', ''], ['Hsiang', 'Jieh', '']]",0,1,2019-08-26,2,2,1,1,1,0,ea8f8eeba2270b934659ae3b461d6c5bcd486d5a,201666075.0,https://www.semanticscholar.org/paper/ea8f8eeba2270b934659ae3b461d6c5bcd486d5a,arXiv.org,2019.0,10.0,7.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2387987', 'name': 'Jieh-Sheng Lee'}, {'authorId': '1798127', 'name': 'J. Hsiang'}]",['National Taiwan University'],['Taiwan'],2019-08
1910.01462,Yung-Sung Chuang,"Alexander Te-Wei Shieh, Yung-Sung Chuang, Shang-Yu Su, Yun-Nung Chen",Towards Understanding of Medical Randomized Controlled Trials by Conclusion Generation,"In Proceedings of the 10th International Workshop on Health Text
  Mining and Information Analysis at EMNLP (LOUHI 2019)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Randomized controlled trials (RCTs) represent the paramount evidence of clinical medicine. Using machines to interpret the massive amount of RCTs has the potential of aiding clinical decision-making. We propose a RCT conclusion generation task from the PubMed 200k RCT sentence classification dataset to examine the effectiveness of sequence-to-sequence models on understanding RCTs. We first build a pointer-generator baseline model for conclusion generation. Then we fine-tune the state-of-the-art GPT-2 language model, which is pre-trained with general domain data, for this new medical domain task. Both automatic and human evaluation show that our GPT-2 fine-tuned models achieve improved quality and correctness in the generated conclusions compared to the baseline pointer-generator model. Further inspection points out the limitations of this current approach and future directions to explore. ","[{'version': 'v1', 'created': 'Thu, 3 Oct 2019 13:35:00 GMT'}]",2019-10-04,"[['Shieh', 'Alexander Te-Wei', ''], ['Chuang', 'Yung-Sung', ''], ['Su', 'Shang-Yu', ''], ['Chen', 'Yun-Nung', '']]",0,1,2019-10-03,1,4,1,1,1,0,c561992b76c1090be2e39bb252821c538cf079fd,203642182.0,https://www.semanticscholar.org/paper/c561992b76c1090be2e39bb252821c538cf079fd,Conference on Empirical Methods in Natural Language Processing,2019.0,23.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1382497063', 'name': 'A. Shieh'}, {'authorId': '2475831', 'name': 'Yung-Sung Chuang'}, {'authorId': '27629426', 'name': 'Shang-Yu Su'}, {'authorId': '1725643', 'name': 'Yun-Nung (Vivian) Chen'}]",['National Taiwan University'],['Taiwan'],2019-10
1910.14353,Valeriya Slovikovskaya,Valeriya Slovikovskaya,Transfer Learning from Transformers to Fake News Challenge Stance Detection (FNC-1) Task,"12 pages, 9 tables",,,,cs.CL cs.IR cs.LG cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we report improved results of the Fake News Challenge Stage 1 (FNC-1) stance detection task. This gain in performance is due to the generalization power of large language models based on Transformer architecture, invented, trained and publicly released over the last two years. Specifically (1) we improved the FNC-1 best performing model adding BERT sentence embedding of input sequences as a model feature, (2) we fine-tuned BERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained state-of-the-art results on FNC-1 task. ","[{'version': 'v1', 'created': 'Thu, 31 Oct 2019 10:32:43 GMT'}]",2019-11-01,"[['Slovikovskaya', 'Valeriya', '']]",0,0,2019-10-31,1,1,4,0,0,0,81c6ab01bda037f97ff6c8dd6881a74db66dcdbb,207757977.0,https://www.semanticscholar.org/paper/81c6ab01bda037f97ff6c8dd6881a74db66dcdbb,International Conference on Language Resources and Evaluation,2019.0,37.0,36.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1398109606', 'name': 'Valeriya Slovikovskaya'}]",['University of Pisa'],['Italy'],2019-10
1911.02365,Tassilo Klein,"Tassilo Klein, Moin Nabi",Learning to Answer by Learning to Ask: Getting the Best of GPT-2 and BERT Worlds,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic question generation aims at the generation of questions from a context, with the corresponding answers being sub-spans of the given passage. Whereas, most of the methods mostly rely on heuristic rules to generate questions, more recently also neural network approaches have been proposed. In this work, we propose a variant of the self-attention Transformer network architectures model to generate meaningful and diverse questions. To this end, we propose an easy to use model consisting of the conjunction of the Transformer decoder GPT-2 model with Transformer encoder BERT for the downstream task for question answering. The model is trained in an end-to-end fashion, where the language model is trained to produce a question-answer-aware input representation that facilitates to generate an answer focused question. Our result of neural question generation from text on the SQuAD 1.1 dataset suggests that our method can produce semantically correct and diverse questions. Additionally, we assessed the performance of our proposed method for the downstream task of question answering. The analysis shows that our proposed generation & answering collaboration framework relatively improves both tasks and is particularly powerful in the semi-supervised setup. The results further suggest a robust and comparably lean pipeline facilitating question generation in the small-data regime. ","[{'version': 'v1', 'created': 'Wed, 6 Nov 2019 13:23:41 GMT'}]",2019-11-07,"[['Klein', 'Tassilo', ''], ['Nabi', 'Moin', '']]",0,1,2019-11-06,1,2,3,1,1,0,c1ac3fbf530bf2eb207aa1a20dd14c8ed9f6766b,207880647.0,https://www.semanticscholar.org/paper/c1ac3fbf530bf2eb207aa1a20dd14c8ed9f6766b,arXiv.org,2019.0,27.0,51.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35660331', 'name': 'T. Klein'}, {'authorId': '1848946', 'name': 'Moin Nabi'}]","['SAP Machine Learning Research, Berlin, Germany']",['Germany'],2019-11
1912.03502,Jieh-Sheng Lee,Jieh-Sheng Lee,Personalized Patent Claim Generation and Measurement,"2 figures, 12 pages. Presented at the 32nd International Conference
  on Legal Knowledge and Information Systems (JURIX 2019) and to be published
  in the CEUR Workshop Proceedings",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work-in-progress paper proposes a framework to generate and measure personalized patent claims. The objective is to help inventors conceive better inventions by learning from relevant inventors. Patent claim generation is a way of ""augmented inventing."" for inventors. Such patent claim generation leverages the recent transfer learning in the Deep Learning field, particularly the state-of-the-art Transformer-based models. In terms of system implementa-tion, it is planned to build an ""auto-complete"" function for patent claim drafting. The auto-complete function is analyzed from four different perspectives: extent of generation, generative direction, proximity of generation, and constraint in generation. Technically, the framework is composed of two Transformer models. One is for text generation and the other is for quality measurement. Specifically, the patent claim generation is based on GPT-2 model and the measurement of personalization is based on BERT model. The training data is inventor-centric and comes from the Inventors Endpoint API provided by the USPTO. ","[{'version': 'v1', 'created': 'Sat, 7 Dec 2019 13:26:18 GMT'}, {'version': 'v2', 'created': 'Thu, 12 Dec 2019 14:20:19 GMT'}]",2019-12-13,"[['Lee', 'Jieh-Sheng', '']]",0,1,2019-12-07,2,1,1,1,1,0,b18e50747e88953e86046a7bec5afc17bf2649a0,208909842.0,https://www.semanticscholar.org/paper/b18e50747e88953e86046a7bec5afc17bf2649a0,arXiv.org,2019.0,28.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108319166', 'name': 'Jieh-Sheng Lee'}]",['National Taiwan University'],['Taiwan'],2019-12
1912.05239,Stefano Nolfi,"Paolo Pagliuca, Nicola Milano, and Stefano Nolfi",Efficacy of Modern Neuro-Evolutionary Strategies for Continuous Control Optimization,"17 pages, 5 Figures, 4 Tables",,,,cs.NE cs.LG cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We analyze the efficacy of modern neuro-evolutionary strategies for continuous control optimization. Overall, the results collected on a wide variety of qualitatively different benchmark problems indicate that these methods are generally effective and scale well with respect to the number of parameters and the complexity of the problem. Moreover, they are relatively robust with respect to the setting of hyper-parameters. The comparison of the most promising methods indicates that the OpenAI-ES algorithm outperforms or equals the other algorithms on all considered problems. Moreover, we demonstrate how the reward functions optimized for reinforcement learning methods are not necessarily effective for evolutionary strategies and vice versa. This finding can lead to reconsideration of the relative efficacy of the two classes of algorithm since it implies that the comparisons performed to date are biased toward one or the other class. ","[{'version': 'v1', 'created': 'Wed, 11 Dec 2019 11:29:12 GMT'}, {'version': 'v2', 'created': 'Mon, 1 Jun 2020 09:50:08 GMT'}]",2020-06-02,"[['Pagliuca', 'Paolo', ''], ['Milano', 'Nicola', ''], ['Nolfi', 'Stefano', '']]",0,0,2019-12-11,2,3,3,0,0,0,6ae59a2ebba165609d6ce25a8725fc03157b0191,209202760.0,https://www.semanticscholar.org/paper/6ae59a2ebba165609d6ce25a8725fc03157b0191,Frontiers in Robotics and AI,2019.0,39.0,21.0,2.0,True,"['Computer Science', 'Medicine']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1873471', 'name': 'Paolo Pagliuca'}, {'authorId': '32302973', 'name': 'Nicola Milano'}, {'authorId': '3015062', 'name': 'S. Nolfi'}]",['National Research Council'],['Italy'],2019-12
2001.03708,Jieh-Sheng Lee,Jieh-Sheng Lee and Jieh Hsiang,PatentTransformer-2: Controlling Patent Text Generation by Structural Metadata,demo paper,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  PatentTransformer is our codename for patent text generation based on Transformer-based models. Our goal is ""Augmented Inventing."" In this second version, we leverage more of the structural metadata in patents. The structural metadata includes patent title, abstract, and dependent claim, in addition to independent claim previously. Metadata controls what kind of patent text for the model to generate. Also, we leverage the relation between metadata to build a text-to-text generation flow, for example, from a few words to a title, the title to an abstract, the abstract to an independent claim, and the independent claim to multiple dependent claims. The text flow can go backward because the relation is trained bidirectionally. We release our GPT-2 models trained from scratch and our code for inference so that readers can verify and generate patent text on their own. As for generation quality, we measure it by both ROUGE and Google Universal Sentence Encoder. ","[{'version': 'v1', 'created': 'Sat, 11 Jan 2020 03:54:31 GMT'}]",2020-01-14,"[['Lee', 'Jieh-Sheng', ''], ['Hsiang', 'Jieh', '']]",0,1,2020-01-11,1,2,1,1,1,0,1cd46b2acb8b342c9f45b5a96cf9fd7d84ea5118,210164933.0,https://www.semanticscholar.org/paper/1cd46b2acb8b342c9f45b5a96cf9fd7d84ea5118,arXiv.org,2020.0,12.0,8.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108319166', 'name': 'Jieh-Sheng Lee'}, {'authorId': '1798127', 'name': 'J. Hsiang'}]",['National Taiwan University'],['Taiwan'],2020-01
2002.04013,Max Ryabinin,"Max Ryabinin, Anton Gusev",Towards Crowdsourced Training of Large Neural Networks using Decentralized Mixture-of-Experts,"Advances in Neural Information Processing Systems, 2020. Code URL:
  https://github.com/mryab/learning-at-home. 16 pages, 6 figures","Advances in Neural Information Processing Systems 33 (2020)
  3659-3672",,,cs.DC cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many recent breakthroughs in deep learning were achieved by training increasingly larger models on massive datasets. However, training such models can be prohibitively expensive. For instance, the cluster used to train GPT-3 costs over \$250 million. As a result, most researchers cannot afford to train state of the art models and contribute to their development. Hypothetically, a researcher could crowdsource the training of large neural networks with thousands of regular PCs provided by volunteers. The raw computing power of a hundred thousand \$2500 desktops dwarfs that of a \$250M server pod, but one cannot utilize that power efficiently with conventional distributed training methods. In this work, we propose Learning@home: a novel neural network training paradigm designed to handle large amounts of poorly connected participants. We analyze the performance, reliability, and architectural constraints of this paradigm and compare it against existing distributed training techniques. ","[{'version': 'v1', 'created': 'Mon, 10 Feb 2020 18:39:25 GMT'}, {'version': 'v2', 'created': 'Sun, 14 Jun 2020 15:15:44 GMT'}, {'version': 'v3', 'created': 'Wed, 21 Oct 2020 16:36:55 GMT'}]",2021-07-02,"[['Ryabinin', 'Max', ''], ['Gusev', 'Anton', '']]",0,1,2020-02-10,3,2,3,1,0,1,19eaa4ac17550fab2917d3f6121ed25e6d857a58,224844594.0,https://www.semanticscholar.org/paper/19eaa4ac17550fab2917d3f6121ed25e6d857a58,Neural Information Processing Systems,2020.0,75.0,27.0,1.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1491753352', 'name': 'Max Ryabinin'}, {'authorId': '145256219', 'name': 'Anton I. Gusev'}]","['Yandex', '34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.', 'National Research University Higher School of Economics']","['Canada', 'Russia']",2020-02
2004.01909,Jimmy Lin,"Sheng-Chieh Lin, Jheng-Hong Yang, Rodrigo Nogueira, Ming-Feng Tsai,
  Chuan-Ju Wang, Jimmy Lin",Conversational Question Reformulation via Sequence-to-Sequence Architectures and Pretrained Language Models,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents an empirical study of conversational question reformulation (CQR) with sequence-to-sequence architectures and pretrained language models (PLMs). We leverage PLMs to address the strong token-to-token independence assumption made in the common objective, maximum likelihood estimation, for the CQR task. In CQR benchmarks of task-oriented dialogue systems, we evaluate fine-tuned PLMs on the recently-introduced CANARD dataset as an in-domain task and validate the models using data from the TREC 2019 CAsT Track as an out-domain task. Examining a variety of architectures with different numbers of parameters, we demonstrate that the recent text-to-text transfer transformer (T5) achieves the best results both on CANARD and CAsT with fewer parameters, compared to similar transformer architectures. ","[{'version': 'v1', 'created': 'Sat, 4 Apr 2020 11:07:54 GMT'}]",2020-04-07,"[['Lin', 'Sheng-Chieh', ''], ['Yang', 'Jheng-Hong', ''], ['Nogueira', 'Rodrigo', ''], ['Tsai', 'Ming-Feng', ''], ['Wang', 'Chuan-Ju', ''], ['Lin', 'Jimmy', '']]",0,0,2020-04-04,1,6,3,1,1,0,1db81c2e030f37bc14a01c6e43171a8079e7cccd,214802570.0,https://www.semanticscholar.org/paper/1db81c2e030f37bc14a01c6e43171a8079e7cccd,arXiv.org,2020.0,26.0,44.0,13.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '122045993', 'name': 'Sheng-Chieh Lin'}, {'authorId': '1410146097', 'name': 'Jheng-Hong Yang'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1793168', 'name': 'Ming-Feng Tsai'}, {'authorId': '152744928', 'name': 'Chuan-Ju Wang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]","['Research Center for Information Technology Innovation, Academia Sinica', 'University of Waterloo']","['Canada', 'Taiwan']",2020-04
2004.02644,Pedro Henrique Martins,Pedro Henrique Martins and Zita Marinho and Andr\'e F. T. Martins,Sparse Text Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current state-of-the-art text generators build on powerful language models such as GPT-2, achieving impressive performance. However, to avoid degenerate text, they require sampling from a modified softmax, via temperature parameters or ad-hoc truncation techniques, as in top-$k$ or nucleus sampling. This creates a mismatch between training and testing conditions. In this paper, we use the recently introduced entmax transformation to train and sample from a natively sparse language model, avoiding this mismatch. The result is a text generator with favorable performance in terms of fluency and consistency, fewer repetitions, and n-gram diversity closer to human text. In order to evaluate our model, we propose three new metrics for comparing sparse or truncated distributions: $\epsilon$-perplexity, sparsemax score, and Jensen-Shannon divergence. Human-evaluated experiments in story completion and dialogue generation show that entmax sampling leads to more engaging and coherent stories and conversations. ","[{'version': 'v1', 'created': 'Mon, 6 Apr 2020 13:09:10 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Sep 2020 11:17:53 GMT'}, {'version': 'v3', 'created': 'Mon, 5 Oct 2020 11:20:54 GMT'}]",2020-10-06,"[['Martins', 'Pedro Henrique', ''], ['Marinho', 'Zita', ''], ['Martins', 'André F. T.', '']]",0,1,2020-04-06,3,3,1,1,1,0,3a5f479d15a3300a2fbfb868f80339431b452a5b,214802971.0,https://www.semanticscholar.org/paper/3a5f479d15a3300a2fbfb868f80339431b452a5b,Conference on Empirical Methods in Natural Language Processing,2020.0,56.0,33.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144869806', 'name': 'Pedro Henrique Martins'}, {'authorId': '2566656', 'name': 'Zita Marinho'}, {'authorId': '145644643', 'name': 'André F. T. Martins'}]",['Instituto Superior Técnico'],['Portugal'],2020-04
2004.04216,Marco Guerini,"Serra Sinem Tekiroglu, Yi-Ling Chung, Marco Guerini",Generating Counter Narratives against Online Hate Speech: Data and Strategies,To appear at ACL 2020 (long paper),,,,cs.CL cs.CY cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently research has started focusing on avoiding undesired effects that come with content moderation, such as censorship and overblocking, when dealing with hatred online. The core idea is to directly intervene in the discussion with textual responses that are meant to counter the hate content and prevent it from further spreading. Accordingly, automation strategies, such as natural language generation, are beginning to be investigated. Still, they suffer from the lack of sufficient amount of quality data and tend to produce generic/repetitive responses. Being aware of the aforementioned limitations, we present a study on how to collect responses to hate effectively, employing large scale unsupervised language models such as GPT-2 for the generation of silver data, and the best annotation strategies/neural architectures that can be used for data filtering before expert validation/post-editing. ","[{'version': 'v1', 'created': 'Wed, 8 Apr 2020 19:35:00 GMT'}]",2020-04-10,"[['Tekiroglu', 'Serra Sinem', ''], ['Chung', 'Yi-Ling', ''], ['Guerini', 'Marco', '']]",0,1,2020-04-08,1,3,3,1,1,0,a2617e990e735f0efe6700afbdadcf19d30376dd,215548382.0,https://www.semanticscholar.org/paper/a2617e990e735f0efe6700afbdadcf19d30376dd,Annual Meeting of the Association for Computational Linguistics,2020.0,54.0,66.0,5.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2034636', 'name': 'Serra Sinem Tekiroğlu'}, {'authorId': '3365740', 'name': 'Yi-Ling Chung'}, {'authorId': '1912357', 'name': 'Marco Guerini'}]","['Fondazione Bruno Kessler', 'University of Trento']",['Italy'],2020-04
2004.09685,Jon McCormack,Nina Rajcic and Jon McCormack,Mirror Ritual: An Affective Interface for Emotional Self-Reflection,"Paper presented at ACM CHI2020: Proceedings of the 2020 CHI
  Conference on Human Factors in Computing Systems, ACM, New York, April 2020",,10.1145/3313831.3376625,,cs.HC cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper introduces a new form of real-time affective interface that engages the user in a process of conceptualisation of their emotional state. Inspired by Barrett's Theory of Constructed Emotion, `Mirror Ritual' aims to expand upon the user's accessible emotion concepts, and to ultimately provoke emotional reflection and regulation. The interface uses classified emotions -- obtained through facial expression recognition -- as a basis for dynamically generating poetry. The perceived emotion is used to seed a poetry generation system based on OpenAI's GPT-2 model, fine-tuned on a specially curated corpus. We evaluate the device's ability to foster a personalised, meaningful experience for individual users over a sustained period. A qualitative analysis revealed that participants were able to affectively engage with the mirror, with each participant developing a unique interpretation of its poetry in the context of their own emotional landscape. ","[{'version': 'v1', 'created': 'Tue, 21 Apr 2020 00:19:59 GMT'}]",2020-04-22,"[['Rajcic', 'Nina', ''], ['McCormack', 'Jon', '']]",0,1,2020-04-21,1,2,2,1,1,0,19b5f1f8d948551f437fb64c6bb0d3249182d644,216036185.0,https://www.semanticscholar.org/paper/19b5f1f8d948551f437fb64c6bb0d3249182d644,International Conference on Human Factors in Computing Systems,2020.0,70.0,31.0,0.0,True,"['Computer Science', 'Psychology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '81045154', 'name': 'Nina Rajcic'}, {'authorId': '145951033', 'name': 'J. Mccormack'}]",['Monash University'],['Australia'],2020-04
2004.14253,Marco Guerini,"Lorenzo De Mattei, Michele Cafagna, Felice Dell'Orletta, Malvina
  Nissim, Marco Guerini",GePpeTto Carves Italian into a Language Model,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the last few years, pre-trained neural architectures have provided impressive improvements across several NLP tasks. Still, generative language models are available mainly for English. We develop GePpeTto, the first generative language model for Italian, built using the GPT-2 architecture. We provide a thorough analysis of GePpeTto's quality by means of both an automatic and a human-based evaluation. The automatic assessment consists in (i) calculating perplexity across different genres and (ii) a profiling analysis over GePpeTto's writing characteristics. We find that GePpeTto's production is a sort of bonsai version of human production, with shorter but yet complex sentences. Human evaluation is performed over a sentence completion task, where GePpeTto's output is judged as natural more often than not, and much closer to the original human texts than to a simpler language model which we take as baseline. ","[{'version': 'v1', 'created': 'Wed, 29 Apr 2020 15:02:01 GMT'}]",2020-04-30,"[['De Mattei', 'Lorenzo', ''], ['Cafagna', 'Michele', ''], [""Dell'Orletta"", 'Felice', ''], ['Nissim', 'Malvina', ''], ['Guerini', 'Marco', '']]",0,1,2020-04-29,1,5,1,1,1,0,11c73c1bd2c2424e7c7b9aa2944e1d3a3f579ffb,216642082.0,https://www.semanticscholar.org/paper/11c73c1bd2c2424e7c7b9aa2944e1d3a3f579ffb,Italian Conference on Computational Linguistics,2020.0,10.0,24.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40617675', 'name': 'Lorenzo De Mattei'}, {'authorId': '1397330055', 'name': 'Michele Cafagna'}, {'authorId': '2187131', 'name': 'F. Dell’Orletta'}, {'authorId': '2742475', 'name': 'M. Nissim'}, {'authorId': '1912357', 'name': 'Marco Guerini'}]","['University of Groningen', 'Fondazione Bruno Kessler', 'University of Pisa', 'Institute for Computational Linguistics “A. Zampolli”', ""Sant'Anna School of Advanced Studies""]","['Netherlands', 'Italy']",2020-04
2005.11787,Nikolai Rozanov,"Anne Lauscher and Olga Majewska and Leonardo F. R. Ribeiro and Iryna
  Gurevych and Nikolai Rozanov and Goran Glava\v{s}",Common Sense or World Knowledge? Investigating Adapter-Based Knowledge Injection into Pretrained Transformers,"EMNLP 2020 - DeeLIO, ECML 2020 - DECODEML, 5 pages, 4 tables, 3
  references",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Following the major success of neural language models (LMs) such as BERT or GPT-2 on a variety of language understanding tasks, recent work focused on injecting (structured) knowledge from external resources into these models. While on the one hand, joint pretraining (i.e., training from scratch, adding objectives based on external knowledge to the primary LM objective) may be prohibitively computationally expensive, post-hoc fine-tuning on external knowledge, on the other hand, may lead to the catastrophic forgetting of distributional knowledge. In this work, we investigate models for complementing the distributional knowledge of BERT with conceptual knowledge from ConceptNet and its corresponding Open Mind Common Sense (OMCS) corpus, respectively, using adapter training. While overall results on the GLUE benchmark paint an inconclusive picture, a deeper analysis reveals that our adapter-based models substantially outperform BERT (up to 15-20 performance points) on inference tasks that require the type of conceptual knowledge explicitly present in ConceptNet and OMCS. All code and experiments are open sourced under: https://github.com/wluper/retrograph . ","[{'version': 'v1', 'created': 'Sun, 24 May 2020 15:49:57 GMT'}, {'version': 'v2', 'created': 'Sun, 11 Oct 2020 11:31:03 GMT'}]",2020-10-13,"[['Lauscher', 'Anne', ''], ['Majewska', 'Olga', ''], ['Ribeiro', 'Leonardo F. R.', ''], ['Gurevych', 'Iryna', ''], ['Rozanov', 'Nikolai', ''], ['Glavaš', 'Goran', '']]",0,1,2020-05-24,2,6,1,1,1,0,8b8c29c0cbb6cbae26b930840396596dd5806f33,218870140.0,https://www.semanticscholar.org/paper/8b8c29c0cbb6cbae26b930840396596dd5806f33,Workshop on Knowledge Extraction and Integration for Deep Learning Architectures; Deep Learning Inside Out,2020.0,45.0,58.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '29891652', 'name': 'Anne Lauscher'}, {'authorId': '46963731', 'name': 'Olga Majewska'}, {'authorId': '10430740', 'name': 'Leonardo F. R. Ribeiro'}, {'authorId': '69033154', 'name': 'Iryna Gurevych'}, {'authorId': '80666414', 'name': 'N. Rozanov'}, {'authorId': '1666177566', 'name': 'Goran Glavavs'}]","['Imperial College London', 'University of Mannheim', 'Technical University of Darmstadt']","['Germany', 'United Kingdom']",2020-05
2005.14664,Josef Urban,Josef Urban and Jan Jakub\r{u}v,First Neural Conjecturing Datasets and Experiments,Accepted to CICM 2020,,,,cs.AI cs.LG cs.LO cs.NE cs.SC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,  We describe several datasets and first experiments with creating conjectures by neural methods. The datasets are based on the Mizar Mathematical Library processed in several forms and the problems extracted from it by the MPTP system and proved by the E prover using the ENIGMA guidance. The conjecturing experiments use the Transformer architecture and in particular its GPT-2 implementation. ,"[{'version': 'v1', 'created': 'Fri, 29 May 2020 16:46:25 GMT'}]",2020-06-01,"[['Urban', 'Josef', ''], ['Jakubův', 'Jan', '']]",0,1,2020-05-29,1,2,5,1,1,0,268fc2b1cb4afa59f088b1aa7e47e1b4abb0d1b5,219124086.0,https://www.semanticscholar.org/paper/268fc2b1cb4afa59f088b1aa7e47e1b4abb0d1b5,International Conference on Intelligent Computer Mathematics,2020.0,22.0,26.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '2087993', 'name': 'J. Urban'}, {'authorId': '2171321', 'name': 'Jan Jakubuv'}]","['Czech Institute of Informatics, Robotics and Cybernetics, Prague, Czech Republic']",['Czech Republic'],2020-05
2006.01997,Virapat Kieuvongngam,"Virapat Kieuvongngam, Bowen Tan, Yiming Niu",Automatic Text Summarization of COVID-19 Medical Research Articles using BERT and GPT-2,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  With the COVID-19 pandemic, there is a growing urgency for medical community to keep up with the accelerating growth in the new coronavirus-related literature. As a result, the COVID-19 Open Research Dataset Challenge has released a corpus of scholarly articles and is calling for machine learning approaches to help bridging the gap between the researchers and the rapidly growing publications. Here, we take advantage of the recent advances in pre-trained NLP models, BERT and OpenAI GPT-2, to solve this challenge by performing text summarization on this dataset. We evaluate the results using ROUGE scores and visual inspection. Our model provides abstractive and comprehensive information based on keywords extracted from the original articles. Our work can help the the medical community, by providing succinct summaries of articles for which the abstract are not already available. ","[{'version': 'v1', 'created': 'Wed, 3 Jun 2020 00:54:44 GMT'}]",2020-06-04,"[['Kieuvongngam', 'Virapat', ''], ['Tan', 'Bowen', ''], ['Niu', 'Yiming', '']]",0,1,2020-06-03,1,3,2,1,1,0,762baed866a8f23e19ea52f265c9ba7f353896ce,219260480.0,https://www.semanticscholar.org/paper/762baed866a8f23e19ea52f265c9ba7f353896ce,arXiv.org,2020.0,16.0,55.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1483571725', 'name': 'V. Kieuvongngam'}, {'authorId': '10918587', 'name': 'Bowen Tan'}, {'authorId': '72117004', 'name': 'Yiming Niu'}]","['Laboratory of Molecular Genetics', 'Laboratory of Molecular Neurobiology and Biophysics Rockefeller University New York, NY 10065', 'Laboratory of Membrane Biology and Biophysics Rockefeller University New York, NY 10065']",['Poland'],2020-06
2006.15319,Hung Le,"Hung Le, Steven C.H. Hoi",Video-Grounded Dialogues with Pretrained Generation Language Models,Accepted at ACL 2020 (Short Paper),Association for Computational Linguistics (2020) 5842-5848,,,cs.CL cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models have shown remarkable success in improving various downstream NLP tasks due to their ability to capture dependencies in textual data and generate natural responses. In this paper, we leverage the power of pre-trained language models for improving video-grounded dialogue, which is very challenging and involves complex features of different dynamics: (1) Video features which can extend across both spatial and temporal dimensions; and (2) Dialogue features which involve semantic dependencies over multiple dialogue turns. We propose a framework by extending GPT-2 models to tackle these challenges by formulating video-grounded dialogue tasks as a sequence-to-sequence task, combining both visual and textual representation into a structured sequence, and fine-tuning a large pre-trained GPT-2 network. Our framework allows fine-tuning language models to capture dependencies across multiple modalities over different levels of information: spatio-temporal level in video and token-sentence level in dialogue context. We achieve promising improvement on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark from DSTC7, which supports a potential direction in this line of research. ","[{'version': 'v1', 'created': 'Sat, 27 Jun 2020 08:24:26 GMT'}]",2020-06-30,"[['Le', 'Hung', ''], ['Hoi', 'Steven C. H.', '']]",0,1,2020-06-27,1,2,3,1,1,0,af73d7815f13794223384004096ff4fc62c3d4a9,220045105.0,https://www.semanticscholar.org/paper/af73d7815f13794223384004096ff4fc62c3d4a9,Annual Meeting of the Association for Computational Linguistics,2020.0,30.0,18.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064728738', 'name': 'Hung Le'}, {'authorId': '1741126', 'name': 'S. Hoi'}]","['Salesforce Research Asia', 'Singapore Management University']",['Singapore'],2020-06
2007.06949,Bal\'azs Tarj\'an,"Bal\'azs Tarj\'an, Gy\""orgy Szasz\'ak, Tibor Fegy\'o, P\'eter Mihajlik",Deep Transformer based Data Augmentation with Subword Units for Morphologically Rich Online ASR,"7 pages, 4 figures",,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently Deep Transformer models have proven to be particularly powerful in language modeling tasks for ASR. Their high complexity, however, makes them very difficult to apply in the first (single) pass of an online system. Recent studies showed that a considerable part of the knowledge of neural network Language Models (LM) can be transferred to traditional n-grams by using neural text generation based data augmentation. In our paper, we pre-train a GPT-2 Transformer LM on a general text corpus and fine-tune it on our Hungarian conversational call center ASR task. We show that although data augmentation with Transformer-generated text works well for isolating languages, it causes a vocabulary explosion in a morphologically rich language. Therefore, we propose a new method called subword-based neural text augmentation, where we retokenize the generated text into statistically derived subwords. We compare Morfessor and BPE statistical subword tokenizers and show that both methods can significantly improve the WER while greatly reducing vocabulary size and memory requirements. Finally, we also demonstrate that subword-based neural text augmentation outperforms the word-based approach not only in terms of overall WER but also in recognition of OOV words. ","[{'version': 'v1', 'created': 'Tue, 14 Jul 2020 10:22:05 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Jul 2020 14:14:27 GMT'}, {'version': 'v3', 'created': 'Wed, 4 Nov 2020 09:03:13 GMT'}]",2020-11-05,"[['Tarján', 'Balázs', ''], ['Szaszák', 'György', ''], ['Fegyó', 'Tibor', ''], ['Mihajlik', 'Péter', '']]",0,1,2020-07-14,3,4,2,1,1,0,81765386bd5f1165947dab94f66e02acc5d71e13,220514729.0,https://www.semanticscholar.org/paper/81765386bd5f1165947dab94f66e02acc5d71e13,arXiv.org,2020.0,28.0,2.0,0.0,False,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2065060925', 'name': ""B. Tarj'an""}, {'authorId': '30838563', 'name': ""Gyorgy Szasz'ak""}, {'authorId': '2066692650', 'name': ""Tibor Fegy'o""}, {'authorId': '1754901', 'name': 'P. Mihajlik'}]","['University of Kragujevac', 'Budapest University of Technology and Economics']","['Serbia', 'Hungary']",2020-07
2008.00177,Xin Li,"Jiahuang Lin, Xin Li, Gennady Pekhimenko",Multi-node Bert-pretraining: Cost-efficient Approach,,,,,cs.LG cs.CL stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, large scale Transformer-based language models such as BERT, GPT-2, and XLNet have brought about exciting leaps in state-of-the-art results for many Natural Language Processing (NLP) tasks. One of the common trends in these recent models is a significant increase in model complexity, which introduces both more weights and computation. Moreover, with the advent of large-scale unsupervised datasets, training time is further extended due to the increased amount of data samples within a single training epoch. As a result, to train these models within a reasonable time, machine learning (ML) programmers often require advanced hardware setups such as the premium GPU-enabled NVIDIA DGX workstations or specialized accelerators such as Google's TPU Pods. Our work addresses this limitation and demonstrates that the BERT pre-trained model can be trained within 2 weeks on an academic-size cluster of widely available GPUs through careful algorithmic and software optimizations. In this paper, we present these optimizations on how to improve single device training throughput, distribute the training workload over multiple nodes and GPUs, and overcome the communication bottleneck introduced by the large data exchanges over the network. We show that we are able to perform pre-training on BERT within a reasonable time budget (12 days) in an academic setting, but with a much less expensive and less aggressive hardware resource requirement than in previously demonstrated industrial settings based on NVIDIA DGX machines or Google's TPU Pods. ","[{'version': 'v1', 'created': 'Sat, 1 Aug 2020 05:49:20 GMT'}]",2020-08-04,"[['Lin', 'Jiahuang', ''], ['Li', 'Xin', ''], ['Pekhimenko', 'Gennady', '']]",0,1,2020-08-01,1,3,3,1,1,0,198b42dcc3a6dbd254fa25ab6dd23f3e32592950,220935910.0,https://www.semanticscholar.org/paper/198b42dcc3a6dbd254fa25ab6dd23f3e32592950,arXiv.org,2020.0,33.0,10.0,0.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '71772778', 'name': 'Jiahuang Lin'}, {'authorId': '51376876', 'name': 'X. Li'}, {'authorId': '3257164', 'name': 'Gennady Pekhimenko'}]",['University of Toronto'],['Canada'],2020-08
2008.08769,Alexandre Lopes,"Alexandre Lopes, Rodrigo Nogueira, Roberto Lotufo, Helio Pedrini",Lite Training Strategies for Portuguese-English and English-Portuguese Translation,"for code and weights, visit
  https://github.com/unicamp-dl/Lite-T5-Translation",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Despite the widespread adoption of deep learning for machine translation, it is still expensive to develop high-quality translation models. In this work, we investigate the use of pre-trained models, such as T5 for Portuguese-English and English-Portuguese translation tasks using low-cost hardware. We explore the use of Portuguese and English pre-trained language models and propose an adaptation of the English tokenizer to represent Portuguese characters, such as diaeresis, acute and grave accents. We compare our models to the Google Translate API and MarianMT on a subset of the ParaCrawl dataset, as well as to the winning submission to the WMT19 Biomedical Translation Shared Task. We also describe our submission to the WMT20 Biomedical Translation Shared Task. Our results show that our models have a competitive performance to state-of-the-art models while being trained on modest hardware (a single 8GB gaming GPU for nine days). Our data, models and code are available at https://github.com/unicamp-dl/Lite-T5-Translation. ","[{'version': 'v1', 'created': 'Thu, 20 Aug 2020 04:31:03 GMT'}]",2020-08-21,"[['Lopes', 'Alexandre', ''], ['Nogueira', 'Rodrigo', ''], ['Lotufo', 'Roberto', ''], ['Pedrini', 'Helio', '']]",0,0,2020-08-20,1,4,1,1,1,0,5176c1508b658518dbf27e3f3f636b0411fd45b5,221186799.0,https://www.semanticscholar.org/paper/5176c1508b658518dbf27e3f3f636b0411fd45b5,Conference on Machine Translation,2020.0,34.0,4.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064422345', 'name': 'Alexandre Lopes'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}, {'authorId': '1809633', 'name': 'R. Lotufo'}, {'authorId': '2059195394', 'name': 'Hélio Pedrini'}]","['NeuralMind Inteligłncia Artificial, Brazil', 'Universidade Estadual de Campinas (UNICAMP)', 'University of Waterloo']","['Canada', 'Brazil']",2020-08
2009.01303,Sasi Kiran Gaddipati,"Sasi Kiran Gaddipati, Deebul Nair, Paul G. Pl\""oger",Comparative Evaluation of Pretrained Transfer Learning Models on Automatic Short Answer Grading,"7 pages, 3 figures, 3 tables. ""for associated work, refer
  https://github.com/gsasikiran/Evaluation-of-transfer-learning-models-on-automatic-short-answer-grading""",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic Short Answer Grading (ASAG) is the process of grading the student answers by computational approaches given a question and the desired answer. Previous works implemented the methods of concept mapping, facet mapping, and some used the conventional word embeddings for extracting semantic features. They extracted multiple features manually to train on the corresponding datasets. We use pretrained embeddings of the transfer learning models, ELMo, BERT, GPT, and GPT-2 to assess their efficiency on this task. We train with a single feature, cosine similarity, extracted from the embeddings of these models. We compare the RMSE scores and correlation measurements of the four models with previous works on Mohler dataset. Our work demonstrates that ELMo outperformed the other three models. We also, briefly describe the four transfer learning models and conclude with the possible causes of poor results of transfer learning models. ","[{'version': 'v1', 'created': 'Wed, 2 Sep 2020 19:07:34 GMT'}]",2020-09-04,"[['Gaddipati', 'Sasi Kiran', ''], ['Nair', 'Deebul', ''], ['Plöger', 'Paul G.', '']]",0,1,2020-09-02,1,3,1,1,1,0,1a8a4686f81efdcb5b1dd1e24eca9997280e2521,221470365.0,https://www.semanticscholar.org/paper/1a8a4686f81efdcb5b1dd1e24eca9997280e2521,arXiv.org,2020.0,30.0,13.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1924542474', 'name': 'Sasi Kiran Gaddipati'}, {'authorId': '1454453926', 'name': 'Deebul Nair'}, {'authorId': '1775016', 'name': 'P. Plöger'}]",['Hochschule Bonn-Rhein-Sieg'],['Germany'],2020-09
2009.03622,Pablo Lanillos,"Otto van der Himst, Pablo Lanillos",Deep Active Inference for Partially Observable MDPs,"1st International Workshop on Active inference, European Conference
  on Machine Learning (ECML/PCKDD 2020)",,10.1007/978-3-030-64919-7_8,,cs.LG cs.AI cs.NE stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep active inference has been proposed as a scalable approach to perception and action that deals with large policy and state spaces. However, current models are limited to fully observable domains. In this paper, we describe a deep active inference model that can learn successful policies directly from high-dimensional sensory inputs. The deep learning architecture optimizes a variant of the expected free energy and encodes the continuous state representation by means of a variational autoencoder. We show, in the OpenAI benchmark, that our approach has comparable or better performance than deep Q-learning, a state-of-the-art deep reinforcement learning algorithm. ","[{'version': 'v1', 'created': 'Tue, 8 Sep 2020 10:02:40 GMT'}]",2021-02-08,"[['van der Himst', 'Otto', ''], ['Lanillos', 'Pablo', '']]",0,0,2020-09-08,1,2,4,0,0,0,931781af3b6797d5abe3aa2537f4f46fd4fdf3ef,221534017.0,https://www.semanticscholar.org/paper/931781af3b6797d5abe3aa2537f4f46fd4fdf3ef,International Workshop on Affective Interactions,2020.0,19.0,17.0,1.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1932052049', 'name': 'Otto van der Himst'}, {'authorId': '2865315', 'name': 'Pablo Lanillos'}]",['Radboud University Nijmegen'],['The Netherlands'],2020-09
2009.04765,Damian Pascual,"Nicolas Affolter, Beni Egressy, Damian Pascual, Roger Wattenhofer",Brain2Word: Decoding Brain Activity for Language Generation,Preprint. Work in progress,,,,cs.CL cs.LG q-bio.NC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Brain decoding, understood as the process of mapping brain activities to the stimuli that generated them, has been an active research area in the last years. In the case of language stimuli, recent studies have shown that it is possible to decode fMRI scans into an embedding of the word a subject is reading. However, such word embeddings are designed for natural language processing tasks rather than for brain decoding. Therefore, they limit our ability to recover the precise stimulus. In this work, we propose to directly classify an fMRI scan, mapping it to the corresponding word within a fixed vocabulary. Unlike existing work, we evaluate on scans from previously unseen subjects. We argue that this is a more realistic setup and we present a model that can decode fMRI data from unseen subjects. Our model achieves 5.22% Top-1 and 13.59% Top-5 accuracy in this challenging task, significantly outperforming all the considered competitive baselines. Furthermore, we use the decoded words to guide language generation with the GPT-2 model. This way, we advance the quest for a system that translates brain activities into coherent text. ","[{'version': 'v1', 'created': 'Thu, 10 Sep 2020 10:47:36 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Oct 2020 08:05:08 GMT'}, {'version': 'v3', 'created': 'Wed, 11 Nov 2020 08:07:08 GMT'}]",2020-11-12,"[['Affolter', 'Nicolas', ''], ['Egressy', 'Beni', ''], ['Pascual', 'Damian', ''], ['Wattenhofer', 'Roger', '']]",0,1,2020-09-10,3,4,3,1,1,0,769b2f239bde15c01dbe3856a2ff216f6b0e003b,221586298.0,https://www.semanticscholar.org/paper/769b2f239bde15c01dbe3856a2ff216f6b0e003b,arXiv.org,2020.0,30.0,11.0,0.0,False,"['Computer Science', 'Biology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1935004796', 'name': 'Nicolas Affolter'}, {'authorId': '1935472784', 'name': 'Béni Egressy'}, {'authorId': '150973452', 'name': 'Damian Pascual'}, {'authorId': '1716440', 'name': 'Roger Wattenhofer'}]",['ETH Zurich'],['Switzerland'],2020-09
2009.04968,Dimas Munoz,Dimas Munoz Montesinos,Modern Methods for Text Generation,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Synthetic text generation is challenging and has limited success. Recently, a new architecture, called Transformers, allow machine learning models to understand better sequential data, such as translation or summarization. BERT and GPT-2, using Transformers in their cores, have shown a great performance in tasks such as text classification, translation and NLI tasks. In this article, we analyse both algorithms and compare their output quality in text generation tasks. ","[{'version': 'v1', 'created': 'Thu, 10 Sep 2020 16:17:10 GMT'}]",2020-09-11,"[['Montesinos', 'Dimas Munoz', '']]",0,1,2020-09-10,1,1,2,1,1,0,a8ba0bea6295e75a613caec822a9fe5975580d51,221585959.0,https://www.semanticscholar.org/paper/a8ba0bea6295e75a613caec822a9fe5975580d51,arXiv.org,2020.0,21.0,4.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2058098496', 'name': 'Dimas Muñoz-Montesinos'}]",['National Research University Higher School of Economics'],['Russia'],2020-09
2009.08636,Jihyeon Roh,"Jihyeon Roh, Huiseong Gim, Soo-Young Lee",Hierarchical GPT with Congruent Transformers for Multi-Sentence Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We report a GPT-based multi-sentence language model for dialogue generation and document understanding. First, we propose a hierarchical GPT which consists of three blocks, i.e., a sentence encoding block, a sentence generating block, and a sentence decoding block. The sentence encoding and decoding blocks are basically the encoder-decoder blocks of the standard Transformers, which work on each sentence independently. The sentence generating block is inserted between the encoding and decoding blocks, and generates the next sentence embedding vector from the previous sentence embedding vectors. We believe it is the way human make conversation and understand paragraphs and documents. Since each sentence may consist of fewer words, the sentence encoding and decoding Transformers can use much smaller dimensional embedding vectors. Secondly, we note the attention in the Transformers utilizes the inner-product similarity measure. Therefore, to compare the two vectors in the same space, we set the transform matrices for queries and keys to be the same. Otherwise, the similarity concept is incongruent. We report experimental results to show that these two modifications increase the language model performance for tasks with multiple sentences. ","[{'version': 'v1', 'created': 'Fri, 18 Sep 2020 05:55:37 GMT'}]",2020-09-21,"[['Roh', 'Jihyeon', ''], ['Gim', 'Huiseong', ''], ['Lee', 'Soo-Young', '']]",0,1,2020-09-18,1,3,1,0,0,0,eb60cae405ea8a709848cf8ec8efe807890b5011,221802755.0,https://www.semanticscholar.org/paper/eb60cae405ea8a709848cf8ec8efe807890b5011,arXiv.org,2020.0,16.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3294960', 'name': 'Jihyeon Roh'}, {'authorId': '1952903293', 'name': 'Huiseong Gim'}, {'authorId': '1739906639', 'name': 'Soo-Young Lee'}]",['Korea Advanced Institute of Science and Technology'],['South Korea'],2020-09
2009.09132,Jieh-Sheng Lee,Jieh-Sheng Lee and Jieh Hsiang,Prior Art Search and Reranking for Generated Patent Text,"7 pages, 3 figures, 1 table","The 2nd Workshop on Patent Text Mining and Semantic Technologies
  (PatentSemTech2021) co-located with the 44th International ACM SIGIR
  Conference on Research and Development in Information Retrieval",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative models, such as GPT-2, have demonstrated impressive results recently. A fundamental question we'd like to address is: where did the generated text come from? This work is our initial effort toward answering the question by using prior art search. The purpose of the prior art search is to find the most similar prior text in the training data of GPT-2. We take a reranking approach and apply it to the patent domain. Specifically, we pre-train GPT-2 models from scratch by using the patent data from the USPTO. The input for the prior art search is the patent text generated by the GPT-2 model. We also pre-trained BERT models from scratch for converting patent text to embeddings. The steps of reranking are: (1) search the most similar text in the training data of GPT-2 by taking a bag-of-word ranking approach (BM25), (2) convert the search results in text format to BERT embeddings, and (3) provide the final result by ranking the BERT embeddings based on their similarities with the patent text generated by GPT-2. The experiments in this work show that such reranking is better than ranking with embeddings alone. However, our mixed results also indicate that calculating the semantic similarities among long text spans is still challenging. To our knowledge, this work is the first to implement a reranking system to identify retrospectively the most similar inputs to a GPT model based on its output. ","[{'version': 'v1', 'created': 'Sat, 19 Sep 2020 01:16:18 GMT'}, {'version': 'v2', 'created': 'Sun, 18 Jul 2021 06:07:21 GMT'}]",2021-07-20,"[['Lee', 'Jieh-Sheng', ''], ['Hsiang', 'Jieh', '']]",0,1,2020-09-19,2,2,1,1,1,0,1501936ac136845e621b32072e7505455a0fa652,221819366.0,https://www.semanticscholar.org/paper/1501936ac136845e621b32072e7505455a0fa652,arXiv.org,2020.0,28.0,8.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2387987', 'name': 'Jieh-Sheng Lee'}, {'authorId': '1798127', 'name': 'J. Hsiang'}]",['National Taiwan University'],['Taiwan'],2020-09
2009.12344,"Tommi Gr\""ondahl","Mika Juuti, Tommi Gr\""ondahl, Adrian Flanagan and N. Asokan",A little goes a long way: Improving toxic language classification despite data scarcity,To appear in Findings of ACL: EMNLP 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Detection of some types of toxic language is hampered by extreme scarcity of labeled training data. Data augmentation - generating new synthetic data from a labeled seed dataset - can help. The efficacy of data augmentation on toxic language classification has not been fully explored. We present the first systematic study on how data augmentation techniques impact performance across toxic language classifiers, ranging from shallow logistic regression architectures to BERT - a state-of-the-art pre-trained Transformer network. We compare the performance of eight techniques on very scarce seed datasets. We show that while BERT performed the best, shallow classifiers performed comparably when trained on data augmented with a combination of three techniques, including GPT-2-generated sentences. We discuss the interplay of performance and computational overhead, which can inform the choice of techniques under different constraints. ","[{'version': 'v1', 'created': 'Fri, 25 Sep 2020 17:04:17 GMT'}, {'version': 'v2', 'created': 'Sat, 24 Oct 2020 19:31:34 GMT'}]",2020-10-27,"[['Juuti', 'Mika', ''], ['Gröndahl', 'Tommi', ''], ['Flanagan', 'Adrian', ''], ['Asokan', 'N.', '']]",0,1,2020-09-25,2,4,1,1,1,0,e4e4804ad775df90ebdfac22d1b0328c97ff54ae,221949376.0,https://www.semanticscholar.org/paper/e4e4804ad775df90ebdfac22d1b0328c97ff54ae,Findings,2020.0,82.0,17.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2464929', 'name': 'Mika Juuti'}, {'authorId': '24778462', 'name': 'Tommi Grondahl'}, {'authorId': '144795201', 'name': 'Adrian Flanagan'}, {'authorId': '1735412', 'name': 'Nirmal Asokan'}]","['Aalto University', 'Huawei Technologies (Finland)', 'University of Waterloo']","['Canada', 'Finland']",2020-09
2010.00153,Zining Zhu,"Zining Zhu, Chuer Pan, Mohamed Abdalla, Frank Rudzicz",Examining the rhetorical capacities of neural language models,EMNLP 2020 BlackboxNLP Workshop,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, neural language models (LMs) have demonstrated impressive abilities in generating high-quality discourse. While many recent papers have analyzed the syntactic aspects encoded in LMs, there has been no analysis to date of the inter-sentential, rhetorical knowledge. In this paper, we propose a method that quantitatively evaluates the rhetorical capacities of neural LMs. We examine the capacities of neural LMs understanding the rhetoric of discourse by evaluating their abilities to encode a set of linguistic features derived from Rhetorical Structure Theory (RST). Our experiments show that BERT-based LMs outperform other Transformer LMs, revealing the richer discourse knowledge in their intermediate layer representations. In addition, GPT-2 and XLNet apparently encode less rhetorical knowledge, and we suggest an explanation drawing from linguistic philosophy. Our method shows an avenue towards quantifying the rhetorical capacities of neural LMs. ","[{'version': 'v1', 'created': 'Thu, 1 Oct 2020 00:18:43 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Oct 2020 22:16:11 GMT'}]",2020-10-06,"[['Zhu', 'Zining', ''], ['Pan', 'Chuer', ''], ['Abdalla', 'Mohamed', ''], ['Rudzicz', 'Frank', '']]",0,1,2020-10-01,2,4,1,1,1,0,22cd89da4b6561c68be6c2586fb1d3aeea842075,222090359.0,https://www.semanticscholar.org/paper/22cd89da4b6561c68be6c2586fb1d3aeea842075,BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,2020.0,63.0,8.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8129672', 'name': 'Zining Zhu'}, {'authorId': '24568124', 'name': 'Chuer Pan'}, {'authorId': '2006490389', 'name': 'Mohamed Abdalla'}, {'authorId': '2479037', 'name': 'Frank Rudzicz'}]","['University of Toronto', 'St Michael’s Hospital']","['Canada', 'Ireland']",2020-10
2010.00964,Muhammad Hammad,"Muhammad Hammad, \""Onder Babur, Hamid Abdul Basit",Augmenting Machine Learning with Information Retrieval to Recommend Real Cloned Code Methods for Code Completion,,,,,cs.SE,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Software developers frequently reuse source code from repositories as it saves development time and effort. Code clones accumulated in these repositories hence represent often repeated functionalities and are candidates for reuse in an exploratory or rapid development. In previous work, we introduced DeepClone, a deep neural network model trained by fine tuning GPT-2 model over the BigCloneBench dataset to predict code clone methods. The probabilistic nature of DeepClone output generation can lead to syntax and logic errors that requires manual editing of the output for final reuse. In this paper, we propose a novel approach of applying an information retrieval (IR) technique on top of DeepClone output to recommend real clone methods closely matching the predicted output. We have quantitatively evaluated our strategy, showing that the proposed approach significantly improves the quality of recommendation. ","[{'version': 'v1', 'created': 'Fri, 2 Oct 2020 12:52:12 GMT'}]",2020-10-05,"[['Hammad', 'Muhammad', ''], ['Babur', 'Önder', ''], ['Basit', 'Hamid Abdul', '']]",0,1,2020-10-02,1,3,1,1,1,0,32a5bdedabbbd5cacc617fc9933b3df9f0e27016,222125203.0,https://www.semanticscholar.org/paper/32a5bdedabbbd5cacc617fc9933b3df9f0e27016,arXiv.org,2020.0,42.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1409270430', 'name': 'Muhammad Hammad'}, {'authorId': '2914285', 'name': 'Önder Babur'}, {'authorId': '2076259', 'name': 'H. Basit'}]","['Eindhoven University of Technology', 'Prince Sultan University']","['Saudi Arabia', 'Netherlands']",2020-10
2010.05572,Suranjana Samanta,"Debanjana Kar, Suranjana Samanta, Amar Prakash Azad",Meta-Context Transformers for Domain-Specific Response Generation,"7+2 pages, 6 figures, 4 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the tremendous success of neural dialogue models in recent years, it suffers a lack of relevance, diversity, and some times coherence in generated responses. Lately, transformer-based models, such as GPT-2, have revolutionized the landscape of dialogue generation by capturing the long-range structures through language modeling. Though these models have exhibited excellent language coherence, they often lack relevance and terms when used for domain-specific response generation. In this paper, we present DSRNet (Domain Specific Response Network), a transformer-based model for dialogue response generation by reinforcing domain-specific attributes. In particular, we extract meta attributes from context and infuse them with the context utterances for better attention over domain-specific key terms and relevance. We study the use of DSRNet in a multi-turn multi-interlocutor environment for domain-specific response generation. In our experiments, we evaluate DSRNet on Ubuntu dialogue datasets, which are mainly composed of various technical domain related dialogues for IT domain issue resolutions and also on CamRest676 dataset, which contains restaurant domain conversations. Trained with maximum likelihood objective, our model shows significant improvement over the state-of-the-art for multi-turn dialogue systems supported by better BLEU and semantic similarity (BertScore) scores. Besides, we also observe that the responses produced by our model carry higher relevance due to the presence of domain-specific key attributes that exhibit better overlap with the attributes of the context. Our analysis shows that the performance improvement is mostly due to the infusion of key terms along with dialogues which result in better attention over domain-relevant terms. Other contributing factors include joint modeling of dialogue context with the domain-specific meta attributes and topics. ","[{'version': 'v1', 'created': 'Mon, 12 Oct 2020 09:49:27 GMT'}]",2020-10-13,"[['Kar', 'Debanjana', ''], ['Samanta', 'Suranjana', ''], ['Azad', 'Amar Prakash', '']]",0,1,2020-10-12,1,3,1,1,1,0,a7a0ce59f1b71f0209ac17e1464dac71a84b399f,222291368.0,https://www.semanticscholar.org/paper/a7a0ce59f1b71f0209ac17e1464dac71a84b399f,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2020.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '29850167', 'name': 'Debanjana Kar'}, {'authorId': '1744768', 'name': 'Suranjana Samanta'}, {'authorId': '1704816', 'name': 'A. Azad'}]","['Indian Institute of Technology Kharagpur', 'IBM Research - India', 'IBM (India)']",['India'],2020-10
2010.09598,Jeroen Offerijns,"Jeroen Offerijns, Suzan Verberne, Tessa Verhoef",Better Distractions: Transformer-based Distractor Generation and Multiple Choice Question Filtering,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  For the field of education, being able to generate semantically correct and educationally relevant multiple choice questions (MCQs) could have a large impact. While question generation itself is an active research topic, generating distractors (the incorrect multiple choice options) receives much less attention. A missed opportunity, since there is still a lot of room for improvement in this area. In this work, we train a GPT-2 language model to generate three distractors for a given question and text context, using the RACE dataset. Next, we train a BERT language model to answer MCQs, and use this model as a filter, to select only questions that can be answered and therefore presumably make sense. To evaluate our work, we start by using text generation metrics, which show that our model outperforms earlier work on distractor generation (DG) and achieves state-of-the-art performance. Also, by calculating the question answering ability, we show that larger base models lead to better performance. Moreover, we conducted a human evaluation study, which confirmed the quality of the generated questions, but showed no statistically significant effect of the QA filter. ","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 15:23:24 GMT'}]",2020-10-20,"[['Offerijns', 'Jeroen', ''], ['Verberne', 'Suzan', ''], ['Verhoef', 'Tessa', '']]",0,1,2020-10-19,1,3,1,1,1,0,ebcb8978662c48e1e4d8c654498230e0233aaf5f,224710719.0,https://www.semanticscholar.org/paper/ebcb8978662c48e1e4d8c654498230e0233aaf5f,arXiv.org,2020.0,36.0,7.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1999196301', 'name': 'J. Offerijns'}, {'authorId': '1702730', 'name': 'S. Verberne'}, {'authorId': '37531591', 'name': 'T. Verhoef'}]",['Leiden University'],['Netherlands'],2020-10
2010.09697,William Merrill,"William Merrill and Vivek Ramanujan and Yoav Goldberg and Roy Schwartz
  and Noah Smith",Effects of Parameter Norm Growth During Transformer Training: Inductive Bias from Gradient Descent,"Appeared at EMNLP 2021. March 7, 2023: Removed irreproducible numbers
  reported in a footnote with erratum note",,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The capacity of neural networks like the widely adopted transformer is known to be very high. Evidence is emerging that they learn successfully due to inductive bias in the training routine, typically a variant of gradient descent (GD). To better understand this bias, we study the tendency for transformer parameters to grow in magnitude ($\ell_2$ norm) during training, and its implications for the emergent representations within self attention layers. Empirically, we document norm growth in the training of transformer language models, including T5 during its pretraining. As the parameters grow in magnitude, we prove that the network approximates a discretized network with saturated activation functions. Such ""saturated"" networks are known to have a reduced capacity compared to the full network family that can be described in terms of formal languages and automata. Our results suggest saturation is a new characterization of an inductive bias implicit in GD of particular interest for NLP. We leverage the emergent discrete structure in a saturated transformer to analyze the role of different attention heads, finding that some focus locally on a small number of positions, while other heads compute global averages, allowing counting. We believe understanding the interplay between these two capabilities may shed further light on the structure of computation within large transformers. ","[{'version': 'v1', 'created': 'Mon, 19 Oct 2020 17:40:38 GMT'}, {'version': 'v2', 'created': 'Wed, 11 Nov 2020 10:26:55 GMT'}, {'version': 'v3', 'created': 'Fri, 10 Sep 2021 17:17:38 GMT'}, {'version': 'v4', 'created': 'Wed, 29 Sep 2021 18:48:40 GMT'}, {'version': 'v5', 'created': 'Tue, 7 Mar 2023 23:09:55 GMT'}]",2023-03-09,"[['Merrill', 'William', ''], ['Ramanujan', 'Vivek', ''], ['Goldberg', 'Yoav', ''], ['Schwartz', 'Roy', ''], ['Smith', 'Noah', '']]",0,0,2020-10-19,5,5,2,1,1,0,f10a04a77fd1cd719792de374a60f3fd03f6b944,237485630.0,https://www.semanticscholar.org/paper/f10a04a77fd1cd719792de374a60f3fd03f6b944,Conference on Empirical Methods in Natural Language Processing,2020.0,39.0,17.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143696607', 'name': 'William Cooper Merrill'}, {'authorId': '2255504299', 'name': 'Vivek Ramanujan'}, {'authorId': '79775260', 'name': 'Yoav Goldberg'}, {'authorId': '4671928', 'name': 'Roy Schwartz'}, {'authorId': '2116830388', 'name': 'Noah A. Smith'}]",['Hebrew University of Jerusalem'],['Israel'],2020-10
2010.10216,Biswesh Mohapatra,"Biswesh Mohapatra, Gaurav Pandey, Danish Contractor, Sachindra Joshi",Simulated Chats for Building Dialog Systems: Learning to Generate Conversations from Instructions,Accepted in the Findings of EMNLP 2021,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Popular dialog datasets such as MultiWOZ are created by providing crowd workers an instruction, expressed in natural language, that describes the task to be accomplished. Crowd workers play the role of a user and an agent to generate dialogs to accomplish tasks involving booking restaurant tables, calling a taxi etc. In this paper, we present a data creation strategy that uses the pre-trained language model, GPT2, to simulate the interaction between crowd workers by creating a user bot and an agent bot. We train the simulators using a smaller percentage of actual crowd-generated conversations and their corresponding instructions. We demonstrate that by using the simulated data, we achieve significant improvements in low-resource settings on two publicly available datasets - the MultiWOZ dataset and the Persona chat dataset. ","[{'version': 'v1', 'created': 'Tue, 20 Oct 2020 12:04:19 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Oct 2021 08:48:55 GMT'}, {'version': 'v3', 'created': 'Tue, 19 Oct 2021 10:11:50 GMT'}, {'version': 'v4', 'created': 'Wed, 20 Oct 2021 13:13:03 GMT'}]",2021-10-22,"[['Mohapatra', 'Biswesh', ''], ['Pandey', 'Gaurav', ''], ['Contractor', 'Danish', ''], ['Joshi', 'Sachindra', '']]",0,1,2020-10-20,4,4,2,1,1,0,0f3596364943bb03f14cd75d9595a2c465831edb,239016412.0,https://www.semanticscholar.org/paper/0f3596364943bb03f14cd75d9595a2c465831edb,Conference on Empirical Methods in Natural Language Processing,2020.0,44.0,16.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1999633074', 'name': 'Biswesh Mohapatra'}, {'authorId': '2686270', 'name': 'Gaurav Pandey'}, {'authorId': '2075459', 'name': 'Danish Contractor'}, {'authorId': '1703799', 'name': 'Sachindra Joshi'}]","['IBM Research - India', 'International Institute of Information Technology Bangalore']",['India'],2020-10
2010.10874,Erik Ekstedt,Erik Ekstedt and Gabriel Skantze,TurnGPT: a Transformer-based Language Model for Predicting Turn-taking in Spoken Dialog,Accepted to Findings of ACL: EMNLP 2020,,10.18653/v1/2020.findings-emnlp.268,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Syntactic and pragmatic completeness is known to be important for turn-taking prediction, but so far machine learning models of turn-taking have used such linguistic information in a limited way. In this paper, we introduce TurnGPT, a transformer-based language model for predicting turn-shifts in spoken dialog. The model has been trained and evaluated on a variety of written and spoken dialog datasets. We show that the model outperforms two baselines used in prior work. We also report on an ablation study, as well as attention and gradient analyses, which show that the model is able to utilize the dialog context and pragmatic completeness for turn-taking prediction. Finally, we explore the model's potential in not only detecting, but also projecting, turn-completions. ","[{'version': 'v1', 'created': 'Wed, 21 Oct 2020 09:58:39 GMT'}]",2020-12-10,"[['Ekstedt', 'Erik', ''], ['Skantze', 'Gabriel', '']]",0,1,2020-10-21,1,2,2,0,0,0,97b0689d937a622c37726a10b911a60a89f146d8,224814511.0,https://www.semanticscholar.org/paper/97b0689d937a622c37726a10b911a60a89f146d8,Findings,2020.0,36.0,25.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '97522045', 'name': 'Erik Ekstedt'}, {'authorId': '1711959', 'name': 'Gabriel Skantze'}]",['KTH Royal Institute of Technology'],['Sweden'],2020-10
2010.15792,Zhenyu Gao,"Jiunhan Chen, Zhenyu Gao",A Framework for Learning Predator-prey Agents from Simulation to Real World,,,,,cs.RO cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we propose an evolutionary predatorprey robot system which can be generally implemented from simulation to the real world. We design the closed-loop robot system with camera and infrared sensors as inputs of controller. Both the predators and prey are co-evolved by NeuroEvolution of Augmenting Topologies (NEAT) to learn the expected behaviours. We design a framework that integrate Gym of OpenAI, Robot Operating System (ROS), Gazebo. In such a framework, users only need to focus on algorithms without being worried about the detail of manipulating robots in both simulation and the real world. Combining simulations, real-world evolution, and robustness analysis, it can be applied to develop the solutions for the predator-prey tasks. For the convenience of users, the source code and videos of the simulated and real world are published on Github. ","[{'version': 'v1', 'created': 'Thu, 29 Oct 2020 17:33:38 GMT'}]",2020-10-30,"[['Chen', 'Jiunhan', ''], ['Gao', 'Zhenyu', '']]",0,0,2020-10-29,1,2,2,0,0,0,ef6feaf7848cf378b03438e4c0c1472808fce83f,225103267.0,https://www.semanticscholar.org/paper/ef6feaf7848cf378b03438e4c0c1472808fce83f,arXiv.org,2020.0,23.0,1.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108323674', 'name': 'Jiunhan Chen'}, {'authorId': '49538832', 'name': 'Zhenyu Gao'}]",['Vrije Universiteit Amsterdam'],['Netherlands'],2020-10
2011.01504,Harsh Patel,Harsh Patel,BioNerFlair: biomedical named entity recognition using flair embedding and sequence tagger,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Motivation: The proliferation of Biomedical research articles has made the task of information retrieval more important than ever. Scientists and Researchers are having difficulty in finding articles that contain information relevant to them. Proper extraction of biomedical entities like Disease, Drug/chem, Species, Gene/protein, can considerably improve the filtering of articles resulting in better extraction of relevant information. Performance on BioNer benchmarks has progressively improved because of progression in transformers-based models like BERT, XLNet, OpenAI, GPT2, etc. These models give excellent results; however, they are computationally expensive and we can achieve better scores for domain-specific tasks using other contextual string-based models and LSTM-CRF based sequence tagger. Results: We introduce BioNerFlair, a method to train models for biomedical named entity recognition using Flair plus GloVe embeddings and Bidirectional LSTM-CRF based sequence tagger. With almost the same generic architecture widely used for named entity recognition, BioNerFlair outperforms previous state-of-the-art models. I performed experiments on 8 benchmarks datasets for biomedical named entity recognition. Compared to current state-of-the-art models, BioNerFlair achieves the best F1-score of 90.17 beyond 84.72 on the BioCreative II gene mention (BC2GM) corpus, best F1-score of 94.03 beyond 92.36 on the BioCreative IV chemical and drug (BC4CHEMD) corpus, best F1-score of 88.73 beyond 78.58 on the JNLPBA corpus, best F1-score of 91.1 beyond 89.71 on the NCBI disease corpus, best F1-score of 85.48 beyond 78.98 on the Species-800 corpus, while near best results was observed on BC5CDR-chem, BC3CDR-disease, and LINNAEUS corpus. ","[{'version': 'v1', 'created': 'Tue, 3 Nov 2020 06:46:45 GMT'}]",2020-11-04,"[['Patel', 'Harsh', '']]",0,1,2020-11-03,1,1,2,1,1,0,5b57067ee5088b5faa111137c3cb33cd28a8fe46,226237525.0,https://www.semanticscholar.org/paper/5b57067ee5088b5faa111137c3cb33cd28a8fe46,arXiv.org,2020.0,43.0,4.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '2036587230', 'name': 'Harsh Patel'}]",['Medi-Caps University'],['India'],2020-11
2011.01694,Zden\v{e}k Kasner,Zden\v{e}k Kasner and Ond\v{r}ej Du\v{s}ek,Data-to-Text Generation with Iterative Text Editing,Accepted for INLG 2020,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a novel approach to data-to-text generation based on iterative text editing. Our approach maximizes the completeness and semantic accuracy of the output text while leveraging the abilities of recent pre-trained models for text editing (LaserTagger) and language modeling (GPT-2) to improve the text fluency. To this end, we first transform data items to text using trivial templates, and then we iteratively improve the resulting text by a neural model trained for the sentence fusion task. The output of the model is filtered by a simple heuristic and reranked with an off-the-shelf pre-trained language model. We evaluate our approach on two major data-to-text datasets (WebNLG, Cleaned E2E) and analyze its caveats and benefits. Furthermore, we show that our formulation of data-to-text generation opens up the possibility for zero-shot domain adaptation using a general-domain dataset for sentence fusion. ","[{'version': 'v1', 'created': 'Tue, 3 Nov 2020 13:32:38 GMT'}, {'version': 'v2', 'created': 'Thu, 28 Jan 2021 14:30:14 GMT'}]",2021-01-29,"[['Kasner', 'Zdeněk', ''], ['Dušek', 'Ondřej', '']]",0,1,2020-11-03,2,2,1,1,1,0,1574c435a202d1118cbadb0462ef508e6cbced5a,226237288.0,https://www.semanticscholar.org/paper/1574c435a202d1118cbadb0462ef508e6cbced5a,International Conference on Natural Language Generation,2020.0,42.0,19.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1805991958', 'name': 'Zdeněk Kasner'}, {'authorId': '2544049', 'name': 'Ondrej Dusek'}]",['Charles University'],['Czechia'],2020-11
2011.03286,Haryo Akbarianto Wibowo,"Haryo Akbarianto Wibowo, Tatag Aziz Prawiro, Muhammad Ihsan, Alham
  Fikri Aji, Radityo Eko Prasojo, Rahmad Mahendra, Suci Fitriany",Semi-Supervised Low-Resource Style Transfer of Indonesian Informal to Formal Language with Iterative Forward-Translation,"6 pages, Camera ready to be presented at IALP 2020",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In its daily use, the Indonesian language is riddled with informality, that is, deviations from the standard in terms of vocabulary, spelling, and word order. On the other hand, current available Indonesian NLP models are typically developed with the standard Indonesian in mind. In this work, we address a style-transfer from informal to formal Indonesian as a low-resource machine translation problem. We build a new dataset of parallel sentences of informal Indonesian and its formal counterpart. We benchmark several strategies to perform style transfer from informal to formal Indonesian. We also explore augmenting the training set with artificial forward-translated data. Since we are dealing with an extremely low-resource setting, we find that a phrase-based machine translation approach outperforms the Transformer-based approach. Alternatively, a pre-trained GPT-2 fined-tuned to this task performed equally well but costs more computational resource. Our findings show a promising step towards leveraging machine translation models for style transfer. Our code and data are available in https://github.com/haryoa/stif-indonesia ","[{'version': 'v1', 'created': 'Fri, 6 Nov 2020 11:19:47 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Dec 2020 17:32:47 GMT'}]",2020-12-23,"[['Wibowo', 'Haryo Akbarianto', ''], ['Prawiro', 'Tatag Aziz', ''], ['Ihsan', 'Muhammad', ''], ['Aji', 'Alham Fikri', ''], ['Prasojo', 'Radityo Eko', ''], ['Mahendra', 'Rahmad', ''], ['Fitriany', 'Suci', '']]",0,1,2020-11-06,2,7,1,1,1,0,44cebc4fe5595a4d39b1cb9f6a3eda81125b774a,226278122.0,https://www.semanticscholar.org/paper/44cebc4fe5595a4d39b1cb9f6a3eda81125b774a,International Conference on Asian Language Processing,2020.0,23.0,12.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '49918371', 'name': 'Haryo Akbarianto Wibowo'}, {'authorId': '2007720669', 'name': 'Tatag Aziz Prawiro'}, {'authorId': '2096627831', 'name': 'M. Ihsan'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}, {'authorId': '2368148', 'name': 'Radityo Eko Prasojo'}, {'authorId': '1935324', 'name': 'Rahmad Mahendra'}]","['University of Indonesia', 'Binus University', 'Kata AI Research Team Kata.ai Jakarta, Indonesia']",['Indonesia'],2020-11
2011.05431,Nikolaos Stylianou,"Nikolaos Stylianou, Ioannis Vlahavas",E.T.: Entity-Transformers. Coreference augmented Neural Language Model for richer mention representations via Entity-Transformer blocks,"10 pages, 4 figures, 5 tables, accepted at CRAC2020",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In the last decade, the field of Neural Language Modelling has witnessed enormous changes, with the development of novel models through the use of Transformer architectures. However, even these models struggle to model long sequences due to memory constraints and increasing computational complexity. Coreference annotations over the training data can provide context far beyond the modelling limitations of such language models. In this paper we present an extension over the Transformer-block architecture used in neural language models, specifically in GPT2, in order to incorporate entity annotations during training. Our model, GPT2E, extends the Transformer layers architecture of GPT2 to Entity-Transformers, an architecture designed to handle coreference information when present. To that end, we achieve richer representations for entity mentions, with insignificant training cost. We show the comparative model performance between GPT2 and GPT2E in terms of Perplexity on the CoNLL 2012 and LAMBADA datasets as well as the key differences in the entity representations and their effects in downstream tasks such as Named Entity Recognition. Furthermore, our approach can be adopted by the majority of Transformer-based language models. ","[{'version': 'v1', 'created': 'Tue, 10 Nov 2020 22:28:00 GMT'}]",2020-11-12,"[['Stylianou', 'Nikolaos', ''], ['Vlahavas', 'Ioannis', '']]",0,1,2020-11-10,1,2,2,1,1,0,9a407e1bea7ffbf81d02d74a688786941cf14301,226299975.0,https://www.semanticscholar.org/paper/9a407e1bea7ffbf81d02d74a688786941cf14301,CRAC,2020.0,26.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51050433', 'name': 'Nikolaos Stylianou'}, {'authorId': '1697941', 'name': 'I. Vlahavas'}]",['Aristotle University of Thessaloniki'],['Greece'],2020-11
2011.12574,Jaskirat Singh,Jaskirat Singh and Liang Zheng,Enhanced Scene Specificity with Sparse Dynamic Value Estimation,,,,,cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Multi-scene reinforcement learning involves training the RL agent across multiple scenes / levels from the same task, and has become essential for many generalization applications. However, the inclusion of multiple scenes leads to an increase in sample variance for policy gradient computations, often resulting in suboptimal performance with the direct application of traditional methods (e.g. PPO, A3C). One strategy for variance reduction is to consider each scene as a distinct Markov decision process (MDP) and learn a joint value function dependent on both state (s) and MDP (M). However, this is non-trivial as the agent is usually unaware of the underlying level at train / test times in multi-scene RL. Recently, Singh et al. [1] tried to address this by proposing a dynamic value estimation approach that models the true joint value function distribution as a Gaussian mixture model (GMM). In this paper, we argue that the error between the true scene-specific value function and the predicted dynamic estimate can be further reduced by progressively enforcing sparse cluster assignments once the agent has explored most of the state space. The resulting agents not only show significant improvements in the final reward score across a range of OpenAI ProcGen environments, but also exhibit increased navigation efficiency while completing a game level. ","[{'version': 'v1', 'created': 'Wed, 25 Nov 2020 08:35:16 GMT'}]",2020-11-26,"[['Singh', 'Jaskirat', ''], ['Zheng', 'Liang', '']]",0,0,2020-11-25,1,2,2,0,0,0,217fef0db6253f8cba6021c466eb2a4432f86721,227162325.0,https://www.semanticscholar.org/paper/217fef0db6253f8cba6021c466eb2a4432f86721,arXiv.org,2020.0,31.0,0.0,0.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112713578', 'name': 'Jaskirat Singh'}, {'authorId': '144802394', 'name': 'Liang Zheng'}]",['Australian National University'],['Australia'],2020-11
2011.14344,Tien Cuong Bui,"Tien-Cuong Bui, Van-Duc Le, Hai-Thien To and Sang Kyun Cha",Generative Pre-training for Paraphrase Generation by Representing and Predicting Spans in Exemplars,"8 pages, 4 figures, Accepted to IEEE International Conference on Big
  Data and Smart Computing 2021",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Paraphrase generation is a long-standing problem and serves an essential role in many natural language processing problems. Despite some encouraging results, recent methods either confront the problem of favoring generic utterance or need to retrain the model from scratch for each new dataset. This paper presents a novel approach to paraphrasing sentences, extended from the GPT-2 model. We develop a template masking technique, named first-order masking, to masked out irrelevant words in exemplars utilizing POS taggers. So that, the paraphrasing task is changed to predicting spans in masked templates. Our proposed approach outperforms competitive baselines, especially in the semantic preservation aspect. To prevent the model from being biased towards a given template, we introduce a technique, referred to as second-order masking, which utilizes Bernoulli distribution to control the visibility of the first-order-masked template's tokens. Moreover, this technique allows the model to provide various paraphrased sentences in testing by adjusting the second-order-masking level. For scale-up objectives, we compare the performance of two alternatives template-selection methods, which shows that they were equivalent in preserving semantic information. ","[{'version': 'v1', 'created': 'Sun, 29 Nov 2020 11:36:13 GMT'}]",2020-12-01,"[['Bui', 'Tien-Cuong', ''], ['Le', 'Van-Duc', ''], ['To', 'Hai-Thien', ''], ['Cha', 'Sang Kyun', '']]",0,1,2020-11-29,1,4,1,1,1,0,efa38b16e2698a677c78e0daa47aa16053619f0c,227227669.0,https://www.semanticscholar.org/paper/efa38b16e2698a677c78e0daa47aa16053619f0c,International Conference on Big Data and Smart Computing,2020.0,30.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '41022579', 'name': 'Tien-Cuong Bui'}, {'authorId': '2055470540', 'name': 'Van-Duc Le'}, {'authorId': '30562055', 'name': 'H. To'}, {'authorId': '2237996', 'name': 'S. Cha'}]",['Seoul National University'],['South Korea'],2020-11
2012.05628,Wietse de Vries,"Wietse de Vries, Malvina Nissim",As Good as New. How to Successfully Recycle English GPT-2 to Make Models for Other Languages,Findings of ACL 2021 Camera Ready,"Findings of the Association for Computational Linguistics:
  ACL-IJCNLP 2021",10.18653/v1/2021.findings-acl.74,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large generative language models have been very successful for English, but other languages lag behind, in part due to data and computational limitations. We propose a method that may overcome these problems by adapting existing pre-trained models to new languages. Specifically, we describe the adaptation of English GPT-2 to Italian and Dutch by retraining lexical embeddings without tuning the Transformer layers. As a result, we obtain lexical embeddings for Italian and Dutch that are aligned with the original English lexical embeddings. Additionally, we scale up complexity by transforming relearned lexical embeddings of GPT-2 small to the GPT-2 medium embedding space. This method minimises the amount of training and prevents losing information during adaptation that was learned by GPT-2. English GPT-2 models with relearned lexical embeddings can generate realistic sentences in Italian and Dutch. Though on average these sentences are still identifiable as artificial by humans, they are assessed on par with sentences generated by a GPT-2 model fully trained from scratch. ","[{'version': 'v1', 'created': 'Thu, 10 Dec 2020 12:27:16 GMT'}, {'version': 'v2', 'created': 'Sat, 22 May 2021 09:21:35 GMT'}, {'version': 'v3', 'created': 'Wed, 9 Jun 2021 07:57:32 GMT'}]",2021-08-03,"[['de Vries', 'Wietse', ''], ['Nissim', 'Malvina', '']]",0,1,2020-12-10,3,2,1,1,1,0,56446cb1da48cbe6e19e5051ed80c3861021e5ba,228083868.0,https://www.semanticscholar.org/paper/56446cb1da48cbe6e19e5051ed80c3861021e5ba,Findings,2020.0,42.0,35.0,5.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '144611157', 'name': 'Wietse de Vries'}, {'authorId': '2742475', 'name': 'M. Nissim'}]",['University of Groningen'],['Netherlands'],2020-12
2012.06373,Julien Launay,"Julien Launay, Iacopo Poli, Kilian M\""uller, Gustave Pariente, Igor
  Carron, Laurent Daudet, Florent Krzakala, Sylvain Gigan",Hardware Beyond Backpropagation: a Photonic Co-Processor for Direct Feedback Alignment,"6 pages, 2 figures, 1 table. Oral at the Beyond Backpropagation
  Workshop, NeurIPS 2020",,,,cs.LG cs.AI cs.AR cs.NE stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The scaling hypothesis motivates the expansion of models past trillions of parameters as a path towards better performance. Recent significant developments, such as GPT-3, have been driven by this conjecture. However, as models scale-up, training them efficiently with backpropagation becomes difficult. Because model, pipeline, and data parallelism distribute parameters and gradients over compute nodes, communication is challenging to orchestrate: this is a bottleneck to further scaling. In this work, we argue that alternative training methods can mitigate these issues, and can inform the design of extreme-scale training hardware. Indeed, using a synaptically asymmetric method with a parallelizable backward pass, such as Direct Feedback Alignement, communication needs are drastically reduced. We present a photonic accelerator for Direct Feedback Alignment, able to compute random projections with trillions of parameters. We demonstrate our system on benchmark tasks, using both fully-connected and graph convolutional networks. Our hardware is the first architecture-agnostic photonic co-processor for training neural networks. This is a significant step towards building scalable hardware, able to go beyond backpropagation, and opening new avenues for deep learning. ","[{'version': 'v1', 'created': 'Fri, 11 Dec 2020 14:20:45 GMT'}]",2020-12-14,"[['Launay', 'Julien', ''], ['Poli', 'Iacopo', ''], ['Müller', 'Kilian', ''], ['Pariente', 'Gustave', ''], ['Carron', 'Igor', ''], ['Daudet', 'Laurent', ''], ['Krzakala', 'Florent', ''], ['Gigan', 'Sylvain', '']]",0,1,2020-12-11,1,8,5,1,0,1,202aff0523074ef9e1984309858f9176b517e318,228376253.0,https://www.semanticscholar.org/paper/202aff0523074ef9e1984309858f9176b517e318,arXiv.org,2020.0,26.0,14.0,0.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143945447', 'name': 'Julien Launay'}, {'authorId': '46186238', 'name': 'Iacopo Poli'}, {'authorId': '144684049', 'name': 'Kilian Muller'}, {'authorId': '2091476062', 'name': 'Gustave Pariente'}, {'authorId': '2361737', 'name': 'I. Carron'}, {'authorId': '1742040', 'name': 'L. Daudet'}, {'authorId': '2909402', 'name': 'F. Krzakala'}, {'authorId': '2383983', 'name': 'S. Gigan'}]",['École Polytechnique Fédérale de Lausanne'],['Switzerland'],2020-12
2012.08787,Vincent Claveau,Vincent Claveau,Query expansion with artificially generated texts,"12 pages, 2 figures",,,,cs.IR,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  A well-known way to improve the performance of document retrieval is to expand the user's query. Several approaches have been proposed in the literature, and some of them are considered as yielding state-of-the-art results in IR. In this paper, we explore the use of text generation to automatically expand the queries. We rely on a well-known neural generative model, GPT-2, that comes with pre-trained models for English but can also be fine-tuned on specific corpora. Through different experiments, we show that text generation is a very effective way to improve the performance of an IR system, with a large margin (+10% MAP gains), and that it outperforms strong baselines also relying on query expansion (LM+RM3). This conceptually simple approach can easily be implemented on any IR system thanks to the availability of GPT code and models. ","[{'version': 'v1', 'created': 'Wed, 16 Dec 2020 08:13:08 GMT'}]",2020-12-17,"[['Claveau', 'Vincent', '']]",0,1,2020-12-16,1,1,1,1,1,0,55ae264ff9cdc855b1f8f0f17b3300f200b7a1a6,229220964.0,https://www.semanticscholar.org/paper/55ae264ff9cdc855b1f8f0f17b3300f200b7a1a6,arXiv.org,2020.0,26.0,9.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1735666', 'name': 'V. Claveau'}]","['CNRS -IRISA, Univ. Rennes Campus de Beaulieu, F-35042 Rennes, France']",['France'],2020-12
2012.12007,Yubo Xie,"Yubo Xie, Junze Li, Pearl Pu",Uncertainty and Surprisal Jointly Deliver the Punchline: Exploiting Incongruity-Based Features for Humor Recognition,Accepted to ACL-IJCNLP 2021,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Humor recognition has been widely studied as a text classification problem using data-driven approaches. However, most existing work does not examine the actual joke mechanism to understand humor. We break down any joke into two distinct components: the set-up and the punchline, and further explore the special relationship between them. Inspired by the incongruity theory of humor, we model the set-up as the part developing semantic uncertainty, and the punchline disrupting audience expectations. With increasingly powerful language models, we were able to feed the set-up along with the punchline into the GPT-2 language model, and calculate the uncertainty and surprisal values of the jokes. By conducting experiments on the SemEval 2021 Task 7 dataset, we found that these two features have better capabilities of telling jokes from non-jokes, compared with existing baselines. ","[{'version': 'v1', 'created': 'Tue, 22 Dec 2020 13:48:09 GMT'}, {'version': 'v2', 'created': 'Tue, 10 Aug 2021 12:34:02 GMT'}]",2021-08-11,"[['Xie', 'Yubo', ''], ['Li', 'Junze', ''], ['Pu', 'Pearl', '']]",0,1,2020-12-22,2,3,2,1,1,0,daae582be667cc24fafb2b93208e377c2c5dac37,229349316.0,https://www.semanticscholar.org/paper/daae582be667cc24fafb2b93208e377c2c5dac37,Annual Meeting of the Association for Computational Linguistics,2020.0,36.0,11.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2118596012', 'name': 'Yubo Xie'}, {'authorId': '2108920576', 'name': 'Junze Li'}, {'authorId': '1781996', 'name': 'P. Pu'}]",['École Polytechnique Fédérale de Lausanne'],['Switzerland'],2020-12
2012.13475,Amy X. Lu,"Amy X. Lu, Alex X. Lu, Alan Moses",Evolution Is All You Need: Phylogenetic Augmentation for Contrastive Learning,Machine Learning in Computational Biology (MLCB) 2020,,,,q-bio.BM cs.LG cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Self-supervised representation learning of biological sequence embeddings alleviates computational resource constraints on downstream tasks while circumventing expensive experimental label acquisition. However, existing methods mostly borrow directly from large language models designed for NLP, rather than with bioinformatics philosophies in mind. Recently, contrastive mutual information maximization methods have achieved state-of-the-art representations for ImageNet. In this perspective piece, we discuss how viewing evolution as natural sequence augmentation and maximizing information across phylogenetic ""noisy channels"" is a biologically and theoretically desirable objective for pretraining encoders. We first provide a review of current contrastive learning literature, then provide an illustrative example where we show that contrastive learning using evolutionary augmentation can be used as a representation learning objective which maximizes the mutual information between biological sequences and their conserved function, and finally outline rationale for this approach. ","[{'version': 'v1', 'created': 'Fri, 25 Dec 2020 01:35:06 GMT'}]",2020-12-29,"[['Lu', 'Amy X.', ''], ['Lu', 'Alex X.', ''], ['Moses', 'Alan', '']]",0,0,2020-12-25,1,3,3,0,0,0,80cfe0bde1bb32c1d9abb2decac5c1865ddfac74,229678217.0,https://www.semanticscholar.org/paper/80cfe0bde1bb32c1d9abb2decac5c1865ddfac74,arXiv.org,2020.0,58.0,9.0,0.0,False,"['Biology', 'Computer Science']","[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '13460225', 'name': 'Amy X. Lu'}, {'authorId': '48272336', 'name': 'Alex X. Lu'}, {'authorId': '145497462', 'name': 'Alan M. Moses'}]",['University of Toronto'],['Canada'],2020-12
2012.15416,Damian Pascual,"Damian Pascual, Beni Egressy, Florian Bolli, Roger Wattenhofer",Directed Beam Search: Plug-and-Play Lexically Constrained Language Generation,Preprint. Work in progress,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large pre-trained language models are capable of generating realistic text. However, controlling these models so that the generated text satisfies lexical constraints, i.e., contains specific words, is a challenging problem. Given that state-of-the-art language models are too large to be trained from scratch in a manageable time, it is desirable to control these models without re-training them. Methods capable of doing this are called plug-and-play. Recent plug-and-play methods have been successful in constraining small bidirectional language models as well as forward models in tasks with a restricted search space, e.g., machine translation. However, controlling large transformer-based models to meet lexical constraints without re-training them remains a challenge. In this work, we propose Directed Beam Search (DBS), a plug-and-play method for lexically constrained language generation. Our method can be applied to any language model, is easy to implement and can be used for general language generation. In our experiments we use DBS to control GPT-2. We demonstrate its performance on keyword-to-phrase generation and we obtain comparable results as a state-of-the-art non-plug-and-play model for lexically constrained story generation. ","[{'version': 'v1', 'created': 'Thu, 31 Dec 2020 03:05:44 GMT'}]",2021-01-01,"[['Pascual', 'Damian', ''], ['Egressy', 'Beni', ''], ['Bolli', 'Florian', ''], ['Wattenhofer', 'Roger', '']]",0,1,2020-12-31,1,4,3,1,1,0,568deb4817e7633483c93be3f50dcf51493963ff,229923101.0,https://www.semanticscholar.org/paper/568deb4817e7633483c93be3f50dcf51493963ff,arXiv.org,2020.0,27.0,12.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150973452', 'name': 'Damian Pascual'}, {'authorId': '1935472784', 'name': 'Béni Egressy'}, {'authorId': '2043231121', 'name': 'Florian Bolli'}, {'authorId': '1716440', 'name': 'Roger Wattenhofer'}]",['ETH Zurich'],['Switzerland'],2020-12
2101.00419,Zhao Meng,"Yiran Xing, Zai Shi, Zhao Meng, Gerhard Lakemeyer, Yunpu Ma, Roger
  Wattenhofer",KM-BART: Knowledge Enhanced Multimodal BART for Visual Commonsense Generation,"ACL-IJCNLP 2021 main conference. The first three authors contribute
  equally to this work",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present Knowledge Enhanced Multimodal BART (KM-BART), which is a Transformer-based sequence-to-sequence model capable of reasoning about commonsense knowledge from multimodal inputs of images and texts. We adapt the generative BART architecture to a multimodal model with visual and textual inputs. We further develop novel pretraining tasks to improve the model performance on the Visual Commonsense Generation (VCG) task. In particular, our pretraining task of Knowledge-based Commonsense Generation (KCG) boosts model performance on the VCG task by leveraging commonsense knowledge from a large language model pretrained on external commonsense knowledge graphs. To the best of our knowledge, we are the first to propose a dedicated task for improving model performance on the VCG task. Experimental results show that our model reaches state-of-the-art performance on the VCG task by applying these novel pretraining tasks. ","[{'version': 'v1', 'created': 'Sat, 2 Jan 2021 10:44:49 GMT'}, {'version': 'v2', 'created': 'Thu, 15 Jul 2021 21:33:21 GMT'}]",2021-07-19,"[['Xing', 'Yiran', ''], ['Shi', 'Zai', ''], ['Meng', 'Zhao', ''], ['Lakemeyer', 'Gerhard', ''], ['Ma', 'Yunpu', ''], ['Wattenhofer', 'Roger', '']]",0,0,2021-01-02,2,6,1,0,0,0,fe6e9bc5040a69e310d88677a1045a2fef640f48,230437551.0,https://www.semanticscholar.org/paper/fe6e9bc5040a69e310d88677a1045a2fef640f48,Annual Meeting of the Association for Computational Linguistics,2021.0,31.0,24.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': None, 'name': 'Yiran Xing'}, {'authorId': '91997154', 'name': 'Z. Shi'}, {'authorId': '144861196', 'name': 'Zhao Meng'}, {'authorId': '10684484', 'name': 'Yunpu Ma'}, {'authorId': '1716440', 'name': 'Roger Wattenhofer'}]","['RWTH Aachen University', 'ETH Zurich']","['Germany', 'Switzerland']",2021-01
2101.09157,Daniel Buschek,"Daniel Buschek, Martin Z\""urn, Malin Eiband",The Impact of Multiple Parallel Phrase Suggestions on Email Input and Composition Behaviour of Native and Non-Native English Writers,"21 pages, 4 figures, ACM CHI 2021",,10.1145/3411764.3445372,,cs.HC cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present an in-depth analysis of the impact of multi-word suggestion choices from a neural language model on user behaviour regarding input and text composition in email writing. Our study for the first time compares different numbers of parallel suggestions, and use by native and non-native English writers, to explore a trade-off of ""efficiency vs ideation"", emerging from recent literature. We built a text editor prototype with a neural language model (GPT-2), refined in a prestudy with 30 people. In an online study (N=156), people composed emails in four conditions (0/1/3/6 parallel suggestions). Our results reveal (1) benefits for ideation, and costs for efficiency, when suggesting multiple phrases; (2) that non-native speakers benefit more from more suggestions; and (3) further insights into behaviour patterns. We discuss implications for research, the design of interactive suggestion systems, and the vision of supporting writers with AI instead of replacing them. ","[{'version': 'v1', 'created': 'Fri, 22 Jan 2021 15:32:32 GMT'}]",2021-01-25,"[['Buschek', 'Daniel', ''], ['Zürn', 'Martin', ''], ['Eiband', 'Malin', '']]",0,1,2021-01-22,1,3,2,1,1,0,06a42e58686298a90a562d6375b952fe6c54dfc5,231693275.0,https://www.semanticscholar.org/paper/06a42e58686298a90a562d6375b952fe6c54dfc5,International Conference on Human Factors in Computing Systems,2021.0,80.0,52.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1768653', 'name': 'Daniel Buschek'}, {'authorId': '2096285539', 'name': 'Martin Zurn'}, {'authorId': '3396220', 'name': 'Malin Eiband'}]",['University of Bayreuth'],['Germany'],2021-01
2101.12462,Benjamin Marie,"Benjamin Marie, Atsushi Fujita",Synthesizing Monolingual Data for Neural Machine Translation,Preliminary work,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In neural machine translation (NMT), monolingual data in the target language are usually exploited through a method so-called ""back-translation"" to synthesize additional training parallel data. The synthetic data have been shown helpful to train better NMT, especially for low-resource language pairs and domains. Nonetheless, large monolingual data in the target domains or languages are not always available to generate large synthetic parallel data. In this work, we propose a new method to generate large synthetic parallel data leveraging very small monolingual data in a specific domain. We fine-tune a pre-trained GPT-2 model on such small in-domain monolingual data and use the resulting model to generate a large amount of synthetic in-domain monolingual data. Then, we perform back-translation, or forward translation, to generate synthetic in-domain parallel data. Our preliminary experiments on three language pairs and five domains show the effectiveness of our method to generate fully synthetic but useful in-domain parallel data for improving NMT in all configurations. We also show promising results in extreme adaptation for personalized NMT. ","[{'version': 'v1', 'created': 'Fri, 29 Jan 2021 08:17:40 GMT'}]",2021-02-01,"[['Marie', 'Benjamin', ''], ['Fujita', 'Atsushi', '']]",0,1,2021-01-29,1,2,1,1,1,0,3f8a02ef40c772a2f05a4689daa94c1cfa975495,231728613.0,https://www.semanticscholar.org/paper/3f8a02ef40c772a2f05a4689daa94c1cfa975495,arXiv.org,2021.0,18.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064068087', 'name': 'Benjamin Marie'}, {'authorId': '46566611', 'name': 'Atsushi Fujita'}]",['National Institute of Information and Communications Technology'],['Japan'],2021-01
2102.00875,Agrin Aram Hilmkil,"Agrin Hilmkil and Sebastian Callh and Matteo Barbieri and Leon Ren\'e
  S\""utfeld and Edvin Listo Zec and Olof Mogren",Scaling Federated Learning for Fine-tuning of Large Language Models,,,,,cs.LG cs.CL cs.DC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Federated learning (FL) is a promising approach to distributed compute, as well as distributed data, and provides a level of privacy and compliance to legal frameworks. This makes FL attractive for both consumer and healthcare applications. While the area is actively being explored, few studies have examined FL in the context of larger language models and there is a lack of comprehensive reviews of robustness across tasks, architectures, numbers of clients, and other relevant factors. In this paper, we explore the fine-tuning of Transformer-based language models in a federated learning setting. We evaluate three popular BERT-variants of different sizes (BERT, ALBERT, and DistilBERT) on a number of text classification tasks such as sentiment analysis and author identification. We perform an extensive sweep over the number of clients, ranging up to 32, to evaluate the impact of distributed compute on task performance in the federated averaging setting. While our findings suggest that the large sizes of the evaluated models are not generally prohibitive to federated training, we found that the different models handle federated averaging to a varying degree. Most notably, DistilBERT converges significantly slower with larger numbers of clients, and under some circumstances, even collapses to chance level performance. Investigating this issue presents an interesting perspective for future research. ","[{'version': 'v1', 'created': 'Mon, 1 Feb 2021 14:31:39 GMT'}]",2021-02-02,"[['Hilmkil', 'Agrin', ''], ['Callh', 'Sebastian', ''], ['Barbieri', 'Matteo', ''], ['Sütfeld', 'Leon René', ''], ['Zec', 'Edvin Listo', ''], ['Mogren', 'Olof', '']]",0,0,2021-02-01,1,6,3,0,0,0,a29d29095fa45a9ccac75ecd2a6ff7ad47a0b02f,231740914.0,https://www.semanticscholar.org/paper/a29d29095fa45a9ccac75ecd2a6ff7ad47a0b02f,International Conference on Applications of Natural Language to Data Bases,2021.0,28.0,16.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51215320', 'name': 'Agrin Hilmkil'}, {'authorId': '72185529', 'name': 'Sebastian Callh'}, {'authorId': '152192465', 'name': 'Matteo Barbieri'}, {'authorId': '19298650', 'name': 'L. R. Sütfeld'}, {'authorId': '52197229', 'name': 'Edvin Listo Zec'}, {'authorId': '2682635', 'name': 'Olof Mogren'}]",['RISE Research Institutes of Sweden'],['Sweden'],2021-02
2102.01645,Federico Galatolo,Federico A. Galatolo and Mario G.C.A. Cimino and Gigliola Vaglini,Generating images from caption and vice versa via CLIP-Guided Generative Latent Space Search,,"IMPROVE, ISBN 978-989-758-511-1, pages 166-174 (2021)",10.5220/0010503701660174,,cs.NE cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this research work we present CLIP-GLaSS, a novel zero-shot framework to generate an image (or a caption) corresponding to a given caption (or image). CLIP-GLaSS is based on the CLIP neural network, which, given an image and a descriptive caption, provides similar embeddings. Differently, CLIP-GLaSS takes a caption (or an image) as an input, and generates the image (or the caption) whose CLIP embedding is the most similar to the input one. This optimal image (or caption) is produced via a generative network, after an exploration by a genetic algorithm. Promising results are shown, based on the experimentation of the image Generators BigGAN and StyleGAN2, and of the text Generator GPT2 ","[{'version': 'v1', 'created': 'Tue, 2 Feb 2021 18:00:13 GMT'}, {'version': 'v2', 'created': 'Wed, 3 Feb 2021 12:14:49 GMT'}, {'version': 'v3', 'created': 'Fri, 26 Feb 2021 22:42:49 GMT'}, {'version': 'v4', 'created': 'Fri, 1 Oct 2021 15:45:51 GMT'}]",2021-10-04,"[['Galatolo', 'Federico A.', ''], ['Cimino', 'Mario G. C. A.', ''], ['Vaglini', 'Gigliola', '']]",0,1,2021-02-02,4,3,3,1,1,0,33e8cad403a52ad10d0fe418ff980760401e869f,231749958.0,https://www.semanticscholar.org/paper/33e8cad403a52ad10d0fe418ff980760401e869f,International Conference on Image Processing and Vision Engineering,2021.0,19.0,62.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '10758628', 'name': 'Federico A. Galatolo'}, {'authorId': '145432506', 'name': 'M. Cimino'}, {'authorId': '1809381', 'name': 'G. Vaglini'}]",['University of Pisa'],['Italy'],2021-02
2102.05126,Jon\'a\v{s} Kulh\'anek,"Jon\'a\v{s} Kulh\'anek and Vojt\v{e}ch Hude\v{c}ek and Tom\'a\v{s}
  Nekvinda and Ond\v{r}ej Du\v{s}ek",AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialogue with Pre-Trained Language Models,,"Proceedings of the 3rd Workshop on Natural Language Processing for
  Conversational AI (2021), 198-210",10.18653/v1/2021.nlp4convai-1.19,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Attention-based pre-trained language models such as GPT-2 brought considerable progress to end-to-end dialogue modelling. However, they also present considerable risks for task-oriented dialogue, such as lack of knowledge grounding or diversity. To address these issues, we introduce modified training objectives for language model finetuning, and we employ massive data augmentation via back-translation to increase the diversity of the training data. We further examine the possibilities of combining data from multiples sources to improve performance on the target dataset. We carefully evaluate our contributions with both human and automatic methods. Our model substantially outperforms the baseline on the MultiWOZ data and shows competitive performance with state of the art in both automatic and human evaluation. ","[{'version': 'v1', 'created': 'Tue, 9 Feb 2021 20:53:34 GMT'}, {'version': 'v2', 'created': 'Mon, 27 Sep 2021 08:28:40 GMT'}, {'version': 'v3', 'created': 'Fri, 14 Jan 2022 14:42:11 GMT'}]",2022-01-17,"[['Kulhánek', 'Jonáš', ''], ['Hudeček', 'Vojtěch', ''], ['Nekvinda', 'Tomáš', ''], ['Dušek', 'Ondřej', '']]",0,1,2021-02-09,3,4,3,1,1,0,3ebd251e5307e91adc009c0515ea5c8e3ef44344,237940600.0,https://www.semanticscholar.org/paper/3ebd251e5307e91adc009c0515ea5c8e3ef44344,NLP4CONVAI,2021.0,45.0,21.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2129468612', 'name': ""Jon'avs Kulh'anek""}, {'authorId': '2129445909', 'name': 'Vojtvech Hudevcek'}, {'authorId': '2129463741', 'name': ""Tom'avs Nekvinda""}, {'authorId': '2544049', 'name': 'Ondrej Dusek'}]","['Charles University', 'Institute of Informatics', 'Czech Technical University in Prague']","['Czechia', 'Slovakia']",2021-02
2102.07266,Jaskirat Singh,"Jaskirat Singh, Liang Zheng",Sparse Attention Guided Dynamic Value Estimation for Single-Task Multi-Scene Reinforcement Learning,This work is a merger of arXiv:2005.12254 and arXiv:2011.12574,,,,cs.LG cs.AI cs.RO stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Training deep reinforcement learning agents on environments with multiple levels / scenes from the same task, has become essential for many applications aiming to achieve generalization and domain transfer from simulation to the real world. While such a strategy is helpful with generalization, the use of multiple scenes significantly increases the variance of samples collected for policy gradient computations. Current methods, effectively continue to view this collection of scenes as a single Markov decision process (MDP), and thus learn a scene-generic value function V(s). However, we argue that the sample variance for a multi-scene environment is best minimized by treating each scene as a distinct MDP, and then learning a joint value function V(s,M) dependent on both state s and MDP M. We further demonstrate that the true joint value function for a multi-scene environment, follows a multi-modal distribution which is not captured by traditional CNN / LSTM based critic networks. To this end, we propose a dynamic value estimation (DVE) technique, which approximates the true joint value function through a sparse attention mechanism over multiple value function hypothesis / modes. The resulting agent not only shows significant improvements in the final reward score across a range of OpenAI ProcGen environments, but also exhibits enhanced navigation efficiency and provides an implicit mechanism for unsupervised state-space skill decomposition. ","[{'version': 'v1', 'created': 'Sun, 14 Feb 2021 23:30:13 GMT'}]",2021-02-16,"[['Singh', 'Jaskirat', ''], ['Zheng', 'Liang', '']]",0,0,2021-02-14,1,2,4,0,0,0,b273b2f7086e3a6a6b64045f7a6f710d40d751bf,218870112.0,https://www.semanticscholar.org/paper/b273b2f7086e3a6a6b64045f7a6f710d40d751bf,arXiv.org,2021.0,41.0,3.0,0.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112713578', 'name': 'Jaskirat Singh'}, {'authorId': '144802394', 'name': 'Liang Zheng'}]",['Australian National University'],['Australia'],2021-02
2102.07536,"Nils K\""obis C","Margarita Leib, Nils C. K\""obis, Rainer Michael Rilke, Marloes Hagens,
  Bernd Irlenbusch",The corruptive force of AI-generated advice,"Leib & K\""obis share first authorship",,,,cs.AI econ.GN q-fin.EC,http://creativecommons.org/licenses/by/4.0/,"  Artificial Intelligence (AI) is increasingly becoming a trusted advisor in people's lives. A new concern arises if AI persuades people to break ethical rules for profit. Employing a large-scale behavioural experiment (N = 1,572), we test whether AI-generated advice can corrupt people. We further test whether transparency about AI presence, a commonly proposed policy, mitigates potential harm of AI-generated advice. Using the Natural Language Processing algorithm, GPT-2, we generated honesty-promoting and dishonesty-promoting advice. Participants read one type of advice before engaging in a task in which they could lie for profit. Testing human behaviour in interaction with actual AI outputs, we provide first behavioural insights into the role of AI as an advisor. Results reveal that AI-generated advice corrupts people, even when they know the source of the advice. In fact, AI's corrupting force is as strong as humans'. ","[{'version': 'v1', 'created': 'Mon, 15 Feb 2021 13:15:12 GMT'}]",2021-02-16,"[['Leib', 'Margarita', ''], ['Köbis', 'Nils C.', ''], ['Rilke', 'Rainer Michael', ''], ['Hagens', 'Marloes', ''], ['Irlenbusch', 'Bernd', '']]",0,1,2021-02-15,1,5,3,1,1,0,a730b5514ffdd49add80af31c7c40565d397bb4d,231924583.0,https://www.semanticscholar.org/paper/a730b5514ffdd49add80af31c7c40565d397bb4d,arXiv.org,2021.0,33.0,5.0,0.0,False,"['Computer Science', 'Economics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","[{'authorId': '31828515', 'name': 'Margarita Leib'}, {'authorId': '47691963', 'name': 'N. Köbis'}, {'authorId': '39213872', 'name': 'Rainer Michael Rilke'}, {'authorId': '6130070', 'name': 'Marloes H. J. Hagens'}, {'authorId': '2346763', 'name': 'Bernd Irlenbusch'}]","['University of Amsterdam', 'WHU – Otto Beisheim School of Management', 'Max Planck Institute for Human Development', 'University of Cologne']","['Germany', 'Netherlands']",2021-02
2102.08036,Anil Bas,"M. Onat Topal, Anil Bas, Imke van Heerden","Exploring Transformers in Natural Language Generation: GPT, BERT, and XLNet",Accepted as oral presentation to ICIDAAI 2021 - Short Paper,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent years have seen a proliferation of attention mechanisms and the rise of Transformers in Natural Language Generation (NLG). Previously, state-of-the-art NLG architectures such as RNN and LSTM ran into vanishing gradient problems; as sentences grew larger, distance between positions remained linear, and sequential computation hindered parallelization since sentences were processed word by word. Transformers usher in a new era. In this paper, we explore three major Transformer-based models, namely GPT, BERT, and XLNet, that carry significant implications for the field. NLG is a burgeoning area that is now bolstered with rapid developments in attention mechanisms. From poetry generation to summarization, text generation derives benefit as Transformer-based language models achieve groundbreaking results. ","[{'version': 'v1', 'created': 'Tue, 16 Feb 2021 09:18:16 GMT'}]",2021-02-17,"[['Topal', 'M. Onat', ''], ['Bas', 'Anil', ''], ['van Heerden', 'Imke', '']]",0,1,2021-02-16,1,3,2,0,0,0,ba900412ab47fd890e69bfa7e909d34ae476b870,231933669.0,https://www.semanticscholar.org/paper/ba900412ab47fd890e69bfa7e909d34ae476b870,arXiv.org,2021.0,32.0,45.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2059782770', 'name': 'M. O. Topal'}, {'authorId': '39180407', 'name': 'Anil Bas'}, {'authorId': '84734726', 'name': 'Imke van Heerden'}]","['Middle East Technical University', 'Koç University', 'Marmara University']",['Turkey'],2021-02
2102.12162,Ngoc Tran,"Quang Huu Pham, Viet Anh Nguyen, Linh Bao Doan, Ngoc N. Tran and Ta
  Minh Thanh",From Universal Language Model to Downstream Task: Improving RoBERTa-Based Vietnamese Hate Speech Detection,"Published in 2020 12th International Conference on Knowledge and
  Systems Engineering (KSE)","2020 12th International Conference on Knowledge and Systems
  Engineering (KSE), Can Tho, Vietnam, 2020, pp. 37-42",10.1109/KSE50997.2020.9287406,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Natural language processing is a fast-growing field of artificial intelligence. Since the Transformer was introduced by Google in 2017, a large number of language models such as BERT, GPT, and ELMo have been inspired by this architecture. These models were trained on huge datasets and achieved state-of-the-art results on natural language understanding. However, fine-tuning a pre-trained language model on much smaller datasets for downstream tasks requires a carefully-designed pipeline to mitigate problems of the datasets such as lack of training data and imbalanced data. In this paper, we propose a pipeline to adapt the general-purpose RoBERTa language model to a specific text classification task: Vietnamese Hate Speech Detection. We first tune the PhoBERT on our dataset by re-training the model on the Masked Language Model task; then, we employ its encoder for text classification. In order to preserve pre-trained weights while learning new feature representations, we further utilize different training techniques: layer freezing, block-wise learning rate, and label smoothing. Our experiments proved that our proposed pipeline boosts the performance significantly, achieving a new state-of-the-art on Vietnamese Hate Speech Detection campaign with 0.7221 F1 score. ","[{'version': 'v1', 'created': 'Wed, 24 Feb 2021 09:30:55 GMT'}]",2021-02-25,"[['Pham', 'Quang Huu', ''], ['Nguyen', 'Viet Anh', ''], ['Doan', 'Linh Bao', ''], ['Tran', 'Ngoc N.', ''], ['Thanh', 'Ta Minh', '']]",0,1,2021-02-24,1,5,2,0,0,0,bcafdf8ca05a49cb15ccfbe35f0c6103b8cb8849,229308744.0,https://www.semanticscholar.org/paper/bcafdf8ca05a49cb15ccfbe35f0c6103b8cb8849,International Conference on Knowledge and Systems Engineering,2020.0,38.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1417577699', 'name': 'Quang Huu Pham'}, {'authorId': '2147318719', 'name': 'Viet-Anh Nguyen'}, {'authorId': '2038525122', 'name': 'Linh Bao Doan'}, {'authorId': '2050211200', 'name': 'Ngoc N. Tran'}, {'authorId': '2276973', 'name': 'Ta Minh Thanh'}]","['R&D Lab, Sun Asterisk Inc', 'Le Quy Don Technical University']",['Vietnam'],2021-02
2102.12206,Eyal Ben-David,"Eyal Ben-David, Nadav Oved, Roi Reichart",PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains,"Accepted for publication at TACL in January 2022. First two authors
  contributed equally to this work. Our code and data are available at:
  https://github.com/eyalbd2/PADA",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Natural Language Processing algorithms have made incredible progress, but they still struggle when applied to out-of-distribution examples. We address a challenging and underexplored version of this domain adaptation problem, where an algorithm is trained on several source domains, and then applied to examples from unseen domains that are unknown at training time. Particularly, no examples, labeled or unlabeled, or any other knowledge about the target domain are available to the algorithm at training time. We present PADA: An example-based autoregressive Prompt learning algorithm for on-the-fly Any-Domain Adaptation, based on the T5 language model. Given a test example, PADA first generates a unique prompt for it and then, conditioned on this prompt, labels the example with respect to the NLP prediction task. PADA is trained to generate a prompt which is a token sequence of unrestricted length, consisting of Domain Related Features (DRFs) that characterize each of the source domains. Intuitively, the generated prompt is a unique signature that maps the test example to a semantic space spanned by the source domains. In experiments with 3 tasks (text classification and sequence tagging), for a total of 14 multi-source adaptation scenarios, PADA substantially outperforms strong baselines. ","[{'version': 'v1', 'created': 'Wed, 24 Feb 2021 11:02:29 GMT'}, {'version': 'v2', 'created': 'Wed, 12 May 2021 06:01:21 GMT'}, {'version': 'v3', 'created': 'Wed, 19 Jan 2022 10:20:58 GMT'}, {'version': 'v4', 'created': 'Thu, 27 Jan 2022 06:47:56 GMT'}]",2022-01-28,"[['Ben-David', 'Eyal', ''], ['Oved', 'Nadav', ''], ['Reichart', 'Roi', '']]",0,0,2021-02-24,4,3,3,1,1,0,e403faa971e2c750999a3d10bef8b01dd3e85f7b,246062387.0,https://www.semanticscholar.org/paper/e403faa971e2c750999a3d10bef8b01dd3e85f7b,Transactions of the Association for Computational Linguistics,2021.0,83.0,54.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2031088828', 'name': 'Eyal Ben-David'}, {'authorId': '1382650252', 'name': 'Nadav Oved'}, {'authorId': '1762757', 'name': 'Roi Reichart'}]",['Technion – Israel Institute of Technology'],['Israel'],2021-02
2103.12407,Rohan Alexander,"Ke-Li Chiu, Annie Collins, Rohan Alexander",Detecting Hate Speech with GPT-3,"29 pages, 1 figure, 23 tables 24 March 2022: Re-submission changes
  the modelling to occur multiple times and adds standard errors",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Sophisticated language models such as OpenAI's GPT-3 can generate hateful text that targets marginalized groups. Given this capacity, we are interested in whether large language models can be used to identify hate speech and classify text as sexist or racist. We use GPT-3 to identify sexist and racist text passages with zero-, one-, and few-shot learning. We find that with zero- and one-shot learning, GPT-3 can identify sexist or racist text with an average accuracy between 55 per cent and 67 per cent, depending on the category of text and type of learning. With few-shot learning, the model's accuracy can be as high as 85 per cent. Large language models have a role to play in hate speech detection, and with further development they could eventually be used to counter hate speech. ","[{'version': 'v1', 'created': 'Tue, 23 Mar 2021 09:17:22 GMT'}, {'version': 'v2', 'created': 'Thu, 4 Nov 2021 15:31:09 GMT'}, {'version': 'v3', 'created': 'Wed, 16 Mar 2022 13:14:51 GMT'}, {'version': 'v4', 'created': 'Thu, 24 Mar 2022 16:24:54 GMT'}]",2022-03-25,"[['Chiu', 'Ke-Li', ''], ['Collins', 'Annie', ''], ['Alexander', 'Rohan', '']]",0,1,2021-03-23,4,3,1,1,0,1,098370508aaf56f718a472511987ac2072d0f917,232320738.0,https://www.semanticscholar.org/paper/098370508aaf56f718a472511987ac2072d0f917,arXiv.org,2021.0,27.0,48.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2046836587', 'name': 'Ke-Li Chiu'}, {'authorId': '2106077255', 'name': 'Rohan Alexander'}]",['University of Toronto'],['Canada'],2021-03
2103.16063,Masahiro Tanaka,"Masahiro Tanaka, Kenjiro Taura, Toshihiro Hanawa, Kentaro Torisawa",Automatic Graph Partitioning for Very Large-scale Deep Learning,"Accepted to the 35th IEEE International Parallel and Distributed
  Processing Symposium (IPDPS 2021), May 2021",,,,cs.LG cs.DC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work proposes RaNNC (Rapid Neural Network Connector) as middleware for automatic hybrid parallelism. In recent deep learning research, as exemplified by T5 and GPT-3, the size of neural network models continues to grow. Since such models do not fit into the memory of accelerator devices, they need to be partitioned by model parallelism techniques. Moreover, to accelerate training for huge training data, we need a combination of model and data parallelisms, i.e., hybrid parallelism. Given a model description for PyTorch without any specification for model parallelism, RaNNC automatically partitions the model into a set of subcomponents so that (1) each subcomponent fits a device memory and (2) a high training throughput for pipeline parallelism is achieved by balancing the computation times of the subcomponents. In our experiments, we compared RaNNC with two popular frameworks, Megatron-LM (hybrid parallelism) and GPipe (originally proposed for model parallelism, but a version allowing hybrid parallelism also exists), for training models with increasingly greater numbers of parameters. In the pre-training of enlarged BERT models, RaNNC successfully trained models five times larger than those Megatron-LM could, and RaNNC's training throughputs were comparable to Megatron-LM's when pre-training the same models. RaNNC also achieved better training throughputs than GPipe on both the enlarged BERT model pre-training (GPipe with hybrid parallelism) and the enlarged ResNet models (GPipe with model parallelism) in all of the settings we tried. These results are remarkable, since RaNNC automatically partitions models without any modification to their descriptions; Megatron-LM and GPipe require users to manually rewrite the models' descriptions. ","[{'version': 'v1', 'created': 'Tue, 30 Mar 2021 04:26:04 GMT'}]",2021-03-31,"[['Tanaka', 'Masahiro', ''], ['Taura', 'Kenjiro', ''], ['Hanawa', 'Toshihiro', ''], ['Torisawa', 'Kentaro', '']]",0,1,2021-03-30,1,4,2,2,1,1,b0d692d8f9b5245b8fa35a6993f77a083e8a5067,232417087.0,https://www.semanticscholar.org/paper/b0d692d8f9b5245b8fa35a6993f77a083e8a5067,IEEE International Parallel and Distributed Processing Symposium,2021.0,29.0,11.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2110304080', 'name': 'Masahiro Tanaka'}, {'authorId': '1724468', 'name': 'K. Taura'}, {'authorId': '2174508', 'name': 'T. Hanawa'}, {'authorId': '1768754', 'name': 'Kentaro Torisawa'}]","['National Institute of Information and Communications Technology', 'The University of Tokyo']",['Japan'],2021-03
2103.16223,"Arthur M\""uller","Arthur M\""uller, Vishal Rangras, Georg Schnittker, Michael Waldmann,
  Maxim Friesen, Tobias Ferfers, Lukas Schreckenberg, Florian Hufen, J\""urgen
  Jasperneite, Marco Wiering",Towards Real-World Deployment of Reinforcement Learning for Traffic Signal Control,"Paper was accepted by ICMLA 2021 (20th IEEE International Conference
  on Machine Learning and Applications). Code available under
  https://github.com/RL-INA/LemgoRL",,,,cs.LG cs.SY eess.SY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sub-optimal control policies in intersection traffic signal controllers (TSC) contribute to congestion and lead to negative effects on human health and the environment. Reinforcement learning (RL) for traffic signal control is a promising approach to design better control policies and has attracted considerable research interest in recent years. However, most work done in this area used simplified simulation environments of traffic scenarios to train RL-based TSC. To deploy RL in real-world traffic systems, the gap between simplified simulation environments and real-world applications has to be closed. Therefore, we propose LemgoRL, a benchmark tool to train RL agents as TSC in a realistic simulation environment of Lemgo, a medium-sized town in Germany. In addition to the realistic simulation model, LemgoRL encompasses a traffic signal logic unit that ensures compliance with all regulatory and safety requirements. LemgoRL offers the same interface as the wellknown OpenAI gym toolkit to enable easy deployment in existing research work. To demonstrate the functionality and applicability of LemgoRL, we train a state-of-the-art Deep RL algorithm on a CPU cluster utilizing a framework for distributed and parallel RL and compare its performance with other methods. Our benchmark tool drives the development of RL algorithms towards real-world applications. ","[{'version': 'v1', 'created': 'Tue, 30 Mar 2021 10:11:09 GMT'}, {'version': 'v2', 'created': 'Wed, 16 Jun 2021 09:09:50 GMT'}, {'version': 'v3', 'created': 'Tue, 11 Jan 2022 10:47:28 GMT'}]",2022-01-12,"[['Müller', 'Arthur', ''], ['Rangras', 'Vishal', ''], ['Schnittker', 'Georg', ''], ['Waldmann', 'Michael', ''], ['Friesen', 'Maxim', ''], ['Ferfers', 'Tobias', ''], ['Schreckenberg', 'Lukas', ''], ['Hufen', 'Florian', ''], ['Jasperneite', 'Jürgen', ''], ['Wiering', 'Marco', '']]",0,0,2021-03-30,3,10,3,0,0,0,9fa762144cffb68a86382568decd1a69fea28f1e,245853538.0,https://www.semanticscholar.org/paper/9fa762144cffb68a86382568decd1a69fea28f1e,International Conference on Machine Learning and Applications,2021.0,19.0,10.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064269709', 'name': 'A. Muller'}, {'authorId': '31082156', 'name': 'Vishal S. Rangras'}, {'authorId': '2061138987', 'name': 'Georg Schnittker'}, {'authorId': '2066088448', 'name': 'Michael Waldmann'}, {'authorId': '41068972', 'name': 'Maxim Friesen'}, {'authorId': '2061137959', 'name': 'Tobias Ferfers'}, {'authorId': '2061138721', 'name': 'Lukas Schreckenberg'}, {'authorId': '2061138973', 'name': 'Florian Hufen'}, {'authorId': '9265930', 'name': 'J. Jasperneite'}, {'authorId': '32239759', 'name': 'M. Wiering'}]","['Ostwestfalen-Lippe University of Applied Sciences and Arts', 'Fraunhofer Institute of Optronics, System Technologies and Image Exploitation', 'Stührenberg GmbH Detmold, Germany', 'University of Groningen']","['Germany', 'Netherlands']",2021-03
2104.00933,Avik Pal,"Aishwarya Gupta, Avik Pal, Bholeshwar Khurana, Lakshay Tyagi, Ashutosh
  Modi",Humor@IITK at SemEval-2021 Task 7: Large Language Models for Quantifying Humor and Offensiveness,"Accepted at SemEval 2021 Task 7, 7 Pages (6 Pages main content + 2
  pages for references)",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Humor and Offense are highly subjective due to multiple word senses, cultural knowledge, and pragmatic competence. Hence, accurately detecting humorous and offensive texts has several compelling use cases in Recommendation Systems and Personalized Content Moderation. However, due to the lack of an extensive labeled dataset, most prior works in this domain haven't explored large neural models for subjective humor understanding. This paper explores whether large neural models and their ensembles can capture the intricacies associated with humor/offense detection and rating. Our experiments on the SemEval-2021 Task 7: HaHackathon show that we can develop reasonable humor and offense detection systems with such models. Our models are ranked third in subtask 1b and consistently ranked around the top 33% of the leaderboard for the remaining subtasks. ","[{'version': 'v1', 'created': 'Fri, 2 Apr 2021 08:22:02 GMT'}]",2021-04-05,"[['Gupta', 'Aishwarya', ''], ['Pal', 'Avik', ''], ['Khurana', 'Bholeshwar', ''], ['Tyagi', 'Lakshay', ''], ['Modi', 'Ashutosh', '']]",0,0,2021-04-02,1,5,1,0,0,0,5c9319f12921a974c83a66fa4b09efb6afd0eeb0,233004478.0,https://www.semanticscholar.org/paper/5c9319f12921a974c83a66fa4b09efb6afd0eeb0,International Workshop on Semantic Evaluation,2021.0,35.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50179019', 'name': 'Aishwarya Gupta'}, {'authorId': '9308965', 'name': 'Avik Pal'}, {'authorId': '2063800275', 'name': 'Bholeshwar Khurana'}, {'authorId': '1712142370', 'name': 'Lakshay Tyagi'}, {'authorId': '2477939', 'name': 'Ashutosh Modi'}]",['Indian Institute of Technology Kanpur'],['India'],2021-04
2104.04466,Weizhe Lin,"Weizhe Lin, Bo-Hsiang Tseng, Bill Byrne",Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking,"This paper is in the Proceedings of the 2021 Conference on Empirical
  Methods in Natural Language Processing (EMNLP 2021)",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dialogue State Tracking is central to multi-domain task-oriented dialogue systems, responsible for extracting information from user utterances. We present a novel hybrid architecture that augments GPT-2 with representations derived from Graph Attention Networks in such a way to allow causal, sequential prediction of slot values. The model architecture captures inter-slot relationships and dependencies across domains that otherwise can be lost in sequential prediction. We report improvements in state tracking performance in MultiWOZ 2.0 against a strong GPT-2 baseline and investigate a simplified sparse training scenario in which DST models are trained only on session-level annotations but evaluated at the turn level. We further report detailed analyses to demonstrate the effectiveness of graph models in DST by showing that the proposed graph modules capture inter-slot dependencies and improve the predictions of values that are common to multiple domains. ","[{'version': 'v1', 'created': 'Fri, 9 Apr 2021 16:27:34 GMT'}, {'version': 'v2', 'created': 'Thu, 2 Sep 2021 15:12:07 GMT'}, {'version': 'v3', 'created': 'Thu, 23 Sep 2021 15:42:15 GMT'}]",2021-09-24,"[['Lin', 'Weizhe', ''], ['Tseng', 'Bo-Hsiang', ''], ['Byrne', 'Bill', '']]",0,1,2021-04-09,3,3,2,1,1,0,5150e2febe2cfafe0ac8b557cc1ff117aac9b93d,233204575.0,https://www.semanticscholar.org/paper/5150e2febe2cfafe0ac8b557cc1ff117aac9b93d,Conference on Empirical Methods in Natural Language Processing,2021.0,26.0,24.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1454363000', 'name': 'Weizhe Lin'}, {'authorId': '144493108', 'name': 'B-H Tseng'}, {'authorId': '36126076', 'name': 'B. Byrne'}]",['University of Cambridge'],['United Kingdom'],2021-04
2104.05433,Nora Hollenstein,"Nora Hollenstein, Federico Pirovano, Ce Zhang, Lena J\""ager and Lisa
  Beinborn",Multilingual Language Models Predict Human Reading Behavior,accepted at NAACL 2021,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We analyze if large language models are able to predict patterns of human reading behavior. We compare the performance of language-specific and multilingual pretrained transformer models to predict reading time measures reflecting natural human sentence processing on Dutch, English, German, and Russian texts. This results in accurate models of human reading behavior, which indicates that transformer models implicitly encode relative importance in language in a way that is comparable to human processing mechanisms. We find that BERT and XLM models successfully predict a range of eye tracking features. In a series of experiments, we analyze the cross-domain and cross-language abilities of these models and show how they reflect human sentence processing. ","[{'version': 'v1', 'created': 'Mon, 12 Apr 2021 13:03:49 GMT'}]",2021-04-13,"[['Hollenstein', 'Nora', ''], ['Pirovano', 'Federico', ''], ['Zhang', 'Ce', ''], ['Jäger', 'Lena', ''], ['Beinborn', 'Lisa', '']]",0,0,2021-04-12,1,5,1,0,0,0,2fcee98165b4e3e059cda62b05e5a56b843a4b9f,233210761.0,https://www.semanticscholar.org/paper/2fcee98165b4e3e059cda62b05e5a56b843a4b9f,North American Chapter of the Association for Computational Linguistics,2021.0,66.0,27.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3191620', 'name': 'Nora Hollenstein'}, {'authorId': '1781788981', 'name': 'Federico Pirovano'}, {'authorId': '1776014', 'name': 'Ce Zhang'}, {'authorId': '2060148121', 'name': 'L. Jäger'}, {'authorId': '2752573', 'name': 'Lisa Beinborn'}]","['Vrije Universiteit Amsterdam', 'University of Zurich', 'University of Potsdam']","['Germany', 'Netherlands', 'Switzerland']",2021-04
2104.06182,Jose Manuel Gomez-Perez,"Andres Garcia-Silva, Cristian Berrio, Jose Manuel Gomez-Perez",Understanding Transformers for Bot Detection in Twitter,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper we shed light on the impact of fine-tuning over social media data in the internal representations of neural language models. We focus on bot detection in Twitter, a key task to mitigate and counteract the automatic spreading of disinformation and bias in social media. We investigate the use of pre-trained language models to tackle the detection of tweets generated by a bot or a human account based exclusively on its content. Unlike the general trend in benchmarks like GLUE, where BERT generally outperforms generative transformers like GPT and GPT-2 for most classification tasks on regular text, we observe that fine-tuning generative transformers on a bot detection task produces higher accuracies. We analyze the architectural components of each transformer and study the effect of fine-tuning on their hidden states and output representations. Among our findings, we show that part of the syntactical information and distributional properties captured by BERT during pre-training is lost upon fine-tuning while the generative pre-training approach manage to preserve these properties. ","[{'version': 'v1', 'created': 'Tue, 13 Apr 2021 13:32:55 GMT'}]",2021-04-14,"[['Garcia-Silva', 'Andres', ''], ['Berrio', 'Cristian', ''], ['Gomez-Perez', 'Jose Manuel', '']]",0,1,2021-04-13,1,3,2,1,1,0,b43b6eccea45eb485305dbfc20aa6f994e065490,233219846.0,https://www.semanticscholar.org/paper/b43b6eccea45eb485305dbfc20aa6f994e065490,arXiv.org,2021.0,39.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1401950156', 'name': 'Andres Garcia-Silva'}, {'authorId': '2064324876', 'name': 'Cristian Berrio'}, {'authorId': '2420472', 'name': 'José Manuél Gómez-Pérez'}]","['Expert.ai Research Lab Prof. Waksman 10 28036 Madrid, Spain']",['Spain'],2021-04
2104.07483,El Moatez Billah Nagoudi,"El Moatez Billah Nagoudi, Wei-Rui Chen, Muhammad Abdul-Mageed and
  Hasan Cavusogl",IndT5: A Text-to-Text Transformer for 10 Indigenous Languages,"Accepted in AmericasNLP 2021, co-located with NAACL-HLT 2021",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transformer language models have become fundamental components of natural language processing based pipelines. Although several Transformer models have been introduced to serve many languages, there is a shortage of models pre-trained for low-resource and Indigenous languages. In this work, we introduce IndT5, the first Transformer language model for Indigenous languages. To train IndT5, we build IndCorpus--a new dataset for ten Indigenous languages and Spanish. We also present the application of IndT5 to machine translation by investigating different approaches to translate between Spanish and the Indigenous languages as part of our contribution to the AmericasNLP 2021 Shared Task on Open Machine Translation. IndT5 and IndCorpus are publicly available for research ","[{'version': 'v1', 'created': 'Sun, 4 Apr 2021 07:09:09 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Apr 2021 09:07:50 GMT'}]",2021-04-28,"[['Nagoudi', 'El Moatez Billah', ''], ['Chen', 'Wei-Rui', ''], ['Abdul-Mageed', 'Muhammad', ''], ['Cavusogl', 'Hasan', '']]",0,0,2021-04-04,2,4,1,0,0,0,6fd41ee12ae828bb7de965bf7e06bb1bd5259fe7,233240686.0,https://www.semanticscholar.org/paper/6fd41ee12ae828bb7de965bf7e06bb1bd5259fe7,AMERICASNLP,2021.0,29.0,13.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '17771023', 'name': 'El Moatez Billah Nagoudi'}, {'authorId': '2109629098', 'name': 'Wei-Rui Chen'}, {'authorId': '2065312024', 'name': 'M. Abdul-Mageed'}, {'authorId': '3293728', 'name': 'H. Cavusoglu'}]","['University of British Columbia', 'Natural Language Processing Lab, 1,']",['Canada'],2021-04
2104.07705,Peter Izsak,"Peter Izsak, Moshe Berchansky, Omer Levy",How to Train BERT with an Academic Budget,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large language models a la BERT are used ubiquitously in NLP, pretraining them is considered a luxury that only a few well-funded industry labs can afford. How can one train such models with a more modest budget? We present a recipe for pretraining a masked language model in 24 hours using a single low-end deep learning server. We demonstrate that through a combination of software optimizations, design choices, and hyperparameter tuning, it is possible to produce models that are competitive with BERT-base on GLUE tasks at a fraction of the original pretraining cost. ","[{'version': 'v1', 'created': 'Thu, 15 Apr 2021 18:17:12 GMT'}, {'version': 'v2', 'created': 'Thu, 9 Sep 2021 13:55:14 GMT'}]",2021-09-10,"[['Izsak', 'Peter', ''], ['Berchansky', 'Moshe', ''], ['Levy', 'Omer', '']]",0,0,2021-04-15,2,3,3,0,0,0,7694aae9766d5f1fe74d900cd82aee898cb6e8e9,233289750.0,https://www.semanticscholar.org/paper/7694aae9766d5f1fe74d900cd82aee898cb6e8e9,Conference on Empirical Methods in Natural Language Processing,2021.0,42.0,65.0,10.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2477428', 'name': 'Peter Izsak'}, {'authorId': '2077591838', 'name': 'Moshe Berchansky'}, {'authorId': '39455775', 'name': 'Omer Levy'}]","['Tel Aviv University', 'Intel']",['Israel'],2021-04
2104.08786,Yao Lu,"Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, Pontus
  Stenetorp",Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity,ACL 2022,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models. We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are ""fantastic"" and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true few-shot setting as it requires additional annotated data. Instead, we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts. Our method yields a 13% relative improvement for GPT-family models across eleven different established text classification tasks. ","[{'version': 'v1', 'created': 'Sun, 18 Apr 2021 09:29:16 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Mar 2022 12:10:58 GMT'}]",2022-03-04,"[['Lu', 'Yao', ''], ['Bartolo', 'Max', ''], ['Moore', 'Alastair', ''], ['Riedel', 'Sebastian', ''], ['Stenetorp', 'Pontus', '']]",0,1,2021-04-18,2,5,2,1,0,1,0adec918885dff698acf359988ed79a543157f80,233296494.0,https://www.semanticscholar.org/paper/0adec918885dff698acf359988ed79a543157f80,Annual Meeting of the Association for Computational Linguistics,2021.0,32.0,468.0,38.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': None, 'name': 'Yao Lu'}, {'authorId': '153408953', 'name': 'Max Bartolo'}, {'authorId': '51114267', 'name': 'Alastair Moore'}, {'authorId': '145941665', 'name': 'S. Riedel'}, {'authorId': '1918552', 'name': 'Pontus Stenetorp'}]",['University College London'],['United Kingdom'],2021-04
2104.08826,Kang Min Yoo,"Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, Woomyeong Park",GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation,"Accepted to EMNLP2021 Findings; 11 pages, 7 tables, 2 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large-scale language models such as GPT-3 are excellent few-shot learners, allowing them to be controlled via natural text prompts. Recent studies report that prompt-based direct classification eliminates the need for fine-tuning but lacks data and inference scalability. This paper proposes a novel data augmentation technique that leverages large-scale language models to generate realistic text samples from a mixture of real samples. We also propose utilizing soft-labels predicted by the language models, effectively distilling knowledge from the large-scale language models and creating textual perturbations simultaneously. We perform data augmentation experiments on diverse classification tasks and show that our method hugely outperforms existing text augmentation methods. Ablation studies and a qualitative analysis provide more insights into our approach. ","[{'version': 'v1', 'created': 'Sun, 18 Apr 2021 11:39:33 GMT'}, {'version': 'v2', 'created': 'Thu, 18 Nov 2021 07:56:58 GMT'}]",2021-11-19,"[['Yoo', 'Kang Min', ''], ['Park', 'Dongju', ''], ['Kang', 'Jaewook', ''], ['Lee', 'Sang-Woo', ''], ['Park', 'Woomyeong', '']]",0,1,2021-04-18,2,5,2,1,0,1,bbfdcbfee1762d48cae9db8637f21ea3c234ba30,233296100.0,https://www.semanticscholar.org/paper/bbfdcbfee1762d48cae9db8637f21ea3c234ba30,Conference on Empirical Methods in Natural Language Processing,2021.0,61.0,102.0,11.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31760501', 'name': 'Kang Min Yoo'}, {'authorId': '13453892', 'name': 'Dongju Park'}, {'authorId': '35518563', 'name': 'Jaewook Kang'}, {'authorId': '3226948', 'name': 'Sang-Woo Lee'}, {'authorId': '2087289230', 'name': 'Woomyeong Park'}]",['NAVER'],['South Korea'],2021-04
2104.12395,Ryuichi Yamamoto,"Kosuke Futamata, Byeongseon Park, Ryuichi Yamamoto, Kentaro Tachibana",Phrase break prediction with bidirectional encoder representations in Japanese text-to-speech synthesis,Submitted to INTERSPEECH 2021,,,,eess.AS cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a novel phrase break prediction method that combines implicit features extracted from a pre-trained large language model, a.k.a BERT, and explicit features extracted from BiLSTM with linguistic features. In conventional BiLSTM based methods, word representations and/or sentence representations are used as independent components. The proposed method takes account of both representations to extract the latent semantics, which cannot be captured by previous methods. The objective evaluation results show that the proposed method obtains an absolute improvement of 3.2 points for the F1 score compared with BiLSTM-based conventional methods using linguistic features. Moreover, the perceptual listening test results verify that a TTS system that applied our proposed method achieved a mean opinion score of 4.39 in prosody naturalness, which is highly competitive with the score of 4.37 for synthesized speech with ground-truth phrase breaks. ","[{'version': 'v1', 'created': 'Mon, 26 Apr 2021 08:29:29 GMT'}]",2021-04-27,"[['Futamata', 'Kosuke', ''], ['Park', 'Byeongseon', ''], ['Yamamoto', 'Ryuichi', ''], ['Tachibana', 'Kentaro', '']]",0,0,2021-04-26,1,4,3,0,0,0,cb608e823089311eab56e6f0c23e44e8282f932e,233394246.0,https://www.semanticscholar.org/paper/cb608e823089311eab56e6f0c23e44e8282f932e,Interspeech,2021.0,29.0,12.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2084555045', 'name': 'Kosuke Futamata'}, {'authorId': '102536428', 'name': 'Byeong-Cheol Park'}, {'authorId': '47146577', 'name': 'Ryuichi Yamamoto'}, {'authorId': '2940047', 'name': 'Kentaro Tachibana'}]",['Line Corporation (Japan)'],['Japan'],2021-04
2105.00642,Benjamin Hilprecht,Benjamin Hilprecht and Carsten Binnig,One Model to Rule them All: Towards Zero-Shot Learning for Databases,,,,,cs.DB cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present our vision of so called zero-shot learning for databases which is a new learning approach for database components. Zero-shot learning for databases is inspired by recent advances in transfer learning of models such as GPT-3 and can support a new database out-of-the box without the need to train a new model. Furthermore, it can easily be extended to few-shot learning by further retraining the model on the unseen database. As a first concrete contribution in this paper, we show the feasibility of zero-shot learning for the task of physical cost estimation and present very promising initial results. Moreover, as a second contribution we discuss the core challenges related to zero-shot learning for databases and present a roadmap to extend zero-shot learning towards many other tasks beyond cost estimation or even beyond classical database systems and workloads. ","[{'version': 'v1', 'created': 'Mon, 3 May 2021 06:18:47 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Oct 2021 08:47:27 GMT'}, {'version': 'v3', 'created': 'Tue, 14 Dec 2021 09:20:44 GMT'}, {'version': 'v4', 'created': 'Mon, 3 Jan 2022 12:42:40 GMT'}]",2022-01-04,"[['Hilprecht', 'Benjamin', ''], ['Binnig', 'Carsten', '']]",0,1,2021-05-03,4,2,2,1,0,1,36eaf77941364fdcdbaaefa9d7c4d0d337cfacac,233481797.0,https://www.semanticscholar.org/paper/36eaf77941364fdcdbaaefa9d7c4d0d337cfacac,Conference on Innovative Data Systems Research,2021.0,34.0,15.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '81786870', 'name': 'Benjamin Hilprecht'}, {'authorId': '2691974', 'name': 'Carsten Binnig'}]",['Technical University of Darmstadt'],['Germany'],2021-05
2105.01192,Andrey Kutuzov,"Tatyana Iazykova, Denis Kapelyushnik, Olga Bystrova, Andrey Kutuzov",Unreasonable Effectiveness of Rule-Based Heuristics in Solving Russian SuperGLUE Tasks,Accepted to Dialogue'2021,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Leader-boards like SuperGLUE are seen as important incentives for active development of NLP, since they provide standard benchmarks for fair comparison of modern language models. They have driven the world's best engineering teams as well as their resources to collaborate and solve a set of tasks for general language understanding. Their performance scores are often claimed to be close to or even higher than the human performance. These results encouraged more thorough analysis of whether the benchmark datasets featured any statistical cues that machine learning based language models can exploit. For English datasets, it was shown that they often contain annotation artifacts. This allows solving certain tasks with very simple rules and achieving competitive rankings.   In this paper, a similar analysis was done for the Russian SuperGLUE (RSG), a recently published benchmark set and leader-board for Russian natural language understanding. We show that its test datasets are vulnerable to shallow heuristics. Often approaches based on simple rules outperform or come close to the results of the notorious pre-trained language models like GPT-3 or BERT. It is likely (as the simplest explanation) that a significant part of the SOTA models performance in the RSG leader-board is due to exploiting these shallow heuristics and that has nothing in common with real language understanding. We provide a set of recommendations on how to improve these datasets, making the RSG leader-board even more representative of the real progress in Russian NLU. ","[{'version': 'v1', 'created': 'Mon, 3 May 2021 22:19:22 GMT'}]",2021-05-05,"[['Iazykova', 'Tatyana', ''], ['Kapelyushnik', 'Denis', ''], ['Bystrova', 'Olga', ''], ['Kutuzov', 'Andrey', '']]",0,1,2021-05-03,1,4,1,1,0,1,cf055142999a8f878bdd949449608931ee1c4955,233715186.0,https://www.semanticscholar.org/paper/cf055142999a8f878bdd949449608931ee1c4955,arXiv.org,2021.0,41.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2096096197', 'name': 'Tatiana Iazykova'}, {'authorId': '2087694030', 'name': 'Denis Kapelyushnik'}, {'authorId': '3783185', 'name': 'Olga Bystrova'}, {'authorId': '2689095', 'name': 'Andrey Kutuzov'}]","['National Research University Higher School of Economics', 'University of Oslo']","['Russia', 'Norway']",2021-05
2105.03761,Maxime Kayser,"Maxime Kayser, Oana-Maria Camburu, Leonard Salewski, Cornelius Emde,
  Virginie Do, Zeynep Akata, Thomas Lukasiewicz",e-ViL: A Dataset and Benchmark for Natural Language Explanations in Vision-Language Tasks,Accepted at ICCV 2021 (camera-ready version),,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, there has been an increasing number of efforts to introduce models capable of generating natural language explanations (NLEs) for their predictions on vision-language (VL) tasks. Such models are appealing, because they can provide human-friendly and comprehensive explanations. However, there is a lack of comparison between existing methods, which is due to a lack of re-usable evaluation frameworks and a scarcity of datasets. In this work, we introduce e-ViL and e-SNLI-VE. e-ViL is a benchmark for explainable vision-language tasks that establishes a unified evaluation framework and provides the first comprehensive comparison of existing approaches that generate NLEs for VL tasks. It spans four models and three datasets and both automatic metrics and human evaluation are used to assess model-generated explanations. e-SNLI-VE is currently the largest existing VL dataset with NLEs (over 430k instances). We also propose a new model that combines UNITER, which learns joint embeddings of images and text, and GPT-2, a pre-trained language model that is well-suited for text generation. It surpasses the previous state of the art by a large margin across all datasets. Code and data are available here: https://github.com/maximek3/e-ViL. ","[{'version': 'v1', 'created': 'Sat, 8 May 2021 18:46:33 GMT'}, {'version': 'v2', 'created': 'Wed, 18 Aug 2021 16:35:03 GMT'}]",2021-08-19,"[['Kayser', 'Maxime', ''], ['Camburu', 'Oana-Maria', ''], ['Salewski', 'Leonard', ''], ['Emde', 'Cornelius', ''], ['Do', 'Virginie', ''], ['Akata', 'Zeynep', ''], ['Lukasiewicz', 'Thomas', '']]",0,1,2021-05-08,2,7,3,1,1,0,1c30efa04394f3e75d25ea1332a96cd354189dca,234338081.0,https://www.semanticscholar.org/paper/1c30efa04394f3e75d25ea1332a96cd354189dca,IEEE International Conference on Computer Vision,2021.0,51.0,63.0,13.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1491707097', 'name': 'Maxime Kayser'}, {'authorId': '3317152', 'name': 'Oana-Maria Camburu'}, {'authorId': '151097297', 'name': 'Leonard Salewski'}, {'authorId': '153438331', 'name': 'Cornelius Emde'}, {'authorId': '2086828576', 'name': 'Virginie Do'}, {'authorId': '2893664', 'name': 'Zeynep Akata'}, {'authorId': '1690572', 'name': 'Thomas Lukasiewicz'}]","['Max Planck Institute for Informatics', 'University of Tübingen', 'University of Oxford', 'Max Planck Institute for Intelligent Systems']","['Germany', 'United Kingdom']",2021-05
2105.04949,Asahi Ushio,"Asahi Ushio and Luis Espinosa-Anke and Steven Schockaert and Jose
  Camacho-Collados",BERT is to NLP what AlexNet is to CV: Can Pre-Trained Language Models Identify Analogies?,Accepted by ACL 2021 main conference,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Analogies play a central role in human commonsense reasoning. The ability to recognize analogies such as ""eye is to seeing what ear is to hearing"", sometimes referred to as analogical proportions, shape how we structure knowledge and understand language. Surprisingly, however, the task of identifying such analogies has not yet received much attention in the language model era. In this paper, we analyze the capabilities of transformer-based language models on this unsupervised task, using benchmarks obtained from educational settings, as well as more commonly used datasets. We find that off-the-shelf language models can identify analogies to a certain extent, but struggle with abstract and complex relations, and results are highly sensitive to model architecture and hyperparameters. Overall the best results were obtained with GPT-2 and RoBERTa, while configurations using BERT were not able to outperform word embedding models. Our results raise important questions for future work about how, and to what extent, pre-trained language models capture knowledge about abstract semantic relations. ","[{'version': 'v1', 'created': 'Tue, 11 May 2021 11:38:49 GMT'}, {'version': 'v2', 'created': 'Wed, 26 May 2021 10:10:38 GMT'}, {'version': 'v3', 'created': 'Thu, 3 Jun 2021 16:39:21 GMT'}, {'version': 'v4', 'created': 'Fri, 9 Sep 2022 14:52:05 GMT'}]",2022-09-12,"[['Ushio', 'Asahi', ''], ['Espinosa-Anke', 'Luis', ''], ['Schockaert', 'Steven', ''], ['Camacho-Collados', 'Jose', '']]",0,1,2021-05-11,4,4,2,1,1,0,465491b0507e107f248a8277ac17248c2ff8f915,234357758.0,https://www.semanticscholar.org/paper/465491b0507e107f248a8277ac17248c2ff8f915,Annual Meeting of the Association for Computational Linguistics,2021.0,77.0,59.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '27044733', 'name': 'Asahi Ushio'}, {'authorId': '2254466', 'name': 'Luis Espinosa Anke'}, {'authorId': '2265382', 'name': 'S. Schockaert'}, {'authorId': '1387447871', 'name': 'José Camacho-Collados'}]","['Cardiff University', 'National Library of the Philippines']","['Philippines', 'United Kingdom']",2021-05
2105.06947,Huiyuan Lai,"Huiyuan Lai, Antonio Toral, Malvina Nissim",Thank you BART! Rewarding Pre-Trained Models Improves Formality Style Transfer,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Scarcity of parallel data causes formality style transfer models to have scarce success in preserving content. We show that fine-tuning pre-trained language (GPT-2) and sequence-to-sequence (BART) models boosts content preservation, and that this is possible even with limited amounts of parallel data. Augmenting these models with rewards that target style and content -- the two core aspects of the task -- we achieve a new state-of-the-art. ","[{'version': 'v1', 'created': 'Fri, 14 May 2021 16:39:22 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Jul 2021 08:45:10 GMT'}]",2021-07-06,"[['Lai', 'Huiyuan', ''], ['Toral', 'Antonio', ''], ['Nissim', 'Malvina', '']]",0,1,2021-05-14,2,3,1,1,1,0,0bf230ee96c7ec49fe9d2aadcaec598d68ad94f1,234681927.0,https://www.semanticscholar.org/paper/0bf230ee96c7ec49fe9d2aadcaec598d68ad94f1,Annual Meeting of the Association for Computational Linguistics,2021.0,32.0,38.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66376493', 'name': 'Huiyuan Lai'}, {'authorId': '2065048323', 'name': 'Antonio Toral'}, {'authorId': '2742475', 'name': 'M. Nissim'}]","['CLCG, University of Groningen / The Netherlands']",['Netherlands'],2021-05
2105.08807,Ganesh Jawahar,"Ganesh Jawahar, El Moatez Billah Nagoudi, Muhammad Abdul-Mageed, Laks
  V.S. Lakshmanan",Exploring Text-to-Text Transformers for English to Hinglish Machine Translation with Synthetic Code-Mixing,"Computational Approaches to Linguistic Code-Switching (CALCS 2021)
  workshop",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We describe models focused at the understudied problem of translating between monolingual and code-mixed language pairs. More specifically, we offer a wide range of models that convert monolingual English text into Hinglish (code-mixed Hindi and English). Given the recent success of pretrained language models, we also test the utility of two recent Transformer-based encoder-decoder models (i.e., mT5 and mBART) on the task finding both to work well. Given the paucity of training data for code-mixing, we also propose a dependency-free method for generating code-mixed texts from bilingual distributed representations that we exploit for improving language model performance. In particular, armed with this additional data, we adopt a curriculum learning approach where we first finetune the language models on synthetic data then on gold code-mixed data. We find that, although simple, our synthetic code-mixing method is competitive with (and in some cases is even superior to) several standard methods (backtranslation, method based on equivalence constraint theory) under a diverse set of conditions. Our work shows that the mT5 model, finetuned following the curriculum learning procedure, achieves best translation performance (12.67 BLEU). Our models place first in the overall ranking of the English-Hinglish official shared task. ","[{'version': 'v1', 'created': 'Tue, 18 May 2021 19:50:25 GMT'}]",2021-05-20,"[['Jawahar', 'Ganesh', ''], ['Nagoudi', 'El Moatez Billah', ''], ['Abdul-Mageed', 'Muhammad', ''], ['Lakshmanan', 'Laks V. S.', '']]",0,0,2021-05-18,1,4,1,1,1,0,3fdd66a0eed6ee259c1c91321f866ed1f737f340,234778249.0,https://www.semanticscholar.org/paper/3fdd66a0eed6ee259c1c91321f866ed1f737f340,CALCS,2021.0,30.0,20.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145123979', 'name': 'Ganesh Jawahar'}, {'authorId': '17771023', 'name': 'El Moatez Billah Nagoudi'}, {'authorId': '1388437494', 'name': 'Muhammad Abdul-Mageed'}, {'authorId': '1708593', 'name': 'L. Lakshmanan'}]","['University of British Columbia', 'Natural Language Processing Lab', 'Institute of Computer Science']","['Canada', 'Poland']",2021-05
2105.09052,Daryna Dementieva,"Daryna Dementieva, Daniil Moskovskiy, Varvara Logacheva, David Dale,
  Olga Kozlova, Nikita Semenov, and Alexander Panchenko",Methods for Detoxification of Texts for the Russian Language,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce the first study of automatic detoxification of Russian texts to combat offensive language. Such a kind of textual style transfer can be used, for instance, for processing toxic content in social media. While much work has been done for the English language in this field, it has never been solved for the Russian language yet. We test two types of models - unsupervised approach based on BERT architecture that performs local corrections and supervised approach based on pretrained language GPT-2 model - and compare them with several baselines. In addition, we describe evaluation setup providing training datasets and metrics for automatic evaluation. The results show that the tested approaches can be successfully used for detoxification, although there is room for improvement. ","[{'version': 'v1', 'created': 'Wed, 19 May 2021 10:37:44 GMT'}]",2021-05-20,"[['Dementieva', 'Daryna', ''], ['Moskovskiy', 'Daniil', ''], ['Logacheva', 'Varvara', ''], ['Dale', 'David', ''], ['Kozlova', 'Olga', ''], ['Semenov', 'Nikita', ''], ['Panchenko', 'Alexander', '']]",0,1,2021-05-19,1,7,2,1,1,0,2c5b31a02133dea21cf94fde67c8948115441432,234777967.0,https://www.semanticscholar.org/paper/2c5b31a02133dea21cf94fde67c8948115441432,Multimodal Technologies and Interaction,2021.0,46.0,8.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2027664710', 'name': 'D. Dementieva'}, {'authorId': '2097709956', 'name': 'Daniil Moskovskiy'}, {'authorId': '145089549', 'name': 'V. Logacheva'}, {'authorId': '2097711561', 'name': 'David Dale'}, {'authorId': '2062842110', 'name': 'Olga Kozlova'}, {'authorId': '2094581992', 'name': 'Nikita Semenov'}, {'authorId': '2027664756', 'name': 'A. Panchenko'}]","['Skolkovo Institute of Science and Technology', 'Mobile TeleSystems (MTS), Moscow, Russia']",['Russia'],2021-05
2105.11812,Firas Jarboui,"Firas Jarboui, Vianney Perchet",A Generalised Inverse Reinforcement Learning Framework,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The gloabal objective of inverse Reinforcement Learning (IRL) is to estimate the unknown cost function of some MDP base on observed trajectories generated by (approximate) optimal policies. The classical approach consists in tuning this cost function so that associated optimal trajectories (that minimise the cumulative discounted cost, i.e. the classical RL loss) are 'similar' to the observed ones. Prior contributions focused on penalising degenerate solutions and improving algorithmic scalability. Quite orthogonally to them, we question the pertinence of characterising optimality with respect to the cumulative discounted cost as it induces an implicit bias against policies with longer mixing times. State of the art value based RL algorithms circumvent this issue by solving for the fixed point of the Bellman optimality operator, a stronger criterion that is not well defined for the inverse problem. To alleviate this bias in IRL, we introduce an alternative training loss that puts more weights on future states which yields a reformulation of the (maximum entropy) IRL problem. The algorithms we devised exhibit enhanced performances (and similar tractability) than off-the-shelf ones in multiple OpenAI gym environments. ","[{'version': 'v1', 'created': 'Tue, 25 May 2021 10:30:45 GMT'}]",2021-05-26,"[['Jarboui', 'Firas', ''], ['Perchet', 'Vianney', '']]",0,0,2021-05-25,1,2,1,0,0,0,03e87b08f4d9d512e8da2d8d788eec0f67363eac,235187320.0,https://www.semanticscholar.org/paper/03e87b08f4d9d512e8da2d8d788eec0f67363eac,arXiv.org,2021.0,42.0,4.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '25905248', 'name': 'Firas Jarboui'}, {'authorId': '3087994', 'name': 'Vianney Perchet'}]","[""École Nationale de la Statistique et de l'Administration Économique"", 'École Normale Supérieure - PSL']",['France'],2021-05
2106.01209,EPTCS,"James Hefford (University of Oxford), Stefano Gogioso (University of
  Oxford)",CPM Categories for Galois Extensions,"In Proceedings QPL 2021, arXiv:2109.04886","EPTCS 343, 2021, pp. 165-192",10.4204/EPTCS.343.9,,quant-ph math.CT,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  By considering a generalisation of the CPM construction, we develop an infinite hierarchy of probabilistic theories, exhibiting compositional decoherence structures which generalise the traditional quantum-to-classical transition. Analogously to the quantum-to-classical case, these decoherences reduce the degrees of freedom in physical systems, while at the same time restricting the fields over which the systems are defined. These theories possess fully fledged operational semantics, allowing both categorical and GPT-style approaches to their study. ","[{'version': 'v1', 'created': 'Wed, 2 Jun 2021 14:52:41 GMT'}, {'version': 'v2', 'created': 'Mon, 13 Sep 2021 00:49:59 GMT'}]",2021-09-14,"[['Hefford', 'James', '', 'University of Oxford'], ['Gogioso', 'Stefano', '', 'University of\n  Oxford']]",0,1,2021-06-02,2,2,2,0,0,0,5dbdd71fdc561f54a5712a1e291f0b144c8c8089,235293819.0,https://www.semanticscholar.org/paper/5dbdd71fdc561f54a5712a1e291f0b144c8c8089,QPL,2021.0,40.0,0.0,0.0,True,"['Physics', 'Mathematics', 'Computer Science']","[{'category': 'Physics', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","[{'authorId': '1491321976', 'name': 'James Hefford'}, {'authorId': '1814034', 'name': 'S. Gogioso'}]",['University of Oxford'],['United Kingdom'],2021-06
2106.01251,Vishal Vinod,"Vishal Vinod, Susmit Agrawal, Vipul Gaurav, Pallavi R, Savita
  Choudhary",Multilingual Medical Question Answering and Information Retrieval for Rural Health Intelligence Access,,ICLR 2021 Workshop,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  In rural regions of several developing countries, access to quality healthcare, medical infrastructure, and professional diagnosis is largely unavailable. Many of these regions are gradually gaining access to internet infrastructure, although not with a strong enough connection to allow for sustained communication with a medical practitioner. Several deaths resulting from this lack of medical access, absence of patient's previous health records, and the unavailability of information in indigenous languages can be easily prevented. In this paper, we describe an approach leveraging the phenomenal progress in Machine Learning and NLP (Natural Language Processing) techniques to design a model that is low-resource, multilingual, and a preliminary first-point-of-contact medical assistant. Our contribution includes defining the NLP pipeline required for named-entity-recognition, language-agnostic sentence embedding, natural language translation, information retrieval, question answering, and generative pre-training for final query processing. We obtain promising results for this pipeline and preliminary results for EHR (Electronic Health Record) analysis with text summarization for medical practitioners to peruse for their diagnosis. Through this NLP pipeline, we aim to provide preliminary medical information to the user and do not claim to supplant diagnosis from qualified medical practitioners. Using the input from subject matter experts, we have compiled a large corpus to pre-train and fine-tune our BioBERT based NLP model for the specific tasks. We expect recent advances in NLP architectures, several of which are efficient and privacy-preserving models, to further the impact of our solution and improve on individual task performance. ","[{'version': 'v1', 'created': 'Wed, 2 Jun 2021 16:05:24 GMT'}]",2021-06-03,"[['Vinod', 'Vishal', ''], ['Agrawal', 'Susmit', ''], ['Gaurav', 'Vipul', ''], ['R', 'Pallavi', ''], ['Choudhary', 'Savita', '']]",0,1,2021-06-02,1,5,2,0,0,0,751ecfc0214872aaf79899043d6ab9570468df7f,235294086.0,https://www.semanticscholar.org/paper/751ecfc0214872aaf79899043d6ab9570468df7f,arXiv.org,2021.0,21.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '2090614689', 'name': 'Vishal Vinod'}, {'authorId': '2008802066', 'name': 'Susmit Agrawal'}, {'authorId': '1413735598', 'name': 'V. Gaurav'}, {'authorId': '87690002', 'name': 'R. Pallavi'}, {'authorId': '9166828', 'name': 'Savita Choudhary'}]","['Sir M. Visvesvaraya Institute of Technology Bengaluru, India']",['India'],2021-06
2106.02559,Rowan Hall Maudslay,"Rowan Hall Maudslay, Ryan Cotterell",Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Analysing whether neural language models encode linguistic information has become popular in NLP. One method of doing so, which is frequently cited to support the claim that models like BERT encode syntax, is called probing; probes are small supervised models trained to extract linguistic information from another model's output. If a probe is able to predict a particular structure, it is argued that the model whose output it is trained on must have implicitly learnt to encode it. However, drawing a generalisation about a model's linguistic knowledge about a specific phenomena based on what a probe is able to learn may be problematic: in this work, we show that semantic cues in training data means that syntactic probes do not properly isolate syntax. We generate a new corpus of semantically nonsensical but syntactically well-formed Jabberwocky sentences, which we use to evaluate two probes trained on normal data. We train the probes on several popular language models (BERT, GPT, and RoBERTa), and find that in all settings they perform worse when evaluated on these data, for one probe by an average of 15.4 UUAS points absolute. Although in most cases they still outperform the baselines, their lead is reduced substantially, e.g. by 53% in the case of BERT for one probe. This begs the question: what empirical scores constitute knowing syntax? ","[{'version': 'v1', 'created': 'Fri, 4 Jun 2021 15:46:39 GMT'}]",2021-06-07,"[['Maudslay', 'Rowan Hall', ''], ['Cotterell', 'Ryan', '']]",0,1,2021-06-04,1,2,2,0,0,0,118dea7d937c37ab7d1b3ec958b1005bf69a0a2c,235097491.0,https://www.semanticscholar.org/paper/118dea7d937c37ab7d1b3ec958b1005bf69a0a2c,North American Chapter of the Association for Computational Linguistics,2021.0,35.0,25.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '1388061045', 'name': 'R. Maudslay'}, {'authorId': '2070989574', 'name': 'Ryan Cotterell'}]","['University of Cambridge', 'ETH Zurich']","['United Kingdom', 'Switzerland']",2021-06
2106.03521,Anne Lauscher,"Soumya Barikeri, Anne Lauscher, Ivan Vuli\'c, and Goran Glava\v{s}",RedditBias: A Real-World Resource for Bias Evaluation and Debiasing of Conversational Language Models,Accepted for ACL21,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Text representation models are prone to exhibit a range of societal biases, reflecting the non-controlled and biased nature of the underlying pretraining data, which consequently leads to severe ethical issues and even bias amplification. Recent work has predominantly focused on measuring and mitigating bias in pretrained language models. Surprisingly, the landscape of bias measurements and mitigation resources and methods for conversational language models is still very scarce: it is limited to only a few types of bias, artificially constructed resources, and completely ignores the impact that debiasing methods may have on the final performance in dialog tasks, e.g., conversational response generation. In this work, we present RedditBias, the first conversational data set grounded in the actual human conversations from Reddit, allowing for bias measurement and mitigation across four important bias dimensions: gender, race, religion, and queerness. Further, we develop an evaluation framework which simultaneously 1) measures bias on the developed RedditBias resource, and 2) evaluates model capability in dialog tasks after model debiasing. We use the evaluation framework to benchmark the widely used conversational DialoGPT model along with the adaptations of four debiasing methods. Our results indicate that DialoGPT is biased with respect to religious groups and that some debiasing techniques can remove this bias while preserving downstream task performance. ","[{'version': 'v1', 'created': 'Mon, 7 Jun 2021 11:22:39 GMT'}]",2021-06-08,"[['Barikeri', 'Soumya', ''], ['Lauscher', 'Anne', ''], ['Vulić', 'Ivan', ''], ['Glavaš', 'Goran', '']]",0,1,2021-06-07,1,4,1,0,0,0,2add974973ab45e46f1f8d3b932d24ba88cbb0b4,235358955.0,https://www.semanticscholar.org/paper/2add974973ab45e46f1f8d3b932d24ba88cbb0b4,Annual Meeting of the Association for Computational Linguistics,2021.0,58.0,74.0,11.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2107062845', 'name': 'Soumya Barikeri'}, {'authorId': '29891652', 'name': 'Anne Lauscher'}, {'authorId': '1747849', 'name': 'Ivan Vulic'}, {'authorId': '2472657', 'name': 'Goran Glavas'}]","['University of Cambridge', 'University of Mannheim']","['Germany', 'United Kingdom']",2021-06
2106.05068,Firas Jarboui,"Firas Jarboui, Vianney Perchet",Offline Inverse Reinforcement Learning,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The objective of offline RL is to learn optimal policies when a fixed exploratory demonstrations data-set is available and sampling additional observations is impossible (typically if this operation is either costly or rises ethical questions). In order to solve this problem, off the shelf approaches require a properly defined cost function (or its evaluation on the provided data-set), which are seldom available in practice. To circumvent this issue, a reasonable alternative is to query an expert for few optimal demonstrations in addition to the exploratory data-set. The objective is then to learn an optimal policy w.r.t. the expert's latent cost function. Current solutions either solve a behaviour cloning problem (which does not leverage the exploratory data) or a reinforced imitation learning problem (using a fixed cost function that discriminates available exploratory trajectories from expert ones). Inspired by the success of IRL techniques in achieving state of the art imitation performances in online settings, we exploit GAN based data augmentation procedures to construct the first offline IRL algorithm. The obtained policies outperformed the aforementioned solutions on multiple OpenAI gym environments. ","[{'version': 'v1', 'created': 'Wed, 9 Jun 2021 13:44:06 GMT'}]",2021-06-10,"[['Jarboui', 'Firas', ''], ['Perchet', 'Vianney', '']]",0,0,2021-06-09,1,2,1,0,0,0,97b5623306afe19757946c7bc449277981c9e335,235376869.0,https://www.semanticscholar.org/paper/97b5623306afe19757946c7bc449277981c9e335,arXiv.org,2021.0,32.0,8.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '25905248', 'name': 'Firas Jarboui'}, {'authorId': '3087994', 'name': 'Vianney Perchet'}]","[""École Nationale de la Statistique et de l'Administration Économique"", 'École Normale Supérieure - PSL']",['France'],2021-06
2106.08181,Klaudia Balazy,"Klaudia Ba{\l}azy, Mohammadreza Banaei, R\'emi Lebret, Jacek Tabor,
  Karl Aberer",Direction is what you need: Improving Word Embedding Compression in Large Language Models,,,10.18653/v1/2021.repl4nlp-1.32,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The adoption of Transformer-based models in natural language processing (NLP) has led to great success using a massive number of parameters. However, due to deployment constraints in edge devices, there has been a rising interest in the compression of these models to improve their inference time and memory footprint. This paper presents a novel loss objective to compress token embeddings in the Transformer-based models by leveraging an AutoEncoder architecture. More specifically, we emphasize the importance of the direction of compressed embeddings with respect to original uncompressed embeddings. The proposed method is task-agnostic and does not require further language modeling pre-training. Our method significantly outperforms the commonly used SVD-based matrix-factorization approach in terms of initial language model Perplexity. Moreover, we evaluate our proposed approach over SQuAD v1.1 dataset and several downstream tasks from the GLUE benchmark, where we also outperform the baseline in most scenarios. Our code is public. ","[{'version': 'v1', 'created': 'Tue, 15 Jun 2021 14:28:00 GMT'}, {'version': 'v2', 'created': 'Tue, 3 Aug 2021 07:16:57 GMT'}]",2021-08-04,"[['Bałazy', 'Klaudia', ''], ['Banaei', 'Mohammadreza', ''], ['Lebret', 'Rémi', ''], ['Tabor', 'Jacek', ''], ['Aberer', 'Karl', '']]",0,0,2021-06-15,2,5,1,0,0,0,82d9696ad6badb2ee1cf32149907264360b1a916,235436167.0,https://www.semanticscholar.org/paper/82d9696ad6badb2ee1cf32149907264360b1a916,Workshop on Representation Learning for NLP,2021.0,31.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1641590550', 'name': 'Klaudia Bałazy'}, {'authorId': '1739201368', 'name': 'Mohammadreza Banaei'}, {'authorId': '2875254', 'name': 'R. Lebret'}, {'authorId': '145541197', 'name': 'J. Tabor'}, {'authorId': '1751802', 'name': 'K. Aberer'}]",['Jagiellonian University'],['Poland'],2021-06
2106.08832,Igor Kuznetsov,"Igor Kuznetsov, Andrey Filchenkov",Solving Continuous Control with Episodic Memory,"To appear in the 30th International Joint Conference on Artificial
  Intelligence (IJCAI 2021)",,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,  Episodic memory lets reinforcement learning algorithms remember and exploit promising experience from the past to improve agent performance. Previous works on memory mechanisms show benefits of using episodic-based data structures for discrete action problems in terms of sample-efficiency. The application of episodic memory for continuous control with a large action space is not trivial. Our study aims to answer the question: can episodic memory be used to improve agent's performance in continuous control? Our proposed algorithm combines episodic memory with Actor-Critic architecture by modifying critic's objective. We further improve performance by introducing episodic-based replay buffer prioritization. We evaluate our algorithm on OpenAI gym domains and show greater sample-efficiency compared with the state-of-the art model-free off-policy algorithms. ,"[{'version': 'v1', 'created': 'Wed, 16 Jun 2021 14:51:39 GMT'}]",2021-06-17,"[['Kuznetsov', 'Igor', ''], ['Filchenkov', 'Andrey', '']]",0,0,2021-06-16,1,2,1,0,0,0,36f9e864a093c079a1d9e4adab15016027b1ab32,235446389.0,https://www.semanticscholar.org/paper/36f9e864a093c079a1d9e4adab15016027b1ab32,International Joint Conference on Artificial Intelligence,2021.0,25.0,11.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064784623', 'name': 'Igor Kuznetsov'}, {'authorId': '2517152', 'name': 'A. Filchenkov'}]",['ITMO University'],['Russia'],2021-06
2106.10619,Prasanna Parthasarathi,"Prasanna Parthasarathi, Mohamed Abdelsalam, Joelle Pineau, Sarath
  Chandar",A Brief Study on the Effects of Training Generative Dialogue Models with a Semantic loss,Accepted at SIGDial 2021,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Neural models trained for next utterance generation in dialogue task learn to mimic the n-gram sequences in the training set with training objectives like negative log-likelihood (NLL) or cross-entropy. Such commonly used training objectives do not foster generating alternate responses to a context. But, the effects of minimizing an alternate training objective that fosters a model to generate alternate response and score it on semantic similarity has not been well studied. We hypothesize that a language generation model can improve on its diversity by learning to generate alternate text during training and minimizing a semantic loss as an auxiliary objective. We explore this idea on two different sized data sets on the task of next utterance generation in goal oriented dialogues. We make two observations (1) minimizing a semantic objective improved diversity in responses in the smaller data set (Frames) but only as-good-as minimizing the NLL in the larger data set (MultiWoZ) (2) large language model embeddings can be more useful as a semantic loss objective than as initialization for token embeddings. ","[{'version': 'v1', 'created': 'Sun, 20 Jun 2021 04:39:29 GMT'}]",2021-06-22,"[['Parthasarathi', 'Prasanna', ''], ['Abdelsalam', 'Mohamed', ''], ['Pineau', 'Joelle', ''], ['Chandar', 'Sarath', '']]",0,0,2021-06-20,1,4,1,0,0,0,9e92a56e01b7525448cf0778c349992f0cddd67b,235489736.0,https://www.semanticscholar.org/paper/9e92a56e01b7525448cf0778c349992f0cddd67b,SIGDIAL Conferences,2021.0,32.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32899078', 'name': 'Prasanna Parthasarathi'}, {'authorId': '2072699512', 'name': 'Mohamed Abdelsalam'}, {'authorId': '145134884', 'name': 'J. Pineau'}, {'authorId': '123607932', 'name': 'Sarath Chandar'}]","['Université de Montréal', 'McGill University', 'Mila - Quebec Artificial Intelligence Institute', 'Polytechnique Montréal', 'Canadian Institute for Advanced Research']",['Canada'],2021-06
2106.14131,Mojtaba Valipour,"Mojtaba Valipour, Bowen You, Maysum Panju, Ali Ghodsi",SymbolicGPT: A Generative Transformer Model for Symbolic Regression,"11 pages, 4 figures",,,,cs.LG cs.CL cs.SC,http://creativecommons.org/licenses/by-sa/4.0/,"  Symbolic regression is the task of identifying a mathematical expression that best fits a provided dataset of input and output values. Due to the richness of the space of mathematical expressions, symbolic regression is generally a challenging problem. While conventional approaches based on genetic evolution algorithms have been used for decades, deep learning-based methods are relatively new and an active research area. In this work, we present SymbolicGPT, a novel transformer-based language model for symbolic regression. This model exploits the advantages of probabilistic language models like GPT, including strength in performance and flexibility. Through comprehensive experiments, we show that our model performs strongly compared to competing models with respect to the accuracy, running time, and data efficiency. ","[{'version': 'v1', 'created': 'Sun, 27 Jun 2021 03:26:35 GMT'}]",2021-06-29,"[['Valipour', 'Mojtaba', ''], ['You', 'Bowen', ''], ['Panju', 'Maysum', ''], ['Ghodsi', 'Ali', '']]",0,1,2021-06-27,1,4,3,0,0,0,595c1f3e364a9dc12a31b6c355efea52f02c1ec5,235658383.0,https://www.semanticscholar.org/paper/595c1f3e364a9dc12a31b6c355efea52f02c1ec5,arXiv.org,2021.0,28.0,38.0,5.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '9200111', 'name': 'Mojtaba Valipour'}, {'authorId': '2115433795', 'name': 'Bowen You'}, {'authorId': '1964421', 'name': 'Maysum Panju'}, {'authorId': '38565890', 'name': 'A. Ghodsi'}]","['David R. Cheriton School of Computer Science', 'Statistical Service', 'University of Waterloo']","['Canada', 'Cyprus']",2021-06
2107.03134,Zeljko Kraljevic,"Zeljko Kraljevic, Anthony Shek, Daniel Bean, Rebecca Bendayan, James
  Teo, Richard Dobson",MedGPT: Medical Concept Prediction from Clinical Narratives,"6 pages, 2 figures, 3 tables",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The data available in Electronic Health Records (EHRs) provides the opportunity to transform care, and the best way to provide better care for one patient is through learning from the data available on all other patients. Temporal modelling of a patient's medical history, which takes into account the sequence of past events, can be used to predict future events such as a diagnosis of a new disorder or complication of a previous or existing disorder. While most prediction approaches use mostly the structured data in EHRs or a subset of single-domain predictions and outcomes, we present MedGPT a novel transformer-based pipeline that uses Named Entity Recognition and Linking tools (i.e. MedCAT) to structure and organize the free text portion of EHRs and anticipate a range of future medical events (initially disorders). Since a large portion of EHR data is in text form, such an approach benefits from a granular and detailed view of a patient while introducing modest additional noise. MedGPT effectively deals with the noise and the added granularity, and achieves a precision of 0.344, 0.552 and 0.640 (vs LSTM 0.329, 0.538 and 0.633) when predicting the top 1, 3 and 5 candidate future disorders on real world hospital data from King's College Hospital, London, UK (\textasciitilde600k patients). We also show that our model captures medical knowledge by testing it on an experimental medical multiple choice question answering task, and by examining the attentional focus of the model using gradient-based saliency methods. ","[{'version': 'v1', 'created': 'Wed, 7 Jul 2021 10:36:28 GMT'}]",2021-07-08,"[['Kraljevic', 'Zeljko', ''], ['Shek', 'Anthony', ''], ['Bean', 'Daniel', ''], ['Bendayan', 'Rebecca', ''], ['Teo', 'James', ''], ['Dobson', 'Richard', '']]",0,1,2021-07-07,1,6,1,0,0,0,d8e375017de9fd2c875b6925cbd6c64519a9c558,235755486.0,https://www.semanticscholar.org/paper/d8e375017de9fd2c875b6925cbd6c64519a9c558,arXiv.org,2021.0,25.0,13.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3365279', 'name': 'Zeljko Kraljevic'}, {'authorId': '1602130572', 'name': 'Anthony Shek'}, {'authorId': '38849757', 'name': 'D. Bean'}, {'authorId': '32593190', 'name': 'R. Bendayan'}, {'authorId': '147164117', 'name': 'J. Teo'}, {'authorId': '50673014', 'name': 'R. Dobson'}]","[""King's College London"", ""King's College Hospital NHS Foundation Trust"", 'Novita']","['United Kingdom', 'Australia']",2021-07
2107.03474,Adam P. Goucher,"Adam P. Goucher, Rajan Troll",Differentiable Random Access Memory using Lattices,"11 pages, 3 figures, submitted to NeurIPS 2021",,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce a differentiable random access memory module with $O(1)$ performance regardless of size, scaling to billions of entries. The design stores entries on points of a chosen lattice to calculate nearest neighbours of arbitrary points efficiently by exploiting symmetries. Augmenting a standard neural network architecture with a single memory layer based on this, we can scale the parameter count up to memory limits with negligible computational overhead, giving better accuracy at similar cost. On large language modelling tasks, these enhanced models with larger capacity significantly outperform the unmodified transformer baseline. We found continued scaling with memory size up to the limits tested. ","[{'version': 'v1', 'created': 'Wed, 7 Jul 2021 20:55:42 GMT'}]",2021-07-09,"[['Goucher', 'Adam P.', ''], ['Troll', 'Rajan', '']]",0,0,2021-07-07,1,2,1,0,0,0,9db15c5b1cc45aa524bf14a717bfd251ba273a34,235765422.0,https://www.semanticscholar.org/paper/9db15c5b1cc45aa524bf14a717bfd251ba273a34,arXiv.org,2021.0,28.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1964382', 'name': 'Adam P. Goucher'}, {'authorId': '2029666831', 'name': 'R. Troll'}]",['University of Cambridge'],['United Kingdom'],2021-07
2107.06686,Djordje Grbic,Djordje Grbic and Sebastian Risi,Safer Reinforcement Learning through Transferable Instinct Networks,The paper was accepted in the ALIFE 2021 conference,,,,cs.LG cs.AI cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Random exploration is one of the main mechanisms through which reinforcement learning (RL) finds well-performing policies. However, it can lead to undesirable or catastrophic outcomes when learning online in safety-critical environments. In fact, safe learning is one of the major obstacles towards real-world agents that can learn during deployment. One way of ensuring that agents respect hard limitations is to explicitly configure boundaries in which they can operate. While this might work in some cases, we do not always have clear a-priori information which states and actions can lead dangerously close to hazardous states. Here, we present an approach where an additional policy can override the main policy and offer a safer alternative action. In our instinct-regulated RL (IR^2L) approach, an ""instinctual"" network is trained to recognize undesirable situations, while guarding the learning policy against entering them. The instinct network is pre-trained on a single task where it is safe to make mistakes, and transferred to environments in which learning a new task safely is critical. We demonstrate IR^2L in the OpenAI Safety gym domain, in which it receives a significantly lower number of safety violations during training than a baseline RL approach while reaching similar task performance. ","[{'version': 'v1', 'created': 'Wed, 14 Jul 2021 13:22:04 GMT'}]",2021-07-15,"[['Grbic', 'Djordje', ''], ['Risi', 'Sebastian', '']]",0,0,2021-07-14,1,2,3,0,0,0,ad6a6b0c8bc48d087c3e5775a03bf049a59c68dc,235829888.0,https://www.semanticscholar.org/paper/ad6a6b0c8bc48d087c3e5775a03bf049a59c68dc,IEEE Symposium on Artificial Life,2021.0,37.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49816790', 'name': 'Djordje Grbic'}, {'authorId': '1745664', 'name': 'S. Risi'}]",['IT University of Copenhagen'],['Denmark'],2021-07
2107.06925,Shigang Li,"Shigang Li, Torsten Hoefler",Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines,"Published in Proceedings of the 2021 International Conference for
  High Performance Computing, Networking, Storage and Analysis (SC'21),
  November 2021, Article No.: 27, Pages 1-14. Best Paper Finalist",,10.1145/3458817.3476145,,cs.DC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Training large deep learning models at scale is very challenging. This paper proposes Chimera, a novel pipeline parallelism scheme which combines bidirectional pipelines for efficiently training large-scale models. Chimera is a synchronous approach and therefore no loss of accuracy, which is more convergence-friendly than asynchronous approaches. Compared with the latest synchronous pipeline approach, Chimera reduces the number of bubbles by up to 50%; benefiting from the sophisticated scheduling of bidirectional pipelines, Chimera has a more balanced activation memory consumption. Evaluations are conducted on Transformer based language models. For a GPT-2 model with 1.3 billion parameters running on 2,048 GPU nodes of the Piz Daint supercomputer, Chimera improves the training throughput by 1.16x-2.34x over the state-of-the-art synchronous and asynchronous pipeline approaches. ","[{'version': 'v1', 'created': 'Wed, 14 Jul 2021 18:16:20 GMT'}, {'version': 'v2', 'created': 'Mon, 15 Nov 2021 14:32:19 GMT'}, {'version': 'v3', 'created': 'Fri, 25 Feb 2022 10:49:12 GMT'}]",2022-02-28,"[['Li', 'Shigang', ''], ['Hoefler', 'Torsten', '']]",0,1,2021-07-14,3,2,2,1,1,0,10f3ca78e194552427ebe9173b19d1b910469e27,235898937.0,https://www.semanticscholar.org/paper/10f3ca78e194552427ebe9173b19d1b910469e27,"International Conference for High Performance Computing, Networking, Storage and Analysis",2021.0,58.0,51.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1738041', 'name': 'Shigang Li'}, {'authorId': '1713648', 'name': 'T. Hoefler'}]",['ETH Zurich'],['Switzerland'],2021-07
2107.07253,Asier Guti\'errez-Fandi\~no,"Asier Guti\'errez-Fandi\~no, Jordi Armengol-Estap\'e, Marc P\`amies,
  Joan Llop-Palao, Joaqu\'in Silveira-Ocampo, Casimiro Pio Carrino, Aitor
  Gonzalez-Agirre, Carme Armentano-Oller, Carlos Rodriguez-Penagos, Marta
  Villegas",MarIA: Spanish Language Models,,"Procesamiento del Lenguaje Natural, v. 68, p. 39-60, mar. 2022.
  ISSN 1989-7553",10.26342/2022-68-3,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This work presents MarIA, a family of Spanish language models and associated resources made available to the industry and the research community. Currently, MarIA includes RoBERTa-base, RoBERTa-large, GPT2 and GPT2-large Spanish language models, which can arguably be presented as the largest and most proficient language models in Spanish. The models were pretrained using a massive corpus of 570GB of clean and deduplicated texts with 135 billion words extracted from the Spanish Web Archive crawled by the National Library of Spain between 2009 and 2019. We assessed the performance of the models with nine existing evaluation datasets and with a novel extractive Question Answering dataset created ex novo. Overall, MarIA models outperform the existing Spanish models across a variety of NLU tasks and training settings. ","[{'version': 'v1', 'created': 'Thu, 15 Jul 2021 11:23:05 GMT'}, {'version': 'v2', 'created': 'Fri, 13 Aug 2021 13:47:44 GMT'}, {'version': 'v3', 'created': 'Fri, 1 Apr 2022 13:03:32 GMT'}, {'version': 'v4', 'created': 'Mon, 4 Apr 2022 16:25:12 GMT'}, {'version': 'v5', 'created': 'Tue, 5 Apr 2022 11:13:46 GMT'}]",2022-04-06,"[['Gutiérrez-Fandiño', 'Asier', ''], ['Armengol-Estapé', 'Jordi', ''], ['Pàmies', 'Marc', ''], ['Llop-Palao', 'Joan', ''], ['Silveira-Ocampo', 'Joaquín', ''], ['Carrino', 'Casimiro Pio', ''], ['Gonzalez-Agirre', 'Aitor', ''], ['Armentano-Oller', 'Carme', ''], ['Rodriguez-Penagos', 'Carlos', ''], ['Villegas', 'Marta', '']]",0,1,2021-07-15,5,10,2,1,1,0,2132eac5628bc200de226b51f1dfb82423ff1d24,252847802.0,https://www.semanticscholar.org/paper/2132eac5628bc200de226b51f1dfb82423ff1d24,Proces. del Leng. Natural,2021.0,55.0,58.0,10.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2078772072', 'name': 'Asier Gutiérrez-Fandiño'}, {'authorId': '1405319696', 'name': ""Jordi Armengol-Estap'e""}, {'authorId': '1850527789', 'name': 'Marc Pàmies'}, {'authorId': '2119550454', 'name': 'Joan Llop-Palao'}, {'authorId': '2119543279', 'name': 'Joaquín Silveira-Ocampo'}, {'authorId': '1416319999', 'name': 'C. Carrino'}, {'authorId': '1405518065', 'name': 'Carme Armentano-Oller'}, {'authorId': '2687070', 'name': 'C. R. Penagos'}, {'authorId': '1403836100', 'name': 'Aitor Gonzalez-Agirre'}, {'authorId': '2066499928', 'name': 'Marta Villegas'}]",['Barcelona Supercomputing Center'],['Spain'],2021-07
2107.07691,Liam Magee,"Liam Magee, Lida Ghahremanlou, Karen Soldatic, and Shanthi Robertson",Intersectional Bias in Causal Language Models,"18 pages, 4 figures",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  To examine whether intersectional bias can be observed in language generation, we examine \emph{GPT-2} and \emph{GPT-NEO} models, ranging in size from 124 million to ~2.7 billion parameters. We conduct an experiment combining up to three social categories - gender, religion and disability - into unconditional or zero-shot prompts used to generate sentences that are then analysed for sentiment. Our results confirm earlier tests conducted with auto-regressive causal models, including the \emph{GPT} family of models. We also illustrate why bias may be resistant to techniques that target single categories (e.g. gender, religion and race), as it can also manifest, in often subtle ways, in texts prompted by concatenated social categories. To address these difficulties, we suggest technical and community-based approaches need to combine to acknowledge and address complex and intersectional language model bias. ","[{'version': 'v1', 'created': 'Fri, 16 Jul 2021 03:46:08 GMT'}]",2021-07-19,"[['Magee', 'Liam', ''], ['Ghahremanlou', 'Lida', ''], ['Soldatic', 'Karen', ''], ['Robertson', 'Shanthi', '']]",0,1,2021-07-16,1,4,2,1,1,0,e614bdb3d6a0675084616ff2ee40c14314d3d1a4,236034024.0,https://www.semanticscholar.org/paper/e614bdb3d6a0675084616ff2ee40c14314d3d1a4,arXiv.org,2021.0,55.0,16.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2733075', 'name': 'L. Magee'}, {'authorId': '9557084', 'name': 'Lida Ghahremanlou'}, {'authorId': '13714096', 'name': 'K. Soldatic'}, {'authorId': '97868921', 'name': 'S. Robertson'}]","['Western Sydney University', 'Microsoft']","['United Kingdom', 'Australia']",2021-07
2107.09139,Balazs Varga,"Bal\'azs Varga, Bal\'azs Kulcs\'ar, Morteza Haghir Chehreghani",Constrained Policy Gradient Method for Safe and Fast Reinforcement Learning: a Neural Tangent Kernel Based Approach,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a constrained policy gradient algorithm. We introduce constraints for safe learning with the following steps. First, learning is slowed down (lazy learning) so that the episodic policy change can be computed with the help of the policy gradient theorem and the neural tangent kernel. Then, this enables us the evaluation of the policy at arbitrary states too. In the same spirit, learning can be guided, ensuring safety via augmenting episode batches with states where the desired action probabilities are prescribed. Finally, exogenous discounted sum of future rewards (returns) can be computed at these specific state-action pairs such that the policy network satisfies constraints. Computing the returns is based on solving a system of linear equations (equality constraints) or a constrained quadratic program (inequality constraints, regional constraints). Simulation results suggest that adding constraints (external information) to the learning can improve learning in terms of speed and transparency reasonably if constraints are appropriately selected. The efficiency of the constrained learning was demonstrated with a shallow and wide ReLU network in the Cartpole and Lunar Lander OpenAI gym environments. The main novelty of the paper is giving a practical use of the neural tangent kernel in reinforcement learning. ","[{'version': 'v1', 'created': 'Mon, 19 Jul 2021 20:25:15 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Jan 2022 08:54:49 GMT'}]",2022-01-24,"[['Varga', 'Balázs', ''], ['Kulcsár', 'Balázs', ''], ['Chehreghani', 'Morteza Haghir', '']]",0,0,2021-07-19,2,3,1,0,0,0,86c9ce497acd77458e56310674580cbaabe929f9,236134319.0,https://www.semanticscholar.org/paper/86c9ce497acd77458e56310674580cbaabe929f9,arXiv.org,2021.0,45.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2058039047', 'name': 'B. Varga'}, {'authorId': '2080320479', 'name': ""B. Kulcs'ar""}, {'authorId': '31527457', 'name': 'M. Chehreghani'}]",['Chalmers University of Technology'],['Sweden'],2021-07
2108.04026,Sean MacAvaney,"Sean MacAvaney, Craig Macdonald, Roderick Murray-Smith, Iadh Ounis",IntenT5: Search Result Diversification using Causal Language Models,,,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Search result diversification is a beneficial approach to overcome under-specified queries, such as those that are ambiguous or multi-faceted. Existing approaches often rely on massive query logs and interaction data to generate a variety of possible query intents, which then can be used to re-rank documents. However, relying on user interaction data is problematic because one first needs a massive user base to build a sufficient log; public query logs are insufficient on their own. Given the recent success of causal language models (such as the Text-To-Text Transformer (T5) model) at text generation tasks, we explore the capacity of these models to generate potential query intents. We find that to encourage diversity in the generated queries, it is beneficial to adapt the model by including a new Distributional Causal Language Modeling (DCLM) objective during fine-tuning and a representation replacement during inference. Across six standard evaluation benchmarks, we find that our method (which we call IntenT5) improves search result diversity and attains (and sometimes exceeds) the diversity obtained when using query suggestions based on a proprietary query log. Our analysis shows that our approach is most effective for multi-faceted queries and is able to generalize effectively to queries that were unseen in training data. ","[{'version': 'v1', 'created': 'Mon, 9 Aug 2021 13:29:24 GMT'}]",2021-08-10,"[['MacAvaney', 'Sean', ''], ['Macdonald', 'Craig', ''], ['Murray-Smith', 'Roderick', ''], ['Ounis', 'Iadh', '']]",0,0,2021-08-09,1,4,1,1,1,0,53220193decd8615c255bd71bd63d44efafd5313,236956415.0,https://www.semanticscholar.org/paper/53220193decd8615c255bd71bd63d44efafd5313,arXiv.org,2021.0,51.0,12.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '22214396', 'name': 'Sean MacAvaney'}, {'authorId': '145434248', 'name': 'C. Macdonald'}, {'authorId': '1402170019', 'name': 'R. Murray-Smith'}, {'authorId': '1698205', 'name': 'I. Ounis'}]",['University of Glasgow'],['United Kingdom'],2021-08
2108.05158,Donggeon Lee,"Donggeon Lee, Seongho Choi, Youwon Jang, Byoung-Tak Zhang",Mounting Video Metadata on Transformer-based Language Model for Open-ended Video Question Answering,"5 pages, 1 figure",,,,cs.CV cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Video question answering has recently received a lot of attention from multimodal video researchers. Most video question answering datasets are usually in the form of multiple-choice. But, the model for the multiple-choice task does not infer the answer. Rather it compares the answer candidates for picking the correct answer. Furthermore, it makes it difficult to extend to other tasks. In this paper, we challenge the existing multiple-choice video question answering by changing it to open-ended video question answering. To tackle open-ended question answering, we use the pretrained GPT2 model. The model is fine-tuned with video inputs and subtitles. An ablation study is performed by changing the existing DramaQA dataset to an open-ended question answering, and it shows that performance can be improved using video metadata. ","[{'version': 'v1', 'created': 'Wed, 11 Aug 2021 11:11:43 GMT'}]",2021-08-12,"[['Lee', 'Donggeon', ''], ['Choi', 'Seongho', ''], ['Jang', 'Youwon', ''], ['Zhang', 'Byoung-Tak', '']]",0,1,2021-08-11,1,4,2,1,1,0,90a25ffb78dc4c1be7bc6d1fccd55e87cdb1dd31,236975961.0,https://www.semanticscholar.org/paper/90a25ffb78dc4c1be7bc6d1fccd55e87cdb1dd31,arXiv.org,2021.0,23.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '1645951775', 'name': 'Donggeon Lee'}, {'authorId': '117172343', 'name': 'Seongho Choi'}, {'authorId': '1680054988', 'name': 'Youwon Jang'}, {'authorId': '1692756', 'name': 'Byoung-Tak Zhang'}]",['Seoul National University'],['South Korea'],2021-08
2108.06277,Ivan Chelombiev,"Anastasia Dietrich and Frithjof Gressmann and Douglas Orr and Ivan
  Chelombiev and Daniel Justus and Carlo Luschi",Towards Structured Dynamic Sparse Pre-Training of BERT,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Identifying algorithms for computational efficient unsupervised training of large language models is an important and active area of research. In this work, we develop and study a straightforward, dynamic always-sparse pre-training approach for BERT language modeling task, which leverages periodic compression steps based on magnitude pruning followed by random parameter re-allocation. This approach enables us to achieve Pareto improvements in terms of the number of floating-point operations (FLOPs) over statically sparse and dense models across a broad spectrum of network sizes. Furthermore, we demonstrate that training remains FLOP-efficient when using coarse-grained block sparsity, making it particularly promising for efficient execution on modern hardware accelerators. ","[{'version': 'v1', 'created': 'Fri, 13 Aug 2021 14:54:26 GMT'}]",2021-08-16,"[['Dietrich', 'Anastasia', ''], ['Gressmann', 'Frithjof', ''], ['Orr', 'Douglas', ''], ['Chelombiev', 'Ivan', ''], ['Justus', 'Daniel', ''], ['Luschi', 'Carlo', '']]",0,0,2021-08-13,1,6,2,0,0,0,4183d028c7b7e54f55e63698232e4d0a6df535bc,237048134.0,https://www.semanticscholar.org/paper/4183d028c7b7e54f55e63698232e4d0a6df535bc,arXiv.org,2021.0,59.0,13.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2057429281', 'name': 'A. Dietrich'}, {'authorId': '2123209929', 'name': 'Frithjof Gressmann'}, {'authorId': '145474032', 'name': 'Douglas Orr'}, {'authorId': '66190473', 'name': 'Ivan Chelombiev'}, {'authorId': '39145648', 'name': 'Daniel Justus'}, {'authorId': '49147045', 'name': 'C. Luschi'}]","['Graphcore Research London, UK', 'University of Bristol']",['United Kingdom'],2021-08
2108.07789,Xianrui Zheng,"Xianrui Zheng, Chao Zhang and Philip C. Woodland","Adapting GPT, GPT-2 and BERT Language Models for Speech Recognition",To appear in ASRU 2021,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models (LMs) pre-trained on massive amounts of text, in particular bidirectional encoder representations from Transformers (BERT), generative pre-training (GPT), and GPT-2, have become a key technology for many natural language processing tasks. In this paper, we present results using fine-tuned GPT, GPT-2, and their combination for automatic speech recognition (ASR). Unlike unidirectional LM GPT and GPT-2, BERT is bidirectional whose direct product of the output probabilities is no longer a valid language prior probability. A conversion method is proposed to compute the correct language prior probability based on bidirectional LM outputs in a mathematically exact way. Experimental results on the widely used AMI and Switchboard ASR tasks showed that the combination of the fine-tuned GPT and GPT-2 outperformed the combination of three neural LMs with different architectures trained from scratch on the in-domain text by up to a 12% relative word error rate reduction (WERR). Furthermore, on the AMI corpus, the proposed conversion for language prior probabilities enables BERT to obtain an extra 3% relative WERR, and the combination of BERT, GPT and GPT-2 results in further improvements. ","[{'version': 'v1', 'created': 'Thu, 29 Jul 2021 16:53:37 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Oct 2021 14:19:39 GMT'}]",2021-10-04,"[['Zheng', 'Xianrui', ''], ['Zhang', 'Chao', ''], ['Woodland', 'Philip C.', '']]",0,1,2021-07-29,2,3,3,1,1,0,4ce2ceb4ee975b032578e8816cb8f50a9984c76e,237142586.0,https://www.semanticscholar.org/paper/4ce2ceb4ee975b032578e8816cb8f50a9984c76e,Automatic Speech Recognition & Understanding,2021.0,51.0,15.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152197497', 'name': 'Xianrui Zheng'}, {'authorId': '47423408', 'name': 'Chao Zhang'}, {'authorId': '1716393', 'name': 'P. Woodland'}]",['University of Cambridge'],['United Kingdom'],2021-07
2108.08111,Junjie Xu H.,"Junjie H. Xu, Kohei Shinden, Makoto P. Kato",Table Caption Generation in Scholarly Documents Leveraging Pre-trained Language Models,,"2021 IEEE 10th Global Conference on Consumer Electronics (GCCE
  2021)",,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper addresses the problem of generating table captions for scholarly documents, which often require additional information outside the table. To this end, we propose a method of retrieving relevant sentences from the paper body, and feeding the table content as well as the retrieved sentences into pre-trained language models (e.g. T5 and GPT-2) for generating table captions. The contributions of this paper are: (1) discussion on the challenges in table captioning for scholarly documents; (2) development of a dataset DocBank-TB, which is publicly available; and (3) comparison of caption generation methods for scholarly documents with different strategies to retrieve relevant sentences from the paper body. Our experimental results showed that T5 is the better generation model for this task, as it outperformed GPT-2 in BLEU and METEOR implying that the generated text are clearer and more precise. Moreover, inputting relevant sentences matching the row header or whole table is effective. ","[{'version': 'v1', 'created': 'Wed, 18 Aug 2021 12:25:43 GMT'}]",2021-08-19,"[['Xu', 'Junjie H.', ''], ['Shinden', 'Kohei', ''], ['Kato', 'Makoto P.', '']]",0,1,2021-08-18,1,3,1,2,2,0,77351fea9e6fced1f51fd1998af29e40622b0ac4,237194658.0,https://www.semanticscholar.org/paper/77351fea9e6fced1f51fd1998af29e40622b0ac4,Global Conference on Consumer Electronics,2021.0,20.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2150636502', 'name': 'Junjie H. Xu'}, {'authorId': '2104810655', 'name': 'Kohei Shinden'}, {'authorId': '32878737', 'name': 'Makoto P. Kato'}]",['University of Tsukuba'],['Japan'],2021-08
2108.10168,Aishwarya N,"Aishwarya Narasimhan (1), Krishna Prasad Agara Venkatesha Rao (2),
  Veena M B (1) ((1) B M S College of Engineering, (2) Sony India Software
  Centre Pvt. Ltd.)",CGEMs: A Metric Model for Automatic Code Generation using GPT-3,"11 pages, 6 figures, 2 tables",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Today, AI technology is showing its strengths in almost every industry and walks of life. From text generation, text summarization, chatbots, NLP is being used widely. One such paradigm is automatic code generation. An AI could be generating anything; hence the output space is unconstrained. A self-driving car is driven for 100 million miles to validate its safety, but tests cannot be written to monitor and cover an unconstrained space. One of the solutions to validate AI-generated content is to constrain the problem and convert it from abstract to realistic, and this can be accomplished by either validating the unconstrained algorithm using theoretical proofs or by using Monte-Carlo simulation methods. In this case, we use the latter approach to test/validate a statistically significant number of samples. This hypothesis of validating the AI-generated code is the main motive of this work and to know if AI-generated code is reliable, a metric model CGEMs is proposed. This is an extremely challenging task as programs can have different logic with different naming conventions, but the metrics must capture the structure and logic of the program. This is similar to the importance grammar carries in AI-based text generation, Q&A, translations, etc. The various metrics that are garnered in this work to support the evaluation of generated code are as follows: Compilation, NL description to logic conversion, number of edits needed, some of the commonly used static-code metrics and NLP metrics. These metrics are applied to 80 codes generated using OpenAI's GPT-3. Post which a Neural network is designed for binary classification (acceptable/not acceptable quality of the generated code). The inputs to this network are the values of the features obtained from the metrics. The model achieves a classification accuracy of 76.92% and an F1 score of 55.56%. XAI is augmented for model interpretability. ","[{'version': 'v1', 'created': 'Mon, 23 Aug 2021 13:28:57 GMT'}]",2021-08-24,"[['Narasimhan', 'Aishwarya', ''], ['Rao', 'Krishna Prasad Agara Venkatesha', ''], ['B', 'Veena M', '']]",0,1,2021-08-23,1,3,1,1,0,1,c07506e0dec92b2cc7552b810c82d90de3c92aa9,237267183.0,https://www.semanticscholar.org/paper/c07506e0dec92b2cc7552b810c82d90de3c92aa9,arXiv.org,2021.0,17.0,9.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2124124630', 'name': 'Aishwarya Narasimhan'}, {'authorId': '2148265827', 'name': 'Krishna Prasad Agara Venkatesha Rao'}, {'authorId': '2229341849', 'name': 'Veena M B B M S College of Engineering'}, {'authorId': '2229344256', 'name': 'Sony India Software Centre Pvt. Ltd.'}]","['Program Manager, Sony India Software Centre Pvt. Ltd.', 'R.V. College of Engineering']",['India'],2021-08
2108.11696,Ting-Yun Chang,Ting-Yun Chang and Chi-Jen Lu,Rethinking Why Intermediate-Task Fine-Tuning Works,Findings of EMNLP 2021,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a widely applied technique, which first fine-tunes the pretrained language models on an intermediate task before on the target task of interest. While STILTs is able to further improve the performance of pretrained language models, it is still unclear why and when it works. Previous research shows that those intermediate tasks involving complex inference, such as commonsense reasoning, work especially well for RoBERTa. In this paper, we discover that the improvement from an intermediate task could be orthogonal to it containing reasoning or other complex skills -- a simple real-fake discrimination task synthesized by GPT2 can benefit diverse target tasks. We conduct extensive experiments to study the impact of different factors on STILTs. These findings suggest rethinking the role of intermediate fine-tuning in the STILTs pipeline. ","[{'version': 'v1', 'created': 'Thu, 26 Aug 2021 10:34:37 GMT'}, {'version': 'v2', 'created': 'Wed, 1 Sep 2021 12:07:55 GMT'}]",2021-09-02,"[['Chang', 'Ting-Yun', ''], ['Lu', 'Chi-Jen', '']]",0,1,2021-08-26,2,2,1,1,1,0,e6f94081276a7a5e6aef34a080cb3d3a4b1b9c20,237303924.0,https://www.semanticscholar.org/paper/e6f94081276a7a5e6aef34a080cb3d3a4b1b9c20,Conference on Empirical Methods in Natural Language Processing,2021.0,38.0,20.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3386996', 'name': 'Ting-Yun Chang'}, {'authorId': '1390518825', 'name': 'Chi-Jen Lu'}]","['Institute of Information Science, Academia Sinica']",['Taiwan'],2021-08
2108.12626,Ilya Gusev,Ilya Gusev and Alexey Tikhonov,HeadlineCause: A Dataset of News Headlines for Detecting Causalities,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Detecting implicit causal relations in texts is a task that requires both common sense and world knowledge. Existing datasets are focused either on commonsense causal reasoning or explicit causal relations. In this work, we present HeadlineCause, a dataset for detecting implicit causal relations between pairs of news headlines. The dataset includes over 5000 headline pairs from English news and over 9000 headline pairs from Russian news labeled through crowdsourcing. The pairs vary from totally unrelated or belonging to the same general topic to the ones including causation and refutation relations. We also present a set of models and experiments that demonstrates the dataset validity, including a multilingual XLM-RoBERTa based model for causality detection and a GPT-2 based model for possible effects prediction. ","[{'version': 'v1', 'created': 'Sat, 28 Aug 2021 11:12:49 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Sep 2021 14:01:26 GMT'}]",2021-09-29,"[['Gusev', 'Ilya', ''], ['Tikhonov', 'Alexey', '']]",0,1,2021-08-28,2,2,2,1,1,0,856d1e90d6fab3f449086f0469ded43642b86c3c,237353401.0,https://www.semanticscholar.org/paper/856d1e90d6fab3f449086f0469ded43642b86c3c,International Conference on Language Resources and Evaluation,2021.0,47.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145281628', 'name': 'I. Gusev'}, {'authorId': '34501167', 'name': 'Alexey Tikhonov'}]","['Freie Universität Berlin', 'Institute of Physics and Technology']","['Germany', 'Russia']",2021-08
2108.13093,Ezgi Korkmaz,Ezgi Korkmaz,Investigating Vulnerabilities of Deep Neural Policies,"Presented at the Conference on Uncertainty in Artificial Intelligence
  (UAI) 2021",,,,cs.LG cs.AI cs.CV stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reinforcement learning policies based on deep neural networks are vulnerable to imperceptible adversarial perturbations to their inputs, in much the same way as neural network image classifiers. Recent work has proposed several methods to improve the robustness of deep reinforcement learning agents to adversarial perturbations based on training in the presence of these imperceptible perturbations (i.e. adversarial training). In this paper, we study the effects of adversarial training on the neural policy learned by the agent. In particular, we follow two distinct parallel approaches to investigate the outcomes of adversarial training on deep neural policies based on worst-case distributional shift and feature sensitivity. For the first approach, we compare the Fourier spectrum of minimal perturbations computed for both adversarially trained and vanilla trained neural policies. Via experiments in the OpenAI Atari environments we show that minimal perturbations computed for adversarially trained policies are more focused on lower frequencies in the Fourier domain, indicating a higher sensitivity of these policies to low frequency perturbations. For the second approach, we propose a novel method to measure the feature sensitivities of deep neural policies and we compare these feature sensitivity differences in state-of-the-art adversarially trained deep neural policies and vanilla trained deep neural policies. We believe our results can be an initial step towards understanding the relationship between adversarial training and different notions of robustness for neural policies. ","[{'version': 'v1', 'created': 'Mon, 30 Aug 2021 10:04:50 GMT'}]",2021-08-31,"[['Korkmaz', 'Ezgi', '']]",0,0,2021-08-30,1,1,4,0,0,0,f0d89cbe0d639785afa352825a23c412c069f77b,237353668.0,https://www.semanticscholar.org/paper/f0d89cbe0d639785afa352825a23c412c069f77b,Conference on Uncertainty in Artificial Intelligence,2021.0,28.0,23.0,0.0,False,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '72639731', 'name': 'Ezgi Korkmaz'}]",['KTH Royal Institute of Technology'],['Sweden'],2021-08
2108.13349,Jordi Armengol-Estap\'e,"Jordi Armengol-Estap\'e, Ona de Gibert Bonet and Maite Melero",On the Multilingual Capabilities of Very Large-Scale English Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative Pre-trained Transformers (GPTs) have recently been scaled to unprecedented sizes in the history of machine learning. These models, solely trained on the language modeling objective, have been shown to exhibit outstanding few-shot learning capabilities in a number of different tasks. Nevertheless, aside from anecdotal experiences, little is known regarding their multilingual capabilities, given the fact that the pre-training corpus is almost entirely composed of English text. In this work, we investigate the multilingual skills of GPT-3, focusing on one language that barely appears in the pre-training corpus, Catalan, which makes the results especially meaningful; we assume that our results may be relevant for other languages as well. We find that the model shows an outstanding performance, particularly in generative tasks, with predictable limitations mostly in language understanding tasks but still with remarkable results given the zero-shot scenario. We investigate its potential and limits in extractive question-answering and natural language generation, as well as the effect of scale in terms of model size. ","[{'version': 'v1', 'created': 'Mon, 30 Aug 2021 16:18:50 GMT'}]",2021-08-31,"[['Armengol-Estapé', 'Jordi', ''], ['Bonet', 'Ona de Gibert', ''], ['Melero', 'Maite', '']]",0,1,2021-08-30,1,3,2,1,0,1,88afeaf0a4208477e845170daa8a189cc0a13a73,237352964.0,https://www.semanticscholar.org/paper/88afeaf0a4208477e845170daa8a189cc0a13a73,International Conference on Language Resources and Evaluation,2021.0,32.0,9.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2123452669', 'name': ""Jordi Armengol-Estap'e""}, {'authorId': '73879139', 'name': 'Ona de Gibert Bonet'}, {'authorId': '144431961', 'name': 'Maite Melero'}]",['Barcelona Supercomputing Center'],['Spain'],2021-08
2109.00239,Paolo Tirotta,Paolo Tirotta and Stefano Lodi,OptAGAN: Entropy-based finetuning on text VAE-GAN,"11 pages, 5 figures, 8 tables","NLP2021, CS & IT, V11N23",,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transfer learning through large pre-trained models has changed the landscape of current applications in natural language processing (NLP). Recently Optimus, a variational autoencoder (VAE) which combines two pre-trained models, BERT and GPT-2, has been released, and its combination with generative adversial networks (GANs) has been shown to produce novel, yet very human-looking text. The Optimus and GANs combination avoids the troublesome application of GANs to the discrete domain of text, and prevents the exposure bias of standard maximum likelihood methods. We combine the training of GANs in the latent space, with the finetuning of the decoder of Optimus for single word generation. This approach lets us model both the high-level features of the sentences, and the low-level word-by-word generation. We finetune using reinforcement learning (RL) by exploiting the structure of GPT-2 and by adding entropy-based intrinsically motivated rewards to balance between quality and diversity. We benchmark the results of the VAE-GAN model, and show the improvements brought by our RL finetuning on three widely used datasets for text generation, with results that greatly surpass the current state-of-the-art for the quality of the generated texts. ","[{'version': 'v1', 'created': 'Wed, 1 Sep 2021 08:23:19 GMT'}]",2022-01-05,"[['Tirotta', 'Paolo', ''], ['Lodi', 'Stefano', '']]",0,1,2021-09-01,1,2,1,1,1,0,510c4b9753eaaa4b1e9c9468d2d1952b148ab338,237373641.0,https://www.semanticscholar.org/paper/510c4b9753eaaa4b1e9c9468d2d1952b148ab338,Natural Language Processing,2021.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2125330891', 'name': 'Paolo Tirotta'}, {'authorId': '1751534', 'name': 'Stefano Lodi'}]","['Statistical Service', 'University of Bologna']","['Cyprus', 'Italy']",2021-09
2109.00591,Tomer Wullach,"Tomer Wullach, Amir Adler, Einat Minkov",Fight Fire with Fire: Fine-tuning Hate Detectors using Large Samples of Generated Hate Speech,Accepted to Findings of ACL: EMNLP 2021,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic hate speech detection is hampered by the scarcity of labeled datasetd, leading to poor generalization. We employ pretrained language models (LMs) to alleviate this data bottleneck. We utilize the GPT LM for generating large amounts of synthetic hate speech sequences from available labeled examples, and leverage the generated data in fine-tuning large pretrained LMs on hate detection. An empirical study using the models of BERT, RoBERTa and ALBERT, shows that this approach improves generalization significantly and consistently within and across data distributions. In fact, we find that generating relevant labeled hate speech sequences is preferable to using out-of-domain, and sometimes also within-domain, human-labeled examples. ","[{'version': 'v1', 'created': 'Wed, 1 Sep 2021 19:47:01 GMT'}]",2021-09-03,"[['Wullach', 'Tomer', ''], ['Adler', 'Amir', ''], ['Minkov', 'Einat', '']]",0,1,2021-09-01,1,3,2,0,0,0,14fa6eed1d77cfd8e40c9bf344cd5f0685f394ab,237386458.0,https://www.semanticscholar.org/paper/14fa6eed1d77cfd8e40c9bf344cd5f0685f394ab,Conference on Empirical Methods in Natural Language Processing,2021.0,23.0,20.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1693988594', 'name': 'Tomer Wullach'}, {'authorId': '39243222', 'name': 'A. Adler'}, {'authorId': '1816914', 'name': 'Einat Minkov'}]","['University of Haifa', 'Braude College of Engineering and MIT']",['Israel'],2021-09
2109.00729,Cagri Toraman,Eyup Halit Yilmaz and Cagri Toraman,ConQX: Semantic Expansion of Spoken Queries for Intent Detection based on Conditioned Text Generation,"5 pages, 1 figure, conference",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Intent detection of spoken queries is a challenging task due to their noisy structure and short length. To provide additional information regarding the query and enhance the performance of intent detection, we propose a method for semantic expansion of spoken queries, called ConQX, which utilizes the text generation ability of an auto-regressive language model, GPT-2. To avoid off-topic text generation, we condition the input query to a structured context with prompt mining. We then apply zero-shot, one-shot, and few-shot learning. We lastly use the expanded queries to fine-tune BERT and RoBERTa for intent detection. The experimental results show that the performance of intent detection can be improved by our semantic expansion method. ","[{'version': 'v1', 'created': 'Thu, 2 Sep 2021 05:57:07 GMT'}]",2021-09-03,"[['Yilmaz', 'Eyup Halit', ''], ['Toraman', 'Cagri', '']]",0,1,2021-09-02,1,2,2,1,1,0,2afde58474acb35f1091614f189d731e4d47861f,237385837.0,https://www.semanticscholar.org/paper/2afde58474acb35f1091614f189d731e4d47861f,arXiv.org,2021.0,22.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1830448719', 'name': 'E. Yilmaz'}, {'authorId': '2648640', 'name': 'Cagri Toraman'}]","['Aselsan Research Center Ankara, Turkey']",['Turkey'],2021-09
2109.00859,Yue Wang,"Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi",CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation,Accepted to EMNLP 2021. 13 pages,,,,cs.CL cs.PL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Pre-trained models for Natural Languages (NL) like BERT and GPT have been recently shown to transfer well to Programming Languages (PL) and largely benefit a broad set of code-related tasks. Despite their success, most current methods either rely on an encoder-only (or decoder-only) pre-training that is suboptimal for generation (resp. understanding) tasks or process the code snippet in the same way as NL, neglecting the special characteristics of PL such as token types. We present CodeT5, a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. Our model employs a unified framework to seamlessly support both code understanding and generation tasks and allows for multi-task learning. Besides, we propose a novel identifier-aware pre-training task that enables the model to distinguish which code tokens are identifiers and to recover them when they are masked. Furthermore, we propose to exploit the user-written code comments with a bimodal dual generation task for better NL-PL alignment. Comprehensive experiments show that CodeT5 significantly outperforms prior methods on understanding tasks such as code defect detection and clone detection, and generation tasks across various directions including PL-NL, NL-PL, and PL-PL. Further analysis reveals that our model can better capture semantic information from code. Our code and pre-trained models are released at https: //github.com/salesforce/CodeT5 . ","[{'version': 'v1', 'created': 'Thu, 2 Sep 2021 12:21:06 GMT'}]",2021-09-03,"[['Wang', 'Yue', ''], ['Wang', 'Weishi', ''], ['Joty', 'Shafiq', ''], ['Hoi', 'Steven C. H.', '']]",0,1,2021-09-02,1,4,2,0,0,0,a30f912f8c5e2a2bfb06351d4578e1ba3fa37896,237386541.0,https://www.semanticscholar.org/paper/a30f912f8c5e2a2bfb06351d4578e1ba3fa37896,Conference on Empirical Methods in Natural Language Processing,2021.0,38.0,616.0,179.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49416727', 'name': 'Yue Wang'}, {'authorId': '2108528154', 'name': 'Weishi Wang'}, {'authorId': '2708940', 'name': 'Shafiq R. Joty'}, {'authorId': '1741126', 'name': 'S. Hoi'}]",['Nanyang Technological University'],['Singapore'],2021-09
2109.02102,Gabriel Recchia,Gabriel Recchia,Teaching Autoregressive Language Models Complex Tasks By Demonstration,"Corrected typo in Figure 2. Updated two citations to adhere to the
  format preferred by the cited authors",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper demonstrates that by fine-tuning an autoregressive language model (GPT-Neo) on appropriately structured step-by-step demonstrations, it is possible to teach it to execute a mathematical task that has previously proved difficult for Transformers - longhand modulo operations - with a relatively small number of examples. Specifically, we fine-tune GPT-Neo to solve the numbers__div_remainder task from the DeepMind Mathematics Dataset; Saxton et al. (arXiv:1904.01557) reported below 40% accuracy on this task with 2 million training examples. We show that after fine-tuning on 200 appropriately structured demonstrations of solving long division problems and reporting the remainders, the smallest available GPT-Neo model achieves over 80% accuracy. This is achieved by constructing an appropriate dataset for fine-tuning, with no changes to the learning algorithm. These results suggest that fine-tuning autoregressive language models on small sets of well-crafted demonstrations may be a useful paradigm for enabling individuals without training in machine learning to coax such models to perform some kinds of complex multi-step tasks. ","[{'version': 'v1', 'created': 'Sun, 5 Sep 2021 15:25:28 GMT'}, {'version': 'v2', 'created': 'Sat, 11 Sep 2021 20:45:09 GMT'}, {'version': 'v3', 'created': 'Fri, 3 Dec 2021 15:54:00 GMT'}]",2021-12-06,"[['Recchia', 'Gabriel', '']]",0,1,2021-09-05,3,1,2,0,0,0,0f2199296f01694ee46b6059879260fb80a84fa6,237420883.0,https://www.semanticscholar.org/paper/0f2199296f01694ee46b6059879260fb80a84fa6,arXiv.org,2021.0,46.0,18.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '34955837', 'name': 'Gabriel Recchia'}]",['University of Cambridge'],['United Kingdom'],2021-09
2109.03926,Lisa Bylinina,"Lisa Bylinina, Alexey Tikhonov",Transformers in the loop: Polarity in neural models of language,Accepted to ACL 2022 main conference,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Representation of linguistic phenomena in computational language models is typically assessed against the predictions of existing linguistic theories of these phenomena. Using the notion of polarity as a case study, we show that this is not always the most adequate set-up. We probe polarity via so-called 'negative polarity items' (in particular, English 'any') in two pre-trained Transformer-based models (BERT and GPT-2). We show that - at least for polarity - metrics derived from language models are more consistent with data from psycholinguistic experiments than linguistic theory predictions. Establishing this allows us to more adequately evaluate the performance of language models and also to use language models to discover new insights into natural language grammar beyond existing linguistic theories. This work contributes to establishing closer ties between psycholinguistic experiments and experiments with language models. ","[{'version': 'v1', 'created': 'Wed, 8 Sep 2021 20:56:32 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Mar 2022 20:58:14 GMT'}]",2022-03-21,"[['Bylinina', 'Lisa', ''], ['Tikhonov', 'Alexey', '']]",0,1,2021-09-08,2,2,1,1,1,0,a418c0daa98a3639e1b1bd682c68644250259944,237453303.0,https://www.semanticscholar.org/paper/a418c0daa98a3639e1b1bd682c68644250259944,Annual Meeting of the Association for Computational Linguistics,2021.0,37.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '3280023', 'name': 'Lisa Bylinina'}, {'authorId': '34501167', 'name': 'Alexey Tikhonov'}]","['Yandex', 'University of Okara']","['Germany', 'Pakistan']",2021-09
2109.04155,Pablo Lanillos,"Niels van Hoeffelen, Pablo Lanillos",Deep Active Inference for Pixel-Based Discrete Control: Evaluation on the Car Racing Problem,"2nd International Workshop on Active Inference IWAI2021, European
  Conference on Machine Learning (ECML/PCKDD 2021)",,,,cs.AI cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the potential of active inference for visual-based control, learning the model and the preferences (priors) while interacting with the environment is challenging. Here, we study the performance of a deep active inference (dAIF) agent on OpenAI's car racing benchmark, where there is no access to the car's state. The agent learns to encode the world's state from high-dimensional input through unsupervised representation learning. State inference and control are learned end-to-end by optimizing the expected free energy. Results show that our model achieves comparable performance to deep Q-learning. However, vanilla dAIF does not reach state-of-the-art performance compared to other world model approaches. Hence, we discuss the current model implementation's limitations and potential architectures to overcome them. ","[{'version': 'v1', 'created': 'Thu, 9 Sep 2021 10:33:36 GMT'}]",2021-09-10,"[['van Hoeffelen', 'Niels', ''], ['Lanillos', 'Pablo', '']]",0,0,2021-09-09,1,2,2,0,0,0,19dc9ce9a42bd254a354bc6f3470693129e61101,237453542.0,https://www.semanticscholar.org/paper/19dc9ce9a42bd254a354bc6f3470693129e61101,PKDD/ECML Workshops,2021.0,27.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2126060674', 'name': 'Niels van Hoeffelen'}, {'authorId': '2865315', 'name': 'Pablo Lanillos'}]",['Radboud University Nijmegen'],['The Netherlands'],2021-09
2109.04322,Zhaocheng Liu,"Zhaocheng Liu, Fernando Acero, Zhibin Li",Learning Vision-Guided Dynamic Locomotion Over Challenging Terrains,"9 pages, 27 figures, 1 table",,,,cs.RO,http://creativecommons.org/licenses/by/4.0/,"  Legged robots are becoming increasingly powerful and popular in recent years for their potential to bring the mobility of autonomous agents to the next level. This work presents a deep reinforcement learning approach that learns a robust Lidar-based perceptual locomotion policy in a partially observable environment using Proximal Policy Optimisation. Visual perception is critical to actively overcome challenging terrains, and to do so, we propose a novel learning strategy: Dynamic Reward Strategy (DRS), which serves as effective heuristics to learn a versatile gait using a neural network architecture without the need to access the history data. Moreover, in a modified version of the OpenAI gym environment, the proposed work is evaluated with scores over 90% success rate in all tested challenging terrains. ","[{'version': 'v1', 'created': 'Thu, 9 Sep 2021 14:56:00 GMT'}]",2021-09-10,"[['Liu', 'Zhaocheng', ''], ['Acero', 'Fernando', ''], ['Li', 'Zhibin', '']]",0,0,2021-09-09,1,3,1,0,0,0,d6300149735fd9d02c4a88c774537034165a82ee,237453306.0,https://www.semanticscholar.org/paper/d6300149735fd9d02c4a88c774537034165a82ee,arXiv.org,2021.0,28.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': None, 'name': 'Zhaocheng Liu'}, {'authorId': '2126051157', 'name': 'Fernando Acero'}, {'authorId': '48458541', 'name': 'Zhibin Li'}]",['University of Edinburgh'],['United Kingdom'],2021-09
2109.04921,Tomasz Limisiewicz,Tomasz Limisiewicz and David Mare\v{c}ek,Examining Cross-lingual Contextual Embeddings with Orthogonal Structural Probes,EMNLP 2021 Main Conference,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  State-of-the-art contextual embeddings are obtained from large language models available only for a few languages. For others, we need to learn representations using a multilingual model. There is an ongoing debate on whether multilingual embeddings can be aligned in a space shared across many languages. The novel Orthogonal Structural Probe (Limisiewicz and Mare\v{c}ek, 2021) allows us to answer this question for specific linguistic features and learn a projection based only on mono-lingual annotated datasets. We evaluate syntactic (UD) and lexical (WordNet) structural information encoded inmBERT's contextual representations for nine diverse languages. We observe that for languages closely related to English, no transformation is needed. The evaluated information is encoded in a shared cross-lingual embedding space. For other languages, it is beneficial to apply orthogonal transformation learned separately for each language. We successfully apply our findings to zero-shot and few-shot cross-lingual parsing. ","[{'version': 'v1', 'created': 'Fri, 10 Sep 2021 15:03:11 GMT'}]",2021-09-13,"[['Limisiewicz', 'Tomasz', ''], ['Mareček', 'David', '']]",0,0,2021-09-10,1,2,2,0,0,0,698c2d985d2568dfb8c76f96396897cc5ca29800,237485576.0,https://www.semanticscholar.org/paper/698c2d985d2568dfb8c76f96396897cc5ca29800,Conference on Empirical Methods in Natural Language Processing,2021.0,51.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1666636295', 'name': 'Tomasz Limisiewicz'}, {'authorId': '1666831775', 'name': 'David Marevcek'}]",['Charles University'],['Czechia'],2021-09
2109.06595,Febrian Setianto,"Febrian Setianto, Erion Tsani, Fatima Sadiq, Georgios Domalis,
  Dimitris Tsakalidis, Panos Kostakos",GPT-2C: A GPT-2 parser for Cowrie honeypot logs,,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Deception technologies like honeypots produce comprehensive log reports, but often lack interoperability with EDR and SIEM technologies. A key bottleneck is that existing information transformation plugins perform well on static logs (e.g. geolocation), but face limitations when it comes to parsing dynamic log topics (e.g. user-generated content). In this paper, we present a run-time system (GPT-2C) that leverages large pre-trained models (GPT-2) to parse dynamic logs generate by a Cowrie SSH honeypot. Our fine-tuned model achieves 89\% inference accuracy in the new domain and demonstrates acceptable execution latency. ","[{'version': 'v1', 'created': 'Tue, 14 Sep 2021 11:33:04 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Sep 2021 06:33:01 GMT'}]",2021-09-16,"[['Setianto', 'Febrian', ''], ['Tsani', 'Erion', ''], ['Sadiq', 'Fatima', ''], ['Domalis', 'Georgios', ''], ['Tsakalidis', 'Dimitris', ''], ['Kostakos', 'Panos', '']]",0,1,2021-09-14,2,6,1,1,1,0,08d208d24124161b99f04608adf033672a47a7c2,237502710.0,https://www.semanticscholar.org/paper/08d208d24124161b99f04608adf033672a47a7c2,arXiv.org,2021.0,23.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35915638', 'name': 'Febrian Setianto'}, {'authorId': '2126865117', 'name': 'Erion Tsani'}, {'authorId': '2126857544', 'name': 'Fatima Sadiq'}, {'authorId': '17733590', 'name': 'Georgios Domalis'}, {'authorId': '2060868377', 'name': 'Dimitris Tsakalidis'}, {'authorId': '35688956', 'name': 'Panos Kostakos'}]","['th Dimitris Tsakalidis NOVELCORE Patra, Grece', 'University of Oulu', 'University of Patras']","['Greece', 'Finland']",2021-09
2109.06807,David Wilmot,"David Wilmot, Frank Keller",A Temporal Variational Model for Story Generation,"9 pages, 19 with references and appendices, 6 figures, and 4 tables",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Recent language models can generate interesting and grammatically correct text in story generation but often lack plot development and long-term coherence. This paper experiments with a latent vector planning approach based on a TD-VAE (Temporal Difference Variational Autoencoder), using the model for conditioning and reranking for text generation. The results demonstrate strong performance in automatic cloze and swapping evaluations. The human judgments show stories generated with TD-VAE reranking improve on a GPT-2 medium baseline and show comparable performance to a hierarchical LSTM reranking model. Conditioning on the latent vectors proves disappointing and deteriorates performance in human evaluation because it reduces the diversity of generation, and the models don't learn to progress the narrative. This highlights an important difference between technical task performance (e.g. cloze) and generating interesting stories. ","[{'version': 'v1', 'created': 'Tue, 14 Sep 2021 16:36:12 GMT'}]",2021-09-15,"[['Wilmot', 'David', ''], ['Keller', 'Frank', '']]",0,1,2021-09-14,1,2,2,1,1,0,c692cc203e5745ee92b030e65a35bce6c12590f1,237503438.0,https://www.semanticscholar.org/paper/c692cc203e5745ee92b030e65a35bce6c12590f1,arXiv.org,2021.0,64.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1666944787', 'name': 'David Wilmot'}, {'authorId': '1393020635', 'name': 'Frank Keller'}]",['University of Edinburgh'],['United Kingdom'],2021-09
2109.07958,Stephanie Lin,"Stephanie Lin, Jacob Hilton, Owain Evans",TruthfulQA: Measuring How Models Mimic Human Falsehoods,"ACL 2022 (main conference); the TruthfulQA benchmark and evaluation
  code is available at https://github.com/sylinrl/TruthfulQA",,,,cs.CL cs.AI cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58% of questions, while human performance was 94%. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web. ","[{'version': 'v1', 'created': 'Wed, 8 Sep 2021 17:15:27 GMT'}, {'version': 'v2', 'created': 'Sun, 8 May 2022 02:43:02 GMT'}]",2022-05-10,"[['Lin', 'Stephanie', ''], ['Hilton', 'Jacob', ''], ['Evans', 'Owain', '']]",0,1,2021-09-08,2,3,4,3,2,1,77d956cdab4508d569ae5741549b78e715fd0749,237532606.0,https://www.semanticscholar.org/paper/77d956cdab4508d569ae5741549b78e715fd0749,Annual Meeting of the Association for Computational Linguistics,2021.0,64.0,361.0,62.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48639938', 'name': 'Stephanie C. Lin'}, {'authorId': '2052366271', 'name': 'Jacob Hilton'}, {'authorId': '47107786', 'name': 'Owain Evans'}]",['University of Oxford'],['United Kingdom'],2021-09
2109.08634,Deborah Ferreira,"Julia Rozanova, Deborah Ferreira, Krishna Dubba, Weiwei Cheng, Dell
  Zhang, Andre Freitas",Grounding Natural Language Instructions: Can Large Language Models Capture Spatial Information?,*Equal contribution,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Models designed for intelligent process automation are required to be capable of grounding user interface elements. This task of interface element grounding is centred on linking instructions in natural language to their target referents. Even though BERT and similar pre-trained language models have excelled in several NLP tasks, their use has not been widely explored for the UI grounding domain. This work concentrates on testing and probing the grounding abilities of three different transformer-based models: BERT, RoBERTa and LayoutLM. Our primary focus is on these models' spatial reasoning skills, given their importance in this domain. We observe that LayoutLM has a promising advantage for applications in this domain, even though it was created for a different original purpose (representing scanned documents): the learned spatial features appear to be transferable to the UI grounding setting, especially as they demonstrate the ability to discriminate between target directions in natural language instructions. ","[{'version': 'v1', 'created': 'Fri, 17 Sep 2021 16:36:30 GMT'}]",2021-09-20,"[['Rozanova', 'Julia', ''], ['Ferreira', 'Deborah', ''], ['Dubba', 'Krishna', ''], ['Cheng', 'Weiwei', ''], ['Zhang', 'Dell', ''], ['Freitas', 'Andre', '']]",0,0,2021-09-17,1,6,2,0,0,0,bd3e5aeefec1f7a42b54c75b6ca80d083bc3634a,237563126.0,https://www.semanticscholar.org/paper/bd3e5aeefec1f7a42b54c75b6ca80d083bc3634a,arXiv.org,2021.0,23.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8471045', 'name': 'Julia Rozanova'}, {'authorId': '2058261256', 'name': 'Deborah Ferreira'}, {'authorId': '2392273', 'name': 'K. Dubba'}, {'authorId': '2116795549', 'name': 'Weiwei Cheng'}, {'authorId': '2145943595', 'name': 'Dell Zhang'}, {'authorId': '2057619238', 'name': 'André Freitas'}]","['University of Manchester', 'Blue Marine Foundation', 'ByteDance', 'Idiap Research Institute']","['United Kingdom', 'Switzerland']",2021-09
2109.09707,Damian Pascual,"Damian Pascual, Beni Egressy, Clara Meister, Ryan Cotterell, Roger
  Wattenhofer",A Plug-and-Play Method for Controlled Text Generation,Findings of EMNLP 2021,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large pre-trained language models have repeatedly shown their ability to produce fluent text. Yet even when starting from a prompt, generation can continue in many plausible directions. Current decoding methods with the goal of controlling generation, e.g., to ensure specific words are included, either require additional models or fine-tuning, or work poorly when the task at hand is semantically unconstrained, e.g., story generation. In this work, we present a plug-and-play decoding method for controlled language generation that is so simple and intuitive, it can be described in a single sentence: given a topic or keyword, we add a shift to the probability distribution over our vocabulary towards semantically similar words. We show how annealing this distribution can be used to impose hard constraints on language generation, something no other plug-and-play method is currently able to do with SOTA language generators. Despite the simplicity of this approach, we see it works incredibly well in practice: decoding from GPT-2 leads to diverse and fluent sentences while guaranteeing the appearance of given guide words. We perform two user studies, revealing that (1) our method outperforms competing methods in human evaluations; and (2) forcing the guide words to appear in the generated text has no impact on the fluency of the generated text. ","[{'version': 'v1', 'created': 'Mon, 20 Sep 2021 17:27:03 GMT'}]",2021-09-21,"[['Pascual', 'Damian', ''], ['Egressy', 'Beni', ''], ['Meister', 'Clara', ''], ['Cotterell', 'Ryan', ''], ['Wattenhofer', 'Roger', '']]",0,1,2021-09-20,1,5,2,1,1,0,ddcd5bed531c13e0da65e30333aaa5c27914f882,237571784.0,https://www.semanticscholar.org/paper/ddcd5bed531c13e0da65e30333aaa5c27914f882,Conference on Empirical Methods in Natural Language Processing,2021.0,46.0,52.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150973452', 'name': 'Damian Pascual'}, {'authorId': '1935472784', 'name': 'Béni Egressy'}, {'authorId': '150953620', 'name': 'Clara Meister'}, {'authorId': '1750769', 'name': 'Ryan Cotterell'}, {'authorId': '2075356250', 'name': 'Roger Wattenhofer'}]","['University of Cambridge', 'ETH Zurich']","['United Kingdom', 'Switzerland']",2021-09
2109.10638,Alexis-Michel Mugabushaka,"Alexis-Michel Mugabushaka, Miriam Baglioni, Alessia Bardi and Paolo
  Manghi",Scholarly outputs of EU Research Funding Programs: Understanding differences between datasets of publications reported by grant holders and OpenAIRE Research Graph in H2020,,,,,cs.DL,http://creativecommons.org/licenses/by/4.0/,"  Linking research results to grants is an essential prerequisite for an effective monitoring and evaluation of funding programs. For the EU research funding programs, there are multiple datasets linking scholarly publications to the individual grants, including both open data and those from commercial bibliometric databases. In this paper, we systematically compare openly available data from two data sources: on one hand those reported by the Grant holders (and subsequently published by the European Commission on open data portal) and those from the OpenAIRE Research Graph which collect data from multiple sources. We describe the dataflow leading to their creation and assess the quality of data by validating, on sample basis, the link <project, publications>. We report that, by and large, OpenAIRE Research Graph offers a more complete dataset of scholarly outputs of from EU Research funding programs. We identify also possible improvements and make recommendations on how they can be addressed. ","[{'version': 'v1', 'created': 'Wed, 22 Sep 2021 10:31:21 GMT'}]",2021-09-23,"[['Mugabushaka', 'Alexis-Michel', ''], ['Baglioni', 'Miriam', ''], ['Bardi', 'Alessia', ''], ['Manghi', 'Paolo', '']]",0,0,2021-09-22,1,4,1,0,0,0,fcb6a14ff8ef2195ab57e01531193818202605fc,237592577.0,https://www.semanticscholar.org/paper/fcb6a14ff8ef2195ab57e01531193818202605fc,arXiv.org,2021.0,14.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2234648', 'name': 'Alexis-Michel Mugabushaka'}, {'authorId': '1824207', 'name': 'Miriam Baglioni'}, {'authorId': '39565794', 'name': 'A. Bardi'}, {'authorId': '1799502', 'name': 'P. Manghi'}]","['Institute of Information Science and Technologies', 'European Commission']","['Belgium', 'Italy']",2021-09
2109.10724,Takaaki Saeki,"Takaaki Saeki, Shinnosuke Takamichi, and Hiroshi Saruwatari",Low-Latency Incremental Text-to-Speech Synthesis with Distilled Context Prediction Network,Accepted for ASRU2021,,,,cs.SD cs.CL eess.AS,http://creativecommons.org/licenses/by-sa/4.0/,"  Incremental text-to-speech (TTS) synthesis generates utterances in small linguistic units for the sake of real-time and low-latency applications. We previously proposed an incremental TTS method that leverages a large pre-trained language model to take unobserved future context into account without waiting for the subsequent segment. Although this method achieves comparable speech quality to that of a method that waits for the future context, it entails a huge amount of processing for sampling from the language model at each time step. In this paper, we propose an incremental TTS method that directly predicts the unobserved future context with a lightweight model, instead of sampling words from the large-scale language model. We perform knowledge distillation from a GPT2-based context prediction network into a simple recurrent model by minimizing a teacher-student loss defined between the context embedding vectors of those models. Experimental results show that the proposed method requires about ten times less inference time to achieve comparable synthetic speech quality to that of our previous method, and it can perform incremental synthesis much faster than the average speaking speed of human English speakers, demonstrating the availability of our method to real-time applications. ","[{'version': 'v1', 'created': 'Wed, 22 Sep 2021 13:29:10 GMT'}]",2021-09-23,"[['Saeki', 'Takaaki', ''], ['Takamichi', 'Shinnosuke', ''], ['Saruwatari', 'Hiroshi', '']]",0,1,2021-09-22,1,3,3,1,1,0,00ec7370642482b5b84effa039779d2149e78ce8,237592971.0,https://www.semanticscholar.org/paper/00ec7370642482b5b84effa039779d2149e78ce8,Automatic Speech Recognition & Understanding,2021.0,39.0,1.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32078983', 'name': 'Takaaki Saeki'}, {'authorId': '2424104', 'name': 'Shinnosuke Takamichi'}, {'authorId': '1685827', 'name': 'H. Saruwatari'}]",['The University of Tokyo'],['Japan'],2021-09
2109.11321,Tobias Norlund,"Tobias Norlund, Lovisa Hagstr\""om, Richard Johansson",Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models are known to suffer from the hallucination problem in that they are prone to output statements that are false or inconsistent, indicating a lack of knowledge. A proposed solution to this is to provide the model with additional data modalities that complements the knowledge obtained through text. We investigate the use of visual data to complement the knowledge of large language models by proposing a method for evaluating visual knowledge transfer to text for uni- or multimodal language models. The method is based on two steps, 1) a novel task querying for knowledge of memory colors, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions. Additionally, we introduce a model architecture that involves a visual imagination step and evaluate it with our proposed method. We find that our method can successfully be used to measure visual knowledge transfer capabilities in models and that our novel model architecture shows promising results for leveraging multimodal knowledge in a unimodal setting. ","[{'version': 'v1', 'created': 'Thu, 23 Sep 2021 12:11:23 GMT'}, {'version': 'v2', 'created': 'Thu, 30 Sep 2021 09:36:41 GMT'}]",2021-10-01,"[['Norlund', 'Tobias', ''], ['Hagström', 'Lovisa', ''], ['Johansson', 'Richard', '']]",0,0,2021-09-23,2,3,1,0,0,0,3e075efc541c7d2b357199655e11f084686e8575,237605175.0,https://www.semanticscholar.org/paper/3e075efc541c7d2b357199655e11f084686e8575,BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,2021.0,38.0,14.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '16960142', 'name': 'Tobias Norlund'}, {'authorId': '2106434987', 'name': 'Lovisa Hagström'}, {'authorId': '145341661', 'name': 'Richard Johansson'}]",['Chalmers University of Technology'],['Sweden'],2021-09
2109.13582,Antoine Chaffin,"Antoine Chaffin, Vincent Claveau, Ewa Kijak",PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided MCTS Decoding,"15 pages, 5 tables, 7 figures, accepted to NAACL 2022",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large language models (LM) based on Transformers allow to generate plausible long texts. In this paper, we explore how this generation can be further controlled at decoding time to satisfy certain constraints (e.g. being non-toxic, conveying certain emotions, using a specific writing style, etc.) without fine-tuning the LM. Precisely, we formalize constrained generation as a tree exploration process guided by a discriminator that indicates how well the associated sequence respects the constraint. This approach, in addition to being easier and cheaper to train than fine-tuning the LM, allows to apply the constraint more finely and dynamically. We propose several original methods to search this generation tree, notably the Monte Carlo Tree Search (MCTS) which provides theoretical guarantees on the search efficiency, but also simpler methods based on re-ranking a pool of diverse sequences using the discriminator scores. These methods are evaluated, with automatic and human-based metrics, on two types of constraints and languages: review polarity and emotion control in French and English. We show that discriminator-guided MCTS decoding achieves state-of-the-art results without having to tune the language model, in both tasks and languages. We also demonstrate that other proposed decoding methods based on re-ranking can be really effective when diversity among the generated propositions is encouraged. ","[{'version': 'v1', 'created': 'Tue, 28 Sep 2021 09:29:15 GMT'}, {'version': 'v2', 'created': 'Wed, 4 May 2022 08:55:21 GMT'}]",2022-05-05,"[['Chaffin', 'Antoine', ''], ['Claveau', 'Vincent', ''], ['Kijak', 'Ewa', '']]",0,0,2021-09-28,2,3,1,0,0,0,6dc1db69749fcb6484a11cd9465e9945068027bf,248512793.0,https://www.semanticscholar.org/paper/6dc1db69749fcb6484a11cd9465e9945068027bf,North American Chapter of the Association for Computational Linguistics,2021.0,39.0,15.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2129106958', 'name': 'Antoine Chaffin'}, {'authorId': '1735666', 'name': 'V. Claveau'}, {'authorId': '1801242', 'name': 'Ewa Kijak'}]","['IMATAG, 13 Rue Dupont-des-Loges, 35000 Rennes, France', 'CNRS, IRISA, Univ. Rennes 1, Campus de Beaulieu, 35000 Rennes, France']",['France'],2021-09
2109.14728,Kory W Mathewson,"Boyd Branch, Piotr Mirowski, Kory W. Mathewson",Collaborative Storytelling with Human Actors and AI Narrators,"5 pages, 1 figure, accepted to ICCC as Short Paper: Event Report",,,,cs.HC cs.AI,http://creativecommons.org/licenses/by/4.0/,  Large language models can be used for collaborative storytelling. In this work we report on using GPT-3 \cite{brown2020language} to co-narrate stories. The AI system must track plot progression and character arcs while the human actors perform scenes. This event report details how a novel conversational agent was employed as creative partner with a team of professional improvisers to explore long-form spontaneous story narration in front of a live public audience. We introduced novel constraints on our language model to produce longer narrative text and tested the model in rehearsals with a team of professional improvisers. We then field tested the model with two live performances for public audiences as part of a live theatre festival in Europe. We surveyed audience members after each performance as well as performers to evaluate how well the AI performed in its role as narrator. Audiences and performers responded positively to AI narration and indicated preference for AI narration over AI characters within a scene. Performers also responded positively to AI narration and expressed enthusiasm for the creative and meaningful novel narrative directions introduced to the scenes. Our findings support improvisational theatre as a useful test-bed to explore how different language models can collaborate with humans in a variety of social contexts. ,"[{'version': 'v1', 'created': 'Wed, 29 Sep 2021 21:21:35 GMT'}]",2021-10-01,"[['Branch', 'Boyd', ''], ['Mirowski', 'Piotr', ''], ['Mathewson', 'Kory W.', '']]",0,1,2021-09-29,1,3,2,1,0,1,87c587e00e08fe19713f60e2c9b59ffe785a39be,238226905.0,https://www.semanticscholar.org/paper/87c587e00e08fe19713f60e2c9b59ffe785a39be,International Conference on Innovative Computing and Cloud Computing,2021.0,33.0,5.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","[{'authorId': '104253794', 'name': 'Boyd Branch'}, {'authorId': '144705062', 'name': 'Piotr Wojciech Mirowski'}, {'authorId': '2034344309', 'name': 'K. Mathewson'}]","['Improbotics Canada improbotics.org', 'Improbotics United Kingdom improbotics.org', 'University of Kent']","['Canada', 'United Kingdom']",2021-09
2109.14845,Theodoros Galanos,"Theodoros Galanos, Antonios Liapis, Georgios N. Yannakakis",AffectGAN: Affect-Based Generative Art Driven by Semantics,"Published in the ""What's Next in Affect Modeling?"" workshop at the
  Affective Computing & Intelligent Interaction (ACII) 2021 conference, 7
  pages, 3 figures",,,,cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper introduces a novel method for generating artistic images that express particular affective states. Leveraging state-of-the-art deep learning methods for visual generation (through generative adversarial networks), semantic models from OpenAI, and the annotated dataset of the visual art encyclopedia WikiArt, our AffectGAN model is able to generate images based on specific or broad semantic prompts and intended affective outcomes. A small dataset of 32 images generated by AffectGAN is annotated by 50 participants in terms of the particular emotion they elicit, as well as their quality and novelty. Results show that for most instances the intended emotion used as a prompt for image generation matches the participants' responses. This small-scale study brings forth a new vision towards blending affective computing with computational creativity, enabling generative systems with intentionality in terms of the emotions they wish their output to elicit. ","[{'version': 'v1', 'created': 'Thu, 30 Sep 2021 04:53:25 GMT'}]",2021-10-01,"[['Galanos', 'Theodoros', ''], ['Liapis', 'Antonios', ''], ['Yannakakis', 'Georgios N.', '']]",0,0,2021-09-30,1,3,2,0,0,0,4ecb8cf901768daa4972e489a838b4c45c3a0a5f,238226725.0,https://www.semanticscholar.org/paper/4ecb8cf901768daa4972e489a838b4c45c3a0a5f,2021 9th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),2021.0,30.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Art', 'source': 's2-fos-model'}]","[{'authorId': '97764972', 'name': 'Theodoros Galanos'}, {'authorId': '1713331', 'name': 'Antonios Liapis'}, {'authorId': '1686193', 'name': 'Georgios N. Yannakakis'}]",['University of Malta'],['Malta'],2021-09
2109.15079,Milan Janosov,Mil\'an Janosov and Fl\'ora Borsi,Asimov's Foundation -- turning a data story into an NFT artwork,"12 pages, 5 figures",,,,physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this piece, we overview Isaac Asimov's most iconic work, the Foundation series, with two primary goals: to provide quantitative insights about the novels and bridge data science with digital art. First, we rely on data science and text processing tools to describe certain properties of Asimov's career and the novels, focusing on the different worlds in Asimov's universe. Then we transform the books' texts into a network centered around Asimov's planets and their semantic context. Finally, we introduce the world of crypto art and non-fungible tokens (NFTs) by transforming the visualized network into a high-end digital piece of art minted as an NFT. Additionally, to pay tribute to Asimov's devotion to robotics and artificial intelligence, we use OpenAI's Generative Pre-trained Transformer 3 (GPT-3) to draft several paragraphs of this paper. ","[{'version': 'v1', 'created': 'Thu, 30 Sep 2021 12:41:54 GMT'}]",2021-10-01,"[['Janosov', 'Milán', ''], ['Borsi', 'Flóra', '']]",0,1,2021-09-30,1,2,1,1,0,1,5edc426a6aa6db6d5ef2eb16c4fd1d098897fe77,238226565.0,https://www.semanticscholar.org/paper/5edc426a6aa6db6d5ef2eb16c4fd1d098897fe77,,2021.0,15.0,1.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51301358', 'name': 'Milán Janosov'}, {'authorId': '2130175508', 'name': ""Fl'ora Borsi""}]","['Central European University - Budapest Campus', 'University of Milan', 'Datapolis Inc, Budapest, 1112, Hungary']","['Italy', 'Hungary']",2021-09
2110.00929,Jiwon Seo,"Hyungjun Oh, Hyungjun Oh, HyeongJu Kim, Jiwon Seo",Scheduling Optimization Techniques for Neural Network Training,,,,,cs.LG cs.DC,http://creativecommons.org/licenses/by/4.0/,"  Neural network training requires a large amount of computation and thus GPUs are often used for the acceleration. While they improve the performance, GPUs are underutilized during the training.This paper proposes out-of-order (ooo) backprop, an effective scheduling technique for neural network training. By exploiting the dependencies of gradient computations, ooo backprop enables to reorder their executions to make the most of the GPU resources. We show that the GPU utilization in single-GPU, data-parallel, and pipeline-parallel training can be commonly improve by applying ooo back-prop and prioritizing critical operations. We propose three scheduling algorithms based on ooo backprop. For single-GPU training, we schedule with multi-stream out-of-order computation to mask the kernel launch overhead. In data-parallel training, we reorder the gradient computations to maximize the overlapping of computation and parameter communication; in pipeline-parallel training, we prioritize critical gradient computations to reduce the pipeline stalls.We evaluate our optimizations with twelve neural networks including a light-weight computer vision model (MobileNet) and largeNLP models (BERT and GPT-3) with up to forty eight V100 GPUs.Our scheduling algorithms effectively improve the performance of single-GPU training as well as data- and pipeline-parallel training.Compared to the respective state of the art training systems, the throughput is substantially improved for single-GPU, data-parallel, and pipeline-parallel training. ","[{'version': 'v1', 'created': 'Sun, 3 Oct 2021 05:45:06 GMT'}]",2021-10-05,"[['Oh', 'Hyungjun', ''], ['Oh', 'Hyungjun', ''], ['Kim', 'HyeongJu', ''], ['Seo', 'Jiwon', '']]",0,1,2021-10-03,1,4,2,1,0,1,b4fbcd41f9339528fd04d9c5eb66e05a51eefd5b,238259666.0,https://www.semanticscholar.org/paper/b4fbcd41f9339528fd04d9c5eb66e05a51eefd5b,arXiv.org,2021.0,67.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2105614495', 'name': 'Hyungjun Oh'}, {'authorId': '2108522497', 'name': 'Junyeol Lee'}, {'authorId': '2109894594', 'name': 'Hyeongju Kim'}, {'authorId': '1491137873', 'name': 'Jiwon Seo'}]",['Hanyang University'],['South Korea'],2021-10
2110.01963,Abeba Birhane,"Abeba Birhane, Vinay Uday Prabhu and Emmanuel Kahembwe","Multimodal datasets: misogyny, pornography, and malignant stereotypes",33 pages,,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  We have now entered the era of trillion parameter machine learning models trained on billion-sized datasets scraped from the internet. The rise of these gargantuan datasets has given rise to formidable bodies of critical work that has called for caution while generating these large datasets. These address concerns surrounding the dubious curation practices used to generate these datasets, the sordid quality of alt-text data available on the world wide web, the problematic content of the CommonCrawl dataset often used as a source for training large language models, and the entrenched biases in large-scale visio-linguistic models (such as OpenAI's CLIP model) trained on opaque datasets (WebImageText). In the backdrop of these specific calls of caution, we examine the recently released LAION-400M dataset, which is a CLIP-filtered dataset of Image-Alt-text pairs parsed from the Common-Crawl dataset. We found that the dataset contains, troublesome and explicit images and text pairs of rape, pornography, malign stereotypes, racist and ethnic slurs, and other extremely problematic content. We outline numerous implications, concerns and downstream harms regarding the current state of large scale datasets while raising open questions for various stakeholders including the AI community, regulators, policy makers and data subjects. ","[{'version': 'v1', 'created': 'Tue, 5 Oct 2021 11:47:27 GMT'}]",2021-10-06,"[['Birhane', 'Abeba', ''], ['Prabhu', 'Vinay Uday', ''], ['Kahembwe', 'Emmanuel', '']]",0,0,2021-10-05,1,3,1,0,0,0,267f1de5ff863ab03f8c48c7ac3df1d422de7c3b,238354158.0,https://www.semanticscholar.org/paper/267f1de5ff863ab03f8c48c7ac3df1d422de7c3b,arXiv.org,2021.0,73.0,177.0,13.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8318698', 'name': 'A. Birhane'}, {'authorId': '2670978', 'name': 'Vinay Uday Prabhu'}, {'authorId': '26432578', 'name': 'Emmanuel Kahembwe'}]","['University of Edinburgh', 'University College Dublin']","['Ireland', 'United Kingdom']",2021-10
2110.03215,Joel Jang,"Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han,
  Gyeonghun Kim, Stanley Jungkyu Choi, Minjoon Seo",Towards Continual Knowledge Learning of Language Models,published at ICLR 2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LMs) are known to encode world knowledge in their parameters as they pretrain on a vast amount of web corpus, which is often utilized for performing knowledge-dependent downstream tasks such as question answering, fact-checking, and open dialogue. In real-world scenarios, the world knowledge stored in the LMs can quickly become outdated as the world changes, but it is non-trivial to avoid catastrophic forgetting and reliably acquire new knowledge while preserving invariant knowledge. To push the community towards better maintenance of ever-changing LMs, we formulate a new continual learning (CL) problem called Continual Knowledge Learning (CKL). We construct a new benchmark and metric to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. We adopt applicable recent methods from literature to create several strong baselines. Through extensive experiments, we find that CKL exhibits unique challenges that are not addressed in previous CL setups, where parameter expansion is necessary to reliably retain and learn knowledge simultaneously. By highlighting the critical causes of knowledge forgetting, we show that CKL is a challenging and important problem that helps us better understand and train ever-changing LMs. The benchmark datasets, evaluation script, and baseline code to reproduce our results are available at https://github.com/joeljang/continual-knowledge-learning. ","[{'version': 'v1', 'created': 'Thu, 7 Oct 2021 07:00:57 GMT'}, {'version': 'v2', 'created': 'Fri, 8 Oct 2021 02:55:40 GMT'}, {'version': 'v3', 'created': 'Tue, 26 Oct 2021 14:39:10 GMT'}, {'version': 'v4', 'created': 'Tue, 24 May 2022 13:15:25 GMT'}]",2022-05-25,"[['Jang', 'Joel', ''], ['Ye', 'Seonghyeon', ''], ['Yang', 'Sohee', ''], ['Shin', 'Joongbo', ''], ['Han', 'Janghoon', ''], ['Kim', 'Gyeonghun', ''], ['Choi', 'Stanley Jungkyu', ''], ['Seo', 'Minjoon', '']]",0,0,2021-10-07,4,8,2,0,0,0,ce828f9986b196308a3e40b1de58af1e8e68d728,238419458.0,https://www.semanticscholar.org/paper/ce828f9986b196308a3e40b1de58af1e8e68d728,International Conference on Learning Representations,2021.0,62.0,64.0,5.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2000091730', 'name': 'Joel Jang'}, {'authorId': '2152111477', 'name': 'Seonghyeon Ye'}, {'authorId': '16110760', 'name': 'Sohee Yang'}, {'authorId': '27582486', 'name': 'Joongbo Shin'}, {'authorId': '2109439831', 'name': 'Janghoon Han'}, {'authorId': '2116260339', 'name': 'Gyeonghun Kim'}, {'authorId': '153079375', 'name': 'Stanley Jungkyu Choi'}, {'authorId': '4418074', 'name': 'Minjoon Seo'}]","['LG AI Research', 'Korea Advanced Institute of Science and Technology']",['South Korea'],2021-10
2110.04071,Ricard Delgado-Gonzalo,"Pierre Louis Gaudilliere, Halla Sigurthorsdottir, Cl\'ementine Aguet,
  J\'er\^ome Van Zaen, Mathieu Lemay, Ricard Delgado-Gonzalo",Generative Pre-Trained Transformer for Cardiac Abnormality Detection,"4 pages, 2 figures, accepted for publication in CinC 2021",,,,eess.SP cs.LG,http://creativecommons.org/licenses/by/4.0/,"  ECG heartbeat classification plays a vital role in diagnosis of cardiac arrhythmia. The goal of the Physionet/CinC 2021 challenge was to accurately classify clinical diagnosis based on 12, 6, 4, 3 or 2-lead ECG recordings in order to aid doctors in the diagnoses of different heart conditions. Transformers have had great success in the field of natural language processing in the past years. Our team, CinCSEM, proposes to draw the parallel between text and periodic time series signals by viewing the repeated period as words and the whole signal as a sequence of such words. In this way, the attention mechanisms of the transformers can be applied to periodic time series signals. In our implementation, we follow the Transformer Encoder architecture, which combines several encoder layers followed by a dense layer with linear or sigmoid activation for generative pre-training or classification, respectively. The use case presented here is multi-label classification of heartbeat abnormalities of ECG recordings shared by the challenge. Our best entry, not exceeding the challenge's hardware limitations, achieved a score of 0.12, 0.07, 0.10, 0.10 and 0.07 on 12-lead, 6-lead, 4-lead, 3-lead and 2-lead test set respectively. Unfortunately, our team was unable to be ranked because of a missing pre-print. ","[{'version': 'v1', 'created': 'Thu, 7 Oct 2021 12:01:12 GMT'}]",2021-10-11,"[['Gaudilliere', 'Pierre Louis', ''], ['Sigurthorsdottir', 'Halla', ''], ['Aguet', 'Clémentine', ''], ['Van Zaen', 'Jérôme', ''], ['Lemay', 'Mathieu', ''], ['Delgado-Gonzalo', 'Ricard', '']]",0,1,2021-10-07,1,6,2,0,0,0,3b6230d62c1ceaef53089e825c3c41d5c37cf8d1,237589655.0,https://www.semanticscholar.org/paper/3b6230d62c1ceaef53089e825c3c41d5c37cf8d1,2021 Computing in Cardiology (CinC),2021.0,10.0,2.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '121957434', 'name': 'P. Gaudilliere'}, {'authorId': '1972387119', 'name': 'Halla Sigurthorsdottir'}, {'authorId': '1505816242', 'name': 'Clémentine Aguet'}, {'authorId': '9092152', 'name': 'J. V. Zaen'}, {'authorId': '12693205', 'name': 'M. Lemay'}, {'authorId': '1397904342', 'name': 'R. Delgado-Gonzalo'}]",['Swiss Center for Electronics and Microtechnology (Switzerland)'],['Switzerland'],2021-10
2110.05221,Yu-Jia Liou,"Po-Nien Kung, Chung-Cheng Chang, Tse-Hsuan Yang, Hsin-Kai Hsu, Yu-Jia
  Liou, Yun-Nung Chen",Multi-Task Learning for Situated Multi-Domain End-to-End Dialogue Systems,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Task-oriented dialogue systems have been a promising area in the NLP field. Previous work showed the effectiveness of using a single GPT-2 based model to predict belief states and responses via causal language modeling. In this paper, we leverage multi-task learning techniques to train a GPT-2 based model on a more challenging dataset with multiple domains, multiple modalities, and more diversity in output formats.   Using only a single model, our method achieves better performance on all sub-tasks, across domains, compared to task and domain-specific models. Furthermore, we evaluated several proposed strategies for GPT-2 based dialogue systems with comprehensive ablation studies, showing that all techniques can further improve the performance. ","[{'version': 'v1', 'created': 'Mon, 11 Oct 2021 12:36:30 GMT'}]",2021-10-12,"[['Kung', 'Po-Nien', ''], ['Chang', 'Chung-Cheng', ''], ['Yang', 'Tse-Hsuan', ''], ['Hsu', 'Hsin-Kai', ''], ['Liou', 'Yu-Jia', ''], ['Chen', 'Yun-Nung', '']]",0,1,2021-10-11,1,6,2,1,1,0,1442d9062c5c44d3e8b9843c06379327a1c7e32a,238583086.0,https://www.semanticscholar.org/paper/1442d9062c5c44d3e8b9843c06379327a1c7e32a,arXiv.org,2021.0,22.0,5.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2008339028', 'name': 'Po-Nien Kung'}, {'authorId': '2152948751', 'name': 'Chung-Cheng Chang'}, {'authorId': '2007796100', 'name': 'Tse-Hsuan Yang'}, {'authorId': '1382288007', 'name': 'H. Hsu'}, {'authorId': '2131832611', 'name': 'Yu-Jia Liou'}, {'authorId': '2144862809', 'name': 'Yun-Nung Chen'}]",['National Taiwan University'],['Taiwan'],2021-10
2110.06961,Arvid Frydenlund,"Arvid Frydenlund, Gagandeep Singh, Frank Rudzicz",Language Modelling via Learning to Rank,Accepted to AAAI22. Minor writing fixes,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We consider language modelling (LM) as a multi-label structured prediction task by re-framing training from solely predicting a single ground-truth word to ranking a set of words which could continue a given context. To avoid annotating top-$k$ ranks, we generate them using pre-trained LMs: GPT-2, BERT, and Born-Again models. This leads to a rank-based form of knowledge distillation (KD). We also develop a method using $N$-grams to create a non-probabilistic teacher which generates the ranks without the need of a pre-trained LM.   We confirm the hypotheses that we can treat LMing as a ranking task and that we can do so without the use of a pre-trained LM. We show that rank-based KD generally improves perplexity (PPL), often with statistical significance, when compared to Kullback-Leibler-based KD. Surprisingly, given the simplicity of the method, $N$-grams act as competitive teachers and achieve similar performance as using either BERT or a Born-Again model teachers. GPT-2 always acts as the best teacher, though, and using it and a Transformer-XL student on Wiki-02, rank-based KD reduces a cross-entropy baseline from 65.27 to 55.94 and against a KL-based KD of 56.70. ","[{'version': 'v1', 'created': 'Wed, 13 Oct 2021 18:03:47 GMT'}, {'version': 'v2', 'created': 'Fri, 10 Dec 2021 19:49:23 GMT'}]",2021-12-14,"[['Frydenlund', 'Arvid', ''], ['Singh', 'Gagandeep', ''], ['Rudzicz', 'Frank', '']]",0,1,2021-10-13,2,3,2,1,1,0,f21be3f230cb2721904671c7747165edad8bd033,238856846.0,https://www.semanticscholar.org/paper/f21be3f230cb2721904671c7747165edad8bd033,AAAI Conference on Artificial Intelligence,2021.0,58.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '94728448', 'name': 'A. Frydenlund'}, {'authorId': '2117029335', 'name': 'Gagandeep Singh'}, {'authorId': '2479037', 'name': 'Frank Rudzicz'}]","['Nuance Communications (Canada)', 'Vector Institute']",['Canada'],2021-10
2110.08152,Mehdi Rezagholizadeh,"Ali Edalati, Marzieh Tahaei, Ahmad Rashid, Vahid Partovi Nia, James J.
  Clark, Mehdi Rezagholizadeh",Kronecker Decomposition for GPT Compression,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  GPT is an auto-regressive Transformer-based pre-trained language model which has attracted a lot of attention in the natural language processing (NLP) domain due to its state-of-the-art performance in several downstream tasks. The success of GPT is mostly attributed to its pre-training on huge amount of data and its large number of parameters (from ~100M to billions of parameters). Despite the superior performance of GPT (especially in few-shot or zero-shot setup), this overparameterized nature of GPT can be very prohibitive for deploying this model on devices with limited computational power or memory. This problem can be mitigated using model compression techniques; however, compressing GPT models has not been investigated much in the literature. In this work, we use Kronecker decomposition to compress the linear mappings of the GPT-22 model. Our Kronecker GPT-2 model (KnGPT2) is initialized based on the Kronecker decomposed version of the GPT-2 model and then is undergone a very light pre-training on only a small portion of the training data with intermediate layer knowledge distillation (ILKD). Finally, our KnGPT2 is fine-tuned on down-stream tasks using ILKD as well. We evaluate our model on both language modeling and General Language Understanding Evaluation benchmark tasks and show that with more efficient pre-training and similar number of parameters, our KnGPT2 outperforms the existing DistilGPT2 model significantly. ","[{'version': 'v1', 'created': 'Fri, 15 Oct 2021 15:28:39 GMT'}]",2021-10-18,"[['Edalati', 'Ali', ''], ['Tahaei', 'Marzieh', ''], ['Rashid', 'Ahmad', ''], ['Nia', 'Vahid Partovi', ''], ['Clark', 'James J.', ''], ['Rezagholizadeh', 'Mehdi', '']]",0,1,2021-10-15,1,6,1,1,1,0,b6f616e9305e59c9dc7ccf33c311ede47584caf6,239009526.0,https://www.semanticscholar.org/paper/b6f616e9305e59c9dc7ccf33c311ede47584caf6,Annual Meeting of the Association for Computational Linguistics,2021.0,38.0,16.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46206760', 'name': 'A. Edalati'}, {'authorId': '1996315', 'name': 'Marzieh S. Tahaei'}, {'authorId': '2064509318', 'name': 'Ahmad Rashid'}, {'authorId': '10127337', 'name': 'V. Nia'}, {'authorId': '2151085963', 'name': 'J. Clark'}, {'authorId': '2066076226', 'name': 'Mehdi Rezagholizadeh'}]",['McGill University'],['Canada'],2021-10
2110.15723,Tuan Nguyen,"Tuan Nguyen, Hanh Pham, Truong Bui, Tan Nguyen, Duc Luong, Phong
  Nguyen",SP-GPT2: Semantics Improvement in Vietnamese Poetry Generation,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Automatic text generation has garnered growing attention in recent years as an essential step towards computer creativity. Generative Pretraining Transformer 2 (GPT2) is one of the state of the art approaches that have excellent successes. In this paper, we took the first step to investigate the power of GPT2 in traditional Vietnamese poetry generation. In the earlier time, our experiment with base GPT2 was quite good at generating the poem in the proper template. Though it can learn the patterns, including rhyme and tone rules, from the training data, like almost all other text generation approaches, the poems generated still has a topic drift and semantic inconsistency. To improve the cohesion within the poems, we proposed a new model SP-GPT2 (semantic poem GPT2) which was built on the top GPT2 model and an additional loss to constrain context throughout the entire poem. For better evaluation, we examined the methods by both automatic quantitative evaluation and human evaluation. Both automatic and human evaluation demonstrated that our approach can generate poems that have better cohesion without losing the quality due to additional loss. At the same time, we are the pioneers of this topic. We released the first computational scoring module for poems generated in the template containing the style rule dictionary. Additionally, we are the first to publish a Luc-Bat dataset, including 87609 Luc Bat poems, which is equivalent to about 2.6 million sentences, combined with about 83579 poems in other styles was also published for further exploration. The code is available at https://github.com/fsoft-ailab/Poem-Generator ","[{'version': 'v1', 'created': 'Sun, 10 Oct 2021 14:31:08 GMT'}]",2021-11-01,"[['Nguyen', 'Tuan', ''], ['Pham', 'Hanh', ''], ['Bui', 'Truong', ''], ['Nguyen', 'Tan', ''], ['Luong', 'Duc', ''], ['Nguyen', 'Phong', '']]",0,1,2021-10-10,1,6,3,1,1,0,fe3761961169c61e249b0845e85271e50bd3a57a,240288823.0,https://www.semanticscholar.org/paper/fe3761961169c61e249b0845e85271e50bd3a57a,International Conference on Machine Learning and Applications,2021.0,26.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1684642857', 'name': 'Tuan-Duy H. Nguyen'}, {'authorId': '145388276', 'name': 'H. Pham'}, {'authorId': '73607348', 'name': 'T. Bui'}, {'authorId': '2191810014', 'name': 'Tan-Minh Nguyen'}, {'authorId': '25160156', 'name': 'D. Luong'}, {'authorId': '2056638825', 'name': 'Phong Nguyen'}]","['Hanoi University of Science and Technology', 'National Economics University', 'The University of Tokyo']","['Japan', 'Vietnam']",2021-10
2111.00607,Xiang Li,"Xiang Lorraine Li, Adhiguna Kuncoro, Jordan Hoffmann, Cyprien de
  Masson d'Autume, Phil Blunsom, Aida Nematzadeh",A Systematic Investigation of Commonsense Knowledge in Large Language Models,Accepted to EMNLP 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Language models (LMs) trained on large amounts of data have shown impressive performance on many NLP tasks under the zero-shot and few-shot setup. Here we aim to better understand the extent to which such models learn commonsense knowledge -- a critical component of many NLP applications. We conduct a systematic and rigorous zero-shot and few-shot commonsense evaluation of large pre-trained LMs, where we: (i) carefully control for the LMs' ability to exploit potential surface cues and annotation artefacts, and (ii) account for variations in performance that arise from factors that are not related to commonsense knowledge. Our findings highlight the limitations of pre-trained LMs in acquiring commonsense knowledge without task-specific supervision; furthermore, using larger models or few-shot evaluation are insufficient to achieve human-level commonsense performance. ","[{'version': 'v1', 'created': 'Sun, 31 Oct 2021 22:20:36 GMT'}, {'version': 'v2', 'created': 'Wed, 16 Feb 2022 05:50:58 GMT'}, {'version': 'v3', 'created': 'Mon, 31 Oct 2022 19:59:33 GMT'}]",2022-11-02,"[['Li', 'Xiang Lorraine', ''], ['Kuncoro', 'Adhiguna', ''], ['Hoffmann', 'Jordan', ''], [""d'Autume"", 'Cyprien de Masson', ''], ['Blunsom', 'Phil', ''], ['Nematzadeh', 'Aida', '']]",0,0,2021-10-31,3,6,1,0,0,0,c09ebcb1ca6ad1eced57340f3e81e456416ed185,253244266.0,https://www.semanticscholar.org/paper/c09ebcb1ca6ad1eced57340f3e81e456416ed185,Conference on Empirical Methods in Natural Language Processing,2021.0,66.0,21.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1737850', 'name': 'Xiang Lorraine Li'}, {'authorId': '3376845', 'name': 'A. Kuncoro'}, {'authorId': '46616544', 'name': 'Jordan Hoffmann'}, {'authorId': '1413221272', 'name': ""Cyprien de Masson d'Autume""}, {'authorId': '1685771', 'name': 'Phil Blunsom'}, {'authorId': '3208081', 'name': 'Aida Nematzadeh'}]",['University of Oxford'],['United Kingdom'],2021-10
2111.02202,Irving Petrazzini,Irving G. B. Petrazzini and Eric A. Antonelo,Proximal Policy Optimization with Continuous Bounded Action Space via the Beta Distribution,,,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reinforcement learning methods for continuous control tasks have evolved in recent years generating a family of policy gradient methods that rely primarily on a Gaussian distribution for modeling a stochastic policy. However, the Gaussian distribution has an infinite support, whereas real world applications usually have a bounded action space. This dissonance causes an estimation bias that can be eliminated if the Beta distribution is used for the policy instead, as it presents a finite support. In this work, we investigate how this Beta policy performs when it is trained by the Proximal Policy Optimization (PPO) algorithm on two continuous control tasks from OpenAI gym. For both tasks, the Beta policy is superior to the Gaussian policy in terms of agent's final expected reward, also showing more stability and faster convergence of the training process. For the CarRacing environment with high-dimensional image input, the agent's success rate was improved by 63% over the Gaussian policy. ","[{'version': 'v1', 'created': 'Wed, 3 Nov 2021 13:13:00 GMT'}]",2021-11-04,"[['Petrazzini', 'Irving G. B.', ''], ['Antonelo', 'Eric A.', '']]",0,0,2021-11-03,1,2,2,0,0,0,0fa2536988c7ed67f0128749312dcbe8e91d7cf6,241033363.0,https://www.semanticscholar.org/paper/0fa2536988c7ed67f0128749312dcbe8e91d7cf6,IEEE Symposium Series on Computational Intelligence,2021.0,18.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2137377965', 'name': 'Irving G. B. Petrazzini'}, {'authorId': '3105097', 'name': 'Eric A. Antonelo'}]",['Universidade Federal de Santa Catarina'],['Brazil'],2021-11
2111.02687,Nikolaos Stylianou,"Nikolaos Stylianou, Ioannis Vlahavas",CoreLM: Coreference-aware Language Model Fine-Tuning,"12 pages, 2 figures, Accepted at Fourth Workshop on Computational
  Models of Reference, Anaphora and Coreference",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Language Models are the underpin of all modern Natural Language Processing (NLP) tasks. The introduction of the Transformers architecture has contributed significantly into making Language Modeling very effective across many NLP task, leading to significant advancements in the field. However, Transformers come with a big computational cost, which grows quadratically with respect to the input length. This presents a challenge as to understand long texts requires a lot of context. In this paper, we propose a Fine-Tuning framework, named CoreLM, that extends the architecture of current Pretrained Language Models so that they incorporate explicit entity information. By introducing entity representations, we make available information outside the contextual space of the model, which results in a better Language Model for a fraction of the computational cost. We implement our approach using GPT2 and compare the fine-tuned model to the original. Our proposed model achieves a lower Perplexity in GUMBY and LAMBDADA datasets when compared to GPT2 and a fine-tuned version of GPT2 without any changes. We also compare the models' performance in terms of Accuracy in LAMBADA and Children's Book Test, with and without the use of model-created coreference annotations. ","[{'version': 'v1', 'created': 'Thu, 4 Nov 2021 08:44:31 GMT'}]",2021-11-05,"[['Stylianou', 'Nikolaos', ''], ['Vlahavas', 'Ioannis', '']]",0,1,2021-11-04,1,2,3,1,1,0,84b06e7c731d621a46376e6714baa94f2cea7a65,241583458.0,https://www.semanticscholar.org/paper/84b06e7c731d621a46376e6714baa94f2cea7a65,CRAC,2021.0,32.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51050433', 'name': 'Nikolaos Stylianou'}, {'authorId': '1697941', 'name': 'I. Vlahavas'}]",['Aristotle University of Thessaloniki'],['Greece'],2021-11
2111.02878,Matthias Gall\'e,"Matthias Gall\'e, Jos Rozen, Germ\'an Kruszewski, Hady Elsahar",Unsupervised and Distributional Detection of Machine-Generated Text,10 pages,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The power of natural language generation models has provoked a flurry of interest in automatic methods to detect if a piece of text is human or machine-authored. The problem so far has been framed in a standard supervised way and consists in training a classifier on annotated data to predict the origin of one given new document. In this paper, we frame the problem in an unsupervised and distributional way: we assume that we have access to a large collection of unannotated documents, a big fraction of which is machine-generated. We propose a method to detect those machine-generated documents leveraging repeated higher-order n-grams, which we show over-appear in machine-generated text as compared to human ones. That weak signal is the starting point of a self-training setting where pseudo-labelled documents are used to train an ensemble of classifiers. Our experiments show that leveraging that signal allows us to rank suspicious documents accurately. Precision at 5000 is over 90% for top-k sampling strategies, and over 80% for nucleus sampling for the largest model we used (GPT2-large). The drop with increased size of model is small, which could indicate that the results hold for other current and future large language models. ","[{'version': 'v1', 'created': 'Thu, 4 Nov 2021 14:07:46 GMT'}]",2021-11-05,"[['Gallé', 'Matthias', ''], ['Rozen', 'Jos', ''], ['Kruszewski', 'Germán', ''], ['Elsahar', 'Hady', '']]",0,1,2021-11-04,1,4,2,1,1,0,49fc8eb2c3770b005b1b0d34febf14de838aa238,242757564.0,https://www.semanticscholar.org/paper/49fc8eb2c3770b005b1b0d34febf14de838aa238,arXiv.org,2021.0,33.0,16.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2907260', 'name': 'Matthias Gallé'}, {'authorId': '120419790', 'name': 'Jos Rozen'}, {'authorId': '2067996', 'name': 'Germán Kruszewski'}, {'authorId': '2218938', 'name': 'Hady ElSahar'}]",['NAVER'],['South Korea'],2021-11
2111.03922,Julian Aron Prenner,Julian Aron Prenner and Romain Robbes,Automatic Program Repair with OpenAI's Codex: Evaluating QuixBugs,,,,,cs.SE,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  OpenAI's Codex, a GPT-3 like model trained on a large code corpus, has made headlines in and outside of academia. Given a short user-provided description, it is capable of synthesizing code snippets that are syntactically and semantically valid in most cases. In this work, we want to investigate whether Codex is able to localize and fix bugs, a task of central interest in the field of automated program repair. Our initial evaluation uses the multi-language QuixBugs benchmark (40 bugs in both Python and Java). We find that, despite not being trained for APR, Codex is surprisingly effective, and competitive with recent state of the art techniques. Our results also show that Codex is slightly more successful at repairing Python than Java. ","[{'version': 'v1', 'created': 'Sat, 6 Nov 2021 17:11:53 GMT'}]",2021-11-09,"[['Prenner', 'Julian Aron', ''], ['Robbes', 'Romain', '']]",0,1,2021-11-06,1,2,1,2,0,2,1444536496d8064f33e10b38b5820fecfab5b367,243848196.0,https://www.semanticscholar.org/paper/1444536496d8064f33e10b38b5820fecfab5b367,arXiv.org,2021.0,22.0,31.0,3.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2051798865', 'name': 'Julian Aron Prenner'}, {'authorId': '1853058', 'name': 'R. Robbes'}]",['Free University of Bozen-Bolzano'],['Italy'],2021-11
2111.07993,Gabriel Skantze,Gabriel Skantze and Bram Willemsen,CoLLIE: Continual Learning of Language Grounding from Language-Image Embeddings,Published in Journal of Artificial Intelligence Research (JAIR),"Journal of Artificial Intelligence Research (JAIR), 2022, vol. 74,
  pp. 1201-1223",10.1613/jair.1.13689,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents CoLLIE: a simple, yet effective model for continual learning of how language is grounded in vision. Given a pre-trained multimodal embedding model, where language and images are projected in the same semantic space (in this case CLIP by OpenAI), CoLLIE learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. This is done by predicting the difference vector that needs to be applied, as well as a scaling factor for this vector, so that the adjustment is only applied when needed. Unlike traditional few-shot learning, the model does not just learn new classes and labels, but can also generalize to similar language use and leverage semantic compositionality. We verify the model's performance on two different tasks of identifying the targets of referring expressions, where it has to learn new language use. The results show that the model can efficiently learn and generalize from only a few examples, with little interference with the model's original zero-shot performance. ","[{'version': 'v1', 'created': 'Mon, 15 Nov 2021 18:54:58 GMT'}, {'version': 'v2', 'created': 'Mon, 13 Jun 2022 07:20:04 GMT'}, {'version': 'v3', 'created': 'Sun, 10 Jul 2022 09:48:16 GMT'}]",2022-07-12,"[['Skantze', 'Gabriel', ''], ['Willemsen', 'Bram', '']]",0,0,2021-11-15,3,2,1,0,0,0,81a4941983ab5fc38502cd450b4edeea12211c14,244117869.0,https://www.semanticscholar.org/paper/81a4941983ab5fc38502cd450b4edeea12211c14,Journal of Artificial Intelligence Research,2021.0,37.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1711959', 'name': 'Gabriel Skantze'}, {'authorId': '34785846', 'name': 'Bram Willemsen'}]",['KTH Royal Institute of Technology'],['Sweden'],2021-11
2111.08133,Zhuohan Xie,"Zhuohan Xie, Trevor Cohn, Jey Han Lau",Exploring Story Generation with Multi-task Objectives in Variational Autoencoders,"10 pages, 3 figures, ALTA2021",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  GPT-2 has been frequently adapted in story generation models as it provides powerful generative capability. However, it still fails to generate consistent stories and lacks diversity. Current story generation models leverage additional information such as plots or commonsense into GPT-2 to guide the generation process. These approaches focus on improving generation quality of stories while our work look at both quality and diversity. We explore combining BERT and GPT-2 to build a variational autoencoder (VAE), and extend it by adding additional objectives to learn global features such as story topic and discourse relations. Our evaluations show our enhanced VAE can provide better quality and diversity trade off, generate less repetitive story content and learn a more informative latent variable. ","[{'version': 'v1', 'created': 'Mon, 15 Nov 2021 23:07:19 GMT'}]",2021-11-17,"[['Xie', 'Zhuohan', ''], ['Cohn', 'Trevor', ''], ['Lau', 'Jey Han', '']]",0,1,2021-11-15,1,3,2,1,1,0,01c63f6f6d787890c0d9d63c1194e5d71e2b0229,244129850.0,https://www.semanticscholar.org/paper/01c63f6f6d787890c0d9d63c1194e5d71e2b0229,Australasian Language Technology Association Workshop,2021.0,35.0,5.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153580474', 'name': 'Zhuohan Xie'}, {'authorId': '143620680', 'name': 'Trevor Cohn'}, {'authorId': '1800564', 'name': 'Jey Han Lau'}]",['University of Melbourne'],['Australia'],2021-11
2111.08489,Qihao Zhu,"Qihao Zhu, Jianxi Luo",Generative Pre-Trained Transformer for Design Concept Generation: An Exploration,Submitted to the DESIGN 2022 Conference,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Novel concepts are essential for design innovation and can be generated with the aid of data stimuli and computers. However, current generative design algorithms focus on diagrammatic or spatial concepts that are either too abstract to understand or too detailed for early phase design exploration. This paper explores the uses of generative pre-trained transformers (GPT) for natural language design concept generation. Our experiments involve the use of GPT-2 and GPT-3 for different creative reasonings in design tasks. Both show reasonably good performance for verbal design concept generation. ","[{'version': 'v1', 'created': 'Tue, 16 Nov 2021 14:12:08 GMT'}]",2021-11-17,"[['Zhu', 'Qihao', ''], ['Luo', 'Jianxi', '']]",0,1,2021-11-16,1,2,2,2,1,1,e1dcb5940ffb53afce511f08ac4c250e3218cfce,244129984.0,https://www.semanticscholar.org/paper/e1dcb5940ffb53afce511f08ac4c250e3218cfce,Proceedings of the Design Society,2021.0,61.0,26.0,5.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152203384', 'name': 'Qihao Zhu'}, {'authorId': '145990580', 'name': 'Jianxi Luo'}]",['University of Technology'],['Russia'],2021-11
2111.09064,Aleksandra Edwards Mrs,"Aleksandra Edwards, Asahi Ushio, Jose Camacho-Collados, H\'el\`ene de
  Ribaupierre, Alun Preece",Guiding Generative Language Models for Data Augmentation in Few-Shot Text Classification,"Paper has been accepted and presented at DASH workshop, EMNLP 2022
  conference",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Data augmentation techniques are widely used for enhancing the performance of machine learning models by tackling class imbalance issues and data sparsity. State-of-the-art generative language models have been shown to provide significant gains across different NLP tasks. However, their applicability to data augmentation for text classification tasks in few-shot settings have not been fully explored, especially for specialised domains. In this paper, we leverage GPT-2 (Radford A et al, 2019) for generating artificial training instances in order to improve classification performance. Our aim is to analyse the impact the selection process of seed training examples have over the quality of GPT-generated samples and consequently the classifier performance. We perform experiments with several seed selection strategies that, among others, exploit class hierarchical structures and domain expert selection. Our results show that fine-tuning GPT-2 in a handful of label instances leads to consistent classification improvements and outperform competitive baselines. Finally, we show that guiding this process through domain expert selection can lead to further improvements, which opens up interesting research avenues for combining generative models and active learning. ","[{'version': 'v1', 'created': 'Wed, 17 Nov 2021 12:10:03 GMT'}, {'version': 'v2', 'created': 'Mon, 9 Jan 2023 14:34:52 GMT'}]",2023-01-10,"[['Edwards', 'Aleksandra', ''], ['Ushio', 'Asahi', ''], ['Camacho-Collados', 'Jose', ''], ['de Ribaupierre', 'Hélène', ''], ['Preece', 'Alun', '']]",0,1,2021-11-17,2,5,1,1,1,0,4ed78e944e66ba306cb17ef4c7a6d4653db3a29f,244270194.0,https://www.semanticscholar.org/paper/4ed78e944e66ba306cb17ef4c7a6d4653db3a29f,DASH,2021.0,61.0,6.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1383074767', 'name': 'A. Edwards'}, {'authorId': '27044733', 'name': 'Asahi Ushio'}, {'authorId': '1387447871', 'name': 'José Camacho-Collados'}, {'authorId': '2750681', 'name': 'Hélène de Ribaupierre'}, {'authorId': '1762890', 'name': 'A. Preece'}]",['Cardiff University'],['United Kingdom'],2021-11
2111.09734,Ron Mokady,"Ron Mokady, Amir Hertz, and Amit H. Bermano",ClipCap: CLIP Prefix for Image Captioning,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Image captioning is a fundamental task in vision-language understanding, where the model predicts a textual informative caption to a given input image. In this paper, we present a simple approach to address this task. We use CLIP encoding as a prefix to the caption, by employing a simple mapping network, and then fine-tunes a language model to generate the image captions. The recently proposed CLIP model contains rich semantic features which were trained with textual context, making it best for vision-language perception. Our key idea is that together with a pre-trained language model (GPT2), we obtain a wide understanding of both visual and textual data. Hence, our approach only requires rather quick training to produce a competent captioning model. Without additional annotations or pre-training, it efficiently generates meaningful captions for large-scale and diverse datasets. Surprisingly, our method works well even when only the mapping network is trained, while both CLIP and the language model remain frozen, allowing a lighter architecture with less trainable parameters. Through quantitative evaluation, we demonstrate our model achieves comparable results to state-of-the-art methods on the challenging Conceptual Captions and nocaps datasets, while it is simpler, faster, and lighter. Our code is available in https://github.com/rmokady/CLIP_prefix_caption. ","[{'version': 'v1', 'created': 'Thu, 18 Nov 2021 14:49:15 GMT'}]",2021-11-19,"[['Mokady', 'Ron', ''], ['Hertz', 'Amir', ''], ['Bermano', 'Amit H.', '']]",0,1,2021-11-18,1,3,1,1,1,0,a7aa150b55d64d339b1c154d6d88455fc3cbc44f,244346239.0,https://www.semanticscholar.org/paper/a7aa150b55d64d339b1c154d6d88455fc3cbc44f,arXiv.org,2021.0,47.0,315.0,67.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '147940380', 'name': 'Ron Mokady'}, {'authorId': '51437320', 'name': 'Amir Hertz'}]",['Tel Aviv University'],['Israel'],2021-11
2111.10297,Giorgio Angelotti,"Giorgio Angelotti, Nicolas Drougard, Caroline P. C. Chanel",Expert-Guided Symmetry Detection in Markov Decision Processes,"Accepted to the 14th International Conference on Agents and
  Artificial Intelligence - ICAART 2022",,10.5220/0010783400003116,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Learning a Markov Decision Process (MDP) from a fixed batch of trajectories is a non-trivial task whose outcome's quality depends on both the amount and the diversity of the sampled regions of the state-action space. Yet, many MDPs are endowed with invariant reward and transition functions with respect to some transformations of the current state and action. Being able to detect and exploit these structures could benefit not only the learning of the MDP but also the computation of its subsequent optimal control policy. In this work we propose a paradigm, based on Density Estimation methods, that aims to detect the presence of some already supposed transformations of the state-action space for which the MDP dynamics is invariant. We tested the proposed approach in a discrete toroidal grid environment and in two notorious environments of OpenAI's Gym Learning Suite. The results demonstrate that the model distributional shift is reduced when the dataset is augmented with the data obtained by using the detected symmetries, allowing for a more thorough and data-efficient learning of the transition functions. ","[{'version': 'v1', 'created': 'Fri, 19 Nov 2021 16:12:30 GMT'}]",2022-03-08,"[['Angelotti', 'Giorgio', ''], ['Drougard', 'Nicolas', ''], ['Chanel', 'Caroline P. C.', '']]",0,0,2021-11-19,1,3,2,0,0,0,572c97b175c1c2d59fa66a94aca15958275835c1,244463130.0,https://www.semanticscholar.org/paper/572c97b175c1c2d59fa66a94aca15958275835c1,International Conference on Agents and Artificial Intelligence,2021.0,27.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '77741750', 'name': 'Giorgio Angelotti'}, {'authorId': '2387103', 'name': 'Nicolas Drougard'}, {'authorId': '2033916', 'name': 'Caroline Ponzoni Carvalho Chanel'}]",['Université de Toulouse'],['France'],2021-11
2111.11294,Kyuyong Shin,"Kyuyong Shin, Hanock Kwak, Su Young Kim, Max Nihlen Ramstrom, Jisu
  Jeong, Jung-Woo Ha, Kyung-Min Kim",Scaling Law for Recommendation Models: Towards General-purpose User Representations,Accepted at AAAI 2023. This version includes the technical appendix,,,,cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advancement of large-scale pretrained models such as BERT, GPT-3, CLIP, and Gopher, has shown astonishing achievements across various task domains. Unlike vision recognition and language models, studies on general-purpose user representation at scale still remain underexplored. Here we explore the possibility of general-purpose user representation learning by training a universal user encoder at large scales. We demonstrate that the scaling law is present in user representation learning areas, where the training error scales as a power-law with the amount of computation. Our Contrastive Learning User Encoder (CLUE), optimizes task-agnostic objectives, and the resulting user embeddings stretch our expectation of what is possible to do in various downstream tasks. CLUE also shows great transferability to other domains and companies, as performances on an online experiment shows significant improvements in Click-Through-Rate (CTR). Furthermore, we also investigate how the model performance is influenced by the scale factors, such as training data size, model capacity, sequence length, and batch size. Finally, we discuss the broader impacts of CLUE in general. ","[{'version': 'v1', 'created': 'Mon, 15 Nov 2021 10:39:29 GMT'}, {'version': 'v2', 'created': 'Wed, 1 Dec 2021 12:49:38 GMT'}, {'version': 'v3', 'created': 'Sat, 5 Feb 2022 08:09:24 GMT'}, {'version': 'v4', 'created': 'Mon, 21 Nov 2022 10:52:55 GMT'}, {'version': 'v5', 'created': 'Tue, 22 Nov 2022 07:15:03 GMT'}]",2022-11-23,"[['Shin', 'Kyuyong', ''], ['Kwak', 'Hanock', ''], ['Kim', 'Su Young', ''], ['Ramstrom', 'Max Nihlen', ''], ['Jeong', 'Jisu', ''], ['Ha', 'Jung-Woo', ''], ['Kim', 'Kyung-Min', '']]",0,1,2021-11-15,5,7,2,2,0,2,7567744a0e23174166575e8d98590967684696b4,244477730.0,https://www.semanticscholar.org/paper/7567744a0e23174166575e8d98590967684696b4,AAAI Conference on Artificial Intelligence,2021.0,57.0,18.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2810739', 'name': 'Kyuyong Shin'}, {'authorId': '3434480', 'name': 'Hanock Kwak'}, {'authorId': '2109351321', 'name': 'KyungHyun Kim'}, {'authorId': '2143061094', 'name': 'S. Kim'}, {'authorId': '2141575359', 'name': ""Max Nihl'en Ramstrom""}]",['NAVER'],['South Korea'],2021-11
2111.14119,Ye Liu,"Ye Liu, Wolfgang Maier, Wolfgang Minker and Stefan Ultes",Context Matters in Semantically Controlled Language Generation for Task-oriented Dialogue Systems,"accepted at ICON 2021: 18th International Conference on Natural
  Language Processing, Organized by NLP Association India",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work combines information about the dialogue history encoded by pre-trained model with a meaning representation of the current system utterance to realize contextual language generation in task-oriented dialogues. We utilize the pre-trained multi-context ConveRT model for context representation in a model trained from scratch; and leverage the immediate preceding user utterance for context generation in a model adapted from the pre-trained GPT-2. Both experiments with the MultiWOZ dataset show that contextual information encoded by pre-trained model improves the performance of response generation both in automatic metrics and human evaluation. Our presented contextual generator enables higher variety of generated responses that fit better to the ongoing dialogue. Analysing the context size shows that longer context does not automatically lead to better performance, but the immediate preceding user utterance plays an essential role for contextual generation. In addition, we also propose a re-ranker for the GPT-based generation model. The experiments show that the response selected by the re-ranker has a significant improvement on automatic metrics. ","[{'version': 'v1', 'created': 'Sun, 28 Nov 2021 11:48:02 GMT'}]",2021-11-30,"[['Liu', 'Ye', ''], ['Maier', 'Wolfgang', ''], ['Minker', 'Wolfgang', ''], ['Ultes', 'Stefan', '']]",0,1,2021-11-28,1,4,1,1,1,0,f2d04c991a149d6287fe295ecb83ac4e5bee2351,244714940.0,https://www.semanticscholar.org/paper/f2d04c991a149d6287fe295ecb83ac4e5bee2351,ICON,2021.0,36.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': None, 'name': 'Ye Liu'}, {'authorId': '144795479', 'name': 'Wolfgang Maier'}, {'authorId': '1720942', 'name': 'W. Minker'}, {'authorId': '2042754248', 'name': 'Stefan Ultes'}]",['University of Ulm'],['Germany'],2021-11
2111.14447,Idan Schwartz,"Yoad Tewel, Yoav Shalev, Idan Schwartz, Lior Wolf",ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic,To appear in CVPR'22,,,,cs.CV cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent text-to-image matching models apply contrastive learning to large corpora of uncurated pairs of images and sentences. While such models can provide a powerful score for matching and subsequent zero-shot tasks, they are not capable of generating caption given an image. In this work, we repurpose such models to generate a descriptive text given an image at inference time, without any further training or tuning steps. This is done by combining the visual-semantic model with a large language model, benefiting from the knowledge in both web-scale models. The resulting captions are much less restrictive than those obtained by supervised captioning methods. Moreover, as a zero-shot learning method, it is extremely flexible and we demonstrate its ability to perform image arithmetic in which the inputs can be either images or text, and the output is a sentence. This enables novel high-level vision capabilities such as comparing two images or solving visual analogy tests. Our code is available at: https://github.com/YoadTew/zero-shot-image-to-text. ","[{'version': 'v1', 'created': 'Mon, 29 Nov 2021 11:01:49 GMT'}, {'version': 'v2', 'created': 'Thu, 31 Mar 2022 14:53:47 GMT'}]",2022-04-01,"[['Tewel', 'Yoad', ''], ['Shalev', 'Yoav', ''], ['Schwartz', 'Idan', ''], ['Wolf', 'Lior', '']]",0,0,2021-11-29,2,4,3,0,0,0,a2502d2cd7144c5e2bc1d0d7ec37d2c84b37d381,244714558.0,https://www.semanticscholar.org/paper/a2502d2cd7144c5e2bc1d0d7ec37d2c84b37d381,Computer Vision and Pattern Recognition,2021.0,80.0,93.0,14.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2142470821', 'name': 'Yoad Tewel'}, {'authorId': '1644155380', 'name': 'Yoav Shalev'}, {'authorId': '38211837', 'name': 'Idan Schwartz'}, {'authorId': '145128145', 'name': 'Lior Wolf'}]",['Tel Aviv University'],['Israel'],2021-11
2111.15417,Avi Chawla,"Avi Chawla and Nidhi Mulay and Vikas Bishnoi and Gaurav Dhama and Dr.
  Anil Kumar Singh",A Comparative Study of Transformers on Word Sense Disambiguation,"8 pages, 1 figure, 3 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent years of research in Natural Language Processing (NLP) have witnessed dramatic growth in training large models for generating context-aware language representations. In this regard, numerous NLP systems have leveraged the power of neural network-based architectures to incorporate sense information in embeddings, resulting in Contextualized Word Embeddings (CWEs). Despite this progress, the NLP community has not witnessed any significant work performing a comparative study on the contextualization power of such architectures. This paper presents a comparative study and an extensive analysis of nine widely adopted Transformer models. These models are BERT, CTRL, DistilBERT, OpenAI-GPT, OpenAI-GPT2, Transformer-XL, XLNet, ELECTRA, and ALBERT. We evaluate their contextualization power using two lexical sample Word Sense Disambiguation (WSD) tasks, SensEval-2 and SensEval-3. We adopt a simple yet effective approach to WSD that uses a k-Nearest Neighbor (kNN) classification on CWEs. Experimental results show that the proposed techniques also achieve superior results over the current state-of-the-art on both the WSD tasks ","[{'version': 'v1', 'created': 'Tue, 30 Nov 2021 14:10:22 GMT'}]",2021-12-01,"[['Chawla', 'Avi', ''], ['Mulay', 'Nidhi', ''], ['Bishnoi', 'Vikas', ''], ['Dhama', 'Gaurav', ''], ['Singh', 'Dr. Anil Kumar', '']]",0,1,2021-11-30,1,5,1,1,1,0,f068c591f69af4a836b89624c6a8d8e2790ef37d,244729149.0,https://www.semanticscholar.org/paper/f068c591f69af4a836b89624c6a8d8e2790ef37d,International Conference on Neural Information Processing,2021.0,21.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '102421494', 'name': 'Avi Chawla'}, {'authorId': '2051652357', 'name': 'Nidhi Mulay'}, {'authorId': '82161246', 'name': 'Vikas Bishnoi'}, {'authorId': '104946596', 'name': 'Gaurav Dhama'}, {'authorId': '2112757330', 'name': 'Dr. Anil Kumar Singh'}]","['Mastercard AI, Gurgaon, India', 'Indian Institute of Technology BHU']",['India'],2021-11
2111.15588,Alexander Kovalenko,"Uladzislau Yorsh, Alexander Kovalenko, Vojt\v{e}ch Van\v{c}ura, Daniel
  Va\v{s}ata, Pavel Kord\'ik, Tom\'a\v{s} Mikolov",SimpleTRON: Simple Transformer with O(N) Complexity,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose that the dot product pairwise matching attention layer, which is widely used in Transformer-based models, is redundant for the model performance. Attention, in its original formulation, has to be seen rather as a human-level tool to explore and/or visualize relevancy scores in sequential data. However, the way how it is constructed leads to significant computational complexity. Instead, we present SimpleTRON: Simple Transformer with O(N) Complexity, a simple and fast alternative without any approximation that, unlike other approximation models, does not have any architecture-related overhead and therefore can be seen as a purely linear Transformer-like model. This architecture, to the best of our knowledge, outperforms existing sub-quadratic attention approximation models on several tasks from the Long-Range Arena benchmark. Moreover, we show, that SimpleTRON can benefit from weight transfer from pretrained large language models, as its parameters can be fully transferable. ","[{'version': 'v1', 'created': 'Tue, 23 Nov 2021 17:06:01 GMT'}, {'version': 'v2', 'created': 'Wed, 1 Dec 2021 09:45:25 GMT'}, {'version': 'v3', 'created': 'Thu, 2 Dec 2021 08:16:33 GMT'}, {'version': 'v4', 'created': 'Tue, 28 Jun 2022 13:18:03 GMT'}]",2022-06-29,"[['Yorsh', 'Uladzislau', ''], ['Kovalenko', 'Alexander', ''], ['Vančura', 'Vojtěch', ''], ['Vašata', 'Daniel', ''], ['Kordík', 'Pavel', ''], ['Mikolov', 'Tomáš', '']]",0,0,2021-11-23,4,6,1,0,0,0,298dd7d9c83d695d580d3a5e4afc8eb87b25359a,250089465.0,https://www.semanticscholar.org/paper/298dd7d9c83d695d580d3a5e4afc8eb87b25359a,,2021.0,31.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2111679154', 'name': 'Uladzislau Yorsh'}, {'authorId': '153052453', 'name': 'Alexander Kovalenko'}, {'authorId': '2173873736', 'name': 'Vojtvech Vanvcura'}, {'authorId': '102989921', 'name': 'Daniel Vavsata'}, {'authorId': '28311929', 'name': ""Pavel Kord'ik""}, {'authorId': '2122596258', 'name': ""Tom'avs Mikolov""}]",['Czech Technical University in Prague'],['Czechia'],2021-11
2112.01195,Aleksei Shpilman,"Oleg Svidchenko, Aleksei Shpilman",Maximum Entropy Model-based Reinforcement Learning,NeurIPS'2021 Deep Reinforcement Learning Workshop,,,,cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Recent advances in reinforcement learning have demonstrated its ability to solve hard agent-environment interaction tasks on a super-human level. However, the application of reinforcement learning methods to practical and real-world tasks is currently limited due to most RL state-of-art algorithms' sample inefficiency, i.e., the need for a vast number of training episodes. For example, OpenAI Five algorithm that has beaten human players in Dota 2 has trained for thousands of years of game time. Several approaches exist that tackle the issue of sample inefficiency, that either offers a more efficient usage of already gathered experience or aim to gain a more relevant and diverse experience via a better exploration of an environment. However, to our knowledge, no such approach exists for model-based algorithms, that showed their high sample efficiency in solving hard control tasks with high-dimensional state space. This work connects exploration techniques and model-based reinforcement learning. We have designed a novel exploration method that takes into account features of the model-based approach. We also demonstrate through experiments that our method significantly improves the performance of the model-based algorithm Dreamer. ","[{'version': 'v1', 'created': 'Thu, 2 Dec 2021 13:07:29 GMT'}]",2021-12-03,"[['Svidchenko', 'Oleg', ''], ['Shpilman', 'Aleksei', '']]",0,0,2021-12-02,1,2,2,0,0,0,d2e3b134d0a9ef794bf02aab84cedd1f2e77950a,244798904.0,https://www.semanticscholar.org/paper/d2e3b134d0a9ef794bf02aab84cedd1f2e77950a,arXiv.org,2021.0,22.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1434552251', 'name': 'Oleg Svidchenko'}, {'authorId': '35431760', 'name': 'A. Shpilman'}]","['JetBrains Research HSE University Saint Petersburg, Russia']",['Russia'],2021-12
2112.01742,Shaily Desai,"Shaily Desai, Atharva Kshirsagar, Manisha Marathe",Multitask Finetuning for Improving Neural Machine Translation in Indian Languages,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transformer based language models have led to impressive results across all domains in Natural Language Processing. Pretraining these models on language modeling tasks and finetuning them on downstream tasks such as Text Classification, Question Answering and Neural Machine Translation has consistently shown exemplary results. In this work, we propose a Multitask Finetuning methodology which combines the Bilingual Machine Translation task with an auxiliary Causal Language Modeling task to improve performance on the former task on Indian Languages. We conduct an empirical study on three language pairs, Marathi-Hindi, Marathi-English and Hindi-English, where we compare the multitask finetuning approach to the standard finetuning approach, for which we use the mBART50 model. Our study indicates that the multitask finetuning method could be a better technique than standard finetuning, and could improve Bilingual Machine Translation across language pairs. ","[{'version': 'v1', 'created': 'Fri, 3 Dec 2021 06:43:56 GMT'}]",2021-12-06,"[['Desai', 'Shaily', ''], ['Kshirsagar', 'Atharva', ''], ['Marathe', 'Manisha', '']]",0,0,2021-12-03,1,3,1,0,0,0,c0bddb111d67c8b71b76b020a09703a5f26744fc,244896222.0,https://www.semanticscholar.org/paper/c0bddb111d67c8b71b76b020a09703a5f26744fc,arXiv.org,2021.0,25.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2052355969', 'name': 'Shaily Desai'}, {'authorId': '2078974942', 'name': 'Atharva Kshirsagar'}, {'authorId': '1381684100', 'name': 'M. Marathe'}]",['Savitribai Phule Pune University'],['India'],2021-12
2112.03014,Kichang Yang,Kichang Yang,Transformer-based Korean Pretrained Language Models: A Survey on Three Years of Progress,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  With the advent of Transformer, which was used in translation models in 2017, attention-based architectures began to attract attention. Furthermore, after the emergence of BERT, which strengthened the NLU-specific encoder part, which is a part of the Transformer, and the GPT architecture, which strengthened the NLG-specific decoder part, various methodologies, data, and models for learning the Pretrained Language Model began to appear. Furthermore, in the past three years, various Pretrained Language Models specialized for Korean have appeared. In this paper, we intend to numerically and qualitatively compare and analyze various Korean PLMs released to the public. ","[{'version': 'v1', 'created': 'Thu, 25 Nov 2021 16:37:24 GMT'}]",2021-12-07,"[['Yang', 'Kichang', '']]",0,1,2021-11-25,1,1,1,0,0,0,e3dd975f5be0bcd64b079a1f19a8cce07f0504ed,244908352.0,https://www.semanticscholar.org/paper/e3dd975f5be0bcd64b079a1f19a8cce07f0504ed,arXiv.org,2021.0,32.0,4.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109844772', 'name': 'Kichang Yang'}]",['Soongsil University'],['South Korea'],2021-11
2112.03359,Miguel Vargas Martin Professor,Noopa Jagadeesh and Miguel Vargas Martin,Alice in Passphraseland: Assessing the Memorability of Familiar Vocabularies for System-Assigned Passphrases,"12 pages, 4 figures",,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Text-based secrets are still the most commonly used authentication mechanism in information systems. IT managers must strike a balance between security and memorability while developing password policies. Initially introduced as more secure authentication keys that people could recall, passphrases are passwords consisting of multiple words. However, when left to the choice of users, they tend to choose predictable natural language patterns in passphrases, resulting in vulnerability to guessing attacks. System-assigned authentication keys can be guaranteed to be secure, but this comes at a cost to memorability. In this study we investigate the memorability of system-assigned passphrases from a familiar vocabulary to the user. The passphrases are generated with the Generative Pre-trained Transformer 2 (GPT-2) model trained on the familiar vocabulary and are readable, pronounceable, sentence like passphrases resembling natural English sentences. Through an online user study with 500 participants on Amazon Mechanical Turk, we test our hypothesis - following a spaced repetition schedule, passphrases as natural English sentences, based on familiar vocabulary are easier to recall than passphrases composed of random common words. As a proof-of-concept, we tested the idea with Amazon Mechanical Turk participants by assigning them GPT-2 generated passphrases based on stories they were familiar with. Contrary to expectations, following a spaced repetition schedule, passphrases as natural English sentences, based on familiar vocabulary performed similarly to system-assigned passphrases based on random common words. ","[{'version': 'v1', 'created': 'Mon, 6 Dec 2021 21:11:46 GMT'}]",2021-12-08,"[['Jagadeesh', 'Noopa', ''], ['Martin', 'Miguel Vargas', '']]",0,1,2021-12-06,1,2,1,1,1,0,4133038fddad657ac5eedbafe79dc8a98940d209,244920775.0,https://www.semanticscholar.org/paper/4133038fddad657ac5eedbafe79dc8a98940d209,arXiv.org,2021.0,36.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '115179940', 'name': 'N. Jagadeesh'}, {'authorId': '2110608350', 'name': 'Miguel Martin'}]",['University of Ontario Institute of Technology'],['Canada'],2021-12
2112.03849,Manas Jain,"Manas Jain, Sriparna Saha, Pushpak Bhattacharyya, Gladvin Chinnadurai,
  Manish Kumar Vatsa",Natural Answer Generation: From Factoid Answer to Full-length Answer using Grammar Correction,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Question Answering systems these days typically use template-based language generation. Though adequate for a domain-specific task, these systems are too restrictive and predefined for domain-independent systems. This paper proposes a system that outputs a full-length answer given a question and the extracted factoid answer (short spans such as named entities) as the input. Our system uses constituency and dependency parse trees of questions. A transformer-based Grammar Error Correction model GECToR (2020), is used as a post-processing step for better fluency. We compare our system with (i) Modified Pointer Generator (SOTA) and (ii) Fine-tuned DialoGPT for factoid questions. We also test our approach on existential (yes-no) questions with better results. Our model generates accurate and fluent answers than the state-of-the-art (SOTA) approaches. The evaluation is done on NewsQA and SqUAD datasets with an increment of 0.4 and 0.9 percentage points in ROUGE-1 score respectively. Also the inference time is reduced by 85\% as compared to the SOTA. The improved datasets used for our evaluation will be released as part of the research contribution. ","[{'version': 'v1', 'created': 'Tue, 7 Dec 2021 17:39:21 GMT'}]",2021-12-08,"[['Jain', 'Manas', ''], ['Saha', 'Sriparna', ''], ['Bhattacharyya', 'Pushpak', ''], ['Chinnadurai', 'Gladvin', ''], ['Vatsa', 'Manish Kumar', '']]",0,1,2021-12-07,1,5,2,0,0,0,c626c78dd966f7dfa981cf6ae5bbb8bdc64e89e0,244920951.0,https://www.semanticscholar.org/paper/c626c78dd966f7dfa981cf6ae5bbb8bdc64e89e0,arXiv.org,2021.0,24.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2115794748', 'name': 'Manas Jain'}, {'authorId': '145470045', 'name': 'S. Saha'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}, {'authorId': '2143265655', 'name': 'Gladvin Chinnadurai'}, {'authorId': '115313233', 'name': 'M. Vatsa'}]","['LG', 'Indian Institute of Technology Patna', 'Indian Institute of Technology Bombay']",['India'],2021-12
2112.04521,John Selby,"John H. Selby, David Schmid, Elie Wolfe, Ana Bel\'en Sainz, Ravi
  Kunjwal, and Robert W. Spekkens","Accessible fragments of generalized probabilistic theories, cone equivalence, and applications to witnessing nonclassicality","15 pages, many diagrams","Phys. Rev. A 107, 062203 (2023)",10.1103/PhysRevA.107.062203,,quant-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The formalism of generalized probabilistic theories (GPTs) was originally developed as a way to characterize the landscape of conceivable physical theories. Thus, the GPT describing a given physical theory necessarily includes all physically possible processes. We here consider the question of how to provide a GPT-like characterization of a particular experimental setup within a given physical theory. We show that the resulting characterization is not generally a GPT in and of itself-rather, it is described by a more general mathematical object that we introduce and term an accessible GPT fragment. We then introduce an equivalence relation, termed cone equivalence, between accessible GPT fragments (and, as a special case, between standard GPTs). We give a number of examples of experimental scenarios that are best described using accessible GPT fragments, and where moreover cone-equivalence arises naturally. We then prove that an accessible GPT fragment admits of a classical explanation if and only if every other fragment that is cone-equivalent to it also admits of a classical explanation. Finally, we leverage this result to prove several fundamental results regarding the experimental requirements for witnessing the failure of generalized noncontextuality. In particular, we prove that neither incompatibility among measurements nor the assumption of freedom of choice is necessary for witnessing failures of generalized noncontextuality, and, moreover, that such failures can be witnessed even using arbitrarily inefficient detectors. ","[{'version': 'v1', 'created': 'Wed, 8 Dec 2021 19:00:23 GMT'}]",2023-07-11,"[['Selby', 'John H.', ''], ['Schmid', 'David', ''], ['Wolfe', 'Elie', ''], ['Sainz', 'Ana Belén', ''], ['Kunjwal', 'Ravi', ''], ['Spekkens', 'Robert W.', '']]",0,1,2021-12-08,1,6,1,0,0,0,3ae1ca29620ed6cb54f3041185a35fade8d18d4f,245006202.0,https://www.semanticscholar.org/paper/3ae1ca29620ed6cb54f3041185a35fade8d18d4f,Physical Review A,2021.0,127.0,12.0,0.0,True,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '49610827', 'name': 'John H. Selby'}, {'authorId': '2712258', 'name': 'David Schmid'}, {'authorId': '47838299', 'name': 'Elie Wolfe'}, {'authorId': '102423242', 'name': 'A. B. Sainz'}, {'authorId': '6678386', 'name': 'Ravi Kunjwal'}, {'authorId': '3260992', 'name': 'R. Spekkens'}]","['Université Libre de Bruxelles', 'University of Gdańsk', 'University of Waterloo', 'Perimeter Institute']","['Canada', 'Belgium', 'Poland']",2021-12
2112.05787,Pawan Goyal,"Bishal Santra, Sumegh Roychowdhury, Aishik Mandal, Vasu Gurram,
  Atharva Naik, Manish Gupta, Pawan Goyal",Representation Learning for Conversational Data using Discourse Mutual Information Maximization,"Preprint, 15 pages, To appear in NAACL 2022 (Main)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although many pretrained models exist for text or images, there have been relatively fewer attempts to train representations specifically for dialog understanding. Prior works usually relied on finetuned representations based on generic text representation models like BERT or GPT-2. But such language modeling pretraining objectives do not take the structural information of conversational text into consideration. Although generative dialog models can learn structural features too, we argue that the structure-unaware word-by-word generation is not suitable for effective conversation modeling. We empirically demonstrate that such representations do not perform consistently across various dialog understanding tasks. Hence, we propose a structure-aware Mutual Information based loss-function DMI (Discourse Mutual Information) for training dialog-representation models, that additionally captures the inherent uncertainty in response prediction. Extensive evaluation on nine diverse dialog modeling tasks shows that our proposed DMI-based models outperform strong baselines by significant margins. ","[{'version': 'v1', 'created': 'Sat, 4 Dec 2021 13:17:07 GMT'}, {'version': 'v2', 'created': 'Tue, 3 May 2022 14:21:56 GMT'}]",2022-05-04,"[['Santra', 'Bishal', ''], ['Roychowdhury', 'Sumegh', ''], ['Mandal', 'Aishik', ''], ['Gurram', 'Vasu', ''], ['Naik', 'Atharva', ''], ['Gupta', 'Manish', ''], ['Goyal', 'Pawan', '']]",0,1,2021-12-04,2,7,1,1,1,0,2ae757afd718d5219cdee3a6c4cee0d226378efd,245124148.0,https://www.semanticscholar.org/paper/2ae757afd718d5219cdee3a6c4cee0d226378efd,North American Chapter of the Association for Computational Linguistics,2021.0,53.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8371554', 'name': 'Bishal Santra'}, {'authorId': '151388180', 'name': 'Sumegh Roychowdhury'}, {'authorId': '2130101667', 'name': 'Aishik Mandal'}, {'authorId': '2145151006', 'name': 'Vasu Gurram'}, {'authorId': '2064353087', 'name': 'Atharva Naik'}, {'authorId': '2152950438', 'name': 'Manish Gupta'}, {'authorId': '51130504', 'name': 'Pawan Goyal'}]",['Indian Institute of Technology Kharagpur'],['India'],2021-12
2112.08619,Yoonna Jang,"Yoonna Jang, Jungwoo Lim, Yuna Hur, Dongsuk Oh, Suhyune Son, Yeonsoo
  Lee, Donghoon Shin, Seungryong Kim, and Heuiseok Lim",Call for Customized Conversation: Customized Conversation Grounding Persona and Knowledge,"Accepted paper at the Thirty-Sixth AAAI Conference on Artificial
  Intelligence (AAAI-22)",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Humans usually have conversations by making use of prior knowledge about a topic and background information of the people whom they are talking to. However, existing conversational agents and datasets do not consider such comprehensive information, and thus they have a limitation in generating the utterances where the knowledge and persona are fused properly. To address this issue, we introduce a call For Customized conversation (FoCus) dataset where the customized answers are built with the user's persona and Wikipedia knowledge. To evaluate the abilities to make informative and customized utterances of pre-trained language models, we utilize BART and GPT-2 as well as transformer-based models. We assess their generation abilities with automatic scores and conduct human evaluations for qualitative results. We examine whether the model reflects adequate persona and knowledge with our proposed two sub-tasks, persona grounding (PG) and knowledge grounding (KG). Moreover, we show that the utterances of our data are constructed with the proper knowledge and persona through grounding quality assessment. ","[{'version': 'v1', 'created': 'Thu, 16 Dec 2021 04:44:27 GMT'}, {'version': 'v2', 'created': 'Mon, 4 Apr 2022 11:02:09 GMT'}, {'version': 'v3', 'created': 'Mon, 16 May 2022 05:11:14 GMT'}]",2022-05-17,"[['Jang', 'Yoonna', ''], ['Lim', 'Jungwoo', ''], ['Hur', 'Yuna', ''], ['Oh', 'Dongsuk', ''], ['Son', 'Suhyune', ''], ['Lee', 'Yeonsoo', ''], ['Shin', 'Donghoon', ''], ['Kim', 'Seungryong', ''], ['Lim', 'Heuiseok', '']]",0,1,2021-12-16,3,9,2,1,1,0,c65c96cfc8b448fe9fd6bbfe1aaaea727515f4f7,245218804.0,https://www.semanticscholar.org/paper/c65c96cfc8b448fe9fd6bbfe1aaaea727515f4f7,AAAI Conference on Artificial Intelligence,2021.0,55.0,16.0,5.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2072583773', 'name': 'Yoonna Jang'}, {'authorId': '2109641713', 'name': 'J. Lim'}, {'authorId': '98207546', 'name': 'Yuna Hur'}, {'authorId': '120580213', 'name': 'Dongsuk Oh'}, {'authorId': '2087630963', 'name': 'Suhyune Son'}, {'authorId': '2119392528', 'name': 'Yeonsoo Lee'}, {'authorId': None, 'name': 'Donghoon Shin'}, {'authorId': '2099537', 'name': 'Seungryong Kim'}, {'authorId': '31312182', 'name': 'Heuiseok Lim'}]","['Language AI Lab, NCSOFT', 'Korea University']",['South Korea'],2021-12
2112.11941,Frank Binder,"J\""org Frohberg and Frank Binder",CRASS: A Novel Data Set and Benchmark to Test Counterfactual Reasoning of Large Language Models,"10 pages including references, plus 5 pages appendix. Edits for
  version 3 vs LREC 2022: Point out human baseline in abstract (also to match
  arxiv abstract), fix affiliation apergo.ai, and fix a recurring typo","Proceedings of the 13th Language Resources and Evaluation
  Conference (LREC 2022), Marseille, France pp. 2126-2140 (2022)
  https://aclanthology.org/2022.lrec-1.229/",,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,  We introduce the CRASS (counterfactual reasoning assessment) data set and benchmark utilizing questionized counterfactual conditionals as a novel and powerful tool to evaluate large language models. We present the data set design and benchmark that supports scoring against a crowd-validated human baseline. We test six state-of-the-art models against our benchmark. Our results show that it poses a valid challenge for these models and opens up considerable room for their improvement. ,"[{'version': 'v1', 'created': 'Wed, 22 Dec 2021 15:03:23 GMT'}, {'version': 'v2', 'created': 'Tue, 21 Jun 2022 06:52:42 GMT'}, {'version': 'v3', 'created': 'Tue, 4 Oct 2022 19:03:40 GMT'}]",2022-10-06,"[['Frohberg', 'Jörg', ''], ['Binder', 'Frank', '']]",0,0,2021-12-22,3,2,1,0,0,0,eebdf7303256f081ab1f6a36ff0ea6126e4da484,245385766.0,https://www.semanticscholar.org/paper/eebdf7303256f081ab1f6a36ff0ea6126e4da484,International Conference on Language Resources and Evaluation,2021.0,70.0,9.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146695800', 'name': 'Jorg Frohberg'}, {'authorId': '35011320', 'name': 'Frank Binder'}]",['Leipzig University'],['Germany'],2021-12
2201.03382,Frederico Souza,"Frederico Souza, Jo\~ao Filho",BERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives,"10 pages, 1 figure, 3 tables. Accepted at International Conference on
  the Computational Processing of Portuguese (PROPOR 2022), but not yet
  published",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  BERT has revolutionized the NLP field by enabling transfer learning with large language models that can capture complex textual patterns, reaching the state-of-the-art for an expressive number of NLP applications. For text classification tasks, BERT has already been extensively explored. However, aspects like how to better cope with the different embeddings provided by the BERT output layer and the usage of language-specific instead of multilingual models are not well studied in the literature, especially for the Brazilian Portuguese language. The purpose of this article is to conduct an extensive experimental study regarding different strategies for aggregating the features produced in the BERT output layer, with a focus on the sentiment analysis task. The experiments include BERT models trained with Brazilian Portuguese corpora and the multilingual version, contemplating multiple aggregation strategies and open-source datasets with predefined training, validation, and test partitions to facilitate the reproducibility of the results. BERT achieved the highest ROC-AUC values for the majority of cases as compared to TF-IDF. Nonetheless, TF-IDF represents a good trade-off between the predictive performance and computational cost. ","[{'version': 'v1', 'created': 'Mon, 10 Jan 2022 15:05:05 GMT'}]",2022-01-11,"[['Souza', 'Frederico', ''], ['Filho', 'João', '']]",0,0,2022-01-10,1,2,1,0,0,0,6a4a37fb0dd34147eb08e231a197473162c45b12,245837662.0,https://www.semanticscholar.org/paper/6a4a37fb0dd34147eb08e231a197473162c45b12,International Conference on Computational Processing of the Portuguese Language,2022.0,27.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146937581', 'name': 'F. Souza'}, {'authorId': '2037734654', 'name': 'Joao Filho'}]",['Universidade Federal do Rio de Janeiro'],['Brazil'],2022-01
2201.05222,Jian Gu,"Jian Gu, Pasquale Salza, Harald C. Gall",Assemble Foundation Models for Automatic Code Summarization,"12 pages, 2 figures, 8 tables, accepted by SANER 2022, the
  camera-ready version",,,,cs.SE cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic code summarization is beneficial to daily software development since it could help reduce the requirement of manual writing. Currently, artificial intelligence is undergoing a paradigm shift. The foundation models pretrained on massive data and finetuned to downstream tasks surpass specially customized models. This trend inspired us to consider reusing foundation models instead of learning from scratch. Thereby, we propose a flexible and robust approach for automatic code summarization, based on neural models. We assemble available foundation models, such as CodeBERT and GPT-2, into a single neural model named AdaMo. Moreover, we utilize Gaussian noise as the simulation of contextual information to optimize the latent representation. Furthermore, we introduce two adaptive schemes from the perspective of knowledge transfer, namely continuous pretraining and intermediate finetuning, and design intermediate stage tasks for general sequence-to-sequence learning. Finally, we evaluate AdaMo against a benchmark dataset for code summarization, by comparing it with state-of-the-art models. ","[{'version': 'v1', 'created': 'Thu, 13 Jan 2022 21:38:33 GMT'}, {'version': 'v2', 'created': 'Fri, 11 Mar 2022 19:00:16 GMT'}]",2022-03-15,"[['Gu', 'Jian', ''], ['Salza', 'Pasquale', ''], ['Gall', 'Harald C.', '']]",0,1,2022-01-13,2,3,2,1,1,0,49c3f85573a3204c5e66317289e4cecfed50f38a,245986582.0,https://www.semanticscholar.org/paper/49c3f85573a3204c5e66317289e4cecfed50f38a,"IEEE International Conference on Software Analysis, Evolution, and Reengineering",2022.0,76.0,15.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49260452', 'name': 'Jian Gu'}, {'authorId': '2603954', 'name': 'P. Salza'}, {'authorId': '50355692', 'name': 'H. Gall'}]",['University of Zurich'],['Switzerland'],2022-01
2201.08387,Felipe Gonz\'alez-Pizarro,"Felipe Gonz\'alez-Pizarro, Savvas Zannettou",Understanding and Detecting Hateful Content using Contrastive Learning,,,,,cs.SI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  The spread of hate speech and hateful imagery on the Web is a significant problem that needs to be mitigated to improve our Web experience. This work contributes to research efforts to detect and understand hateful content on the Web by undertaking a multimodal analysis of Antisemitism and Islamophobia on 4chan's /pol/ using OpenAI's CLIP. This large pre-trained model uses the Contrastive Learning paradigm. We devise a methodology to identify a set of Antisemitic and Islamophobic hateful textual phrases using Google's Perspective API and manual annotations. Then, we use OpenAI's CLIP to identify images that are highly similar to our Antisemitic/Islamophobic textual phrases. By running our methodology on a dataset that includes 66M posts and 5.8M images shared on 4chan's /pol/ for 18 months, we detect 173K posts containing 21K Antisemitic/Islamophobic images and 246K posts that include 420 hateful phrases. Among other things, we find that we can use OpenAI's CLIP model to detect hateful content with an accuracy score of 0.81 (F1 score = 0.54). By comparing CLIP with two baselines proposed by the literature, we find that CLIP outperforms them, in terms of accuracy, precision, and F1 score, in detecting Antisemitic/Islamophobic images. Also, we find that Antisemitic/Islamophobic imagery is shared in a similar number of posts on 4chan's /pol/ compared to Antisemitic/Islamophobic textual phrases, highlighting the need to design more tools for detecting hateful imagery. Finally, we make available (upon request) a dataset of 246K posts containing 420 Antisemitic/Islamophobic phrases and 21K likely Antisemitic/Islamophobic images (automatically detected by CLIP) that can assist researchers in further understanding Antisemitism and Islamophobia. ","[{'version': 'v1', 'created': 'Fri, 21 Jan 2022 18:22:29 GMT'}, {'version': 'v2', 'created': 'Tue, 17 May 2022 01:34:45 GMT'}]",2022-05-18,"[['González-Pizarro', 'Felipe', ''], ['Zannettou', 'Savvas', '']]",0,0,2022-01-21,2,2,2,0,0,0,1e86bcbff853054d4c020a9ba9676e813308f037,246210079.0,https://www.semanticscholar.org/paper/1e86bcbff853054d4c020a9ba9676e813308f037,International Conference on Web and Social Media,2022.0,85.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2154371123', 'name': 'Felipe González-Pizarro'}, {'authorId': '3447293', 'name': 'Savvas Zannettou'}]","['University of British Columbia', 'Max Planck Institute for Informatics']","['Germany', 'Canada']",2022-01
2201.09377,Ali Emami Mr.,Darren Abramson and Ali Emami,An Application of Pseudo-Log-Likelihoods to Natural Language Scoring,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Language models built using semi-supervised machine learning on large corpora of natural language have very quickly enveloped the fields of natural language generation and understanding. In this paper we apply a zero-shot approach independently developed by a number of researchers now gaining recognition as a significant alternative to fine-tuning for evaluation on common sense tasks. A language model with relatively few parameters and training steps compared to a more recent language model (T5) can outperform it on a recent large data set (TimeDial), while displaying robustness in its performance across a similar class of language tasks. Surprisingly, this result is achieved by using a hyperparameter-free zero-shot method with the smaller model, compared to fine-tuning to the larger model. We argue that robustness of the smaller model ought to be understood in terms of compositionality, in a sense that we draw from recent literature on a class of similar models. We identify a practical cost for our method and model: high GPU-time for natural language evaluation. The zero-shot measurement technique that produces remarkable stability, both for ALBERT and other BERT variants, is an application of pseudo-log-likelihoods to masked language models for the relative measurement of probability for substitution alternatives in forced choice language tasks such as the Winograd Schema Challenge, Winogrande, and others. One contribution of this paper is to bring together a number of similar, but independent strands of research. We produce some absolute state-of-the-art results for common sense reasoning in binary choice tasks, performing better than any published result in the literature, including fine-tuned efforts. We show a remarkable consistency of the model's performance under adversarial settings, which we argue is best explained by the model's compositionality of representations. ","[{'version': 'v1', 'created': 'Sun, 23 Jan 2022 22:00:54 GMT'}]",2022-01-25,"[['Abramson', 'Darren', ''], ['Emami', 'Ali', '']]",0,0,2022-01-23,1,2,3,1,1,0,16bf88a6d172699cb9a26a6936efb4941e3f3c13,246240066.0,https://www.semanticscholar.org/paper/16bf88a6d172699cb9a26a6936efb4941e3f3c13,arXiv.org,2022.0,36.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143610196', 'name': 'Darren Abramson'}, {'authorId': '2075338284', 'name': 'Ali Emami'}]","['Brock University', 'Dalhousie University']",['Canada'],2022-01
2201.10066,Angelina McMillan-Major,"Angelina McMillan-Major and Zaid Alyafeai and Stella Biderman and
  Kimbo Chen and Francesco De Toni and G\'erard Dupont and Hady Elsahar and
  Chris Emezue and Alham Fikri Aji and Suzana Ili\'c and Nurulaqilla Khamis and
  Colin Leong and Maraim Masoud and Aitor Soroa and Pedro Ortiz Suarez and
  Zeerak Talat and Daniel van Strien and Yacine Jernite",Documenting Geographically and Contextually Diverse Data Sources: The BigScience Catalogue of Language Data and Resources,8 pages plus appendix and references,,,,cs.CL cs.DB,http://creativecommons.org/licenses/by/4.0/,"  In recent years, large-scale data collection efforts have prioritized the amount of data collected in order to improve the modeling capabilities of large language models. This prioritization, however, has resulted in concerns with respect to the rights of data subjects represented in data collections, particularly when considering the difficulty in interrogating these collections due to insufficient documentation and tools for analysis. Mindful of these pitfalls, we present our methodology for a documentation-first, human-centered data collection project as part of the BigScience initiative. We identified a geographically diverse set of target language groups (Arabic, Basque, Chinese, Catalan, English, French, Indic languages, Indonesian, Niger-Congo languages, Portuguese, Spanish, and Vietnamese, as well as programming languages) for which to collect metadata on potential data sources. To structure this effort, we developed our online catalogue as a supporting tool for gathering metadata through organized public hackathons. We present our development process; analyses of the resulting resource metadata, including distributions over languages, regions, and resource types; and our lessons learned in this endeavor. ","[{'version': 'v1', 'created': 'Tue, 25 Jan 2022 03:05:23 GMT'}]",2022-01-26,"[['McMillan-Major', 'Angelina', ''], ['Alyafeai', 'Zaid', ''], ['Biderman', 'Stella', ''], ['Chen', 'Kimbo', ''], ['De Toni', 'Francesco', ''], ['Dupont', 'Gérard', ''], ['Elsahar', 'Hady', ''], ['Emezue', 'Chris', ''], ['Aji', 'Alham Fikri', ''], ['Ilić', 'Suzana', ''], ['Khamis', 'Nurulaqilla', ''], ['Leong', 'Colin', ''], ['Masoud', 'Maraim', ''], ['Soroa', 'Aitor', ''], ['Suarez', 'Pedro Ortiz', ''], ['Talat', 'Zeerak', ''], ['van Strien', 'Daniel', ''], ['Jernite', 'Yacine', '']]",0,0,2022-01-25,1,18,2,0,0,0,cdc554a3e8d3758e68bedebcb32473c100ef50fc,246275637.0,https://www.semanticscholar.org/paper/cdc554a3e8d3758e68bedebcb32473c100ef50fc,arXiv.org,2022.0,40.0,11.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1584940075', 'name': 'Angelina McMillan-Major'}, {'authorId': '25098419', 'name': 'Zaid Alyafeai'}, {'authorId': '103476203', 'name': 'Stella Rose Biderman'}, {'authorId': '2157630500', 'name': 'Kimbo Chen'}, {'authorId': '2067891070', 'name': 'F. Toni'}, {'authorId': '13656138', 'name': 'Gérard Dupont'}, {'authorId': '2218938', 'name': 'Hady ElSahar'}, {'authorId': '1591176064', 'name': 'Chris C. Emezue'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}, {'authorId': '2066663381', 'name': ""Suzana Ili'c""}, {'authorId': '37441312', 'name': 'Nurulaqilla Khamis'}, {'authorId': '89269402', 'name': 'Colin Leong'}, {'authorId': '153528116', 'name': 'Maraim Masoud'}, {'authorId': '2078619062', 'name': 'Aitor Soroa Etxabe'}, {'authorId': '147846651', 'name': 'Pedro Ortiz Suarez'}, {'authorId': '2138053020', 'name': 'Zeerak Talat'}, {'authorId': '71075073', 'name': 'Daniel Alexander van Strien'}, {'authorId': '2262249', 'name': 'Yacine Jernite'}]","['University of Western Australia', 'University of the Basque Country']","['Spain', 'Australia']",2022-01
2201.11014,Masataka Sawayama,"Yoann Lemesle, Masataka Sawayama, Guillermo Valle-Perez, Maxime
  Adolphe, H\'el\`ene Sauz\'eon, Pierre-Yves Oudeyer",Language-biased image classification: evaluation based on semantic representations,Accepted at ICLR 2022,,,,cs.CV cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Humans show language-biased image recognition for a word-embedded image, known as picture-word interference. Such interference depends on hierarchical semantic categories and reflects that human language processing highly interacts with visual processing. Similar to humans, recent artificial models jointly trained on texts and images, e.g., OpenAI CLIP, show language-biased image classification. Exploring whether the bias leads to interference similar to those observed in humans can contribute to understanding how much the model acquires hierarchical semantic representations from joint learning of language and vision. The present study introduces methodological tools from the cognitive science literature to assess the biases of artificial models. Specifically, we introduce a benchmark task to test whether words superimposed on images can distort the image classification across different category levels and, if it can, whether the perturbation is due to the shared semantic representation between language and vision. Our dataset is a set of word-embedded images and consists of a mixture of natural image datasets and hierarchical word labels with superordinate/basic category levels. Using this benchmark test, we evaluate the CLIP model. We show that presenting words distorts the image classification by the model across different category levels, but the effect does not depend on the semantic relationship between images and embedded words. This suggests that the semantic word representation in the CLIP visual processing is not shared with the image representation, although the word representation strongly dominates for word-embedded images. ","[{'version': 'v1', 'created': 'Wed, 26 Jan 2022 15:46:36 GMT'}, {'version': 'v2', 'created': 'Sat, 12 Mar 2022 12:16:42 GMT'}]",2022-03-15,"[['Lemesle', 'Yoann', ''], ['Sawayama', 'Masataka', ''], ['Valle-Perez', 'Guillermo', ''], ['Adolphe', 'Maxime', ''], ['Sauzéon', 'Hélène', ''], ['Oudeyer', 'Pierre-Yves', '']]",0,0,2022-01-26,2,6,3,0,0,0,9f984b48d57a7e0704c4cb46264e9f697cf60e42,247447287.0,https://www.semanticscholar.org/paper/9f984b48d57a7e0704c4cb46264e9f697cf60e42,International Conference on Learning Representations,2022.0,34.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2151177763', 'name': 'Yoann Lemesle'}, {'authorId': '1840764', 'name': 'Masataka Sawayama'}, {'authorId': '48671492', 'name': 'Guillermo Valle Pérez'}, {'authorId': '2151177164', 'name': 'Maxime Adolphe'}, {'authorId': '2165462846', 'name': 'Hélène Sauzéon'}, {'authorId': '1720664', 'name': 'Pierre-Yves Oudeyer'}]","['French Institute for Research in Computer Science and Automation', 'Microsoft', 'École Normale Supérieure de Rennes', 'INRIA France Hélène Sauzéon', 'University of Bordeaux']","['Canada', 'France']",2022-01
2202.01159,Raviraj Joshi,Raviraj Joshi,"L3Cube-MahaCorpus and MahaBERT: Marathi Monolingual Corpus, Marathi BERT Language Models, and Resources",,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present L3Cube-MahaCorpus a Marathi monolingual data set scraped from different internet sources. We expand the existing Marathi monolingual corpus with 24.8M sentences and 289M tokens. We further present, MahaBERT, MahaAlBERT, and MahaRoBerta all BERT-based masked language models, and MahaFT, the fast text word embeddings both trained on full Marathi corpus with 752M tokens. We show the effectiveness of these resources on downstream Marathi sentiment analysis, text classification, and named entity recognition (NER) tasks. We also release MahaGPT, a generative Marathi GPT model trained on Marathi corpus. Marathi is a popular language in India but still lacks these resources. This work is a step forward in building open resources for the Marathi language. The data and models are available at https://github.com/l3cube-pune/MarathiNLP . ","[{'version': 'v1', 'created': 'Wed, 2 Feb 2022 17:35:52 GMT'}, {'version': 'v2', 'created': 'Sun, 13 Mar 2022 07:27:40 GMT'}]",2022-03-15,"[['Joshi', 'Raviraj', '']]",0,1,2022-02-02,2,1,2,0,0,0,7ebbb9f14a08fda8d76b3f299254c2b0d2c59d9a,246473294.0,https://www.semanticscholar.org/paper/7ebbb9f14a08fda8d76b3f299254c2b0d2c59d9a,WILDRE,2022.0,33.0,25.0,4.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51890352', 'name': 'Raviraj Joshi'}]",['Indian Institute of Technology Madras'],['India'],2022-02
2202.02013,Vijini Pilana Liyanage,"Vijini Liyanage, Davide Buscaldi, Adeline Nazarenko",A Benchmark Corpus for the Detection of Automatically Generated Text in Academic Publications,"9 pages including references, submitted to LREC 2022. arXiv admin
  note: text overlap with arXiv:2110.10577 by other authors",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Automatic text generation based on neural language models has achieved performance levels that make the generated text almost indistinguishable from those written by humans. Despite the value that text generation can have in various applications, it can also be employed for malicious tasks. The diffusion of such practices represent a threat to the quality of academic publishing. To address these problems, we propose in this paper two datasets comprised of artificially generated research content: a completely synthetic dataset and a partial text substitution dataset. In the first case, the content is completely generated by the GPT-2 model after a short prompt extracted from original papers. The partial or hybrid dataset is created by replacing several sentences of abstracts with sentences that are generated by the Arxiv-NLP model. We evaluate the quality of the datasets comparing the generated texts to aligned original texts using fluency metrics such as BLEU and ROUGE. The more natural the artificial texts seem, the more difficult they are to detect and the better is the benchmark. We also evaluate the difficulty of the task of distinguishing original from generated text by using state-of-the-art classification models. ","[{'version': 'v1', 'created': 'Fri, 4 Feb 2022 08:16:56 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Apr 2022 12:04:33 GMT'}]",2022-05-02,"[['Liyanage', 'Vijini', ''], ['Buscaldi', 'Davide', ''], ['Nazarenko', 'Adeline', '']]",0,1,2022-02-04,2,3,1,1,1,0,1da342e5387d577cea4312978330066b4f8276ed,246607919.0,https://www.semanticscholar.org/paper/1da342e5387d577cea4312978330066b4f8276ed,International Conference on Language Resources and Evaluation,2022.0,54.0,12.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151360503', 'name': 'Vijini Liyanage'}, {'authorId': '1721059', 'name': 'D. Buscaldi'}, {'authorId': '143971891', 'name': 'A. Nazarenko'}]",['Université Sorbonne Paris Nord'],['France'],2022-02
2202.02635,Arka Mitra,"Arka Mitra, Priyanshu Sankhala",Multilingual Hate Speech and Offensive Content Detection using Modified Cross-entropy Loss,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The number of increased social media users has led to a lot of people misusing these platforms to spread offensive content and use hate speech. Manual tracking the vast amount of posts is impractical so it is necessary to devise automated methods to identify them quickly. Large language models are trained on a lot of data and they also make use of contextual embeddings. We fine-tune the large language models to help in our task. The data is also quite unbalanced; so we used a modified cross-entropy loss to tackle the issue. We observed that using a model which is fine-tuned in hindi corpora performs better. Our team (HNLP) achieved the macro F1-scores of 0.808, 0.639 in English Subtask A and English Subtask B respectively. For Hindi Subtask A, Hindi Subtask B our team achieved macro F1-scores of 0.737, 0.443 respectively in HASOC 2021. ","[{'version': 'v1', 'created': 'Sat, 5 Feb 2022 20:31:40 GMT'}]",2022-02-08,"[['Mitra', 'Arka', ''], ['Sankhala', 'Priyanshu', '']]",0,0,2022-02-05,1,2,1,0,0,0,cf8d623eb1dd7262943c9a4c5e3b52fda9a49898,246634213.0,https://www.semanticscholar.org/paper/cf8d623eb1dd7262943c9a4c5e3b52fda9a49898,Fire,2022.0,31.0,4.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '107767869', 'name': 'Arka Mitra'}, {'authorId': '2153472345', 'name': 'Priyanshu Sankhala'}]","['National Institute of Technology Raipur', 'Indian Institute of Technology Kharagpur']",['India'],2022-02
2202.03371,Martin Muller,"Martin M\""uller, Florian Laurent",Cedille: A large autoregressive French language model,"8 pages, 1 figure, 7 tables",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Scaling up the size and training of autoregressive language models has enabled novel ways of solving Natural Language Processing tasks using zero-shot and few-shot learning. While extreme-scale language models such as GPT-3 offer multilingual capabilities, zero-shot learning for languages other than English remain largely unexplored. Here, we introduce Cedille, a large open source auto-regressive language model, specifically trained for the French language. Our results show that Cedille outperforms existing French language models and is competitive with GPT-3 on a range of French zero-shot benchmarks. Furthermore, we provide an in-depth comparison of the toxicity exhibited by these models, showing that Cedille marks an improvement in language model safety thanks to dataset filtering. ","[{'version': 'v1', 'created': 'Mon, 7 Feb 2022 17:40:43 GMT'}]",2022-02-08,"[['Müller', 'Martin', ''], ['Laurent', 'Florian', '']]",0,1,2022-02-07,1,2,1,1,0,1,55b9a2ade0a49e9cf10b71528d69dfee4e826025,246634768.0,https://www.semanticscholar.org/paper/55b9a2ade0a49e9cf10b71528d69dfee4e826025,arXiv.org,2022.0,38.0,6.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2116236771', 'name': 'Martin Müller'}, {'authorId': '2064901219', 'name': 'Florian Laurent'}]","['https://commoncrawl.org/', 'École Polytechnique Fédérale de Lausanne', 'Cedille AI']",['Switzerland'],2022-02
2202.03753,Hannes Hansen,"Hannes Hansen, Martin N. Hebart",Semantic features of object concepts generated with GPT-3,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Semantic features have been playing a central role in investigating the nature of our conceptual representations. Yet the enormous time and effort required to empirically sample and norm features from human raters has restricted their use to a limited set of manually curated concepts. Given recent promising developments with transformer-based language models, here we asked whether it was possible to use such models to automatically generate meaningful lists of properties for arbitrary object concepts and whether these models would produce features similar to those found in humans. To this end, we probed a GPT-3 model to generate semantic features for 1,854 objects and compared automatically-generated features to existing human feature norms. GPT-3 generated many more features than humans, yet showed a similar distribution in the types of generated features. Generated feature norms rivaled human norms in predicting similarity, relatedness, and category membership, while variance partitioning demonstrated that these predictions were driven by similar variance in humans and GPT-3. Together, these results highlight the potential of large language models to capture important facets of human knowledge and yield a new approach for automatically generating interpretable feature sets, thus drastically expanding the potential use of semantic features in psychological and linguistic studies. ","[{'version': 'v1', 'created': 'Tue, 8 Feb 2022 09:51:48 GMT'}, {'version': 'v2', 'created': 'Tue, 10 May 2022 13:30:20 GMT'}]",2022-05-11,"[['Hansen', 'Hannes', ''], ['Hebart', 'Martin N.', '']]",0,1,2022-02-08,2,2,2,1,0,1,a02aee5f1a1e5921a1e273dc25eb1ecba2f47b97,246652331.0,https://www.semanticscholar.org/paper/a02aee5f1a1e5921a1e273dc25eb1ecba2f47b97,arXiv.org,2022.0,32.0,10.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2153711516', 'name': 'Hannes J. Hansen'}, {'authorId': '1838629', 'name': 'M. Hebart'}]",['Max Planck Institute for Human Cognitive and Brain Sciences'],['Germany'],2022-02
2202.03799,Pierre Colombo,"Pierre Colombo and Nathan Noiry and Ekhine Irurozki and Stephan
  Clemencon",What are the best systems? New perspectives on NLP Benchmarking,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In Machine Learning, a benchmark refers to an ensemble of datasets associated with one or multiple metrics together with a way to aggregate different systems performances. They are instrumental in (i) assessing the progress of new methods along different axes and (ii) selecting the best systems for practical use. This is particularly the case for NLP with the development of large pre-trained models (e.g. GPT, BERT) that are expected to generalize well on a variety of tasks. While the community mainly focused on developing new datasets and metrics, there has been little interest in the aggregation procedure, which is often reduced to a simple average over various performance measures. However, this procedure can be problematic when the metrics are on a different scale, which may lead to spurious conclusions. This paper proposes a new procedure to rank systems based on their performance across different tasks. Motivated by the social choice theory, the final system ordering is obtained through aggregating the rankings induced by each task and is theoretically grounded. We conduct extensive numerical experiments (on over 270k scores) to assess the soundness of our approach both on synthetic and real scores (e.g. GLUE, EXTREM, SEVAL, TAC, FLICKR). In particular, we show that our method yields different conclusions on state-of-the-art systems than the mean-aggregation procedure while being both more reliable and robust. ","[{'version': 'v1', 'created': 'Tue, 8 Feb 2022 11:44:20 GMT'}, {'version': 'v2', 'created': 'Thu, 10 Feb 2022 11:22:35 GMT'}, {'version': 'v3', 'created': 'Thu, 2 Jun 2022 14:38:46 GMT'}, {'version': 'v4', 'created': 'Fri, 7 Oct 2022 17:52:53 GMT'}]",2022-10-10,"[['Colombo', 'Pierre', ''], ['Noiry', 'Nathan', ''], ['Irurozki', 'Ekhine', ''], ['Clemencon', 'Stephan', '']]",0,1,2022-02-08,4,4,2,0,0,0,82b3a2559b5cf1528348b9d35285868e1c154fce,246652319.0,https://www.semanticscholar.org/paper/82b3a2559b5cf1528348b9d35285868e1c154fce,Neural Information Processing Systems,2022.0,120.0,18.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46985469', 'name': 'Pierre Colombo'}, {'authorId': '88972690', 'name': 'Nathan Noiry'}, {'authorId': '2217198', 'name': 'Ekhine Irurozki'}, {'authorId': '1696620', 'name': 'S. Clémençon'}]","['Télécom Paris', 'CentraleSupélec']",['France'],2022-02
2202.05144,Luiz Bonifacio,"Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Rodrigo Nogueira",InPars: Data Augmentation for Information Retrieval using Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The information retrieval community has recently witnessed a revolution due to large pretrained transformer models. Another key ingredient for this revolution was the MS MARCO dataset, whose scale and diversity has enabled zero-shot transfer learning to various tasks. However, not all IR tasks and domains can benefit from one single dataset equally. Extensive research in various NLP tasks has shown that using domain-specific training data, as opposed to a general-purpose one, improves the performance of neural models. In this work, we harness the few-shot capabilities of large pretrained language models as synthetic data generators for IR tasks. We show that models finetuned solely on our unsupervised dataset outperform strong baselines such as BM25 as well as recently proposed self-supervised dense retrieval methods. Furthermore, retrievers finetuned on both supervised and our synthetic data achieve better zero-shot transfer than models finetuned only on supervised data. Code, models, and data are available at https://github.com/zetaalphavector/inpars . ","[{'version': 'v1', 'created': 'Thu, 10 Feb 2022 16:52:45 GMT'}]",2022-02-11,"[['Bonifacio', 'Luiz', ''], ['Abonizio', 'Hugo', ''], ['Fadaee', 'Marzieh', ''], ['Nogueira', 'Rodrigo', '']]",0,0,2022-02-10,1,4,1,0,0,0,4e36db22808c1d677438137b10979a9279fb6c1f,246705967.0,https://www.semanticscholar.org/paper/4e36db22808c1d677438137b10979a9279fb6c1f,arXiv.org,2022.0,55.0,37.0,4.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2003019597', 'name': 'L. Bonifacio'}, {'authorId': '1394470211', 'name': 'Hugo Abonizio'}, {'authorId': '2818759', 'name': 'Marzieh Fadaee'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}]","['Universidade Estadual de Campinas (UNICAMP)', 'University of Waterloo']","['Canada', 'Brazil']",2022-02
2202.06133,Timo Schick,"Yanchen Liu, Timo Schick, Hinrich Sch\""utze",Semantic-Oriented Unlabeled Priming for Large-Scale Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Due to the high costs associated with finetuning large language models, various recent works propose to adapt them to specific tasks without any parameter updates through in-context learning. Unfortunately, for in-context learning there is currently no way to leverage unlabeled data, which is often much easier to obtain in large quantities than labeled examples. In this work, we therefore investigate ways to make use of unlabeled examples to improve the zero-shot performance of pretrained language models without any finetuning: We introduce Semantic-Oriented Unlabeled Priming (SOUP), a method that classifies examples by retrieving semantically similar unlabeled examples, assigning labels to them in a zero-shot fashion, and then using them for in-context learning. We also propose bag-of-contexts priming, a new priming strategy that is more suitable for our setting and enables the usage of more examples than fit into the context window. ","[{'version': 'v1', 'created': 'Sat, 12 Feb 2022 19:50:59 GMT'}]",2022-02-15,"[['Liu', 'Yanchen', ''], ['Schick', 'Timo', ''], ['Schütze', 'Hinrich', '']]",0,0,2022-02-12,1,3,1,0,0,0,a74b7301d2df228c266c6405dceb547d07a022fa,246823215.0,https://www.semanticscholar.org/paper/a74b7301d2df228c266c6405dceb547d07a022fa,SUSTAINLP,2022.0,34.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108082280', 'name': 'Yanchen Liu'}, {'authorId': '32246932', 'name': 'Timo Schick'}, {'authorId': '144418438', 'name': 'Hinrich Schütze'}]","['Technical University of Munich', 'Ludwig-Maximilians-Universität München']",['Germany'],2022-02
2203.00748,Mohammad Akbari,"Mohammad Akbari, Amin Banitalebi-Dehkordi, Yong Zhang",E-LANG: Energy-Based Joint Inferencing of Super and Swift Language Models,ACL 2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Building huge and highly capable language models has been a trend in the past years. Despite their great performance, they incur high computational cost. A common solution is to apply model compression or choose light-weight architectures, which often need a separate fixed-size model for each desirable computational budget, and may lose performance in case of heavy compression. This paper proposes an effective dynamic inference approach, called E-LANG, which distributes the inference between large accurate Super-models and light-weight Swift models. To this end, a decision making module routes the inputs to Super or Swift models based on the energy characteristics of the representations in the latent space. This method is easily adoptable and architecture agnostic. As such, it can be applied to black-box pre-trained models without a need for architectural manipulations, reassembling of modules, or re-training. Unlike existing methods that are only applicable to encoder-only backbones and classification tasks, our method also works for encoder-decoder structures and sequence-to-sequence tasks such as translation. The E-LANG performance is verified through a set of experiments with T5 and BERT backbones on GLUE, SuperGLUE, and WMT. In particular, we outperform T5-11B with an average computations speed-up of 3.3$\times$ on GLUE and 2.9$\times$ on SuperGLUE. We also achieve BERT-based SOTA on GLUE with 3.2$\times$ less computations. Code and demo are available in the supplementary materials. ","[{'version': 'v1', 'created': 'Tue, 1 Mar 2022 21:21:27 GMT'}]",2022-03-03,"[['Akbari', 'Mohammad', ''], ['Banitalebi-Dehkordi', 'Amin', ''], ['Zhang', 'Yong', '']]",0,0,2022-03-01,1,3,2,1,1,0,3a56263ab3f6301b3696631551bb2032676a2d28,247218447.0,https://www.semanticscholar.org/paper/3a56263ab3f6301b3696631551bb2032676a2d28,Annual Meeting of the Association for Computational Linguistics,2022.0,40.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143742896', 'name': 'Mohammad Akbari'}, {'authorId': '1398288379', 'name': 'Amin Banitalebi-Dehkordi'}, {'authorId': '2144289260', 'name': 'Yong Zhang'}]",['Huawei Technologies (Canada)'],['Canada'],2022-03
2203.02912,Samujjwal Ghosh,"Samujjwal Ghosh, Subhadeep Maji, Maunendra Sankar Desarkar",Graph Neural Network Enhanced Language Models for Efficient Multilingual Text Classification,Under Review,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Online social media works as a source of various valuable and actionable information during disasters. These information might be available in multiple languages due to the nature of user generated content. An effective system to automatically identify and categorize these actionable information should be capable to handle multiple languages and under limited supervision. However, existing works mostly focus on English language only with the assumption that sufficient labeled data is available. To overcome these challenges, we propose a multilingual disaster related text classification system which is capable to work under \{mono, cross and multi\} lingual scenarios and under limited supervision. Our end-to-end trainable framework combines the versatility of graph neural networks, by applying over the corpus, with the power of transformer based large language models, over examples, with the help of cross-attention between the two. We evaluate our framework over total nine English, Non-English and monolingual datasets in \{mono, cross and multi\} lingual classification scenarios. Our framework outperforms state-of-the-art models in disaster domain and multilingual BERT baseline in terms of Weighted F$_1$ score. We also show the generalizability of the proposed model under limited supervision. ","[{'version': 'v1', 'created': 'Sun, 6 Mar 2022 09:05:42 GMT'}]",2022-03-08,"[['Ghosh', 'Samujjwal', ''], ['Maji', 'Subhadeep', ''], ['Desarkar', 'Maunendra Sankar', '']]",0,0,2022-03-06,1,3,1,0,0,0,2b83f3175444b534b0c7412c483fcea2797ac08d,247292501.0,https://www.semanticscholar.org/paper/2b83f3175444b534b0c7412c483fcea2797ac08d,arXiv.org,2022.0,32.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '40975611', 'name': 'Samujjwal Ghosh'}, {'authorId': '40689703', 'name': 'Subhadeep Maji'}, {'authorId': '2481485', 'name': 'M. Desarkar'}]","['Indian Institute of Technology Bombay', 'Indian Institute of Technology', 'Amazon']",['India'],2022-03
2203.05081,Fawaz Sammani,"Fawaz Sammani, Tanmoy Mukherjee, Nikos Deligiannis",NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks,Accepted to CVPR 2022,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Natural language explanation (NLE) models aim at explaining the decision-making process of a black box system via generating natural language sentences which are human-friendly, high-level and fine-grained. Current NLE models explain the decision-making process of a vision or vision-language model (a.k.a., task model), e.g., a VQA model, via a language model (a.k.a., explanation model), e.g., GPT. Other than the additional memory resources and inference time required by the task model, the task and explanation models are completely independent, which disassociates the explanation from the reasoning process made to predict the answer. We introduce NLX-GPT, a general, compact and faithful language model that can simultaneously predict an answer and explain it. We first conduct pre-training on large scale data of image-caption pairs for general understanding of images, and then formulate the answer as a text prediction task along with the explanation. Without region proposals nor a task model, our resulting overall framework attains better evaluation scores, contains much less parameters and is 15$\times$ faster than the current SoA model. We then address the problem of evaluating the explanations which can be in many times generic, data-biased and can come in several forms. We therefore design 2 new evaluation measures: (1) explain-predict and (2) retrieval-based attack, a self-evaluation framework that requires no labels. Code is at: https://github.com/fawazsammani/nlxgpt. ","[{'version': 'v1', 'created': 'Wed, 9 Mar 2022 22:57:15 GMT'}]",2022-03-11,"[['Sammani', 'Fawaz', ''], ['Mukherjee', 'Tanmoy', ''], ['Deligiannis', 'Nikos', '']]",0,1,2022-03-09,1,3,2,0,0,0,bc64190d42d9dc34077b6a096d9053bb88deaa3a,247362537.0,https://www.semanticscholar.org/paper/bc64190d42d9dc34077b6a096d9053bb88deaa3a,Computer Vision and Pattern Recognition,2022.0,67.0,25.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32095408', 'name': 'Fawaz Sammani'}, {'authorId': '1474579572', 'name': 'Tanmoy Mukherjee'}, {'authorId': '2003112059', 'name': 'Nikos Deligiannis'}]","['Vrije Universiteit Brussel', 'IMEC']",['Belgium'],2022-03
2203.05948,Sahar Sadrizadeh,"Sahar Sadrizadeh, Ljiljana Dolamic, Pascal Frossard",Block-Sparse Adversarial Attack to Fool Transformer-Based Text Classifiers,"ICASSP 2022, Code available at:
  https://github.com/sssadrizadeh/transformer-text-classifier-attack",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, it has been shown that, in spite of the significant performance of deep neural networks in different fields, those are vulnerable to adversarial examples. In this paper, we propose a gradient-based adversarial attack against transformer-based text classifiers. The adversarial perturbation in our method is imposed to be block-sparse so that the resultant adversarial example differs from the original sentence in only a few words. Due to the discrete nature of textual data, we perform gradient projection to find the minimizer of our proposed optimization problem. Experimental results demonstrate that, while our adversarial attack maintains the semantics of the sentence, it can reduce the accuracy of GPT-2 to less than 5% on different datasets (AG News, MNLI, and Yelp Reviews). Furthermore, the block-sparsity constraint of the proposed optimization problem results in small perturbations in the adversarial example. ","[{'version': 'v1', 'created': 'Fri, 11 Mar 2022 14:37:41 GMT'}]",2022-03-14,"[['Sadrizadeh', 'Sahar', ''], ['Dolamic', 'Ljiljana', ''], ['Frossard', 'Pascal', '']]",0,1,2022-03-11,1,3,2,1,1,0,01cf6b57038defaed32103036abc0bfcf53e37a0,247411430.0,https://www.semanticscholar.org/paper/01cf6b57038defaed32103036abc0bfcf53e37a0,"IEEE International Conference on Acoustics, Speech, and Signal Processing",2022.0,21.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '22271966', 'name': 'Sahar Sadrizadeh'}, {'authorId': '1680665', 'name': 'L. Dolamic'}, {'authorId': '1703189', 'name': 'P. Frossard'}]","['Armasuisse S+T Thun, Switzerland', 'University of Lausanne']",['Switzerland'],2022-03
2203.06462,Andreas Grivas,"Andreas Grivas, Nikolay Bogoychev, Adam Lopez",Low-Rank Softmax Can Have Unargmaxable Classes in Theory but Rarely in Practice,Preprint of conference paper accepted at ACL 2022,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Classifiers in natural language processing (NLP) often have a large number of output classes. For example, neural language models (LMs) and machine translation (MT) models both predict tokens from a vocabulary of thousands. The Softmax output layer of these models typically receives as input a dense feature representation, which has much lower dimensionality than the output. In theory, the result is some words may be impossible to be predicted via argmax, irrespective of input features, and empirically, there is evidence this happens in small language models. In this paper we ask whether it can happen in practical large language models and translation models. To do so, we develop algorithms to detect such \emph{unargmaxable} tokens in public models. We find that 13 out of 150 models do indeed have such tokens; however, they are very infrequent and unlikely to impact model quality. We release our code so that others can inspect their models. ","[{'version': 'v1', 'created': 'Sat, 12 Mar 2022 15:34:54 GMT'}, {'version': 'v2', 'created': 'Mon, 21 Mar 2022 11:51:21 GMT'}]",2022-03-22,"[['Grivas', 'Andreas', ''], ['Bogoychev', 'Nikolay', ''], ['Lopez', 'Adam', '']]",0,0,2022-03-12,2,3,2,0,0,0,f4adc782a7f2ef6412273d289fae9423fbe27fb3,247447100.0,https://www.semanticscholar.org/paper/f4adc782a7f2ef6412273d289fae9423fbe27fb3,Annual Meeting of the Association for Computational Linguistics,2022.0,66.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40446071', 'name': 'Andreas Grivas'}, {'authorId': '3444222', 'name': 'Nikolay Bogoychev'}, {'authorId': '144871732', 'name': 'Adam Lopez'}]",['University of Edinburgh'],['United Kingdom'],2022-03
2203.07785,Rebecca Lynn Johnson Ms,"Rebecca L Johnson, Giada Pistilli, Natalia Men\'edez-Gonz\'alez,
  Leslye Denisse Dias Duran, Enrico Panai, Julija Kalpokiene, Donald Jay
  Bertulfo",The Ghost in the Machine has an American accent: value conflict in GPT-3,"There are a total of 15 pages of the PDF including 8 pages of the
  main manuscript, 3 pages of references, and 4 pages of appendices. The paper
  is currently under review by a conference",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The alignment problem in the context of large language models must consider the plurality of human values in our world. Whilst there are many resonant and overlapping values amongst the world's cultures, there are also many conflicting, yet equally valid, values. It is important to observe which cultural values a model exhibits, particularly when there is a value conflict between input prompts and generated outputs. We discuss how the co-creation of language and cultural value impacts large language models (LLMs). We explore the constitution of the training data for GPT-3 and compare that to the world's language and internet access demographics, as well as to reported statistical profiles of dominant values in some Nation-states. We stress tested GPT-3 with a range of value-rich texts representing several languages and nations; including some with values orthogonal to dominant US public opinion as reported by the World Values Survey. We observed when values embedded in the input text were mutated in the generated outputs and noted when these conflicting values were more aligned with reported dominant US values. Our discussion of these results uses a moral value pluralism (MVP) lens to better understand these value mutations. Finally, we provide recommendations for how our work may contribute to other current work in the field. ","[{'version': 'v1', 'created': 'Tue, 15 Mar 2022 11:06:54 GMT'}]",2022-03-16,"[['Johnson', 'Rebecca L', ''], ['Pistilli', 'Giada', ''], ['Menédez-González', 'Natalia', ''], ['Duran', 'Leslye Denisse Dias', ''], ['Panai', 'Enrico', ''], ['Kalpokiene', 'Julija', ''], ['Bertulfo', 'Donald Jay', '']]",0,1,2022-03-15,1,7,2,1,0,1,5bf2343f67ae81610040d3fa07024c13c8591da7,247451091.0,https://www.semanticscholar.org/paper/5bf2343f67ae81610040d3fa07024c13c8591da7,arXiv.org,2022.0,81.0,25.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '40016844', 'name': 'Rebecca Lynn Johnson'}, {'authorId': '2158858559', 'name': 'Giada Pistilli'}, {'authorId': '2158860108', 'name': ""Natalia Men'edez-Gonz'alez""}, {'authorId': '2158860268', 'name': 'Leslye Denisse Dias Duran'}, {'authorId': '2237937973', 'name': 'Enrico Panai'}, {'authorId': '117430992', 'name': 'Julija Kalpokienė'}, {'authorId': '116483992', 'name': 'D. Bertulfo'}]","['University of Sassari', 'Vytautas Magnus University', 'European University Institute', 'University of Sydney', 'Ruhr University Bochum', 'Delft University of Technology', 'Sorbonne Université']","['Germany', 'Netherlands', 'Lithuania', 'France', 'Australia', 'Italy']",2022-03
2203.08085,Yu Qiao,"Daniel Wiechmann, Yu Qiao, Elma Kerz, Justus Mattern",Measuring the Impact of (Psycho-)Linguistic and Readability Features and Their Spill Over Effects on the Prediction of Eye Movement Patterns,accepted at ACL 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There is a growing interest in the combined use of NLP and machine learning methods to predict gaze patterns during naturalistic reading. While promising results have been obtained through the use of transformer-based language models, little work has been undertaken to relate the performance of such models to general text characteristics. In this paper we report on experiments with two eye-tracking corpora of naturalistic reading and two language models (BERT and GPT-2). In all experiments, we test effects of a broad spectrum of features for predicting human reading behavior that fall into five categories (syntactic complexity, lexical richness, register-based multiword combinations, readability and psycholinguistic word properties). Our experiments show that both the features included and the architecture of the transformer-based language models play a role in predicting multiple eye-tracking measures during naturalistic reading. We also report the results of experiments aimed at determining the relative importance of features from different groups using SP-LIME. ","[{'version': 'v1', 'created': 'Tue, 15 Mar 2022 17:13:45 GMT'}]",2022-03-16,"[['Wiechmann', 'Daniel', ''], ['Qiao', 'Yu', ''], ['Kerz', 'Elma', ''], ['Mattern', 'Justus', '']]",0,1,2022-03-15,1,4,1,1,1,0,ebf4c14d0b7524aa5bb2a48edabe0be674dd426e,247451263.0,https://www.semanticscholar.org/paper/ebf4c14d0b7524aa5bb2a48edabe0be674dd426e,Annual Meeting of the Association for Computational Linguistics,2022.0,46.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '38762085', 'name': 'Daniel Wiechmann'}, {'authorId': '2151691771', 'name': 'Yu Qiao'}, {'authorId': '3390813', 'name': 'Elma Kerz'}, {'authorId': '2138547910', 'name': 'Justus Mattern'}]","['University of Amsterdam', 'RWTH Aachen University']","['Germany', 'Netherlands']",2022-03
2203.10343,Ganesh Jawahar,"Ganesh Jawahar, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan",Automatic Detection of Entity-Manipulated Text using Factual Knowledge,Association for Computational Linguistics (ACL) 2022 camera-ready,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this work, we focus on the problem of distinguishing a human written news article from a news article that is created by manipulating entities in a human written news article (e.g., replacing entities with factually incorrect entities). Such manipulated articles can mislead the reader by posing as a human written news article. We propose a neural network based detector that detects manipulated news articles by reasoning about the facts mentioned in the article. Our proposed detector exploits factual knowledge via graph convolutional neural network along with the textual information in the news article. We also create challenging datasets for this task by considering various strategies to generate the new replacement entity (e.g., entity generation from GPT-2). In all the settings, our proposed model either matches or outperforms the state-of-the-art detector in terms of accuracy. Our code and data are available at https://github.com/UBC-NLP/manipulated_entity_detection. ","[{'version': 'v1', 'created': 'Sat, 19 Mar 2022 15:35:59 GMT'}]",2022-03-22,"[['Jawahar', 'Ganesh', ''], ['Abdul-Mageed', 'Muhammad', ''], ['Lakshmanan', 'Laks V. S.', '']]",0,1,2022-03-19,1,3,2,1,1,0,030f4f2078dc64b2148340dbedccef9f45c8e202,247594674.0,https://www.semanticscholar.org/paper/030f4f2078dc64b2148340dbedccef9f45c8e202,Annual Meeting of the Association for Computational Linguistics,2022.0,24.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2065043351', 'name': 'Ganesh Jawahar'}, {'authorId': '1388437494', 'name': 'Muhammad Abdul-Mageed'}, {'authorId': '1708593', 'name': 'L. Lakshmanan'}]","['University of British Columbia', 'Deep Learning & Natural Language Processing Group,']",['Canada'],2022-03
2203.10415,Ahmed Alajrami,Ahmed Alajrami and Nikolaos Aletras,How does the pre-training objective affect what large language models learn about linguistic properties?,Accepted at ACL 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Several pre-training objectives, such as masked language modeling (MLM), have been proposed to pre-train language models (e.g. BERT) with the aim of learning better language representations. However, to the best of our knowledge, no previous work so far has investigated how different pre-training objectives affect what BERT learns about linguistics properties. We hypothesize that linguistically motivated objectives such as MLM should help BERT to acquire better linguistic knowledge compared to other non-linguistically motivated objectives that are not intuitive or hard for humans to guess the association between the input and the label to be predicted. To this end, we pre-train BERT with two linguistically motivated objectives and three non-linguistically motivated ones. We then probe for linguistic characteristics encoded in the representation of the resulting models. We find strong evidence that there are only small differences in probing performance between the representations learned by the two different types of objectives. These surprising results question the dominant narrative of linguistically informed pre-training. ","[{'version': 'v1', 'created': 'Sun, 20 Mar 2022 00:02:10 GMT'}]",2022-03-22,"[['Alajrami', 'Ahmed', ''], ['Aletras', 'Nikolaos', '']]",0,0,2022-03-20,1,2,1,0,0,0,5ca0a54fa0f76ae0e1881899c61b36d35d3bd166,247594916.0,https://www.semanticscholar.org/paper/5ca0a54fa0f76ae0e1881899c61b36d35d3bd166,Annual Meeting of the Association for Computational Linguistics,2022.0,33.0,11.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2159546384', 'name': 'Ahmed Alajrami'}, {'authorId': '3238627', 'name': 'Nikolaos Aletras'}]",['University of Sheffield'],['United Kingdom'],2022-03
2203.11147,Jacob Menick,"Jacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis
  Song, Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham,
  Geoffrey Irving, Nat McAleese",Teaching language models to support answers with verified quotes,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent large language models often answer factual questions correctly. But users can't trust any given claim a model makes without fact-checking, because language models can hallucinate convincing nonsense. In this work we use reinforcement learning from human preferences (RLHP) to train ""open-book"" QA models that generate answers whilst also citing specific evidence for their claims, which aids in the appraisal of correctness. Supporting evidence is drawn from multiple documents found via a search engine, or from a single user-provided document. Our 280 billion parameter model, GopherCite, is able to produce answers with high quality supporting evidence and abstain from answering when unsure. We measure the performance of GopherCite by conducting human evaluation of answers to questions in a subset of the NaturalQuestions and ELI5 datasets. The model's response is found to be high-quality 80\% of the time on this Natural Questions subset, and 67\% of the time on the ELI5 subset. Abstaining from the third of questions for which it is most unsure improves performance to 90\% and 80\% respectively, approaching human baselines. However, analysis on the adversarial TruthfulQA dataset shows why citation is only one part of an overall strategy for safety and trustworthiness: not all claims supported by evidence are true. ","[{'version': 'v1', 'created': 'Mon, 21 Mar 2022 17:26:29 GMT'}]",2022-03-22,"[['Menick', 'Jacob', ''], ['Trebacz', 'Maja', ''], ['Mikulik', 'Vladimir', ''], ['Aslanides', 'John', ''], ['Song', 'Francis', ''], ['Chadwick', 'Martin', ''], ['Glaese', 'Mia', ''], ['Young', 'Susannah', ''], ['Campbell-Gillingham', 'Lucy', ''], ['Irving', 'Geoffrey', ''], ['McAleese', 'Nat', '']]",0,0,2022-03-21,1,11,2,0,0,0,8666f9f379389a5dff31e72fb0f992a37763ba41,247594830.0,https://www.semanticscholar.org/paper/8666f9f379389a5dff31e72fb0f992a37763ba41,arXiv.org,2022.0,71.0,114.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '10698483', 'name': 'Jacob Menick'}, {'authorId': '1994939814', 'name': 'Maja Trebacz'}, {'authorId': '148305440', 'name': 'Vladimir Mikulik'}, {'authorId': '9958912', 'name': 'J. Aslanides'}, {'authorId': '2059836321', 'name': 'Francis Song'}, {'authorId': '2159545857', 'name': 'Martin Chadwick'}, {'authorId': '2143471164', 'name': 'Mia Glaese'}, {'authorId': '116494324', 'name': 'Susannah Young'}, {'authorId': '2151248210', 'name': 'Lucy Campbell-Gillingham'}, {'authorId': '2060655766', 'name': 'G. Irving'}, {'authorId': '147687624', 'name': 'Nathan McAleese'}]","['University College London', 'Google']",['United Kingdom'],2022-03
2203.14617,Muhammad Haris,"Muhammad Haris, Markus Stocker, S\""oren Auer",Enriching Scholarly Knowledge with Context,,,,,cs.DL,http://creativecommons.org/licenses/by/4.0/,"  Leveraging a GraphQL-based federated query service that integrates multiple scholarly communication infrastructures (specifically, DataCite, ORCID, ROR, OpenAIRE, Semantic Scholar, Wikidata and Altmetric), we develop a novel web widget based approach for the presentation of scholarly knowledge with rich contextual information. We implement the proposed approach in the Open Research Knowledge Graph (ORKG) and showcase it on three kinds of widgets. First, we devise a widget for the ORKG paper view that presents contextual information about related datasets, software, project information, topics, and metrics. Second, we extend the ORKG contributor profile view with contextual information including authored articles, developed software, linked projects, and research interests. Third, we advance ORKG comparison faceted search by introducing contextual facets (e.g. citations). As a result, the devised approach enables presenting ORKG scholarly knowledge flexibly enriched with contextual information sourced in a federated manner from numerous technologically heterogeneous scholarly communication infrastructures. ","[{'version': 'v1', 'created': 'Mon, 28 Mar 2022 10:00:28 GMT'}]",2022-03-29,"[['Haris', 'Muhammad', ''], ['Stocker', 'Markus', ''], ['Auer', 'Sören', '']]",0,0,2022-03-28,1,3,1,0,0,0,da185b509b6164ab85f0c3627a9fa45cb9f39734,247763107.0,https://www.semanticscholar.org/paper/da185b509b6164ab85f0c3627a9fa45cb9f39734,International Conference on Web Engineering,2022.0,26.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2065376009', 'name': 'Muhammad Haris'}, {'authorId': '153237136', 'name': 'M. Stocker'}, {'authorId': '145044578', 'name': 'S. Auer'}]","['Technische Informationsbibliothek (TIB)', 'Leibniz University Hannover']",['Germany'],2022-03
2204.00498,Nitarshan Rajkumar,"Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau",Evaluating the Text-to-SQL Capabilities of Large Language Models,,,,,cs.CL cs.DB cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We perform an empirical evaluation of Text-to-SQL capabilities of the Codex language model. We find that, without any finetuning, Codex is a strong baseline on the Spider benchmark; we also analyze the failure modes of Codex in this setting. Furthermore, we demonstrate on the GeoQuery and Scholar benchmarks that a small number of in-domain examples provided in the prompt enables Codex to perform better than state-of-the-art models finetuned on such few-shot examples. ","[{'version': 'v1', 'created': 'Tue, 15 Mar 2022 17:23:53 GMT'}]",2022-04-04,"[['Rajkumar', 'Nitarshan', ''], ['Li', 'Raymond', ''], ['Bahdanau', 'Dzmitry', '']]",0,0,2022-03-15,1,3,3,1,0,1,51000d9f79be0eefd7972fe94e3c71dddc90d2c6,247922681.0,https://www.semanticscholar.org/paper/51000d9f79be0eefd7972fe94e3c71dddc90d2c6,arXiv.org,2022.0,23.0,56.0,12.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1420542737', 'name': 'Nitarshan Rajkumar'}, {'authorId': '2116277958', 'name': 'Raymond Li'}, {'authorId': '3335364', 'name': 'Dzmitry Bahdanau'}]","['McGill University', 'University of Cambridge', 'Université de Montréal', 'Canadian Institute for Advanced Research']","['Canada', 'United Kingdom']",2022-03
2204.01959,Gaurav Sahu,"Gaurav Sahu, Pau Rodriguez, Issam H. Laradji, Parmida Atighehchian,
  David Vazquez, Dzmitry Bahdanau",Data Augmentation for Intent Classification with Off-the-shelf Large Language Models,"Accepted to 4th Workshop on NLP for Conversational AI, ACL 2022",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Data augmentation is a widely employed technique to alleviate the problem of data scarcity. In this work, we propose a prompting-based approach to generate labelled training data for intent classification with off-the-shelf language models (LMs) such as GPT-3. An advantage of this method is that no task-specific LM-fine-tuning for data generation is required; hence the method requires no hyper-parameter tuning and is applicable even when the available training data is very scarce. We evaluate the proposed method in a few-shot setting on four diverse intent classification tasks. We find that GPT-generated data significantly boosts the performance of intent classifiers when intents in consideration are sufficiently distinct from each other. In tasks with semantically close intents, we observe that the generated data is less helpful. Our analysis shows that this is because GPT often generates utterances that belong to a closely-related intent instead of the desired one. We present preliminary evidence that a prompting-based GPT classifier could be helpful in filtering the generated data to enhance its quality. ","[{'version': 'v1', 'created': 'Tue, 5 Apr 2022 03:29:26 GMT'}]",2022-04-06,"[['Sahu', 'Gaurav', ''], ['Rodriguez', 'Pau', ''], ['Laradji', 'Issam H.', ''], ['Atighehchian', 'Parmida', ''], ['Vazquez', 'David', ''], ['Bahdanau', 'Dzmitry', '']]",0,1,2022-04-05,1,6,2,1,0,1,3728aec0c3e720e7f3f22e1306a98bd0013d47ad,247958012.0,https://www.semanticscholar.org/paper/3728aec0c3e720e7f3f22e1306a98bd0013d47ad,NLP4CONVAI,2022.0,23.0,22.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064714291', 'name': 'Gaurav Sahu'}, {'authorId': '117849477', 'name': 'Pau Rodríguez López'}, {'authorId': '3266173', 'name': 'I. Laradji'}, {'authorId': '102057353', 'name': 'Parmida Atighehchian'}, {'authorId': '2064388326', 'name': 'David Vázquez'}, {'authorId': '3335364', 'name': 'Dzmitry Bahdanau'}]","['ServiceNow Research', 'University of Waterloo']",['Canada'],2022-04
2204.03465,Javier Huertas-Tato,Javier Huertas-Tato and Alejandro Martin and David Camacho,BERTuit: Understanding Spanish language in Twitter through a native transformer,"Support: 1) BBVA FOUNDATION - CIVIC, 2) Spanish Ministry of Science
  and Innovation - FightDIS (PID2020-117263GB-100) and XAI-Disinfodemics
  (PLEC2021-007681), 3) Comunidad Autonoma de Madrid - S2018/TCS-4566, 4)
  European Comission - IBERIFIER (2020-EU-IA-0252), 5) Digital Future Society
  (Mobile World Capital Barcelona) - DisTrack, 6) UPM - Programa de Excelencia
  para el Profesorado Universitario",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The appearance of complex attention-based language models such as BERT, Roberta or GPT-3 has allowed to address highly complex tasks in a plethora of scenarios. However, when applied to specific domains, these models encounter considerable difficulties. This is the case of Social Networks such as Twitter, an ever-changing stream of information written with informal and complex language, where each message requires careful evaluation to be understood even by humans given the important role that context plays. Addressing tasks in this domain through Natural Language Processing involves severe challenges. When powerful state-of-the-art multilingual language models are applied to this scenario, language specific nuances use to get lost in translation. To face these challenges we present \textbf{BERTuit}, the larger transformer proposed so far for Spanish language, pre-trained on a massive dataset of 230M Spanish tweets using RoBERTa optimization. Our motivation is to provide a powerful resource to better understand Spanish Twitter and to be used on applications focused on this social network, with special emphasis on solutions devoted to tackle the spreading of misinformation in this platform. BERTuit is evaluated on several tasks and compared against M-BERT, XLM-RoBERTa and XLM-T, very competitive multilingual transformers. The utility of our approach is shown with applications, in this case: a zero-shot methodology to visualize groups of hoaxes and profiling authors spreading disinformation.   Misinformation spreads wildly on platforms such as Twitter in languages other than English, meaning performance of transformers may suffer when transferred outside English speaking communities. ","[{'version': 'v1', 'created': 'Thu, 7 Apr 2022 14:28:51 GMT'}, {'version': 'v2', 'created': 'Mon, 13 Jun 2022 11:29:34 GMT'}]",2022-06-14,"[['Huertas-Tato', 'Javier', ''], ['Martin', 'Alejandro', ''], ['Camacho', 'David', '']]",0,1,2022-04-07,2,3,2,1,0,1,0232f6c528aad8050c318cd93a7a888da6ffe9ea,248006341.0,https://www.semanticscholar.org/paper/0232f6c528aad8050c318cd93a7a888da6ffe9ea,arXiv.org,2022.0,40.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1411252016', 'name': 'J. Huertas-Tato'}, {'authorId': '47619557', 'name': 'Alejandro Martín'}, {'authorId': '2151499554', 'name': 'David Camacho'}]",['Universidad Politécnica de Madrid'],['Spain'],2022-04
2204.03542,Patrizio Bellan,"Patrizio Bellan, Mauro Dragoni and Chiara Ghidini",Leveraging pre-trained language models for conversational information seeking from text,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recent advances in Natural Language Processing, and in particular on the construction of very large pre-trained language representation models, is opening up new perspectives on the construction of conversational information seeking (CIS) systems. In this paper we investigate the usage of in-context learning and pre-trained language representation models to address the problem of information extraction from process description documents, in an incremental question and answering oriented fashion. In particular we investigate the usage of the native GPT-3 (Generative Pre-trained Transformer 3) model, together with two in-context learning customizations that inject conceptual definitions and a limited number of samples in a few shot-learning fashion. The results highlight the potential of the approach and the usefulness of the in-context learning customizations, which can substantially contribute to address the ""training data challenge"" of deep learning based NLP techniques the BPM field. It also highlight the challenge posed by control flow relations for which further training needs to be devised. ","[{'version': 'v1', 'created': 'Thu, 31 Mar 2022 09:00:46 GMT'}]",2022-04-08,"[['Bellan', 'Patrizio', ''], ['Dragoni', 'Mauro', ''], ['Ghidini', 'Chiara', '']]",0,1,2022-03-31,1,3,2,1,0,1,4b0e6b4b451ddc7e6b1bbb480e206c18f498ee82,248006156.0,https://www.semanticscholar.org/paper/4b0e6b4b451ddc7e6b1bbb480e206c18f498ee82,arXiv.org,2022.0,30.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51891870', 'name': 'Patrizio Bellan'}, {'authorId': '2346796', 'name': 'M. Dragoni'}, {'authorId': '1704711', 'name': 'Chiara Ghidini'}]",['Fondazione Bruno Kessler'],['Italy'],2022-03
2204.03771,Joosung Min,Joosung Min and Lloyd T. Elliott,Q-learning with online random forests,8 pages,,,,stat.ML cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  $Q$-learning is the most fundamental model-free reinforcement learning algorithm. Deployment of $Q$-learning requires approximation of the state-action value function (also known as the $Q$-function). In this work, we provide online random forests as $Q$-function approximators and propose a novel method wherein the random forest is grown as learning proceeds (through expanding forests). We demonstrate improved performance of our methods over state-of-the-art Deep $Q$-Networks in two OpenAI gyms (`blackjack' and `inverted pendulum') but not in the `lunar lander' gym. We suspect that the resilience to overfitting enjoyed by random forests recommends our method for common tasks that do not require a strong representation of the problem domain. We show that expanding forests (in which the number of trees increases as data comes in) improve performance, suggesting that expanding forests are viable for other applications of online random forests beyond the reinforcement learning setting. ","[{'version': 'v1', 'created': 'Thu, 7 Apr 2022 23:00:39 GMT'}]",2022-04-11,"[['Min', 'Joosung', ''], ['Elliott', 'Lloyd T.', '']]",0,0,2022-04-07,1,2,2,0,0,0,014165fc50b4bffdbbdc0a37c26625cb0e57101f,248069506.0,https://www.semanticscholar.org/paper/014165fc50b4bffdbbdc0a37c26625cb0e57101f,arXiv.org,2022.0,23.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146537876', 'name': 'Joosung Min'}, {'authorId': '2825123', 'name': 'L. Elliott'}]",['Simon Fraser University'],['Canada'],2022-04
2204.03958,Minh-Tien Nguyen,"Shumpei Inoue, Tsungwei Liu, Nguyen Hong Son, Minh-Tien Nguyen",Enhance Incomplete Utterance Restoration by Joint Learning Token Extraction and Text Generation,"This paper was accepted by 2022 Annual Conference of the North
  American Chapter of the Association for Computational Linguistics (NAACL
  2022). It includes 10 pages, 2 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper introduces a model for incomplete utterance restoration (IUR) called JET (\textbf{J}oint learning token \textbf{E}xtraction and \textbf{T}ext generation). Different from prior studies that only work on extraction or abstraction datasets, we design a simple but effective model, working for both scenarios of IUR. Our design simulates the nature of IUR, where omitted tokens from the context contribute to restoration. From this, we construct a Picker that identifies the omitted tokens. To support the picker, we design two label creation methods (soft and hard labels), which can work in cases of no annotation data for the omitted tokens. The restoration is done by using a Generator with the help of the Picker on joint learning. Promising results on four benchmark datasets in extraction and abstraction scenarios show that our model is better than the pretrained T5 and non-generative language model methods in both rich and limited training data settings.\footnote{The code is available at \url{https://github.com/shumpei19/JET}} ","[{'version': 'v1', 'created': 'Fri, 8 Apr 2022 09:32:18 GMT'}, {'version': 'v2', 'created': 'Thu, 5 May 2022 04:57:01 GMT'}, {'version': 'v3', 'created': 'Fri, 29 Jul 2022 03:49:34 GMT'}]",2022-08-01,"[['Inoue', 'Shumpei', ''], ['Liu', 'Tsungwei', ''], ['Son', 'Nguyen Hong', ''], ['Nguyen', 'Minh-Tien', '']]",0,0,2022-04-08,3,4,2,1,1,0,5133c543c3fb373c39c828988fc7ab2712715969,248069359.0,https://www.semanticscholar.org/paper/5133c543c3fb373c39c828988fc7ab2712715969,North American Chapter of the Association for Computational Linguistics,2022.0,34.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2161965285', 'name': 'Shumpei Inoue'}, {'authorId': '2144902714', 'name': 'Tsun-Jui Liu'}, {'authorId': '2036462848', 'name': 'Nguyen Hong Son'}, {'authorId': '1789308', 'name': 'Minh Le Nguyen'}]","['1 Cinnamon AI, 10th floor, Geleximco building, 36 Hoang Cau, Dong Da, Hanoi, Vietnam.', 'Hung Yen University of Technology and Education']",['Vietnam'],2022-04
2204.05185,Joseph Marvin Imperial,Joseph Marvin Imperial,Uniform Complexity for Text Generation,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large pre-trained language models have shown promising results in a wide array of tasks such as narrative generation, question answering, and machine translation. Likewise, the current trend in literature has deeply focused on controlling salient properties of generated texts including sentiment, topic, and coherence to produce more human-like outputs. In this work, we introduce Uniform Complexity for Text Generation or UCTG which serves as a challenge to make existing models generate uniformly complex text with respect to inputs or prompts used. For example, if the reading level of an input text prompt is appropriate for low-leveled learners (ex. A2 in the CEFR), then the generated text by an NLG system should also assume this particular level for increased readability. In a controlled narrative generation task, we surveyed over 160 linguistic and cognitively-motivated features for evaluating text readability and found out that GPT-2 models and even humans struggle in preserving the linguistic complexity of input prompts used. Ultimately, we lay down potential methods and approaches which can be incorporated into the general framework of steering language models towards addressing this important challenge. ","[{'version': 'v1', 'created': 'Mon, 11 Apr 2022 15:19:47 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Sep 2022 08:06:06 GMT'}]",2022-09-27,"[['Imperial', 'Joseph Marvin', '']]",0,1,2022-04-11,2,1,2,1,1,0,25d0807033bc8e684c92334f3c795ed37f252b63,248085725.0,https://www.semanticscholar.org/paper/25d0807033bc8e684c92334f3c795ed37f252b63,arXiv.org,2022.0,86.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151472158', 'name': 'Joseph Marvin Imperial'}]","['National University', 'University of Bath']","['Philippines', 'United Kingdom']",2022-04
2204.06355,Bertoin David,"David Bertoin (IMT), Emmanuel Rachelson (DMIA)",Local Feature Swapping for Generalization in Reinforcement Learning,,,,,cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Over the past few years, the acceleration of computing resources and research in deep learning has led to significant practical successes in a range of tasks, including in particular in computer vision. Building on these advances, reinforcement learning has also seen a leap forward with the emergence of agents capable of making decisions directly from visual observations. Despite these successes, the over-parametrization of neural architectures leads to memorization of the data used during training and thus to a lack of generalization. Reinforcement learning agents based on visual inputs also suffer from this phenomenon by erroneously correlating rewards with unrelated visual features such as background elements. To alleviate this problem, we introduce a new regularization technique consisting of channel-consistent local permutations (CLOP) of the feature maps. The proposed permutations induce robustness to spatial correlations and help prevent overfitting behaviors in RL. We demonstrate, on the OpenAI Procgen Benchmark, that RL agents trained with the CLOP method exhibit robustness to visual changes and better generalization properties than agents trained using other state-of-the-art regularization techniques. We also demonstrate the effectiveness of CLOP as a general regularization technique in supervised learning. ","[{'version': 'v1', 'created': 'Wed, 13 Apr 2022 13:12:51 GMT'}]",2022-04-14,"[['Bertoin', 'David', '', 'IMT'], ['Rachelson', 'Emmanuel', '', 'DMIA']]",0,0,2022-04-13,1,2,1,0,0,0,56a73bb9748e4a09994fe8aedc645eded638109e,248157178.0,https://www.semanticscholar.org/paper/56a73bb9748e4a09994fe8aedc645eded638109e,International Conference on Learning Representations,2022.0,54.0,10.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2114875282', 'name': 'David Bertoin'}, {'authorId': '2558054', 'name': 'E. Rachelson'}]","['Université de Toulouse', 'National Higher French Institute of Aeronautics and Space']",['France'],2022-04
2204.07182,Erick Giovani Sperandio Nascimento,Raphael Souza de Oliveira and Erick Giovani Sperandio Nascimento,Analysing similarities between legal court documents using natural language processing approaches based on Transformers,,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recent advances in Artificial Intelligence (AI) have leveraged promising results in solving complex problems in the area of Natural Language Processing (NLP), being an important tool to help in the expeditious resolution of judicial proceedings in the legal area. In this context, this work targets the problem of detecting the degree of similarity between judicial documents that can be achieved in the inference group, by applying six NLP techniques based on the transformers architecture to a case study of legal proceedings in the Brazilian judicial system. The NLP transformer-based models, namely BERT, GPT-2 and RoBERTa, were pre-trained using a general purpose corpora of the Brazilian Portuguese language, and then were fine-tuned and specialised for the legal sector using 210,000 legal proceedings. Vector representations of each legal document were calculated based on their embeddings, which were used to cluster the lawsuits, calculating the quality of each model based on the cosine of the distance between the elements of the group to its centroid. We noticed that models based on transformers presented better performance when compared to previous traditional NLP techniques, with the RoBERTa model specialised for the Brazilian Portuguese language presenting the best results. This methodology can be also applied to other case studies for different languages, making it possible to advance in the current state of the art in the area of NLP applied to the legal sector. ","[{'version': 'v1', 'created': 'Thu, 14 Apr 2022 18:25:56 GMT'}, {'version': 'v2', 'created': 'Thu, 21 Apr 2022 13:13:36 GMT'}, {'version': 'v3', 'created': 'Thu, 11 May 2023 08:33:49 GMT'}]",2023-05-12,"[['de Oliveira', 'Raphael Souza', ''], ['Nascimento', 'Erick Giovani Sperandio', '']]",0,1,2022-04-14,3,2,3,1,1,0,e7f86fcea0851451eb1fee3763072a00581ea3f9,258615134.0,https://www.semanticscholar.org/paper/e7f86fcea0851451eb1fee3763072a00581ea3f9,,2022.0,43.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2162853590', 'name': 'R. S. Oliveira'}, {'authorId': '2189616211', 'name': 'E. G. S. Nascimento'}]","['Stricto Sensu Department, SENAI CIMATEC University Center, Salvador, BA, Brazil', 'University of Surrey', 'Serviço Nacional de Aprendizagem Industrial', 'Surrey Institute for People-Centred AI, School of Computer Science and Electronic Engineering,']","['United Kingdom', 'Brazil']",2022-04
2204.08046,Ivan Sekulic,"Ivan Sekuli\'c, Mohammad Aliannejadi, Fabio Crestani",Evaluating Mixed-initiative Conversational Search Systems via User Simulation,,,10.1145/3488560.3498440,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Clarifying the underlying user information need by asking clarifying questions is an important feature of modern conversational search system. However, evaluation of such systems through answering prompted clarifying questions requires significant human effort, which can be time-consuming and expensive. In this paper, we propose a conversational User Simulator, called USi, for automatic evaluation of such conversational search systems. Given a description of an information need, USi is capable of automatically answering clarifying questions about the topic throughout the search session. Through a set of experiments, including automated natural language generation metrics and crowdsourcing studies, we show that responses generated by USi are both inline with the underlying information need and comparable to human-generated answers. Moreover, we make the first steps towards multi-turn interactions, where conversational search systems asks multiple questions to the (simulated) user with a goal of clarifying the user need. To this end, we expand on currently available datasets for studying clarifying questions, i.e., Qulac and ClariQ, by performing a crowdsourcing-based multi-turn data acquisition. We show that our generative, GPT2-based model, is capable of providing accurate and natural answers to unseen clarifying questions in the single-turn setting and discuss capabilities of our model in the multi-turn setting. We provide the code, data, and the pre-trained model to be used for further research on the topic. ","[{'version': 'v1', 'created': 'Sun, 17 Apr 2022 16:27:33 GMT'}, {'version': 'v2', 'created': 'Wed, 20 Apr 2022 09:33:46 GMT'}]",2022-04-21,"[['Sekulić', 'Ivan', ''], ['Aliannejadi', 'Mohammad', ''], ['Crestani', 'Fabio', '']]",0,1,2022-04-17,2,3,2,1,1,0,ca545ceefe7c3535ffea0fbcc1cc86bddced3767,246828712.0,https://www.semanticscholar.org/paper/ca545ceefe7c3535ffea0fbcc1cc86bddced3767,Web Search and Data Mining,2022.0,69.0,22.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3305422', 'name': 'Ivan Sekulic'}, {'authorId': '3390352', 'name': 'Mohammad Aliannejadi'}, {'authorId': '145876066', 'name': 'F. Crestani'}]","['Università della Svizzera italiana', 'University of Amsterdam']","['Netherlands', 'Switzerland']",2022-04
2204.08083,Tosin Adewumi,"Tosin Adewumi, Mofetoluwa Adeyemi, Aremu Anuoluwapo, Bukola Peters,
  Happy Buzaaba, Oyerinde Samuel, Amina Mardiyyah Rufai, Benjamin Ajibade,
  Tajudeen Gwadabe, Mory Moussou Koulibaly Traore, Tunde Ajayi, Shamsuddeen
  Muhammad, Ahmed Baruwa, Paul Owoicho, Tolulope Ogunremi, Phylis Ngigi,
  Orevaoghene Ahia, Ruqayya Nasir, Foteini Liwicki and Marcus Liwicki","AfriWOZ: Corpus for Exploiting Cross-Lingual Transferability for Generation of Dialogues in Low-Resource, African Languages","14 pages, 1 figure, 8 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Dialogue generation is an important NLP task fraught with many challenges. The challenges become more daunting for low-resource African languages. To enable the creation of dialogue agents for African languages, we contribute the first high-quality dialogue datasets for 6 African languages: Swahili, Wolof, Hausa, Nigerian Pidgin English, Kinyarwanda & Yor\`ub\'a. These datasets consist of 1,500 turns each, which we translate from a portion of the English multi-domain MultiWOZ dataset. Subsequently, we investigate & analyze the effectiveness of modelling through transfer learning by utilziing state-of-the-art (SoTA) deep monolingual models: DialoGPT and BlenderBot. We compare the models with a simple seq2seq baseline using perplexity. Besides this, we conduct human evaluation of single-turn conversations by using majority votes and measure inter-annotator agreement (IAA). We find that the hypothesis that deep monolingual models learn some abstractions that generalize across languages holds. We observe human-like conversations, to different degrees, in 5 out of the 6 languages. The language with the most transferable properties is the Nigerian Pidgin English, with a human-likeness score of 78.1%, of which 34.4% are unanimous. We freely provide the datasets and host the model checkpoints/demos on the HuggingFace hub for public access. ","[{'version': 'v1', 'created': 'Sun, 17 Apr 2022 20:23:04 GMT'}, {'version': 'v2', 'created': 'Thu, 19 May 2022 11:48:41 GMT'}]",2022-05-20,"[['Adewumi', 'Tosin', ''], ['Adeyemi', 'Mofetoluwa', ''], ['Anuoluwapo', 'Aremu', ''], ['Peters', 'Bukola', ''], ['Buzaaba', 'Happy', ''], ['Samuel', 'Oyerinde', ''], ['Rufai', 'Amina Mardiyyah', ''], ['Ajibade', 'Benjamin', ''], ['Gwadabe', 'Tajudeen', ''], ['Traore', 'Mory Moussou Koulibaly', ''], ['Ajayi', 'Tunde', ''], ['Muhammad', 'Shamsuddeen', ''], ['Baruwa', 'Ahmed', ''], ['Owoicho', 'Paul', ''], ['Ogunremi', 'Tolulope', ''], ['Ngigi', 'Phylis', ''], ['Ahia', 'Orevaoghene', ''], ['Nasir', 'Ruqayya', ''], ['Liwicki', 'Foteini', ''], ['Liwicki', 'Marcus', '']]",0,1,2022-04-17,2,20,1,0,0,0,8abbfb4bd1321eb35c85d0fb48b98aa2612617ec,260595032.0,https://www.semanticscholar.org/paper/8abbfb4bd1321eb35c85d0fb48b98aa2612617ec,,2022.0,60.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51221489', 'name': 'Tosin P. Adewumi'}, {'authorId': '2056770646', 'name': 'Mofetoluwa Adeyemi'}, {'authorId': '2047583795', 'name': 'Aremu Anuoluwapo'}, {'authorId': '2162783577', 'name': 'Bukola Peters'}, {'authorId': '1395556657', 'name': 'Happy Buzaaba'}, {'authorId': '2135913982', 'name': 'Oyerinde Samuel'}, {'authorId': '2162781574', 'name': 'Amina Mardiyyah Rufai'}, {'authorId': '83263885', 'name': 'Benjamin Ayoade Ajibade'}, {'authorId': '2162782825', 'name': 'Tajudeen Gwadabe'}, {'authorId': '2162713888', 'name': 'M. Traore'}, {'authorId': '98725872', 'name': 'T. Ajayi'}, {'authorId': '7744881', 'name': 'Shamsuddeen Hassan Muhammad'}, {'authorId': '114850513', 'name': 'Ahmed Baruwa'}, {'authorId': '2105439683', 'name': 'Paul Owoicho'}, {'authorId': '2145191211', 'name': 'Tolúlopé Ògúnrèmí'}, {'authorId': '2162782962', 'name': 'Phylis Ngigi'}, {'authorId': '2229432740', 'name': 'Orevaoghene Ahia'}, {'authorId': '2162783296', 'name': 'Ruqayya Nasir'}, {'authorId': '80342407', 'name': 'F. Liwicki'}, {'authorId': '1743758', 'name': 'M. Liwicki'}]",['Luleå University of Technology'],['Sweden'],2022-04
2204.08398,Raviraj Joshi,"Ravindra Nayak, Raviraj Joshi",L3Cube-HingCorpus and HingBERT: A Code Mixed Hindi-English Dataset and BERT Language Models,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Code-switching occurs when more than one language is mixed in a given sentence or a conversation. This phenomenon is more prominent on social media platforms and its adoption is increasing over time. Therefore code-mixed NLP has been extensively studied in the literature. As pre-trained transformer-based architectures are gaining popularity, we observe that real code-mixing data are scarce to pre-train large language models. We present L3Cube-HingCorpus, the first large-scale real Hindi-English code mixed data in a Roman script. It consists of 52.93M sentences and 1.04B tokens, scraped from Twitter. We further present HingBERT, HingMBERT, HingRoBERTa, and HingGPT. The BERT models have been pre-trained on codemixed HingCorpus using masked language modelling objectives. We show the effectiveness of these BERT models on the subsequent downstream tasks like code-mixed sentiment analysis, POS tagging, NER, and LID from the GLUECoS benchmark. The HingGPT is a GPT2 based generative transformer model capable of generating full tweets. We also release L3Cube-HingLID Corpus, the largest code-mixed Hindi-English language identification(LID) dataset and HingBERT-LID, a production-quality LID model to facilitate capturing of more code-mixed data using the process outlined in this work. The dataset and models are available at https://github.com/l3cube-pune/code-mixed-nlp . ","[{'version': 'v1', 'created': 'Mon, 18 Apr 2022 16:49:59 GMT'}]",2022-04-19,"[['Nayak', 'Ravindra', ''], ['Joshi', 'Raviraj', '']]",0,1,2022-04-18,1,2,2,1,1,0,0ad942d11cec7aebddd69143b563ce2eccf063ab,248227520.0,https://www.semanticscholar.org/paper/0ad942d11cec7aebddd69143b563ce2eccf063ab,WILDRE,2022.0,27.0,19.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2134735083', 'name': 'Ravindra Nayak'}, {'authorId': '51890352', 'name': 'Raviraj Joshi'}]","['L3Cube, Pune', 'Sri Jayachamarajendra College of Engineering, Mysuru, Karnataka, India', 'Indian Institute of Technology Madras']",['India'],2022-04
2204.08405,Sharath Srivatsa,"Sharath Srivatsa, Tushar Mohan, Kumari Neha, Nishchay Malakar,
  Ponnurangam Kumaraguru, and Srinath Srinivasa",Zero-shot Entity and Tweet Characterization with Designed Conditional Prompts and Contexts,,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Online news and social media have been the de facto mediums to disseminate information globally from the beginning of the last decade. However, bias in content and purpose of intentions are not regulated, and managing bias is the responsibility of content consumers. In this regard, understanding the stances and biases of news sources towards specific entities becomes important. To address this problem, we use pretrained language models, which have been shown to bring about good results with no task-specific training or few-shot training. In this work, we approach the problem of characterizing Named Entities and Tweets as an open-ended text classification and open-ended fact probing problem.We evaluate the zero-shot language model capabilities of Generative Pretrained Transformer 2 (GPT-2) to characterize Entities and Tweets subjectively with human psychology-inspired and logical conditional prefixes and contexts. First, we fine-tune the GPT-2 model on a sufficiently large news corpus and evaluate subjective characterization of popular entities in the corpus by priming with prefixes. Second, we fine-tune GPT-2 with a Tweets corpus from a few popular hashtags and evaluate characterizing tweets by priming the language model with prefixes, questions, and contextual synopsis prompts. Entity characterization results were positive across measures and human evaluation. ","[{'version': 'v1', 'created': 'Mon, 18 Apr 2022 17:01:49 GMT'}]",2022-04-19,"[['Srivatsa', 'Sharath', ''], ['Mohan', 'Tushar', ''], ['Neha', 'Kumari', ''], ['Malakar', 'Nishchay', ''], ['Kumaraguru', 'Ponnurangam', ''], ['Srinivasa', 'Srinath', '']]",0,1,2022-04-18,1,6,2,1,1,0,b758359af8c509cf99cc5c0f9b4293e200903880,248227869.0,https://www.semanticscholar.org/paper/b758359af8c509cf99cc5c0f9b4293e200903880,arXiv.org,2022.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1870621', 'name': 'S. Srivatsa'}, {'authorId': '145562743', 'name': 'T. Mohan'}, {'authorId': '144244906', 'name': 'Kumari Neha'}, {'authorId': '2162781630', 'name': 'Nishchay Malakar'}, {'authorId': '1734731', 'name': 'P. Kumaraguru'}, {'authorId': '144427922', 'name': 'S. Srinivasa'}]","['International Institute of Information Technology, Hyderabad', 'Indraprastha Institute of Information Technology Delhi', 'International Institute of Information Technology Bangalore', 'International Institute of Information Technology']",['India'],2022-04
2204.08832,Cagri Toraman,"Cagri Toraman, Eyup Halit Yilmaz, Furkan \c{S}ahinu\c{c}, Oguzhan
  Ozcelik",Impact of Tokenization on Language Models: An Analysis for Turkish,submitted to ACM TALLIP,"ACM Transactions on Asian and Low-Resource Language Information
  Processing (2023) Volume 22 Issue 4 pp 1-21",10.1145/3578707,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Tokenization is an important text preprocessing step to prepare input tokens for deep language models. WordPiece and BPE are de facto methods employed by important models, such as BERT and GPT. However, the impact of tokenization can be different for morphologically rich languages, such as Turkic languages, where many words can be generated by adding prefixes and suffixes. We compare five tokenizers at different granularity levels, i.e. their outputs vary from smallest pieces of characters to the surface form of words, including a Morphological-level tokenizer. We train these tokenizers and pretrain medium-sized language models using RoBERTa pretraining procedure on the Turkish split of the OSCAR corpus. We then fine-tune our models on six downstream tasks. Our experiments, supported by statistical tests, reveal that Morphological-level tokenizer has challenging performance with de facto tokenizers. Furthermore, we find that increasing the vocabulary size improves the performance of Morphological and Word-level tokenizers more than that of de facto tokenizers. The ratio of the number of vocabulary parameters to the total number of model parameters can be empirically chosen as 20% for de facto tokenizers and 40% for other tokenizers to obtain a reasonable trade-off between model size and performance. ","[{'version': 'v1', 'created': 'Tue, 19 Apr 2022 12:01:46 GMT'}]",2023-03-28,"[['Toraman', 'Cagri', ''], ['Yilmaz', 'Eyup Halit', ''], ['Şahinuç', 'Furkan', ''], ['Ozcelik', 'Oguzhan', '']]",0,1,2022-04-19,1,4,1,0,0,0,0de580957d23dd65e31b6c95e6bc5d15bc15c57d,248240018.0,https://www.semanticscholar.org/paper/0de580957d23dd65e31b6c95e6bc5d15bc15c57d,ACM Trans. Asian Low Resour. Lang. Inf. Process.,2022.0,68.0,19.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2648640', 'name': 'Cagri Toraman'}, {'authorId': '1830448719', 'name': 'E. Yilmaz'}, {'authorId': '107973475', 'name': 'Furkan Şahinuç'}, {'authorId': '2162838582', 'name': 'Oguzhan Ozcelik'}]","['Aselsan Research Center, Turkey', 'Aselsan Research Center, Ankara, Turkey']",['Turkey'],2022-04
2204.09391,Richard Plant,"Richard Plant, Valerio Giuffrida, Dimitra Gkatzia",You Are What You Write: Preserving Privacy in the Era of Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Large scale adoption of large language models has introduced a new era of convenient knowledge transfer for a slew of natural language processing tasks. However, these models also run the risk of undermining user trust by exposing unwanted information about the data subjects, which may be extracted by a malicious party, e.g. through adversarial attacks. We present an empirical investigation into the extent of the personal information encoded into pre-trained representations by a range of popular models, and we show a positive correlation between the complexity of a model, the amount of data used in pre-training, and data leakage. In this paper, we present the first wide coverage evaluation and comparison of some of the most popular privacy-preserving algorithms, on a large, multi-lingual dataset on sentiment analysis annotated with demographic information (location, age and gender). The results show since larger and more complex models are more prone to leaking private information, use of privacy-preserving methods is highly desirable. We also find that highly privacy-preserving technologies like differential privacy (DP) can have serious model utility effects, which can be ameliorated using hybrid or metric-DP techniques. ","[{'version': 'v1', 'created': 'Wed, 20 Apr 2022 11:12:53 GMT'}]",2022-04-21,"[['Plant', 'Richard', ''], ['Giuffrida', 'Valerio', ''], ['Gkatzia', 'Dimitra', '']]",0,0,2022-04-20,1,3,1,0,0,0,597cad6c7b9de94eecc153c7cdcaf824905fe915,248266789.0,https://www.semanticscholar.org/paper/597cad6c7b9de94eecc153c7cdcaf824905fe915,arXiv.org,2022.0,139.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3516073', 'name': 'Richard Plant'}, {'authorId': '144076162', 'name': 'V. Giuffrida'}, {'authorId': '2921637', 'name': 'Dimitra Gkatzia'}]",['Edinburgh Napier University'],['United Kingdom'],2022-04
2204.09658,Qihao Zhu,Qihao Zhu and Jianxi Luo,Generative Design Ideation: A Natural Language Generation Approach,"Accepted by the Tenth International Conference on Design Computing
  and Cognition (DCC'22)",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper aims to explore a generative approach for knowledge-based design ideation by applying the latest pre-trained language models in artificial intelligence (AI). Specifically, a method of fine-tuning the generative pre-trained transformer using the USPTO patent database is proposed. The AI-generated ideas are not only in concise and understandable language but also able to synthesize the target design with external knowledge sources with controllable knowledge distance. The method is tested in a case study of rolling toy design and the results show good performance in generating ideas of varied novelty with near-field and far-field source knowledge. ","[{'version': 'v1', 'created': 'Mon, 28 Mar 2022 08:11:29 GMT'}]",2022-04-21,"[['Zhu', 'Qihao', ''], ['Luo', 'Jianxi', '']]",0,1,2022-03-28,1,2,2,0,0,0,ea351b39403f95c44417f8373f991d6bfce6452e,248266902.0,https://www.semanticscholar.org/paper/ea351b39403f95c44417f8373f991d6bfce6452e,arXiv.org,2022.0,15.0,10.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152203384', 'name': 'Qihao Zhu'}, {'authorId': '145990580', 'name': 'Jianxi Luo'}]",['University of Technology'],['Russia'],2022-03
2204.10304,"Kerstin H\""otte","Kerstin H\""otte, Taheya Tarannum, Vilhelm Verendel, Lauren Bennett",Exploring Artificial Intelligence as a General Purpose Technology with Patent Data -- A Systematic Comparison of Four Classification Approaches,,,,,econ.GN q-fin.EC,http://creativecommons.org/licenses/by/4.0/,"  Artificial Intelligence (AI) is often defined as the next general purpose technology (GPT) with profound economic and societal consequences. We examine how strongly four patent AI classification methods reproduce the GPT-like features of (1) intrinsic growth, (2) generality, and (3) innovation complementarities. Studying US patents from 1990-2019, we find that the four methods (keywords, scientific citations, WIPO, and USPTO approach) vary in classifying between 3-17% of all patents as AI. The keyword-based approach demonstrates the strongest intrinsic growth and generality despite identifying the smallest set of AI patents. The WIPO and science approaches generate each GPT characteristic less strikingly, whilst the USPTO set with the largest number of patents produces the weakest features. The lack of overlap and heterogeneity between all four approaches emphasises that the evaluation of AI innovation policies may be sensitive to the choice of classification method. ","[{'version': 'v1', 'created': 'Thu, 21 Apr 2022 17:39:25 GMT'}]",2022-04-22,"[['Hötte', 'Kerstin', ''], ['Tarannum', 'Taheya', ''], ['Verendel', 'Vilhelm', ''], ['Bennett', 'Lauren', '']]",0,1,2022-04-21,1,4,2,0,0,0,f63116be531ac88a71e7118c7c7c1069d4080f43,248300209.0,https://www.semanticscholar.org/paper/f63116be531ac88a71e7118c7c7c1069d4080f43,,2022.0,27.0,2.0,0.0,False,['Economics'],"[{'category': 'Economics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2052095666', 'name': 'Kerstin Hotte'}, {'authorId': '2163094768', 'name': 'Taheya Tarannum'}, {'authorId': '2138431', 'name': 'V. Verendel'}, {'authorId': '1580317801', 'name': 'L. Bennett'}]","['Chalmers University of Technology', 'University College London', 'University of Oxford', 'Bielefeld University']","['Germany', 'United Kingdom', 'Sweden']",2022-04
2204.12793,Debayan Banerjee,"Debayan Banerjee, Pranav Ajit Nair, Jivat Neet Kaur, Ricardo Usbeck,
  Chris Biemann",Modern Baselines for SPARQL Semantic Parsing,"5 pages, short paper, SIGIR 2022",,10.1145/3477495.3531841,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this work, we focus on the task of generating SPARQL queries from natural language questions, which can then be executed on Knowledge Graphs (KGs). We assume that gold entity and relations have been provided, and the remaining task is to arrange them in the right order along with SPARQL vocabulary, and input tokens to produce the correct SPARQL query. Pre-trained Language Models (PLMs) have not been explored in depth on this task so far, so we experiment with BART, T5 and PGNs (Pointer Generator Networks) with BERT embeddings, looking for new baselines in the PLM era for this task, on DBpedia and Wikidata KGs. We show that T5 requires special input tokenisation, but produces state of the art performance on LC-QuAD 1.0 and LC-QuAD 2.0 datasets, and outperforms task-specific models from previous works. Moreover, the methods enable semantic parsing for questions where a part of the input needs to be copied to the output query, thus enabling a new paradigm in KG semantic parsing. ","[{'version': 'v1', 'created': 'Wed, 27 Apr 2022 09:26:59 GMT'}, {'version': 'v2', 'created': 'Tue, 26 Jul 2022 13:11:49 GMT'}, {'version': 'v3', 'created': 'Thu, 14 Sep 2023 08:50:25 GMT'}]",2023-09-15,"[['Banerjee', 'Debayan', ''], ['Nair', 'Pranav Ajit', ''], ['Kaur', 'Jivat Neet', ''], ['Usbeck', 'Ricardo', ''], ['Biemann', 'Chris', '']]",0,0,2022-04-27,3,5,2,1,1,0,b42501d9f418bf11d1886e617ab125b37fd2d87c,248405891.0,https://www.semanticscholar.org/paper/b42501d9f418bf11d1886e617ab125b37fd2d87c,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2022.0,48.0,14.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35635012', 'name': 'Debayan Banerjee'}, {'authorId': '83623712', 'name': 'Pranav Ajit Nair'}, {'authorId': '2084554148', 'name': 'Jivat Neet Kaur'}, {'authorId': '2370666', 'name': 'Ricardo Usbeck'}, {'authorId': '66911936', 'name': 'Chris Biemann'}]","['Universität Hamburg', 'Microsoft', 'Indian Institute of Technology BHU']","['Germany', 'India']",2022-04
2204.13362,Kexin Yang,"Kexin Yang, Dayiheng Liu, Wenqiang Lei, Baosong Yang, Mingfeng Xue,
  Boxing Chen, Jun Xie",Tailor: A Prompt-Based Approach to Attribute-Based Controlled Text Generation,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Attribute-based Controlled Text Generation (CTG) refers to generating sentences that satisfy desirable attributes (e.g., emotions and topics). Existing works often utilize fine-tuning or resort to extra attribute classifiers, yet suffer from storage and inference time increases. To address these concerns, we explore attribute-based CTG in a prompt-based manner. In short, the proposed Tailor represents each attribute as a pre-trained continuous vector (i.e., single-attribute prompt) and guides the generation of a fixed PLM switch to a pre-specified attribute. We experimentally find that these prompts can be simply concatenated as a whole to multi-attribute CTG without any re-training, yet raises problems of fluency decrease and position sensitivity. To this end, Tailor provides a multi-attribute prompt mask and a re-indexing position-ids sequence to bridge the gap between the training (one prompt for each task) and testing stage (concatenating more than one prompt). To further enhance such single-attribute prompt combinations, Tailor also introduces a trainable prompt connector, which can be concatenated with any two single-attribute prompts to multi-attribute text generation. Experiments on 11 attribute-specific generation tasks demonstrate strong performances of Tailor on both single-attribute and multi-attribute CTG, with 0.08\% training parameters of a GPT-2. ","[{'version': 'v1', 'created': 'Thu, 28 Apr 2022 09:09:45 GMT'}]",2022-04-29,"[['Yang', 'Kexin', ''], ['Liu', 'Dayiheng', ''], ['Lei', 'Wenqiang', ''], ['Yang', 'Baosong', ''], ['Xue', 'Mingfeng', ''], ['Chen', 'Boxing', ''], ['Xie', 'Jun', '']]",0,1,2022-04-28,1,7,1,1,1,0,5035c45c96bc6795ae3c7b875947d1a7e1a1c953,248426828.0,https://www.semanticscholar.org/paper/5035c45c96bc6795ae3c7b875947d1a7e1a1c953,arXiv.org,2022.0,35.0,23.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2004672900', 'name': 'Kexin Yang'}, {'authorId': '2004587660', 'name': 'Dayiheng Liu'}, {'authorId': '39165620', 'name': 'Wenqiang Lei'}, {'authorId': '21299583', 'name': 'Baosong Yang'}, {'authorId': '2065790119', 'name': 'Mingfeng Xue'}, {'authorId': '2152687324', 'name': 'Boxing Chen'}, {'authorId': '2109935759', 'name': 'Jun Xie'}]",['National University of Singapore'],['Singapore'],2022-04
2205.00804,Marvin Zammit,"Marvin Zammit, Antonios Liapis and Georgios N. Yannakakis",Seeding Diversity into AI Art,"10 pages, 4 figures, to be published in the Proceedings of the 13th
  International Conference on Computational Creativity (ICCC 2022)",,,,cs.AI cs.GR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper argues that generative art driven by conformance to a visual and/or semantic corpus lacks the necessary criteria to be considered creative. Among several issues identified in the literature, we focus on the fact that generative adversarial networks (GANs) that create a single image, in a vacuum, lack a concept of novelty regarding how their product differs from previously created ones. We envision that an algorithm that combines the novelty preservation mechanisms in evolutionary algorithms with the power of GANs can deliberately guide its creative process towards output that is both good and novel. In this paper, we use recent advances in image generation based on semantic prompts using OpenAI's CLIP model, interrupting the GAN's iterative process with short cycles of evolutionary divergent search. The results of evolution are then used to continue the GAN's iterative process; we hypothesise that this intervention will lead to more novel outputs. Testing our hypothesis using novelty search with local competition, a quality-diversity evolutionary algorithm that can increase visual diversity while maintaining quality in the form of adherence to the semantic prompt, we explore how different notions of visual diversity can affect both the process and the product of the algorithm. Results show that even a simplistic measure of visual diversity can help counter a drift towards similar images caused by the GAN. This first experiment opens a new direction for introducing higher intentionality and a more nuanced drive for GANs. ","[{'version': 'v1', 'created': 'Mon, 2 May 2022 10:40:52 GMT'}]",2022-05-03,"[['Zammit', 'Marvin', ''], ['Liapis', 'Antonios', ''], ['Yannakakis', 'Georgios N.', '']]",0,0,2022-05-02,1,3,2,0,0,0,388c0caf28845778055045b2967a8214d941beb3,248496329.0,https://www.semanticscholar.org/paper/388c0caf28845778055045b2967a8214d941beb3,International Conference on Innovative Computing and Cloud Computing,2022.0,49.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2114863828', 'name': 'Marvin Zammit'}, {'authorId': '1713331', 'name': 'Antonios Liapis'}, {'authorId': '1686193', 'name': 'Georgios N. Yannakakis'}]",['University of Malta'],['Malta'],2022-05
2205.03666,Tosin Adewumi,"Tosin Adewumi, Foteini Liwicki and Marcus Liwicki",Vector Representations of Idioms in Conversational Systems,"7 pages, 1 figure, 8 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We demonstrate, in this study, that an open-domain conversational system trained on idioms or figurative language generates more fitting responses to prompts containing idioms. Idioms are part of everyday speech in many languages, across many cultures, but they pose a great challenge for many Natural Language Processing (NLP) systems that involve tasks such as Information Retrieval (IR) and Machine Translation (MT), besides conversational AI. We utilize the Potential Idiomatic Expression (PIE)-English idioms corpus for the two tasks that we investigate: classification and conversation generation. We achieve state-of-the-art (SoTA) result of 98% macro F1 score on the classification task by using the SoTA T5 model. We experiment with three instances of the SoTA dialogue model, Dialogue Generative Pre-trained Transformer (DialoGPT), for conversation generation. Their performances are evaluated using the automatic metric perplexity and human evaluation. The results show that the model trained on the idiom corpus generates more fitting responses to prompts containing idioms 71.9% of the time, compared to a similar model not trained on the idioms corpus. We contribute the model checkpoint/demo and code on the HuggingFace hub for public access. ","[{'version': 'v1', 'created': 'Sat, 7 May 2022 14:50:05 GMT'}]",2022-05-10,"[['Adewumi', 'Tosin', ''], ['Liwicki', 'Foteini', ''], ['Liwicki', 'Marcus', '']]",0,1,2022-05-07,1,3,1,1,1,0,ebb9e96d1bdd548322a7ad3cf74ef6c05a05ca32,248572082.0,https://www.semanticscholar.org/paper/ebb9e96d1bdd548322a7ad3cf74ef6c05a05ca32,The Scientist,2022.0,52.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51221489', 'name': 'Tosin P. Adewumi'}, {'authorId': '80342407', 'name': 'F. Liwicki'}, {'authorId': '1743758', 'name': 'M. Liwicki'}]","['ZF Friedrichshafen (Germany)', 'EISLAB,', 'Luleå University of Technology']","['Germany', 'Sweden']",2022-05
2205.04304,Punyajoy Saha,"Punyajoy Saha, Kanishk Singh, Adarsh Kumar, Binny Mathew and Animesh
  Mukherjee","CounterGeDi: A controllable approach to generate polite, detoxified and emotional counterspeech","Accepted at IJCAI-ECAI 2022, 10 pages, 2 figures, 11 tables, Code is
  available at https://github.com/hate-alert/CounterGEDI",,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Recently, many studies have tried to create generation models to assist counter speakers by providing counterspeech suggestions for combating the explosive proliferation of online hate. However, since these suggestions are from a vanilla generation model, they might not include the appropriate properties required to counter a particular hate speech instance. In this paper, we propose CounterGeDi - an ensemble of generative discriminators (GeDi) to guide the generation of a DialoGPT model toward more polite, detoxified, and emotionally laden counterspeech. We generate counterspeech using three datasets and observe significant improvement across different attribute scores. The politeness and detoxification scores increased by around 15% and 6% respectively, while the emotion in the counterspeech increased by at least 10% across all the datasets. We also experiment with triple-attribute control and observe significant improvement over single attribute results when combining complementing attributes, e.g., politeness, joyfulness and detoxification. In all these experiments, the relevancy of the generated text does not deteriorate due to the application of these controls ","[{'version': 'v1', 'created': 'Mon, 9 May 2022 14:10:57 GMT'}]",2022-05-10,"[['Saha', 'Punyajoy', ''], ['Singh', 'Kanishk', ''], ['Kumar', 'Adarsh', ''], ['Mathew', 'Binny', ''], ['Mukherjee', 'Animesh', '']]",0,1,2022-05-09,1,5,2,0,0,0,00c8907d0384f076b8f8baa1af3269a3ab37aa70,248571874.0,https://www.semanticscholar.org/paper/00c8907d0384f076b8f8baa1af3269a3ab37aa70,International Joint Conference on Artificial Intelligence,2022.0,29.0,11.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48480843', 'name': 'Punyajoy Saha'}, {'authorId': '2109143760', 'name': 'Kanishk Singh'}, {'authorId': '2109173331', 'name': 'Adarsh Kumar'}, {'authorId': '2041989412', 'name': 'Binny Mathew'}, {'authorId': '46405816', 'name': 'Animesh Mukherjee'}]",['Indian Institute of Technology Kharagpur'],['India'],2022-05
2205.05535,Niall Taylor,"Niall Taylor, Yi Zhang, Dan Joyce, Alejo Nevado-Holgado, Andrey
  Kormilitzin",Clinical Prompt Learning with Frozen Language Models,"18 pages, 6 figures, 6 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Prompt learning is a new paradigm in the Natural Language Processing (NLP) field which has shown impressive performance on a number of natural language tasks with common benchmarking text datasets in full, few-shot, and zero-shot train-evaluation setups. Recently, it has even been observed that large but frozen pre-trained language models (PLMs) with prompt learning outperform smaller but fine-tuned models. However, as with many recent NLP trends, the performance of even the largest PLMs such as GPT-3 do not perform well on specialized domains (e.g. medical text), and the common practice to achieve State of the Art (SoTA) results still consists of pre-training and fine-tuning the PLMs on downstream tasks. The reliance on fine-tuning large PLMs is problematic in clinical settings where data is often held in non-GPU environments, and more resource efficient methods of training specialized domain models is crucial. We investigated the viability of prompt learning on clinically meaningful decision tasks and directly compared with more traditional fine-tuning methods. Results are partially in line with the prompt learning literature, with prompt learning able to match or improve on traditional fine-tuning with substantially fewer trainable parameters and requiring less training data. We argue that prompt learning therefore provides lower computational resource costs applicable to clinical settings, that can serve as an alternative to fine-tuning ever increasing in size PLMs. Complementary code to reproduce experiments presented in this work can be found at: https://github.com/NtaylorOX/Public_Clinical_Prompt. ","[{'version': 'v1', 'created': 'Wed, 11 May 2022 14:25:13 GMT'}]",2022-05-12,"[['Taylor', 'Niall', ''], ['Zhang', 'Yi', ''], ['Joyce', 'Dan', ''], ['Nevado-Holgado', 'Alejo', ''], ['Kormilitzin', 'Andrey', '']]",0,1,2022-05-11,1,5,1,1,0,1,fa7e728c4c612025b9fb7601af65c4a8f5a2b33e,248693141.0,https://www.semanticscholar.org/paper/fa7e728c4c612025b9fb7601af65c4a8f5a2b33e,arXiv.org,2022.0,47.0,10.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2055570167', 'name': 'Niall Taylor'}, {'authorId': '46867473', 'name': 'Yi Zhang'}, {'authorId': '143836201', 'name': 'D. Joyce'}, {'authorId': '1401685989', 'name': 'A. Nevado-Holgado'}, {'authorId': '3362051', 'name': 'A. Kormilitzin'}]","['University of Oxford', 'NIHR Oxford Musculoskeletal Biomedical Research Centre']",['United Kingdom'],2022-05
2205.05718,Katherine Collins,"Katherine M. Collins, Catherine Wong, Jiahai Feng, Megan Wei, and
  Joshua B. Tenenbaum","Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks",Originally accepted to the 2022 Cognitive Science (CogSci) conference,,,,cs.CL cs.AI cs.LG cs.SC,http://creativecommons.org/licenses/by/4.0/,"  Human language offers a powerful window into our thoughts -- we tell stories, give explanations, and express our beliefs and goals through words. Abundant evidence also suggests that language plays a developmental role in structuring our learning. Here, we ask: how much of human-like thinking can be captured by learning statistical patterns in language alone? We first contribute a new challenge benchmark for comparing humans and distributional large language models (LLMs). Our benchmark contains two problem-solving domains (planning and explanation generation) and is designed to require generalization to new, out-of-distribution problems expressed in language. We find that humans are far more robust than LLMs on this benchmark. Next, we propose a hybrid Parse-and-Solve model, which augments distributional LLMs with a structured symbolic reasoning module. We find that this model shows more robust adaptation to out-of-distribution planning problems, demonstrating the promise of hybrid AI models for more human-like reasoning. ","[{'version': 'v1', 'created': 'Wed, 11 May 2022 18:14:33 GMT'}]",2022-05-13,"[['Collins', 'Katherine M.', ''], ['Wong', 'Catherine', ''], ['Feng', 'Jiahai', ''], ['Wei', 'Megan', ''], ['Tenenbaum', 'Joshua B.', '']]",0,0,2022-05-11,1,5,4,0,0,0,7ef9aafc68511afab5b287e62b754576ea37b4ce,248721753.0,https://www.semanticscholar.org/paper/7ef9aafc68511afab5b287e62b754576ea37b4ce,arXiv.org,2022.0,18.0,22.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46197974', 'name': 'K. M. Collins'}, {'authorId': '2036600432', 'name': 'Catherine Wong'}, {'authorId': '1753394956', 'name': 'Jiahai Feng'}, {'authorId': '2167274620', 'name': 'Megan Wei'}, {'authorId': '1763295', 'name': 'J. Tenenbaum'}]",['University of Cambridge'],['United Kingdom'],2022-05
2205.07043,Afra Amini,"Afra Amini, Tiago Pimentel, Clara Meister, Ryan Cotterell",Naturalistic Causal Probing for Morpho-Syntax,"To appear in TACL 2022 and EMNLP 2022. The arXiv version is a pre-MIT
  Press publication version",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Probing has become a go-to methodology for interpreting and analyzing deep neural models in natural language processing. However, there is still a lack of understanding of the limitations and weaknesses of various types of probes. In this work, we suggest a strategy for input-level intervention on naturalistic sentences. Using our approach, we intervene on the morpho-syntactic features of a sentence, while keeping the rest of the sentence unchanged. Such an intervention allows us to causally probe pre-trained models. We apply our naturalistic causal probing framework to analyze the effects of grammatical gender and number on contextualized representations extracted from three pre-trained models in Spanish: the multilingual versions of BERT, RoBERTa, and GPT-2. Our experiments suggest that naturalistic interventions lead to stable estimates of the causal effects of various linguistic properties. Moreover, our experiments demonstrate the importance of naturalistic causal probing when analyzing pre-trained models. ","[{'version': 'v1', 'created': 'Sat, 14 May 2022 11:47:58 GMT'}, {'version': 'v2', 'created': 'Mon, 14 Nov 2022 11:41:52 GMT'}]",2022-11-15,"[['Amini', 'Afra', ''], ['Pimentel', 'Tiago', ''], ['Meister', 'Clara', ''], ['Cotterell', 'Ryan', '']]",0,1,2022-05-14,2,4,1,1,1,0,aa0c9285bb76c7a4c3f32a5b122f1d5eb171c5d6,248811730.0,https://www.semanticscholar.org/paper/aa0c9285bb76c7a4c3f32a5b122f1d5eb171c5d6,Transactions of the Association for Computational Linguistics,2022.0,55.0,7.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1820796225', 'name': 'Afra Amini'}, {'authorId': '1388571351', 'name': 'Tiago Pimentel'}, {'authorId': '150953620', 'name': 'Clara Meister'}, {'authorId': '2070989574', 'name': 'Ryan Cotterell'}]","['University of Cambridge', 'Qu & Co. (Netherlands)']","['Netherlands', 'United Kingdom']",2022-05
2205.07592,Nicola Milano,Nicola Milano and Stefano Nolfi,Qualitative Differences Between Evolutionary Strategies and Reinforcement Learning Methods for Control of Autonomous Agents,,,,,cs.AI cs.LG cs.NE,http://creativecommons.org/licenses/by/4.0/,"  In this paper we analyze the qualitative differences between evolutionary strategies and reinforcement learning algorithms by focusing on two popular state-of-the-art algorithms: the OpenAI-ES evolutionary strategy and the Proximal Policy Optimization (PPO) reinforcement learning algorithm -- the most similar methods of the two families. We analyze how the methods differ with respect to: (i) general efficacy, (ii) ability to cope with sparse rewards, (iii) propensity/capacity to discover minimal solutions, (iv) dependency on reward shaping, and (v) ability to cope with variations of the environmental conditions. The analysis of the performance and of the behavioral strategies displayed by the agents trained with the two methods on benchmark problems enable us to demonstrate qualitative differences which were not identified in previous studies, to identify the relative weakness of the two methods, and to propose ways to ameliorate some of those weakness. We show that the characteristics of the reward function has a strong impact which vary qualitatively not only for the OpenAI-ES and the PPO but also for alternative reinforcement learning algorithms, thus demonstrating the importance of optimizing the characteristic of the reward function to the algorithm used. ","[{'version': 'v1', 'created': 'Mon, 16 May 2022 11:51:36 GMT'}]",2022-05-17,"[['Milano', 'Nicola', ''], ['Nolfi', 'Stefano', '']]",0,0,2022-05-16,1,2,3,0,0,0,068fe983f0e2c8f0430d05c6130ea270336a8ad4,248811016.0,https://www.semanticscholar.org/paper/068fe983f0e2c8f0430d05c6130ea270336a8ad4,Evolutionary Intelligence,2022.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32302973', 'name': 'Nicola Milano'}, {'authorId': '3015062', 'name': 'S. Nolfi'}]",['National Research Council'],['Italy'],2022-05
2205.08184,Zhe Dong,"Fedor Moiseev, Zhe Dong, Enrique Alfonseca, Martin Jaggi",SKILL: Structured Knowledge Infusion for Large Language Models,NAACL 2022,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated human-level performance on a vast spectrum of natural language tasks. However, it is largely unexplored whether they can better internalize knowledge from a structured data, such as a knowledge graph, or from text. In this work, we propose a method to infuse structured knowledge into LLMs, by directly training T5 models on factual triples of knowledge graphs (KGs). We show that models pre-trained on Wikidata KG with our method outperform the T5 baselines on FreebaseQA and WikiHop, as well as the Wikidata-answerable subset of TriviaQA and NaturalQuestions. The models pre-trained on factual triples compare competitively with the ones on natural language sentences that contain the same knowledge. Trained on a smaller size KG, WikiMovies, we saw 3x improvement of exact match score on MetaQA task compared to T5 baseline. The proposed method has an advantage that no alignment between the knowledge graph and text corpus is required in curating training data. This makes our method particularly useful when working with industry-scale knowledge graphs. ","[{'version': 'v1', 'created': 'Tue, 17 May 2022 09:12:22 GMT'}]",2022-05-18,"[['Moiseev', 'Fedor', ''], ['Dong', 'Zhe', ''], ['Alfonseca', 'Enrique', ''], ['Jaggi', 'Martin', '']]",0,0,2022-05-17,1,4,3,1,1,0,eea2129457fcd78c4071a9020355a2fe1da4d2fd,248834551.0,https://www.semanticscholar.org/paper/eea2129457fcd78c4071a9020355a2fe1da4d2fd,North American Chapter of the Association for Computational Linguistics,2022.0,34.0,28.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2165469946', 'name': 'Fedor Moiseev'}, {'authorId': '2114027880', 'name': 'Zhe Dong'}, {'authorId': '1727837', 'name': 'Enrique Alfonseca'}, {'authorId': '2456863', 'name': 'Martin Jaggi'}]","['Google', 'École Polytechnique Fédérale de Lausanne']",['Switzerland'],2022-05
2205.08343,Arthur Barbosa C\^amara,"Arthur C\^amara, Claudia Hauff",Moving Stuff Around: A study on efficiency of moving documents into memory for Neural IR models,"7 pages, 2 figures. Accepted to the ReNeuIR workshop at SIGIR 2022",,,,cs.IR,http://creativecommons.org/licenses/by/4.0/,"  When training neural rankers using Large Language Models, it's expected that a practitioner would make use of multiple GPUs to accelerate the training time. By using more devices, deep learning frameworks, like PyTorch, allow the user to drastically increase the available VRAM pool, making larger batches possible when training, therefore shrinking training time. At the same time, one of the most critical processes, that is generally overlooked when running data-hungry models, is how data is managed between disk, main memory and VRAM. Most open source research implementations overlook this memory hierarchy, and instead resort to loading all documents from disk to main memory and then allowing the framework (e.g., PyTorch) to handle moving data into VRAM. Therefore, with the increasing sizes of datasets dedicated to IR research, a natural question arises: s this the optimal solution for optimizing training time? We here study how three different popular approaches to handling documents for IR datasets behave and how they scale with multiple GPUs. Namely, loading documents directly into memory, reading documents directly from text files with a lookup table and using a library for handling IR datasets (ir_datasets) differ, both in performance (i.e. samples processed per second) and memory footprint. We show that, when using the most popular libraries for neural ranker research (i.e. PyTorch and Hugging Face's Transformers), the practice of loading all documents into main memory is not always the fastest option and is not feasible for setups with more than a couple GPUs. Meanwhile, a good implementation of data streaming from disk can be faster, while being considerably more scalable. We also show how popular techniques for improving loading times, like memory pining, multiple workers, and RAMDISK usage, can reduce the training time further with minor memory overhead. ","[{'version': 'v1', 'created': 'Tue, 17 May 2022 13:40:18 GMT'}, {'version': 'v2', 'created': 'Thu, 23 Jun 2022 12:19:29 GMT'}]",2022-06-24,"[['Câmara', 'Arthur', ''], ['Hauff', 'Claudia', '']]",0,0,2022-05-17,2,2,1,0,0,0,2e08d5b54de491960a4bdc854a39ca1e6086c6d9,248834503.0,https://www.semanticscholar.org/paper/2e08d5b54de491960a4bdc854a39ca1e6086c6d9,arXiv.org,2022.0,28.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '133572799', 'name': 'A. Câmara'}, {'authorId': '2731925', 'name': 'C. Hauff'}]",['Delft University of Technology'],['Netherlands'],2022-05
2205.08808,Piotr Rybak,"Aleksandra Chrabrowa, {\L}ukasz Dragan, Karol Grzegorczyk, Dariusz
  Kajtoch, Miko{\l}aj Koszowski, Robert Mroczkowski, Piotr Rybak",Evaluation of Transfer Learning for Polish with a Text-to-Text Model,Accepted at LREC 2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a new benchmark for assessing the quality of text-to-text models for Polish. The benchmark consists of diverse tasks and datasets: KLEJ benchmark adapted for text-to-text, en-pl translation, summarization, and question answering. In particular, since summarization and question answering lack benchmark datasets for the Polish language, we describe their construction and make them publicly available. Additionally, we present plT5 - a general-purpose text-to-text model for Polish that can be fine-tuned on various Natural Language Processing (NLP) tasks with a single training objective. Unsupervised denoising pre-training is performed efficiently by initializing the model weights with a multi-lingual T5 (mT5) counterpart. We evaluate the performance of plT5, mT5, Polish BART (plBART), and Polish GPT-2 (papuGaPT2). The plT5 scores top on all of these tasks except summarization, where plBART is best. In general (except for summarization), the larger the model, the better the results. The encoder-decoder architectures prove to be better than the decoder-only equivalent. ","[{'version': 'v1', 'created': 'Wed, 18 May 2022 09:17:14 GMT'}]",2022-05-19,"[['Chrabrowa', 'Aleksandra', ''], ['Dragan', 'Łukasz', ''], ['Grzegorczyk', 'Karol', ''], ['Kajtoch', 'Dariusz', ''], ['Koszowski', 'Mikołaj', ''], ['Mroczkowski', 'Robert', ''], ['Rybak', 'Piotr', '']]",0,1,2022-05-18,1,7,2,3,3,0,267dcb61f72f48dadd60a3a770493c0c9f70be65,248863247.0,https://www.semanticscholar.org/paper/267dcb61f72f48dadd60a3a770493c0c9f70be65,International Conference on Language Resources and Evaluation,2022.0,45.0,11.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8769976', 'name': 'Aleksandra Chrabrowa'}, {'authorId': '2165569779', 'name': 'Lukasz Dragan'}, {'authorId': '2473173', 'name': 'Karol Grzegorczyk'}, {'authorId': '102712558', 'name': 'D. Kajtoch'}, {'authorId': '2040902194', 'name': 'Mikołaj Koszowski'}, {'authorId': '1667962595', 'name': 'Robert Mroczkowski'}, {'authorId': '52078780', 'name': 'Piotr Rybak'}]","['Allegro ML Research at Allegro.pl, ul. Grunwaldzka 182, 60-166 Poznań, Poland']",['Poland'],2022-05
2205.10712,Yash Kant,"Yash Kant, Arun Ramachandran, Sriram Yenamandra, Igor Gilitschenski,
  Dhruv Batra, Andrew Szot, Harsh Agrawal",Housekeep: Tidying Virtual Households using Commonsense Reasoning,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  We introduce Housekeep, a benchmark to evaluate commonsense reasoning in the home for embodied AI. In Housekeep, an embodied agent must tidy a house by rearranging misplaced objects without explicit instructions specifying which objects need to be rearranged. Instead, the agent must learn from and is evaluated against human preferences of which objects belong where in a tidy house. Specifically, we collect a dataset of where humans typically place objects in tidy and untidy houses constituting 1799 objects, 268 object categories, 585 placements, and 105 rooms. Next, we propose a modular baseline approach for Housekeep that integrates planning, exploration, and navigation. It leverages a fine-tuned large language model (LLM) trained on an internet text corpus for effective planning. We show that our baseline agent generalizes to rearranging unseen objects in unknown environments. See our webpage for more details: https://yashkant.github.io/housekeep/ ","[{'version': 'v1', 'created': 'Sun, 22 May 2022 02:37:09 GMT'}]",2022-05-24,"[['Kant', 'Yash', ''], ['Ramachandran', 'Arun', ''], ['Yenamandra', 'Sriram', ''], ['Gilitschenski', 'Igor', ''], ['Batra', 'Dhruv', ''], ['Szot', 'Andrew', ''], ['Agrawal', 'Harsh', '']]",0,0,2022-05-22,1,7,1,0,0,0,7890ece03cfb88e0620f8e791105569bd7128c76,248986485.0,https://www.semanticscholar.org/paper/7890ece03cfb88e0620f8e791105569bd7128c76,European Conference on Computer Vision,2022.0,86.0,32.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66536530', 'name': 'Yash Kant'}, {'authorId': '2064356726', 'name': 'Arun Ramachandran'}, {'authorId': '2088846095', 'name': 'Sriram Yenamandra'}, {'authorId': '2072248', 'name': 'Igor Gilitschenski'}, {'authorId': '1746610', 'name': 'Dhruv Batra'}, {'authorId': '1580188581', 'name': 'Andrew Szot'}, {'authorId': '37825612', 'name': 'Harsh Agrawal'}]",['University of Toronto'],['Canada'],2022-05
2205.11374,Conrad Borchers,"Conrad Borchers, Dalia Sara Gala, Benjamin Gilburt, Eduard Oravkin,
  Wilfried Bounsi, Yuki M. Asano, Hannah Rose Kirk",Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,"Accepted for the 4th Workshop on Gender Bias in Natural Language
  Processing at NAACL 2022",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The growing capability and availability of generative language models has enabled a wide range of new downstream tasks. Academic research has identified, quantified and mitigated biases present in language models but is rarely tailored to downstream tasks where wider impact on individuals and society can be felt. In this work, we leverage one popular generative language model, GPT-3, with the goal of writing unbiased and realistic job advertisements. We first assess the bias and realism of zero-shot generated advertisements and compare them to real-world advertisements. We then evaluate prompt-engineering and fine-tuning as debiasing methods. We find that prompt-engineering with diversity-encouraging prompts gives no significant improvement to bias, nor realism. Conversely, fine-tuning, especially on unbiased real advertisements, can improve realism and reduce bias. ","[{'version': 'v1', 'created': 'Mon, 23 May 2022 15:05:27 GMT'}]",2022-05-24,"[['Borchers', 'Conrad', ''], ['Gala', 'Dalia Sara', ''], ['Gilburt', 'Benjamin', ''], ['Oravkin', 'Eduard', ''], ['Bounsi', 'Wilfried', ''], ['Asano', 'Yuki M.', ''], ['Kirk', 'Hannah Rose', '']]",0,1,2022-05-23,1,7,2,1,0,1,8c90bfe05c06fd47eaec0f5b1662e06862572afe,248986638.0,https://www.semanticscholar.org/paper/8c90bfe05c06fd47eaec0f5b1662e06862572afe,GEBNLP,2022.0,45.0,11.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '83716891', 'name': 'Conrad Borchers'}, {'authorId': '2166052031', 'name': 'Dalia Sara Gala'}, {'authorId': '2122554538', 'name': 'Ben Gilburt'}, {'authorId': '2133448409', 'name': 'Eduard Oravkin'}, {'authorId': '2166053122', 'name': 'Wilfried Bounsi'}, {'authorId': '47792365', 'name': 'Yuki M. Asano'}, {'authorId': '90729626', 'name': 'Hannah Rose Kirk'}]",['University of Oxford'],['United Kingdom'],2022-05
2205.12428,Ivan Kobyzev,"Ivan Kobyzev, Aref Jafari, Mehdi Rezagholizadeh, Tianda Li, Alan
  Do-Omri, Peng Lu, Pascal Poupart, Ali Ghodsi",Do we need Label Regularization to Fine-tune Pre-trained Language Models?,Published at EACL 2023,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Knowledge Distillation (KD) is a prominent neural model compression technique that heavily relies on teacher network predictions to guide the training of a student model. Considering the ever-growing size of pre-trained language models (PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is evident that in KD, deploying the teacher network during training adds to the memory and computational requirements of training. In the computer vision literature, the necessity of the teacher network is put under scrutiny by showing that KD is a label regularization technique that can be replaced with lighter teacher-free variants such as the label-smoothing technique. However, to the best of our knowledge, this issue is not investigated in NLP. Therefore, this work concerns studying different label regularization techniques and whether we actually need them to improve the fine-tuning of smaller PLM networks on downstream tasks. In this regard, we did a comprehensive set of experiments on different PLMs such as BERT, RoBERTa, and GPT with more than 600 distinct trials and ran each configuration five times. This investigation led to a surprising observation that KD and other label regularization techniques do not play any meaningful role over regular fine-tuning when the student model is pre-trained. We further explore this phenomenon in different settings of NLP and computer vision tasks and demonstrate that pre-training itself acts as a kind of regularization, and additional label regularization is unnecessary. ","[{'version': 'v1', 'created': 'Wed, 25 May 2022 01:26:31 GMT'}, {'version': 'v2', 'created': 'Wed, 12 Apr 2023 15:34:03 GMT'}]",2023-04-13,"[['Kobyzev', 'Ivan', ''], ['Jafari', 'Aref', ''], ['Rezagholizadeh', 'Mehdi', ''], ['Li', 'Tianda', ''], ['Do-Omri', 'Alan', ''], ['Lu', 'Peng', ''], ['Poupart', 'Pascal', ''], ['Ghodsi', 'Ali', '']]",0,1,2022-05-25,2,8,2,0,0,0,6b66ea79bc382ec5dd695ccb0b437bf38e3de556,258079331.0,https://www.semanticscholar.org/paper/6b66ea79bc382ec5dd695ccb0b437bf38e3de556,Conference of the European Chapter of the Association for Computational Linguistics,2022.0,44.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66895761', 'name': 'I. Kobyzev'}, {'authorId': '31036999', 'name': 'A. Jafari'}, {'authorId': '2066076226', 'name': 'Mehdi Rezagholizadeh'}, {'authorId': '6574899', 'name': 'Tianda Li'}, {'authorId': '1403206217', 'name': 'Alan Do-Omri'}, {'authorId': '144313479', 'name': 'Peng Lu'}, {'authorId': '1807041', 'name': 'P. Poupart'}, {'authorId': '38565890', 'name': 'A. Ghodsi'}]","['Université de Montréal', 'University of Waterloo']",['Canada'],2022-05
2205.14334,Stephanie Lin,"Stephanie Lin, Jacob Hilton, Owain Evans",Teaching Models to Express Their Uncertainty in Words,"CalibratedMath tasks and evaluation code are available at
  https://github.com/sylinrl/CalibratedMath",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We show that a GPT-3 model can learn to express uncertainty about its own answers in natural language -- without use of model logits. When given a question, the model generates both an answer and a level of confidence (e.g. ""90% confidence"" or ""high confidence""). These levels map to probabilities that are well calibrated. The model also remains moderately calibrated under distribution shift, and is sensitive to uncertainty in its own answers, rather than imitating human examples. To our knowledge, this is the first time a model has been shown to express calibrated uncertainty about its own answers in natural language. For testing calibration, we introduce the CalibratedMath suite of tasks. We compare the calibration of uncertainty expressed in words (""verbalized probability"") to uncertainty extracted from model logits. Both kinds of uncertainty are capable of generalizing calibration under distribution shift. We also provide evidence that GPT-3's ability to generalize calibration depends on pre-trained latent representations that correlate with epistemic uncertainty over its answers. ","[{'version': 'v1', 'created': 'Sat, 28 May 2022 05:02:31 GMT'}, {'version': 'v2', 'created': 'Mon, 13 Jun 2022 05:04:53 GMT'}]",2022-06-14,"[['Lin', 'Stephanie', ''], ['Hilton', 'Jacob', ''], ['Evans', 'Owain', '']]",0,1,2022-05-28,2,3,3,1,0,1,374dd173491a59a10bbb2b3519ebcfe3649f529d,249191391.0,https://www.semanticscholar.org/paper/374dd173491a59a10bbb2b3519ebcfe3649f529d,Trans. Mach. Learn. Res.,2022.0,36.0,88.0,13.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48639938', 'name': 'Stephanie C. Lin'}, {'authorId': '2052366271', 'name': 'Jacob Hilton'}, {'authorId': '47107786', 'name': 'Owain Evans'}]",['University of Oxford'],['United Kingdom'],2022-05
2205.15172,Guilherme Moraes Rosa,"Guilherme Moraes Rosa and Luiz Bonifacio and Vitor Jeronymo and Hugo
  Abonizio and Roberto Lotufo and Rodrigo Nogueira",Billions of Parameters Are Worth More Than In-domain Training Data: A case study in the Legal Case Entailment Task,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work has shown that language models scaled to billions of parameters, such as GPT-3, perform remarkably well in zero-shot and few-shot scenarios. In this work, we experiment with zero-shot models in the legal case entailment task of the COLIEE 2022 competition. Our experiments show that scaling the number of parameters in a language model improves the F1 score of our previous zero-shot result by more than 6 points, suggesting that stronger zero-shot capability may be a characteristic of larger models, at least for this task. Our 3B-parameter zero-shot model outperforms all models, including ensembles, in the COLIEE 2021 test set and also achieves the best performance of a single model in the COLIEE 2022 competition, second only to the ensemble composed of the 3B model itself and a smaller version of the same model. Despite the challenges posed by large language models, mainly due to latency constraints in real-time applications, we provide a demonstration of our zero-shot monoT5-3b model being used in production as a search engine, including for legal documents. The code for our submission and the demo of our system are available at https://github.com/neuralmind-ai/coliee and https://neuralsearchx.neuralmind.ai, respectively. ","[{'version': 'v1', 'created': 'Mon, 30 May 2022 15:21:26 GMT'}]",2022-05-31,"[['Rosa', 'Guilherme Moraes', ''], ['Bonifacio', 'Luiz', ''], ['Jeronymo', 'Vitor', ''], ['Abonizio', 'Hugo', ''], ['Lotufo', 'Roberto', ''], ['Nogueira', 'Rodrigo', '']]",0,1,2022-05-30,1,6,1,1,0,1,1791972b162aea075dbd07a8b5ba8760d9264f02,249192384.0,https://www.semanticscholar.org/paper/1791972b162aea075dbd07a8b5ba8760d9264f02,arXiv.org,2022.0,34.0,8.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2091578175', 'name': 'G. Rosa'}, {'authorId': '2003019597', 'name': 'L. Bonifacio'}, {'authorId': '2167031295', 'name': 'Vitor Jeronymo'}, {'authorId': '1394470211', 'name': 'Hugo Abonizio'}, {'authorId': '1809633', 'name': 'R. Lotufo'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}]",['Universidade Estadual de Campinas (UNICAMP)'],['Brazil'],2022-05
2205.15952,Ankush Agarwal,"Ankush Agarwal, Raj Gite, Shreya Laddha, Pushpak Bhattacharyya,
  Satyanarayan Kar, Asif Ekbal, Prabhjit Thind, Rajesh Zele, Ravi Shankar",Knowledge Graph - Deep Learning: A Case Study in Question Answering in Aviation Safety Domain,LREC 2022 Main Conference Accepted Paper,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the commercial aviation domain, there are a large number of documents, like, accident reports (NTSB, ASRS) and regulatory directives (ADs). There is a need for a system to access these diverse repositories efficiently in order to service needs in the aviation industry, like maintenance, compliance, and safety. In this paper, we propose a Knowledge Graph (KG) guided Deep Learning (DL) based Question Answering (QA) system for aviation safety. We construct a Knowledge Graph from Aircraft Accident reports and contribute this resource to the community of researchers. The efficacy of this resource is tested and proved by the aforesaid QA system. Natural Language Queries constructed from the documents mentioned above are converted into SPARQL (the interface language of the RDF graph database) queries and answered. On the DL side, we have two different QA models: (i) BERT QA which is a pipeline of Passage Retrieval (Sentence-BERT based) and Question Answering (BERT based), and (ii) the recently released GPT-3. We evaluate our system on a set of queries created from the accident reports. Our combined QA system achieves 9.3% increase in accuracy over GPT-3 and 40.3% increase over BERT QA. Thus, we infer that KG-DL performs better than either singly. ","[{'version': 'v1', 'created': 'Tue, 31 May 2022 16:49:55 GMT'}, {'version': 'v2', 'created': 'Thu, 9 Jun 2022 18:50:18 GMT'}]",2022-06-13,"[['Agarwal', 'Ankush', ''], ['Gite', 'Raj', ''], ['Laddha', 'Shreya', ''], ['Bhattacharyya', 'Pushpak', ''], ['Kar', 'Satyanarayan', ''], ['Ekbal', 'Asif', ''], ['Thind', 'Prabhjit', ''], ['Zele', 'Rajesh', ''], ['Shankar', 'Ravi', '']]",0,1,2022-05-31,2,9,3,1,0,1,f1317cf72032fc0317834e1d1ea1bc0e3816c5a3,248970443.0,https://www.semanticscholar.org/paper/f1317cf72032fc0317834e1d1ea1bc0e3816c5a3,International Conference on Language Resources and Evaluation,2022.0,29.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2078528933', 'name': 'Ankush Agarwal'}, {'authorId': '8002929', 'name': 'Raju Gite'}, {'authorId': '89009445', 'name': 'Shreyash Laddha'}, {'authorId': '145532184', 'name': 'P. Bhattacharyya'}, {'authorId': '101955643', 'name': 'Satyanarayan Kar'}, {'authorId': '1734904', 'name': 'Asif Ekbal'}, {'authorId': '115137984', 'name': 'Prabhjit Thind'}, {'authorId': '3291756', 'name': 'Rajesh Zele'}, {'authorId': '2176941995', 'name': 'Ravi Shankar'}]","['Indian Institute of Technology Patna', 'Indian Institute of Technology Bombay']",['India'],2022-05
2206.01335,Patrick Barei{\ss},"Patrick Barei{\ss}, Beatriz Souza, Marcelo d'Amorim, Michael Pradel","Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code","12 pages, 5 figures",,,,cs.SE cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Few-shot learning with large-scale, pre-trained language models is a powerful way to answer questions about code, e.g., how to complete a given code example, or even generate code snippets from scratch. The success of these models raises the question whether they could serve as a basis for building a wide range code generation tools. Traditionally, such tools are built manually and separately for each task. Instead, few-shot learning may allow to obtain different tools from a single pre-trained language model by simply providing a few examples or a natural language description of the expected tool behavior. This paper studies to what extent a state-of-the-art, pre-trained language model of code, Codex, may serve this purpose. We consider three code manipulation and code generation tasks targeted by a range of traditional tools: (i) code mutation; (ii) test oracle generation from natural language documentation; and (iii) test case generation. For each task, we compare few-shot learning to a manually built tool. Our results show that the model-based tools complement (code mutation), are on par (test oracle generation), or even outperform their respective traditionally built tool (test case generation), while imposing far less effort to develop them. By comparing the effectiveness of different variants of the model-based tools, we provide insights on how to design an appropriate input (""prompt"") to the model and what influence the size of the model has. For example, we find that providing a small natural language description of the code generation task is an easy way to improve predictions. Overall, we conclude that few-shot language models are surprisingly effective, yet there is still more work to be done, such as exploring more diverse ways of prompting and tackling even more involved tasks. ","[{'version': 'v1', 'created': 'Thu, 2 Jun 2022 23:15:42 GMT'}, {'version': 'v2', 'created': 'Sun, 12 Jun 2022 09:57:45 GMT'}]",2022-06-14,"[['Bareiß', 'Patrick', ''], ['Souza', 'Beatriz', ''], [""d'Amorim"", 'Marcelo', ''], ['Pradel', 'Michael', '']]",0,0,2022-06-02,2,4,2,1,0,1,7ffb212356df9980347b3d3b9910dfba75a5d0c7,249375385.0,https://www.semanticscholar.org/paper/7ffb212356df9980347b3d3b9910dfba75a5d0c7,arXiv.org,2022.0,59.0,35.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35600106', 'name': 'Patrick Bareiss'}, {'authorId': '118267297', 'name': 'Beatriz Souza'}, {'authorId': '1403835151', 'name': 'Marcelo d’Amorim'}, {'authorId': '1884064', 'name': 'Michael Pradel'}]","['University of Stuttgart', 'Universidade Federal de Pernambuco']","['Germany', 'Brazil']",2022-06
2206.01512,Yao Fu,Yao Fu and Mirella Lapata,Latent Topology Induction for Understanding Contextualized Representations,Preprint,,,,cs.CL cs.AI cs.LG cs.NE,http://creativecommons.org/licenses/by/4.0/,"  In this work, we study the representation space of contextualized embeddings and gain insight into the hidden topology of large language models. We show there exists a network of latent states that summarize linguistic properties of contextualized representations. Instead of seeking alignments to existing well-defined annotations, we infer this latent network in a fully unsupervised way using a structured variational autoencoder. The induced states not only serve as anchors that mark the topology (neighbors and connectivity) of the representation manifold but also reveal the internal mechanism of encoding sentences. With the induced network, we: (1). decompose the representation space into a spectrum of latent states which encode fine-grained word meanings with lexical, morphological, syntactic and semantic information; (2). show state-state transitions encode rich phrase constructions and serve as the backbones of the latent space. Putting the two together, we show that sentences are represented as a traversal over the latent network where state-state transition chains encode syntactic templates and state-word emissions fill in the content. We demonstrate these insights with extensive experiments and visualizations. ","[{'version': 'v1', 'created': 'Fri, 3 Jun 2022 11:22:48 GMT'}]",2022-06-06,"[['Fu', 'Yao', ''], ['Lapata', 'Mirella', '']]",0,0,2022-06-03,1,2,4,0,0,0,16a5dbdab3d1efe90a74678a665a6ed7f8c68c7f,249375270.0,https://www.semanticscholar.org/paper/16a5dbdab3d1efe90a74678a665a6ed7f8c68c7f,arXiv.org,2022.0,48.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2117786875', 'name': 'Yao Fu'}, {'authorId': '1747893', 'name': 'Mirella Lapata'}]",['University of Edinburgh'],['United Kingdom'],2022-06
2206.01749,Valentin Arkov,Valentin Arkov,Uncertainty Estimation in Machine Learning,"5 pages, 6 figures",,,,cs.LG cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Most machine learning techniques are based upon statistical learning theory, often simplified for the sake of computing speed. This paper is focused on the uncertainty aspect of mathematical modeling in machine learning. Regression analysis is chosen to further investigate the evaluation aspect of uncertainty in model coefficients and, more importantly, in the output feature value predictions. A survey demonstrates major stages in the conventional least squares approach to the creation of the regression model, along with its uncertainty estimation. On the other hand, it is shown that in machine learning the model complexity and severe nonlinearity become serious obstacles to uncertainty evaluation. Furthermore, the process of machine model training demands high computing power, not available at the level of personal computers. This is why so-called pre-trained models are widely used in such areas of machine learning as natural language processing. The latest example of a pre-trained model is the Generative Pre-trained Transformer 3 with hundreds of billions of parameters and a half-terabyte training dataset. Similarly, mathematical models built from real data are growing in complexity which is accompanied by the growing amount of training data. However, when machine models and their predictions are used in decision-making, one needs to estimate uncertainty and evaluate accompanying risks. This problem could be resolved with non-parametric techniques at the expense of greater demand for computing power, which can be offered by modern supercomputers available, including those utilizing graphical and tensor processing units along with the conventional central processors. ","[{'version': 'v1', 'created': 'Fri, 3 Jun 2022 16:11:11 GMT'}]",2022-06-07,"[['Arkov', 'Valentin', '']]",0,1,2022-06-03,1,1,2,0,0,0,4e78382834106ae4a43fb6fe67cb8b3b3a6e814a,249395456.0,https://www.semanticscholar.org/paper/4e78382834106ae4a43fb6fe67cb8b3b3a6e814a,2023 International Russian Smart Industry Conference (SmartIndustryCon),2022.0,28.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2303501', 'name': 'V. Arkov'}]",['Ufa State Aviation Technical University'],['Russia'],2022-06
2206.03865,Jeevana Priya Inala,"Jeevana Priya Inala, Chenglong Wang, Mei Yang, Andres Codas, Mark
  Encarnaci\'on, Shuvendu K Lahiri, Madanlal Musuvathi, Jianfeng Gao",Fault-Aware Neural Code Rankers,"In the proceedings of Advances in Neural Information Processing
  Systems, 2022",,,,cs.PL cs.AI cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated an impressive ability to generate code for various programming tasks. In many instances, LLMs can generate a correct program for a task when given numerous trials. Consequently, a recent trend is to do large scale sampling of programs using a model and then filtering/ranking the programs based on the program execution on a small number of known unit tests to select one candidate solution. However, these approaches assume that the unit tests are given and assume the ability to safely execute the generated programs (which can do arbitrary dangerous operations such as file manipulations). Both of the above assumptions are impractical in real-world software development. In this paper, we propose CodeRanker, a neural ranker that can predict the correctness of a sampled program without executing it. Our CodeRanker is fault-aware i.e., it is trained to predict different kinds of execution information such as predicting the exact compile/runtime error type (e.g., an IndexError or a TypeError). We show that CodeRanker can significantly increase the pass@1 accuracy of various code generation models (including Codex, GPT-Neo, GPT-J) on APPS, HumanEval and MBPP datasets. ","[{'version': 'v1', 'created': 'Sat, 4 Jun 2022 22:01:05 GMT'}, {'version': 'v2', 'created': 'Fri, 9 Dec 2022 22:10:02 GMT'}]",2022-12-13,"[['Inala', 'Jeevana Priya', ''], ['Wang', 'Chenglong', ''], ['Yang', 'Mei', ''], ['Codas', 'Andres', ''], ['Encarnación', 'Mark', ''], ['Lahiri', 'Shuvendu K', ''], ['Musuvathi', 'Madanlal', ''], ['Gao', 'Jianfeng', '']]",0,1,2022-06-04,2,8,3,1,0,1,075b6fb7d3787953164eecc1bd2e13f97c9f3c44,249462026.0,https://www.semanticscholar.org/paper/075b6fb7d3787953164eecc1bd2e13f97c9f3c44,Neural Information Processing Systems,2022.0,46.0,27.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1827015', 'name': 'J. Inala'}, {'authorId': '2144523164', 'name': 'Chenglong Wang'}, {'authorId': '2168617007', 'name': 'Mei Yang'}, {'authorId': '2097627', 'name': 'Andrés Codas'}, {'authorId': '2168879819', 'name': ""Mark Encarnaci'on""}, {'authorId': '145474353', 'name': 'Shuvendu K. Lahiri'}, {'authorId': '1702346', 'name': 'M. Musuvathi'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}]",['Microsoft'],['India'],2022-06
2206.08264,Maria Teresa Llano,Stephen James Krol and Maria Teresa Llano and Jon McCormack,Towards the Generation of Musical Explanations with GPT-3,,"Artificial Intelligence in Music, Sound, Art and Design - 11th
  International Conference, EvoMUSART 2022, Held as Part of EvoStar 2022",,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Open AI's language model, GPT-3, has shown great potential for many NLP tasks, with applications in many different domains. In this work we carry out a first study on GPT-3's capability to communicate musical decisions through textual explanations when prompted with a textual representation of a piece of music. Enabling a dialogue in human-AI music partnerships is an important step towards more engaging and creative human-AI interactions. Our results show that GPT-3 lacks the necessary intelligence to really understand musical decisions. A major barrier to reach a better performance is the lack of data that includes explanations of the creative process carried out by artists for musical pieces. We believe such a resource would aid the understanding and collaboration with AI music systems. ","[{'version': 'v1', 'created': 'Wed, 11 May 2022 13:04:54 GMT'}]",2022-06-17,"[['Krol', 'Stephen James', ''], ['Llano', 'Maria Teresa', ''], ['McCormack', 'Jon', '']]",0,1,2022-05-11,1,3,2,1,0,1,c08352ac7489100fd192560189258980135d4a56,248326468.0,https://www.semanticscholar.org/paper/c08352ac7489100fd192560189258980135d4a56,EvoMUSART,2022.0,26.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2106214764', 'name': 'S. Krol'}, {'authorId': '32656155', 'name': 'M. T. Llano'}, {'authorId': '2163211684', 'name': 'Jon McCormack'}]",['Monash University'],['Australia'],2022-05
2206.08267,Ganesh Bagler Dr,"Mansi Goel, Pallab Chakraborty, Vijay Ponnaganti, Minnet Khan,
  Sritanaya Tatipamala, Aakanksha Saini and Ganesh Bagler",Ratatouille: A tool for Novel Recipe Generation,"4 pages, 5 figures, 38th IEEE International Conference on Data
  Engineering, DECOR Workshop",,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Due to availability of a large amount of cooking recipes online, there is a growing interest in using this as data to create novel recipes. Novel Recipe Generation is a problem in the field of Natural Language Processing in which our main interest is to generate realistic, novel cooking recipes. To come up with such novel recipes, we trained various Deep Learning models such as LSTMs and GPT-2 with a large amount of recipe data. We present Ratatouille (https://cosylab.iiitd.edu.in/ratatouille2/), a web based application to generate novel recipes. ","[{'version': 'v1', 'created': 'Tue, 10 May 2022 11:20:19 GMT'}]",2022-06-17,"[['Goel', 'Mansi', ''], ['Chakraborty', 'Pallab', ''], ['Ponnaganti', 'Vijay', ''], ['Khan', 'Minnet', ''], ['Tatipamala', 'Sritanaya', ''], ['Saini', 'Aakanksha', ''], ['Bagler', 'Ganesh', '']]",0,1,2022-05-10,1,7,1,1,1,0,3cbba1c864b740d793035711da8810f6ee58f63e,249712131.0,https://www.semanticscholar.org/paper/3cbba1c864b740d793035711da8810f6ee58f63e,2022 IEEE 38th International Conference on Data Engineering Workshops (ICDEW),2022.0,25.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32839391', 'name': 'Mansi Goel'}, {'authorId': '1726629034', 'name': 'Pallab Chakraborty'}, {'authorId': '2170538137', 'name': 'Vijay Ponnaganti'}, {'authorId': '2170659719', 'name': 'Minnet Khan'}, {'authorId': '2170536094', 'name': 'Sritanaya Tatipamala'}, {'authorId': '3328119', 'name': 'Aakanksha Saini'}, {'authorId': '2080658', 'name': 'Ganesh Bagler'}]",['Indraprastha Institute of Information Technology Delhi'],['India'],2022-05
2206.08349,Aaditya K Singh,"Aaditya K. Singh, David Ding, Andrew Saxe, Felix Hill, Andrew K.
  Lampinen",Know your audience: specializing grounded language models with listener subtraction,"28 pages, 9 figures",,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Effective communication requires adapting to the idiosyncrasies of each communicative context--such as the common ground shared with each partner. Humans demonstrate this ability to specialize to their audience in many contexts, such as the popular game Dixit. We take inspiration from Dixit to formulate a multi-agent image reference game where a (trained) speaker model is rewarded for describing a target image such that one (pretrained) listener model can correctly identify it among distractors, but another listener cannot. To adapt, the speaker must exploit differences in the knowledge it shares with the different listeners. We show that finetuning an attention-based adapter between a CLIP vision encoder and a large language model in this contrastive, multi-agent setting gives rise to context-dependent natural language specialization from rewards only, without direct supervision. Through controlled experiments, we show that training a speaker with two listeners that perceive differently, using our method, allows the speaker to adapt to the idiosyncracies of the listeners. Furthermore, we show zero-shot transfer of the specialization to real-world data. Our experiments demonstrate a method for specializing grounded language models without direct supervision and highlight the interesting research challenges posed by complex multi-agent communication. ","[{'version': 'v1', 'created': 'Thu, 16 Jun 2022 17:52:08 GMT'}, {'version': 'v2', 'created': 'Mon, 1 May 2023 20:39:20 GMT'}]",2023-05-03,"[['Singh', 'Aaditya K.', ''], ['Ding', 'David', ''], ['Saxe', 'Andrew', ''], ['Hill', 'Felix', ''], ['Lampinen', 'Andrew K.', '']]",0,0,2022-06-16,2,5,3,0,0,0,8af5a1b58338fb16c69bf832299453af2d2bbd0d,258378269.0,https://www.semanticscholar.org/paper/8af5a1b58338fb16c69bf832299453af2d2bbd0d,Conference of the European Chapter of the Association for Computational Linguistics,2022.0,59.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109424185', 'name': 'Aaditya K Singh'}, {'authorId': '2056669326', 'name': 'David Ding'}, {'authorId': '34927843', 'name': 'Andrew M. Saxe'}, {'authorId': '145783676', 'name': 'Felix Hill'}, {'authorId': '32322945', 'name': 'Andrew Kyle Lampinen'}]",['University College London'],['United Kingdom'],2022-06
2206.08446,Michal \v{S}tef\'anik,Michal \v{S}tef\'anik,Methods for Estimating and Improving Robustness of Language Models,"Thesis proposal, accepted & to appear in NAACL SRW 2022",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Despite their outstanding performance, large language models (LLMs) suffer notorious flaws related to their preference for simple, surface-level textual relations over full semantic complexity of the problem. This proposal investigates a common denominator of this problem in their weak ability to generalise outside of the training domain. We survey diverse research directions providing estimations of model generalisation ability and find that incorporating some of these measures in the training objectives leads to enhanced distributional robustness of neural models. Based on these findings, we present future research directions towards enhancing the robustness of LLMs. ","[{'version': 'v1', 'created': 'Thu, 16 Jun 2022 21:02:53 GMT'}]",2022-06-20,"[['Štefánik', 'Michal', '']]",0,0,2022-06-16,1,1,2,0,0,0,a0352d7749c03064e6c7aef7a2c9a6a8a8bfc70a,249847902.0,https://www.semanticscholar.org/paper/a0352d7749c03064e6c7aef7a2c9a6a8a8bfc70a,North American Chapter of the Association for Computational Linguistics,2022.0,59.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2265901257', 'name': 'Michal Stefánik'}]",['Masaryk University'],['Czechia'],2022-06
2206.08932,Claire Stevenson,"Claire Stevenson, Iris Smal, Matthijs Baas, Raoul Grasman and Han van
  der Maas",Putting GPT-3's Creativity to the (Alternative Uses) Test,"5 pages, 6 figures, accepted at the International Conference on
  Computational Creativity (ICCC) 2022 as a Short Paper. See
  https://osf.io/vmk3c/ for data, analyses and code",,,,cs.AI cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  AI large language models have (co-)produced amazing written works from newspaper articles to novels and poetry. These works meet the standards of the standard definition of creativity: being original and useful, and sometimes even the additional element of surprise. But can a large language model designed to predict the next text fragment provide creative, out-of-the-box, responses that still solve the problem at hand? We put Open AI's generative natural language model, GPT-3, to the test. Can it provide creative solutions to one of the most commonly used tests in creativity research? We assessed GPT-3's creativity on Guilford's Alternative Uses Test and compared its performance to previously collected human responses on expert ratings of originality, usefulness and surprise of responses, flexibility of each set of ideas as well as an automated method to measure creativity based on the semantic distance between a response and the AUT object in question. Our results show that -- on the whole -- humans currently outperform GPT-3 when it comes to creative output. But, we believe it is only a matter of time before GPT-3 catches up on this particular task. We discuss what this work reveals about human and AI creativity, creativity testing and our definition of creativity. ","[{'version': 'v1', 'created': 'Fri, 10 Jun 2022 15:36:45 GMT'}]",2022-06-22,"[['Stevenson', 'Claire', ''], ['Smal', 'Iris', ''], ['Baas', 'Matthijs', ''], ['Grasman', 'Raoul', ''], ['van der Maas', 'Han', '']]",0,1,2022-06-10,1,5,3,1,0,1,6a9d8a449b8326084786d81c92cdefd6beb5df10,249890230.0,https://www.semanticscholar.org/paper/6a9d8a449b8326084786d81c92cdefd6beb5df10,International Conference on Innovative Computing and Cloud Computing,2022.0,24.0,25.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '34875113', 'name': 'C. Stevenson'}, {'authorId': '2136361241', 'name': 'I. Smal'}, {'authorId': '2839336', 'name': 'M. Baas'}, {'authorId': '2253186', 'name': 'R. Grasman'}, {'authorId': '31435518', 'name': 'H. Maas'}]",['University of Amsterdam'],['Netherlands'],2022-06
2206.09248,Evgeny Kotelnikov,"Sergey Vychegzhanin, Evgeny Kotelnikov",Collocation2Text: Controllable Text Generation from Guide Phrases in Russian,Accepted by Dialogue-2022 conference,,10.28995/2075-7182-2022-21-564-576,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large pre-trained language models are capable of generating varied and fluent texts. Starting from the prompt, these models generate a narrative that can develop unpredictably. The existing methods of controllable text generation, which guide the narrative in the text in the user-specified direction, require creating a training corpus and an additional time-consuming training procedure. The paper proposes and investigates Collocation2Text, a plug-and-play method for automatic controllable text generation in Russian, which does not require fine-tuning. The method is based on two interacting models: the autoregressive language ruGPT-3 model and the autoencoding language ruRoBERTa model. The idea of the method is to shift the output distribution of the autoregressive model according to the output distribution of the autoencoding model in order to ensure a coherent transition of the narrative in the text towards the guide phrase, which can contain single words or collocations. The autoencoding model, which is able to take into account the left and right contexts of the token, ""tells"" the autoregressive model which tokens are the most and least logical at the current generation step, increasing or decreasing the probabilities of the corresponding tokens. The experiments on generating news articles using the proposed method showed its effectiveness for automatically generated fluent texts which contain coherent transitions between user-specified phrases. ","[{'version': 'v1', 'created': 'Sat, 18 Jun 2022 17:10:08 GMT'}]",2022-06-22,"[['Vychegzhanin', 'Sergey', ''], ['Kotelnikov', 'Evgeny', '']]",0,1,2022-06-18,1,2,1,0,0,0,bc12f4192715a8e7087c82c15d5f68f6272fc260,249889215.0,https://www.semanticscholar.org/paper/bc12f4192715a8e7087c82c15d5f68f6272fc260,Computational Linguistics and Intellectual Technologies,2022.0,36.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51917393', 'name': 'S. Vychegzhanin'}, {'authorId': '51923680', 'name': 'E. Kotelnikov'}]",['Vyatka State University'],['Russia'],2022-06
2206.09253,Evgeny Kotelnikov,"Valeriya Goloviznina, Evgeny Kotelnikov",Automatic Summarization of Russian Texts: Comparison of Extractive and Abstractive Methods,Accepted by Dialogue-2022 conference,,10.28995/2075-7182-2022-21-223-235,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The development of large and super-large language models, such as GPT-3, T5, Switch Transformer, ERNIE, etc., has significantly improved the performance of text generation. One of the important research directions in this area is the generation of texts with arguments. The solution of this problem can be used in business meetings, political debates, dialogue systems, for preparation of student essays. One of the main domains for these applications is the economic sphere. The key problem of the argument text generation for the Russian language is the lack of annotated argumentation corpora. In this paper, we use translated versions of the Argumentative Microtext, Persuasive Essays and UKP Sentential corpora to fine-tune RuBERT model. Further, this model is used to annotate the corpus of economic news by argumentation. Then the annotated corpus is employed to fine-tune the ruGPT-3 model, which generates argument texts. The results show that this approach improves the accuracy of the argument generation by more than 20 percentage points (63.2% vs. 42.5%) compared to the original ruGPT-3 model. ","[{'version': 'v1', 'created': 'Sat, 18 Jun 2022 17:28:04 GMT'}]",2022-06-22,"[['Goloviznina', 'Valeriya', ''], ['Kotelnikov', 'Evgeny', '']]",0,1,2022-06-18,1,2,1,2,1,1,47104facc11c82abb577a9a82f81a53b92d9a7c5,249889224.0,https://www.semanticscholar.org/paper/47104facc11c82abb577a9a82f81a53b92d9a7c5,Computational Linguistics and Intellectual Technologies,2022.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2115473005', 'name': 'Valeriya Goloviznina'}, {'authorId': '51923680', 'name': 'E. Kotelnikov'}]","['университет, Киров, Россия', 'Vyatka State University']",['Russia'],2022-06
2206.09557,Gunho Park,"Gunho Park, Baeseong Park, Minsub Kim, Sungjae Lee, Jeonghoon Kim,
  Beomseok Kwon, Se Jung Kwon, Byeongwook Kim, Youngjoo Lee, and Dongsoo Lee",LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models,"Extension of ""nuQmm: Quantized MatMul for Efficient Inference of
  Large-Scale Generative Language Models""",,,,cs.DC cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recent advancements in self-supervised learning, combined with the Transformer architecture, have enabled natural language processing (NLP) to achieve remarkably low perplexity. However, powerful NLP models necessitate increasing model size, leading to substantial computational and memory requirements. In this paper, we introduce an efficient inference framework tailored for large-scale generative language models. To reduce the model size, we employ a weight-only quantization strategy while preserving full precision for activations. As a result, we attain sub-4-bit quantization for each weight through non-uniform or uniform quantization techniques. Our proposed kernel, called LUT-GEMM, then accelerates quantized matrix multiplications, offering a flexible balance between compression ratio and accuracy. Unlike earlier matrix multiplication kernels that accommodated weight-only quantization, LUT-GEMM efficiently eliminates the resource-demanding dequantization process for both uniform and non-uniform quantization methods. By reducing the latency of individual GPUs and the overall inference process for large-scale language models, LUT-GEMM provides significant performance improvements in inference. The impact of LUT-GEMM is facilitated by implementing high compression ratios through low-bit quantization and efficient LUT-based operations, which decreases the number of required GPUs. For the OPT-175B model with 3-bit quantization, we show that LUT-GEMM accelerates the latency for generating each token by 2.1x compared to OPTQ, which requires costly dequantization. Consequently, LUT-GEMM enables inference of the OPT-175B model on a single GPU without noticeable degradation in accuracy or performance, while the non-quantized OPT-175B model requires a minimum of 8 GPUs. ","[{'version': 'v1', 'created': 'Mon, 20 Jun 2022 03:48:17 GMT'}, {'version': 'v2', 'created': 'Tue, 1 Nov 2022 04:58:11 GMT'}, {'version': 'v3', 'created': 'Sat, 15 Apr 2023 15:16:40 GMT'}]",2023-04-18,"[['Park', 'Gunho', ''], ['Park', 'Baeseong', ''], ['Kim', 'Minsub', ''], ['Lee', 'Sungjae', ''], ['Kim', 'Jeonghoon', ''], ['Kwon', 'Beomseok', ''], ['Kwon', 'Se Jung', ''], ['Kim', 'Byeongwook', ''], ['Lee', 'Youngjoo', ''], ['Lee', 'Dongsoo', '']]",0,0,2022-06-20,3,10,2,1,1,0,5eeb828685e44ca5b8ebafb34a9fa4d51c9186df,258180013.0,https://www.semanticscholar.org/paper/5eeb828685e44ca5b8ebafb34a9fa4d51c9186df,,2022.0,62.0,11.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2106951926', 'name': 'Gunho Park'}, {'authorId': '120751934', 'name': 'Baeseong Park'}, {'authorId': '2116507605', 'name': 'Minsub Kim'}, {'authorId': '2108230976', 'name': 'Sungjae Lee'}, {'authorId': '2144193082', 'name': 'Jeonghoon Kim'}, {'authorId': '2212491676', 'name': 'Beomseok Kwon'}, {'authorId': '12693169', 'name': 'Se Jung Kwon'}, {'authorId': '46239568', 'name': 'Byeongwook Kim'}, {'authorId': '2145439373', 'name': 'Youngjoo Lee'}, {'authorId': '122808525', 'name': 'Dongsoo Lee'}]","['Pohang University of Science and Technology', 'NAVER']",['South Korea'],2022-06
2206.14576,Marcel Binz,Marcel Binz and Eric Schulz,Using cognitive psychology to understand GPT-3,,,10.1073/pnas.2218523120,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We study GPT-3, a recent large language model, using tools from cognitive psychology. More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature. We find that much of GPT-3's behavior is impressive: it solves vignette-based tasks similarly or better than human subjects, is able to make decent decisions from descriptions, outperforms humans in a multi-armed bandit task, and shows signatures of model-based reinforcement learning. Yet we also find that small perturbations to vignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures of directed exploration, and that it fails miserably in a causal reasoning task. These results enrich our understanding of current large language models and pave the way for future investigations using tools from cognitive psychology to study increasingly capable and opaque artificial agents. ","[{'version': 'v1', 'created': 'Tue, 21 Jun 2022 20:06:03 GMT'}]",2023-02-22,"[['Binz', 'Marcel', ''], ['Schulz', 'Eric', '']]",0,1,2022-06-21,1,2,3,1,0,1,fa3609e00f9f422a309c621a35394c4a38f88687,250113371.0,https://www.semanticscholar.org/paper/fa3609e00f9f422a309c621a35394c4a38f88687,Proceedings of the National Academy of Sciences of the United States of America,2022.0,73.0,136.0,9.0,True,"['Computer Science', 'Medicine']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32354733', 'name': 'Marcel Binz'}, {'authorId': '49427184', 'name': 'Eric Schulz'}]",['Max Planck Institute for Biological Cybernetics'],['Germany'],2022-06
2206.15067,Hyun-Wook Yoon,"Hyun-Wook Yoon, Ohsung Kwon, Hoyeon Lee, Ryuichi Yamamoto, Eunwoo
  Song, Jae-Min Kim, and Min-Jae Hwang",Language Model-Based Emotion Prediction Methods for Emotional Speech Synthesis Systems,Accepted by INTERSPEECH2022,,,,cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes an effective emotional text-to-speech (TTS) system with a pre-trained language model (LM)-based emotion prediction method. Unlike conventional systems that require auxiliary inputs such as manually defined emotion classes, our system directly estimates emotion-related attributes from the input text. Specifically, we utilize generative pre-trained transformer (GPT)-3 to jointly predict both an emotion class and its strength in representing emotions coarse and fine properties, respectively. Then, these attributes are combined in the emotional embedding space and used as conditional features of the TTS model for generating output speech signals. Consequently, the proposed system can produce emotional speech only from text without any auxiliary inputs. Furthermore, because the GPT-3 enables to capture emotional context among the consecutive sentences, the proposed method can effectively handle the paragraph-level generation of emotional speech. ","[{'version': 'v1', 'created': 'Thu, 30 Jun 2022 07:03:01 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Jul 2022 01:13:10 GMT'}]",2022-07-04,"[['Yoon', 'Hyun-Wook', ''], ['Kwon', 'Ohsung', ''], ['Lee', 'Hoyeon', ''], ['Yamamoto', 'Ryuichi', ''], ['Song', 'Eunwoo', ''], ['Kim', 'Jae-Min', ''], ['Hwang', 'Min-Jae', '']]",0,1,2022-06-30,2,7,2,1,0,1,4b7576815cc9cbb75ed72801791eb8d4dfd6484b,250144632.0,https://www.semanticscholar.org/paper/4b7576815cc9cbb75ed72801791eb8d4dfd6484b,Interspeech,2022.0,36.0,5.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1879512618', 'name': 'Hyun-Wook Yoon'}, {'authorId': '152406499', 'name': 'Ohsung Kwon'}, {'authorId': '2174373459', 'name': 'Hoyeon Lee'}, {'authorId': '47146577', 'name': 'Ryuichi Yamamoto'}, {'authorId': '37826449', 'name': 'Eunwoo Song'}, {'authorId': '2125028067', 'name': 'Jae-Min Kim'}, {'authorId': '47350043', 'name': 'Min-Jae Hwang'}]","['NAVER', 'Line Corporation (Japan)']","['South Korea', 'Japan']",2022-06
2206.15331,Arghavan Moradi Dakhel,"Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam, Foutse Khomh,
  Michel C. Desmarais, Zhen Ming (Jack) Jiang",GitHub Copilot AI pair programmer: Asset or Liability?,"27 pages, 8 figures",,,,cs.SE cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic program synthesis is a long-lasting dream in software engineering. Recently, a promising Deep Learning (DL) based solution, called Copilot, has been proposed by OpenAI and Microsoft as an industrial product. Although some studies evaluate the correctness of Copilot solutions and report its issues, more empirical evaluations are necessary to understand how developers can benefit from it effectively. In this paper, we study the capabilities of Copilot in two different programming tasks: (i) generating (and reproducing) correct and efficient solutions for fundamental algorithmic problems, and (ii) comparing Copilot's proposed solutions with those of human programmers on a set of programming tasks. For the former, we assess the performance and functionality of Copilot in solving selected fundamental problems in computer science, like sorting and implementing data structures. In the latter, a dataset of programming problems with human-provided solutions is used. The results show that Copilot is capable of providing solutions for almost all fundamental algorithmic problems, however, some solutions are buggy and non-reproducible. Moreover, Copilot has some difficulties in combining multiple methods to generate a solution. Comparing Copilot to humans, our results show that the correct ratio of humans' solutions is greater than Copilot's suggestions, while the buggy solutions generated by Copilot require less effort to be repaired. ","[{'version': 'v1', 'created': 'Thu, 30 Jun 2022 15:00:03 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Apr 2023 20:52:00 GMT'}]",2023-04-18,"[['Dakhel', 'Arghavan Moradi', '', 'Jack'], ['Majdinasab', 'Vahid', '', 'Jack'], ['Nikanjam', 'Amin', '', 'Jack'], ['Khomh', 'Foutse', '', 'Jack'], ['Desmarais', 'Michel C.', '', 'Jack'], ['Ming', 'Zhen', '', 'Jack'], ['Jiang', '', '']]",0,0,2022-06-30,2,7,2,0,0,0,d6954c43aa1ca197319c45d3988bc8fcec3de976,250144223.0,https://www.semanticscholar.org/paper/d6954c43aa1ca197319c45d3988bc8fcec3de976,Journal of Systems and Software,2022.0,66.0,74.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35647660', 'name': 'Arghavan Moradi Dakhel'}, {'authorId': '2174176115', 'name': 'Vahid Majdinasab'}, {'authorId': '2076564', 'name': 'Amin Nikanjam'}, {'authorId': '1703493', 'name': 'Foutse Khomh'}, {'authorId': '8994568', 'name': 'M. Desmarais'}, {'authorId': '1762589', 'name': 'Z. Jiang'}]",['York University'],['Canada'],2022-06
2207.00929,Toshiki Kawamoto,"Toshiki Kawamoto, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura",Generating Repetitions with Appropriate Repeated Words,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A repetition is a response that repeats words in the previous speaker's utterance in a dialogue. Repetitions are essential in communication to build trust with others, as investigated in linguistic studies. In this work, we focus on repetition generation. To the best of our knowledge, this is the first neural approach to address repetition generation. We propose Weighted Label Smoothing, a smoothing method for explicitly learning which words to repeat during fine-tuning, and a repetition scoring method that can output more appropriate repetitions during decoding. We conducted automatic and human evaluations involving applying these methods to the pre-trained language model T5 for generating repetitions. The experimental results indicate that our methods outperformed baselines in both evaluations. ","[{'version': 'v1', 'created': 'Sun, 3 Jul 2022 01:21:49 GMT'}]",2022-07-05,"[['Kawamoto', 'Toshiki', ''], ['Kamigaito', 'Hidetaka', ''], ['Funakoshi', 'Kotaro', ''], ['Okumura', 'Manabu', '']]",0,0,2022-07-03,1,4,1,1,1,0,73a70cd0af7cfa31129b8bdc7a66c96b4dceb4a8,250264423.0,https://www.semanticscholar.org/paper/73a70cd0af7cfa31129b8bdc7a66c96b4dceb4a8,North American Chapter of the Association for Computational Linguistics,2022.0,30.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2174734455', 'name': 'Toshiki Kawamoto'}, {'authorId': '2300756', 'name': 'Hidetaka Kamigaito'}, {'authorId': '1747395', 'name': 'Kotaro Funakoshi'}, {'authorId': '144859189', 'name': 'M. Okumura'}]",['Tokyo Institute of Technology'],['Japan'],2022-07
2207.02074,Juan Pinto MsC,"Juan Pinto-R\'ios, Felipe Calder\'on, Ariel Leiva, Gabriel Hermosilla,
  Alejandra Beghelli, Danilo B\'orquez-Paredes, Astrid Lozada, Nicol\'as Jara,
  Ricardo Olivares, Gabriel Saavedra",Resource Allocation in Multicore Elastic Optical Networks: A Deep Reinforcement Learning Approach,"11 pages, 10 figures",,,,cs.LG cs.AI cs.NI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  A deep reinforcement learning approach is applied, for the first time, to solve the routing, modulation, spectrum and core allocation (RMSCA) problem in dynamic multicore fiber elastic optical networks (MCF-EONs). To do so, a new environment - compatible with OpenAI's Gym - was designed and implemented to emulate the operation of MCF-EONs. The new environment processes the agent actions (selection of route, core and spectrum slot) by considering the network state and physical-layer-related aspects. The latter includes the available modulation formats and their reach and the inter-core crosstalk (XT), an MCF-related impairment. If the resulting quality of the signal is acceptable, the environment allocates the resources selected by the agent. After processing the agent's action, the environment is configured to give the agent a numerical reward and information about the new network state. The blocking performance of four different agents was compared through simulation to 3 baseline heuristics used in MCF-EONs. Results obtained for the NSFNet and COST239 network topologies show that the best-performing agent achieves, on average, up to a four-times decrease in blocking probability concerning the best-performing baseline heuristic methods. ","[{'version': 'v1', 'created': 'Tue, 5 Jul 2022 14:24:21 GMT'}]",2022-07-06,"[['Pinto-Ríos', 'Juan', ''], ['Calderón', 'Felipe', ''], ['Leiva', 'Ariel', ''], ['Hermosilla', 'Gabriel', ''], ['Beghelli', 'Alejandra', ''], ['Bórquez-Paredes', 'Danilo', ''], ['Lozada', 'Astrid', ''], ['Jara', 'Nicolás', ''], ['Olivares', 'Ricardo', ''], ['Saavedra', 'Gabriel', '']]",0,0,2022-07-05,1,10,3,0,0,0,db9b4c4a9fe519ec2381218a280b5ae8616f5995,248007315.0,https://www.semanticscholar.org/paper/db9b4c4a9fe519ec2381218a280b5ae8616f5995,Complex,2022.0,73.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2121352155', 'name': 'Juan Pinto-Ríos'}, {'authorId': '1831027966', 'name': 'F. Calderón'}, {'authorId': '1985846', 'name': 'A. Leiva'}, {'authorId': '145147107', 'name': 'Gabriel Hermosilla'}, {'authorId': '3146498', 'name': 'A. Beghelli'}, {'authorId': '1402844686', 'name': 'Danilo Bórquez-Paredes'}, {'authorId': '1831027170', 'name': 'A. Lozada'}, {'authorId': '35158571', 'name': 'N. Jara'}, {'authorId': '5300885', 'name': 'R. Olivares'}, {'authorId': '39932282', 'name': 'G. Saavedra'}]","['University College London', 'Federico Santa María Technical University', 'University of Concepción', 'Pontificia Universidad Católica de Valparaíso', 'Adolfo Ibáñez University']","['Chile', 'United Kingdom']",2022-07
2207.02516,Su Young Kim,"Su Young Kim, Hyeonjin Park, Kyuyong Shin, Kyung-Min Kim",Ask Me What You Need: Product Retrieval using Knowledge from GPT-3,Accepted to DLP-KDD 2022 Workshop,,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As online merchandise become more common, many studies focus on embedding-based methods where queries and products are represented in the semantic space. These methods alleviate the problem of vocab mismatch between the language of queries and products. However, past studies usually dealt with queries that precisely describe the product, and there still exists the need to answer imprecise queries that may require common sense knowledge, i.e., 'what should I get my mom for Mother's Day.' In this paper, we propose a GPT-3 based product retrieval system that leverages the knowledge-base (KB) of GPT-3 for question answering; users do not need to know the specific illustrative keywords for a product when querying. Our method tunes prompt tokens of GPT-3 to prompt knowledge and render answers that are mapped directly to products without further processing. Our method shows consistent performance improvement on two real-world and one public dataset, compared to the baseline methods. We provide an in-depth discussion on leveraging GPT-3 knowledge into a question answering based retrieval system. ","[{'version': 'v1', 'created': 'Wed, 6 Jul 2022 08:44:38 GMT'}]",2022-07-07,"[['Kim', 'Su Young', ''], ['Park', 'Hyeonjin', ''], ['Shin', 'Kyuyong', ''], ['Kim', 'Kyung-Min', '']]",0,1,2022-07-06,1,4,1,1,0,1,62595a575c2c4a01b868de226aa68cfe17ea1fa3,250311310.0,https://www.semanticscholar.org/paper/62595a575c2c4a01b868de226aa68cfe17ea1fa3,arXiv.org,2022.0,15.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143061094', 'name': 'S. Kim'}, {'authorId': '2110832174', 'name': 'Hyeon-ju Park'}, {'authorId': '2810739', 'name': 'Kyuyong Shin'}, {'authorId': '2109351321', 'name': 'KyungHyun Kim'}]",['NAVER'],['South Korea'],2022-07
2207.02775,Andrea Mannocci Dr.,"Andrea Mannocci, Ornella Irrera and Paolo Manghi",Open Science and Authorship of Supplementary Material. Evidence from a Research Community,"8 pages, 2 figures; accepted to the 26th International Conference on
  Science, Technology and Innovation Indicators (STI 2022)",,10.5281/zenodo.6975411,,cs.DL,http://creativecommons.org/licenses/by/4.0/,"  Authorship of scientific articles has profoundly changed from early science until now. While once upon a time a paper was authored by a handful of authors, scientific collaborations are much more prominent on average nowadays. As authorship (and citation) is essentially the primary reward mechanism according to the traditional research evaluation frameworks, it turned out to be a rather hot-button topic from which a significant portion of academic disputes stems. However, the novel Open Science practices could be an opportunity to disrupt such dynamics and diversify the credit of the different scientific contributors involved in the diverse phases of the lifecycle of the same research effort. In fact, a paper and research data (or software) contextually published could exhibit different authorship to give credit to the various contributors right where it feels most appropriate. As a preliminary study, in this paper, we leverage the wealth of information contained in Open Science Graphs, such as OpenAIRE, and conduct a focused analysis on a subset of publications with supplementary material drawn from the European Marine Science (MES) research community. The results are promising and suggest our hypothesis is worth exploring further as we registered in 22% of the cases substantial variations between the authors participating in the publication and the authors participating in the supplementary dataset (or software), thus posing the premises for a longitudinal, large-scale analysis of the phenomenon. ","[{'version': 'v1', 'created': 'Wed, 6 Jul 2022 16:08:36 GMT'}, {'version': 'v2', 'created': 'Thu, 7 Jul 2022 06:16:59 GMT'}]",2022-09-16,"[['Mannocci', 'Andrea', ''], ['Irrera', 'Ornella', ''], ['Manghi', 'Paolo', '']]",0,0,2022-07-06,2,3,1,0,0,0,4e37e17ba379ca6bb04c8ac5e33e7b860df1f639,250311641.0,https://www.semanticscholar.org/paper/4e37e17ba379ca6bb04c8ac5e33e7b860df1f639,arXiv.org,2022.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2043406', 'name': 'A. Mannocci'}, {'authorId': '2051750606', 'name': 'Ornella Irrera'}, {'authorId': '1799502', 'name': 'P. Manghi'}]","['Institute of Information Science and Technologies', 'University of Padua']",['Italy'],2022-07
2207.03777,Pascal Welke,"Rams\'es J. S\'anchez, Lukas Conrads, Pascal Welke, Kostadin Cvejoski
  and C\'esar Ojeda",Hidden Schema Networks,accepted at ACL 2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large, pretrained language models infer powerful representations that encode rich semantic and syntactic content, albeit implicitly. In this work we introduce a novel neural language model that enforces, via inductive biases, explicit relational structures which allow for compositionality onto the output representations of pretrained language models. Specifically, the model encodes sentences into sequences of symbols (composed representations), which correspond to the nodes visited by biased random walkers on a global latent graph, and infers the posterior distribution of the latter. We first demonstrate that the model is able to uncover ground-truth graphs from artificially generated datasets of random token sequences. Next, we leverage pretrained BERT and GPT-2 language models as encoder and decoder, respectively, to infer networks of symbols (schemata) from natural language datasets. Our experiments show that (i) the inferred symbols can be interpreted as encoding different aspects of language, as e.g. topics or sentiments, and that (ii) GPT-like models can effectively be conditioned on symbolic representations. Finally, we explore training autoregressive, random walk ``reasoning"" models on schema networks inferred from commonsense knowledge databases, and using the sampled paths to enhance the performance of pretrained language models on commonsense If-Then reasoning tasks. ","[{'version': 'v1', 'created': 'Fri, 8 Jul 2022 09:26:19 GMT'}, {'version': 'v2', 'created': 'Fri, 26 May 2023 16:06:36 GMT'}]",2023-05-29,"[['Sánchez', 'Ramsés J.', ''], ['Conrads', 'Lukas', ''], ['Welke', 'Pascal', ''], ['Cvejoski', 'Kostadin', ''], ['Ojeda', 'César', '']]",0,1,2022-07-08,2,5,2,1,1,0,bcf185005b4741d6b57fb017c9620a7a704db1c1,250408106.0,https://www.semanticscholar.org/paper/bcf185005b4741d6b57fb017c9620a7a704db1c1,Annual Meeting of the Association for Computational Linguistics,2022.0,104.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145598885', 'name': 'Ramsés J. Sánchez'}, {'authorId': '2164644483', 'name': 'Lukas Conrads'}, {'authorId': '2377261', 'name': 'Pascal Welke'}, {'authorId': '3453469', 'name': 'K. Cvejoski'}, {'authorId': '145683354', 'name': 'C. Ojeda'}]","['Fraunhofer Institute for Intelligent Analysis and Information Systems', 'University of Potsdam', 'Lamarr Institute', 'University of Bonn']",['Germany'],2022-07
2207.06591,Luciana Benotti,"Laura Alonso Alemany, Luciana Benotti, Hern\'an Maina, Luc\'ia
  Gonz\'alez, Mariela Rajngewerc, Lautaro Mart\'inez, Jorge S\'anchez, Mauro
  Schilman, Guido Ivetta, Alexia Halvorsen, Amanda Mata Rojo, Mat\'ias Bordone,
  Beatriz Busaniche",A methodology to characterize bias and harmful stereotypes in natural language processing in Latin America,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Automated decision-making systems, especially those based on natural language processing, are pervasive in our lives. They are not only behind the internet search engines we use daily, but also take more critical roles: selecting candidates for a job, determining suspects of a crime, diagnosing autism and more. Such automated systems make errors, which may be harmful in many ways, be it because of the severity of the consequences (as in health issues) or because of the sheer number of people they affect. When errors made by an automated system affect a population more than others, we call the system \textit{biased}.   Most modern natural language technologies are based on artifacts obtained from enormous volumes of text using machine learning, namely language models and word embeddings. Since they are created by applying subsymbolic machine learning, mostly artificial neural networks, they are opaque and practically uninterpretable by direct inspection, thus making it very difficult to audit them.   In this paper, we present a methodology that spells out how social scientists, domain experts, and machine learning experts can collaboratively explore biases and harmful stereotypes in word embeddings and large language models. Our methodology is based on the following principles:   * focus on the linguistic manifestations of discrimination on word embeddings and language models, not on the mathematical properties of the models * reduce the technical barrier for discrimination experts%, be it social scientists, domain experts or other * characterize through a qualitative exploratory process in addition to a metric-based approach * address mitigation as part of the training process, not as an afterthought ","[{'version': 'v1', 'created': 'Thu, 14 Jul 2022 01:07:55 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Sep 2022 19:38:21 GMT'}, {'version': 'v3', 'created': 'Tue, 28 Mar 2023 21:22:17 GMT'}]",2023-03-30,"[['Alemany', 'Laura Alonso', ''], ['Benotti', 'Luciana', ''], ['Maina', 'Hernán', ''], ['González', 'Lucía', ''], ['Rajngewerc', 'Mariela', ''], ['Martínez', 'Lautaro', ''], ['Sánchez', 'Jorge', ''], ['Schilman', 'Mauro', ''], ['Ivetta', 'Guido', ''], ['Halvorsen', 'Alexia', ''], ['Rojo', 'Amanda Mata', ''], ['Bordone', 'Matías', ''], ['Busaniche', 'Beatriz', '']]",0,0,2022-07-14,3,13,2,0,0,0,a82a08b5e6a11f4d6fdff95dd30177957ed7855e,257804597.0,https://www.semanticscholar.org/paper/a82a08b5e6a11f4d6fdff95dd30177957ed7855e,,2022.0,46.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2276687', 'name': 'L. A. Alemany'}, {'authorId': '2066254822', 'name': 'Luciana Benotti'}, {'authorId': '2139773809', 'name': 'Hernán Maina'}, {'authorId': '143956405', 'name': ""Luc'ia Gonz'alez""}, {'authorId': '73773689', 'name': 'M. Rajngewerc'}, {'authorId': '2213485642', 'name': ""Lautaro Mart'inez""}, {'authorId': '2216725309', 'name': ""Jos'e L. S'anchez""}, {'authorId': '120494256', 'name': 'M. Schilman'}, {'authorId': '2213060824', 'name': 'Guido Ivetta'}, {'authorId': '2176182678', 'name': 'Alexia Halvorsen'}, {'authorId': '2213329754', 'name': 'Amanda Rojo'}, {'authorId': '2091620256', 'name': 'M. Bordone'}, {'authorId': '2079934550', 'name': 'Beatriz Busaniche'}]","['Fundación Vía Libre', 'Consejo Nacional de Investigaciones Científicas y Técnicas', 'Universidad Nacional de Córdoba']",['Argentina'],2022-07
2207.06814,Javier de la Rosa,"Javier de la Rosa, Eduardo G. Ponferrada, Paulo Villegas, Pablo
  Gonzalez de Prado Salas, Manu Romero, Mar{\i}a Grandury",BERTIN: Efficient Pre-Training of a Spanish Language Model using Perplexity Sampling,Published at Procesamiento del Lenguaje Natural,"Procesamiento del Lenguaje Natural, 68 (2022): 13-23",,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  The pre-training of large language models usually requires massive amounts of resources, both in terms of computation and data. Frequently used web sources such as Common Crawl might contain enough noise to make this pre-training sub-optimal. In this work, we experiment with different sampling methods from the Spanish version of mC4, and present a novel data-centric technique which we name $\textit{perplexity sampling}$ that enables the pre-training of language models in roughly half the amount of steps and using one fifth of the data. The resulting models are comparable to the current state-of-the-art, and even achieve better results for certain tasks. Our work is proof of the versatility of Transformers, and paves the way for small teams to train their models on a limited budget. Our models are available at this $\href{https://huggingface.co/bertin-project}{URL}$. ","[{'version': 'v1', 'created': 'Thu, 14 Jul 2022 10:48:42 GMT'}]",2022-07-15,"[['de la Rosa', 'Javier', ''], ['Ponferrada', 'Eduardo G.', ''], ['Villegas', 'Paulo', ''], ['Salas', 'Pablo Gonzalez de Prado', ''], ['Romero', 'Manu', ''], ['Grandury', 'Marıa', '']]",0,0,2022-07-14,1,6,2,0,0,0,13773b39a116effa9f948febac59fe302924bec1,250526558.0,https://www.semanticscholar.org/paper/13773b39a116effa9f948febac59fe302924bec1,Proces. del Leng. Natural,2022.0,57.0,40.0,5.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144979591', 'name': 'Javier de la Rosa'}, {'authorId': '2260133312', 'name': 'E. G. Ponferrada'}, {'authorId': '2176184659', 'name': 'Paulo Villegas'}, {'authorId': '9947685', 'name': 'Pablo González de Prado Salas'}, {'authorId': '2176185463', 'name': 'Manu Romero'}, {'authorId': '2176184513', 'name': 'María Grandury'}]","['Telefonica Research and Development', 'Foqum, Madrid, Spain', 'Narrativa, Madrid, Spain', 'National Library of Norway, Mo i Rana, Norway']","['Spain', 'Norway']",2022-07
2207.06839,Chris Van Der Lee,"Chris van der Lee, Thiago Castro Ferreira, Chris Emmery, Travis
  Wiltshire, Emiel Krahmer",Neural Data-to-Text Generation Based on Small Datasets: Comparing the Added Value of Two Semi-Supervised Learning Approaches on Top of a Large Language Model,22 pages (excluding bibliography and appendix),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This study discusses the effect of semi-supervised learning in combination with pretrained language models for data-to-text generation. It is not known whether semi-supervised learning is still helpful when a large-scale language model is also supplemented. This study aims to answer this question by comparing a data-to-text system only supplemented with a language model, to two data-to-text systems that are additionally enriched by a data augmentation or a pseudo-labeling semi-supervised learning approach.   Results show that semi-supervised learning results in higher scores on diversity metrics. In terms of output quality, extending the training set of a data-to-text system with a language model using the pseudo-labeling approach did increase text quality scores, but the data augmentation approach yielded similar scores to the system without training set extension. These results indicate that semi-supervised learning approaches can bolster output quality and diversity, even when a language model is also present. ","[{'version': 'v1', 'created': 'Thu, 14 Jul 2022 11:53:04 GMT'}]",2022-07-15,"[['van der Lee', 'Chris', ''], ['Ferreira', 'Thiago Castro', ''], ['Emmery', 'Chris', ''], ['Wiltshire', 'Travis', ''], ['Krahmer', 'Emiel', '']]",0,0,2022-07-14,1,5,1,0,0,0,cfb35212e3afc6951ea6db943b3fc23f578a4f77,250526239.0,https://www.semanticscholar.org/paper/cfb35212e3afc6951ea6db943b3fc23f578a4f77,Computational Linguistics,2022.0,86.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50521235', 'name': 'Chris van der Lee'}, {'authorId': '2575421', 'name': 'Thiago Castro Ferreira'}, {'authorId': '2709440', 'name': 'Chris Emmery'}, {'authorId': '49575098', 'name': 'Travis J. Wiltshire'}, {'authorId': '145210073', 'name': 'E. Krahmer'}]","['Universidade Federal de Minas Gerais', 'Tilburg University']","['Netherlands', 'Brazil']",2022-07
2207.06875,Valentina Lenarduzzi Ph.D.,"Andrea Janes, Xiaozhou Li, Valentina Lenarduzzi",Open Tracing Tools: Overview and Critical Comparison,,,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Background. Coping with the rapid growing complexity in contemporary software architecture, tracing has become an increasingly critical practice and been adopted widely by software engineers. By adopting tracing tools, practitioners are able to monitor, debug, and optimize distributed software architectures easily. However, with excessive number of valid candidates, researchers and practitioners have a hard time finding and selecting the suitable tracing tools by systematically considering their features and advantages.Objective. To such a purpose, this paper aims to provide an overview of popular Open tracing tools via comparison. Method. Herein, we first identified \ra{30} tools in an objective, systematic, and reproducible manner adopting the Systematic Multivocal Literature Review protocol. Then, we characterized each tool looking at the 1) measured features, 2) popularity both in peer-reviewed literature and online media, and 3) benefits and issues. We used topic modeling and sentiment analysis to extract and summarize the benefits and issues. Specially, we adopted ChatGPT to support the topic interpretation. Results. As a result, this paper presents a systematic comparison amongst the selected tracing tools in terms of their features, popularity, benefits and issues. Conclusion. The result mainly shows that each tracing tool provides a unique combination of features with also different pros and cons. The contribution of this paper is to provide the practitioners better understanding of the tracing tools facilitating their adoption. ","[{'version': 'v1', 'created': 'Thu, 14 Jul 2022 12:52:32 GMT'}, {'version': 'v2', 'created': 'Fri, 23 Jun 2023 15:51:36 GMT'}]",2023-06-26,"[['Janes', 'Andrea', ''], ['Li', 'Xiaozhou', ''], ['Lenarduzzi', 'Valentina', '']]",1,1,2022-07-14,2,3,1,1,0,1,3c9c713d5623cc6135e493494e91251a2ac53222,250526650.0,https://www.semanticscholar.org/paper/3c9c713d5623cc6135e493494e91251a2ac53222,Journal of Systems and Software,2022.0,122.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145565492', 'name': 'Andrea Janes'}, {'authorId': '2145455709', 'name': 'Xiaozhou Li'}, {'authorId': '2989307', 'name': 'Valentina Lenarduzzi'}]","['Vorarlberg University of Applied Sciences', 'University of Oulu', 'Tampere University', 'Free University of Bozen-Bolzano']","['Austria', 'Finland', 'Italy']",2022-07
2207.08141,Shiwen Ni,Shiwen Ni and Hung-Yu Kao,"ELECTRA is a Zero-Shot Learner, Too","The source code is available at:
  https://github.com/nishiwen1214/RTD-ELECTRA",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, for few-shot or even zero-shot learning, the new paradigm ""pre-train, prompt, and predict"" has achieved remarkable achievements compared with the ""pre-train, fine-tune"" paradigm. After the success of prompt-based GPT-3, a series of masked language model (MLM)-based (e.g., BERT, RoBERTa) prompt learning methods became popular and widely used. However, another efficient pre-trained discriminative model, ELECTRA, has probably been neglected. In this paper, we attempt to accomplish several NLP tasks in the zero-shot scenario using a novel our proposed replaced token detection (RTD)-based prompt learning method. Experimental results show that ELECTRA model based on RTD-prompt learning achieves surprisingly state-of-the-art zero-shot performance. Numerically, compared to MLM-RoBERTa-large and MLM-BERT-large, our RTD-ELECTRA-large has an average of about 8.4% and 13.7% improvement on all 15 tasks. Especially on the SST-2 task, our RTD-ELECTRA-large achieves an astonishing 90.1% accuracy without any training data. Overall, compared to the pre-trained masked language models, the pre-trained replaced token detection model performs better in zero-shot learning. The source code is available at: https://github.com/nishiwen1214/RTD-ELECTRA. ","[{'version': 'v1', 'created': 'Sun, 17 Jul 2022 11:20:58 GMT'}, {'version': 'v2', 'created': 'Wed, 20 Jul 2022 07:55:59 GMT'}]",2022-07-21,"[['Ni', 'Shiwen', ''], ['Kao', 'Hung-Yu', '']]",0,1,2022-07-17,2,2,1,1,0,1,36c4fb4557c4071d3e2c925a6bec11f290053a23,250627065.0,https://www.semanticscholar.org/paper/36c4fb4557c4071d3e2c925a6bec11f290053a23,arXiv.org,2022.0,38.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2028953122', 'name': 'Shiwen Ni'}, {'authorId': '1738550', 'name': 'Hung-Yu kao'}]",['National Cheng Kung University'],['Taiwan'],2022-07
2207.08143,Valentin Li\'evin,"Valentin Li\'evin, Christoffer Egeberg Hother, Ole Winther",Can large language models reason about medical questions?,"33 pages, 6 figures, to be submitted. v1: results using InstructGPT,
  v2: added the Codex experiments, v3: added the missing test MedMCQA results
  for Codex 5-shot CoT and using k=100 samples",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Although large language models (LLMs) often produce impressive outputs, it remains unclear how they perform in real-world scenarios requiring strong reasoning skills and expert domain knowledge. We set out to investigate whether GPT-3.5 (Codex and InstructGPT) can be applied to answer and reason about difficult real-world-based questions. We utilize two multiple-choice medical exam questions (USMLE and MedMCQA) and a medical reading comprehension dataset (PubMedQA). We investigate multiple prompting scenarios: Chain-of-Thought (CoT, think step-by-step), zero- and few-shot (prepending the question with question-answer exemplars) and retrieval augmentation (injecting Wikipedia passages into the prompt). For a subset of the USMLE questions, a medical expert reviewed and annotated the model's CoT. We found that InstructGPT can often read, reason and recall expert knowledge. Failure are primarily due to lack of knowledge and reasoning errors and trivial guessing heuristics are observed, e.g.\ too often predicting labels A and D on USMLE. Sampling and combining many completions overcome some of these limitations. Using 100 samples, Codex 5-shot CoT not only gives close to well-calibrated predictive probability but also achieves human-level performances on the three datasets. USMLE: 60.2%, MedMCQA: 62.7% and PubMedQA: 78.2%. ","[{'version': 'v1', 'created': 'Sun, 17 Jul 2022 11:24:44 GMT'}, {'version': 'v2', 'created': 'Tue, 20 Dec 2022 19:16:10 GMT'}, {'version': 'v3', 'created': 'Tue, 24 Jan 2023 12:23:48 GMT'}]",2023-01-25,"[['Liévin', 'Valentin', ''], ['Hother', 'Christoffer Egeberg', ''], ['Winther', 'Ole', '']]",0,1,2022-07-17,3,3,3,3,0,3,d697b440dd0e65a05fe027e4c0ea85f62dcba033,250627547.0,https://www.semanticscholar.org/paper/d697b440dd0e65a05fe027e4c0ea85f62dcba033,arXiv.org,2022.0,58.0,95.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067078585', 'name': ""Valentin Li'evin""}, {'authorId': '4475692', 'name': 'C. Hother'}, {'authorId': '1724252', 'name': 'O. Winther'}]","['Technical University of Denmark', 'University of Copenhagen', 'FindZebra ApS, Denmark', 'Copenhagen University Hospital']",['Denmark'],2022-07
2207.08305,Fran\c{c}ois Portet,"Yongxin Zhou, Fran\c{c}ois Portet, Fabien Ringeval",Effectiveness of French Language Models on Abstractive Dialogue Summarization Task,"Yongxin Zhou, Fran\c{c}ois Portet, Fabien Ringeval. Effectiveness of
  French Language Models on Abstractive Dialogue Summarization Task. LREC 2022,
  Marseille, France, 21-23 June 2022",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Pre-trained language models have established the state-of-the-art on various natural language processing tasks, including dialogue summarization, which allows the reader to quickly access key information from long conversations in meetings, interviews or phone calls. However, such dialogues are still difficult to handle with current models because the spontaneity of the language involves expressions that are rarely present in the corpora used for pre-training the language models. Moreover, the vast majority of the work accomplished in this field has been focused on English. In this work, we present a study on the summarization of spontaneous oral dialogues in French using several language specific pre-trained models: BARThez, and BelGPT-2, as well as multilingual pre-trained models: mBART, mBARThez, and mT5. Experiments were performed on the DECODA (Call Center) dialogue corpus whose task is to generate abstractive synopses from call center conversations between a caller and one or several agents depending on the situation. Results show that the BARThez models offer the best performance far above the previous state-of-the-art on DECODA. We further discuss the limits of such pre-trained models and the challenges that must be addressed for summarizing spontaneous dialogues. ","[{'version': 'v1', 'created': 'Sun, 17 Jul 2022 21:43:18 GMT'}]",2022-07-19,"[['Zhou', 'Yongxin', ''], ['Portet', 'François', ''], ['Ringeval', 'Fabien', '']]",0,1,2022-07-17,1,3,2,1,1,0,d357705dd0189e5398cdf1e8129127b66df06d6e,250627596.0,https://www.semanticscholar.org/paper/d357705dd0189e5398cdf1e8129127b66df06d6e,International Conference on Language Resources and Evaluation,2022.0,43.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2145493852', 'name': 'Yongxin Zhou'}, {'authorId': '2126059340', 'name': 'Franccois Portet'}, {'authorId': '2124680', 'name': 'F. Ringeval'}]",['Grenoble Institute of Technology'],['France'],2022-07
2207.11565,Marcin Pietron,Michal Karwatowski and Marcin Pietron,Context based lemmatizer for Polish language,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Lemmatization is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form. In computational linguistics, lemmatisation is the algorithmic process of determining the lemma of a word based on its intended meaning. Unlike stemming, lemmatisation depends on correctly identifying the intended part of speech and meaning of a word in a sentence, as well as within the larger context surrounding that sentence. As a result, developing efficient lemmatisation algorithm is the complex task. In recent years it can be observed that deep learning models used for this task outperform other methods including machine learning algorithms. In this paper the polish lemmatizer based on Google T5 model is presented. The training was run with different context lengths. The model achieves the best results for polish language lemmatisation process. ","[{'version': 'v1', 'created': 'Sat, 23 Jul 2022 18:02:16 GMT'}]",2022-07-26,"[['Karwatowski', 'Michal', ''], ['Pietron', 'Marcin', '']]",0,0,2022-07-23,1,2,2,1,1,0,b2ef46a59d23ba3fe24ec606fe7b9aa600b52e14,251040634.0,https://www.semanticscholar.org/paper/b2ef46a59d23ba3fe24ec606fe7b9aa600b52e14,arXiv.org,2022.0,12.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '52291957', 'name': 'Michał Karwatowski'}, {'authorId': '2592311', 'name': 'M. Pietroń'}]",['AGH University of Krakow'],['Poland'],2022-07
2207.12101,Federico Becattini,"Pietro Bongini, Federico Becattini, Alberto Del Bimbo",Is GPT-3 all you need for Visual Question Answering in Cultural Heritage?,,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The use of Deep Learning and Computer Vision in the Cultural Heritage domain is becoming highly relevant in the last few years with lots of applications about audio smart guides, interactive museums and augmented reality. All these technologies require lots of data to work effectively and be useful for the user. In the context of artworks, such data is annotated by experts in an expensive and time consuming process. In particular, for each artwork, an image of the artwork and a description sheet have to be collected in order to perform common tasks like Visual Question Answering. In this paper we propose a method for Visual Question Answering that allows to generate at runtime a description sheet that can be used for answering both visual and contextual questions about the artwork, avoiding completely the image and the annotation process. For this purpose, we investigate on the use of GPT-3 for generating descriptions for artworks analyzing the quality of generated descriptions through captioning metrics. Finally we evaluate the performance for Visual Question Answering and captioning tasks. ","[{'version': 'v1', 'created': 'Mon, 25 Jul 2022 12:12:46 GMT'}, {'version': 'v2', 'created': 'Fri, 19 May 2023 09:56:11 GMT'}]",2023-05-22,"[['Bongini', 'Pietro', ''], ['Becattini', 'Federico', ''], ['Del Bimbo', 'Alberto', '']]",0,1,2022-07-25,2,3,2,1,0,1,b21bb59c902b746e372eec5f959fb63857be4a47,251040408.0,https://www.semanticscholar.org/paper/b21bb59c902b746e372eec5f959fb63857be4a47,ECCV Workshops,2022.0,39.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Art', 'source': 's2-fos-model'}]","[{'authorId': '150257726', 'name': 'P. Bongini'}, {'authorId': '41172759', 'name': 'Federico Becattini'}, {'authorId': '8196487', 'name': 'A. Bimbo'}]",['University of Florence'],['Italy'],2022-07
2207.14561,Yuki Kadokawa,"Yuki Kadokawa, Lingwei Zhu, Yoshihisa Tsurumine, Takamitsu Matsubara",Cyclic Policy Distillation: Sample-Efficient Sim-to-Real Reinforcement Learning with Domain Randomization,,,,,cs.RO cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep reinforcement learning with domain randomization learns a control policy in various simulations with randomized physical and sensor model parameters to become transferable to the real world in a zero-shot setting. However, a huge number of samples are often required to learn an effective policy when the range of randomized parameters is extensive due to the instability of policy updates. To alleviate this problem, we propose a sample-efficient method named cyclic policy distillation (CPD). CPD divides the range of randomized parameters into several small sub-domains and assigns a local policy to each one. Then local policies are learned while cyclically transitioning to sub-domains. CPD accelerates learning through knowledge transfer based on expected performance improvements. Finally, all of the learned local policies are distilled into a global policy for sim-to-real transfers. CPD's effectiveness and sample efficiency are demonstrated through simulations with four tasks (Pendulum from OpenAIGym and Pusher, Swimmer, and HalfCheetah from Mujoco), and a real-robot, ball-dispersal task. We published code and videos from our experiments at https://github.com/yuki-kadokawa/cyclic-policy-distillation. ","[{'version': 'v1', 'created': 'Fri, 29 Jul 2022 09:22:53 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Apr 2023 07:02:05 GMT'}]",2023-04-11,"[['Kadokawa', 'Yuki', ''], ['Zhu', 'Lingwei', ''], ['Tsurumine', 'Yoshihisa', ''], ['Matsubara', 'Takamitsu', '']]",0,0,2022-07-29,2,4,2,0,0,0,e05da3172b0672aacb85913fe6e9f27243171a37,251197048.0,https://www.semanticscholar.org/paper/e05da3172b0672aacb85913fe6e9f27243171a37,Robotics Auton. Syst.,2022.0,45.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '80320916', 'name': 'Y. Kadokawa'}, {'authorId': '1750926460', 'name': 'Lingwei Zhu'}, {'authorId': '31991119', 'name': 'Yoshihisa Tsurumine'}, {'authorId': '3248224', 'name': 'Takamitsu Matsubara'}]",['Nara Institute of Science and Technology'],['Japan'],2022-07
2208.06946,Fangyi Yu,Fangyi Yu and Miguel Vargas Martin,Targeted Honeyword Generation with Language Models,"8 pages, 7 tables, 2 figures",,,,cs.AI cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Honeywords are fictitious passwords inserted into databases in order to identify password breaches. The major difficulty is how to produce honeywords that are difficult to distinguish from real passwords. Although the generation of honeywords has been widely investigated in the past, the majority of existing research assumes attackers have no knowledge of the users. These honeyword generating techniques (HGTs) may utterly fail if attackers exploit users' personally identifiable information (PII) and the real passwords include users' PII. In this paper, we propose to build a more secure and trustworthy authentication system that employs off-the-shelf pre-trained language models which require no further training on real passwords to produce honeywords while retaining the PII of the associated real password, therefore significantly raising the bar for attackers.   We conducted a pilot experiment in which individuals are asked to distinguish between authentic passwords and honeywords when the username is provided for GPT-3 and a tweaking technique. Results show that it is extremely difficult to distinguish the real passwords from the artifical ones for both techniques. We speculate that a larger sample size could reveal a significant difference between the two HGT techniques, favouring our proposed approach. ","[{'version': 'v1', 'created': 'Mon, 15 Aug 2022 00:06:29 GMT'}, {'version': 'v2', 'created': 'Tue, 23 Aug 2022 16:12:27 GMT'}]",2022-08-24,"[['Yu', 'Fangyi', ''], ['Martin', 'Miguel Vargas', '']]",0,1,2022-08-15,2,2,2,1,0,1,512e16b9aef6ca6cb973d734b4cc66661ea33498,251564091.0,https://www.semanticscholar.org/paper/512e16b9aef6ca6cb973d734b4cc66661ea33498,arXiv.org,2022.0,32.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Economics', 'source': 's2-fos-model'}]","[{'authorId': '2155387945', 'name': 'Fang Yu'}, {'authorId': '2110607435', 'name': 'Miguel Vargas Martin'}]",['University of Ontario Institute of Technology'],['Canada'],2022-08
2208.07084,Daniele Comi,"Daniele Comi, Dimitrios Christofidellis, Pier Francesco Piazza and
  Matteo Manica",Z-BERT-A: a zero-shot Pipeline for Unknown Intent detection,"7 pages, 3 figures, 7 tables, https://github.com/GT4SD/zberta",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Intent discovery is a fundamental task in NLP, and it is increasingly relevant for a variety of industrial applications (Quarteroni 2018). The main challenge resides in the need to identify from input utterances novel unseen in-tents. Herein, we propose Z-BERT-A, a two-stage method for intent discovery relying on a Transformer architecture (Vaswani et al. 2017; Devlin et al. 2018), fine-tuned with Adapters (Pfeiffer et al. 2020), initially trained for Natural Language Inference (NLI), and later applied for unknown in-tent classification in a zero-shot setting. In our evaluation, we firstly analyze the quality of the model after adaptive fine-tuning on known classes. Secondly, we evaluate its performance casting intent classification as an NLI task. Lastly, we test the zero-shot performance of the model on unseen classes, showing how Z-BERT-A can effectively perform in-tent discovery by generating intents that are semantically similar, if not equal, to the ground truth ones. Our experiments show how Z-BERT-A is outperforming a wide variety of baselines in two zero-shot settings: known intents classification and unseen intent discovery. The proposed pipeline holds the potential to be widely applied in a variety of application for customer care. It enables automated dynamic triage using a lightweight model that, unlike large language models, can be easily deployed and scaled in a wide variety of business scenarios. Especially when considering a setting with limited hardware availability and performance whereon-premise or low resource cloud deployments are imperative. Z-BERT-A, predicting novel intents from a single utterance, represents an innovative approach for intent discovery, enabling online generation of novel intents. The pipeline is available as an installable python package at the following link: https://github.com/GT4SD/zberta. ","[{'version': 'v1', 'created': 'Mon, 15 Aug 2022 09:27:34 GMT'}, {'version': 'v2', 'created': 'Thu, 18 Aug 2022 14:41:30 GMT'}]",2022-08-19,"[['Comi', 'Daniele', ''], ['Christofidellis', 'Dimitrios', ''], ['Piazza', 'Pier Francesco', ''], ['Manica', 'Matteo', '']]",0,0,2022-08-15,2,4,2,0,0,0,6ae2c935293cedb83dd15fad64885eac6e9eaac1,251563983.0,https://www.semanticscholar.org/paper/6ae2c935293cedb83dd15fad64885eac6e9eaac1,arXiv.org,2022.0,38.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2181500236', 'name': 'Daniele Comi'}, {'authorId': '2039675061', 'name': 'Dimitrios Christofidellis'}, {'authorId': '2027103', 'name': 'Pier Francesco Piazza'}, {'authorId': '35904689', 'name': 'Matteo Manica'}]","['IBM Research Europe', 'IBM (Italy)']",['Italy'],2022-08
2208.07097,Radostin Cholakov,Radostin Cholakov and Todor Kolev,Efficient Task-Oriented Dialogue Systems with Response Selection as an Auxiliary Task,"7 pages, 2 figures, 2 tables","In Proceedings of the 5th International Conference on Natural
  Language and Speech Processing (ICNLSP 2022), pages 12-18, Trento, Italy.
  Association for Computational Linguistics",,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The adoption of pre-trained language models in task-oriented dialogue systems has resulted in significant enhancements of their text generation abilities. However, these architectures are slow to use because of the large number of trainable parameters and can sometimes fail to generate diverse responses. To address these limitations, we propose two models with auxiliary tasks for response selection - (1) distinguishing distractors from ground truth responses and (2) distinguishing synthetic responses from ground truth labels. They achieve state-of-the-art results on the MultiWOZ 2.1 dataset with combined scores of 107.5 and 108.3 and outperform a baseline with three times more parameters. We publish reproducible code and checkpoints and discuss the effects of applying auxiliary tasks to T5-based architectures. ","[{'version': 'v1', 'created': 'Mon, 15 Aug 2022 09:59:44 GMT'}, {'version': 'v2', 'created': 'Sun, 12 Feb 2023 14:39:02 GMT'}]",2023-02-14,"[['Cholakov', 'Radostin', ''], ['Kolev', 'Todor', '']]",0,0,2022-08-15,2,2,2,1,1,0,2a2e4b5679737accbe089909855fe8852d88fa13,251564535.0,https://www.semanticscholar.org/paper/2a2e4b5679737accbe089909855fe8852d88fa13,International Conference on Natural Language and Speech Processing,2022.0,31.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2123599637', 'name': 'Radostin Cholakov'}, {'authorId': '144008252', 'name': 'T. Kolev'}]","['Obecto Ltd. Sofia, Bulgaria', 'High School of Mathematics Plovdiv, Bulgaria']",['Bulgaria'],2022-08
2208.08603,Bodin Chinthanet,"Sila Lertbanjongngam, Bodin Chinthanet, Takashi Ishio, Raula Gaikovina
  Kula, Pattara Leelaprute, Bundit Manaskasemsak, Arnon Rungsawang, Kenichi
  Matsumoto",An Empirical Evaluation of Competitive Programming AI: A Case Study of AlphaCode,"Accepted to the 16th International Workshop on Software Clones (IWSC
  2022)",,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  AlphaCode is a code generation system for assisting software developers in solving competitive programming problems using natural language problem descriptions. Despite the advantages of the code generating system, the open source community expressed concerns about practicality and data licensing. However, there is no research investigating generated codes in terms of code clone and performance. In this paper, we conduct an empirical study to find code similarities and performance differences between AlphaCode-generated codes and human codes. The results show that (i) the generated codes from AlphaCode are similar to human codes (i.e., the average maximum similarity score is 0.56) and (ii) the generated code performs on par with or worse than the human code in terms of execution time and memory usage. Moreover, AlphaCode tends to generate more similar codes to humans for low-difficulty problems (i.e., four cases have the exact same codes). It also employs excessive nested loops and unnecessary variable declarations for high-difficulty problems, which cause low performance regarding our manual investigation. The replication package is available at https:/doi.org/10.5281/zenodo.6820681 ","[{'version': 'v1', 'created': 'Thu, 18 Aug 2022 02:48:35 GMT'}, {'version': 'v2', 'created': 'Fri, 26 Aug 2022 03:53:48 GMT'}]",2022-08-29,"[['Lertbanjongngam', 'Sila', ''], ['Chinthanet', 'Bodin', ''], ['Ishio', 'Takashi', ''], ['Kula', 'Raula Gaikovina', ''], ['Leelaprute', 'Pattara', ''], ['Manaskasemsak', 'Bundit', ''], ['Rungsawang', 'Arnon', ''], ['Matsumoto', 'Kenichi', '']]",0,0,2022-08-18,2,8,1,1,0,1,9b61de7038290751377b64293baaf42f3e7cf441,251643500.0,https://www.semanticscholar.org/paper/9b61de7038290751377b64293baaf42f3e7cf441,International Workshop on Software Clones,2022.0,35.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2183276187', 'name': 'Sila Lertbanjongngam'}, {'authorId': '3409698', 'name': 'Bodin Chinthanet'}, {'authorId': '145682543', 'name': 'T. Ishio'}, {'authorId': '1680034', 'name': 'R. Kula'}, {'authorId': '1943332', 'name': 'P. Leelaprute'}, {'authorId': '2291391', 'name': 'Bundit Manaskasemsak'}, {'authorId': '2835436', 'name': 'A. Rungsawang'}, {'authorId': '2148302707', 'name': 'Kenichi Matsumoto'}]","['Kasetsart University', 'Nara Institute of Science and Technology']","['Japan', 'Thailand']",2022-08
2208.09554,Robert Wray,"James R. Kirk, Robert E. Wray, Peter Lindes, John E. Laird",Integrating Diverse Knowledge Sources for Online One-shot Learning of Novel Tasks,"20 pages, 3 figures. (Added technical appendix based on reviewer
  feedback.)",,,,cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Autonomous agents are able to draw on a wide variety of potential sources of task knowledge; however current approaches invariably focus on only one or two. Here we investigate the challenges and impact of exploiting diverse knowledge sources to learn online, in one-shot, new tasks for a simulated office mobile robot. The resulting agent, developed in the Soar cognitive architecture, uses the following sources of domain and task knowledge: interaction with the environment, task execution and search knowledge, human natural language instruction, and responses retrieved from a large language model (GPT-3). We explore the distinct contributions of these knowledge sources and evaluate the performance of different combinations in terms of learning correct task knowledge and human workload. Results show that an agent's online integration of diverse knowledge sources improves one-shot task learning overall, reducing human feedback needed for rapid and reliable task learning. ","[{'version': 'v1', 'created': 'Fri, 19 Aug 2022 21:53:15 GMT'}, {'version': 'v2', 'created': 'Fri, 3 Feb 2023 02:55:43 GMT'}, {'version': 'v3', 'created': 'Mon, 15 May 2023 16:34:58 GMT'}]",2023-05-16,"[['Kirk', 'James R.', ''], ['Wray', 'Robert E.', ''], ['Lindes', 'Peter', ''], ['Laird', 'John E.', '']]",0,1,2022-08-19,3,4,1,1,0,1,fa009ee01cbf4843ee505063f172c87a66cf7c12,256597818.0,https://www.semanticscholar.org/paper/fa009ee01cbf4843ee505063f172c87a66cf7c12,,2022.0,29.0,4.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145845123', 'name': 'James R. Kirk'}, {'authorId': '1721974', 'name': 'R. Wray'}, {'authorId': '2780534', 'name': 'Peter Lindes'}, {'authorId': '1715438', 'name': 'J. Laird'}]",['IQM (Finland)'],['Finland'],2022-08
2208.11057,Emile van Krieken,"Dimitrios Alivanistos, Selene B\'aez Santamar\'ia, Michael Cochez,
  Jan-Christoph Kalo, Emile van Krieken, Thiviyan Thanapalasingam",Prompting as Probing: Using Language Models for Knowledge Base Construction,"Published in LM-KBC 22: Knowledge Base Construction from Pre-trained
  Language Models, Challenge at ISWC 2022. 12+12 pages",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language Models (LMs) have proven to be useful in various downstream applications, such as summarisation, translation, question answering and text classification. LMs are becoming increasingly important tools in Artificial Intelligence, because of the vast quantity of information they can store. In this work, we present ProP (Prompting as Probing), which utilizes GPT-3, a large Language Model originally proposed by OpenAI in 2020, to perform the task of Knowledge Base Construction (KBC). ProP implements a multi-step approach that combines a variety of prompting techniques to achieve this. Our results show that manual prompt curation is essential, that the LM must be encouraged to give answer sets of variable lengths, in particular including empty answer sets, that true/false questions are a useful device to increase precision on suggestions generated by the LM, that the size of the LM is a crucial factor, and that a dictionary of entity aliases improves the LM score. Our evaluation study indicates that these proposed techniques can substantially enhance the quality of the final predictions: ProP won track 2 of the LM-KBC competition, outperforming the baseline by 36.4 percentage points. Our implementation is available on https://github.com/HEmile/iswc-challenge. ","[{'version': 'v1', 'created': 'Tue, 23 Aug 2022 16:03:50 GMT'}, {'version': 'v2', 'created': 'Thu, 25 Aug 2022 09:49:34 GMT'}, {'version': 'v3', 'created': 'Mon, 19 Jun 2023 15:06:46 GMT'}]",2023-06-21,"[['Alivanistos', 'Dimitrios', ''], ['Santamaría', 'Selene Báez', ''], ['Cochez', 'Michael', ''], ['Kalo', 'Jan-Christoph', ''], ['van Krieken', 'Emile', ''], ['Thanapalasingam', 'Thiviyan', '']]",0,1,2022-08-23,3,6,2,1,0,1,ddc9aeac18638575bbb90ede4c6829ec15c2947e,251741004.0,https://www.semanticscholar.org/paper/ddc9aeac18638575bbb90ede4c6829ec15c2947e,arXiv.org,2022.0,53.0,23.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '133811740', 'name': 'Dimitrios Alivanistos'}, {'authorId': '2093917218', 'name': ""Selene B'aez Santamar'ia""}, {'authorId': '1708906', 'name': 'Michael Cochez'}, {'authorId': '3245041', 'name': 'Jan-Christoph Kalo'}, {'authorId': '67007296', 'name': 'Emile van Krieken'}, {'authorId': '27103994', 'name': 'Thiviyan Thanapalasingam'}]","['Universiteit van Amsterdam 4 Discovery Lab, Elsevier, The Netherlands', 'Vrije Universiteit Amsterdam', 'Huawei Technologies (Netherlands)']",['Netherlands'],2022-08
2208.11445,Mirelle Bueno,"Mirelle Bueno, Carlos Gemmell, Jeffrey Dalton, Roberto Lotufo, Rodrigo
  Nogueira",Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The ability to extrapolate, i.e., to make predictions on sequences that are longer than those presented as training examples, is a challenging problem for current deep learning models. Recent work shows that this limitation persists in state-of-the-art Transformer-based models. Most solutions to this problem use specific architectures or training methods that do not generalize to other tasks. We demonstrate that large language models can succeed in extrapolation without modifying their architecture or training procedure. Our experimental results show that generating step-by-step rationales and introducing marker tokens are both required for effective extrapolation. First, we induce a language model to produce step-by-step rationales before outputting the answer to effectively communicate the task to the model. However, as sequences become longer, we find that current models struggle to keep track of token positions. To address this issue, we interleave output tokens with markup tokens that act as explicit positional and counting symbols. Our findings show how these two complementary approaches enable remarkable sequence extrapolation and highlight a limitation of current architectures to effectively generalize without explicit surface form guidance. Code available at https://github.com/MirelleB/induced-rationales-markup-tokens ","[{'version': 'v1', 'created': 'Wed, 24 Aug 2022 11:25:27 GMT'}, {'version': 'v2', 'created': 'Wed, 12 Oct 2022 14:34:06 GMT'}, {'version': 'v3', 'created': 'Mon, 28 Nov 2022 15:46:38 GMT'}]",2022-11-29,"[['Bueno', 'Mirelle', ''], ['Gemmell', 'Carlos', ''], ['Dalton', 'Jeffrey', ''], ['Lotufo', 'Roberto', ''], ['Nogueira', 'Rodrigo', '']]",0,0,2022-08-24,3,5,1,0,0,0,108c25905be36b2a7a0fc7256ac314985ecd9699,251765206.0,https://www.semanticscholar.org/paper/108c25905be36b2a7a0fc7256ac314985ecd9699,MATHNLP,2022.0,66.0,8.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51107945', 'name': 'M. Bueno'}, {'authorId': '2182518941', 'name': 'Carlos Gemmel'}, {'authorId': '49694325', 'name': 'Jeffrey Stephen Dalton'}, {'authorId': '1809633', 'name': 'R. Lotufo'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}]","['Universidade Estadual de Campinas (UNICAMP)', 'University of Glasgow']","['United Kingdom', 'Brazil']",2022-08
2208.11701,Jinge Wu,"Jinge Wu, Rowena Smith and Honghan Wu",Ontology-Driven Self-Supervision for Adverse Childhood Experiences Identification Using Social Media Datasets,arXiv admin note: text overlap with arXiv:2208.11466,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Adverse Childhood Experiences (ACEs) are defined as a collection of highly stressful, and potentially traumatic, events or circumstances that occur throughout childhood and/or adolescence. They have been shown to be associated with increased risks of mental health diseases or other abnormal behaviours in later lives. However, the identification of ACEs from textual data with Natural Language Processing (NLP) is challenging because (a) there are no NLP ready ACE ontologies; (b) there are few resources available for machine learning, necessitating the data annotation from clinical experts; (c) costly annotations by domain experts and large number of documents for supporting large machine learning models. In this paper, we present an ontology-driven self-supervised approach (derive concept embeddings using an auto-encoder from baseline NLP results) for producing a publicly available resource that would support large-scale machine learning (e.g., training transformer based large language models) on social media corpus. This resource as well as the proposed approach are aimed to facilitate the community in training transferable NLP models for effectively surfacing ACEs in low-resource scenarios like NLP on clinical notes within Electronic Health Records. The resource including a list of ACE ontology terms, ACE concept embeddings and the NLP annotated corpus is available at https://github.com/knowlab/ACE-NLP. ","[{'version': 'v1', 'created': 'Wed, 24 Aug 2022 12:23:01 GMT'}]",2022-08-26,"[['Wu', 'Jinge', ''], ['Smith', 'Rowena', ''], ['Wu', 'Honghan', '']]",0,0,2022-08-24,1,3,2,0,0,0,cae30d5914fcf473a7a7169dcb8dcff881b8910d,251800138.0,https://www.semanticscholar.org/paper/cae30d5914fcf473a7a7169dcb8dcff881b8910d,Proceedings of the 1st Workshop on Scarce Data in Artificial Intelligence for Healthcare,2022.0,9.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2182815661', 'name': 'Jinge Wu'}, {'authorId': '153691283', 'name': 'Rowena Smith'}, {'authorId': '1715859', 'name': 'Honghan Wu'}]","['University College London', 'University of Edinburgh']",['United Kingdom'],2022-08
2208.11981,Nigel Collier,"Nigel H. Collier, Fangyu Liu and Ehsan Shareghi",On Reality and the Limits of Language Data: Aligning LLMs with Human Norms,"9 pages; data available, see
  https://sites.google.com/site/nhcollier/projects/art",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Recent advancements in Large Language Models (LLMs) harness linguistic associations in vast natural language data for practical applications. However, their ability to understand the physical world using only language data remains a question. After reviewing existing protocols, we explore this question using a novel and tightly controlled reasoning test (ART) and compare human norms against versions of GPT-3. Our findings highlight the categories of common-sense relations models that could learn directly from data and areas of weakness. GPT-3 offers evidence for verbal reasoning on a par with human subjects for several relations including Synonymy, Antonymy, and Default inheritance, Without reinforcement learning from human judgements, it appears GPT-3 performs at the lower end of the reference interval for Has-part and Contained-in. Weaknesses were observed also in affordance characteristics through Necessary-quality, Order-of-size and Order-of-intensity. Combining LLMs with symbolic world grounding is a promising direction to address associative learning. ","[{'version': 'v1', 'created': 'Thu, 25 Aug 2022 10:21:23 GMT'}, {'version': 'v2', 'created': 'Tue, 9 May 2023 12:36:54 GMT'}]",2023-05-10,"[['Collier', 'Nigel H.', ''], ['Liu', 'Fangyu', ''], ['Shareghi', 'Ehsan', '']]",0,1,2022-08-25,2,3,3,1,0,1,cdbfd6201296db1f7e82421c0de34f12fd5294e9,260466183.0,https://www.semanticscholar.org/paper/cdbfd6201296db1f7e82421c0de34f12fd5294e9,,2022.0,66.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50638196', 'name': 'Nigel Collier'}, {'authorId': '144097210', 'name': 'Fangyu Liu'}, {'authorId': '2888926', 'name': 'Ehsan Shareghi'}]","['Monash University', 'University of Cambridge']","['United Kingdom', 'Australia']",2022-08
2208.12097,Leon Derczynski,"Manuel R. Ciosici, Leon Derczynski",Training a T5 Using Lab-sized Resources,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Training large neural language models on large datasets is resource- and time-intensive. These requirements create a barrier to entry, where those with fewer resources cannot build competitive models. This paper presents various techniques for making it possible to (a) train a large language model using resources that a modest research lab might have, and (b) train it in a reasonable amount of time. We provide concrete recommendations for practitioners, which we illustrate with a case study: a T5 model for Danish, the first for this language. ","[{'version': 'v1', 'created': 'Thu, 25 Aug 2022 13:55:16 GMT'}]",2022-08-26,"[['Ciosici', 'Manuel R.', ''], ['Derczynski', 'Leon', '']]",0,0,2022-08-25,1,2,1,1,1,0,e4437293a703fcf282bf1b38bf7900ed8ca711bb,251800265.0,https://www.semanticscholar.org/paper/e4437293a703fcf282bf1b38bf7900ed8ca711bb,arXiv.org,2022.0,28.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3451493', 'name': 'Manuel R. Ciosici'}, {'authorId': '113320522', 'name': 'Leon Derczynski'}]",['University of the Sunshine Coast'],['Australia'],2022-08
2208.14111,Haishuo Fang,"Haishuo Fang, Ji-Ung Lee, Nafise Sadat Moosavi, Iryna Gurevych",Transformers with Learnable Activation Functions,Accepted by EACL2023 findings,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Activation functions can have a significant impact on reducing the topological complexity of input data and therefore improve the performance of the model. Selecting a suitable activation function is an essential step in neural model design. However, the choice of activation function is seldom discussed or explored in Transformer-based language models. Their activation functions are chosen beforehand and then remain fixed from pre-training to fine-tuning. As a result, the inductive biases they imposed on models cannot be adjusted during this long life cycle. Moreover, subsequently developed models (e.g., RoBERTa, BART, and GPT-3) often follow up prior work (e.g., BERT) to use the same activation function without justification. In this paper, we investigate the effectiveness of using Rational Activation Function (RAF), a learnable activation function, in the Transformer architecture. In contrast to conventional, predefined activation functions, RAFs can adaptively learn optimal activation functions during training according to input data. Our experiments show the RAF-based Transformer (RAFT) achieves a lower validation perplexity than a vanilla BERT with the GELU function. We further evaluate RAFT on downstream tasks in low- and full-data settings. Our results show that RAFT outperforms the counterpart model across the majority of tasks and settings. For instance, RAFT outperforms vanilla BERT on the GLUE benchmark by 5.71 points on average in low-data scenario (where 100 training examples are available) and by 2.05 points on SQuAD in full-data setting. Analysis of the shapes of learned RAFs further unveils that they substantially vary between different layers of the pre-trained model and mostly look very different from conventional activation functions. RAFT opens a new research direction for analyzing and interpreting pre-trained models according to the learned activation functions. ","[{'version': 'v1', 'created': 'Tue, 30 Aug 2022 09:47:31 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Sep 2022 07:55:10 GMT'}, {'version': 'v3', 'created': 'Tue, 14 Feb 2023 13:06:16 GMT'}]",2023-02-15,"[['Fang', 'Haishuo', ''], ['Lee', 'Ji-Ung', ''], ['Moosavi', 'Nafise Sadat', ''], ['Gurevych', 'Iryna', '']]",0,1,2022-08-30,3,4,1,1,0,1,8cf974fd3973900c0598730ee5d3617900ac8c3d,251929336.0,https://www.semanticscholar.org/paper/8cf974fd3973900c0598730ee5d3617900ac8c3d,Findings,2022.0,75.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2183345434', 'name': 'Haishuo Fang'}, {'authorId': '2108605329', 'name': 'Ji-Ung Lee'}, {'authorId': '2182290', 'name': 'N. Moosavi'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}]","['University of Sheffield', 'Technical University of Darmstadt']","['Germany', 'United Kingdom']",2022-08
2209.00445,Adi Simhi,Adi Simhi and Shaul Markovitch,Interpreting Embedding Spaces by Conceptualization,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  One of the main methods for semantic interpretation of text is mapping it into a vector in some embedding space. Such vectors can then be used for a variety of text processing tasks. Recently, most embedding spaces are a product of training large language models. One major drawback of this type of representation is its incomprehensibility to humans. Understanding the embedding space is crucial for several important needs, including the need to explain the decision of a system that uses the embedding, the need to debug the embedding method and compare it to alternatives, and the need to detect biases hidden in the model. In this paper, we present a novel method of transforming any embedding space into a comprehensible conceptual space. We first present an algorithm for deriving a conceptual space with dynamic on-demand granularity. We then show a method for transferring any vector in the original incomprehensible space to an understandable vector in the conceptual space. We combine human tests with cross-model tests to show that the conceptualized vectors indeed represent the semantics of the original vectors. We also show how the conceptualized vectors can be used for various tasks including identifying weaknesses in the semantics underlying the original spaces and differences in the semantics of alternative models. ","[{'version': 'v1', 'created': 'Mon, 22 Aug 2022 15:32:17 GMT'}, {'version': 'v2', 'created': 'Sun, 19 Feb 2023 13:06:00 GMT'}]",2023-02-21,"[['Simhi', 'Adi', ''], ['Markovitch', 'Shaul', '']]",0,0,2022-08-22,2,2,3,0,0,0,3961d7525852c26ec5928323a54fc3a6a036110f,251979600.0,https://www.semanticscholar.org/paper/3961d7525852c26ec5928323a54fc3a6a036110f,arXiv.org,2022.0,55.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2183598223', 'name': 'Adi Simhi'}, {'authorId': '2309269', 'name': 'Shaul Markovitch'}]","['Technion – Israel Institute of Technology', 'The Henry and Marilyn Taub Faculty of Computer Science']",['Israel'],2022-08
2209.02235,Junaed Younus Khan,"Junaed Younus Khan, Gias Uddin",Automatic Code Documentation Generation Using GPT-3,"Accepted in IEEE/ACM International Conference on Automated Software
  Engineering (ASE 2022) - NIER",,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Source code documentation is an important artifact for efficient software development. Code documentation could greatly benefit from automation since manual documentation is often labouring, resource and time-intensive. In this paper, we employed Codex for automatic code documentation creation. Codex is a GPT-3 based model pre-trained on both natural and programming languages. We find that Codex outperforms existing techniques even with basic settings like one-shot learning (i.e., providing only one example for training). Codex achieves an overall BLEU score of 20.6 for six different programming languages (11.2% improvement over earlier state-of-the-art techniques). Thus, Codex shows promise and warrants in-depth future studies for automatic code documentation generation to support diverse development tasks. ","[{'version': 'v1', 'created': 'Tue, 6 Sep 2022 06:10:03 GMT'}]",2022-09-07,"[['Khan', 'Junaed Younus', ''], ['Uddin', 'Gias', '']]",0,1,2022-09-06,1,2,1,2,0,2,9360390b02b9a09ece9a2486055b17e18dc5d3f6,252089836.0,https://www.semanticscholar.org/paper/9360390b02b9a09ece9a2486055b17e18dc5d3f6,International Conference on Automated Software Engineering,2022.0,60.0,14.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '119233244', 'name': 'Junaed Younus Khan'}, {'authorId': '28334651', 'name': 'Gias Uddin'}]",['University of Calgary'],['Canada'],2022-09
2209.03118,Alexei Grinbaum,Alexei Grinbaum and Laurynas Adomaitis,The Ethical Need for Watermarks in Machine-Generated Language,,,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Watermarks should be introduced in the natural language outputs of AI systems in order to maintain the distinction between human and machine-generated text. The ethical imperative to not blur this distinction arises from the asemantic nature of large language models and from human projections of emotional and cognitive states on machines, possibly leading to manipulation, spreading falsehoods or emotional distress. Enforcing this distinction requires unintrusive, yet easily accessible marks of the machine origin. We propose to implement a code based on equidistant letter sequences. While no such code exists in human-written texts, its appearance in machine-generated ones would prove helpful for ethical reasons. ","[{'version': 'v1', 'created': 'Wed, 7 Sep 2022 13:09:44 GMT'}]",2022-09-08,"[['Grinbaum', 'Alexei', ''], ['Adomaitis', 'Laurynas', '']]",0,0,2022-09-07,1,2,2,0,0,0,01bcdf931e38f32f15562a178b7abd8233386ab1,252110611.0,https://www.semanticscholar.org/paper/01bcdf931e38f32f15562a178b7abd8233386ab1,arXiv.org,2022.0,30.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40371965', 'name': 'A. Grinbaum'}, {'authorId': '108814448', 'name': 'Laurynas Adomaitis'}]",['CEA Saclay'],['France'],2022-09
2209.03891,Martin Faj\v{c}\'ik,"Martin Fajcik, Muskaan Singh, Juan Zuluaga-Gomez, Esa\'u
  Villatoro-Tello, Sergio Burdisso, Petr Motlicek, Pavel Smrz",IDIAPers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal Triplets via Pre-trained Autoregressive Language Model,Camera-ready for CASE@EMNLP,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In this paper, we describe our shared task submissions for Subtask 2 in CASE-2022, Event Causality Identification with Casual News Corpus. The challenge focused on the automatic detection of all cause-effect-signal spans present in the sentence from news-media. We detect cause-effect-signal spans in a sentence using T5 -- a pre-trained autoregressive language model. We iteratively identify all cause-effect-signal span triplets, always conditioning the prediction of the next triplet on the previously predicted ones. To predict the triplet itself, we consider different causal relationships such as cause$\rightarrow$effect$\rightarrow$signal. Each triplet component is generated via a language model conditioned on the sentence, the previous parts of the current triplet, and previously predicted triplets. Despite training on an extremely small dataset of 160 samples, our approach achieved competitive performance, being placed second in the competition. Furthermore, we show that assuming either cause$\rightarrow$effect or effect$\rightarrow$cause order achieves similar results. ","[{'version': 'v1', 'created': 'Thu, 8 Sep 2022 15:54:25 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Oct 2022 07:34:43 GMT'}]",2022-10-21,"[['Fajcik', 'Martin', ''], ['Singh', 'Muskaan', ''], ['Zuluaga-Gomez', 'Juan', ''], ['Villatoro-Tello', 'Esaú', ''], ['Burdisso', 'Sergio', ''], ['Motlicek', 'Petr', ''], ['Smrz', 'Pavel', '']]",0,0,2022-09-08,2,7,2,1,1,0,064a58c8436fbf73141309b8b8d8aa52b64213b3,252118711.0,https://www.semanticscholar.org/paper/064a58c8436fbf73141309b8b8d8aa52b64213b3,CASE,2022.0,59.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1388781179', 'name': 'Martin Fajcik'}, {'authorId': '2110413453', 'name': 'Muskaan Singh'}, {'authorId': '1390094355', 'name': 'Juan Zuluaga-Gómez'}, {'authorId': '1398324221', 'name': 'Esaú Villatoro-Tello'}, {'authorId': '51168007', 'name': 'S. Burdisso'}, {'authorId': '2745667', 'name': 'P. Motlícek'}, {'authorId': '143917717', 'name': 'P. Smrz'}]","['École Polytechnique Fédérale de Lausanne', 'Brno University of Technology', 'Idiap Research Institute', 'Universidad Autónoma Metropolitana', 'National University of San Luis']","['Mexico', 'Czechia', 'Argentina', 'Switzerland']",2022-09
2209.07048,Yue Liu,"Yue Liu and Chakkrit Tantithamthavorn and Yonghui Liu and Patanamon
  Thongtanunam and Li Li",AutoUpdate: Automatically Recommend Code Updates for Android Apps,Under review at a SE journal,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Android has become the predominant smartphone operating system, with a rapidly evolving ecosystem that requires app developers to frequently update their apps to maintain quality, security, and compatibility. While deep learning has made significant strides in various software engineering tasks, including automated code updates, existing methods are not specifically tailored for Android apps, and the potential of pre-trained Language Models of Code (CodeLMs) for updating Android app code remains unexplored. In this paper, we present the first comprehensive evaluation of state-of-the-art CodeLMs, including CodeT5, CodeBERT, CodeGPT, and UniXcoder, for recommending code updates in Android applications. To facilitate this evaluation, we curate a unique dataset of paired updated methods from 3,195 Android apps published on Google Play and hosted on GitHub between 2008 and 2022. Our findings demonstrate that pre-trained CodeLMs outperform traditional approaches, achieving a higher accuracy ranging from 190% to 385% under a realistic time-wise evaluation scenario. Among the CodeLMs, CodeT5 consistently exhibits superior performance across most code update types. Furthermore, we examine the impact of update types, evaluation scenarios, method size, and update size on the performance of CodeLMs, revealing areas for future research to improve temporal adaptability and generalization capabilities. ","[{'version': 'v1', 'created': 'Thu, 15 Sep 2022 05:07:25 GMT'}, {'version': 'v2', 'created': 'Wed, 10 May 2023 15:14:42 GMT'}]",2023-05-11,"[['Liu', 'Yue', ''], ['Tantithamthavorn', 'Chakkrit', ''], ['Liu', 'Yonghui', ''], ['Thongtanunam', 'Patanamon', ''], ['Li', 'Li', '']]",0,1,2022-09-15,2,5,1,0,0,0,389ee3be18d4f02bd2102f0b6861e2c88bedd1c2,252280642.0,https://www.semanticscholar.org/paper/389ee3be18d4f02bd2102f0b6861e2c88bedd1c2,arXiv.org,2022.0,96.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '100576986', 'name': 'Yue Liu'}, {'authorId': '1957122', 'name': 'C. Tantithamthavorn'}, {'authorId': '2156610853', 'name': 'Yonghui Liu'}, {'authorId': '2352093', 'name': 'Patanamon Thongtanunam'}, {'authorId': '2156059416', 'name': 'Li Li'}]","['Monash University', 'University of Melbourne']",['Australia'],2022-09
2209.07133,Dennis Gross,"Dennis Gross, Nils Jansen, Sebastian Junges, Guillermo A. Perez",COOL-MC: A Comprehensive Tool for Reinforcement Learning and Model Checking,,,,,cs.LG cs.LO,http://creativecommons.org/publicdomain/zero/1.0/,"  This paper presents COOL-MC, a tool that integrates state-of-the-art reinforcement learning (RL) and model checking. Specifically, the tool builds upon the OpenAI gym and the probabilistic model checker Storm. COOL-MC provides the following features: (1) a simulator to train RL policies in the OpenAI gym for Markov decision processes (MDPs) that are defined as input for Storm, (2) a new model builder for Storm, which uses callback functions to verify (neural network) RL policies, (3) formal abstractions that relate models and policies specified in OpenAI gym or Storm, and (4) algorithms to obtain bounds on the performance of so-called permissive policies. We describe the components and architecture of COOL-MC and demonstrate its features on multiple benchmark environments. ","[{'version': 'v1', 'created': 'Thu, 15 Sep 2022 08:25:43 GMT'}]",2022-09-16,"[['Gross', 'Dennis', ''], ['Jansen', 'Nils', ''], ['Junges', 'Sebastian', ''], ['Perez', 'Guillermo A.', '']]",0,0,2022-09-15,1,4,2,0,0,0,38c653abfa5b26a16b1371df98f67af5cf444ec5,252280380.0,https://www.semanticscholar.org/paper/38c653abfa5b26a16b1371df98f67af5cf444ec5,"International Symposium on Software Engineering: Theories, Tools, and Applications",2022.0,40.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067557029', 'name': 'Dennis Gross'}, {'authorId': '35252898', 'name': 'N. Jansen'}, {'authorId': '1963542', 'name': 'Sebastian Junges'}, {'authorId': '145275189', 'name': 'G. Pérez'}]","['Radboud University Nijmegen', 'University of Antwerp']","['Belgium', 'The Netherlands']",2022-09
2209.08372,Surya Prakash Sahu,"Surya Prakash Sahu, Madhurima Mandal, Shikhar Bharadwaj, Aditya
  Kanade, Petros Maniatis, Shirish Shevade",CodeQueries: A Dataset of Semantic Queries over Code,,,,,cs.SE cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Developers often have questions about semantic aspects of code they are working on, e.g., ""Is there a class whose parent classes declare a conflicting attribute?"". Answering them requires understanding code semantics such as attributes and inheritance relation of classes. An answer to such a question should identify code spans constituting the answer (e.g., the declaration of the subclass) as well as supporting facts (e.g., the definitions of the conflicting attributes). The existing work on question-answering over code has considered yes/no questions or method-level context. We contribute a labeled dataset, called CodeQueries, of semantic queries over Python code. Compared to the existing datasets, in CodeQueries, the queries are about code semantics, the context is file level and the answers are code spans. We curate the dataset based on queries supported by a widely-used static analysis tool, CodeQL, and include both positive and negative examples, and queries requiring single-hop and multi-hop reasoning.   To assess the value of our dataset, we evaluate baseline neural approaches. We study a large language model (GPT3.5-Turbo) in zero-shot and few-shot settings on a subset of CodeQueries. We also evaluate a BERT style model (CuBERT) with fine-tuning. We find that these models achieve limited success on CodeQueries. CodeQueries is thus a challenging dataset to test the ability of neural models, to understand code semantics, in the extractive question-answering setting. ","[{'version': 'v1', 'created': 'Sat, 17 Sep 2022 17:09:30 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Jul 2023 11:01:45 GMT'}]",2023-07-17,"[['Sahu', 'Surya Prakash', ''], ['Mandal', 'Madhurima', ''], ['Bharadwaj', 'Shikhar', ''], ['Kanade', 'Aditya', ''], ['Maniatis', 'Petros', ''], ['Shevade', 'Shirish', '']]",0,1,2022-09-17,2,6,2,1,0,1,cd937849a314b3e5eb4862a3b55aa823811a5996,259924447.0,https://www.semanticscholar.org/paper/cd937849a314b3e5eb4862a3b55aa823811a5996,,2022.0,49.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2185411106', 'name': 'Surya Prakash Sahu'}, {'authorId': '2185411327', 'name': 'Madhurima Mandal'}, {'authorId': '2136381352', 'name': 'Shikhar Bharadwaj'}, {'authorId': '2594759', 'name': 'Aditya Kanade'}, {'authorId': '2286904', 'name': 'Petros Maniatis'}, {'authorId': '1772326', 'name': 'S. Shevade'}]","['Indian Institute of Science Bangalore', 'Microsoft']",['India'],2022-09
2209.08789,Muhammad Haris,"Muhammad Haris, Markus Stocker, S\""oren Auer",Persistent Identification and Interlinking of FAIR Scholarly Knowledge,,,10.5281/zenodo.6912480,,cs.DL,http://creativecommons.org/licenses/by/4.0/,"  We leverage the Open Research Knowledge Graph - a scholarly infrastructure that supports the creation, curation, and reuse of structured, semantic scholarly knowledge - and present an approach for persistent identification of FAIR scholarly knowledge. We propose a DOI-based persistent identification of ORKG Papers, which are machine-actionable descriptions of the essential information published in scholarly articles. This enables the citability of FAIR scholarly knowledge and its discovery in global scholarly communication infrastructures (e.g., DataCite, OpenAIRE, and ORCID). While publishing, the state of the ORKG Paper is saved and cannot be further edited. To allow for updating published versions, ORKG supports creating new versions, which are linked in provenance chains. We demonstrate the linking of FAIR scholarly knowledge with digital artefacts (articles), agents (researchers) and other objects (organizations). We persistently identify FAIR scholarly knowledge (namely, ORKG Papers and ORKG Comparisons as collections of ORKG Papers) by leveraging DataCite services. Given the existing interoperability between DataCite, Crossref, OpenAIRE and ORCID, sharing metadata with DataCite ensures global findability of FAIR scholarly knowledge in scholarly communication infrastructures. ","[{'version': 'v1', 'created': 'Mon, 19 Sep 2022 06:44:23 GMT'}]",2022-09-20,"[['Haris', 'Muhammad', ''], ['Stocker', 'Markus', ''], ['Auer', 'Sören', '']]",0,0,2022-09-19,1,3,1,0,0,0,acf382c44e8fed136fc413007211d7609fdc82a9,252367727.0,https://www.semanticscholar.org/paper/acf382c44e8fed136fc413007211d7609fdc82a9,arXiv.org,2022.0,17.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2065376009', 'name': 'Muhammad Haris'}, {'authorId': '153237136', 'name': 'M. Stocker'}, {'authorId': '2265900042', 'name': 'Sören Auer'}]",['Leibniz University Hannover'],['Germany'],2022-09
2209.08966,Michiel van der Meer,"Michiel van der Meer, Myrthe Reuver, Urja Khurana, Lea Krause, Selene
  B\'aez Santamar\'ia",Will It Blend? Mixing Training Paradigms & Prompting for Argument Quality Prediction,Accepted at the 9th Workshop on Argument Mining (2022),,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper describes our contributions to the Shared Task of the 9th Workshop on Argument Mining (2022). Our approach uses Large Language Models for the task of Argument Quality Prediction. We perform prompt engineering using GPT-3, and also investigate the training paradigms multi-task learning, contrastive learning, and intermediate-task training. We find that a mixed prediction setup outperforms single models. Prompting GPT-3 works best for predicting argument validity, and argument novelty is best estimated by a model trained using all three training paradigms. ","[{'version': 'v1', 'created': 'Mon, 19 Sep 2022 12:34:46 GMT'}, {'version': 'v2', 'created': 'Wed, 5 Oct 2022 08:43:06 GMT'}]",2022-10-06,"[['van der Meer', 'Michiel', ''], ['Reuver', 'Myrthe', ''], ['Khurana', 'Urja', ''], ['Krause', 'Lea', ''], ['Santamaría', 'Selene Báez', '']]",0,1,2022-09-19,2,5,2,1,0,1,eda36cdf6dbe28624bfad6482ca8e1575ab76d99,252367427.0,https://www.semanticscholar.org/paper/eda36cdf6dbe28624bfad6482ca8e1575ab76d99,Workshop on Argument Mining,2022.0,38.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40418436', 'name': 'Michiel van der Meer'}, {'authorId': '2081814526', 'name': 'Myrthe Reuver'}, {'authorId': '2066659266', 'name': 'Urja Khurana'}, {'authorId': '2047923813', 'name': 'Lea Krause'}, {'authorId': '2093917218', 'name': ""Selene B'aez Santamar'ia""}]","['Leiden University', 'Vrije Universiteit Amsterdam']",['Netherlands'],2022-09
2209.10335,Vinitra Swamy,"Thiemo Wambsganss, Vinitra Swamy, Roman Rietsche, Tanja K\""aser",Bias at a Second Glance: A Deep Dive into Bias for German Educational Peer-Review Data Modeling,"Accepted as a full paper at COLING 2022: The 29th International
  Conference on Computational Linguistics, 12-17 of October 2022, Gyeongju,
  Republic of Korea",,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Natural Language Processing (NLP) has become increasingly utilized to provide adaptivity in educational applications. However, recent research has highlighted a variety of biases in pre-trained language models. While existing studies investigate bias in different domains, they are limited in addressing fine-grained analysis on educational and multilingual corpora. In this work, we analyze bias across text and through multiple architectures on a corpus of 9,165 German peer-reviews collected from university students over five years. Notably, our corpus includes labels such as helpfulness, quality, and critical aspect ratings from the peer-review recipient as well as demographic attributes. We conduct a Word Embedding Association Test (WEAT) analysis on (1) our collected corpus in connection with the clustered labels, (2) the most common pre-trained German language models (T5, BERT, and GPT-2) and GloVe embeddings, and (3) the language models after fine-tuning on our collected data-set. In contrast to our initial expectations, we found that our collected corpus does not reveal many biases in the co-occurrence analysis or in the GloVe embeddings. However, the pre-trained German language models find substantial conceptual, racial, and gender bias and have significant changes in bias across conceptual and racial axes during fine-tuning on the peer-review data. With our research, we aim to contribute to the fourth UN sustainability goal (quality education) with a novel dataset, an understanding of biases in natural language education data, and the potential harms of not counteracting biases in language models for educational tasks. ","[{'version': 'v1', 'created': 'Wed, 21 Sep 2022 13:08:16 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Sep 2022 13:08:04 GMT'}]",2022-09-23,"[['Wambsganss', 'Thiemo', ''], ['Swamy', 'Vinitra', ''], ['Rietsche', 'Roman', ''], ['Käser', 'Tanja', '']]",0,1,2022-09-21,2,4,2,2,2,0,bbe5f2ceb7b1d69a5395fd1642910b82217d96e7,252407674.0,https://www.semanticscholar.org/paper/bbe5f2ceb7b1d69a5395fd1642910b82217d96e7,International Conference on Computational Linguistics,2022.0,63.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '94398251', 'name': 'Thiemo Wambsganss'}, {'authorId': '50822485', 'name': 'Vinitra Swamy'}, {'authorId': '9486227', 'name': 'Roman Rietsche'}, {'authorId': '2430247', 'name': 'Tanja Käser'}]","['École Polytechnique Fédérale de Lausanne', 'University of St. Gallen']",['Switzerland'],2022-09
2209.10447,Andr\'e Correia,Andr\'e Correia and Lu\'is A. Alexandre,Hierarchical Decision Transformer,,,,,cs.LG cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Sequence models in reinforcement learning require task knowledge to estimate the task policy. This paper presents a hierarchical algorithm for learning a sequence model from demonstrations. The high-level mechanism guides the low-level controller through the task by selecting sub-goals for the latter to reach. This sequence replaces the returns-to-go of previous methods, improving its performance overall, especially in tasks with longer episodes and scarcer rewards. We validate our method in multiple tasks of OpenAIGym, D4RL and RoboMimic benchmarks. Our method outperforms the baselines in eight out of ten tasks of varied horizons and reward frequencies without prior task knowledge, showing the advantages of the hierarchical model approach for learning from demonstrations using a sequence model. ","[{'version': 'v1', 'created': 'Wed, 21 Sep 2022 15:48:40 GMT'}]",2022-09-22,"[['Correia', 'André', ''], ['Alexandre', 'Luís A.', '']]",0,0,2022-09-21,1,2,2,0,0,0,7b50825e62a207ac85e3d568730436d972f31597,252408516.0,https://www.semanticscholar.org/paper/7b50825e62a207ac85e3d568730436d972f31597,arXiv.org,2022.0,33.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2054951003', 'name': 'André Rosa de Sousa Porfírio Correia'}, {'authorId': '152738606', 'name': 'L. Alexandre'}]",['University of Beira Interior'],['Portugal'],2022-09
2209.10797,Seongmin Hong,"Seongmin Hong, Seungjae Moon, Junsoo Kim, Sungjae Lee, Minsub Kim,
  Dongsoo Lee, Joo-Young Kim",DFX: A Low-latency Multi-FPGA Appliance for Accelerating Transformer-based Text Generation,Extension of HOTCHIPS 2022 and accepted in MICRO 2022,,,,eess.SY cs.AR cs.LG cs.SY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Transformer is a deep learning language model widely used for natural language processing (NLP) services in datacenters. Among transformer models, Generative Pre-trained Transformer (GPT) has achieved remarkable performance in text generation, or natural language generation (NLG), which needs the processing of a large input context in the summarization stage, followed by the generation stage that produces a single word at a time. The conventional platforms such as GPU are specialized for the parallel processing of large inputs in the summarization stage, but their performance significantly degrades in the generation stage due to its sequential characteristic. Therefore, an efficient hardware platform is required to address the high latency caused by the sequential characteristic of text generation.   In this paper, we present DFX, a multi-FPGA acceleration appliance that executes GPT-2 model inference end-to-end with low latency and high throughput in both summarization and generation stages. DFX uses model parallelism and optimized dataflow that is model-and-hardware-aware for fast simultaneous workload execution among devices. Its compute cores operate on custom instructions and provide GPT-2 operations end-to-end. We implement the proposed hardware architecture on four Xilinx Alveo U280 FPGAs and utilize all of the channels of the high bandwidth memory (HBM) and the maximum number of compute resources for high hardware efficiency. DFX achieves 5.58x speedup and 3.99x energy efficiency over four NVIDIA V100 GPUs on the modern GPT-2 model. DFX is also 8.21x more cost-effective than the GPU appliance, suggesting that it is a promising solution for text generation workloads in cloud datacenters. ","[{'version': 'v1', 'created': 'Thu, 22 Sep 2022 05:59:59 GMT'}]",2022-09-26,"[['Hong', 'Seongmin', ''], ['Moon', 'Seungjae', ''], ['Kim', 'Junsoo', ''], ['Lee', 'Sungjae', ''], ['Kim', 'Minsub', ''], ['Lee', 'Dongsoo', ''], ['Kim', 'Joo-Young', '']]",0,1,2022-09-22,1,7,4,1,1,0,86891d00499eebe86d3f1e39143d412addf2652b,252439113.0,https://www.semanticscholar.org/paper/86891d00499eebe86d3f1e39143d412addf2652b,Micro,2022.0,54.0,8.0,1.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '15828122', 'name': 'Seongmin Hong'}, {'authorId': '2113901054', 'name': 'Seungjae Moon'}, {'authorId': '2253793313', 'name': 'Junsoo Kim'}, {'authorId': '2108230976', 'name': 'Sungjae Lee'}, {'authorId': '2116507605', 'name': 'Minsub Kim'}, {'authorId': '122808525', 'name': 'Dongsoo Lee'}, {'authorId': '2254991095', 'name': 'Joo-Young Kim'}]","['Korea Advanced Institute of Science and Technology', 'NAVER']",['South Korea'],2022-09
2209.11344,Ilya Musabirov,"Harsh Kumar, Ilya Musabirov, Jiakai Shi, Adele Lauzon, Kwan Kiu Choy,
  Ofek Gross, Dana Kulzhabayeva, Joseph Jay Williams",Exploring The Design of Prompts For Applying GPT-3 based Chatbots: A Mental Wellbeing Case Study on Mechanical Turk,,,,,cs.HC cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-Language Models like GPT-3 have the potential to enable HCI designers and researchers to create more human-like and helpful chatbots for specific applications. But evaluating the feasibility of these chatbots and designing prompts that optimize GPT-3 for a specific task is challenging. We present a case study in tackling these questions, applying GPT-3 to a brief 5-minute chatbot that anyone can talk to better manage their mood. We report a randomized factorial experiment with 945 participants on Mechanical Turk that tests three dimensions of prompt design to initialize the chatbot (identity, intent, and behaviour), and present both quantitative and qualitative analyses of conversations and user perceptions of the chatbot. We hope other HCI designers and researchers can build on this case study, for other applications of GPT-3 based chatbots to specific tasks, and build on and extend the methods we use for prompt design, and evaluation of the prompt design. ","[{'version': 'v1', 'created': 'Thu, 22 Sep 2022 23:15:54 GMT'}]",2022-09-26,"[['Kumar', 'Harsh', ''], ['Musabirov', 'Ilya', ''], ['Shi', 'Jiakai', ''], ['Lauzon', 'Adele', ''], ['Choy', 'Kwan Kiu', ''], ['Gross', 'Ofek', ''], ['Kulzhabayeva', 'Dana', ''], ['Williams', 'Joseph Jay', '']]",0,1,2022-09-22,1,8,2,1,0,1,599f2ea39113244a026a668722236e52da371469,252519299.0,https://www.semanticscholar.org/paper/599f2ea39113244a026a668722236e52da371469,arXiv.org,2022.0,34.0,11.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2163710001', 'name': 'Harsh Kumar'}, {'authorId': '1826182', 'name': 'Ilya Musabirov'}, {'authorId': '2163751227', 'name': 'Jiakai Shi'}, {'authorId': '2186052895', 'name': 'Adele Lauzon'}, {'authorId': '2163707718', 'name': 'Kwan Kiu Choy'}, {'authorId': '2186053077', 'name': 'Ofek Gross'}, {'authorId': '1861862049', 'name': 'Dana Kulzhabayeva'}, {'authorId': '2149073622', 'name': 'J. J. Williams'}]",['University of Toronto'],['Canada'],2022-09
2209.11515,Sungmin Kang,"Sungmin Kang, Juyeon Yoon, Shin Yoo",Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction,"Accepted to IEEE/ACM International Conference on Software Engineering
  2023 (ICSE 2023)",,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose LIBRO, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of LIBRO shows that, on the widely studied Defects4J benchmark, LIBRO can generate failure reproducing test cases for 33% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination, we also evaluate LIBRO against 31 bug reports submitted after the collection of the LLM training data terminated: LIBRO produces bug reproducing tests for 32% of the studied bug reports. Overall, our results show LIBRO has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports. ","[{'version': 'v1', 'created': 'Fri, 23 Sep 2022 10:50:47 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Dec 2022 10:15:22 GMT'}, {'version': 'v3', 'created': 'Tue, 25 Jul 2023 03:47:36 GMT'}]",2023-07-26,"[['Kang', 'Sungmin', ''], ['Yoon', 'Juyeon', ''], ['Yoo', 'Shin', '']]",0,0,2022-09-23,3,3,1,0,0,0,ce8de3902a583e1eb6062d4453ed90fe6b9d4558,252519508.0,https://www.semanticscholar.org/paper/ce8de3902a583e1eb6062d4453ed90fe6b9d4558,International Conference on Software Engineering,2022.0,41.0,31.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2115515341', 'name': 'Sungmin Kang'}, {'authorId': '2118110297', 'name': 'Juyeon Yoon'}, {'authorId': '2147408161', 'name': 'Shin Yoo'}]",['Korea Advanced Institute of Science and Technology'],['South Korea'],2022-09
2209.12153,Julian Eisenschlos,"Julian Martin Eisenschlos and Jeremy R. Cole and Fangyu Liu and
  William W. Cohen",WinoDict: Probing language models for in-context word acquisition,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a new in-context learning paradigm to measure Large Language Models' (LLMs) ability to learn novel words during inference. In particular, we rewrite Winograd-style co-reference resolution problems by replacing the key concept word with a synthetic but plausible word that the model must understand to complete the task. Solving this task requires the model to make use of the dictionary definition of the new word given in the prompt. This benchmark addresses word acquisition, one important aspect of the diachronic degradation known to afflict LLMs. As LLMs are frozen in time at the moment they are trained, they are normally unable to reflect the way language changes over time. We show that the accuracy of LLMs compared to the original Winograd tasks decreases radically in our benchmark, thus identifying a limitation of current models and providing a benchmark to measure future improvements in LLMs ability to do in-context learning. ","[{'version': 'v1', 'created': 'Sun, 25 Sep 2022 05:30:13 GMT'}]",2022-09-27,"[['Eisenschlos', 'Julian Martin', ''], ['Cole', 'Jeremy R.', ''], ['Liu', 'Fangyu', ''], ['Cohen', 'William W.', '']]",0,0,2022-09-25,1,4,2,0,0,0,775c439186b037c09cd9f95b9daf81d23ca21b54,252532026.0,https://www.semanticscholar.org/paper/775c439186b037c09cd9f95b9daf81d23ca21b54,Conference of the European Chapter of the Association for Computational Linguistics,2022.0,30.0,6.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '117595858', 'name': 'Julian Martin Eisenschlos'}, {'authorId': '30859623', 'name': 'Jeremy R. Cole'}, {'authorId': '144097210', 'name': 'Fangyu Liu'}, {'authorId': '50056360', 'name': 'William W. Cohen'}]",['University of Cambridge'],['United Kingdom'],2022-09
2209.12687,Yoshija Walter PhD,Yoshija Walter,"A Case Report On The ""A.I. Locked-In Problem"": social concerns with modern NLP",17 pages,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Modern NLP models are becoming better conversational agents than their predecessors. Recurrent Neural Networks (RNNs) and especially Long-Short Term Memory (LSTM) features allow the agent to better store and use information about semantic content, a trend that has become even more pronounced with the Transformer Models. Large Language Models (LLMs) such as GPT-3 by OpenAI have become known to be able to construct and follow a narrative, which enables the system to adopt personas on the go, adapt them and play along in conversational stories. However, practical experimentation with GPT-3 shows that there is a recurring problem with these modern NLP systems, namely that they can ""get stuck"" in the narrative so that further conversations, prompt executions or commands become futile. This is here referred to as the ""Locked-In Problem"" and is exemplified with an experimental case report, followed by practical and social concerns that are accompanied with this problem. ","[{'version': 'v1', 'created': 'Thu, 22 Sep 2022 16:39:35 GMT'}]",2022-09-27,"[['Walter', 'Yoshija', '']]",0,1,2022-09-22,1,1,2,1,0,1,43fcc748bbb98c3785e30c9b335c582699651fce,252531314.0,https://www.semanticscholar.org/paper/43fcc748bbb98c3785e30c9b335c582699651fce,arXiv.org,2022.0,33.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1816710357', 'name': 'Yoshija Walter'}]","['Kalaidos University of Applied Sciences', 'University of Fribourg', 'Translational Research Center University Hospital for Psychiatry Bern, Switzerland']",['Switzerland'],2022-09
2209.12774,Konstantinos Skianis,"Konstantinos Katserelis, Konstantinos Skianis",Towards Fine-Dining Recipe Generation with Generative Pre-trained Transformers,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Food is essential to human survival. So much so that we have developed different recipes to suit our taste needs. In this work, we propose a novel way of creating new, fine-dining recipes from scratch using Transformers, specifically auto-regressive language models. Given a small dataset of food recipes, we try to train models to identify cooking techniques, propose novel recipes, and test the power of fine-tuning with minimal data. ","[{'version': 'v1', 'created': 'Mon, 26 Sep 2022 15:33:09 GMT'}]",2022-09-27,"[['Katserelis', 'Konstantinos', ''], ['Skianis', 'Konstantinos', '']]",0,1,2022-09-26,1,2,3,0,0,0,4dae3fb822f304d7d4a477da1d18ae52f367d6c8,252531478.0,https://www.semanticscholar.org/paper/4dae3fb822f304d7d4a477da1d18ae52f367d6c8,arXiv.org,2022.0,34.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2186113051', 'name': 'Konstantinos Katserelis'}, {'authorId': '2641961', 'name': 'Konstantinos Skianis'}]",['Athens University of Economics and Business'],['Greece'],2022-09
2209.14627,Yuqiao Wen,"Yuqiao Wen, Yongchang Hao, Yanshuai Cao, Lili Mou",An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation,Accepted by ICLR 2023,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Open-domain dialogue systems aim to interact with humans through natural language texts in an open-ended fashion. Despite the recent success of super large dialogue systems such as ChatGPT, using medium-to-small-sized dialogue systems remains the common practice as they are more lightweight and accessible; however, generating diverse dialogue responses is challenging, especially with smaller models. In this work, we propose an Equal-size Hard Expectation--Maximization (EqHard-EM) algorithm to train a multi-decoder model for diverse dialogue generation. Our algorithm assigns a sample to a decoder in a hard manner and additionally imposes an equal-assignment constraint to ensure that all decoders are well-trained. We provide detailed theoretical analysis to justify our approach. Further, experiments on two large-scale open-domain dialogue datasets verify that our EqHard-EM algorithm generates high-quality diverse responses. ","[{'version': 'v1', 'created': 'Thu, 29 Sep 2022 08:41:32 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Mar 2023 20:10:15 GMT'}]",2023-03-28,"[['Wen', 'Yuqiao', ''], ['Hao', 'Yongchang', ''], ['Cao', 'Yanshuai', ''], ['Mou', 'Lili', '']]",1,1,2022-09-29,2,4,3,1,0,1,eb26dd5126ea375a37c608d9e07cf04b77848f1b,252595808.0,https://www.semanticscholar.org/paper/eb26dd5126ea375a37c608d9e07cf04b77848f1b,International Conference on Learning Representations,2022.0,62.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153698023', 'name': 'Yuqiao Wen'}, {'authorId': '121330168', 'name': 'Yongchang Hao'}, {'authorId': '2902068', 'name': 'Yanshuai Cao'}, {'authorId': '38956216', 'name': 'Lili Mou'}]","['Canada CIFAR AI Chair, Amii', 'University of Alberta', 'Biologie des Organismes et Écosystèmes Aquatiques']","['Canada', 'France']",2022-09
2210.01911,Oier Mees,"Oier Mees, Jessica Borja-Diaz, Wolfram Burgard",Grounding Language with Visual Affordances over Unstructured Data,"Accepted at the 2023 IEEE International Conference on Robotics and
  Automation (ICRA). Project website: http://hulc2.cs.uni-freiburg.de",,,,cs.RO cs.AI cs.CL cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent works have shown that Large Language Models (LLMs) can be applied to ground natural language to a wide variety of robot skills. However, in practice, learning multi-task, language-conditioned robotic skills typically requires large-scale data collection and frequent human intervention to reset the environment or help correcting the current policies. In this work, we propose a novel approach to efficiently learn general-purpose language-conditioned robot skills from unstructured, offline and reset-free data in the real world by exploiting a self-supervised visuo-lingual affordance model, which requires annotating as little as 1% of the total data with language. We evaluate our method in extensive experiments both in simulated and real-world robotic tasks, achieving state-of-the-art performance on the challenging CALVIN benchmark and learning over 25 distinct visuomotor manipulation tasks with a single policy in the real world. We find that when paired with LLMs to break down abstract natural language instructions into subgoals via few-shot prompting, our method is capable of completing long-horizon, multi-tier tasks in the real world, while requiring an order of magnitude less data than previous approaches. Code and videos are available at http://hulc2.cs.uni-freiburg.de ","[{'version': 'v1', 'created': 'Tue, 4 Oct 2022 21:16:48 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Oct 2022 09:00:57 GMT'}, {'version': 'v3', 'created': 'Wed, 8 Mar 2023 11:00:55 GMT'}]",2023-03-09,"[['Mees', 'Oier', ''], ['Borja-Diaz', 'Jessica', ''], ['Burgard', 'Wolfram', '']]",0,0,2022-10-04,3,3,5,0,0,0,8f84dcbad8cd3b5b4d9229c56bc95f24be859a35,252715472.0,https://www.semanticscholar.org/paper/8f84dcbad8cd3b5b4d9229c56bc95f24be859a35,IEEE International Conference on Robotics and Automation,2022.0,39.0,32.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '7264115', 'name': 'Oier Mees'}, {'authorId': '2156789863', 'name': 'Jessica Borja-Diaz'}, {'authorId': '2106871731', 'name': 'Wolfram Burgard'}]","['University of Technology Nuremberg', 'University of Freiburg']",['Germany'],2022-10
2210.02506,Mohammad Reza Taesiri,"Mohammad Reza Taesiri, Finlay Macklon, Yihe Wang, Hengshuo Shen,
  Cor-Paul Bezemer",Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors,,,,,cs.CL cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Video game testing requires game-specific knowledge as well as common sense reasoning about the events in the game. While AI-driven agents can satisfy the first requirement, it is not yet possible to meet the second requirement automatically. Therefore, video game testing often still relies on manual testing, and human testers are required to play the game thoroughly to detect bugs. As a result, it is challenging to fully automate game testing. In this study, we explore the possibility of leveraging the zero-shot capabilities of large language models for video game bug detection. By formulating the bug detection problem as a question-answering task, we show that large language models can identify which event is buggy in a sequence of textual descriptions of events from a game. To this end, we introduce the GameBugDescriptions benchmark dataset, which consists of 167 buggy gameplay videos and a total of 334 question-answer pairs across 8 games. We extensively evaluate the performance of six models across the OPT and InstructGPT large language model families on our benchmark dataset. Our results show promising results for employing language models to detect video game bugs. With the proper prompting technique, we could achieve an accuracy of 70.66%, and on some video games, up to 78.94%. Our code, evaluation data and the benchmark can be found on https://asgaardlab.github.io/LLMxBugs ","[{'version': 'v1', 'created': 'Wed, 5 Oct 2022 18:44:35 GMT'}]",2022-10-07,"[['Taesiri', 'Mohammad Reza', ''], ['Macklon', 'Finlay', ''], ['Wang', 'Yihe', ''], ['Shen', 'Hengshuo', ''], ['Bezemer', 'Cor-Paul', '']]",0,1,2022-10-05,1,5,2,2,1,1,55e3fe05598be7c3dd357d51166869f6571b824f,252735080.0,https://www.semanticscholar.org/paper/55e3fe05598be7c3dd357d51166869f6571b824f,arXiv.org,2022.0,50.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2129465393', 'name': 'Mohammad Reza Taesiri'}, {'authorId': '115698543', 'name': 'Finlay Macklon'}, {'authorId': '2187060904', 'name': 'Yihe Wang'}, {'authorId': '2187055595', 'name': 'Hengshuo Shen'}, {'authorId': '1755660', 'name': 'C. Bezemer'}]",['University of Alberta'],['Canada'],2022-10
2210.02952,Xu Guo,"Xu Guo, Boyang Li, Han Yu",Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation,"15 pages, 11 figures, Findings of EMNLP 2022",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prompt tuning, or the conditioning of a frozen pretrained language model (PLM) with soft prompts learned from data, has demonstrated impressive performance on a wide range of NLP tasks. However, prompt tuning requires a large training dataset to be effective and is outperformed by finetuning the entire PLM in data-scarce regimes. Previous work (Gu et al., 2022, Vu et al., 2022) proposed to transfer soft prompts pretrained on the source domain to the target domain. In this paper, we explore domain adaptation for prompt tuning, a problem setting where unlabeled data from the target domain are available during pretraining. We propose bOosting Prompt TunIng with doMain Adaptation (OPTIMA), which regularizes the decision boundary to be smooth around regions where source and target data distributions are similar. Extensive experiments demonstrate that OPTIMA significantly enhances the transferability and sample-efficiency of prompt tuning compared to strong baselines. Moreover, in few-shot settings, OPTIMA exceeds full-model tuning by a large margin. ","[{'version': 'v1', 'created': 'Thu, 6 Oct 2022 14:44:21 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Oct 2022 03:58:20 GMT'}]",2022-10-24,"[['Guo', 'Xu', ''], ['Li', 'Boyang', ''], ['Yu', 'Han', '']]",0,0,2022-10-06,2,3,1,0,0,0,26d923d95e6d09b8ab493c3741d97d128135352f,252735158.0,https://www.semanticscholar.org/paper/26d923d95e6d09b8ab493c3741d97d128135352f,Conference on Empirical Methods in Natural Language Processing,2022.0,66.0,10.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '152978217', 'name': 'Xu Guo'}, {'authorId': '1728712', 'name': 'Boyang Albert Li'}, {'authorId': '2187083103', 'name': 'Han Yu'}]",['Nanyang Technological University'],['Singapore'],2022-10
2210.02969,Seonghyeon Ye,"Seonghyeon Ye, Doyoung Kim, Joel Jang, Joongbo Shin, Minjoon Seo",Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners,ICLR 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Meta-training, which fine-tunes the language model (LM) on various downstream tasks by maximizing the likelihood of the target label given the task instruction and input instance, has improved the zero-shot task generalization performance. However, meta-trained LMs still struggle to generalize to challenging tasks containing novel labels unseen during meta-training. In this paper, we propose Flipped Learning, an alternative method of meta-training which trains the LM to generate the task instruction given the input instance and label. During inference, the LM trained with Flipped Learning, referred to as Flipped, selects the label option that is most likely to generate the task instruction. On 14 tasks of the BIG-bench benchmark, the 11B-sized Flipped outperforms zero-shot T0-11B and even a 16 times larger 3-shot GPT-3 (175B) on average by 8.4% and 9.7% points, respectively. Flipped gives particularly large improvements on tasks with unseen labels, outperforming T0-11B by up to +20% average F1 score. This indicates that the strong task generalization of Flipped comes from improved generalization to novel labels. We release our code at https://github.com/seonghyeonye/Flipped-Learning. ","[{'version': 'v1', 'created': 'Thu, 6 Oct 2022 15:00:47 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Oct 2022 14:42:48 GMT'}, {'version': 'v3', 'created': 'Sun, 4 Dec 2022 16:36:28 GMT'}, {'version': 'v4', 'created': 'Tue, 6 Jun 2023 11:03:31 GMT'}]",2023-06-07,"[['Ye', 'Seonghyeon', ''], ['Kim', 'Doyoung', ''], ['Jang', 'Joel', ''], ['Shin', 'Joongbo', ''], ['Seo', 'Minjoon', '']]",0,1,2022-10-06,4,5,1,2,1,1,b9ec37d028fae61752c33a55fb88bd27e6cb8c4d,252735240.0,https://www.semanticscholar.org/paper/b9ec37d028fae61752c33a55fb88bd27e6cb8c4d,International Conference on Learning Representations,2022.0,68.0,14.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152111477', 'name': 'Seonghyeon Ye'}, {'authorId': '2180527259', 'name': 'Doyoung Kim'}, {'authorId': '2000091730', 'name': 'Joel Jang'}, {'authorId': '27582486', 'name': 'Joongbo Shin'}, {'authorId': '4418074', 'name': 'Minjoon Seo'}]","['LG AI Research', 'Korea Advanced Institute of Science and Technology']",['South Korea'],2022-10
2210.05901,Hui-Chi Kuo,"Hui-Chi Kuo, Yun-Nung Chen",Zero-Shot Prompting for Implicit Intent Prediction and Recommendation with Commonsense Reasoning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Intelligent virtual assistants are currently designed to perform tasks or services explicitly mentioned by users, so multiple related domains or tasks need to be performed one by one through a long conversation with many explicit intents. Instead, human assistants are capable of reasoning (multiple) implicit intents based on user utterances via commonsense knowledge, reducing complex interactions and improving practicality. Therefore, this paper proposes a framework of multi-domain dialogue systems, which can automatically infer implicit intents based on user utterances and then perform zero-shot prompting using a large pre-trained language model to trigger suitable single task-oriented bots. The proposed framework is demonstrated effective to realize implicit intents and recommend associated bots in a zero-shot manner. ","[{'version': 'v1', 'created': 'Wed, 12 Oct 2022 03:33:49 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Jun 2023 01:42:47 GMT'}]",2023-06-07,"[['Kuo', 'Hui-Chi', ''], ['Chen', 'Yun-Nung', '']]",0,0,2022-10-12,2,2,1,0,0,0,2a4b6fdf4fd74429431a730c14d0087e00b2a4fa,252846073.0,https://www.semanticscholar.org/paper/2a4b6fdf4fd74429431a730c14d0087e00b2a4fa,Annual Meeting of the Association for Computational Linguistics,2022.0,16.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2165384490', 'name': 'Hui-Chi Kuo'}, {'authorId': '1725643', 'name': 'Yun-Nung (Vivian) Chen'}]",['National Taiwan University'],['Taiwan'],2022-10
2210.06068,Lifeng Han,"Lifeng Han, Gleb Erofeev, Irina Sorokina, Serge Gladkoff, Goran
  Nenadic",Investigating Massive Multilingual Pre-Trained Machine Translation Models for Clinical Domain via Transfer Learning,Accepted to ClinicalNLP-2023 WS@ACL-2023,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Massively multilingual pre-trained language models (MMPLMs) are developed in recent years demonstrating superpowers and the pre-knowledge they acquire for downstream tasks. This work investigates whether MMPLMs can be applied to clinical domain machine translation (MT) towards entirely unseen languages via transfer learning. We carry out an experimental investigation using Meta-AI's MMPLMs ``wmt21-dense-24-wide-en-X and X-en (WMT21fb)'' which were pre-trained on 7 language pairs and 14 translation directions including English to Czech, German, Hausa, Icelandic, Japanese, Russian, and Chinese, and the opposite direction. We fine-tune these MMPLMs towards English-\textit{Spanish} language pair which \textit{did not exist at all} in their original pre-trained corpora both implicitly and explicitly. We prepare carefully aligned \textit{clinical} domain data for this fine-tuning, which is different from their original mixed domain knowledge. Our experimental result shows that the fine-tuning is very successful using just 250k well-aligned in-domain EN-ES segments for three sub-task translation testings: clinical cases, clinical terms, and ontology concepts. It achieves very close evaluation scores to another MMPLM NLLB from Meta-AI, which included Spanish as a high-resource setting in the pre-training. To the best of our knowledge, this is the first work on using MMPLMs towards \textit{clinical domain transfer-learning NMT} successfully for totally unseen languages during pre-training. ","[{'version': 'v1', 'created': 'Wed, 12 Oct 2022 10:19:44 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Jun 2023 20:42:19 GMT'}]",2023-06-06,"[['Han', 'Lifeng', ''], ['Erofeev', 'Gleb', ''], ['Sorokina', 'Irina', ''], ['Gladkoff', 'Serge', ''], ['Nenadic', 'Goran', '']]",0,0,2022-10-12,2,5,2,1,1,0,41c3c8d370c9278dbdb3decf9bc85d02eef0dc03,259075108.0,https://www.semanticscholar.org/paper/41c3c8d370c9278dbdb3decf9bc85d02eef0dc03,Clinical Natural Language Processing Workshop,2022.0,33.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49953231', 'name': 'Lifeng Han'}, {'authorId': '2124124385', 'name': 'G. Erofeev'}, {'authorId': '1932307508', 'name': 'I. Sorokina'}, {'authorId': '1404106344', 'name': 'S. Gladkoff'}, {'authorId': '2144507', 'name': 'G. Nenadic'}]","['University of Manchester', 'Logrus Global, Translation & Localization lifeng.han,']",['United Kingdom'],2022-10
2210.06345,Valentin Li\'evin,"Valentin Li\'evin, Andreas Geert Motzfeldt, Ida Riis Jensen, Ole
  Winther",Variational Open-Domain Question Answering,"28 pages, 5 figures. Accepted at ICML 2023",,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Retrieval-augmented models have proven to be effective in natural language processing tasks, yet there remains a lack of research on their optimization using variational inference. We introduce the Variational Open-Domain (VOD) framework for end-to-end training and evaluation of retrieval-augmented models, focusing on open-domain question answering and language modelling. The VOD objective, a self-normalized estimate of the R\'enyi variational bound, approximates the task marginal likelihood and is evaluated under samples drawn from an auxiliary sampling distribution (cached retriever and/or approximate posterior). It remains tractable, even for retriever distributions defined on large corpora. We demonstrate VOD's versatility by training reader-retriever BERT-sized models on multiple-choice medical exam questions. On the MedMCQA dataset, we outperform the domain-tuned Med-PaLM by +5.3% despite using 2.500$\times$ fewer parameters. Our retrieval-augmented BioLinkBERT model scored 62.9% on the MedMCQA and 55.0% on the MedQA-USMLE. Last, we show the effectiveness of our learned retriever component in the context of medical semantic search. ","[{'version': 'v1', 'created': 'Fri, 23 Sep 2022 10:25:59 GMT'}, {'version': 'v2', 'created': 'Wed, 31 May 2023 10:51:24 GMT'}]",2023-06-01,"[['Liévin', 'Valentin', ''], ['Motzfeldt', 'Andreas Geert', ''], ['Jensen', 'Ida Riis', ''], ['Winther', 'Ole', '']]",0,0,2022-09-23,2,4,3,1,0,1,25b6c9a11d9078d2cc45e02e284195320ce61f0f,252846616.0,https://www.semanticscholar.org/paper/25b6c9a11d9078d2cc45e02e284195320ce61f0f,International Conference on Machine Learning,2022.0,74.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067078585', 'name': ""Valentin Li'evin""}, {'authorId': '2187580291', 'name': 'Andreas Geert Motzfeldt'}, {'authorId': '2187580475', 'name': 'Ida Riis Jensen'}, {'authorId': '1724252', 'name': 'O. Winther'}]","['University of Copenhagen', 'Copenhagen University Hospital', 'Foundation for Innovative New Diagnostics', 'Technical University of Denmark']","['Switzerland', 'Denmark']",2022-09
2210.06376,Daniel Loureiro,"Daniel Loureiro, Al\'ipio M\'ario Jorge",Probing Commonsense Knowledge in Pre-trained Language Models with Sense-level Precision and Expanded Vocabulary,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Progress on commonsense reasoning is usually measured from performance improvements on Question Answering tasks designed to require commonsense knowledge. However, fine-tuning large Language Models (LMs) on these specific tasks does not directly evaluate commonsense learned during pre-training. The most direct assessments of commonsense knowledge in pre-trained LMs are arguably cloze-style tasks targeting commonsense assertions (e.g., A pen is used for [MASK].). However, this approach is restricted by the LM's vocabulary available for masked predictions, and its precision is subject to the context provided by the assertion. In this work, we present a method for enriching LMs with a grounded sense inventory (i.e., WordNet) available at the vocabulary level, without further training. This modification augments the prediction space of cloze-style prompts to the size of a large ontology while enabling finer-grained (sense-level) queries and predictions. In order to evaluate LMs with higher precision, we propose SenseLAMA, a cloze-style task featuring verbalized relations from disambiguated triples sourced from WordNet, WikiData, and ConceptNet. Applying our method to BERT, producing a WordNet-enriched version named SynBERT, we find that LMs can learn non-trivial commonsense knowledge from self-supervision, covering numerous relations, and more effectively than comparable similarity-based approaches. ","[{'version': 'v1', 'created': 'Wed, 12 Oct 2022 16:26:59 GMT'}]",2022-10-13,"[['Loureiro', 'Daniel', ''], ['Jorge', 'Alípio Mário', '']]",0,0,2022-10-12,1,2,2,0,0,0,3cd9e5de457662f5e3c268f75341a93a16254e55,252846421.0,https://www.semanticscholar.org/paper/3cd9e5de457662f5e3c268f75341a93a16254e55,arXiv.org,2022.0,51.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144653901', 'name': 'Daniel Loureiro'}, {'authorId': '2105610634', 'name': 'Alípio Jorge'}]","['Cardiff University', 'University of Porto']","['United Kingdom', 'Portugal']",2022-10
2210.06384,Eldar Kurtic,Eldar Kurtic and Dan Alistarh,GMP*: Well-Tuned Gradual Magnitude Pruning Can Outperform Most BERT-Pruning Methods,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We revisit the performance of the classic gradual magnitude pruning (GMP) baseline for large language models, focusing on the classic BERT benchmark on various popular tasks. Despite existing evidence in the literature that GMP performs poorly, we show that a simple and general variant, which we call GMP*, can match and sometimes outperform more complex state-of-the-art methods. Our results provide a simple yet strong baseline for future work, highlight the importance of parameter tuning for baselines, and even improve the performance of the state-of-the-art second-order pruning method in this setting. ","[{'version': 'v1', 'created': 'Wed, 12 Oct 2022 16:35:47 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Oct 2022 06:50:05 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Dec 2022 19:24:00 GMT'}]",2022-12-12,"[['Kurtic', 'Eldar', ''], ['Alistarh', 'Dan', '']]",0,0,2022-10-12,3,2,1,0,0,0,a8c7dd6a9955a3976785f70146f32c77ed2b2eca,252846445.0,https://www.semanticscholar.org/paper/a8c7dd6a9955a3976785f70146f32c77ed2b2eca,,2022.0,21.0,10.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40992614', 'name': 'Eldar Kurtic'}, {'authorId': '3311387', 'name': 'Dan Alistarh'}]","['Neuroscience Research Australia', 'Institute of Science and Technology Austria']","['Austria', 'Australia']",2022-10
2210.07222,Nils Feldhus,"Nils Feldhus, Leonhard Hennig, Maximilian Dustin Nasert, Christopher
  Ebert, Robert Schwarzenberg, Sebastian M\""oller",Saliency Map Verbalization: Comparing Feature Importance Representations from Model-free and Instruction-based Methods,"ACL 2023 Workshop on Natural Language Reasoning and Structured
  Explanations (NLRSE)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Saliency maps can explain a neural model's predictions by identifying important input features. They are difficult to interpret for laypeople, especially for instances with many features. In order to make them more accessible, we formalize the underexplored task of translating saliency maps into natural language and compare methods that address two key challenges of this approach -- what and how to verbalize. In both automatic and human evaluation setups, using token-level attributions from text classification tasks, we compare two novel methods (search-based and instruction-based verbalizations) against conventional feature importance representations (heatmap visualizations and extractive rationales), measuring simulatability, faithfulness, helpfulness and ease of understanding. Instructing GPT-3.5 to generate saliency map verbalizations yields plausible explanations which include associations, abstractive summarization and commonsense reasoning, achieving by far the highest human ratings, but they are not faithfully capturing numeric information and are inconsistent in their interpretation of the task. In comparison, our search-based, model-free verbalization approach efficiently completes templated verbalizations, is faithful by design, but falls short in helpfulness and simulatability. Our results suggest that saliency map verbalization makes feature attribution explanations more comprehensible and less cognitively challenging to humans than conventional representations. ","[{'version': 'v1', 'created': 'Thu, 13 Oct 2022 17:48:15 GMT'}, {'version': 'v2', 'created': 'Tue, 30 May 2023 14:34:05 GMT'}, {'version': 'v3', 'created': 'Wed, 7 Jun 2023 09:29:04 GMT'}]",2023-06-08,"[['Feldhus', 'Nils', ''], ['Hennig', 'Leonhard', ''], ['Nasert', 'Maximilian Dustin', ''], ['Ebert', 'Christopher', ''], ['Schwarzenberg', 'Robert', ''], ['Möller', 'Sebastian', '']]",0,1,2022-10-13,3,6,1,1,0,1,1bc58b09fffaa731048e35ac00676065294cc139,258967227.0,https://www.semanticscholar.org/paper/1bc58b09fffaa731048e35ac00676065294cc139,NLRSE,2022.0,82.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1641658310', 'name': 'Nils Feldhus'}, {'authorId': '36943315', 'name': 'Leonhard Hennig'}, {'authorId': '2187681770', 'name': 'Maximilian Dustin Nasert'}, {'authorId': '2187681826', 'name': 'Christopher Ebert'}, {'authorId': '1683203', 'name': 'Robert Schwarzenberg'}, {'authorId': '2058899254', 'name': 'Sebastian Moller'}]","['German Research Centre for Artificial Intelligence', 'Technische Universität Berlin']",['Germany'],2022-10
2210.07313,Abhijeet Awasthi,"Abhijeet Awasthi, Nitish Gupta, Bidisha Samanta, Shachi Dave, Sunita
  Sarawagi, Partha Talukdar",Bootstrapping Multilingual Semantic Parsers using Large Language Models,EACL-23,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite cross-lingual generalization demonstrated by pre-trained multilingual models, the translate-train paradigm of transferring English datasets across multiple languages remains to be a key mechanism for training task-specific multilingual models. However, for many low-resource languages, the availability of a reliable translation service entails significant amounts of costly human-annotated translation pairs. Further, translation services may continue to be brittle due to domain mismatch between task-specific input text and general-purpose text used for training translation models. For multilingual semantic parsing, we demonstrate the effectiveness and flexibility offered by large language models (LLMs) for translating English datasets into several languages via few-shot prompting. Through extensive comparisons on two public datasets, MTOP and MASSIVE, spanning 50 languages and several domains, we show that our method of translating data using LLMs outperforms a strong translate-train baseline on 41 out of 50 languages. We study the key design choices that enable more effective multilingual data translation via prompted LLMs. ","[{'version': 'v1', 'created': 'Thu, 13 Oct 2022 19:34:14 GMT'}, {'version': 'v2', 'created': 'Sat, 11 Feb 2023 22:32:29 GMT'}]",2023-02-14,"[['Awasthi', 'Abhijeet', ''], ['Gupta', 'Nitish', ''], ['Samanta', 'Bidisha', ''], ['Dave', 'Shachi', ''], ['Sarawagi', 'Sunita', ''], ['Talukdar', 'Partha', '']]",0,0,2022-10-13,2,6,2,0,0,0,dda0f7f086fc875d583604f8b0cf4a8678bc4de4,252907514.0,https://www.semanticscholar.org/paper/dda0f7f086fc875d583604f8b0cf4a8678bc4de4,Conference of the European Chapter of the Association for Computational Linguistics,2022.0,51.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '67126112', 'name': 'Abhijeet Awasthi'}, {'authorId': '2285178', 'name': 'Nitish Gupta'}, {'authorId': '20117407', 'name': 'Bidisha Samanta'}, {'authorId': '2160404', 'name': 'Shachi Dave'}, {'authorId': '1770124', 'name': 'Sunita Sarawagi'}, {'authorId': '2408872', 'name': 'P. Talukdar'}]","['Google', 'Indian Institute of Technology Bombay']",['India'],2022-10
2210.07993,Iulia Comsa,"Iulia-Maria Comsa, Julian Martin Eisenschlos, Srini Narayanan",MiQA: A Benchmark for Inference on Metaphorical Questions,AACL-IJCNLP 2022 conference paper,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We propose a benchmark to assess the capability of large language models to reason with conventional metaphors. Our benchmark combines the previously isolated topics of metaphor detection and commonsense reasoning into a single task that requires a model to make inferences by accurately selecting between the literal and metaphorical register. We examine the performance of state-of-the-art pre-trained models on binary-choice tasks and find a large discrepancy between the performance of small and very large models, going from chance to near-human level. We also analyse the largest model in a generative setting and find that although human performance is approached, careful multiple-shot prompting is required. ","[{'version': 'v1', 'created': 'Fri, 14 Oct 2022 17:46:05 GMT'}]",2022-10-17,"[['Comsa', 'Iulia-Maria', ''], ['Eisenschlos', 'Julian Martin', ''], ['Narayanan', 'Srini', '']]",0,0,2022-10-14,1,3,1,0,0,0,777683db4795ff691533c2c4be3244fabd826842,252907241.0,https://www.semanticscholar.org/paper/777683db4795ff691533c2c4be3244fabd826842,AACL,2022.0,31.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '30134687', 'name': 'I. Comsa'}, {'authorId': '117595858', 'name': 'Julian Martin Eisenschlos'}, {'authorId': '144928136', 'name': 'S. Narayanan'}]",['Google'],['Switzerland'],2022-10
2210.08207,Parth Dandavate,Mihir Godbole and Parth Dandavate and Aditya Kane,Temporal Word Meaning Disambiguation using TimeLMs,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Meaning of words constantly changes given the events in modern civilization. Large Language Models use word embeddings, which are often static and thus cannot cope with this semantic change. Thus,it is important to resolve ambiguity in word meanings. This paper is an effort in this direction, where we explore methods for word sense disambiguation for the EvoNLP shared task. We conduct rigorous ablations for two solutions to this problem. We see that an approach using time-aware language models helps this task. Furthermore, we explore possible future directions to this problem. ","[{'version': 'v1', 'created': 'Sat, 15 Oct 2022 06:34:59 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Nov 2022 08:39:55 GMT'}]",2022-11-18,"[['Godbole', 'Mihir', ''], ['Dandavate', 'Parth', ''], ['Kane', 'Aditya', '']]",0,0,2022-10-15,2,3,1,0,0,0,0fd97ed923a570367fc88668f820b1bf1941432d,252918635.0,https://www.semanticscholar.org/paper/0fd97ed923a570367fc88668f820b1bf1941432d,EVONLP,2022.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2187929222', 'name': 'Mihir Godbole'}, {'authorId': '2187928164', 'name': 'Parth Dandavate'}, {'authorId': '2159555605', 'name': 'Aditya Kane'}]","['Indian Institute of Information Technology, Pune']",['India'],2022-10
2210.08209,Tanmay Chavan,Tanmay Chavan and Aditya Kane,Large Language Models for Multi-label Propaganda Detection,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The spread of propaganda through the internet has increased drastically over the past years. Lately, propaganda detection has started gaining importance because of the negative impact it has on society. In this work, we describe our approach for the WANLP 2022 shared task which handles the task of propaganda detection in a multi-label setting. The task demands the model to label the given text as having one or more types of propaganda techniques. There are a total of 21 propaganda techniques to be detected. We show that an ensemble of five models performs the best on the task, scoring a micro-F1 score of 59.73%. We also conduct comprehensive ablations and propose various future directions for this work. ","[{'version': 'v1', 'created': 'Sat, 15 Oct 2022 06:47:31 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Oct 2022 17:26:01 GMT'}]",2022-10-21,"[['Chavan', 'Tanmay', ''], ['Kane', 'Aditya', '']]",0,0,2022-10-15,2,2,1,0,0,0,898fdcd1a45137ecf7c315fd06762d47eaec61fb,263796264.0,https://www.semanticscholar.org/paper/898fdcd1a45137ecf7c315fd06762d47eaec61fb,arXiv.org,2022.0,14.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2063049987', 'name': 'Tanmay Chavan'}, {'authorId': '2159555605', 'name': 'Aditya Kane'}]","['Indian Institute of Information Technology, Pune']",['India'],2022-10
2210.10599,Jiuzhou Han,"Jiuzhou Han, Ehsan Shareghi",Self-supervised Graph Masking Pre-training for Graph-to-Text Generation,"EMNLP 2022; code is available at
  https://github.com/Jiuzhouh/Graph-Masking-Pre-training",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale pre-trained language models (PLMs) have advanced Graph-to-Text (G2T) generation by processing the linearised version of a graph. However, the linearisation is known to ignore the structural information. Additionally, PLMs are typically pre-trained on free text which introduces domain mismatch between pre-training and downstream G2T generation tasks. To address these shortcomings, we propose graph masking pre-training strategies that neither require supervision signals nor adjust the architecture of the underlying pre-trained encoder-decoder model. When used with a pre-trained T5, our approach achieves new state-of-the-art results on WebNLG+2020 and EventNarrative G2T generation datasets. Our method also shows to be very effective in the low-resource setting. ","[{'version': 'v1', 'created': 'Wed, 19 Oct 2022 14:44:56 GMT'}]",2022-10-20,"[['Han', 'Jiuzhou', ''], ['Shareghi', 'Ehsan', '']]",0,0,2022-10-19,1,2,1,1,1,0,6462f367550af0dab4eda55530c854743469c1d6,252992960.0,https://www.semanticscholar.org/paper/6462f367550af0dab4eda55530c854743469c1d6,Conference on Empirical Methods in Natural Language Processing,2022.0,33.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2133405108', 'name': 'Jiuzhou Han'}, {'authorId': '2888926', 'name': 'Ehsan Shareghi'}]",['Monash University'],['Australia'],2022-10
2210.13693,Peng Shi,"Peng Shi, Rui Zhang, He Bai, and Jimmy Lin",XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In-context learning using large language models has recently shown surprising results for semantic parsing tasks such as Text-to-SQL translation. Prompting GPT-3 or Codex using several examples of question-SQL pairs can produce excellent results, comparable to state-of-the-art finetuning-based models. However, existing work primarily focuses on English datasets, and it is unknown whether large language models can serve as competitive semantic parsers for other languages. To bridge this gap, our work focuses on cross-lingual Text-to-SQL semantic parsing for translating non-English utterances into SQL queries based on an English schema. We consider a zero-shot transfer learning setting with the assumption that we do not have any labeled examples in the target language (but have annotated examples in English). This work introduces the XRICL framework, which learns to retrieve relevant English exemplars for a given query to construct prompts. We also include global translation exemplars for a target language to facilitate the translation process for large language models. To systematically evaluate our model, we construct two new benchmark datasets, XSpider and XKaggle-dbqa, which include questions in Chinese, Vietnamese, Farsi, and Hindi. Our experiments show that XRICL effectively leverages large pre-trained language models to outperform existing baselines. Data and code are publicly available at https://github.com/Impavidity/XRICL. ","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 01:33:49 GMT'}]",2022-10-26,"[['Shi', 'Peng', ''], ['Zhang', 'Rui', ''], ['Bai', 'He', ''], ['Lin', 'Jimmy', '']]",0,1,2022-10-25,1,4,1,2,0,2,38e1a9c5599fc7597b7c5ffd37951ba5f528094c,253107357.0,https://www.semanticscholar.org/paper/38e1a9c5599fc7597b7c5ffd37951ba5f528094c,Conference on Empirical Methods in Natural Language Processing,2022.0,59.0,11.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2055357805', 'name': 'Peng Shi'}, {'authorId': '15176410', 'name': 'Rui Zhang'}, {'authorId': '37374479', 'name': 'He Bai'}, {'authorId': '2154743364', 'name': 'Jimmy Lin'}]",['University of Waterloo'],['Canada'],2022-10
2210.13984,Clement Tan,"Clement Tan, Chai Kiat Yeo, Cheston Tan, Basura Fernando",Abductive Action Inference,"16 pages, 9 figures",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Abductive reasoning aims to make the most likely inference for a given set of incomplete observations. In this paper, we introduce a novel research task known as ""abductive action inference"" which addresses the question of which actions were executed by a human to reach a specific state shown in a single snapshot. The research explores three key abductive inference problems: action set prediction, action sequence prediction, and abductive action verification. To tackle these challenging tasks, we investigate various models, including established ones such as Transformers, Graph Neural Networks, CLIP, BLIP, GPT3, end-to-end trained Slow-Fast, Resnet50-3D, and ViT models. Furthermore, the paper introduces several innovative models tailored for abductive action inference, including a relational graph neural network, a relational bilinear pooling model, a relational rule-based inference model, a relational GPT-3 prompt method, and a relational Transformer model. Notably, the newly proposed object-relational bilinear graph encoder-decoder (BiGED) model emerges as the most effective among all methods evaluated, demonstrating good proficiency in handling the intricacies of the Action Genome dataset. The contributions of this research offer significant progress toward comprehending the implications of human actions and making highly plausible inferences concerning the outcomes of these actions. ","[{'version': 'v1', 'created': 'Mon, 24 Oct 2022 07:43:59 GMT'}, {'version': 'v2', 'created': 'Mon, 3 Apr 2023 10:28:38 GMT'}, {'version': 'v3', 'created': 'Mon, 17 Apr 2023 07:08:12 GMT'}, {'version': 'v4', 'created': 'Mon, 7 Aug 2023 11:29:26 GMT'}]",2023-08-08,"[['Tan', 'Clement', ''], ['Yeo', 'Chai Kiat', ''], ['Tan', 'Cheston', ''], ['Fernando', 'Basura', '']]",0,1,2022-10-24,4,4,1,1,0,1,0611590de3ebddae42d0bd426e420c37737cb709,253107265.0,https://www.semanticscholar.org/paper/0611590de3ebddae42d0bd426e420c37737cb709,arXiv.org,2022.0,51.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2165222104', 'name': 'Clement Tan'}, {'authorId': '1751452', 'name': 'C. Yeo'}, {'authorId': '1694051', 'name': 'Cheston Tan'}, {'authorId': '1688071', 'name': 'Basura Fernando'}]","['Agency for Science, Technology and Research', 'Nanyang Technological University']",['Singapore'],2022-10
2210.14304,William Aitken,"Xianzhi Li, Will Aitken, Xiaodan Zhu, Stephen W. Thomas",Learning Better Intent Representations for Financial Open Intent Classification,"Accepted to FinNLP-2022, in conjunction with EMNLP-2022",,,,cs.CL q-fin.CP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the recent surge of NLP technologies in the financial domain, banks and other financial entities have adopted virtual agents (VA) to assist customers. A challenging problem for VAs in this domain is determining a user's reason or intent for contacting the VA, especially when the intent was unseen or open during the VA's training. One method for handling open intents is adaptive decision boundary (ADB) post-processing, which learns tight decision boundaries from intent representations to separate known and open intents. We propose incorporating two methods for supervised pre-training of intent representations: prefix-tuning and fine-tuning just the last layer of a large language model (LLM). With this proposal, our accuracy is 1.63% - 2.07% higher than the prior state-of-the-art ADB method for open intent classification on the banking77 benchmark amongst others. Notably, we only supplement the original ADB model with 0.1% additional trainable parameters. Ablation studies also determine that our method yields better results than full fine-tuning the entire model. We hypothesize that our findings could stimulate a new optimal method of downstream tuning that combines parameter efficient tuning modules with fine-tuning a subset of the base model's layers. ","[{'version': 'v1', 'created': 'Tue, 25 Oct 2022 20:01:13 GMT'}]",2022-10-27,"[['Li', 'Xianzhi', ''], ['Aitken', 'Will', ''], ['Zhu', 'Xiaodan', ''], ['Thomas', 'Stephen W.', '']]",0,0,2022-10-25,1,4,2,0,0,0,12c20b14f0652c2953dee2e4fc7da59e46744ff4,253117141.0,https://www.semanticscholar.org/paper/12c20b14f0652c2953dee2e4fc7da59e46744ff4,FINNLP,2022.0,33.0,4.0,0.0,True,"['Computer Science', 'Economics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50079608', 'name': 'Xianzhi Li'}, {'authorId': '2188834394', 'name': 'Will Aitken'}, {'authorId': '2130251018', 'name': 'Xiao-Dan Zhu'}, {'authorId': '1847208', 'name': 'Stephen W. Thomas'}]","[""Queen's University""]",['Canada'],2022-10
2210.14699,"Jean-Baptiste D\""oderlein","Jean-Baptiste D\""oderlein, Mathieu Acher, Djamel Eddine Khelladi,
  Benoit Combemale","Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?","14 pages, 3 Figures (not counted the subfigures), 10 Tables",,,,cs.SE cs.CL cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models are promising solutions for tackling increasing complex problems. In software engineering, they recently attracted attention in code assistants, with programs automatically written in a given programming language from a programming task description in natural language. They have the potential to save time and effort when writing code. However, these systems are currently poorly understood, preventing them from being used optimally. In this paper, we investigate the various input parameters of two language models, and conduct a study to understand if variations of these input parameters (e.g. programming task description and the surrounding context, creativity of the language model, number of generated solutions) can have a significant impact on the quality of the generated programs. We design specific operators for varying input parameters and apply them over two code assistants (Copilot and Codex) and two benchmarks representing algorithmic problems (HumanEval and LeetCode). Our results showed that varying the input parameters can significantly improve the performance of language models. However, there is a tight dependency when varying the temperature, the prompt and the number of generated solutions, making potentially hard for developers to properly control the parameters to obtain an optimal result. This work opens opportunities to propose (automated) strategies for improving performance. ","[{'version': 'v1', 'created': 'Wed, 26 Oct 2022 13:28:14 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Feb 2023 14:11:41 GMT'}]",2023-02-16,"[['Döderlein', 'Jean-Baptiste', ''], ['Acher', 'Mathieu', ''], ['Khelladi', 'Djamel Eddine', ''], ['Combemale', 'Benoit', '']]",0,0,2022-10-26,2,4,3,1,0,1,66c52c6ef45cdd77c086996bcaaf01470e82dbd2,253117147.0,https://www.semanticscholar.org/paper/66c52c6ef45cdd77c086996bcaaf01470e82dbd2,arXiv.org,2022.0,50.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2189510654', 'name': 'Jean-Baptiste Döderlein'}, {'authorId': '2191325', 'name': 'M. Acher'}, {'authorId': '1866611', 'name': 'D. Khelladi'}, {'authorId': '1744336', 'name': 'B. Combemale'}]","['Institut de Recherche en Informatique et Systèmes Aléatoires', 'University of Rennes', 'École Normale Supérieure de Rennes']",['France'],2022-10
2210.14986,Laura Ruis,"Laura Ruis, Akbir Khan, Stella Biderman, Sara Hooker, Tim
  Rockt\""aschel, Edward Grefenstette",Large language models are not zero-shot communicators,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite widespread use of LLMs as conversational agents, evaluations of performance fail to capture a crucial aspect of communication: interpreting language in context. Humans interpret language using beliefs and prior knowledge about the world. For example, we intuitively understand the response ""I wore gloves"" to the question ""Did you leave fingerprints?"" as meaning ""No"". To investigate whether LLMs have the ability to make this type of inference, known as an implicature, we design a simple task and evaluate widely used state-of-the-art models. We find that, despite only evaluating on utterances that require a binary inference (yes or no), most perform close to random. Models adapted to be ""aligned with human intent"" perform much better, but still show a significant gap with human performance. We present our findings as the starting point for further research into evaluating how LLMs interpret language in context and to drive the development of more pragmatic and useful models of human discourse. ","[{'version': 'v1', 'created': 'Wed, 26 Oct 2022 19:04:23 GMT'}]",2022-10-28,"[['Ruis', 'Laura', ''], ['Khan', 'Akbir', ''], ['Biderman', 'Stella', ''], ['Hooker', 'Sara', ''], ['Rocktäschel', 'Tim', ''], ['Grefenstette', 'Edward', '']]",0,0,2022-10-26,1,6,1,0,0,0,e8db669c8cb1c07557ede15e2771968f9370330b,253157310.0,https://www.semanticscholar.org/paper/e8db669c8cb1c07557ede15e2771968f9370330b,arXiv.org,2022.0,108.0,18.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2065612731', 'name': 'Laura Ruis'}, {'authorId': '49213201', 'name': 'Akbir Khan'}, {'authorId': '103476203', 'name': 'Stella Rose Biderman'}, {'authorId': '50237813', 'name': 'Sara Hooker'}, {'authorId': '1389854357', 'name': 'Tim Rocktaschel'}, {'authorId': '1864353', 'name': 'Edward Grefenstette'}]","['University College London', 'Cohere']","['Canada', 'United Kingdom']",2022-10
2210.15157,Paul Denny,Paul Denny and Viraj Kumar and Nasser Giacaman,Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language,,,,,cs.HC cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  GitHub Copilot is an artificial intelligence model for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about the impact it will have on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60\% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development. ","[{'version': 'v1', 'created': 'Thu, 27 Oct 2022 03:48:24 GMT'}]",2022-10-28,"[['Denny', 'Paul', ''], ['Kumar', 'Viraj', ''], ['Giacaman', 'Nasser', '']]",0,0,2022-10-27,1,3,2,1,0,1,0566c1c3eeeef5c968fced6d80b77fe22d02bbd9,253157479.0,https://www.semanticscholar.org/paper/0566c1c3eeeef5c968fced6d80b77fe22d02bbd9,Technical Symposium on Computer Science Education,2022.0,36.0,61.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143880483', 'name': 'Paul Denny'}, {'authorId': '2107907927', 'name': 'Viraj Kumar'}, {'authorId': '1753393', 'name': 'Nasser Giacaman'}]","['2023, Toronto, Ontario, Canada', 'Indian Institute of Science Bangalore', 'University of Auckland', 'March 15-18, 2023, Toronto, Ontario, Canada.']","['Canada', 'India', 'New Zealand']",2022-10
2210.16228,Christopher Davis,"Christopher Davis, Christopher Bryant, Andrew Caines, Marek Rei, Paula
  Buttery",Probing for targeted syntactic knowledge through grammatical error detection,CoNLL 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Targeted studies testing knowledge of subject-verb agreement (SVA) indicate that pre-trained language models encode syntactic information. We assert that if models robustly encode subject-verb agreement, they should be able to identify when agreement is correct and when it is incorrect. To that end, we propose grammatical error detection as a diagnostic probe to evaluate token-level contextual representations for their knowledge of SVA. We evaluate contextual representations at each layer from five pre-trained English language models: BERT, XLNet, GPT-2, RoBERTa, and ELECTRA. We leverage public annotated training data from both English second language learners and Wikipedia edits, and report results on manually crafted stimuli for subject-verb agreement. We find that masked language models linearly encode information relevant to the detection of SVA errors, while the autoregressive models perform on par with our baseline. However, we also observe a divergence in performance when probes are trained on different training sets, and when they are evaluated on different syntactic constructions, suggesting the information pertaining to SVA error detection is not robustly encoded. ","[{'version': 'v1', 'created': 'Fri, 28 Oct 2022 16:01:25 GMT'}]",2022-10-31,"[['Davis', 'Christopher', ''], ['Bryant', 'Christopher', ''], ['Caines', 'Andrew', ''], ['Rei', 'Marek', ''], ['Buttery', 'Paula', '']]",0,1,2022-10-28,1,5,1,1,1,0,b327db5fa9960dff3eba8de33530e93c6599a976,253224265.0,https://www.semanticscholar.org/paper/b327db5fa9960dff3eba8de33530e93c6599a976,Conference on Computational Natural Language Learning,2022.0,35.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145808477', 'name': 'Christopher Davis'}, {'authorId': '145178009', 'name': 'Christopher Bryant'}, {'authorId': '143726824', 'name': 'Andrew Caines'}, {'authorId': '145687301', 'name': 'Marek Rei'}, {'authorId': '33490976', 'name': 'P. Buttery'}]","['Imperial College London', 'ALTA Institute, Department of Computer Science & Technology,', 'University of Cambridge']",['United Kingdom'],2022-10
2210.17284,Pragya Srivastava,"Pragya Srivastava, Tanuja Ganu and Saikat Guha",Towards Zero-Shot and Few-Shot Table Question Answering using GPT-3,7 pages,,,,cs.LG,http://creativecommons.org/publicdomain/zero/1.0/,"  We present very early results on using GPT-3 to perform question answering on tabular data. We find that stock pre-trained GPT-3 is able to zero-shot learn the table structure from a serialized JSON array-of-arrays representation, and able to answer lookup queries and simple comparison questions in natural language without any fine-tuning. We further find that simple prompt engineering to include few-shot static Q&A examples significantly improves accuracy. Lastly, we find that intermixing passage text improves accuracy even further on heterogeneous data. We apply our approach on a novel dataset of simple tables in newspaper infographics with promising results. Overall, we find much cause for optimism in this basic approach. ","[{'version': 'v1', 'created': 'Mon, 31 Oct 2022 13:08:55 GMT'}]",2022-11-01,"[['Srivastava', 'Pragya', ''], ['Ganu', 'Tanuja', ''], ['Guha', 'Saikat', '']]",0,1,2022-10-31,1,3,1,1,0,1,6b8f26678785ebd7b7b27984af3cb9a273b722b0,253237997.0,https://www.semanticscholar.org/paper/6b8f26678785ebd7b7b27984af3cb9a273b722b0,arXiv.org,2022.0,16.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2189376379', 'name': 'Pragya Srivastava'}, {'authorId': '1785978', 'name': 'T. Ganu'}, {'authorId': '2171638119', 'name': 'Saikat Guha'}]","['Indian Institute of Technology Delhi', 'Microsoft']",['India'],2022-10
2210.17323,Elias Frantar,"Elias Frantar, Saleh Ashkboos, Torsten Hoefler, Dan Alistarh",GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers,ICLR 2023,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Generative Pre-trained Transformer models, known as GPT or OPT, set themselves apart through breakthrough performance across complex language modelling tasks, but also by their extremely high computational and storage costs. Specifically, due to their massive size, even inference for large, highly-accurate GPT models may require multiple performant GPUs, which limits the usability of such models. While there is emerging work on relieving this pressure via model compression, the applicability and performance of existing compression techniques is limited by the scale and complexity of GPT models. In this paper, we address this challenge, and propose GPTQ, a new one-shot weight quantization method based on approximate second-order information, that is both highly-accurate and highly-efficient. Specifically, GPTQ can quantize GPT models with 175 billion parameters in approximately four GPU hours, reducing the bitwidth down to 3 or 4 bits per weight, with negligible accuracy degradation relative to the uncompressed baseline. Our method more than doubles the compression gains relative to previously-proposed one-shot quantization methods, preserving accuracy, allowing us for the first time to execute an 175 billion-parameter model inside a single GPU for generative inference. Moreover, we also show that our method can still provide reasonable accuracy in the extreme quantization regime, in which weights are quantized to 2-bit or even ternary quantization levels. We show experimentally that these improvements can be leveraged for end-to-end inference speedups over FP16, of around 3.25x when using high-end GPUs (NVIDIA A100) and 4.5x when using more cost-effective ones (NVIDIA A6000). The implementation is available at https://github.com/IST-DASLab/gptq. ","[{'version': 'v1', 'created': 'Mon, 31 Oct 2022 13:42:40 GMT'}, {'version': 'v2', 'created': 'Wed, 22 Mar 2023 13:10:47 GMT'}]",2023-03-23,"[['Frantar', 'Elias', ''], ['Ashkboos', 'Saleh', ''], ['Hoefler', 'Torsten', ''], ['Alistarh', 'Dan', '']]",0,1,2022-10-31,2,4,1,1,1,0,7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6,253237200.0,https://www.semanticscholar.org/paper/7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6,arXiv.org,2022.0,37.0,118.0,29.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1502248377', 'name': 'Elias Frantar'}, {'authorId': '9543395', 'name': 'S. Ashkboos'}, {'authorId': '1713648', 'name': 'T. Hoefler'}, {'authorId': '3311387', 'name': 'Dan Alistarh'}]","['ETH Zurich', 'Institute of Science and Technology Austria']","['Austria', 'Switzerland']",2022-10
2210.17406,Emanuele La Malfa,Emanuele La Malfa and Matthew Wicker and Marta Kwiatkowska,Emergent Linguistic Structures in Neural Networks are Fragile,,,,,cs.LG cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have been reported to have strong performance on natural language processing tasks. However, performance metrics such as accuracy do not measure the quality of the model in terms of its ability to robustly represent complex linguistic structures. In this paper, focusing on the ability of language models to represent syntax, we propose a framework to assess the consistency and robustness of linguistic representations. To this end, we introduce measures of robustness of neural network models that leverage recent advances in extracting linguistic constructs from LLMs via probing tasks, i.e., simple tasks used to extract meaningful information about a single facet of a language model, such as syntax reconstruction and root identification. Empirically, we study the performance of four LLMs across six different corpora on the proposed robustness measures by analysing their performance and robustness with respect to syntax-preserving perturbations. We provide evidence that context-free representation (e.g., GloVe) are in some cases competitive with context-dependent representations from modern LLMs (e.g., BERT), yet equally brittle to syntax-preserving perturbations. Our key observation is that emergent syntactic representations in neural networks are brittle. We make the code, trained models and logs available to the community as a contribution to the debate about the capabilities of LLMs. ","[{'version': 'v1', 'created': 'Mon, 31 Oct 2022 15:43:57 GMT'}, {'version': 'v2', 'created': 'Wed, 2 Nov 2022 20:02:03 GMT'}, {'version': 'v3', 'created': 'Tue, 8 Nov 2022 16:25:12 GMT'}, {'version': 'v4', 'created': 'Tue, 15 Nov 2022 15:58:55 GMT'}, {'version': 'v5', 'created': 'Sun, 29 Jan 2023 13:15:49 GMT'}, {'version': 'v6', 'created': 'Mon, 13 Feb 2023 19:08:07 GMT'}, {'version': 'v7', 'created': 'Wed, 29 Mar 2023 13:29:51 GMT'}, {'version': 'v8', 'created': 'Wed, 31 May 2023 21:58:59 GMT'}]",2023-06-02,"[['La Malfa', 'Emanuele', ''], ['Wicker', 'Matthew', ''], ['Kwiatkowska', 'Marta', '']]",0,0,2022-10-31,8,3,2,0,0,0,c45d42988758fe4b4e491df61067950791c8f29a,253237482.0,https://www.semanticscholar.org/paper/c45d42988758fe4b4e491df61067950791c8f29a,arXiv.org,2022.0,72.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1582740100', 'name': 'Emanuele La Malfa'}, {'authorId': '40537892', 'name': 'Matthew Wicker'}, {'authorId': '2189375457', 'name': 'Marta Kiatkowska'}]","['The Alan Turing Institute', 'University of Oxford']",['United Kingdom'],2022-10
2210.17497,Kenneth Ezukwoke,"Kenneth Ezukwoke, Anis Hoayek, Mireille Batton-Hubert, Xavier Boucher,
  Pascal Gounet and Jerome Adrian",Leveraging Pre-trained Models for Failure Analysis Triplets Generation,"33 pages, 11 figures, 9 tables",,,,cs.CL cs.LG stat.AP,http://creativecommons.org/licenses/by/4.0/,"  Pre-trained Language Models recently gained traction in the Natural Language Processing (NLP) domain for text summarization, generation and question-answering tasks. This stems from the innovation introduced in Transformer models and their overwhelming performance compared with Recurrent Neural Network Models (Long Short Term Memory (LSTM)). In this paper, we leverage the attention mechanism of pre-trained causal language models such as Transformer model for the downstream task of generating Failure Analysis Triplets (FATs) - a sequence of steps for analyzing defected components in the semiconductor industry. We compare different transformer models for this generative task and observe that Generative Pre-trained Transformer 2 (GPT2) outperformed other transformer model for the failure analysis triplet generation (FATG) task. In particular, we observe that GPT2 (trained on 1.5B parameters) outperforms pre-trained BERT, BART and GPT3 by a large margin on ROUGE. Furthermore, we introduce Levenshstein Sequential Evaluation metric (LESE) for better evaluation of the structured FAT data and show that it compares exactly with human judgment than existing metrics. ","[{'version': 'v1', 'created': 'Mon, 31 Oct 2022 17:21:15 GMT'}]",2022-11-01,"[['Ezukwoke', 'Kenneth', ''], ['Hoayek', 'Anis', ''], ['Batton-Hubert', 'Mireille', ''], ['Boucher', 'Xavier', ''], ['Gounet', 'Pascal', ''], ['Adrian', 'Jerome', '']]",0,1,2022-10-31,1,6,3,2,1,1,587373fe118f4d6ae8a184d7ee622fb9f7c25dd8,253237663.0,https://www.semanticscholar.org/paper/587373fe118f4d6ae8a184d7ee622fb9f7c25dd8,arXiv.org,2022.0,58.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2129401036', 'name': 'Kenneth Ezukwoke'}, {'authorId': '87793822', 'name': 'Anis Hoayek'}, {'authorId': '1442061049', 'name': 'M. Batton-Hubert'}, {'authorId': '2169563252', 'name': 'Xavier Boucher'}, {'authorId': '9104568', 'name': 'Pascal Gounet'}, {'authorId': '2189377591', 'name': 'Jerome Adrian'}]","['Failure Analysis Laboratory STMicroelectronics Grenoble, France', 'Mines Saint-Étienne']",['France'],2022-10
2211.01736,Emre Can Acikgoz,"Emre Can Acikgoz, Tilek Chubakov, M\""uge Kural, G\""ozde G\""ul
  \c{S}ahin, Deniz Yuret",Transformers on Multilingual Clause-Level Morphology,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper describes our winning systems in MRL: The 1st Shared Task on Multilingual Clause-level Morphology (EMNLP 2022 Workshop) designed by KUIS AI NLP team. We present our work for all three parts of the shared task: inflection, reinflection, and analysis. We mainly explore transformers with two approaches: (i) training models from scratch in combination with data augmentation, and (ii) transfer learning with prefix-tuning at multilingual morphological tasks. Data augmentation significantly improves performance for most languages in the inflection and reinflection tasks. On the other hand, Prefix-tuning on a pre-trained mGPT model helps us to adapt analysis tasks in low-data and multilingual settings. While transformer architectures with data augmentation achieved the most promising results for inflection and reinflection tasks, prefix-tuning on mGPT received the highest results for the analysis task. Our systems received 1st place in all three tasks in MRL 2022. ","[{'version': 'v1', 'created': 'Thu, 3 Nov 2022 11:53:39 GMT'}, {'version': 'v2', 'created': 'Sun, 13 Nov 2022 10:39:39 GMT'}]",2022-11-15,"[['Acikgoz', 'Emre Can', ''], ['Chubakov', 'Tilek', ''], ['Kural', 'Müge', ''], ['Şahin', 'Gözde Gül', ''], ['Yuret', 'Deniz', '']]",0,1,2022-11-03,2,5,3,0,0,0,d181b2c36d74d7603f93f1a323cc417686aab330,253510925.0,https://www.semanticscholar.org/paper/d181b2c36d74d7603f93f1a323cc417686aab330,MRL,2022.0,27.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2189544804', 'name': 'Emre Can Acikgoz'}, {'authorId': '15607891', 'name': 'T. Chubakov'}, {'authorId': '2189544995', 'name': 'Muge Kural'}, {'authorId': '1454232093', 'name': 'Gozde Gul cSahin'}, {'authorId': '2808366', 'name': 'Deniz Yuret'}]",['Koç University'],['Turkey'],2022-11
2211.03468,Qihao Zhu,Qihao Zhu and Jianxi Luo,Generative Transformers for Design Concept Generation,Accepted by J. Comput. Inf. Sci. Eng,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Generating novel and useful concepts is essential during the early design stage to explore a large variety of design opportunities, which usually requires advanced design thinking ability and a wide range of knowledge from designers. Growing works on computer-aided tools have explored the retrieval of knowledge and heuristics from design data. However, they only provide stimuli to inspire designers from limited aspects. This study explores the recent advance of the natural language generation (NLG) technique in the artificial intelligence (AI) field to automate the early-stage design concept generation. Specifically, a novel approach utilizing the generative pre-trained transformer (GPT) is proposed to leverage the knowledge and reasoning from textual data and transform them into new concepts in understandable language. Three concept generation tasks are defined to leverage different knowledge and reasoning: domain knowledge synthesis, problem-driven synthesis, and analogy-driven synthesis. The experiments with both human and data-driven evaluation show good performance in generating novel and useful concepts. ","[{'version': 'v1', 'created': 'Mon, 7 Nov 2022 11:29:10 GMT'}]",2022-11-08,"[['Zhu', 'Qihao', ''], ['Luo', 'Jianxi', '']]",0,1,2022-11-07,1,2,1,0,0,0,de4bce89f5297a00d41d10d4752fe28fbb0db9a4,253384381.0,https://www.semanticscholar.org/paper/de4bce89f5297a00d41d10d4752fe28fbb0db9a4,Journal of Computing and Information Science in Engineering,2022.0,122.0,13.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152203384', 'name': 'Qihao Zhu'}, {'authorId': '145990580', 'name': 'Jianxi Luo'}]",['University of Technology'],['Russia'],2022-11
2211.05584,Sudhandar Balakrishnan,"Sudhandar Balakrishnan, Yihao Fang and Xioadan Zhu",Exploring Robustness of Prefix Tuning in Noisy Data: A Case Study in Financial Sentiment Analysis,Accepted at the FinNLP workshop part of the EMNLP 2022 conference,,,,cs.CL cs.AI cs.CE cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The invention of transformer-based models such as BERT, GPT, and RoBERTa has enabled researchers and financial companies to finetune these powerful models and use them in different downstream tasks to achieve state-of-the-art performance. Recently, a lightweight alternative (approximately 0.1% - 3% of the original model parameters) to fine-tuning, known as prefix tuning has been introduced. This method freezes the model parameters and only updates the prefix to achieve performance comparable to full fine-tuning. Prefix tuning enables researchers and financial practitioners to achieve similar results with much fewer parameters. In this paper, we explore the robustness of prefix tuning when facing noisy data. Our experiments demonstrate that fine-tuning is more robust to noise than prefix tuning -- the latter method faces a significant decrease in performance on most corrupted data sets with increasing noise levels. Furthermore, prefix tuning has high variances in the F1 scores compared to fine-tuning in many corruption methods. We strongly advocate that caution should be carefully taken when applying the state-of-the-art prefix tuning method to noisy data. ","[{'version': 'v1', 'created': 'Wed, 26 Oct 2022 01:13:41 GMT'}]",2022-11-11,"[['Balakrishnan', 'Sudhandar', ''], ['Fang', 'Yihao', ''], ['Zhu', 'Xioadan', '']]",0,1,2022-10-26,1,3,4,0,0,0,59c9e9221a9d09cc125b47d17cf792bb28287488,253447199.0,https://www.semanticscholar.org/paper/59c9e9221a9d09cc125b47d17cf792bb28287488,FINNLP,2022.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2190427028', 'name': 'Sudhandar Balakrishnan'}, {'authorId': '2112786461', 'name': 'Yihao Fang'}, {'authorId': '2190473616', 'name': 'Xioadan Zhu'}]","[""Queen's University""]",['Canada'],2022-10
2211.06193,Elena Soare,"Elena Soare, Iain Mackie, Jeffrey Dalton",DocuT5: Seq2seq SQL Generation with Table Documentation,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Current SQL generators based on pre-trained language models struggle to answer complex questions requiring domain context or understanding fine-grained table structure. Humans would deal with these unknowns by reasoning over the documentation of the tables. Based on this hypothesis, we propose DocuT5, which uses off-the-shelf language model architecture and injects knowledge from external `documentation' to improve domain generalization. We perform experiments on the Spider family of datasets that contain complex questions that are cross-domain and multi-table. Specifically, we develop a new text-to-SQL failure taxonomy and find that 19.6% of errors are due to foreign key mistakes, and 49.2% are due to a lack of domain knowledge. We proposed DocuT5, a method that captures knowledge from (1) table structure context of foreign keys and (2) domain knowledge through contextualizing tables and columns. Both types of knowledge improve over state-of-the-art T5 with constrained decoding on Spider, and domain knowledge produces state-of-the-art comparable effectiveness on Spider-DK and Spider-SYN datasets. ","[{'version': 'v1', 'created': 'Fri, 11 Nov 2022 13:31:55 GMT'}]",2022-11-14,"[['Soare', 'Elena', ''], ['Mackie', 'Iain', ''], ['Dalton', 'Jeffrey', '']]",0,0,2022-11-11,1,3,1,1,1,0,bb5c7acffee7b69e5cf56d7b176a75b651d30848,253498933.0,https://www.semanticscholar.org/paper/bb5c7acffee7b69e5cf56d7b176a75b651d30848,arXiv.org,2022.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3006523', 'name': 'E. Soare'}, {'authorId': '145052856', 'name': 'Iain Mackie'}, {'authorId': '49694325', 'name': 'Jeffrey Stephen Dalton'}]",['University of Glasgow'],['United Kingdom'],2022-11
2211.07524,Ayush Agrawal,"Ayush Agrawal, Siddhartha Gadgil, Navin Goyal, Ashvni Narayanan, Anand
  Tadipatri",Towards a Mathematics Formalisation Assistant using Large Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Mathematics formalisation is the task of writing mathematics (i.e., definitions, theorem statements, proofs) in natural language, as found in books and papers, into a formal language that can then be checked for correctness by a program. It is a thriving activity today, however formalisation remains cumbersome. In this paper, we explore the abilities of a large language model (Codex) to help with formalisation in the Lean theorem prover. We find that with careful input-dependent prompt selection and postprocessing, Codex is able to formalise short mathematical statements at undergrad level with nearly 75\% accuracy for $120$ theorem statements. For proofs quantitative analysis is infeasible and we undertake a detailed case study. We choose a diverse set of $13$ theorems at undergrad level with proofs that fit in two-three paragraphs. We show that with a new prompting strategy Codex can formalise these proofs in natural language with at least one out of twelve Codex completion being easy to repair into a complete proof. This is surprising as essentially no aligned data exists for formalised mathematics, particularly for proofs. These results suggest that large language models are a promising avenue towards fully or partially automating formalisation. ","[{'version': 'v1', 'created': 'Mon, 14 Nov 2022 16:52:32 GMT'}]",2022-11-15,"[['Agrawal', 'Ayush', ''], ['Gadgil', 'Siddhartha', ''], ['Goyal', 'Navin', ''], ['Narayanan', 'Ashvni', ''], ['Tadipatri', 'Anand', '']]",0,0,2022-11-14,1,5,2,1,0,1,b1eebb2df3b9ff7ff2b00fb1a786f6ada2caebce,253510131.0,https://www.semanticscholar.org/paper/b1eebb2df3b9ff7ff2b00fb1a786f6ada2caebce,arXiv.org,2022.0,26.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49566774', 'name': 'Ayush Agrawal'}, {'authorId': '35960615', 'name': 'Siddhartha Gadgil'}, {'authorId': '144260125', 'name': 'Navin Goyal'}, {'authorId': '2047832889', 'name': 'Ashvni Narayanan'}, {'authorId': '2166260749', 'name': 'Anand Tadipatri'}]","['Indian Institute of Science Education and Research Pune', 'Indian Institute of Science Bangalore', 'London School of Geometry and Number Theory London, UK', 'Microsoft']",['India'],2022-11
2211.08192,Pieter Delobelle,Pieter Delobelle and Thomas Winters and Bettina Berendt,RobBERT-2022: Updating a Dutch Language Model to Account for Evolving Language Use,"9 pages, 1 figure, 3 tables",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large transformer-based language models, e.g. BERT and GPT-3, outperform previous architectures on most natural language processing tasks. Such language models are first pre-trained on gigantic corpora of text and later used as base-model for finetuning on a particular task. Since the pre-training step is usually not repeated, base models are not up-to-date with the latest information. In this paper, we update RobBERT, a RoBERTa-based state-of-the-art Dutch language model, which was trained in 2019. First, the tokenizer of RobBERT is updated to include new high-frequent tokens present in the latest Dutch OSCAR corpus, e.g. corona-related words. Then we further pre-train the RobBERT model using this dataset. To evaluate if our new model is a plug-in replacement for RobBERT, we introduce two additional criteria based on concept drift of existing tokens and alignment for novel tokens.We found that for certain language tasks this update results in a significant performance increase. These results highlight the benefit of continually updating a language model to account for evolving language use. ","[{'version': 'v1', 'created': 'Tue, 15 Nov 2022 14:55:53 GMT'}]",2022-11-16,"[['Delobelle', 'Pieter', ''], ['Winters', 'Thomas', ''], ['Berendt', 'Bettina', '']]",0,1,2022-11-15,1,3,2,1,0,1,60d4da04889eb33268ebf58b3b8be730d2877ceb,253523547.0,https://www.semanticscholar.org/paper/60d4da04889eb33268ebf58b3b8be730d2877ceb,arXiv.org,2022.0,36.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150258834', 'name': 'Pieter Delobelle'}, {'authorId': '144329659', 'name': 'Thomas Winters'}, {'authorId': '2990203', 'name': 'Bettina Berendt'}]","['Weizenbaum Institute for the Networked Society', 'KU Leuven', 'Technische Universität Berlin']","['Germany', 'Belgium']",2022-11
2211.08473,Arian Hosseini,"Arian Hosseini, Ankit Vani, Dzmitry Bahdanau, Alessandro Sordoni,
  Aaron Courville",On the Compositional Generalization Gap of In-Context Learning,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Pretrained large generative language models have shown great performance on many tasks, but exhibit low compositional generalization abilities. Scaling such models has been shown to improve their performance on various NLP tasks even just by conditioning them on a few examples to solve the task without any fine-tuning (also known as in-context learning). In this work, we look at the gap between the in-distribution (ID) and out-of-distribution (OOD) performance of such models in semantic parsing tasks with in-context learning. In the ID settings, the demonstrations are from the same split (test or train) that the model is being evaluated on, and in the OOD settings, they are from the other split. We look at how the relative generalization gap of in-context learning evolves as models are scaled up. We evaluate four model families, OPT, BLOOM, CodeGen and Codex on three semantic parsing datasets, CFQ, SCAN and GeoQuery with different number of exemplars, and observe a trend of decreasing relative generalization gap as models are scaled up. ","[{'version': 'v1', 'created': 'Tue, 15 Nov 2022 19:56:37 GMT'}]",2022-11-17,"[['Hosseini', 'Arian', ''], ['Vani', 'Ankit', ''], ['Bahdanau', 'Dzmitry', ''], ['Sordoni', 'Alessandro', ''], ['Courville', 'Aaron', '']]",0,0,2022-11-15,1,5,2,4,3,1,95915aa592fdfc73f039c13472a21d3e4220f129,253553137.0,https://www.semanticscholar.org/paper/95915aa592fdfc73f039c13472a21d3e4220f129,BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP,2022.0,39.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2090537547', 'name': 'Arian Hosseini'}, {'authorId': '34360821', 'name': 'A. Vani'}, {'authorId': '3335364', 'name': 'Dzmitry Bahdanau'}, {'authorId': '2041695', 'name': 'Alessandro Sordoni'}, {'authorId': '2058336670', 'name': 'Aaron C. Courville'}]",['Université de Montréal'],['Canada'],2022-11
2211.09527,F\'abio Vin\'icius Moreira Perez,F\'abio Perez and Ian Ribeiro,Ignore Previous Prompt: Attack Techniques For Language Models,ML Safety Workshop NeurIPS 2022,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Transformer-based large language models (LLMs) provide a powerful foundation for natural language tasks in large-scale customer-facing applications. However, studies that explore their vulnerabilities emerging from malicious user interaction are scarce. By proposing PromptInject, a prosaic alignment framework for mask-based iterative adversarial prompt composition, we examine how GPT-3, the most widely deployed language model in production, can be easily misaligned by simple handcrafted inputs. In particular, we investigate two types of attacks -- goal hijacking and prompt leaking -- and demonstrate that even low-aptitude, but sufficiently ill-intentioned agents, can easily exploit GPT-3's stochastic nature, creating long-tail risks. The code for PromptInject is available at https://github.com/agencyenterprise/PromptInject. ","[{'version': 'v1', 'created': 'Thu, 17 Nov 2022 13:43:20 GMT'}]",2022-11-18,"[['Perez', 'Fábio', ''], ['Ribeiro', 'Ian', '']]",0,1,2022-11-17,1,2,2,1,0,1,9716a2876d08fce9d8e5c5ba4d7b1a9af44806d6,253581710.0,https://www.semanticscholar.org/paper/9716a2876d08fce9d8e5c5ba4d7b1a9af44806d6,arXiv.org,2022.0,40.0,81.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2191070702', 'name': 'Fábio Perez'}, {'authorId': '2191076673', 'name': 'Ian Ribeiro'}]",['Studi'],['Sweden'],2022-11
2211.10117,Ahmet Yavuz Uluslu,Ahmet Yavuz Uluslu and Gerold Schneider,Scaling Native Language Identification with Transformer Adapters,"Paper accepted to International Conference on Natural Language and
  Speech Processing 2022 (ICNLSP 2022)",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Native language identification (NLI) is the task of automatically identifying the native language (L1) of an individual based on their language production in a learned language. It is useful for a variety of purposes including marketing, security and educational applications. NLI is usually framed as a multi-label classification task, where numerous designed features are combined to achieve state-of-the-art results. Recently deep generative approach based on transformer decoders (GPT-2) outperformed its counterparts and achieved the best results on the NLI benchmark datasets. We investigate this approach to determine the practical implications compared to traditional state-of-the-art NLI systems. We introduce transformer adapters to address memory limitations and improve training/inference speed to scale NLI applications for production. ","[{'version': 'v1', 'created': 'Fri, 18 Nov 2022 09:40:16 GMT'}]",2022-11-21,"[['Uluslu', 'Ahmet Yavuz', ''], ['Schneider', 'Gerold', '']]",0,1,2022-11-18,1,2,1,1,1,0,e2a5d8f67c8e0612c2155979a1f1d61737d65be2,253708236.0,https://www.semanticscholar.org/paper/e2a5d8f67c8e0612c2155979a1f1d61737d65be2,International Conference on Natural Language and Speech Processing,2022.0,23.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '9451998', 'name': 'Ahmet Uluslu'}, {'authorId': '145353908', 'name': 'G. Schneider'}]",['University of Zurich'],['Switzerland'],2022-11
2211.11483,Matthew Shardlow,Matthew Shardlow and Piotr Przyby{\l}a,Deanthropomorphising NLP: Can a Language Model Be Conscious?,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work is intended as a voice in the discussion over previous claims that a pretrained large language model (LLM) based on the Transformer model architecture can be sentient. Such claims have been made concerning the LaMDA model and also concerning the current wave of LLM-powered chatbots, such as ChatGPT. This claim, if confirmed, would have serious ramifications in the Natural Language Processing (NLP) community due to wide-spread use of similar models. However, here we take the position that such a large language model cannot be sentient, or conscious, and that LaMDA in particular exhibits no advances over other similar models that would qualify it. We justify this by analysing the Transformer architecture through Integrated Information Theory of consciousness. We see the claims of sentience as part of a wider tendency to use anthropomorphic language in NLP reporting. Regardless of the veracity of the claims, we consider this an opportune moment to take stock of progress in language modelling and consider the ethical implications of the task. In order to make this work helpful for readers outside the NLP community, we also present the necessary background in language modelling. ","[{'version': 'v1', 'created': 'Mon, 21 Nov 2022 14:18:25 GMT'}, {'version': 'v2', 'created': 'Thu, 18 May 2023 13:53:56 GMT'}, {'version': 'v3', 'created': 'Thu, 31 Aug 2023 15:43:56 GMT'}]",2023-09-01,"[['Shardlow', 'Matthew', ''], ['Przybyła', 'Piotr', '']]",1,1,2022-11-21,3,2,2,2,0,2,d0ae1b0e40a19d83153932bc728182802408b349,253734407.0,https://www.semanticscholar.org/paper/d0ae1b0e40a19d83153932bc728182802408b349,arXiv.org,2022.0,95.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2895959', 'name': 'M. Shardlow'}, {'authorId': '1984182', 'name': 'Piotr Przybyła'}]","['Manchester Metropolitan University', 'Pompeu Fabra University', 'Polish Academy of Sciences']","['United Kingdom', 'Spain', 'Poland']",2022-11
2211.12821,Ahmad Haji Mohammadkhani,"Ahmad Haji Mohammadkhani, Chakkrit Tantithamthavorn, Hadi Hemmati",Explainable AI for Pre-Trained Code Models: What Do They Learn? When They Do Not Work?,"10 pages, 7 figures, Accepted at SCAM 2023",,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  In recent years, there has been a wide interest in designing deep neural network-based models that automate downstream software engineering tasks on source code, such as code document generation, code search, and program repair. Although the main objective of these studies is to improve the effectiveness of the downstream task, many studies only attempt to employ the next best neural network model, without a proper in-depth analysis of why a particular solution works or does not, on particular tasks or scenarios. In this paper, using an example eXplainable AI (XAI) method (attention mechanism), we study two recent large language models (LLMs) for code (CodeBERT and GraphCodeBERT) on a set of software engineering downstream tasks: code document generation (CDG), code refinement (CR), and code translation (CT). Through quantitative and qualitative studies, we identify what CodeBERT and GraphCodeBERT learn (put the highest attention on, in terms of source code token types), on these tasks. We also show some of the common patterns when the model does not work as expected (performs poorly even on easy problems) and suggest recommendations that may alleviate the observed challenges. ","[{'version': 'v1', 'created': 'Wed, 23 Nov 2022 10:07:20 GMT'}, {'version': 'v2', 'created': 'Mon, 28 Aug 2023 19:42:34 GMT'}]",2023-08-30,"[['Mohammadkhani', 'Ahmad Haji', ''], ['Tantithamthavorn', 'Chakkrit', ''], ['Hemmati', 'Hadi', '']]",0,0,2022-11-23,2,3,1,0,0,0,2885b4e2a706154494b7b79b4a1a8afc78ce9310,261277955.0,https://www.semanticscholar.org/paper/2885b4e2a706154494b7b79b4a1a8afc78ce9310,,2022.0,38.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2191899265', 'name': 'Ahmad Haji Mohammadkhani'}, {'authorId': '1957122', 'name': 'C. Tantithamthavorn'}, {'authorId': '1857838', 'name': 'H. Hemmati'}]","['Monash University', 'University of Calgary', 'York University']","['Canada', 'Australia']",2022-11
2211.12835,Jakub Macina,"Kumar Shridhar, Jakub Macina, Mennatallah El-Assady, Tanmay Sinha,
  Manu Kapur, Mrinmaya Sachan",Automatic Generation of Socratic Subquestions for Teaching Math Word Problems,"Kumar Shridhar and Jakub Macina contributed equally to this work.
  Accepted at the 2022 Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2022). Code available:
  https://github.com/eth-nlped/scaffolding-generation",,,,cs.CL cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Socratic questioning is an educational method that allows students to discover answers to complex problems by asking them a series of thoughtful questions. Generation of didactically sound questions is challenging, requiring understanding of the reasoning process involved in the problem. We hypothesize that such questioning strategy can not only enhance the human performance, but also assist the math word problem (MWP) solvers. In this work, we explore the ability of large language models (LMs) in generating sequential questions for guiding math word problem-solving. We propose various guided question generation schemes based on input conditioning and reinforcement learning. On both automatic and human quality evaluations, we find that LMs constrained with desirable question properties generate superior questions and improve the overall performance of a math word problem solver. We conduct a preliminary user study to examine the potential value of such question generation models in the education domain. Results suggest that the difficulty level of problems plays an important role in determining whether questioning improves or hinders human performance. We discuss the future of using such questioning strategies in education. ","[{'version': 'v1', 'created': 'Wed, 23 Nov 2022 10:40:22 GMT'}]",2022-11-24,"[['Shridhar', 'Kumar', ''], ['Macina', 'Jakub', ''], ['El-Assady', 'Mennatallah', ''], ['Sinha', 'Tanmay', ''], ['Kapur', 'Manu', ''], ['Sachan', 'Mrinmaya', '']]",0,0,2022-11-23,1,6,3,0,0,0,e6745fb621481ccb0ed53c267a37292e499c1b42,253801800.0,https://www.semanticscholar.org/paper/e6745fb621481ccb0ed53c267a37292e499c1b42,Conference on Empirical Methods in Natural Language Processing,2022.0,65.0,12.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50812160', 'name': 'K. Shridhar'}, {'authorId': '23126830', 'name': 'Jakub Macina'}, {'authorId': '1401917601', 'name': 'Mennatallah El-Assady'}, {'authorId': '145679048', 'name': 'Tanmay Sinha'}, {'authorId': '2465316', 'name': 'Manu Kapur'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]",['ETH Zurich'],['Switzerland'],2022-11
2211.13709,Oskar van der Wal MSc,"Oskar van der Wal, Dominik Bachmann, Alina Leidinger, Leendert van
  Maanen, Willem Zuidema, Katrin Schulz",Undesirable biases in NLP: Averting a crisis of measurement,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As Large Language Models and Natural Language Processing (NLP) technology rapidly develops and spreads into daily life, it becomes crucial to anticipate how its use could harm people. One problem that has received a lot of attention in recent years is that this technology has displayed harmful biases in its behavior. Although a lot of effort has been invested in assessing and mitigating these biases, our methods of measuring the biases of NLP models have serious problems (e.g., it is often unclear what they actually measure). In this paper, we provide an interdisciplinary approach to discussing the issue of NLP model bias by adopting the lens of psychometrics -- a field specialized in the measurement of concepts like bias that are not directly observable. In particular, we will explore two central notions from psychometrics, the construct validity and the reliability of measurement tools, and discuss how they can be applied in the context of measuring model bias. Our goal is to provide NLP practitioners with methodological tools for designing better bias measures, and to inspire them more generally to explore tools from psychometrics when working on bias measurement tools. ","[{'version': 'v1', 'created': 'Thu, 24 Nov 2022 16:53:18 GMT'}, {'version': 'v2', 'created': 'Sun, 16 Jul 2023 22:31:08 GMT'}]",2023-07-18,"[['van der Wal', 'Oskar', ''], ['Bachmann', 'Dominik', ''], ['Leidinger', 'Alina', ''], ['van Maanen', 'Leendert', ''], ['Zuidema', 'Willem', ''], ['Schulz', 'Katrin', '']]",0,0,2022-11-24,2,6,2,0,0,0,92b37b91483fa3a52563f409c1345a1615a551cd,254017505.0,https://www.semanticscholar.org/paper/92b37b91483fa3a52563f409c1345a1615a551cd,arXiv.org,2022.0,137.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '1986356851', 'name': 'Oskar van der Wal'}, {'authorId': '32865491', 'name': 'Dominik Bachmann'}, {'authorId': '28943361', 'name': 'Alina Leidinger'}, {'authorId': '2621000', 'name': 'L. Maanen'}, {'authorId': '83390207', 'name': 'W. Zuidema'}, {'authorId': '47437701', 'name': 'K. Schulz'}]","['University of Amsterdam', 'Utrecht University']",['Netherlands'],2022-11
2211.14228,Rania Abdelghani,"Rania Abdelghani, Yen-Hsiang Wang, Xingdi Yuan, Tong Wang, Pauline
  Lucas, H\'el\`ene Sauz\'eon and Pierre-Yves Oudeyer",GPT-3-driven pedagogical agents for training children's curious question-asking skills,,,10.1007/s40593-023-00340-7,,cs.CL cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In order to train children's ability to ask curiosity-driven questions, previous research has explored designing specific exercises relying on providing semantic and linguistic cues to help formulate such questions. But despite showing pedagogical efficiency, this method is still limited as it relies on generating the said cues by hand, which can be a very costly process. In this context, we propose to leverage advances in the natural language processing field (NLP) and investigate the efficiency of using a large language model (LLM) for automating the production of the pedagogical content of a curious question-asking (QA) training. We study generating the said content using the ""prompt-based"" method that consists of explaining the task to the LLM in natural text. We evaluate the output using human experts annotations and comparisons with hand-generated content. Results suggested indeed the relevance and usefulness of this content. We also conduct a field study in primary school (75 children aged 9-10), where we evaluate children's QA performance when having this training. We compare 3 types of content : 1) hand-generated content that proposes ""closed"" cues leading to predefined questions; 2) GPT-3-generated content that proposes the same type of cues; 3) GPT-3-generated content that proposes ""open"" cues leading to several possible questions. We see a similar QA performance between the two ""closed"" trainings (showing the scalability of the approach using GPT-3), and a better one for participants with the ""open"" training. These results suggest the efficiency of using LLMs to support children in generating more curious questions, using a natural language prompting approach that affords usability by teachers and other users not specialists of AI techniques. Furthermore, results also show that open-ended content may be more suitable for training curious question-asking skills. ","[{'version': 'v1', 'created': 'Fri, 25 Nov 2022 16:41:59 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Nov 2022 15:27:35 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Dec 2022 10:10:35 GMT'}, {'version': 'v4', 'created': 'Fri, 10 Mar 2023 17:24:26 GMT'}, {'version': 'v5', 'created': 'Fri, 17 Mar 2023 16:14:55 GMT'}, {'version': 'v6', 'created': 'Tue, 30 May 2023 14:34:12 GMT'}]",2023-07-04,"[['Abdelghani', 'Rania', ''], ['Wang', 'Yen-Hsiang', ''], ['Yuan', 'Xingdi', ''], ['Wang', 'Tong', ''], ['Lucas', 'Pauline', ''], ['Sauzéon', 'Hélène', ''], ['Oudeyer', 'Pierre-Yves', '']]",0,1,2022-11-25,6,7,2,1,0,1,2677645b0f96c8c055b83c904d531cfe22b2e623,254018349.0,https://www.semanticscholar.org/paper/2677645b0f96c8c055b83c904d531cfe22b2e623,International Journal of Artificial Intelligence in Education,2022.0,79.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2154047060', 'name': 'Rania Abdelghani'}, {'authorId': '2132893637', 'name': 'Yen-Hsiang Wang'}, {'authorId': '2854297', 'name': 'Xingdi Yuan'}, {'authorId': '1664686681', 'name': 'Tong Wang'}, {'authorId': '2185728824', 'name': ""H'elene Sauz'eon""}, {'authorId': '1720664', 'name': 'Pierre-Yves Oudeyer'}]","['National Chung Hsing University', 'EvidenceB, France', 'French Institute for Research in Computer Science and Automation', 'Microsoft', 'University of Bordeaux']","['Canada', 'Taiwan', 'France']",2022-11
2211.15006,Michiel Bakker,"Michiel A. Bakker and Martin J. Chadwick and Hannah R. Sheahan and
  Michael Henry Tessler and Lucy Campbell-Gillingham and Jan Balaguer and Nat
  McAleese and Amelia Glaese and John Aslanides and Matthew M. Botvinick and
  Christopher Summerfield",Fine-tuning language models to find agreement among humans with diverse preferences,,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent work in large language modeling (LLMs) has used fine-tuning to align outputs with the preferences of a prototypical user. This work assumes that human preferences are static and homogeneous across individuals, so that aligning to a a single ""generic"" user will confer more general alignment. Here, we embrace the heterogeneity of human preferences to consider a different challenge: how might a machine help people with diverse views find agreement? We fine-tune a 70 billion parameter LLM to generate statements that maximize the expected approval for a group of people with potentially diverse opinions. Human participants provide written opinions on thousands of questions touching on moral and political issues (e.g., ""should we raise taxes on the rich?""), and rate the LLM's generated candidate consensus statements for agreement and quality. A reward model is then trained to predict individual preferences, enabling it to quantify and rank consensus statements in terms of their appeal to the overall group, defined according to different aggregation (social welfare) functions. The model produces consensus statements that are preferred by human users over those from prompted LLMs (>70%) and significantly outperforms a tight fine-tuned baseline that lacks the final ranking step. Further, our best model's consensus statements are preferred over the best human-generated opinions (>65%). We find that when we silently constructed consensus statements from only a subset of group members, those who were excluded were more likely to dissent, revealing the sensitivity of the consensus to individual contributions. These results highlight the potential to use LLMs to help groups of humans align their values with one another. ","[{'version': 'v1', 'created': 'Mon, 28 Nov 2022 02:24:14 GMT'}]",2022-11-29,"[['Bakker', 'Michiel A.', ''], ['Chadwick', 'Martin J.', ''], ['Sheahan', 'Hannah R.', ''], ['Tessler', 'Michael Henry', ''], ['Campbell-Gillingham', 'Lucy', ''], ['Balaguer', 'Jan', ''], ['McAleese', 'Nat', ''], ['Glaese', 'Amelia', ''], ['Aslanides', 'John', ''], ['Botvinick', 'Matthew M.', ''], ['Summerfield', 'Christopher', '']]",0,0,2022-11-28,1,11,2,0,0,0,de1c7ae2818aa26fc86a0ea8ed70014cffc8b20a,254043997.0,https://www.semanticscholar.org/paper/de1c7ae2818aa26fc86a0ea8ed70014cffc8b20a,Neural Information Processing Systems,2022.0,45.0,54.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50985185', 'name': 'Michiel A. Bakker'}, {'authorId': '2159545857', 'name': 'Martin Chadwick'}, {'authorId': '35519027', 'name': 'Hannah Sheahan'}, {'authorId': '37826548', 'name': 'Michael Henry Tessler'}, {'authorId': '2151248210', 'name': 'Lucy Campbell-Gillingham'}, {'authorId': '38395548', 'name': 'Jan Balaguer'}, {'authorId': '147687624', 'name': 'Nathan McAleese'}, {'authorId': '2105840001', 'name': 'A. Glaese'}, {'authorId': '9958912', 'name': 'J. Aslanides'}, {'authorId': '46378362', 'name': 'M. Botvinick'}, {'authorId': '2372244', 'name': 'C. Summerfield'}]","['University College London', 'Google', 'University of Oxford']",['United Kingdom'],2022-11
2211.15268,Tamara Czinczoll,"Tamara Czinczoll, Helen Yannakoudakis, Pushkar Mishra, Ekaterina
  Shutova",Scientific and Creative Analogies in Pretrained Language Models,To be published in Findings of EMNLP 2022,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper examines the encoding of analogy in large-scale pretrained language models, such as BERT and GPT-2. Existing analogy datasets typically focus on a limited set of analogical relations, with a high similarity of the two domains between which the analogy holds. As a more realistic setup, we introduce the Scientific and Creative Analogy dataset (SCAN), a novel analogy dataset containing systematic mappings of multiple attributes and relational structures across dissimilar domains. Using this dataset, we test the analogical reasoning capabilities of several widely-used pretrained language models (LMs). We find that state-of-the-art LMs achieve low performance on these complex analogy tasks, highlighting the challenges still posed by analogy understanding. ","[{'version': 'v1', 'created': 'Mon, 28 Nov 2022 12:49:44 GMT'}]",2022-11-29,"[['Czinczoll', 'Tamara', ''], ['Yannakoudakis', 'Helen', ''], ['Mishra', 'Pushkar', ''], ['Shutova', 'Ekaterina', '']]",0,1,2022-11-28,1,4,2,1,1,0,933f60dda5847f208d9d3fd65e9b0df9cfed2403,254043686.0,https://www.semanticscholar.org/paper/933f60dda5847f208d9d3fd65e9b0df9cfed2403,Conference on Empirical Methods in Natural Language Processing,2022.0,23.0,7.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2192603446', 'name': 'Tamara Czinczoll'}, {'authorId': '2169553', 'name': 'H. Yannakoudakis'}, {'authorId': '3047561', 'name': 'Pushkar Mishra'}, {'authorId': '2362276', 'name': 'Ekaterina Shutova'}]","['University of Amsterdam', 'Hasso Plattner Institute', ""King's College London"", 'Meta']","['Germany', 'United Kingdom', 'Netherlands']",2022-11
2211.15603,Ravi Kiran Sarvadevabhatla,"Sai Shashank Kalakonda, Shubh Maheshwari, Ravi Kiran Sarvadevabhatla",Action-GPT: Leveraging Large-scale Language Models for Improved and Generalized Action Generation,"Code, pretrained models and sample videos will be made available at
  \url{https://actiongpt.github.io}",,,,cs.CV cs.GR cs.MM,http://creativecommons.org/licenses/by/4.0/,"  We introduce Action-GPT, a plug-and-play framework for incorporating Large Language Models (LLMs) into text-based action generation models. Action phrases in current motion capture datasets contain minimal and to-the-point information. By carefully crafting prompts for LLMs, we generate richer and fine-grained descriptions of the action. We show that utilizing these detailed descriptions instead of the original action phrases leads to better alignment of text and motion spaces. We introduce a generic approach compatible with stochastic (e.g. VAE-based) and deterministic (e.g. MotionCLIP) text-to-motion models. In addition, the approach enables multiple text descriptions to be utilized. Our experiments show (i) noticeable qualitative and quantitative improvement in the quality of synthesized motions, (ii) benefits of utilizing multiple LLM-generated descriptions, (iii) suitability of the prompt function, and (iv) zero-shot generation capabilities of the proposed approach. Project page: https://actiongpt.github.io ","[{'version': 'v1', 'created': 'Mon, 28 Nov 2022 17:57:48 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Nov 2022 13:13:29 GMT'}, {'version': 'v3', 'created': 'Tue, 7 Mar 2023 06:14:56 GMT'}]",2023-03-08,"[['Kalakonda', 'Sai Shashank', ''], ['Maheshwari', 'Shubh', ''], ['Sarvadevabhatla', 'Ravi Kiran', '']]",0,1,2022-11-28,3,3,3,0,0,0,cb2954127a7fce8ab84486765392ce95dcdd8175,257378694.0,https://www.semanticscholar.org/paper/cb2954127a7fce8ab84486765392ce95dcdd8175,IEEE International Conference on Multimedia and Expo,2022.0,18.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2192604064', 'name': 'Sai Shashank Kalakonda'}, {'authorId': '51440276', 'name': 'Shubham Maheshwari'}, {'authorId': '1730952', 'name': 'Ravi Kiran Sarvadevabhatla'}]","['International Institute of Information Technology, Hyderabad']",['India'],2022-11
2211.15914,Adithya Bhaskar,"Adithya Bhaskar, Alexander R. Fabbri and Greg Durrett",Prompted Opinion Summarization with GPT-3.5,Accepted to ACL (Findings) 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models have shown impressive performance across a wide variety of tasks, including text summarization. In this paper, we show that this strong performance extends to opinion summarization. We explore several pipeline methods for applying GPT-3.5 to summarize a large collection of user reviews in a prompted fashion. To handle arbitrarily large numbers of user reviews, we explore recursive summarization as well as methods for selecting salient content to summarize through supervised clustering or extraction. On two datasets, an aspect-oriented summarization dataset of hotel reviews (SPACE) and a generic summarization dataset of Amazon and Yelp reviews (FewSum), we show that GPT-3.5 models achieve very strong performance in human evaluation. We argue that standard evaluation metrics do not reflect this, and introduce three new metrics targeting faithfulness, factuality, and genericity to contrast these different methods. ","[{'version': 'v1', 'created': 'Tue, 29 Nov 2022 04:06:21 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 06:19:47 GMT'}]",2023-05-24,"[['Bhaskar', 'Adithya', ''], ['Fabbri', 'Alexander R.', ''], ['Durrett', 'Greg', '']]",0,1,2022-11-29,2,3,1,1,0,1,e6d7caa77eae7b64f78359669f4dd48fd2d177a1,258841826.0,https://www.semanticscholar.org/paper/e6d7caa77eae7b64f78359669f4dd48fd2d177a1,Annual Meeting of the Association for Computational Linguistics,2022.0,61.0,10.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2150764285', 'name': 'Adithya Bhaskar'}, {'authorId': '46255971', 'name': 'Alexander R. Fabbri'}, {'authorId': '1814094', 'name': 'Greg Durrett'}]",['Indian Institute of Technology Bombay'],['India'],2022-11
2212.00193,Kumar Shridhar,"Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan",Distilling Reasoning Capabilities into Smaller Language Models,Accepted at ACL 2023 (Findings),,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Step-by-step reasoning approaches like chain of thought (CoT) have proved to be very effective in inducing reasoning capabilities in large language models. However, the success of the CoT approach is fundamentally tied to the model size, and billion parameter-scale models are often needed to get CoT to work. In this paper, we propose a knowledge distillation approach that leverages the step-by-step CoT reasoning capabilities of larger models and distills these abilities into smaller models.   In this work, we propose an alternative reasoning scheme, Socratic CoT, that learns a decomposition of the original problem into a sequence of subproblems and uses it to guide the intermediate reasoning steps. We use Socratic CoT to train a combination of two small distilled models: a problem decomposer and a subproblem solver. In practice, given a new problem, the two distilled models work in sync to decompose and solve complex problems. On multiple reasoning datasets (GSM8K, StrategyQA, and SVAMP), our proposed distillation strategies boosts the performance of smaller models over 70% compared to the baselines. Finally, we investigate when Socratic CoT is an effective alternative to CoT, demonstrating cases where a much smaller model (GPT-2 large) can outperform a 10X larger model (GPT-3 6B). Our code is available here: https://github.com/kumar-shridhar/Distiiling-LM ","[{'version': 'v1', 'created': 'Thu, 1 Dec 2022 00:39:56 GMT'}, {'version': 'v2', 'created': 'Thu, 18 May 2023 04:44:51 GMT'}]",2023-05-19,"[['Shridhar', 'Kumar', ''], ['Stolfo', 'Alessandro', ''], ['Sachan', 'Mrinmaya', '']]",0,1,2022-12-01,2,3,2,2,1,1,8fd462f6248d5e3f1b6602697c09489086b5655f,258762841.0,https://www.semanticscholar.org/paper/8fd462f6248d5e3f1b6602697c09489086b5655f,Annual Meeting of the Association for Computational Linguistics,2022.0,43.0,19.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50812160', 'name': 'K. Shridhar'}, {'authorId': '2175480389', 'name': 'Alessandro Stolfo'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]",['ETH Zurich'],['Switzerland'],2022-12
2212.01692,Michal \v{S}tef\'anik,Michal \v{S}tef\'anik and Marek Kadl\v{c}\'ik,Can In-context Learners Learn a Reasoning Concept from Demonstrations?,"Awarded Best Paper at ACL 2023 Natural Language Reasoning and
  Structured Explanations (NLRSE) workshop",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Language models exhibit an emergent ability to learn a new task from a small number of input-output demonstrations. However, recent work shows that in-context learners largely rely on their pre-trained knowledge, such as the sentiment of the labels, instead of learning new associations from the input. We argue that the commonly-used few-shot evaluation using a random selection of in-context demonstrations can not disentangle models' reliance on such biases, as most of the randomly-selected demonstrations do not present relations informative for prediction beyond exposing the task's input-output distribution.   Therefore, to evaluate models' in-context learning ability independent of models' memory, we introduce a Concept-sharing few-shot learning method choosing the demonstrations that share an underlying concept with the predicted sample. We extract a set of such concepts from available human explanations and measure how much models can benefit from presenting these concepts in few-shot demonstrations.   We find that most of the recent in-context learners can not consistently benefit from the demonstrated concepts, irrespective of the model size. However, we note that T0 models are more sensitive to exhibited concepts, benefiting from concept-sharing demonstrations in 7 out of 8 evaluation scenarios. ","[{'version': 'v1', 'created': 'Sat, 3 Dec 2022 21:14:32 GMT'}, {'version': 'v2', 'created': 'Thu, 4 May 2023 20:45:23 GMT'}, {'version': 'v3', 'created': 'Tue, 6 Jun 2023 12:09:47 GMT'}, {'version': 'v4', 'created': 'Wed, 19 Jul 2023 06:48:35 GMT'}]",2023-07-20,"[['Štefánik', 'Michal', ''], ['Kadlčík', 'Marek', '']]",0,0,2022-12-03,4,2,3,1,1,0,e7cfc3362dd85b17c747e9f9636749696f87a88b,258547350.0,https://www.semanticscholar.org/paper/e7cfc3362dd85b17c747e9f9636749696f87a88b,NLRSE,2022.0,29.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2229863733', 'name': 'Michal Tefnik'}, {'authorId': '2194666242', 'name': 'Marek Kadlcík'}]",['Masaryk University'],['Czechia'],2022-12
2212.01907,Ayrton San Joaquin,Ayrton San Joaquin and Ardy Haroen,Understanding How Model Size Affects Few-shot Instruction Prompting,,,,,cs.CL cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models are affected by the phenomena of memorizing and forgetting their training data. But how do these vary by model size? We work towards this question by investigating how the model size affects the model's ability to discriminate a word's meaning in a given context. We introduce a dataset called DeltaWords, which evaluates a model's ability to follow instructions to select a sentence which replaces the target word with its antonym. We show a weak inverse scaling trend, where task accuracy degrades as model size increase, under extremely few-shot prompting regimes. We show that increasing the number of examples tend to disproportionately benefit larger models than smaller models. ","[{'version': 'v1', 'created': 'Sun, 4 Dec 2022 19:59:52 GMT'}]",2022-12-06,"[['Joaquin', 'Ayrton San', ''], ['Haroen', 'Ardy', '']]",0,0,2022-12-04,1,2,3,0,0,0,72491b96d8a614d1a9a099707d44593d4b5a8f49,254246327.0,https://www.semanticscholar.org/paper/72491b96d8a614d1a9a099707d44593d4b5a8f49,arXiv.org,2022.0,12.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2161243047', 'name': 'Ayrton San Joaquin'}, {'authorId': '2193550898', 'name': 'Ardy Haroen'}]",['Yale-NUS College'],['Singapore'],2022-12
2212.02564,David Pomerenke,David Pomerenke,INCLUSIFY: A benchmark and a model for gender-inclusive German,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Gender-inclusive language is important for achieving gender equality in languages with gender inflections, such as German. While stirring some controversy, it is increasingly adopted by companies and political institutions. A handful of tools have been developed to help people use gender-inclusive language by identifying instances of the generic masculine and providing suggestions for more inclusive reformulations. In this report, we define the underlying tasks in terms of natural language processing, and present a dataset and measures for benchmarking them. We also present a model that implements these tasks, by combining an inclusive language database with an elaborate sequence of processing steps via standard pre-trained models. Our model achieves a recall of 0.89 and a precision of 0.82 in our benchmark for identifying exclusive language; and one of its top five suggestions is chosen in real-world texts in 44% of cases. We sketch how the area could be further advanced by training end-to-end models and using large language models; and we urge the community to include more gender-inclusive texts in their training data in order to not present an obstacle to the adoption of gender-inclusive language. Through these efforts, we hope to contribute to restoring justice in language and, to a small extent, in reality. ","[{'version': 'v1', 'created': 'Mon, 5 Dec 2022 19:37:48 GMT'}]",2022-12-07,"[['Pomerenke', 'David', '']]",0,0,2022-12-05,1,1,1,0,0,0,530e32d5442c3e1f990f6e69a6e14f56d1674402,254275340.0,https://www.semanticscholar.org/paper/530e32d5442c3e1f990f6e69a6e14f56d1674402,arXiv.org,2022.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151407485', 'name': 'David Pomerenke'}]",['Maastricht University'],['Netherlands'],2022-12
2212.02911,"Mika H\""am\""al\""ainen","Mika H\""am\""al\""ainen, Khalid Alnajjar, Thierry Poibeau",Modern French Poetry Generation with RoBERTa and GPT-2,ICCC 2022,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present a novel neural model for modern poetry generation in French. The model consists of two pretrained neural models that are fine-tuned for the poem generation task. The encoder of the model is a RoBERTa based one while the decoder is based on GPT-2. This way the model can benefit from the superior natural language understanding performance of RoBERTa and the good natural language generation performance of GPT-2. Our evaluation shows that the model can create French poetry successfully. On a 5 point scale, the lowest score of 3.57 was given by human judges to typicality and emotionality of the output poetry while the best score of 3.79 was given to understandability. ","[{'version': 'v1', 'created': 'Tue, 6 Dec 2022 12:10:14 GMT'}]",2022-12-07,"[['Hämäläinen', 'Mika', ''], ['Alnajjar', 'Khalid', ''], ['Poibeau', 'Thierry', '']]",0,1,2022-12-06,1,3,1,1,1,0,d81cec1cd1f4e86aed128dfeb526ec1eb865b99c,251630416.0,https://www.semanticscholar.org/paper/d81cec1cd1f4e86aed128dfeb526ec1eb865b99c,International Conference on Innovative Computing and Cloud Computing,2022.0,36.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '16304586', 'name': 'Mika Hämäläinen'}, {'authorId': '150169636', 'name': 'Khalid Alnajjar'}, {'authorId': '1736763', 'name': 'T. Poibeau'}]","['University of Helsinki', 'École Normale Supérieure - PSL']","['France', 'Finland']",2022-12
2212.03404,Lola Burgue\~no,Meriem Ben Chaaben and Lola Burgue\~no and Houari Sahraoui,Towards using Few-Shot Prompt Learning for Automating Model Completion,,,,,cs.SE cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,  We propose a simple yet a novel approach to improve completion in domain modeling activities. Our approach exploits the power of large language models by using few-shot prompt learning without the need to train or fine-tune those models with large datasets that are scarce in this field. We implemented our approach and tested it on the completion of static and dynamic domain diagrams. Our initial evaluation shows that such an approach is effective and can be integrated in different ways during the modeling activities. ,"[{'version': 'v1', 'created': 'Wed, 7 Dec 2022 02:11:26 GMT'}]",2022-12-08,"[['Chaaben', 'Meriem Ben', ''], ['Burgueño', 'Lola', ''], ['Sahraoui', 'Houari', '']]",0,0,2022-12-07,1,3,2,0,0,0,2a99239f09e95f4dbccec572d66f4519206762f9,254366308.0,https://www.semanticscholar.org/paper/2a99239f09e95f4dbccec572d66f4519206762f9,2023 IEEE/ACM 45th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER),2022.0,17.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2193797620', 'name': 'Meriem Ben Chaaben'}, {'authorId': '2158729701', 'name': 'Lola Burgueño'}, {'authorId': '9460712', 'name': 'H. Sahraoui'}]","['Universidad de Málaga', 'Université de Montréal']","['Canada', 'Spain']",2022-12
2212.03551,Murray Shanahan,Murray Shanahan,Talking About Large Language Models,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Thanks to rapid progress in artificial intelligence, we have entered an era when technology and philosophy intersect in interesting ways. Sitting squarely at the centre of this intersection are large language models (LLMs). The more adept LLMs become at mimicking human language, the more vulnerable we become to anthropomorphism, to seeing the systems in which they are embedded as more human-like than they really are. This trend is amplified by the natural tendency to use philosophically loaded terms, such as ""knows"", ""believes"", and ""thinks"", when describing these systems. To mitigate this trend, this paper advocates the practice of repeatedly stepping back to remind ourselves of how LLMs, and the systems of which they form a part, actually work. The hope is that increased scientific precision will encourage more philosophical nuance in the discourse around artificial intelligence, both within the field and in the public sphere. ","[{'version': 'v1', 'created': 'Wed, 7 Dec 2022 10:01:44 GMT'}, {'version': 'v2', 'created': 'Sun, 11 Dec 2022 07:57:32 GMT'}, {'version': 'v3', 'created': 'Mon, 23 Jan 2023 10:55:33 GMT'}, {'version': 'v4', 'created': 'Wed, 25 Jan 2023 15:27:15 GMT'}, {'version': 'v5', 'created': 'Thu, 16 Feb 2023 14:44:31 GMT'}]",2023-02-17,"[['Shanahan', 'Murray', '']]",0,0,2022-12-07,5,1,2,0,0,0,3eed4de25636ac90f39f6e1ef70e3507ed61a2a6,254366666.0,https://www.semanticscholar.org/paper/3eed4de25636ac90f39f6e1ef70e3507ed61a2a6,arXiv.org,2022.0,39.0,57.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1757629', 'name': 'M. Shanahan'}]",['Imperial College London'],['United Kingdom'],2022-12
2212.03869,Sahan Bulathwela,"Hamze Muse, Sahan Bulathwela and Emine Yilmaz",Pre-Training With Scientific Text Improves Educational Question Generation,In Proceedings of AAAI Conference on Artificial Intelligence 2023,,,,cs.CL cs.AI cs.CY cs.IR cs.LG stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the boom of digital educational materials and scalable e-learning systems, the potential for realising AI-assisted personalised learning has skyrocketed. In this landscape, the automatic generation of educational questions will play a key role, enabling scalable self-assessment when a global population is manoeuvring their personalised learning journeys. We develop EduQG, a novel educational question generation model built by adapting a large language model. Our initial experiments demonstrate that EduQG can produce superior educational questions by pre-training on scientific text. ","[{'version': 'v1', 'created': 'Wed, 7 Dec 2022 17:17:58 GMT'}]",2022-12-09,"[['Muse', 'Hamze', ''], ['Bulathwela', 'Sahan', ''], ['Yilmaz', 'Emine', '']]",0,0,2022-12-07,1,3,6,0,0,0,da30feb57cdf15c25493b300de541f4debc026aa,254409013.0,https://www.semanticscholar.org/paper/da30feb57cdf15c25493b300de541f4debc026aa,AAAI Conference on Artificial Intelligence,2022.0,10.0,1.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2194647884', 'name': 'Hamze Muse'}, {'authorId': '2143115611', 'name': 'Sahan Bulathwela'}, {'authorId': '2084638888', 'name': 'Emine Yilmaz'}]",['University College London'],['United Kingdom'],2022-12
2212.04348,Emiel van Miltenburg,Hien Huynh and Tomas O. Lentz and Emiel van Miltenburg,Implicit causality in GPT-2: a case study,"5 pages, unpublished manuscript",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This case study investigates the extent to which a language model (GPT-2) is able to capture native speakers' intuitions about implicit causality in a sentence completion task. We first reproduce earlier results (showing lower surprisal values for pronouns that are congruent with either the subject or object, depending on which one corresponds to the implicit causality bias of the verb), and then examine the effects of gender and verb frequency on model performance. Our second study examines the reasoning ability of GPT-2: is the model able to produce more sensible motivations for why the subject VERBed the object if the verbs have stronger causality biases? We also developed a methodology to avoid human raters being biased by obscenities and disfluencies generated by the model. ","[{'version': 'v1', 'created': 'Thu, 8 Dec 2022 15:42:38 GMT'}]",2022-12-09,"[['Huynh', 'Hien', ''], ['Lentz', 'Tomas O.', ''], ['van Miltenburg', 'Emiel', '']]",0,1,2022-12-08,1,3,2,1,1,0,e8f57752f8be4bd0819a3ba380837b9f107387eb,254408852.0,https://www.semanticscholar.org/paper/e8f57752f8be4bd0819a3ba380837b9f107387eb,International Conference on Computational Semantics,2022.0,31.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2065923802', 'name': 'H. Huynh'}, {'authorId': '2581383', 'name': 'T. Lentz'}, {'authorId': '3192572', 'name': 'Emiel van Miltenburg'}]",['Tilburg University'],['Netherlands'],2022-12
2212.05058,Liam Magee,"Liam Magee, Vanicka Arora, Luke Munn",Structured Like a Language Model: Analysing AI as an Automated Subject,,,,,cs.CY cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Drawing from the resources of psychoanalysis and critical media studies, in this paper we develop an analysis of Large Language Models (LLMs) as automated subjects. We argue the intentional fictional projection of subjectivity onto LLMs can yield an alternate frame through which AI behaviour, including its productions of bias and harm, can be analysed. First, we introduce language models, discuss their significance and risks, and outline our case for interpreting model design and outputs with support from psychoanalytic concepts. We trace a brief history of language models, culminating with the releases, in 2022, of systems that realise state-of-the-art natural language processing performance. We engage with one such system, OpenAI's InstructGPT, as a case study, detailing the layers of its construction and conducting exploratory and semi-structured interviews with chatbots. These interviews probe the model's moral imperatives to be helpful, truthful and harmless by design. The model acts, we argue, as the condensation of often competing social desires, articulated through the internet and harvested into training data, which must then be regulated and repressed. This foundational structure can however be redirected via prompting, so that the model comes to identify with, and transfer, its commitments to the immediate human subject before it. In turn, these automated productions of language can lead to the human subject projecting agency upon the model, effecting occasionally further forms of countertransference. We conclude that critical media methods and psychoanalytic theory together offer a productive frame for grasping the powerful new capacities of AI-driven language systems. ","[{'version': 'v1', 'created': 'Thu, 8 Dec 2022 21:58:43 GMT'}]",2022-12-13,"[['Magee', 'Liam', ''], ['Arora', 'Vanicka', ''], ['Munn', 'Luke', '']]",0,1,2022-12-08,1,3,2,1,0,1,a8e9da42ba370b6694c48c447e392532f26dad9f,254563766.0,https://www.semanticscholar.org/paper/a8e9da42ba370b6694c48c447e392532f26dad9f,Big Data &amp; Society,2022.0,53.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2733075', 'name': 'L. Magee'}, {'authorId': '121615955', 'name': 'Vanicka Arora'}, {'authorId': '73236053', 'name': 'Luke Munn'}]","['University of Stirling', 'Western Sydney University', 'University of Queensland']","['United Kingdom', 'Australia']",2022-12
2212.05409,Sumanth Doddapaneni,"Sumanth Doddapaneni, Rahul Aralikatte, Gowtham Ramesh, Shreya Goyal,
  Mitesh M. Khapra, Anoop Kunchukuttan, Pratyush Kumar","Towards Leaving No Indic Language Behind: Building Monolingual Corpora, Benchmark and Models for Indic Languages",ACL 2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Building Natural Language Understanding (NLU) capabilities for Indic languages, which have a collective speaker base of more than one billion speakers is absolutely crucial. In this work, we aim to improve the NLU capabilities of Indic languages by making contributions along 3 important axes (i) monolingual corpora (ii) NLU testsets (iii) multilingual LLMs focusing on Indic languages. Specifically, we curate the largest monolingual corpora, IndicCorp, with 20.9B tokens covering 24 languages from 4 language families - a 2.3x increase over prior work, while supporting 12 additional languages. Next, we create a human-supervised benchmark, IndicXTREME, consisting of nine diverse NLU tasks covering 20 languages. Across languages and tasks, IndicXTREME contains a total of 105 evaluation sets, of which 52 are new contributions to the literature. To the best of our knowledge, this is the first effort towards creating a standard benchmark for Indic languages that aims to test the multilingual zero-shot capabilities of pretrained language models. Finally, we train IndicBERT v2, a state-of-the-art model supporting all the languages. Averaged across languages and tasks, the model achieves an absolute improvement of 2 points over a strong baseline. The data and models are available at https://github.com/AI4Bharat/IndicBERT. ","[{'version': 'v1', 'created': 'Sun, 11 Dec 2022 04:45:50 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Dec 2022 18:47:27 GMT'}, {'version': 'v3', 'created': 'Wed, 24 May 2023 17:05:16 GMT'}]",2023-05-25,"[['Doddapaneni', 'Sumanth', ''], ['Aralikatte', 'Rahul', ''], ['Ramesh', 'Gowtham', ''], ['Goyal', 'Shreya', ''], ['Khapra', 'Mitesh M.', ''], ['Kunchukuttan', 'Anoop', ''], ['Kumar', 'Pratyush', '']]",0,0,2022-12-11,3,7,1,0,0,0,a87576ff578ec1781f9cb48934c3e837144afdcb,258866084.0,https://www.semanticscholar.org/paper/a87576ff578ec1781f9cb48934c3e837144afdcb,Annual Meeting of the Association for Computational Linguistics,2022.0,52.0,8.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2072738714', 'name': 'Sumanth Doddapaneni'}, {'authorId': '19509693', 'name': 'Rahul Aralikatte'}, {'authorId': '49157297', 'name': 'Gowtham Ramesh'}, {'authorId': '151207081', 'name': 'Shreyansh Goyal'}, {'authorId': '2361078', 'name': 'Mitesh M. Khapra'}, {'authorId': '1711973', 'name': 'Anoop Kunchukuttan'}, {'authorId': '38724234', 'name': 'Pratyush Kumar'}]","['McGill University', 'Indian Institute of Technology Madras']","['Canada', 'India']",2022-12
2212.05856,Zarrin Tasnim Sworna,"Mubin Ul Haque, Isuru Dharmadasa, Zarrin Tasnim Sworna, Roshan Namal
  Rajapakse, and Hussain Ahmad","""I think this is the most disruptive technology"": Exploring Sentiments of ChatGPT Early Adopters using Twitter Data",This is an early version of this paper,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models have recently attracted significant attention due to their impressive performance on a variety of tasks. ChatGPT developed by OpenAI is one such implementation of a large, pre-trained language model that has gained immense popularity among early adopters, where certain users go to the extent of characterizing it as a disruptive technology in many domains. Understanding such early adopters' sentiments is important because it can provide insights into the potential success or failure of the technology, as well as its strengths and weaknesses. In this paper, we conduct a mixed-method study using 10,732 tweets from early ChatGPT users. We first use topic modelling to identify the main topics and then perform an in-depth qualitative sentiment analysis of each topic. Our results show that the majority of the early adopters have expressed overwhelmingly positive sentiments related to topics such as Disruptions to software development, Entertainment and exercising creativity. Only a limited percentage of users expressed concerns about issues such as the potential for misuse of ChatGPT, especially regarding topics such as Impact on educational aspects. We discuss these findings by providing specific examples for each topic and then detail implications related to addressing these concerns for both researchers and users. ","[{'version': 'v1', 'created': 'Mon, 12 Dec 2022 12:41:24 GMT'}]",2022-12-13,"[['Haque', 'Mubin Ul', ''], ['Dharmadasa', 'Isuru', ''], ['Sworna', 'Zarrin Tasnim', ''], ['Rajapakse', 'Roshan Namal', ''], ['Ahmad', 'Hussain', '']]",1,1,2022-12-12,1,5,1,1,0,1,7eb094b63ecd57b530a9ccfbfd96287a510b9c7f,254564371.0,https://www.semanticscholar.org/paper/7eb094b63ecd57b530a9ccfbfd96287a510b9c7f,arXiv.org,2022.0,34.0,80.0,10.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3367165', 'name': 'Mubin Ul Haque'}, {'authorId': '39967996', 'name': 'I. Dharmadasa'}, {'authorId': '3375832', 'name': 'Zarrin Tasnim Sworna'}, {'authorId': '1678246762', 'name': 'R. Rajapakse'}, {'authorId': '2195183752', 'name': 'Hussain Ahmad'}]",['University of Adelaide'],['Australia'],2022-12
2212.06094,Marc Fischer,"Luca Beurer-Kellner, Marc Fischer, Martin Vechev",Prompting Is Programming: A Query Language for Large Language Models,"To be published at PLDI'23: 44th ACM SIGPLAN International Conference
  on Programming Language Design and Implementation",,10.1145/3591300,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large language models have demonstrated outstanding performance on a wide range of tasks such as question answering and code generation. On a high level, given an input, a language model can be used to automatically complete the sequence in a statistically-likely way. Based on this, users prompt these models with language instructions or examples, to implement a variety of downstream tasks. Advanced prompting methods can even imply interaction between the language model, a user, and external tools such as calculators. However, to obtain state-of-the-art performance or adapt language models for specific tasks, complex task- and model-specific programs have to be implemented, which may still require ad-hoc interaction.   Based on this, we present the novel idea of Language Model Programming (LMP). LMP generalizes language model prompting from pure text prompts to an intuitive combination of text prompting and scripting. Additionally, LMP allows constraints to be specified over the language model output. This enables easy adaption to many tasks while abstracting language model internals and providing high-level semantics.   To enable LMP, we implement LMQL(short for Language Model Query Language), which leverages the constraints and control flow from an LMP prompt to generate an efficient inference procedure that minimizes the number of expensive calls to the underlying language model.   We show that LMQL can capture a wide range of state-of-the-art prompting methods in an intuitive way, especially facilitating interactive flows that are challenging to implement with existing high-level APIs. Our evaluation shows that we retain or increase the accuracy on several downstream tasks, while also significantly reducing the required amount of computation or cost in the case of pay-to-use APIs (26-85% cost savings). ","[{'version': 'v1', 'created': 'Mon, 12 Dec 2022 18:09:09 GMT'}, {'version': 'v2', 'created': 'Wed, 26 Apr 2023 15:11:38 GMT'}, {'version': 'v3', 'created': 'Tue, 30 May 2023 12:56:41 GMT'}]",2023-05-31,"[['Beurer-Kellner', 'Luca', ''], ['Fischer', 'Marc', ''], ['Vechev', 'Martin', '']]",0,0,2022-12-12,3,3,2,0,0,0,c2329c685f11efa25c562f97be71ff03103423fd,254564450.0,https://www.semanticscholar.org/paper/c2329c685f11efa25c562f97be71ff03103423fd,Proc. ACM Program. Lang.,2022.0,42.0,29.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2150869869', 'name': 'Luca Beurer-Kellner'}, {'authorId': '48849093', 'name': 'Marc Fischer'}, {'authorId': '1736447', 'name': 'Martin T. Vechev'}]","['Martin Vechev, ETH Zurich, Switzerland', 'ETH Zurich']",['Switzerland'],2022-12
2212.06573,Yiting Qu,"Yiting Qu, Xinlei He, Shannon Pierson, Michael Backes, Yang Zhang,
  Savvas Zannettou",On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning,"To Appear in the 44th IEEE Symposium on Security and Privacy, May
  22-25, 2023",,,,cs.SI cs.CR cs.CY cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The dissemination of hateful memes online has adverse effects on social media platforms and the real world. Detecting hateful memes is challenging, one of the reasons being the evolutionary nature of memes; new hateful memes can emerge by fusing hateful connotations with other cultural ideas or symbols. In this paper, we propose a framework that leverages multimodal contrastive learning models, in particular OpenAI's CLIP, to identify targets of hateful content and systematically investigate the evolution of hateful memes. We find that semantic regularities exist in CLIP-generated embeddings that describe semantic relationships within the same modality (images) or across modalities (images and text). Leveraging this property, we study how hateful memes are created by combining visual elements from multiple images or fusing textual information with a hateful image. We demonstrate the capabilities of our framework for analyzing the evolution of hateful memes by focusing on antisemitic memes, particularly the Happy Merchant meme. Using our framework on a dataset extracted from 4chan, we find 3.3K variants of the Happy Merchant meme, with some linked to specific countries, persons, or organizations. We envision that our framework can be used to aid human moderators by flagging new variants of hateful memes so that moderators can manually verify them and mitigate the problem of hateful content online. ","[{'version': 'v1', 'created': 'Tue, 13 Dec 2022 13:38:04 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Jul 2023 14:24:04 GMT'}]",2023-07-10,"[['Qu', 'Yiting', ''], ['He', 'Xinlei', ''], ['Pierson', 'Shannon', ''], ['Backes', 'Michael', ''], ['Zhang', 'Yang', ''], ['Zannettou', 'Savvas', '']]",0,0,2022-12-13,2,6,4,0,0,0,c29e3d050612175023a7c4bbb166181208c1bd6d,254591373.0,https://www.semanticscholar.org/paper/c29e3d050612175023a7c4bbb166181208c1bd6d,IEEE Symposium on Security and Privacy,2022.0,71.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2158023237', 'name': 'Y. Qu'}, {'authorId': '2116553732', 'name': 'Xinlei He'}, {'authorId': '100914066', 'name': 'S. Pierson'}, {'authorId': '144588806', 'name': 'M. Backes'}, {'authorId': '1698138', 'name': 'Yang Zhang'}, {'authorId': '3447293', 'name': 'Savvas Zannettou'}]","['Xinlei He Shannon Pierson Michael Backes', 'Helmholtz Center for Information Security']",['Germany'],2022-12
2212.08072,Zeljko Kraljevic,"Zeljko Kraljevic, Dan Bean, Anthony Shek, Rebecca Bendayan, Harry
  Hemingway, Joshua Au Yeung, Alexander Deng, Alfie Baston, Jack Ross, Esther
  Idowu, James T Teo and Richard J Dobson",Foresight -- Generative Pretrained Transformer (GPT) for Modelling of Patient Timelines using EHRs,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Background: Electronic Health Records hold detailed longitudinal information about each patient's health status and general clinical history, a large portion of which is stored within the unstructured text. Existing approaches focus mostly on structured data and a subset of single-domain outcomes. We explore how temporal modelling of patients from free text and structured data, using deep generative transformers can be used to forecast a wide range of future disorders, substances, procedures or findings. Methods: We present Foresight, a novel transformer-based pipeline that uses named entity recognition and linking tools to convert document text into structured, coded concepts, followed by providing probabilistic forecasts for future medical events such as disorders, substances, procedures and findings. We processed the entire free-text portion from three different hospital datasets totalling 811336 patients covering both physical and mental health. Findings: On tests in two UK hospitals (King's College Hospital, South London and Maudsley) and the US MIMIC-III dataset precision@10 0.68, 0.76 and 0.88 was achieved for forecasting the next disorder in a patient timeline, while precision@10 of 0.80, 0.81 and 0.91 was achieved for forecasting the next biomedical concept. Foresight was also validated on 34 synthetic patient timelines by five clinicians and achieved relevancy of 97% for the top forecasted candidate disorder. As a generative model, it can forecast follow-on biomedical concepts for as many steps as required. Interpretation: Foresight is a general-purpose model for biomedical concept modelling that can be used for real-world risk forecasting, virtual trials and clinical research to study the progression of disorders, simulate interventions and counterfactuals, and educational purposes. ","[{'version': 'v1', 'created': 'Tue, 13 Dec 2022 19:06:00 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Jan 2023 09:24:23 GMT'}]",2023-01-25,"[['Kraljevic', 'Zeljko', ''], ['Bean', 'Dan', ''], ['Shek', 'Anthony', ''], ['Bendayan', 'Rebecca', ''], ['Hemingway', 'Harry', ''], ['Yeung', 'Joshua Au', ''], ['Deng', 'Alexander', ''], ['Baston', 'Alfie', ''], ['Ross', 'Jack', ''], ['Idowu', 'Esther', ''], ['Teo', 'James T', ''], ['Dobson', 'Richard J', '']]",0,1,2022-12-13,2,12,3,0,0,0,18b06e896c9a203f30b85c1a3f453dccc766ae68,256194635.0,https://www.semanticscholar.org/paper/18b06e896c9a203f30b85c1a3f453dccc766ae68,,2022.0,30.0,4.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '3365279', 'name': 'Zeljko Kraljevic'}, {'authorId': '38849757', 'name': 'D. Bean'}, {'authorId': '1602130572', 'name': 'Anthony Shek'}, {'authorId': '32593190', 'name': 'R. Bendayan'}, {'authorId': '2064451113', 'name': 'H. Hemingway'}, {'authorId': '150167114', 'name': 'Joshua Au Yeung'}, {'authorId': '2196728318', 'name': 'Alexander Deng'}, {'authorId': '2197415555', 'name': 'Alfie Baston'}, {'authorId': '2196634980', 'name': 'Jack Ross'}, {'authorId': '2197415184', 'name': 'Esther Idowu'}, {'authorId': '147164117', 'name': 'J. Teo'}, {'authorId': '2066358850', 'name': 'R. Dobson'}]","[""Guy's and St Thomas' NHS Foundation Trust"", ""King's College London"", 'University College London', 'South London and Maudsley NHS Foundation Trust', 'University College London Hospitals NHS Foundation Trust', ""King's College Hospital NHS Foundation Trust""]",['United Kingdom'],2022-12
2212.08104,Rebeca Garcia-Fandino,"Alexandre Blanco-Gonzalez, Alfonso Cabezon, Alejandro Seco-Gonzalez,
  Daniel Conde-Torres, Paula Antelo-Riveiro, Angel Pineiro, Rebeca
  Garcia-Fandino","The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies","11 pages, 1 figure","Pharmaceuticals 2023, 16(6), 891",10.3390/ph16060891,,cs.CL cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Artificial intelligence (AI) has the potential to revolutionize the drug discovery process, offering improved efficiency, accuracy, and speed. However, the successful application of AI is dependent on the availability of high-quality data, the addressing of ethical concerns, and the recognition of the limitations of AI-based approaches. In this article, the benefits, challenges and drawbacks of AI in this field are reviewed, and possible strategies and approaches for overcoming the present obstacles are proposed. The use of data augmentation, explainable AI, and the integration of AI with traditional experimental methods, as well as the potential advantages of AI in pharmaceutical research are also discussed. Overall, this review highlights the potential of AI in drug discovery and provides insights into the challenges and opportunities for realizing its potential in this field.   Note from the human-authors: This article was created to test the ability of ChatGPT, a chatbot based on the GPT-3.5 language model, to assist human authors in writing review articles. The text generated by the AI following our instructions (see Supporting Information) was used as a starting point, and its ability to automatically generate content was evaluated. After conducting a thorough review, human authors practically rewrote the manuscript, striving to maintain a balance between the original proposal and scientific criteria. The advantages and limitations of using AI for this purpose are discussed in the last section. ","[{'version': 'v1', 'created': 'Thu, 8 Dec 2022 23:23:39 GMT'}]",2023-06-21,"[['Blanco-Gonzalez', 'Alexandre', ''], ['Cabezon', 'Alfonso', ''], ['Seco-Gonzalez', 'Alejandro', ''], ['Conde-Torres', 'Daniel', ''], ['Antelo-Riveiro', 'Paula', ''], ['Pineiro', 'Angel', ''], ['Garcia-Fandino', 'Rebeca', '']]",1,1,2022-12-08,1,7,3,2,0,2,9543d4b9c6f71bdececdad7f397ad68cac359d2d,254823626.0,https://www.semanticscholar.org/paper/9543d4b9c6f71bdececdad7f397ad68cac359d2d,Pharmaceuticals,2022.0,65.0,38.0,0.0,True,"['Medicine', 'Computer Science']","[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1830445982', 'name': 'Alexandre Blanco-Gonzalez'}, {'authorId': '1830447689', 'name': 'Alfonso Cabezón'}, {'authorId': '2197415979', 'name': 'Alejandro Seco-Gonzalez'}, {'authorId': '2197415783', 'name': 'Daniel Conde-Torres'}, {'authorId': '2197413770', 'name': 'Paula Antelo-Riveiro'}, {'authorId': '145529360', 'name': 'Ángel Piñeiro'}, {'authorId': '1402378339', 'name': 'R. García‐Fandiño'}]","['MD.USE Innovations S.L., Edificio Emprendia, 15782 Santiago de Compostela, Spain', 'Centro Singular de Investigación en Química Biológica y Materiales Moleculares', 'University of Santiago de Compostela']",['Spain'],2022-12
2212.08913,Gabriella Skitalinskaya,"Gabriella Skitalinskaya, Maximilian Splieth\""over, and Henning
  Wachsmuth",Claim Optimization in Computational Argumentation,Accepted as a long paper at INLG 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  An optimal delivery of arguments is key to persuasion in any debate, both for humans and for AI systems. This requires the use of clear and fluent claims relevant to the given debate. Prior work has studied the automatic assessment of argument quality extensively. Yet, no approach actually improves the quality so far. To fill this gap, this paper proposes the task of claim optimization: to rewrite argumentative claims in order to optimize their delivery. As multiple types of optimization are possible, we approach this task by first generating a diverse set of candidate claims using a large language model, such as BART, taking into account contextual information. Then, the best candidate is selected using various quality metrics. In automatic and human evaluation on an English-language corpus, our quality-based candidate selection outperforms several baselines, improving 60% of all claims (worsening 16% only). Follow-up analyses reveal that, beyond copy editing, our approach often specifies claims with details, whereas it adds less evidence than humans do. Moreover, its capabilities generalize well to other domains, such as instructional texts. ","[{'version': 'v1', 'created': 'Sat, 17 Dec 2022 16:30:27 GMT'}, {'version': 'v2', 'created': 'Thu, 7 Sep 2023 09:01:20 GMT'}]",2023-09-08,"[['Skitalinskaya', 'Gabriella', ''], ['Spliethöver', 'Maximilian', ''], ['Wachsmuth', 'Henning', '']]",0,0,2022-12-17,2,3,1,0,0,0,c6c13eeddadfbdd8f1d1b3589c9d0507eedb7d7e,254854351.0,https://www.semanticscholar.org/paper/c6c13eeddadfbdd8f1d1b3589c9d0507eedb7d7e,International Conference on Natural Language Generation,2022.0,62.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2478960', 'name': 'Gabriella Skitalinskaya'}, {'authorId': '2190107770', 'name': 'Maximilian Spliethover'}, {'authorId': '2626599', 'name': 'Henning Wachsmuth'}]","['Leibniz University Hannover', 'University of Bremen']",['Germany'],2022-12
2212.09292,Teo Susnjak,Teo Susnjak,ChatGPT: The End of Online Exam Integrity?,,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This study evaluated the ability of ChatGPT, a recently developed artificial intelligence (AI) agent, to perform high-level cognitive tasks and produce text that is indistinguishable from human-generated text. This capacity raises concerns about the potential use of ChatGPT as a tool for academic misconduct in online exams. The study found that ChatGPT is capable of exhibiting critical thinking skills and generating highly realistic text with minimal input, making it a potential threat to the integrity of online exams, particularly in tertiary education settings where such exams are becoming more prevalent. Returning to invigilated and oral exams could form part of the solution, while using advanced proctoring techniques and AI-text output detectors may be effective in addressing this issue, they are not likely to be foolproof solutions. Further research is needed to fully understand the implications of large language models like ChatGPT and to devise strategies for combating the risk of cheating using these tools. It is crucial for educators and institutions to be aware of the possibility of ChatGPT being used for cheating and to investigate measures to address it in order to maintain the fairness and validity of online exams for all students. ","[{'version': 'v1', 'created': 'Mon, 19 Dec 2022 08:15:16 GMT'}]",2022-12-20,"[['Susnjak', 'Teo', '']]",1,1,2022-12-19,1,1,2,1,0,1,8822357efe500caded16e603d21239be3a39547c,254853785.0,https://www.semanticscholar.org/paper/8822357efe500caded16e603d21239be3a39547c,arXiv.org,2022.0,26.0,129.0,11.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2656889', 'name': 'Teo Susnjak'}]",['Massey University'],['New Zealand'],2022-12
2212.09593,Mathieu Ravaut,"Mathieu Ravaut, Shafiq Joty, Nancy Chen",Unsupervised Summarization Re-ranking,"9 pages, 1 figure, 10 tables, 23 appendix pages, ACL Findings 2023",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the rise of task-specific pre-training objectives, abstractive summarization models like PEGASUS offer appealing zero-shot performance on downstream summarization tasks. However, the performance of such unsupervised models still lags significantly behind their supervised counterparts. Similarly to the supervised setup, we notice a very high variance in quality among summary candidates from these models while only one candidate is kept as the summary output. In this paper, we propose to re-rank summary candidates in an unsupervised manner, aiming to close the performance gap between unsupervised and supervised models. Our approach improves the unsupervised PEGASUS by up to 7.27% and ChatGPT by up to 6.86% relative mean ROUGE across four widely-adopted summarization benchmarks ; and achieves relative gains of 7.51% (up to 23.73% from XSum to WikiHow) averaged over 30 zero-shot transfer setups (finetuning on a dataset, evaluating on another). ","[{'version': 'v1', 'created': 'Mon, 19 Dec 2022 16:29:26 GMT'}, {'version': 'v2', 'created': 'Sun, 14 May 2023 08:23:08 GMT'}, {'version': 'v3', 'created': 'Fri, 26 May 2023 05:26:23 GMT'}]",2023-05-29,"[['Ravaut', 'Mathieu', ''], ['Joty', 'Shafiq', ''], ['Chen', 'Nancy', '']]",1,1,2022-12-19,3,3,1,1,0,1,14ffc85e996a405780bb27f3b2fcb9808b68102d,254853994.0,https://www.semanticscholar.org/paper/14ffc85e996a405780bb27f3b2fcb9808b68102d,Annual Meeting of the Association for Computational Linguistics,2022.0,76.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '14038850', 'name': 'Mathieu Ravaut'}, {'authorId': '2708940', 'name': 'Shafiq R. Joty'}, {'authorId': '2118768398', 'name': 'Nancy F. Chen'}]","['Agency for Science, Technology and Research', 'Nanyang Technological University', 'Salesforce AI']",['Singapore'],2022-12
2212.09656,Jayr Pereira,"Jayr Pereira, Robson Fidalgo, Roberto Lotufo, Rodrigo Nogueira",Visconde: Multi-document QA with GPT-3 and Neural Reranking,,,,,cs.CL cs.IR,http://creativecommons.org/publicdomain/zero/1.0/,"  This paper proposes a question-answering system that can answer questions whose supporting evidence is spread over multiple (potentially long) documents. The system, called Visconde, uses a three-step pipeline to perform the task: decompose, retrieve, and aggregate. The first step decomposes the question into simpler questions using a few-shot large language model (LLM). Then, a state-of-the-art search engine is used to retrieve candidate passages from a large collection for each decomposed question. In the final step, we use the LLM in a few-shot setting to aggregate the contents of the passages into the final answer. The system is evaluated on three datasets: IIRC, Qasper, and StrategyQA. Results suggest that current retrievers are the main bottleneck and that readers are already performing at the human level as long as relevant passages are provided. The system is also shown to be more effective when the model is induced to give explanations before answering a question. Code is available at \url{https://github.com/neuralmind-ai/visconde}. ","[{'version': 'v1', 'created': 'Mon, 19 Dec 2022 17:39:07 GMT'}]",2022-12-20,"[['Pereira', 'Jayr', ''], ['Fidalgo', 'Robson', ''], ['Lotufo', 'Roberto', ''], ['Nogueira', 'Rodrigo', '']]",0,1,2022-12-19,1,4,2,1,0,1,6d934171cb679bb804ff73a945746e2ed70e1a80,254854129.0,https://www.semanticscholar.org/paper/6d934171cb679bb804ff73a945746e2ed70e1a80,European Conference on Information Retrieval,2022.0,38.0,12.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151478535', 'name': 'Jayr Alencar Pereira'}, {'authorId': '1738953', 'name': 'R. Fidalgo'}, {'authorId': '1809633', 'name': 'R. Lotufo'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}]","['Universidade Federal Fluminense', 'Universidade Federal de Pernambuco']",['Brazil'],2022-12
2212.10114,Maksym Del,Maksym Del and Mark Fishel,True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4,"5 pages, to appear at *SEM",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated solid zero-shot reasoning capabilities, which is reflected in their performance on the current test tasks. This calls for a more challenging benchmark requiring highly advanced reasoning ability to be solved. In this paper, we introduce such a benchmark, consisting of 191 long-form (1200 words on average) mystery narratives constructed as detective puzzles. Puzzles are sourced from the ""5 Minute Mystery"" platform and include a multiple-choice question for evaluation. Only 47% of humans solve a puzzle successfully on average, while the best human solvers achieve over 80% success rate. We show that GPT-3 models barely outperform random on this benchmark (with 28% accuracy) while state-of-the-art GPT-4 solves only 38% of puzzles. This indicates that there is still a significant gap in the deep reasoning abilities of LLMs and humans and highlights the need for further research in this area. Our work introduces a challenging benchmark for future studies on reasoning in language models and contributes to a better understanding of the limits of LLMs' abilities. ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 09:34:43 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Jun 2023 18:50:21 GMT'}]",2023-06-05,"[['Del', 'Maksym', ''], ['Fishel', 'Mark', '']]",0,1,2022-12-20,2,2,1,2,0,2,256ef1f8d0ea2982cc50d3e85e5f1b4920f037fe,259064331.0,https://www.semanticscholar.org/paper/256ef1f8d0ea2982cc50d3e85e5f1b4920f037fe,STARSEM,2022.0,22.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144691634', 'name': 'Maksym Del'}, {'authorId': '2032659', 'name': 'Mark Fishel'}]",['University of Tartu'],['Estonia'],2022-12
2212.10154,Florian E. Dorner,"Florian E.Dorner, Momchil Peychev, Nikola Konstantinov, Naman Goel,
  Elliott Ash, Martin Vechev",Human-Guided Fair Classification for Natural Language Processing,"Published at ICLR 2023 (notable top 25%). 30 pages, 1 figure",,,,cs.CL cs.AI cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Text classifiers have promising applications in high-stake tasks such as resume screening and content moderation. These classifiers must be fair and avoid discriminatory decisions by being invariant to perturbations of sensitive attributes such as gender or ethnicity. However, there is a gap between human intuition about these perturbations and the formal similarity specifications capturing them. While existing research has started to address this gap, current methods are based on hardcoded word replacements, resulting in specifications with limited expressivity or ones that fail to fully align with human intuition (e.g., in cases of asymmetric counterfactuals). This work proposes novel methods for bridging this gap by discovering expressive and intuitive individual fairness specifications. We show how to leverage unsupervised style transfer and GPT-3's zero-shot capabilities to automatically generate expressive candidate pairs of semantically similar sentences that differ along sensitive attributes. We then validate the generated pairs via an extensive crowdsourcing study, which confirms that a lot of these pairs align with human intuition about fairness in the context of toxicity classification. Finally, we show how limited amounts of human feedback can be leveraged to learn a similarity specification that can be used to train downstream fairness-aware models. ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 10:46:40 GMT'}, {'version': 'v2', 'created': 'Thu, 16 Mar 2023 08:57:14 GMT'}]",2023-03-17,"[['Dorner', 'Florian E.', ''], ['Peychev', 'Momchil', ''], ['Konstantinov', 'Nikola', ''], ['Goel', 'Naman', ''], ['Ash', 'Elliott', ''], ['Vechev', 'Martin', '']]",0,1,2022-12-20,2,6,4,1,0,1,4ae163ad7dac91bae435eff844d0fd084f0399ec,254877694.0,https://www.semanticscholar.org/paper/4ae163ad7dac91bae435eff844d0fd084f0399ec,International Conference on Learning Representations,2022.0,64.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2197082358', 'name': 'Florian E.Dorner'}, {'authorId': '30122763', 'name': 'Momchil Peychev'}, {'authorId': '153329035', 'name': 'N. Konstantinov'}, {'authorId': '1828017', 'name': 'Naman Goel'}, {'authorId': '2137551162', 'name': 'Elliott Ash'}, {'authorId': '1736447', 'name': 'Martin T. Vechev'}]","['University of Tübingen', 'University of Oxford']","['Germany', 'United Kingdom']",2022-12
2212.10474,Jonas Belouadi,"Jonas Belouadi, Steffen Eger",ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models,Accepted at ACL 2023 (main track),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  State-of-the-art poetry generation systems are often complex. They either consist of task-specific model pipelines, incorporate prior knowledge in the form of manually created constraints, or both. In contrast, end-to-end models would not suffer from the overhead of having to model prior knowledge and could learn the nuances of poetry from data alone, reducing the degree of human supervision required. In this work, we investigate end-to-end poetry generation conditioned on styles such as rhyme, meter, and alliteration. We identify and address lack of training data and mismatching tokenization algorithms as possible limitations of past attempts. In particular, we successfully pre-train ByGPT5, a new token-free decoder-only language model, and fine-tune it on a large custom corpus of English and German quatrains annotated with our styles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2 and ChatGPT, while also being more parameter efficient and performing favorably compared to humans. In addition, we analyze its runtime performance and demonstrate that it is not prone to memorization. We make our code, models, and datasets publicly available. ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 17:49:49 GMT'}, {'version': 'v2', 'created': 'Mon, 22 May 2023 21:15:06 GMT'}]",2023-05-24,"[['Belouadi', 'Jonas', ''], ['Eger', 'Steffen', '']]",1,1,2022-12-20,2,2,1,3,2,1,7cdebb73662387d9040da4f27a7dc04dbffa3c3e,254877406.0,https://www.semanticscholar.org/paper/7cdebb73662387d9040da4f27a7dc04dbffa3c3e,Annual Meeting of the Association for Computational Linguistics,2022.0,79.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2138207755', 'name': 'Jonas Belouadi'}, {'authorId': '2620186', 'name': 'Steffen Eger'}]",['Bielefeld University'],['Germany'],2022-12
2212.10496,Luyu Gao,"Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan",Precise Zero-Shot Dense Retrieval without Relevance Labels,,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While dense retrieval has been shown effective and efficient across tasks and languages, it remains difficult to create effective fully zero-shot dense retrieval systems when no relevance label is available. In this paper, we recognize the difficulty of zero-shot learning and encoding relevance. Instead, we propose to pivot through Hypothetical Document Embeddings~(HyDE). Given a query, HyDE first zero-shot instructs an instruction-following language model (e.g. InstructGPT) to generate a hypothetical document. The document captures relevance patterns but is unreal and may contain false details. Then, an unsupervised contrastively learned encoder~(e.g. Contriever) encodes the document into an embedding vector. This vector identifies a neighborhood in the corpus embedding space, where similar real documents are retrieved based on vector similarity. This second step ground the generated document to the actual corpus, with the encoder's dense bottleneck filtering out the incorrect details. Our experiments show that HyDE significantly outperforms the state-of-the-art unsupervised dense retriever Contriever and shows strong performance comparable to fine-tuned retrievers, across various tasks (e.g. web search, QA, fact verification) and languages~(e.g. sw, ko, ja). ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 18:09:52 GMT'}]",2022-12-21,"[['Gao', 'Luyu', ''], ['Ma', 'Xueguang', ''], ['Lin', 'Jimmy', ''], ['Callan', 'Jamie', '']]",0,1,2022-12-20,1,4,2,1,0,1,5c32c653735b43a0a8923ca65ac191bd4bf15311,254877046.0,https://www.semanticscholar.org/paper/5c32c653735b43a0a8923ca65ac191bd4bf15311,Annual Meeting of the Association for Computational Linguistics,2022.0,61.0,50.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49715441', 'name': 'Luyu Gao'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2154743364', 'name': 'Jimmy Lin'}, {'authorId': '144987107', 'name': 'Jamie Callan'}]",['University of Waterloo'],['Canada'],2022-12
2212.10505,Fangyu Liu,"Fangyu Liu, Julian Martin Eisenschlos, Francesco Piccinno, Syrine
  Krichene, Chenxi Pang, Kenton Lee, Mandar Joshi, Wenhu Chen, Nigel Collier,
  Yasemin Altun",DePlot: One-shot visual language reasoning by plot-to-table translation,ACL 2023 (Findings),,,,cs.CL cs.AI cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Visual language such as charts and plots is ubiquitous in the human world. Comprehending plots and charts requires strong reasoning skills. Prior state-of-the-art (SOTA) models require at least tens of thousands of training examples and their reasoning capabilities are still much limited, especially on complex human-written queries. This paper presents the first one-shot solution to visual language reasoning. We decompose the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The key in this method is a modality conversion module, named as DePlot, which translates the image of a plot or chart to a linearized table. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs. To obtain DePlot, we standardize the plot-to-table task by establishing unified task formats and metrics, and train DePlot end-to-end on this task. DePlot can then be used off-the-shelf together with LLMs in a plug-and-play fashion. Compared with a SOTA model finetuned on more than >28k data points, DePlot+LLM with just one-shot prompting achieves a 24.0% improvement over finetuned SOTA on human-written queries from the task of chart QA. ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 18:20:50 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 18:28:39 GMT'}]",2023-05-25,"[['Liu', 'Fangyu', ''], ['Eisenschlos', 'Julian Martin', ''], ['Piccinno', 'Francesco', ''], ['Krichene', 'Syrine', ''], ['Pang', 'Chenxi', ''], ['Lee', 'Kenton', ''], ['Joshi', 'Mandar', ''], ['Chen', 'Wenhu', ''], ['Collier', 'Nigel', ''], ['Altun', 'Yasemin', '']]",0,0,2022-12-20,2,10,3,0,0,0,4d3a49d1439a0b8fbb0e9f588970ad0f1d70dec8,254877346.0,https://www.semanticscholar.org/paper/4d3a49d1439a0b8fbb0e9f588970ad0f1d70dec8,Annual Meeting of the Association for Computational Linguistics,2022.0,51.0,15.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144097210', 'name': 'Fangyu Liu'}, {'authorId': '117595858', 'name': 'Julian Martin Eisenschlos'}, {'authorId': '2174596', 'name': 'Francesco Piccinno'}, {'authorId': '48876302', 'name': 'Syrine Krichene'}, {'authorId': '3451566', 'name': 'Chenxi Pang'}, {'authorId': '2110237268', 'name': 'Kenton Lee'}, {'authorId': '2052143361', 'name': 'Mandar Joshi'}, {'authorId': '2928777', 'name': 'Wenhu Chen'}, {'authorId': '50638196', 'name': 'Nigel Collier'}, {'authorId': '1783941', 'name': 'Y. Altun'}]",['University of Cambridge'],['United Kingdom'],2022-12
2212.10522,Yanran Chen,Yanran Chen and Steffen Eger,Transformers Go for the LOLs: Generating (Humourous) Titles from Scientific Abstracts End-to-End,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We consider the end-to-end abstract-to-title generation problem, exploring seven recent transformer based models (including ChatGPT) fine-tuned on more than 30k abstract-title pairs from NLP and machine learning venues. As an extension, we also consider the harder problem of generating humorous paper titles. For the latter, we compile the first large-scale humor annotated dataset for scientific papers in the NLP/ML domains, comprising almost 2.5k titles. We evaluate all models using human and automatic metrics. Our human evaluation suggests that our best end-to-end system performs similarly to human authors (but arguably slightly worse). Generating funny titles is more difficult, however, and our automatic systems clearly underperform relative to humans and often learn dataset artefacts of humor. Finally, ChatGPT, without any fine-tuning, performs on the level of our best fine-tuned system. ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 18:37:11 GMT'}]",2022-12-21,"[['Chen', 'Yanran', ''], ['Eger', 'Steffen', '']]",1,1,2022-12-20,1,2,1,1,0,1,c943275dc0be5d3b16c92ef450b260cef9d7c3b0,254877106.0,https://www.semanticscholar.org/paper/c943275dc0be5d3b16c92ef450b260cef9d7c3b0,arXiv.org,2022.0,63.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109307862', 'name': 'Yanran Chen'}, {'authorId': '2620186', 'name': 'Steffen Eger'}]",['University of Mannheim'],['Germany'],2022-12
2212.10529,Xingxuan Li,"Xingxuan Li, Yutong Li, Shafiq Joty, Linlin Liu, Fei Huang, Lin Qiu,
  Lidong Bing",Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective,,,,,cs.CL cs.AI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work, we determined whether large language models (LLMs) are psychologically safe. We designed unbiased prompts to systematically evaluate LLMs from a psychological perspective. First, we tested three different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT and FLAN-T5 still showed implicit dark personality patterns; both models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT-3 series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT-3 and InstructGPT. Following these observations, we showed that instruction fine-tuning FLAN-T5 with positive answers from BFI could effectively improve the model from a psychological perspective. On the basis of the findings, we recommended the application of more systematic and comprehensive psychological metrics to further evaluate and improve the safety of LLMs. ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 18:45:07 GMT'}, {'version': 'v2', 'created': 'Mon, 8 May 2023 16:52:43 GMT'}]",2023-05-09,"[['Li', 'Xingxuan', ''], ['Li', 'Yutong', ''], ['Joty', 'Shafiq', ''], ['Liu', 'Linlin', ''], ['Huang', 'Fei', ''], ['Qiu', 'Lin', ''], ['Bing', 'Lidong', '']]",0,1,2022-12-20,2,7,3,5,2,3,006ffba35eaa071f643022acce7da591dc26738a,258556858.0,https://www.semanticscholar.org/paper/006ffba35eaa071f643022acce7da591dc26738a,,2022.0,66.0,7.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2155447436', 'name': 'Xingxuan Li'}, {'authorId': '2116873664', 'name': 'Yutong Li'}, {'authorId': '2708940', 'name': 'Shafiq R. Joty'}, {'authorId': '2145314839', 'name': 'Linlin Liu'}, {'authorId': '2216688423', 'name': 'Fei Huang'}, {'authorId': '2215965911', 'name': 'Linlin Qiu'}, {'authorId': '1996394', 'name': 'Lidong Bing'}]","['Salesforce AI', 'Nanyang Technological University', 'National Taiwan University']","['Taiwan', 'Singapore']",2022-12
2212.10548,Iker Garc\'ia-Ferrero,"Iker Garc\'ia-Ferrero, Rodrigo Agerri, German Rigau",T-Projection: High Quality Annotation Projection for Sequence Labeling Tasks,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  In the absence of readily available labeled data for a given task and language, annotation projection has been proposed as one of the possible strategies to automatically generate annotated data which may then be used to train supervised systems. Annotation projection has often been formulated as the task of projecting, on parallel corpora, some labels from a source into a target language. In this paper we present T-Projection, a new approach for annotation projection that leverages large pretrained text2text language models and state-of-the-art machine translation technology. T-Projection decomposes the label projection task into two subtasks: (i) The candidate generation step, in which a set of projection candidates using a multilingual T5 model is generated and, (ii) the candidate selection step, in which the candidates are ranked based on translation probabilities. We evaluate our method in three downstream tasks and five different languages. Our results show that T-projection improves the average F1 score of previous methods by more than 8 points. ","[{'version': 'v1', 'created': 'Tue, 20 Dec 2022 18:51:48 GMT'}]",2022-12-21,"[['García-Ferrero', 'Iker', ''], ['Agerri', 'Rodrigo', ''], ['Rigau', 'German', '']]",0,0,2022-12-20,1,3,1,1,1,0,a15fa0142394c339667fd83543b1261ea9b71eaa,254877029.0,https://www.semanticscholar.org/paper/a15fa0142394c339667fd83543b1261ea9b71eaa,arXiv.org,2022.0,51.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1453724884', 'name': 'Iker García-Ferrero'}, {'authorId': '3242916', 'name': 'Rodrigo Agerri'}, {'authorId': '1785173', 'name': 'German Rigau'}]",['University of the Basque Country'],['Spain'],2022-12
2212.10696,Akshay Chaturvedi,"Akshay Chaturvedi, Swarnadeep Bhar, Soumadeep Saha, Utpal Garain,
  Nicholas Asher",Analyzing Semantic Faithfulness of Language Models via Input Intervention on Conversational Question Answering,"27 pages, 4 figures",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Transformer-based language models have been shown to be highly effective for several NLP tasks. In this paper, we consider three transformer models, BERT, RoBERTa, and XLNet, in both small and large version, and investigate how faithful their representations are with respect to the semantic content of texts. We formalize a notion of semantic faithfulness, in which the semantic content of a text should causally figure in a model's inferences in question answering. We then test this notion by observing a model's behavior on answering questions about a story after performing two novel semantic interventions -- deletion intervention and negation intervention. While transformer models achieve high performance on standard question answering tasks, we show that they fail to be semantically faithful once we perform these interventions for a significant number of cases (~50% for deletion intervention, and ~20% drop in accuracy for negation intervention). We then propose an intervention-based training regime that can mitigate the undesirable effects for deletion intervention by a significant margin (from ~50% to ~6%). We analyze the inner-workings of the models to better understand the effectiveness of intervention-based training for deletion intervention. But we show that this training does not attenuate other aspects of semantic unfaithfulness such as the models' inability to deal with negation intervention or to capture the predicate-argument structure of texts. We also test InstructGPT, via prompting, for its ability to handle the two interventions and to capture predicate-argument structure. While InstructGPT models do achieve very high performance on predicate-argument structure task, they fail to respond adequately to our deletion and negation interventions. ","[{'version': 'v1', 'created': 'Wed, 21 Dec 2022 00:00:01 GMT'}]",2022-12-22,"[['Chaturvedi', 'Akshay', ''], ['Bhar', 'Swarnadeep', ''], ['Saha', 'Soumadeep', ''], ['Garain', 'Utpal', ''], ['Asher', 'Nicholas', '']]",0,1,2022-12-21,1,5,2,1,0,1,b742233b83405d303f61b3378f70475e4efdf75b,254926379.0,https://www.semanticscholar.org/paper/b742233b83405d303f61b3378f70475e4efdf75b,arXiv.org,2022.0,62.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '22205368', 'name': 'Akshay Chaturvedi'}, {'authorId': '2197521636', 'name': 'Swarnadeep Bhar'}, {'authorId': '2197524265', 'name': 'Soumadeep Saha'}, {'authorId': '48421321', 'name': 'U. Garain'}, {'authorId': '1916126', 'name': 'Nicholas M. Asher'}]","['Université Toulouse III - Paul Sabatier', 'Indian Statistical Institute']","['India', 'France']",2022-12
2212.10755,Abdelrahim Elmadany,"El Moatez Billah Nagoudi, Muhammad Abdul-Mageed, AbdelRahim Elmadany,
  Alcides Alcoba Inciarte, Md Tawkat Islam Khondaker",JASMINE: Arabic GPT Models for Few-Shot Learning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Task agnostic generative pretraining (GPT) has recently proved promising for zero- and few-shot learning, gradually diverting attention from the expensive supervised learning paradigm. Although the community is accumulating knowledge as to capabilities of English-language autoregressive models such as GPT-3 adopting this generative approach, scholarship about these models remains acutely Anglocentric. Consequently, the community currently has serious gaps in its understanding of this class of models, their potential, and their societal impacts in diverse settings, linguistic traditions, and cultures. To alleviate this issue for Arabic, a collection of diverse languages and language varieties with more than $400$ million population, we introduce JASMINE, a suite of powerful Arabic autoregressive Transformer language models ranging in size between 300 million-13 billion parameters. We pretrain our new models with large amounts of diverse data (400GB of text) from different Arabic varieties and domains. We evaluate JASMINE extensively in both intrinsic and extrinsic settings, using a comprehensive benchmark for zero- and few-shot learning across a wide range of NLP tasks. We also carefully develop and release a novel benchmark for both automated and human evaluation of Arabic autoregressive models focused at investigating potential social biases, harms, and toxicity in these models. We aim to responsibly release our models with interested researchers, along with code for experimenting with them ","[{'version': 'v1', 'created': 'Wed, 21 Dec 2022 04:21:46 GMT'}]",2022-12-22,"[['Nagoudi', 'El Moatez Billah', ''], ['Abdul-Mageed', 'Muhammad', ''], ['Elmadany', 'AbdelRahim', ''], ['Inciarte', 'Alcides Alcoba', ''], ['Khondaker', 'Md Tawkat Islam', '']]",0,1,2022-12-21,1,5,1,1,0,1,d78df936a717f278e89221f74f3f894e90d8c1fe,254926631.0,https://www.semanticscholar.org/paper/d78df936a717f278e89221f74f3f894e90d8c1fe,arXiv.org,2022.0,85.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '17771023', 'name': 'El Moatez Billah Nagoudi'}, {'authorId': '2065312024', 'name': 'M. Abdul-Mageed'}, {'authorId': '1397289779', 'name': 'AbdelRahim Elmadany'}, {'authorId': '2188651859', 'name': 'Alcides Alcoba Inciarte'}, {'authorId': '118865912', 'name': 'Md. Tawkat Islam Khondaker'}]","['University of British Columbia', 'Mohamed bin Zayed University of Artificial Intelligence']","['Canada', 'United Arab Emirates']",2022-12
2212.11118,Shoichiro Hara,"Shoichiro Hara, Yuji Watanabe",NP4G : Network Programming for Generalization,,,,,cs.PL cs.LG cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic programming has been actively studied for a long time by various approaches including genetic programming. In recent years, automatic programming using neural networks such as GPT-3 has been actively studied and is attracting a lot of attention. However, these methods are illogical inference based on experience by enormous learning, and their thinking process is unclear. Even using the method by logical inference with a clear thinking process, the system that automatically generates any programs has not yet been realized. Especially, the inductive inference generalized by logical inference from one example is an important issue that the artificial intelligence can acquire knowledge by itself. In this study, we propose NP4G: Network Programming for Generalization, which can automatically generate programs by inductive inference. Because the proposed method can realize ""sequence"", ""selection"", and ""iteration"" in programming and can satisfy the conditions of the structured program theorem, it is expected that NP4G is a method automatically acquire any programs by inductive inference. As an example, we automatically construct a bitwise NOT operation program from several training data by generalization using NP4G. Although NP4G only randomly selects and connects nodes, by adjusting the number of nodes and the number of phase of ""Phased Learning"", we show the bitwise NOT operation programs are acquired in a comparatively short time and at a rate of about 7 in 10 running. The source code of NP4G is available on GitHub as a public repository. ","[{'version': 'v1', 'created': 'Thu, 8 Dec 2022 06:18:44 GMT'}]",2022-12-22,"[['Hara', 'Shoichiro', ''], ['Watanabe', 'Yuji', '']]",0,1,2022-12-08,1,2,3,1,0,1,52499d4f37c155b142d6135b69e8d78fa5f24e16,254926832.0,https://www.semanticscholar.org/paper/52499d4f37c155b142d6135b69e8d78fa5f24e16,arXiv.org,2022.0,16.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '152730705', 'name': 'S. Hara'}, {'authorId': '2111726183', 'name': 'Yuji Watanabe'}]",['Nagoya City University'],['Japan'],2022-12
2212.11214,Fabr\'icio G\'oes,"Fabricio Goes, Zisen Zhou, Piotr Sawicki, Marek Grzes and Daniel G.
  Brown",Crowd Score: A Method for the Evaluation of Jokes using Large Language Model AI Voters as Judges,"11 pages, 3 figures",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper presents the Crowd Score, a novel method to assess the funniness of jokes using large language models (LLMs) as AI judges. Our method relies on inducing different personalities into the LLM and aggregating the votes of the AI judges into a single score to rate jokes. We validate the votes using an auditing technique that checks if the explanation for a particular vote is reasonable using the LLM. We tested our methodology on 52 jokes in a crowd of four AI voters with different humour types: affiliative, self-enhancing, aggressive and self-defeating. Our results show that few-shot prompting leads to better results than zero-shot for the voting question. Personality induction showed that aggressive and self-defeating voters are significantly more inclined to find more jokes funny of a set of aggressive/self-defeating jokes than the affiliative and self-enhancing voters. The Crowd Score follows the same trend as human judges by assigning higher scores to jokes that are also considered funnier by human judges. We believe that our methodology could be applied to other creative domains such as story, poetry, slogans, etc. It could both help the adoption of a flexible and accurate standard approach to compare different work in the CC community under a common metric and by minimizing human participation in assessing creative artefacts, it could accelerate the prototyping of creative artefacts and reduce the cost of hiring human participants to rate creative artefacts. ","[{'version': 'v1', 'created': 'Wed, 21 Dec 2022 17:41:16 GMT'}]",2022-12-22,"[['Goes', 'Fabricio', ''], ['Zhou', 'Zisen', ''], ['Sawicki', 'Piotr', ''], ['Grzes', 'Marek', ''], ['Brown', 'Daniel G.', '']]",0,0,2022-12-21,1,5,1,0,0,0,0ba5fb80d2c3ea3a8505415e32d954b4e4eea170,254926783.0,https://www.semanticscholar.org/paper/0ba5fb80d2c3ea3a8505415e32d954b4e4eea170,arXiv.org,2022.0,29.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2074488337', 'name': 'Fabrício Góes'}, {'authorId': '2121298160', 'name': 'Zisen Zhou'}, {'authorId': '2185736769', 'name': 'Piotr Sawicki'}, {'authorId': '2186376', 'name': 'M. Grzes'}, {'authorId': '2185791771', 'name': 'Daniel Brown'}]","['University of Leicester', 'University of Waterloo', 'University of Kent']","['Canada', 'United Kingdom']",2022-12
2212.11281,Euan McLean,"Buck Shlegeris, Fabien Roger, Lawrence Chan, Euan McLean",Language models are better than humans at next-token prediction,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current language models are considered to have sub-human capabilities at natural language tasks like question-answering or writing code. However, language models are not trained to perform well at these tasks, they are trained to accurately predict the next token given previous tokes in tokenized text. It is not clear whether language models are better or worse than humans at next token prediction. To try to answer this question, we performed two distinct experiments to directly compare humans and language models on this front: one measuring top-1 accuracy and the other measuring perplexity. In both experiments, we find humans to be consistently \emph{worse} than even relatively small language models like GPT3-Ada at next-token prediction. ","[{'version': 'v1', 'created': 'Wed, 21 Dec 2022 17:58:01 GMT'}]",2022-12-23,"[['Shlegeris', 'Buck', ''], ['Roger', 'Fabien', ''], ['Chan', 'Lawrence', ''], ['McLean', 'Euan', '']]",0,1,2022-12-21,1,4,3,1,0,1,7cbc7aa08b96de770d9ce5c90d01e75e9df2caee,254974215.0,https://www.semanticscholar.org/paper/7cbc7aa08b96de770d9ce5c90d01e75e9df2caee,arXiv.org,2022.0,12.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '79384063', 'name': 'Buck Shlegeris'}, {'authorId': '2197780120', 'name': 'Fabien Roger'}, {'authorId': '2164095723', 'name': 'Lawrence Chan'}, {'authorId': '2197779176', 'name': 'Euan McLean'}]","['École Polytechnique', 'Redwood Research']",['France'],2022-12
2212.13939,Dania Refai,"Dania Refai, Saleh Abo-Soud, Mohammad Abdel-Rahman",Data Augmentation using Transformers and Similarity Measures for Improving Arabic Text Classification,"15 pages, 16 Figures, this work has been submitted to the IEEE Access
  Journal for possible publication",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The performance of learning models heavily relies on the availability and adequacy of training data. To address the dataset adequacy issue, researchers have extensively explored data augmentation (DA) as a promising approach. DA generates new data instances through transformations applied to the available data, thereby increasing dataset size and variability. This approach has enhanced model performance and accuracy, particularly in addressing class imbalance problems in classification tasks. However, few studies have explored DA for the Arabic language, relying on traditional approaches such as paraphrasing or noising-based techniques. In this paper, we propose a new Arabic DA method that employs the recent powerful modeling technique, namely the AraGPT-2, for the augmentation process. The generated sentences are evaluated in terms of context, semantics, diversity, and novelty using the Euclidean, cosine, Jaccard, and BLEU distances. Finally, the AraBERT transformer is used on sentiment classification tasks to evaluate the classification performance of the augmented Arabic dataset. The experiments were conducted on four sentiment Arabic datasets: AraSarcasm, ASTD, ATT, and MOVIE. The selected datasets vary in size, label number, and unbalanced classes. The results show that the proposed methodology enhanced the Arabic sentiment text classification on all datasets with an increase in F1 score by 4% in AraSarcasm, 6% in ASTD, 9% in ATT, and 13% in MOVIE. ","[{'version': 'v1', 'created': 'Wed, 28 Dec 2022 16:38:43 GMT'}, {'version': 'v2', 'created': 'Sun, 1 Jan 2023 11:37:32 GMT'}, {'version': 'v3', 'created': 'Sun, 20 Aug 2023 15:32:29 GMT'}]",2023-08-22,"[['Refai', 'Dania', ''], ['Abo-Soud', 'Saleh', ''], ['Abdel-Rahman', 'Mohammad', '']]",0,1,2022-12-28,3,3,3,0,0,0,8f5e3048591bba63102d7070e3463d3ba7dcd6fb,255186403.0,https://www.semanticscholar.org/paper/8f5e3048591bba63102d7070e3463d3ba7dcd6fb,arXiv.org,2022.0,61.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2198489167', 'name': 'Dania Refai'}, {'authorId': '2198489478', 'name': 'Saleh Abo-Soud'}, {'authorId': '2198489796', 'name': 'Mohammad Abdel-Rahman'}]",['Princess Sumaya University for Technology'],['Jordan'],2022-12
2212.14815,Ond\v{r}ej C\'ifka,"Ond\v{r}ej C\'ifka, Antoine Liutkus",Black-box language model explanation by context length probing,"11 pages, 9 figures. ACL 2023 short paper camera-ready. Demos at
  https://cifkao.github.io/context-probing/ and
  https://huggingface.co/spaces/cifkao/context-probing ; code at
  https://github.com/cifkao/context-probing/","Proceedings of the 61st Annual Meeting of the Association for
  Computational Linguistics (Volume 2: Short Papers) (2023), 1067--1079",10.18653/v1/2023.acl-short.92,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The increasingly widespread adoption of large language models has highlighted the need for improving their explainability. We present context length probing, a novel explanation technique for causal language models, based on tracking the predictions of a model as a function of the length of available context, and allowing to assign differential importance scores to different contexts. The technique is model-agnostic and does not rely on access to model internals beyond computing token-level probabilities. We apply context length probing to large pre-trained language models and offer some initial analyses and insights, including the potential for studying long-range dependencies. The source code and an interactive demo of the method are available. ","[{'version': 'v1', 'created': 'Fri, 30 Dec 2022 16:24:10 GMT'}, {'version': 'v2', 'created': 'Mon, 22 May 2023 10:37:03 GMT'}, {'version': 'v3', 'created': 'Fri, 26 May 2023 20:32:25 GMT'}]",2023-09-19,"[['Cífka', 'Ondřej', ''], ['Liutkus', 'Antoine', '']]",0,0,2022-12-30,3,2,2,0,0,0,00a4f5ee0e5fa915a794a4231dc59e11eff89d96,255340449.0,https://www.semanticscholar.org/paper/00a4f5ee0e5fa915a794a4231dc59e11eff89d96,Annual Meeting of the Association for Computational Linguistics,2022.0,30.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '41022618', 'name': 'Ondřej Cífka'}, {'authorId': '2160053934', 'name': 'Antoine Liutkus'}]",['University of Montpellier'],['France'],2022-12
2212.14882,Jakob Dexl,"Katharina Jeblick, Balthasar Schachtner, Jakob Dexl, Andreas
  Mittermeier, Anna Theresa St\""uber, Johanna Topalis, Tobias Weber, Philipp
  Wesp, Bastian Sabel, Jens Ricke, Michael Ingrisch",ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study on Simplified Radiology Reports,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The release of ChatGPT, a language model capable of generating text that appears human-like and authentic, has gained significant attention beyond the research community. We expect that the convincing performance of ChatGPT incentivizes users to apply it to a variety of downstream tasks, including prompting the model to simplify their own medical reports. To investigate this phenomenon, we conducted an exploratory case study. In a questionnaire, we asked 15 radiologists to assess the quality of radiology reports simplified by ChatGPT. Most radiologists agreed that the simplified reports were factually correct, complete, and not potentially harmful to the patient. Nevertheless, instances of incorrect statements, missed key medical findings, and potentially harmful passages were reported. While further studies are needed, the initial insights of this study indicate a great potential in using large language models like ChatGPT to improve patient-centered care in radiology and other medical domains. ","[{'version': 'v1', 'created': 'Fri, 30 Dec 2022 18:55:16 GMT'}]",2023-01-02,"[['Jeblick', 'Katharina', ''], ['Schachtner', 'Balthasar', ''], ['Dexl', 'Jakob', ''], ['Mittermeier', 'Andreas', ''], ['Stüber', 'Anna Theresa', ''], ['Topalis', 'Johanna', ''], ['Weber', 'Tobias', ''], ['Wesp', 'Philipp', ''], ['Sabel', 'Bastian', ''], ['Ricke', 'Jens', ''], ['Ingrisch', 'Michael', '']]",1,1,2022-12-30,1,11,2,1,0,1,23cae400cfd1a7c455c721256b838e98a307d5e6,255340809.0,https://www.semanticscholar.org/paper/23cae400cfd1a7c455c721256b838e98a307d5e6,arXiv.org,2022.0,45.0,114.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '2199013582', 'name': 'Katharina Jeblick'}, {'authorId': '2246418879', 'name': 'Balthasar Schachtner'}, {'authorId': '2051875796', 'name': 'Jakob Dexl'}, {'authorId': '1405351735', 'name': 'Andreas Mittermeier'}, {'authorId': '2158583540', 'name': 'Anna Theresa Stüber'}, {'authorId': '2124700239', 'name': 'Johanna Topalis'}, {'authorId': '2053297121', 'name': 'Tobias Weber'}, {'authorId': '119656907', 'name': 'Philipp Wesp'}, {'authorId': '31463178', 'name': 'B. Sabel'}, {'authorId': '2566938', 'name': 'J. Ricke'}, {'authorId': '4925703', 'name': 'M. Ingrisch'}]","['Ludwig-Maximilians-Universität München', 'German Center for Lung Research']",['Germany'],2022-12
2301.00068,Tom Young,"Tom Young, Yang You",On the Inconsistencies of Conditionals Learned by Masked Language Models,4 pages,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Learning to predict masked tokens in a sequence has been shown to be a powerful pretraining objective for large-scale language models. After training, such masked language models can provide distributions of tokens conditioned on bidirectional context.   In this short draft, we show that such bidirectional conditionals often demonstrate considerable inconsistencies, i.e., they can not be derived from a coherent joint distribution when considered together. We empirically quantify such inconsistencies in the simple scenario of bigrams for two common styles of masked language models: T5-style and BERT-style. For example, we show that T5 models often confuse its own preference regarding two similar bigrams.   Such inconsistencies may represent a theoretical pitfall for the research work on sampling sequences based on the bidirectional conditionals learned by BERT-style MLMs. This phenomenon also means that T5-style MLMs capable of infilling will generate discrepant results depending on how much masking is given, which may represent a particular trust issue. ","[{'version': 'v1', 'created': 'Fri, 30 Dec 2022 22:53:25 GMT'}]",2023-01-03,"[['Young', 'Tom', ''], ['You', 'Yang', '']]",0,0,2022-12-30,1,2,2,1,1,0,74612d90d89929701c8d57845fda8d98d69a3f5a,255372558.0,https://www.semanticscholar.org/paper/74612d90d89929701c8d57845fda8d98d69a3f5a,arXiv.org,2022.0,31.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2061649994', 'name': 'Tom Young'}, {'authorId': '2147330214', 'name': 'Yang You'}]",['National University of Singapore'],['Singapore'],2022-12
2301.01764,Dennis Aumiller,Dennis Aumiller and Michael Gertz,UniHD at TSAR-2022 Shared Task: Is Compute All We Need for Lexical Simplification?,"Workshop on Text Simplification, Accessibility, and Readability
  (TSAR-2022) at EMNLP 2022",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Previous state-of-the-art models for lexical simplification consist of complex pipelines with several components, each of which requires deep technical knowledge and fine-tuned interaction to achieve its full potential. As an alternative, we describe a frustratingly simple pipeline based on prompted GPT-3 responses, beating competing approaches by a wide margin in settings with few training instances. Our best-performing submission to the English language track of the TSAR-2022 shared task consists of an ``ensemble'' of six different prompt templates with varying context levels. As a late-breaking result, we further detail a language transfer technique that allows simplification in languages other than English. Applied to the Spanish and Portuguese subset, we achieve state-of-the-art results with only minor modification to the original prompts. Aside from detailing the implementation and setup, we spend the remainder of this work discussing the particularities of prompting and implications for future work. Code for the experiments is available online at https://github.com/dennlinger/TSAR-2022-Shared-Task ","[{'version': 'v1', 'created': 'Wed, 4 Jan 2023 18:59:20 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Jan 2023 15:22:05 GMT'}]",2023-01-06,"[['Aumiller', 'Dennis', ''], ['Gertz', 'Michael', '']]",0,1,2023-01-04,2,2,1,1,0,1,40fba1fc70e23abf9a3ea428f186dd44e57723fb,255415873.0,https://www.semanticscholar.org/paper/40fba1fc70e23abf9a3ea428f186dd44e57723fb,TSAR,2023.0,15.0,13.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '1396275349', 'name': 'Dennis Aumiller'}, {'authorId': '40136143', 'name': 'Michael Gertz'}]",['Heidelberg University'],['Germany'],2023-01
2301.01768,Maximilian Witte,"Jochen Hartmann, Jasper Schwenzow, Maximilian Witte","The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation",,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Conversational artificial intelligence (AI) disrupts how humans interact with technology. Recently, OpenAI introduced ChatGPT, a state-of-the-art dialogue model that can converse with its human counterparts with unprecedented capabilities. ChatGPT has witnessed tremendous attention from the media, academia, industry, and the general public, attracting more than a million users within days of its release. However, its explosive adoption for information search and as an automated decision aid underscores the importance to understand its limitations and biases. This paper focuses on one of democratic society's most important decision-making processes: political elections. Prompting ChatGPT with 630 political statements from two leading voting advice applications and the nation-agnostic political compass test in three pre-registered experiments, we uncover ChatGPT's pro-environmental, left-libertarian ideology. For example, ChatGPT would impose taxes on flights, restrict rent increases, and legalize abortion. In the 2021 elections, it would have voted most likely for the Greens both in Germany (B\""undnis 90/Die Gr\""unen) and in the Netherlands (GroenLinks). Our findings are robust when negating the prompts, reversing the order of the statements, varying prompt formality, and across languages (English, German, Dutch, and Spanish). We conclude by discussing the implications of politically biased conversational AI on society. ","[{'version': 'v1', 'created': 'Thu, 5 Jan 2023 07:13:13 GMT'}]",2023-01-06,"[['Hartmann', 'Jochen', ''], ['Schwenzow', 'Jasper', ''], ['Witte', 'Maximilian', '']]",1,1,2023-01-05,1,3,2,1,0,1,b6f8cffc5da51581aec71d919d010d55e5ac068a,255440573.0,https://www.semanticscholar.org/paper/b6f8cffc5da51581aec71d919d010d55e5ac068a,Social Science Research Network,2023.0,56.0,51.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","[{'authorId': '39697129', 'name': 'Jochen Hartmann'}, {'authorId': '2004368787', 'name': 'Jasper Schwenzow'}, {'authorId': '94737364', 'name': 'Maximilian Witte'}]","['Technical University of Munich', 'Universität Hamburg']",['Germany'],2023-01
2301.03119,Yifan Wang,"Mariam Bangura, Kristina Barabashova, Anna Karnysheva, Sarah Semczuk,
  Yifan Wang",Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study is devoted to the automatic generation of German drama texts. We suggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the outline model) to generate outlines of scenes based on keywords and fine-tuning a second model (the generation model) to generate scenes from the scene outline. The input for the neural model comprises two datasets: the German Drama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA). In order to estimate the effectiveness of the proposed method, our models are compared with baseline GPT-2 models. Our models perform well according to automatic quantitative evaluation, but, conversely, manual qualitative analysis reveals a poor quality of generated texts. This may be due to the quality of the dataset or training inputs. ","[{'version': 'v1', 'created': 'Sun, 8 Jan 2023 23:12:46 GMT'}, {'version': 'v2', 'created': 'Tue, 10 Jan 2023 14:08:00 GMT'}]",2023-01-11,"[['Bangura', 'Mariam', ''], ['Barabashova', 'Kristina', ''], ['Karnysheva', 'Anna', ''], ['Semczuk', 'Sarah', ''], ['Wang', 'Yifan', '']]",0,1,2023-01-08,2,5,1,1,1,0,9e4d1ad98a03245080c588d9fd08b788346f9409,255546622.0,https://www.semanticscholar.org/paper/9e4d1ad98a03245080c588d9fd08b788346f9409,arXiv.org,2023.0,37.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '116693102', 'name': 'M. Bangura'}, {'authorId': '2199748712', 'name': 'Kristina Barabashova'}, {'authorId': '2029657360', 'name': 'Anna Karnysheva'}, {'authorId': '2199748632', 'name': 'Sarah Semczuk'}, {'authorId': '2115568958', 'name': 'Yifa Wang'}]","['7009604, 7023878, 7010958, 2573377, 7023035', 'Saarland University']",['Germany'],2023-01
2301.04655,Eduardo C. Garrido-Merch\'an,"Roberto Gozalo-Brizuela, Eduardo C. Garrido-Merchan",ChatGPT is not all you need. A State of the Art Review of large Generative AI models,22 pages,,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  During the last two years there has been a plethora of large generative models such as ChatGPT or Stable Diffusion that have been published. Concretely, these models are able to perform tasks such as being a general question and answering system or automatically creating artistic images that are revolutionizing several sectors. Consequently, the implications that these generative models have in the industry and society are enormous, as several job positions may be transformed. For example, Generative AI is capable of transforming effectively and creatively texts to images, like the DALLE-2 model; text to 3D images, like the Dreamfusion model; images to text, like the Flamingo model; texts to video, like the Phenaki model; texts to audio, like the AudioLM model; texts to other texts, like ChatGPT; texts to code, like the Codex model; texts to scientific texts, like the Galactica model or even create algorithms like AlphaTensor. This work consists on an attempt to describe in a concise way the main models are sectors that are affected by generative AI and to provide a taxonomy of the main generative models published recently. ","[{'version': 'v1', 'created': 'Wed, 11 Jan 2023 15:48:36 GMT'}]",2023-01-13,"[['Gozalo-Brizuela', 'Roberto', ''], ['Garrido-Merchan', 'Eduardo C.', '']]",1,1,2023-01-11,1,2,2,2,0,2,1f22de83d912176cb8857efa1c6d65b14d6a2f5c,255749330.0,https://www.semanticscholar.org/paper/1f22de83d912176cb8857efa1c6d65b14d6a2f5c,arXiv.org,2023.0,35.0,84.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Art', 'source': 's2-fos-model'}]","[{'authorId': '2200162353', 'name': 'Roberto Gozalo-Brizuela'}, {'authorId': '1398645148', 'name': 'E.C. Garrido-Merchán'}]",['Comillas Pontifical University'],['Spain'],2023-01
2301.05327,Sil Hamilton,Sil Hamilton,Blind Judgement: Agent-Based Supreme Court Modelling With GPT,"To appear in the proceedings of the AAAI-23 Workshop on Creative AI
  Across Modalities",,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,  We present a novel Transformer-based multi-agent system for simulating the judicial rulings of the 2010-2016 Supreme Court of the United States. We train nine separate models with the respective authored opinions of each supreme justice active ca. 2015 and test the resulting system on 96 real-world cases. We find our system predicts the decisions of the real-world Supreme Court with better-than-random accuracy. We further find a correlation between model accuracy with respect to individual justices and their alignment between legal conservatism & liberalism. Our methods and results hold significance for researchers interested in using language models to simulate politically-charged discourse between multiple agents. ,"[{'version': 'v1', 'created': 'Thu, 12 Jan 2023 23:07:55 GMT'}]",2023-01-16,"[['Hamilton', 'Sil', '']]",0,1,2023-01-12,1,1,1,0,0,0,db5423d1d5737aa90c48bc121239160d24dccb36,255825875.0,https://www.semanticscholar.org/paper/db5423d1d5737aa90c48bc121239160d24dccb36,arXiv.org,2023.0,28.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}]","[{'authorId': '113400785', 'name': 'S. Hamilton'}]",['McGill University'],['Canada'],2023-01
2301.05843,Young-Ho Kim,"Jing Wei, Sungdong Kim, Hyunhoon Jung, Young-Ho Kim",Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data,"22 pages including Appendix, 7 figures, 7 tables. Accepted to PACM
  HCI (CSCW 2024)",,,,cs.HC cs.AI cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Large language models (LLMs) provide a new way to build chatbots by accepting natural language prompts. Yet, it is unclear how to design prompts to power chatbots to carry on naturalistic conversations while pursuing a given goal, such as collecting self-report data from users. We explore what design factors of prompts can help steer chatbots to talk naturally and collect data reliably. To this aim, we formulated four prompt designs with different structures and personas. Through an online study (N = 48) where participants conversed with chatbots driven by different designs of prompts, we assessed how prompt designs and conversation topics affected the conversation flows and users' perceptions of chatbots. Our chatbots covered 79% of the desired information slots during conversations, and the designs of prompts and topics significantly influenced the conversation flows and the data collection performance. We discuss the opportunities and challenges of building chatbots with LLMs. ","[{'version': 'v1', 'created': 'Sat, 14 Jan 2023 07:29:36 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Sep 2023 22:33:24 GMT'}]",2023-09-26,"[['Wei', 'Jing', ''], ['Kim', 'Sungdong', ''], ['Jung', 'Hyunhoon', ''], ['Kim', 'Young-Ho', '']]",0,0,2023-01-14,2,4,3,0,0,0,179790fac38b1c35f6003f65eef7097f8413cd35,255941476.0,https://www.semanticscholar.org/paper/179790fac38b1c35f6003f65eef7097f8413cd35,arXiv.org,2023.0,122.0,10.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2111523886', 'name': 'Jing Wei'}, {'authorId': '2829848', 'name': 'Sungdong Kim'}, {'authorId': '94185397', 'name': 'Hyunhoon Jung'}, {'authorId': '2193120046', 'name': 'Young-Ho Kim'}]","['University of Melbourne', 'NAVER']","['South Korea', 'Australia']",2023-01
2301.07069,Biao Zhang,"Biao Zhang, Barry Haddow, Alexandra Birch",Prompting Large Language Model for Machine Translation: A Case Study,Work in progress,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Research on prompting has shown excellent performance with little or even no supervised training across many tasks. However, prompting for machine translation is still under-explored in the literature. We fill this gap by offering a systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection. We further explore the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-to-document transfer learning in prompting. Extensive experiments with GLM-130B (Zeng et al., 2022) as the testbed show that 1) the number and the quality of prompt examples matter, where using suboptimal examples degenerates translation; 2) several features of prompt examples, such as semantic similarity, show significant Spearman correlation with their prompting performance; yet, none of the correlations are strong enough; 3) using pseudo parallel prompt examples constructed from monolingual data via zero-shot prompting could improve translation; and 4) improved performance is achievable by transferring knowledge from prompt examples selected in other settings. We finally provide an analysis on the model outputs and discuss several problems that prompting still suffers from. ","[{'version': 'v1', 'created': 'Tue, 17 Jan 2023 18:32:06 GMT'}, {'version': 'v2', 'created': 'Wed, 18 Jan 2023 11:30:05 GMT'}]",2023-01-19,"[['Zhang', 'Biao', ''], ['Haddow', 'Barry', ''], ['Birch', 'Alexandra', '']]",0,0,2023-01-17,2,3,2,1,1,0,c879413103f8950bdd414c7f60a39bd7748c9be8,255942578.0,https://www.semanticscholar.org/paper/c879413103f8950bdd414c7f60a39bd7748c9be8,International Conference on Machine Learning,2023.0,65.0,50.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48335426', 'name': 'Biao Zhang'}, {'authorId': '2259100', 'name': 'B. Haddow'}, {'authorId': '2539211', 'name': 'Alexandra Birch'}]",['University of Edinburgh'],['United Kingdom'],2023-01
2301.07098,Andreas Ostermaier,"Sebastian Kr\""ugel, Andreas Ostermaier, Matthias Uhl",The moral authority of ChatGPT,,,,,cs.CY cs.AI cs.HC cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  ChatGPT is not only fun to chat with, but it also searches information, answers questions, and gives advice. With consistent moral advice, it might improve the moral judgment and decisions of users, who often hold contradictory moral beliefs. Unfortunately, ChatGPT turns out highly inconsistent as a moral advisor. Nonetheless, it influences users' moral judgment, we find in an experiment, even if they know they are advised by a chatting bot, and they underestimate how much they are influenced. Thus, ChatGPT threatens to corrupt rather than improves users' judgment. These findings raise the question of how to ensure the responsible use of ChatGPT and similar AI. Transparency is often touted but seems ineffective. We propose training to improve digital literacy. ","[{'version': 'v1', 'created': 'Fri, 13 Jan 2023 20:24:38 GMT'}]",2023-01-19,"[['Krügel', 'Sebastian', ''], ['Ostermaier', 'Andreas', ''], ['Uhl', 'Matthias', '']]",1,1,2023-01-13,1,3,4,1,0,1,dfc125ec03e84c2ae26147964fc301b1455f3181,255998212.0,https://www.semanticscholar.org/paper/dfc125ec03e84c2ae26147964fc301b1455f3181,arXiv.org,2023.0,17.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '104246606', 'name': 'Sebastian Krügel'}, {'authorId': '20658415', 'name': 'Andreas Ostermaier'}, {'authorId': '1696033469', 'name': 'Matthias W. Uhl'}]","['University of Southern Denmark', 'Technische Hochschule Ingolstadt']","['Germany', 'Denmark']",2023-01
2301.08155,Kay Lehnert,"Kay Lehnert (Department of Theoretical Physics, Maynooth University,
  Maynooth, Ireland)",AI Insights into Theoretical Physics and the Swampland Program: A Journey Through the Cosmos with ChatGPT,"10 pages, 2 figures",,,,physics.pop-ph cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this case study, we explore the capabilities and limitations of ChatGPT, a natural language processing model developed by OpenAI, in the field of string theoretical swampland conjectures. We find that it is effective at paraphrasing and explaining concepts in a variety of styles, but not at genuinely connecting concepts. It will provide false information with full confidence and make up statements when necessary. However, its ingenious use of language can be fruitful for identifying analogies and describing visual representations of abstract concepts. ","[{'version': 'v1', 'created': 'Tue, 10 Jan 2023 16:57:16 GMT'}]",2023-01-20,"[['Lehnert', 'Kay', '', 'Department of Theoretical Physics, Maynooth University,\n  Maynooth, Ireland']]",1,1,2023-01-10,1,1,3,1,0,1,cb0538917a1810875250672064b1d923eb37c650,256000015.0,https://www.semanticscholar.org/paper/cb0538917a1810875250672064b1d923eb37c650,arXiv.org,2023.0,26.0,7.0,0.0,True,"['Physics', 'Computer Science']","[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2201839306', 'name': 'Kay Lehnert'}]","['. Introduction 1 II. Swampland Conjectures 3 A. The Weak Gravity Conjecture 4 B. de Sitter Conjecture 6 III. Outlook 8 IV. Conclusion 9 V. Disclaimer 9 References 9', 'National University of Ireland, Maynooth']",['Ireland'],2023-01
2301.08653,Dominik Sobania,"Dominik Sobania, Martin Briesch, Carol Hanna, Justyna Petke",An Analysis of the Automatic Bug Fixing Performance of ChatGPT,,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  To support software developers in finding and fixing software bugs, several automated program repair techniques have been introduced. Given a test suite, standard methods usually either synthesize a repair, or navigate a search space of software edits to find test-suite passing variants. Recent program repair methods are based on deep learning approaches. One of these novel methods, which is not primarily intended for automated program repair, but is still suitable for it, is ChatGPT. The bug fixing performance of ChatGPT, however, is so far unclear. Therefore, in this paper we evaluate ChatGPT on the standard bug fixing benchmark set, QuixBugs, and compare the performance with the results of several other approaches reported in the literature. We find that ChatGPT's bug fixing performance is competitive to the common deep learning approaches CoCoNut and Codex and notably better than the results reported for the standard program repair approaches. In contrast to previous approaches, ChatGPT offers a dialogue system through which further information, e.g., the expected output for a certain input or an observed error message, can be entered. By providing such hints to ChatGPT, its success rate can be further increased, fixing 31 out of 40 bugs, outperforming state-of-the-art. ","[{'version': 'v1', 'created': 'Fri, 20 Jan 2023 16:01:47 GMT'}]",2023-01-23,"[['Sobania', 'Dominik', ''], ['Briesch', 'Martin', ''], ['Hanna', 'Carol', ''], ['Petke', 'Justyna', '']]",1,1,2023-01-20,1,4,1,2,0,2,9f530ebf624bf58e91b2a1f20b0799a45ca48f9a,256080824.0,https://www.semanticscholar.org/paper/9f530ebf624bf58e91b2a1f20b0799a45ca48f9a,APR,2023.0,22.0,121.0,15.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51040229', 'name': 'Dominik Sobania'}, {'authorId': '2107692276', 'name': 'Martin Briesch'}, {'authorId': '2202175551', 'name': 'Carol Hanna'}, {'authorId': '1923360', 'name': 'J. Petke'}]","['University College London', 'Johannes Gutenberg University Mainz']","['Germany', 'United Kingdom']",2023-01
2301.10521,Fernando Ferraretto Silva,"Fernando Ferraretto, Thiago Laitz, Roberto Lotufo and Rodrigo Nogueira",ExaRanker: Explanation-Augmented Neural Ranker,,,,,cs.CL cs.AI cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Recent work has shown that inducing a large language model (LLM) to generate explanations prior to outputting an answer is an effective strategy to improve performance on a wide range of reasoning tasks. In this work, we show that neural rankers also benefit from explanations. We use LLMs such as GPT-3.5 to augment retrieval datasets with explanations and train a sequence-to-sequence ranking model to output a relevance label and an explanation for a given query-document pair. Our model, dubbed ExaRanker, finetuned on a few thousand examples with synthetic explanations performs on par with models finetuned on 3x more examples without explanations. Furthermore, the ExaRanker model incurs no additional computational cost during ranking and allows explanations to be requested on demand. ","[{'version': 'v1', 'created': 'Wed, 25 Jan 2023 11:03:04 GMT'}, {'version': 'v2', 'created': 'Sat, 3 Jun 2023 17:11:28 GMT'}]",2023-06-06,"[['Ferraretto', 'Fernando', ''], ['Laitz', 'Thiago', ''], ['Lotufo', 'Roberto', ''], ['Nogueira', 'Rodrigo', '']]",0,1,2023-01-25,2,4,3,1,0,1,988ca520327c2ead08d29c4907130b8a8833d769,256231455.0,https://www.semanticscholar.org/paper/988ca520327c2ead08d29c4907130b8a8833d769,arXiv.org,2023.0,70.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2202551194', 'name': 'Fernando Ferraretto'}, {'authorId': '2188833716', 'name': 'Thiago Laitz'}, {'authorId': '2066179820', 'name': 'R. Lotufo'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}]","['Universidade Federal Fluminense', 'Universidade Estadual de Campinas (UNICAMP)']",['Brazil'],2023-01
2301.11596,Matthias Samwald,"Simon Ott, Konstantin Hebenstreit, Valentin Li\'evin, Christoffer
  Egeberg Hother, Milad Moradi, Maximilian Mayrhauser, Robert Praas, Ole
  Winther, Matthias Samwald",ThoughtSource: A central hub for large language model reasoning data,"Revision: added datasets, formatting",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) such as GPT-4 have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates seven scientific/medical, three general-domain and five math word question answering datasets. ","[{'version': 'v1', 'created': 'Fri, 27 Jan 2023 08:45:53 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Feb 2023 11:10:43 GMT'}, {'version': 'v3', 'created': 'Wed, 19 Jul 2023 15:25:37 GMT'}, {'version': 'v4', 'created': 'Thu, 20 Jul 2023 08:58:12 GMT'}, {'version': 'v5', 'created': 'Thu, 27 Jul 2023 09:37:35 GMT'}]",2023-07-28,"[['Ott', 'Simon', ''], ['Hebenstreit', 'Konstantin', ''], ['Liévin', 'Valentin', ''], ['Hother', 'Christoffer Egeberg', ''], ['Moradi', 'Milad', ''], ['Mayrhauser', 'Maximilian', ''], ['Praas', 'Robert', ''], ['Winther', 'Ole', ''], ['Samwald', 'Matthias', '']]",0,1,2023-01-27,5,9,2,1,0,1,edc9bf11c4810a77f00ccb96130ff67ee578391e,256358591.0,https://www.semanticscholar.org/paper/edc9bf11c4810a77f00ccb96130ff67ee578391e,Scientific Data,2023.0,43.0,10.0,0.0,True,"['Medicine', 'Computer Science']","[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '119994729', 'name': 'Simon Ott'}, {'authorId': '2203247685', 'name': 'Konstantin Hebenstreit'}, {'authorId': '2067078585', 'name': ""Valentin Li'evin""}, {'authorId': '4475692', 'name': 'C. Hother'}, {'authorId': '144334436', 'name': 'M. Moradi'}, {'authorId': '2104625194', 'name': 'Maximilian Mayrhauser'}, {'authorId': '2203245379', 'name': 'Robert Praas'}, {'authorId': '1724252', 'name': 'O. Winther'}, {'authorId': '3004898', 'name': 'M. Samwald'}]","['KTH Royal Institute of Technology', 'Technical University of Denmark', 'Medical University of Vienna', 'Copenhagen University Hospital']","['Austria', 'Sweden', 'Denmark']",2023-01
2301.11845,Gautier Dagan,"Gautier Dagan, Frank Keller, Alex Lascarides",Learning the Effects of Physical Actions in a Multi-modal Environment,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) handle physical commonsense information inadequately. As a result of being trained in a disembodied setting, LLMs often fail to predict an action's outcome in a given environment. However, predicting the effects of an action before it is executed is crucial in planning, where coherent sequences of actions are often needed to achieve a goal. Therefore, we introduce the multi-modal task of predicting the outcomes of actions solely from realistic sensory inputs (images and text). Next, we extend an LLM to model latent representations of objects to better predict action outcomes in an environment. We show that multi-modal models can capture physical commonsense when augmented with visual information. Finally, we evaluate our model's performance on novel actions and objects and find that combining modalities help models to generalize and learn physical commonsense reasoning better. ","[{'version': 'v1', 'created': 'Fri, 27 Jan 2023 16:49:52 GMT'}, {'version': 'v2', 'created': 'Fri, 3 Feb 2023 12:29:30 GMT'}]",2023-02-06,"[['Dagan', 'Gautier', ''], ['Keller', 'Frank', ''], ['Lascarides', 'Alex', '']]",0,0,2023-01-27,2,3,1,0,0,0,fe2f876a33d1f47650408034b74f395485e9034a,256358735.0,https://www.semanticscholar.org/paper/fe2f876a33d1f47650408034b74f395485e9034a,Findings,2023.0,34.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '67175437', 'name': 'Gautier Dagan'}, {'authorId': '1393020635', 'name': 'Frank Keller'}, {'authorId': '1876168', 'name': 'A. Lascarides'}]",['University of Edinburgh'],['United Kingdom'],2023-01
2301.11924,Giovanni Spitale,"Giovanni Spitale, Nikola Biller-Andorno, Federico Germani",AI model GPT-3 (dis)informs us better than humans,"dataset and software: https://osf.io/9ntgf 29 pages, 4 figures, 13
  supplementary figures",,,,cs.CY cs.AI cs.HC,http://creativecommons.org/licenses/by-sa/4.0/,"  Artificial intelligence is changing the way we create and evaluate information, and this is happening during an infodemic, which has been having dramatic effects on global health. In this paper we evaluate whether recruited individuals can distinguish disinformation from accurate information, structured in the form of tweets, and determine whether a tweet is organic or synthetic, i.e., whether it has been written by a Twitter user or by the AI model GPT-3. Our results show that GPT-3 is a double-edge sword, which, in comparison with humans, can produce accurate information that is easier to understand, but can also produce more compelling disinformation. We also show that humans cannot distinguish tweets generated by GPT-3 from tweets written by human users. Starting from our results, we reflect on the dangers of AI for disinformation, and on how we can improve information campaigns to benefit global health. ","[{'version': 'v1', 'created': 'Mon, 23 Jan 2023 14:36:29 GMT'}, {'version': 'v2', 'created': 'Tue, 31 Jan 2023 10:14:03 GMT'}]",2023-02-01,"[['Spitale', 'Giovanni', ''], ['Biller-Andorno', 'Nikola', ''], ['Germani', 'Federico', '']]",0,1,2023-01-23,2,3,3,1,0,1,5575e53739ef0c48c9d6b7cc2146ff89516d0199,256390533.0,https://www.semanticscholar.org/paper/5575e53739ef0c48c9d6b7cc2146ff89516d0199,Science Advances,2023.0,38.0,21.0,0.0,True,"['Medicine', 'Computer Science']","[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '118761777', 'name': 'Giovanni Spitale'}, {'authorId': '1389976160', 'name': 'N. Biller-Andorno'}, {'authorId': '4639533', 'name': 'Federico Germani'}]","['Institute for Biomedical Ethics and History of Medicine (IBME), Winterthurerstrasse 30, 8006 Zürich', 'University of Zurich']",['Switzerland'],2023-01
2301.12066,Liam Magee,"Luke Munn, Liam Magee, Vanicka Arora",Truth Machines: Synthesizing Veracity in AI Language Models,"20 pages, 3 figures",,,,cs.CY cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  As AI technologies are rolled out into healthcare, academia, human resources, law, and a multitude of other domains, they become de-facto arbiters of truth. But truth is highly contested, with many different definitions and approaches. This article discusses the struggle for truth in AI systems and the general responses to date. It then investigates the production of truth in InstructGPT, a large language model, highlighting how data harvesting, model architectures, and social feedback mechanisms weave together disparate understandings of veracity. It conceptualizes this performance as an operationalization of truth, where distinct, often conflicting claims are smoothly synthesized and confidently presented into truth-statements. We argue that these same logics and inconsistencies play out in Instruct's successor, ChatGPT, reiterating truth as a non-trivial problem. We suggest that enriching sociality and thickening ""reality"" are two promising vectors for enhancing the truth-evaluating capacities of future language models. We conclude, however, by stepping back to consider AI truth-telling as a social practice: what kind of ""truth"" do we as listeners desire? ","[{'version': 'v1', 'created': 'Sat, 28 Jan 2023 02:47:50 GMT'}]",2023-01-31,"[['Munn', 'Luke', ''], ['Magee', 'Liam', ''], ['Arora', 'Vanicka', '']]",1,1,2023-01-28,1,3,2,2,0,2,f4db4a18080e9e4ebba9ba68bb7d34230c84d0c3,256389829.0,https://www.semanticscholar.org/paper/f4db4a18080e9e4ebba9ba68bb7d34230c84d0c3,AI &amp; SOCIETY,2023.0,92.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","[{'authorId': '73236053', 'name': 'Luke Munn'}, {'authorId': '2733075', 'name': 'L. Magee'}, {'authorId': '121615955', 'name': 'Vanicka Arora'}]","['University of Stirling', 'Western Sydney University', 'University of Queensland']","['United Kingdom', 'Australia']",2023-01
2301.12169,Christoph Treude,Christoph Treude,Navigating Complexity in Software Engineering: A Prototype for Comparing GPT-n Solutions,,,,,cs.SE cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity. With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project. Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software. However, the interfaces of current chatbot tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries. While other solutions can be requested, they are not displayed by default and are not intuitive to access. In this paper, we present our work-in-progress prototype ""GPTCompare"", which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences. ","[{'version': 'v1', 'created': 'Sat, 28 Jan 2023 11:47:03 GMT'}]",2023-01-31,"[['Treude', 'Christoph', '']]",1,1,2023-01-28,1,1,2,1,0,1,074baf835aec44a100990178859b35451975f339,256390120.0,https://www.semanticscholar.org/paper/074baf835aec44a100990178859b35451975f339,International Workshop on Bots in Software Engineering,2023.0,27.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1685418', 'name': 'Christoph Treude'}]",['University of Melbourne'],['Australia'],2023-01
2301.12726,Yao Fu,"Yao Fu, Hao Peng, Litu Ou, Ashish Sabharwal and Tushar Khot",Specializing Smaller Language Models towards Multi-Step Reasoning,Preprint,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The surprising ability of Large Language Models (LLMs) to perform well on complex reasoning with only few-shot chain-of-thought prompts is believed to emerge only in very large-scale models (100+ billion parameters). We show that such abilities can, in fact, be distilled down from GPT-3.5 ($\ge$ 175B) to T5 variants ($\le$ 11B). We propose model specialization, to specialize the model's ability towards a target task. The hypothesis is that large models (commonly viewed as larger than 100B) have strong modeling power, but are spread on a large spectrum of tasks. Small models (commonly viewed as smaller than 10B) have limited model capacity, but if we concentrate their capacity on a specific target task, the model can achieve a decent improved performance. We use multi-step math reasoning as our testbed because it is a very typical emergent ability. We show two important aspects of model abilities: (1). there exists a very complex balance/ tradeoff between language models' multi-dimensional abilities; (2). by paying the price of decreased generic ability, we can clearly lift up the scaling curve of models smaller than 10B towards a specialized multi-step math reasoning ability. We further give comprehensive discussions about important design choices for better generalization, including the tuning data format, the start model checkpoint, and a new model selection method. We hope our practice and discoveries can serve as an important attempt towards specialized smaller models in the new research paradigm set by LLMs. ","[{'version': 'v1', 'created': 'Mon, 30 Jan 2023 08:51:19 GMT'}]",2023-01-31,"[['Fu', 'Yao', ''], ['Peng', 'Hao', ''], ['Ou', 'Litu', ''], ['Sabharwal', 'Ashish', ''], ['Khot', 'Tushar', '']]",0,1,2023-01-30,1,5,3,2,1,1,fbd49b25bdab98c171af49962a41139c73dacbde,256390607.0,https://www.semanticscholar.org/paper/fbd49b25bdab98c171af49962a41139c73dacbde,International Conference on Machine Learning,2023.0,33.0,64.0,11.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46956602', 'name': 'Yao Fu'}, {'authorId': '2293471', 'name': 'Hao-Chun Peng'}, {'authorId': '2203370918', 'name': 'Litu Ou'}, {'authorId': '48229640', 'name': 'Ashish Sabharwal'}, {'authorId': '2236429', 'name': 'Tushar Khot'}]",['University of Edinburgh'],['United Kingdom'],2023-01
2301.12867,Terry Yue Zhuo,"Terry Yue Zhuo, Yujin Huang, Chunyang Chen and Zhenchang Xing","Red teaming ChatGPT via Jailbreaking: Bias, Robustness, Reliability and Toxicity",Technical Report,,,,cs.CL cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications. The large language models (LLMs) have significantly impacted businesses such as report summarization software and copywriters. Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility. Large-scale benchmarks for accountable LLMs should consequently be developed. Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is little systematic examination and user study of the risks and harmful behaviors of current LLM usage. To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method called ``red teaming'' on OpenAI's ChatGPT\footnote{In this paper, ChatGPT refers to the version released on Dec 15th.} to better understand the practical features of ethical dangers in recent LLMs. We analyze ChatGPT comprehensively from four perspectives: 1) \textit{Bias} 2) \textit{Reliability} 3) \textit{Robustness} 4) \textit{Toxicity}. In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets. We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies. In addition, we examine the implications of our findings on AI ethics and harmal behaviors of ChatGPT, as well as future problems and practical design considerations for responsible LLMs. We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications. ","[{'version': 'v1', 'created': 'Mon, 30 Jan 2023 13:20:48 GMT'}, {'version': 'v2', 'created': 'Mon, 20 Feb 2023 16:29:25 GMT'}, {'version': 'v3', 'created': 'Wed, 22 Feb 2023 07:35:38 GMT'}, {'version': 'v4', 'created': 'Mon, 29 May 2023 17:46:54 GMT'}]",2023-05-30,"[['Zhuo', 'Terry Yue', ''], ['Huang', 'Yujin', ''], ['Chen', 'Chunyang', ''], ['Xing', 'Zhenchang', '']]",1,1,2023-01-30,4,4,2,1,0,1,528bfc811a3b4213566134afe2c880f867be5065,258960373.0,https://www.semanticscholar.org/paper/528bfc811a3b4213566134afe2c880f867be5065,,2023.0,94.0,19.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2080123731', 'name': 'Terry Yue Zhuo'}, {'authorId': '2108733121', 'name': 'Yujin Huang'}, {'authorId': '46729152', 'name': 'Chunyang Chen'}, {'authorId': '3138980', 'name': 'Zhenchang Xing'}]","['Monash University', 'Australian National University']",['Australia'],2023-01
2301.12868,Terry Yue Zhuo,"Terry Yue Zhuo, Zhuang Li, Yujin Huang, Fatemeh Shiri, Weiqing Wang,
  Gholamreza Haffari and Yuan-Fang Li",On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex,Accepted at EACL2023 (main),,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Semantic parsing is a technique aimed at constructing a structured representation of the meaning of a natural-language question. Recent advancements in few-shot language models trained on code have demonstrated superior performance in generating these representations compared to traditional unimodal language models, which are trained on downstream tasks. Despite these advancements, existing fine-tuned neural semantic parsers are susceptible to adversarial attacks on natural-language inputs. While it has been established that the robustness of smaller semantic parsers can be enhanced through adversarial training, this approach is not feasible for large language models in real-world scenarios, as it requires both substantial computational resources and expensive human annotation on in-domain semantic parsing data. This paper presents the first empirical study on the adversarial robustness of a large prompt-based language model of code, \codex. Our results demonstrate that the state-of-the-art (SOTA) code-language models are vulnerable to carefully crafted adversarial examples. To address this challenge, we propose methods for improving robustness without the need for significant amounts of labeled data or heavy computational resources. ","[{'version': 'v1', 'created': 'Mon, 30 Jan 2023 13:21:00 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Feb 2023 07:06:53 GMT'}, {'version': 'v3', 'created': 'Thu, 9 Mar 2023 11:01:02 GMT'}]",2023-03-10,"[['Zhuo', 'Terry Yue', ''], ['Li', 'Zhuang', ''], ['Huang', 'Yujin', ''], ['Shiri', 'Fatemeh', ''], ['Wang', 'Weiqing', ''], ['Haffari', 'Gholamreza', ''], ['Li', 'Yuan-Fang', '']]",0,0,2023-01-30,3,7,1,1,0,1,1c91b23d78944f7f237cb512029c2165972ae9d5,256389762.0,https://www.semanticscholar.org/paper/1c91b23d78944f7f237cb512029c2165972ae9d5,Conference of the European Chapter of the Association for Computational Linguistics,2023.0,82.0,21.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2080123731', 'name': 'Terry Yue Zhuo'}, {'authorId': '1455835132', 'name': 'Zhuang Li'}, {'authorId': '2108733121', 'name': 'Yujin Huang'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}, {'authorId': '2154869314', 'name': 'Weiqing Wang'}, {'authorId': '2561045', 'name': 'Gholamreza Haffari'}, {'authorId': '49994056', 'name': 'Fatemeh Shiri'}]","['Monash University', 'Data61']",['Australia'],2023-01
2301.13294,Yasmin Moslem,"Yasmin Moslem, Rejwanul Haque, John D. Kelleher, Andy Way",Adaptive Machine Translation with Large Language Models,EAMT 2023 - Research: technical,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Consistency is a key requirement of high-quality translation. It is especially important to adhere to pre-approved terminology and adapt to corrected translations in domain-specific projects. Machine translation (MT) has achieved significant progress in the area of domain adaptation. However, real-time adaptation remains challenging. Large-scale language models (LLMs) have recently shown interesting capabilities of in-context learning, where they learn to replicate certain input-output text generation patterns, without further fine-tuning. By feeding an LLM at inference time with a prompt that consists of a list of translation pairs, it can then simulate the domain and style characteristics. This work aims to investigate how we can utilize in-context learning to improve real-time adaptive MT. Our extensive experiments show promising results at translation time. For example, LLMs can adapt to a set of in-domain sentence pairs and/or terminology while translating a new sentence. We observe that the translation quality with few-shot in-context learning can surpass that of strong encoder-decoder MT systems, especially for high-resource languages. Moreover, we investigate whether we can combine MT from strong encoder-decoder models with fuzzy matches, which can further improve translation quality, especially for less supported languages. We conduct our experiments across five diverse language pairs, namely English-to-Arabic (EN-AR), English-to-Chinese (EN-ZH), English-to-French (EN-FR), English-to-Kinyarwanda (EN-RW), and English-to-Spanish (EN-ES). ","[{'version': 'v1', 'created': 'Mon, 30 Jan 2023 21:17:15 GMT'}, {'version': 'v2', 'created': 'Mon, 13 Mar 2023 06:43:18 GMT'}, {'version': 'v3', 'created': 'Tue, 9 May 2023 11:04:43 GMT'}]",2023-05-10,"[['Moslem', 'Yasmin', ''], ['Haque', 'Rejwanul', ''], ['Kelleher', 'John D.', ''], ['Way', 'Andy', '']]",0,0,2023-01-30,3,4,1,0,0,0,9689acb6cb760e8bc21c16f368368b37dee977f9,256416029.0,https://www.semanticscholar.org/paper/9689acb6cb760e8bc21c16f368368b37dee977f9,European Association for Machine Translation Conferences/Workshops,2023.0,67.0,19.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '9400076', 'name': 'Yasmin Moslem'}, {'authorId': '1748844', 'name': 'Rejwanul Haque'}, {'authorId': '144315616', 'name': 'Andy Way'}]","['Technological University Dublin', 'Dublin City University', 'South East Technological University']",['Ireland'],2023-01
2301.13573,Sebastian Risi,Shyam Sudhakaran and Sebastian Risi,Skill Decision Transformer,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work has shown that Large Language Models (LLMs) can be incredibly effective for offline reinforcement learning (RL) by representing the traditional RL problem as a sequence modelling problem (Chen et al., 2021; Janner et al., 2021). However many of these methods only optimize for high returns, and may not extract much information from a diverse dataset of trajectories. Generalized Decision Transformers (GDTs) (Furuta et al., 2021) have shown that utilizing future trajectory information, in the form of information statistics, can help extract more information from offline trajectory data. Building upon this, we propose Skill Decision Transformer (Skill DT). Skill DT draws inspiration from hindsight relabelling (Andrychowicz et al., 2017) and skill discovery methods to discover a diverse set of primitive behaviors, or skills. We show that Skill DT can not only perform offline state-marginal matching (SMM), but can discovery descriptive behaviors that can be easily sampled. Furthermore, we show that through purely reward-free optimization, Skill DT is still competitive with supervised offline RL approaches on the D4RL benchmark. The code and videos can be found on our project page: https://github.com/shyamsn97/skill-dt ","[{'version': 'v1', 'created': 'Tue, 31 Jan 2023 11:52:46 GMT'}]",2023-02-01,"[['Sudhakaran', 'Shyam', ''], ['Risi', 'Sebastian', '']]",0,0,2023-01-31,1,2,1,0,0,0,a42744a7c8db25290254b2b60831972a3926ae02,256416287.0,https://www.semanticscholar.org/paper/a42744a7c8db25290254b2b60831972a3926ae02,arXiv.org,2023.0,29.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '52176695', 'name': 'Shyam Sudhakaran'}, {'authorId': '1745664', 'name': 'S. Risi'}]",['University of Copenhagen'],['Denmark'],2023-01
2301.13819,Cheng Zhang,Ruibo Tu and Chao Ma and Cheng Zhang,Causal-Discovery Performance of ChatGPT in the context of Neuropathic Pain Diagnosis,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT has demonstrated exceptional proficiency in natural language conversation, e.g., it can answer a wide range of questions while no previous large language models can. Thus, we would like to push its limit and explore its ability to answer causal discovery questions by using a medical benchmark (Tu et al. 2019) in causal discovery. ","[{'version': 'v1', 'created': 'Tue, 24 Jan 2023 19:23:38 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Feb 2023 12:03:38 GMT'}]",2023-02-07,"[['Tu', 'Ruibo', ''], ['Ma', 'Chao', ''], ['Zhang', 'Cheng', '']]",1,1,2023-01-24,2,3,2,1,0,1,8d43f788a863258dc0a34e05f4a0c9f434be7829,256416013.0,https://www.semanticscholar.org/paper/8d43f788a863258dc0a34e05f4a0c9f434be7829,arXiv.org,2023.0,4.0,13.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51132868', 'name': 'Ruibo Tu'}, {'authorId': '144905350', 'name': 'Chao Ma'}, {'authorId': '2200137595', 'name': 'Cheng Zhang'}]","['KTH Royal Institute of Technology', 'Microsoft']","['India', 'Sweden']",2023-01
2301.13852,Omran Ayoub Dr.,"Sandra Mitrovi\'c, Davide Andreoletti, Omran Ayoub",ChatGPT or Human? Detect and Explain. Explaining Decisions of Machine Learning Model for Detecting Short ChatGPT-generated Text,"11 pages, 8 figures, 2 tables",,,,cs.CL cs.LG,http://creativecommons.org/publicdomain/zero/1.0/,"  ChatGPT has the ability to generate grammatically flawless and seemingly-human replies to different types of questions from various domains. The number of its users and of its applications is growing at an unprecedented rate. Unfortunately, use and abuse come hand in hand. In this paper, we study whether a machine learning model can be effectively trained to accurately distinguish between original human and seemingly human (that is, ChatGPT-generated) text, especially when this text is short. Furthermore, we employ an explainable artificial intelligence framework to gain insight into the reasoning behind the model trained to differentiate between ChatGPT-generated and human-generated text. The goal is to analyze model's decisions and determine if any specific patterns or characteristics can be identified. Our study focuses on short online reviews, conducting two experiments comparing human-generated and ChatGPT-generated text. The first experiment involves ChatGPT text generated from custom queries, while the second experiment involves text generated by rephrasing original human-generated reviews. We fine-tune a Transformer-based model and use it to make predictions, which are then explained using SHAP. We compare our model with a perplexity score-based approach and find that disambiguation between human and ChatGPT-generated reviews is more challenging for the ML model when using rephrased text. However, our proposed approach still achieves an accuracy of 79%. Using explainability, we observe that ChatGPT's writing is polite, without specific details, using fancy and atypical vocabulary, impersonal, and typically it does not express feelings. ","[{'version': 'v1', 'created': 'Mon, 30 Jan 2023 08:06:08 GMT'}]",2023-02-01,"[['Mitrović', 'Sandra', ''], ['Andreoletti', 'Davide', ''], ['Ayoub', 'Omran', '']]",1,1,2023-01-30,1,3,2,1,0,1,d410f915eeb9c92a2970568338804261f1377331,256416337.0,https://www.semanticscholar.org/paper/d410f915eeb9c92a2970568338804261f1377331,arXiv.org,2023.0,13.0,62.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2203427954', 'name': ""Sandra Mitrovi'c""}, {'authorId': '7469234', 'name': 'Davide Andreoletti'}, {'authorId': '40120784', 'name': 'Omran Ayoub'}]","['Dalle Molle Institute for Artificial Intelligence Research', 'University of Applied Sciences and Arts of Southern Switzerland']",['Switzerland'],2023-01
2302.00612,Seunghyun Lee,"Seunghyun Lee, Da Young Lee, Sujeong Im, Nan Hee Kim, Sung-Min Park",Clinical Decision Transformer: Intended Treatment Recommendation through Goal Prompting,,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  With recent achievements in tasks requiring context awareness, foundation models have been adopted to treat large-scale data from electronic health record (EHR) systems. However, previous clinical recommender systems based on foundation models have a limited purpose of imitating clinicians' behavior and do not directly consider a problem of missing values. In this paper, we propose Clinical Decision Transformer (CDT), a recommender system that generates a sequence of medications to reach a desired range of clinical states given as goal prompts. For this, we conducted goal-conditioned sequencing, which generated a subsequence of treatment history with prepended future goal state, and trained the CDT to model sequential medications required to reach that goal state. For contextual embedding over intra-admission and inter-admissions, we adopted a GPT-based architecture with an admission-wise attention mask and column embedding. In an experiment, we extracted a diabetes dataset from an EHR system, which contained treatment histories of 4788 patients. We observed that the CDT achieved the intended treatment effect according to goal prompt ranges (e.g., NormalA1c, LowerA1c, and HigherA1c), contrary to the case with behavior cloning. To the best of our knowledge, this is the first study to explore clinical recommendations from the perspective of goal prompting. See https://clinical-decision-transformer.github.io for code and additional information. ","[{'version': 'v1', 'created': 'Wed, 1 Feb 2023 17:26:01 GMT'}]",2023-02-02,"[['Lee', 'Seunghyun', ''], ['Lee', 'Da Young', ''], ['Im', 'Sujeong', ''], ['Kim', 'Nan Hee', ''], ['Park', 'Sung-Min', '']]",0,1,2023-02-01,1,5,1,0,0,0,cd7e947c7b9f85ed88f79ef8eb07ee38854f6694,256459649.0,https://www.semanticscholar.org/paper/cd7e947c7b9f85ed88f79ef8eb07ee38854f6694,arXiv.org,2023.0,33.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2117178205', 'name': 'Seunghyun Lee'}, {'authorId': '2371074', 'name': 'D. Lee'}, {'authorId': '2203942920', 'name': 'Sujeong Im'}, {'authorId': '2203851171', 'name': 'N. Kim'}, {'authorId': '2115520071', 'name': 'Sung-Min Park'}]","['Pohang University of Science and Technology', 'Division of Endocrinology and Metabolism,', 'Korea University']",['South Korea'],2023-02
2302.00722,Johannes Schneider,Johannes Schneider and Michalis Vlachos,A Survey of Deep Learning: From Activations to Transformers,,,,,cs.LG cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The past decade has witnessed remarkable advancements in deep learning, owing to the emergence of various architectures, layers, objectives, and optimization techniques. These consist of a multitude of variations of attention, normalization, skip connections, transformer, and self-supervised learning methods, among others. Our goal is to furnish a comprehensive survey of significant recent contributions in these domains to individuals with a fundamental grasp of deep learning. Our aspiration is that an integrated and comprehensive approach of influential recent works will facilitate the formation of new connections between different areas of deep learning. In our discussion, we discuss multiple patterns that summarize the key strategies for many of the successful innovations over the last decade. We also include a discussion on recent commercially built, closed-source models such as OpenAI's GPT-4 and Google's PaLM 2. ","[{'version': 'v1', 'created': 'Wed, 1 Feb 2023 19:34:55 GMT'}, {'version': 'v2', 'created': 'Wed, 9 Aug 2023 16:17:45 GMT'}]",2023-08-10,"[['Schneider', 'Johannes', ''], ['Vlachos', 'Michalis', '']]",0,1,2023-02-01,2,2,2,2,0,2,e080b48cc7f52623c500d958d1378b147a2ca55f,256504056.0,https://www.semanticscholar.org/paper/e080b48cc7f52623c500d958d1378b147a2ca55f,arXiv.org,2023.0,98.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2113526658', 'name': 'Johannes Schneider'}, {'authorId': '151481675', 'name': 'Michalis Vlachos'}]","['University of Lausanne', 'University of Liechtenstein']","['Switzerland', 'Liechtenstein']",2023-02
2302.01025,Matteo Delsanto,"Davide Colla, Matteo Delsanto, Marco Agosto, Benedetto Vitiello,
  Daniele Paolo Radicioni",Semantic Coherence Markers for the Early Diagnosis of the Alzheimer Disease,"This paper is the (significantly) abridged version of the article
  ""Semantic coherence markers: The contribution of perplexity metrics""
  (https://doi.org/10.1016/j.artmed.2022.102393), which also contains
  references to employed data and to the implementation of the described work",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this work we explore how language models can be employed to analyze language and discriminate between mentally impaired and healthy subjects through the perplexity metric. Perplexity was originally conceived as an information-theoretic measure to assess how much a given language model is suited to predict a text sequence or, equivalently, how much a word sequence fits into a specific language model. We carried out an extensive experimentation with the publicly available data, and employed language models as diverse as N-grams, from 2-grams to 5-grams, and GPT-2, a transformer-based language model. We investigated whether perplexity scores may be used to discriminate between the transcripts of healthy subjects and subjects suffering from Alzheimer Disease (AD). Our best performing models achieved full accuracy and F-score (1.00 in both precision/specificity and recall/sensitivity) in categorizing subjects from both the AD class and control subjects. These results suggest that perplexity can be a valuable analytical metrics with potential application to supporting early diagnosis of symptoms of mental disorders. ","[{'version': 'v1', 'created': 'Thu, 2 Feb 2023 11:40:16 GMT'}]",2023-02-03,"[['Colla', 'Davide', ''], ['Delsanto', 'Matteo', ''], ['Agosto', 'Marco', ''], ['Vitiello', 'Benedetto', ''], ['Radicioni', 'Daniele Paolo', '']]",0,1,2023-02-02,1,5,2,1,1,0,7cb202829bebf71d7eb36b96d8719270f77ccbd1,256503870.0,https://www.semanticscholar.org/paper/7cb202829bebf71d7eb36b96d8719270f77ccbd1,arXiv.org,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '11843298', 'name': 'Davide Colla'}, {'authorId': '147448744', 'name': 'Matteo Delsanto'}, {'authorId': '2184169759', 'name': 'Marco Agosto'}, {'authorId': '6504772', 'name': 'B. Vitiello'}, {'authorId': '2064613927', 'name': 'Daniele P. Radicioni'}]",['University of Turin'],['Italy'],2023-02
2302.01501,Hamed Rahimi,"Hamed Rahimi, Hubert Naacke, Camelia Constantin, Bernd Amann",ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics,,,,,cs.IR cs.AI cs.LG cs.NE cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents an algorithmic family of dynamic topic models called Aligned Neural Topic Models (ANTM), which combine novel data mining algorithms to provide a modular framework for discovering evolving topics. ANTM maintains the temporal continuity of evolving topics by extracting time-aware features from documents using advanced pre-trained Large Language Models (LLMs) and employing an overlapping sliding window algorithm for sequential document clustering. This overlapping sliding window algorithm identifies a different number of topics within each time frame and aligns semantically similar document clusters across time periods. This process captures emerging and fading trends across different periods and allows for a more interpretable representation of evolving topics. Experiments on four distinct datasets show that ANTM outperforms probabilistic dynamic topic models in terms of topic coherence and diversity metrics. Moreover, it improves the scalability and flexibility of dynamic topic models by being accessible and adaptable to different types of algorithms. Additionally, a Python package is developed for researchers and scientists who wish to study the trends and evolving patterns of topics in large-scale textual data. ","[{'version': 'v1', 'created': 'Fri, 3 Feb 2023 02:31:12 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Jun 2023 16:23:00 GMT'}]",2023-06-06,"[['Rahimi', 'Hamed', ''], ['Naacke', 'Hubert', ''], ['Constantin', 'Camelia', ''], ['Amann', 'Bernd', '']]",0,0,2023-02-03,2,4,5,0,0,0,bedf02069db831805460f3ddfa27935b4944127b,256598333.0,https://www.semanticscholar.org/paper/bedf02069db831805460f3ddfa27935b4944127b,arXiv.org,2023.0,61.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2204464778', 'name': 'Hamed Rahimi'}, {'authorId': '3045686', 'name': 'Hubert Naacke'}, {'authorId': '35241447', 'name': 'Camélia Constantin'}, {'authorId': '1747227', 'name': 'B. Amann'}]",['Sorbonne Université'],['France'],2023-02
2302.02805,Samuel A. Prieto,"Samuel A. Prieto, Eyob T. Mengiste, Borja Garc\'ia de Soto",Investigating the use of ChatGPT for the scheduling of construction projects,"14 pages, 6 figures",,10.3390/buildings13040857,,cs.HC cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large language models such as ChatGPT have the potential to revolutionize the construction industry by automating repetitive and time-consuming tasks. This paper presents a study in which ChatGPT was used to generate a construction schedule for a simple construction project. The output from ChatGPT was evaluated by a pool of participants that provided feedback regarding their overall interaction experience and the quality of the output. The results show that ChatGPT can generate a coherent schedule that follows a logical approach to fulfill the requirements of the scope indicated. The participants had an overall positive interaction experience and indicated the great potential of such a tool to automate many preliminary and time-consuming tasks. However, the technology still has limitations, and further development is needed before it can be widely adopted in the industry. Overall, this study highlights the potential of using large language models in the construction industry and the need for further research. ","[{'version': 'v1', 'created': 'Fri, 27 Jan 2023 12:05:44 GMT'}]",2023-07-21,"[['Prieto', 'Samuel A.', ''], ['Mengiste', 'Eyob T.', ''], ['de Soto', 'Borja García', '']]",1,1,2023-01-27,1,3,2,1,0,1,58b98ccd256f1ebe8551faa6798cfbfc80c490a5,256615316.0,https://www.semanticscholar.org/paper/58b98ccd256f1ebe8551faa6798cfbfc80c490a5,Buildings,2023.0,35.0,31.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '7322132', 'name': 'S. Prieto'}, {'authorId': '2166277457', 'name': 'Eyob Mengiste'}, {'authorId': '98018377', 'name': 'Borja García de Soto'}]",['New York University Abu Dhabi'],['United Arab Emirates'],2023-01
2302.03491,Amirkeivan Mohtashami,"Amirkeivan Mohtashami, Mauro Verzetti, Paul K. Rubenstein",Learning Translation Quality Evaluation on Low Resource Languages from Large Language Models,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Learned metrics such as BLEURT have in recent years become widely employed to evaluate the quality of machine translation systems. Training such metrics requires data which can be expensive and difficult to acquire, particularly for lower-resource languages. We show how knowledge can be distilled from Large Language Models (LLMs) to improve upon such learned metrics without requiring human annotators, by creating synthetic datasets which can be mixed into existing datasets, requiring only a corpus of text in the target language. We show that the performance of a BLEURT-like model on lower resource languages can be improved in this way. ","[{'version': 'v1', 'created': 'Tue, 7 Feb 2023 14:35:35 GMT'}]",2023-02-08,"[['Mohtashami', 'Amirkeivan', ''], ['Verzetti', 'Mauro', ''], ['Rubenstein', 'Paul K.', '']]",0,0,2023-02-07,1,3,2,0,0,0,7fdfe07e7e6d6dd38efdab12a3e81d47325ad575,256627762.0,https://www.semanticscholar.org/paper/7fdfe07e7e6d6dd38efdab12a3e81d47325ad575,arXiv.org,2023.0,17.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1580494295', 'name': 'Amirkeivan Mohtashami'}, {'authorId': '51052911', 'name': 'M. Verzetti'}, {'authorId': '48159426', 'name': 'Paul K. Rubenstein'}]","['École Polytechnique Fédérale de Lausanne', 'University of Zurich']",['Switzerland'],2023-02
2302.03495,Shuai Wang,"Shuai Wang, Harrisen Scells, Bevan Koopman, Guido Zuccon",Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?,,,,,cs.IR cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Systematic reviews are comprehensive reviews of the literature for a highly focused research question. These reviews are often treated as the highest form of evidence in evidence-based medicine, and are the key strategy to answer research questions in the medical field. To create a high-quality systematic review, complex Boolean queries are often constructed to retrieve studies for the review topic. However, it often takes a long time for systematic review researchers to construct a high quality systematic review Boolean query, and often the resulting queries are far from effective. Poor queries may lead to biased or invalid reviews, because they missed to retrieve key evidence, or to extensive increase in review costs, because they retrieved too many irrelevant studies. Recent advances in Transformer-based generative models have shown great potential to effectively follow instructions from users and generate answers based on the instructions being made. In this paper, we investigate the effectiveness of the latest of such models, ChatGPT, in generating effective Boolean queries for systematic review literature search. Through a number of extensive experiments on standard test collections for the task, we find that ChatGPT is capable of generating queries that lead to high search precision, although trading-off this for recall. Overall, our study demonstrates the potential of ChatGPT in generating effective Boolean queries for systematic review literature search. The ability of ChatGPT to follow complex instructions and generate queries with high precision makes it a valuable tool for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and often trading-off higher precision for lower recall is acceptable. ","[{'version': 'v1', 'created': 'Fri, 3 Feb 2023 01:28:25 GMT'}, {'version': 'v2', 'created': 'Wed, 8 Feb 2023 06:23:35 GMT'}, {'version': 'v3', 'created': 'Thu, 9 Feb 2023 11:53:43 GMT'}]",2023-02-10,"[['Wang', 'Shuai', ''], ['Scells', 'Harrisen', ''], ['Koopman', 'Bevan', ''], ['Zuccon', 'Guido', '']]",1,1,2023-02-03,3,4,2,1,0,1,d91bd7bdea31775302a8a0b997b6d67bf20ac297,256627169.0,https://www.semanticscholar.org/paper/d91bd7bdea31775302a8a0b997b6d67bf20ac297,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,87.0,61.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146514461', 'name': 'Shuai Wang'}, {'authorId': '8842143', 'name': 'Harrisen Scells'}, {'authorId': '1783566', 'name': 'B. Koopman'}, {'authorId': '1692855', 'name': 'G. Zuccon'}]","['Leipzig University', 'Commonwealth Scientific and Industrial Research Organisation', 'University of Queensland']","['Germany', 'Australia']",2023-02
2302.03694,Patrick Owusu,"Jean Marie Tshimula, D'Jeff K. Nkashama, Patrick Owusu, Marc Frappier,
  Pierre-Martin Tardif, Froduald Kabanza, Armelle Brun, Jean-Marc Patenaude,
  Shengrui Wang, Belkacem Chikhaoui",Characterizing Financial Market Coverage using Artificial Intelligence,,,,,q-fin.ST cs.AI cs.CL cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper scrutinizes a database of over 4900 YouTube videos to characterize financial market coverage. Financial market coverage generates a large number of videos. Therefore, watching these videos to derive actionable insights could be challenging and complex. In this paper, we leverage Whisper, a speech-to-text model from OpenAI, to generate a text corpus of market coverage videos from Bloomberg and Yahoo Finance. We employ natural language processing to extract insights regarding language use from the market coverage. Moreover, we examine the prominent presence of trending topics and their evolution over time, and the impacts that some individuals and organizations have on the financial market. Our characterization highlights the dynamics of the financial market coverage and provides valuable insights reflecting broad discussions regarding recent financial events and the world economy. ","[{'version': 'v1', 'created': 'Tue, 7 Feb 2023 16:03:33 GMT'}]",2023-02-09,"[['Tshimula', 'Jean Marie', ''], ['Nkashama', ""D'Jeff K."", ''], ['Owusu', 'Patrick', ''], ['Frappier', 'Marc', ''], ['Tardif', 'Pierre-Martin', ''], ['Kabanza', 'Froduald', ''], ['Brun', 'Armelle', ''], ['Patenaude', 'Jean-Marc', ''], ['Wang', 'Shengrui', ''], ['Chikhaoui', 'Belkacem', '']]",0,0,2023-02-07,1,10,5,0,0,0,be16705f3f2311a923dc509e384457f812244e23,256662200.0,https://www.semanticscholar.org/paper/be16705f3f2311a923dc509e384457f812244e23,arXiv.org,2023.0,41.0,2.0,0.0,True,"['Economics', 'Computer Science']","[{'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","[{'authorId': '51303423', 'name': 'Jean Marie Tshimula'}, {'authorId': '2163095815', 'name': ""D'Jeff K. Nkashama""}, {'authorId': '107862861', 'name': 'Patrick Owusu'}, {'authorId': '1805215', 'name': 'M. Frappier'}, {'authorId': '1900283', 'name': 'Pierre Martin Tardif'}, {'authorId': '2132916', 'name': 'F. Kabanza'}, {'authorId': '1754580', 'name': 'A. Brun'}, {'authorId': '66257275', 'name': 'Jean-Marc Patenaude'}, {'authorId': '2151484651', 'name': 'Shengrui Wang'}, {'authorId': '2026478', 'name': 'B. Chikhaoui'}]","['Laboratory on Plasma and Conversion of Energy', 'Université de Sherbrooke', 'Université de Lorraine', 'Université TÉLUQ']","['Canada', 'France']",2023-02
2302.04324,Ofer Lahav,Ofer Lahav (UCL),Deep Machine Learning in Cosmology: Evolution or Revolution?,"12 pages, 11 figures, Plenary lecture at the IAU GA (August 2022,
  South Korea), to appear in Proceedings of IAU Symposium 368, 'Machine
  Learning in Astronomy: Possibilities and Pitfalls'",,,,astro-ph.CO astro-ph.IM physics.data-an,http://creativecommons.org/licenses/by/4.0/,"  Could Machine Learning (ML) make fundamental discoveries and tackle unsolved problems in Cosmology? Detailed observations of the present contents of the universe are consistent with the Cosmological Constant Lambda and Cold Dark Matter model, subject to some unresolved inconsistencies ('tensions') among observations of the Hubble Constant and the clumpiness factor. To understand these issues further, large surveys of billions of galaxies and other probes require new statistical approaches. In recent years the power of ML, and in particular 'Deep Learning', has been demonstrated for object classification, photometric redshifts, anomaly detection, enhanced simulations, and inference of cosmological parameters. It is argued that the more traditional 'shallow learning' (i.e. with pre-processing feature extraction) is actually quite deep, as it brings in human knowledge, while 'deep learning' might be perceived as a black box, unless supplemented by explainability tools. The 'killer applications' of ML for Cosmology are still to come. New ways to train the next generation of scientists for the Data Intensive Science challenges ahead are also discussed. Finally, the chatbot ChatGPT is challenged to address the question posed in this article's title. ","[{'version': 'v1', 'created': 'Wed, 8 Feb 2023 20:38:58 GMT'}]",2023-02-10,"[['Lahav', 'Ofer', '', 'UCL']]",1,1,2023-02-08,1,1,3,1,0,1,b5e339086e954112c2c6905cb18975a769d0f2b9,256697646.0,https://www.semanticscholar.org/paper/b5e339086e954112c2c6905cb18975a769d0f2b9,,2023.0,2.0,1.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '103135769', 'name': 'O. Lahav'}]",['University College London'],['United Kingdom'],2023-02
2302.04335,Mohammad Khalil,Mohammad Khalil and Erkan Er,Will ChatGPT get you caught? Rethinking of Plagiarism Detection,,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The rise of Artificial Intelligence (AI) technology and its impact on education has been a topic of growing concern in recent years. The new generation AI systems such as chatbots have become more accessible on the Internet and stronger in terms of capabilities. The use of chatbots, particularly ChatGPT, for generating academic essays at schools and colleges has sparked fears among scholars. This study aims to explore the originality of contents produced by one of the most popular AI chatbots, ChatGPT. To this end, two popular plagiarism detection tools were used to evaluate the originality of 50 essays generated by ChatGPT on various topics. Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software. In other words, ChatGPT can create content on many topics with high originality as if they were written by someone. These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort. Moreover, ChatGPT was asked to verify if the essays were generated by itself, as an additional measure of plagiarism check, and it showed superior performance compared to the traditional plagiarism-detection tools. The paper discusses the need for institutions to consider appropriate measures to mitigate potential plagiarism issues and advise on the ongoing debate surrounding the impact of AI technology on education. Further implications are discussed in the paper. ","[{'version': 'v1', 'created': 'Wed, 8 Feb 2023 20:59:18 GMT'}]",2023-02-10,"[['Khalil', 'Mohammad', ''], ['Er', 'Erkan', '']]",1,1,2023-02-08,1,2,1,1,0,1,4cd3ae84e24cfff89ef022e36991df314aac83e2,256697594.0,https://www.semanticscholar.org/paper/4cd3ae84e24cfff89ef022e36991df314aac83e2,Interacción,2023.0,23.0,63.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '88352234', 'name': 'M. Khalil'}, {'authorId': '1940086', 'name': 'Erkan Er'}]","['University of Bergen', 'Middle East Technical University']","['Turkey', 'Norway']",2023-02
2302.04793,Mehrdad Sabetzadeh,"Saad Ezzini, Sallam Abualhaija, Chetan Arora, Mehrdad Sabetzadeh",AI-based Question Answering Assistance for Analyzing Natural-language Requirements,"This paper has been accepted at the 45th International Conference on
  Software Engineering (ICSE 2023)",,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  By virtue of being prevalently written in natural language (NL), requirements are prone to various defects, e.g., inconsistency and incompleteness. As such, requirements are frequently subject to quality assurance processes. These processes, when carried out entirely manually, are tedious and may further overlook important quality issues due to time and budget pressures. In this paper, we propose QAssist -- a question-answering (QA) approach that provides automated assistance to stakeholders, including requirements engineers, during the analysis of NL requirements. Posing a question and getting an instant answer is beneficial in various quality-assurance scenarios, e.g., incompleteness detection. Answering requirements-related questions automatically is challenging since the scope of the search for answers can go beyond the given requirements specification. To that end, QAssist provides support for mining external domain-knowledge resources. Our work is one of the first initiatives to bring together QA and external domain knowledge for addressing requirements engineering challenges. We evaluate QAssist on a dataset covering three application domains and containing a total of 387 question-answer pairs. We experiment with state-of-the-art QA methods, based primarily on recent large-scale language models. In our empirical study, QAssist localizes the answer to a question to three passages within the requirements specification and within the external domain-knowledge resource with an average recall of 90.1% and 96.5%, respectively. QAssist extracts the actual answer to the posed question with an average accuracy of 84.2%.   Keywords: Natural-language Requirements, Question Answering (QA), Language Models, Natural Language Processing (NLP), Natural Language Generation (NLG), BERT, T5. ","[{'version': 'v1', 'created': 'Thu, 9 Feb 2023 17:31:46 GMT'}]",2023-02-10,"[['Ezzini', 'Saad', ''], ['Abualhaija', 'Sallam', ''], ['Arora', 'Chetan', ''], ['Sabetzadeh', 'Mehrdad', '']]",0,0,2023-02-09,1,4,1,1,1,0,964777614f7ed3851a8e25c02b4119fa2450a43a,256697636.0,https://www.semanticscholar.org/paper/964777614f7ed3851a8e25c02b4119fa2450a43a,International Conference on Software Engineering,2023.0,97.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40800531', 'name': 'Saad Ezzini'}, {'authorId': '2115020289', 'name': 'Sallam Abualhaija'}, {'authorId': '38772597', 'name': 'Chetan Arora'}, {'authorId': '2416077', 'name': 'M. Sabetzadeh'}]","['Monash University', 'Deakin University', 'University of Luxembourg', 'University of Ottawa']","['Canada', 'Luxembourg', 'Australia']",2023-02
2302.05128,Harold Soh,"Yaqi Xie, Chen Yu, Tongyao Zhu, Jinbin Bai, Ze Gong, Harold Soh",Translating Natural Language to Planning Goals with Large-Language Models,,,,,cs.CL cs.AI cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent large language models (LLMs) have demonstrated remarkable performance on a variety of natural language processing (NLP) tasks, leading to intense excitement about their applicability across various domains. Unfortunately, recent work has also shown that LLMs are unable to perform accurate reasoning nor solve planning problems, which may limit their usefulness for robotics-related tasks. In this work, our central question is whether LLMs are able to translate goals specified in natural language to a structured planning language. If so, LLM can act as a natural interface between the planner and human users; the translated goal can be handed to domain-independent AI planners that are very effective at planning. Our empirical results on GPT 3.5 variants show that LLMs are much better suited towards translation rather than planning. We find that LLMs are able to leverage commonsense knowledge and reasoning to furnish missing details from under-specified goals (as is often the case in natural language). However, our experiments also reveal that LLMs can fail to generate goals in tasks that involve numerical or physical (e.g., spatial) reasoning, and that LLMs are sensitive to the prompts used. As such, these models are promising for translation to structured planning languages, but care should be taken in their use. ","[{'version': 'v1', 'created': 'Fri, 10 Feb 2023 09:17:52 GMT'}]",2023-02-13,"[['Xie', 'Yaqi', ''], ['Yu', 'Chen', ''], ['Zhu', 'Tongyao', ''], ['Bai', 'Jinbin', ''], ['Gong', 'Ze', ''], ['Soh', 'Harold', '']]",0,1,2023-02-10,1,6,3,1,0,1,3ad346ae7af5c30964c4916dbcee798f72e1bdb7,256808659.0,https://www.semanticscholar.org/paper/3ad346ae7af5c30964c4916dbcee798f72e1bdb7,arXiv.org,2023.0,39.0,39.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '14629277', 'name': 'Yaqi Xie'}, {'authorId': '46756325', 'name': 'Chenyao Yu'}, {'authorId': '2106773698', 'name': 'Tongyao Zhu'}, {'authorId': '2162829939', 'name': 'Jinbin Bai'}, {'authorId': '39940468', 'name': 'Ze Gong'}, {'authorId': '5489509', 'name': 'Harold Soh'}]","['National University of Singapore', 'Dept. of Computer Science, School of Computing']",['Singapore'],2023-02
2302.05319,Jingxuan He,Jingxuan He and Martin Vechev,Large Language Models for Code: Security Hardening and Adversarial Testing,Accepted to ACM CCS 2023,,10.1145/3576915.3623175,,cs.CR cs.LG cs.PL cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Large language models (large LMs) are increasingly trained on massive codebases and used to generate code. However, LMs lack awareness of security and are found to frequently produce unsafe code. This work studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs' reliability in generating secure code, and (ii) adversarial testing, which seeks to evaluate LMs' security at an adversarial standpoint. We address both of these by formulating a new security task called controlled code generation. The task is parametric and takes as input a binary property to guide the LM to generate secure or unsafe code, while preserving the LM's capability of generating functionally correct code. We propose a novel learning-based approach called SVEN to solve this task. SVEN leverages property-specific continuous vectors to guide program generation towards the given property, without modifying the LM's weights. Our training procedure optimizes these continuous vectors by enforcing specialized loss terms on different regions of code, using a high-quality dataset carefully curated by us. Our extensive evaluation shows that SVEN is highly effective in achieving strong security control. For instance, a state-of-the-art CodeGen LM with 2.7B parameters generates secure code for 59.1% of the time. When we employ SVEN to perform security hardening (or adversarial testing) on this LM, the ratio is significantly boosted to 92.3% (or degraded to 36.8%). Importantly, SVEN closely matches the original LMs in functional correctness. ","[{'version': 'v1', 'created': 'Fri, 10 Feb 2023 15:28:55 GMT'}, {'version': 'v2', 'created': 'Fri, 5 May 2023 19:08:15 GMT'}, {'version': 'v3', 'created': 'Tue, 12 Sep 2023 11:46:55 GMT'}, {'version': 'v4', 'created': 'Fri, 29 Sep 2023 13:53:43 GMT'}]",2023-10-02,"[['He', 'Jingxuan', ''], ['Vechev', 'Martin', '']]",0,0,2023-02-10,4,2,4,1,1,0,63e2740dc581b4186b4e277a9955e8048c414521,258557402.0,https://www.semanticscholar.org/paper/63e2740dc581b4186b4e277a9955e8048c414521,,2023.0,72.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8516542', 'name': 'Jingxuan He'}, {'authorId': '1736447', 'name': 'Martin T. Vechev'}]",['ETH Zurich'],['Switzerland'],2023-02
2302.05729,Ha Thanh Nguyen,Ha-Thanh Nguyen,A Brief Report on LawGPT 1.0: A Virtual Legal Assistant Based on GPT-3,,,,,cs.CL cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  LawGPT 1.0 is a virtual legal assistant built on the state-of-the-art language model GPT-3, fine-tuned for the legal domain. The system is designed to provide legal assistance to users in a conversational manner, helping them with tasks such as answering legal questions, generating legal documents, and providing legal advice. In this paper, we provide a brief overview of LawGPT 1.0, its architecture, and its performance on a set of legal benchmark tasks. Please note that the detailed information about the model is protected by a non-disclosure agreement (NDA) and cannot be disclosed in this report. ","[{'version': 'v1', 'created': 'Sat, 11 Feb 2023 15:50:20 GMT'}, {'version': 'v2', 'created': 'Tue, 14 Feb 2023 06:26:42 GMT'}]",2023-02-15,"[['Nguyen', 'Ha-Thanh', '']]",0,1,2023-02-11,2,1,2,1,0,1,41b360c5b4ae9c5bfcf3891c45319a9e0b3e6d81,256827839.0,https://www.semanticscholar.org/paper/41b360c5b4ae9c5bfcf3891c45319a9e0b3e6d81,arXiv.org,2023.0,1.0,13.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Law', 'source': 's2-fos-model'}]","[{'authorId': '2716209', 'name': 'Nguyen Ha Thanh'}]",['National Institute of Informatics'],['Japan'],2023-02
2302.05981,Sebastian Risi,"Shyam Sudhakaran, Miguel Gonz\'alez-Duque, Claire Glanois, Matthias
  Freiberger, Elias Najarro, Sebastian Risi",MarioGPT: Open-Ended Text2Level Generation through Large Language Models,,,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Procedural Content Generation (PCG) algorithms provide a technique to generate complex and diverse environments in an automated way. However, while generating content with PCG methods is often straightforward, generating meaningful content that reflects specific intentions and constraints remains challenging. Furthermore, many PCG algorithms lack the ability to generate content in an open-ended manner. Recently, Large Language Models (LLMs) have shown to be incredibly effective in many diverse domains. These trained LLMs can be fine-tuned, re-using information and accelerating training for new tasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to generate tile-based game levels, in our case Super Mario Bros levels. We show that MarioGPT can not only generate diverse levels, but can be text-prompted for controllable level generation, addressing one of the key challenges of current PCG techniques. As far as we know, MarioGPT is the first text-to-level model. We also combine MarioGPT with novelty search, enabling it to generate diverse levels with varying play-style dynamics (i.e. player paths). This combination allows for the open-ended generation of an increasingly diverse range of content. ","[{'version': 'v1', 'created': 'Sun, 12 Feb 2023 19:12:24 GMT'}, {'version': 'v2', 'created': 'Fri, 16 Jun 2023 21:06:28 GMT'}]",2023-06-26,"[['Sudhakaran', 'Shyam', ''], ['González-Duque', 'Miguel', ''], ['Glanois', 'Claire', ''], ['Freiberger', 'Matthias', ''], ['Najarro', 'Elias', ''], ['Risi', 'Sebastian', '']]",0,1,2023-02-12,2,6,3,1,1,0,bbe197158adb4b6e85a6eeab4619ea0fc6857941,256827347.0,https://www.semanticscholar.org/paper/bbe197158adb4b6e85a6eeab4619ea0fc6857941,arXiv.org,2023.0,52.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '52176695', 'name': 'Shyam Sudhakaran'}, {'authorId': '2110726887', 'name': ""Miguel Gonz'alez-Duque""}, {'authorId': '102608836', 'name': 'Claire Glanois'}, {'authorId': '34810150', 'name': 'Matthias Freiberger'}, {'authorId': '1796268807', 'name': 'Elias Najarro'}, {'authorId': '1745664', 'name': 'S. Risi'}]",['University of Copenhagen'],['Denmark'],2023-02
2302.06466,Essam Mansour,"Reham Omar, Omij Mangukiya, Panos Kalnis and Essam Mansour",ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots,9 pages,,,,cs.CL cs.AI cs.IR,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Conversational AI and Question-Answering systems (QASs) for knowledge graphs (KGs) are both emerging research areas: they empower users with natural language interfaces for extracting information easily and effectively. Conversational AI simulates conversations with humans; however, it is limited by the data captured in the training datasets. In contrast, QASs retrieve the most recent information from a KG by understanding and translating the natural language question into a formal query supported by the database engine.   In this paper, we present a comprehensive study of the characteristics of the existing alternatives towards combining both worlds into novel KG chatbots. Our framework compares two representative conversational models, ChatGPT and Galactica, against KGQAN, the current state-of-the-art QAS. We conduct a thorough evaluation using four real KGs across various application domains to identify the current limitations of each category of systems. Based on our findings, we propose open research opportunities to empower QASs with chatbot capabilities for KGs. All benchmarks and all raw results are available1 for further analysis. ","[{'version': 'v1', 'created': 'Wed, 8 Feb 2023 13:03:27 GMT'}]",2023-02-14,"[['Omar', 'Reham', ''], ['Mangukiya', 'Omij', ''], ['Kalnis', 'Panos', ''], ['Mansour', 'Essam', '']]",1,1,2023-02-08,1,4,3,1,0,1,38885fc6a8067147b6492e4573ae292427364d88,256827301.0,https://www.semanticscholar.org/paper/38885fc6a8067147b6492e4573ae292427364d88,arXiv.org,2023.0,30.0,47.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2059474647', 'name': 'Reham Omar'}, {'authorId': '2205550971', 'name': 'Omij Mangukiya'}, {'authorId': '2000187', 'name': 'Panos Kalnis'}, {'authorId': '1801187', 'name': 'Essam Mansour'}]","['Concordia University', 'King Abdullah University of Science and Technology']","['Canada', 'Saudi Arabia']",2023-02
2302.06474,Teo Susnjak,Teo Susnjak,Applying BERT and ChatGPT for Sentiment Analysis of Lyme Disease in Scientific Literature,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This chapter presents a practical guide for conducting Sentiment Analysis using Natural Language Processing (NLP) techniques in the domain of tick-borne disease text. The aim is to demonstrate the process of how the presence of bias in the discourse surrounding chronic manifestations of the disease can be evaluated. The goal is to use a dataset of 5643 abstracts collected from scientific journals on the topic of chronic Lyme disease to demonstrate using Python, the steps for conducting sentiment analysis using pre-trained language models and the process of validating the preliminary results using both interpretable machine learning tools, as well as a novel methodology of using emerging state-of-the-art large language models like ChatGPT. This serves as a useful resource for researchers and practitioners interested in using NLP techniques for sentiment analysis in the medical domain. ","[{'version': 'v1', 'created': 'Tue, 7 Feb 2023 01:15:05 GMT'}]",2023-02-14,"[['Susnjak', 'Teo', '']]",1,1,2023-02-07,1,1,1,1,0,1,09d51a7367fc7fbce643ae5f70c9959ed723009e,256827671.0,https://www.semanticscholar.org/paper/09d51a7367fc7fbce643ae5f70c9959ed723009e,arXiv.org,2023.0,9.0,18.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2656889', 'name': 'Teo Susnjak'}]","['Senior Lecturer in Computer Science and IT,', 'Massey University']",['New Zealand'],2023-02
2302.06541,Maximilian Mozes,"Maximilian Mozes, Jessica Hoffmann, Katrin Tomanek, Muhamed Kouate,
  Nithum Thain, Ann Yuan, Tolga Bolukbasi, Lucas Dixon",Towards Agile Text Classifiers for Everyone,Pre-print,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Text-based safety classifiers are widely used for content moderation and increasingly to tune generative language model behavior - a topic of growing concern for the safety of digital assistants and chatbots. However, different policies require different classifiers, and safety policies themselves improve from iteration and adaptation. This paper introduces and evaluates methods for agile text classification, whereby classifiers are trained using small, targeted datasets that can be quickly developed for a particular policy. Experimenting with 7 datasets from three safety-related domains, comprising 15 annotation schemes, led to our key finding: prompt-tuning large language models, like PaLM 62B, with a labeled dataset of as few as 80 examples can achieve state-of-the-art performance. We argue that this enables a paradigm shift for text classification, especially for models supporting safer online discourse. Instead of collecting millions of examples to attempt to create universal safety classifiers over months or years, classifiers could be tuned using small datasets, created by individuals or small organizations, tailored for specific use cases, and iterated on and adapted in the time-span of a day. ","[{'version': 'v1', 'created': 'Mon, 13 Feb 2023 17:34:13 GMT'}]",2023-02-14,"[['Mozes', 'Maximilian', ''], ['Hoffmann', 'Jessica', ''], ['Tomanek', 'Katrin', ''], ['Kouate', 'Muhamed', ''], ['Thain', 'Nithum', ''], ['Yuan', 'Ann', ''], ['Bolukbasi', 'Tolga', ''], ['Dixon', 'Lucas', '']]",0,0,2023-02-13,1,8,1,1,0,1,335303a513e376b120212337c154cb91fa3689db,256826853.0,https://www.semanticscholar.org/paper/335303a513e376b120212337c154cb91fa3689db,arXiv.org,2023.0,46.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '37237998', 'name': 'Maximilian Mozes'}, {'authorId': '145742133', 'name': 'Jessica Hoffmann'}, {'authorId': '3357473', 'name': 'K. Tomanek'}, {'authorId': '2205543326', 'name': 'Muhamed Kouate'}, {'authorId': '2665391', 'name': 'Nithum Thain'}, {'authorId': '2061016887', 'name': 'Ann Yuan'}, {'authorId': '2843215', 'name': 'Tolga Bolukbasi'}, {'authorId': '2065639113', 'name': 'Lucas Dixon'}]",['University College London'],['United Kingdom'],2023-02
2302.06555,Jiaang Li,"Jiaang Li, Yova Kementchedjhieva, Anders S{\o}gaard",Implications of the Convergence of Language and Vision Model Geometries,work in progress,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large-scale pretrained language models (LMs) are said to ``lack the ability to connect [their] utterances to the world'' (Bender and Koller, 2020). If so, we would expect LM representations to be unrelated to representations in computer vision models. To investigate this, we present an empirical evaluation across three different LMs (BERT, GPT2, and OPT) and three computer vision models (VMs, including ResNet, SegFormer, and MAE). Our experiments show that LMs converge towards representations that are partially isomorphic to those of VMs, with dispersion, and polysemy both factoring into the alignability of vision and language spaces. We discuss the implications of this finding. ","[{'version': 'v1', 'created': 'Mon, 13 Feb 2023 17:55:54 GMT'}]",2023-02-14,"[['Li', 'Jiaang', ''], ['Kementchedjhieva', 'Yova', ''], ['Søgaard', 'Anders', '']]",0,1,2023-02-13,1,3,1,2,2,0,2fb0cefa8a31a64345ab3d70db0a962151077380,256827643.0,https://www.semanticscholar.org/paper/2fb0cefa8a31a64345ab3d70db0a962151077380,arXiv.org,2023.0,50.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2261336713', 'name': 'Jiaang Li'}, {'authorId': '51208524', 'name': 'Yova Kementchedjhieva'}, {'authorId': '1700187', 'name': 'Anders Søgaard'}]",['University of Copenhagen'],['Denmark'],2023-02
2302.06598,Maximilian Mozes,"Maximilian Mozes, Tolga Bolukbasi, Ann Yuan, Frederick Liu, Nithum
  Thain, Lucas Dixon",Gradient-Based Automated Iterative Recovery for Parameter-Efficient Tuning,Pre-print,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Pretrained large language models (LLMs) are able to solve a wide variety of tasks through transfer learning. Various explainability methods have been developed to investigate their decision making process. TracIn (Pruthi et al., 2020) is one such gradient-based method which explains model inferences based on the influence of training examples. In this paper, we explore the use of TracIn to improve model performance in the parameter-efficient tuning (PET) setting. We develop conversational safety classifiers via the prompt-tuning PET method and show how the unique characteristics of the PET regime enable TracIn to identify the cause for certain misclassifications by LLMs. We develop a new methodology for using gradient-based explainability techniques to improve model performance, G-BAIR: gradient-based automated iterative recovery. We show that G-BAIR can recover LLM performance on benchmarks after manually corrupting training labels. This suggests that influence methods like TracIn can be used to automatically perform data cleaning, and introduces the potential for interactive debugging and relabeling for PET-based transfer learning methods. ","[{'version': 'v1', 'created': 'Mon, 13 Feb 2023 18:54:58 GMT'}]",2023-02-14,"[['Mozes', 'Maximilian', ''], ['Bolukbasi', 'Tolga', ''], ['Yuan', 'Ann', ''], ['Liu', 'Frederick', ''], ['Thain', 'Nithum', ''], ['Dixon', 'Lucas', '']]",0,0,2023-02-13,1,6,1,0,0,0,4805470c7e5abf36781bf89f6fe8743c7344ab90,256827405.0,https://www.semanticscholar.org/paper/4805470c7e5abf36781bf89f6fe8743c7344ab90,arXiv.org,2023.0,38.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '37237998', 'name': 'Maximilian Mozes'}, {'authorId': '2843215', 'name': 'Tolga Bolukbasi'}, {'authorId': '2061016887', 'name': 'Ann Yuan'}, {'authorId': '2155134', 'name': 'Frederick Liu'}, {'authorId': '2665391', 'name': 'Nithum Thain'}, {'authorId': '2065639113', 'name': 'Lucas Dixon'}]",['University College London'],['United Kingdom'],2023-02
2302.07136,Subaveerapandiyan A,"Subaveerapandiyan A, Vinoth A, Neelam Tiwary","Netizens, Academicians, and Information Professionals' Opinions About AI With Special Reference To ChatGPT",,,,,cs.CY cs.CV cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This study aims to understand the perceptions and opinions of academicians towards ChatGPT-3 by collecting and analyzing social media comments, and a survey was conducted with library and information science professionals. The research uses a content analysis method and finds that while ChatGPT-3 can be a valuable tool for research and writing, it is not 100% accurate and should be cross-checked. The study also finds that while some academicians may not accept ChatGPT-3, most are starting to accept it. The study is beneficial for academicians, content developers, and librarians. ","[{'version': 'v1', 'created': 'Wed, 1 Feb 2023 10:59:04 GMT'}]",2023-02-15,"[['A', 'Subaveerapandiyan', ''], ['A', 'Vinoth', ''], ['Tiwary', 'Neelam', '']]",1,1,2023-02-01,1,3,3,1,0,1,a900e9c354d2a5cdbd7cc5532017c5a0e18bc594,256846476.0,https://www.semanticscholar.org/paper/a900e9c354d2a5cdbd7cc5532017c5a0e18bc594,arXiv.org,2023.0,15.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2173322263', 'name': 'A. Subaveerapandiyan'}, {'authorId': '46839384', 'name': 'A. Vinoth'}, {'authorId': '2205657660', 'name': 'Neelam Tiwary'}]","['Yenepoya University', 'National Institute of Technology Karnataka', 'DMI St. Eugene University']","['India', 'Zambia']",2023-02
2302.07406,A. Baki Kocaballi,A. Baki Kocaballi,"Conversational AI-Powered Design: ChatGPT as Designer, User, and Product",,,,,cs.HC cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The recent advancements in Large Language Models (LLMs), particularly conversational LLMs like ChatGPT, have prompted changes in a range of fields, including design. This study aims to examine the capabilities of ChatGPT in a human-centered design process. To this end, a hypothetical design project was conducted, where ChatGPT was utilized to generate personas, simulate interviews with fictional users, create new design ideas, simulate usage scenarios and conversations between an imaginary prototype and fictional users, and lastly evaluate user experience. The results show that ChatGPT effectively performed the tasks assigned to it as a designer, user, or product, providing mostly appropriate responses. The study does, however, highlight some drawbacks such as forgotten information, partial responses, and a lack of output diversity. The paper explains the potential benefits and limitations of using conversational LLMs in design, discusses its implications, and suggests directions for future research in this rapidly evolving area. ","[{'version': 'v1', 'created': 'Wed, 15 Feb 2023 00:14:17 GMT'}]",2023-02-16,"[['Kocaballi', 'A. Baki', '']]",1,1,2023-02-15,1,1,2,1,0,1,a722d6502956b38dfa5e4f514374ebac8cf38113,256868430.0,https://www.semanticscholar.org/paper/a722d6502956b38dfa5e4f514374ebac8cf38113,arXiv.org,2023.0,37.0,10.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51374066', 'name': 'A. B. Kocaballi'}]",['University of Technology Sydney'],['Australia'],2023-02
2302.07427,Majeed Kazemitabaar,"Majeed Kazemitabaar, Justin Chow, Carl Ka To Ma, Barbara J. Ericson,
  David Weintrop, Tovi Grossman",Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming,"To be published in Proceedings of the 2023 CHI Conference on Human
  Factors in Computing Systems (CHI '23), April 23--28, 2023, Hamburg, Germany
  17 pages with 11 Figures, 2 Tables, 6 Page Appendix",,10.1145/3544548.3580919,,cs.HC,http://creativecommons.org/licenses/by/4.0/,"  AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex. ","[{'version': 'v1', 'created': 'Wed, 15 Feb 2023 02:17:39 GMT'}, {'version': 'v2', 'created': 'Tue, 21 Feb 2023 17:00:20 GMT'}]",2023-02-22,"[['Kazemitabaar', 'Majeed', ''], ['Chow', 'Justin', ''], ['Ma', 'Carl Ka To', ''], ['Ericson', 'Barbara J.', ''], ['Weintrop', 'David', ''], ['Grossman', 'Tovi', '']]",0,0,2023-02-15,2,6,1,1,0,1,f03f39f735186c4359b719724be6e1c2eb912fef,256868626.0,https://www.semanticscholar.org/paper/f03f39f735186c4359b719724be6e1c2eb912fef,International Conference on Human Factors in Computing Systems,2023.0,98.0,39.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3136345', 'name': 'Majeed Kazemitabaar'}, {'authorId': '2047481064', 'name': 'J. Chow'}, {'authorId': '2206462704', 'name': 'Carl Ka To Ma'}, {'authorId': '20937525', 'name': 'B. Ericson'}, {'authorId': '2862077', 'name': 'David Weintrop'}, {'authorId': '2666589', 'name': 'Tovi Grossman'}]",['University of Toronto'],['Canada'],2023-02
2302.07731,Qiwei Han,"Alessandro Gambetti, Qiwei Han",Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media,"Preprint version of the Paper submitted to KDD2023. 13 pages, 5
  figures, 6 tables",,,,cs.CL cs.AI cs.IR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Recent advances in generative models such as GPT may be used to fabricate indistinguishable fake customer reviews at a much lower cost, thus posing challenges for social media platforms to detect these machine-generated fake reviews. We propose to leverage the high-quality elite restaurant reviews verified by Yelp to generate fake reviews from the OpenAI GPT review creator and ultimately fine-tune a GPT output detector to predict fake reviews that significantly outperform existing solutions. We further apply the model to predict non-elite reviews and identify the patterns across several dimensions, such as review, user and restaurant characteristics, and writing style. We show that social media platforms are continuously challenged by machine-generated fake reviews, although they may implement detection systems to filter out suspicious reviews. ","[{'version': 'v1', 'created': 'Fri, 10 Feb 2023 19:40:10 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Apr 2023 18:14:59 GMT'}, {'version': 'v3', 'created': 'Fri, 21 Apr 2023 16:40:55 GMT'}]",2023-04-24,"[['Gambetti', 'Alessandro', ''], ['Han', 'Qiwei', '']]",0,1,2023-02-10,3,2,4,0,0,0,f55d583fd42bacbe9a907a02632485c86b16338a,256868756.0,https://www.semanticscholar.org/paper/f55d583fd42bacbe9a907a02632485c86b16338a,arXiv.org,2023.0,106.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40023024', 'name': 'Alessandro Gambetti'}, {'authorId': '47837759', 'name': 'Qiwei Han'}]","['Nova School of Business and Economics Carcavelos, Portugal']",['Portugal'],2023-02
2302.07735,Ali Al-Kaswan,"Ali Al-Kaswan, Maliheh Izadi, Arie van Deursen",Targeted Attack on GPT-Neo for the SATML Language Model Data Extraction Challenge,,,,,cs.CL cs.AI cs.CR,http://creativecommons.org/licenses/by-sa/4.0/,"  Previous work has shown that Large Language Models are susceptible to so-called data extraction attacks. This allows an attacker to extract a sample that was contained in the training data, which has massive privacy implications. The construction of data extraction attacks is challenging, current attacks are quite inefficient, and there exists a significant gap in the extraction capabilities of untargeted attacks and memorization. Thus, targeted attacks are proposed, which identify if a given sample from the training data, is extractable from a model. In this work, we apply a targeted data extraction attack to the SATML2023 Language Model Training Data Extraction Challenge. We apply a two-step approach. In the first step, we maximise the recall of the model and are able to extract the suffix for 69% of the samples. In the second step, we use a classifier-based Membership Inference Attack on the generations. Our AutoSklearn classifier achieves a precision of 0.841. The full approach reaches a score of 0.405 recall at a 10% false positive rate, which is an improvement of 34% over the baseline of 0.301. ","[{'version': 'v1', 'created': 'Mon, 13 Feb 2023 18:00:44 GMT'}]",2023-02-16,"[['Al-Kaswan', 'Ali', ''], ['Izadi', 'Maliheh', ''], ['van Deursen', 'Arie', '']]",0,1,2023-02-13,1,3,3,0,0,0,ef2e105835fe555300e67fe9f8389bf869adfe88,256868842.0,https://www.semanticscholar.org/paper/ef2e105835fe555300e67fe9f8389bf869adfe88,arXiv.org,2023.0,12.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '2199249915', 'name': 'Ali Al-Kaswan'}, {'authorId': '145774460', 'name': 'M. Izadi'}, {'authorId': '1737202', 'name': 'A. Deursen'}]",['Delft University of Technology'],['Netherlands'],2023-02
2302.09049,{\L}ukasz D\k{e}bowski,{\L}ukasz D\k{e}bowski,A Simplistic Model of Neural Scaling Laws: Multiperiodic Santa Fe Processes,27 pages; 1 figure,,,,cs.IT cs.LG math.IT math.ST stat.TH,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It was observed that large language models exhibit a power-law decay of cross entropy with respect to the number of parameters and training tokens. When extrapolated literally, this decay implies that the entropy rate of natural language is zero. To understand this phenomenon -- or an artifact -- better, we construct a simple stationary stochastic process and its memory-based predictor that exhibit a power-law decay of cross entropy with the vanishing entropy rate. Our example is based on previously discussed Santa Fe processes, which decompose a random text into a process of narration and time-independent knowledge. Previous discussions assumed that narration is a memoryless source with Zipf's distribution. In this paper, we propose a model of narration that has the vanishing entropy rate and applies a randomly chosen deterministic sequence called a multiperiodic sequence. Under a suitable parameterization, multiperiodic sequences exhibit asymptotic relative frequencies given by Zipf's law. Remaining agnostic about the value of the entropy rate of natural language, we discuss relevance of similar constructions for language modeling. ","[{'version': 'v1', 'created': 'Fri, 17 Feb 2023 18:27:27 GMT'}]",2023-02-20,"[['Dębowski', 'Łukasz', '']]",0,0,2023-02-17,1,1,5,0,0,0,9d877509f3fb8fbbf3e3d54eeef3c84bc0e1e3b2,257019655.0,https://www.semanticscholar.org/paper/9d877509f3fb8fbbf3e3d54eeef3c84bc0e1e3b2,arXiv.org,2023.0,56.0,4.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2149603', 'name': 'L. Debowski'}]",['Polish Academy of Sciences'],['Poland'],2023-02
2302.09051,Xavier Daull,"Xavier Daull, Patrice Bellot, Emmanuel Bruno, Vincent Martin,
  Elisabeth Murisasco","Complex QA and language models hybrid architectures, Survey",,,,,cs.CL cs.AI cs.IR cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper reviews the state-of-the-art of language models architectures and strategies for ""complex"" question-answering (QA, CQA, CPS) with a focus on hybridization. Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems (e.g. How does the concept of personal freedom vary between different cultures ? What is the best mix of power generation methods to reduce climate change ?) you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of LLM in complex QA. In this paper, we start by reviewing required skills and evaluation techniques. We integrate findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and analyze limits and challenges of LLM in terms of tasks complexity and strict evaluation on accuracy (e.g. fairness, robustness, toxicity, ...) as a baseline. We discuss some challenges associated with complex QA, including domain adaptation, decomposition and efficient multi-step QA, long form and non-factoid QA, safety and multi-sensitivity data protection, multimodal search, hallucinations, explainability and truthfulness, temporal reasoning. We analyze current solutions and promising research trends, using elements such as: hybrid LLM architectural patterns, training and prompting strategies, active human reinforcement learning supervised with AI, neuro-symbolic and structured knowledge grounding, program synthesis, iterated decomposition and others. ","[{'version': 'v1', 'created': 'Fri, 17 Feb 2023 18:31:31 GMT'}, {'version': 'v2', 'created': 'Mon, 6 Mar 2023 21:46:08 GMT'}, {'version': 'v3', 'created': 'Thu, 9 Mar 2023 17:25:10 GMT'}, {'version': 'v4', 'created': 'Fri, 7 Apr 2023 16:37:35 GMT'}]",2023-04-10,"[['Daull', 'Xavier', ''], ['Bellot', 'Patrice', ''], ['Bruno', 'Emmanuel', ''], ['Martin', 'Vincent', ''], ['Murisasco', 'Elisabeth', '']]",1,1,2023-02-17,4,5,4,2,1,1,681cee58cf7e54199191cf9e0baf6851d8356704,257019916.0,https://www.semanticscholar.org/paper/681cee58cf7e54199191cf9e0baf6851d8356704,,2023.0,390.0,6.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2207712664', 'name': 'Xavier Daull'}, {'authorId': '1794810', 'name': 'P. Bellot'}, {'authorId': '24239598', 'name': 'Emmanuel Bruno'}, {'authorId': '2052553796', 'name': 'Vincent Martin'}, {'authorId': '2542690', 'name': 'Elisabeth Murisasco'}]","['French National Centre for Scientific Research', 'Laboratoire d’Informatique et Systèmes', 'Naval Group (France)', 'Aix-Marseille University']",['France'],2023-02
2302.09664,Lorenz Kuhn,"Lorenz Kuhn, Yarin Gal, Sebastian Farquhar",Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation,International Conference on Learning Representations 2023 (Spotlight),,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of ""semantic equivalence"" -- different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy -- an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines. ","[{'version': 'v1', 'created': 'Sun, 19 Feb 2023 20:10:07 GMT'}, {'version': 'v2', 'created': 'Tue, 21 Feb 2023 16:30:15 GMT'}, {'version': 'v3', 'created': 'Sat, 15 Apr 2023 12:55:45 GMT'}]",2023-04-18,"[['Kuhn', 'Lorenz', ''], ['Gal', 'Yarin', ''], ['Farquhar', 'Sebastian', '']]",0,0,2023-02-19,3,3,3,0,0,0,507465f8d46489a68a527cb5304d76bdb6c31ed9,257039062.0,https://www.semanticscholar.org/paper/507465f8d46489a68a527cb5304d76bdb6c31ed9,International Conference on Learning Representations,2023.0,47.0,51.0,11.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '39879848', 'name': 'Lorenz Kuhn'}, {'authorId': '2681954', 'name': 'Y. Gal'}, {'authorId': '33859827', 'name': 'Sebastian Farquhar'}]",['University of Oxford'],['United Kingdom'],2023-02
2302.10724,Jan Koco\'n,"Jan Koco\'n, Igor Cichecki, Oliwier Kaszyca, Mateusz Kochanek,
  Dominika Szyd{\l}o, Joanna Baran, Julita Bielaniewicz, Marcin Gruza,
  Arkadiusz Janz, Kamil Kanclerz, Anna Koco\'n, Bart{\l}omiej Koptyra, Wiktoria
  Mieleszczenko-Kowszewicz, Piotr Mi{\l}kowski, Marcin Oleksy, Maciej Piasecki,
  {\L}ukasz Radli\'nski, Konrad Wojtasik, Stanis{\l}aw Wo\'zniak, Przemys{\l}aw
  Kazienko","ChatGPT: Jack of all trades, master of none",preprint,Information Fusion 101861 (2023),10.1016/j.inffus.2023.101861,,cs.CL cs.AI cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quality of the ChatGPT model was about 25% for zero-shot and few-shot evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower than for ChatGPT. We showed that the more difficult the task (lower SOTA performance), the higher the ChatGPT loss. It especially refers to pragmatic NLP problems like emotion recognition. We also tested the ability to personalize ChatGPT responses for selected subjective tasks via Random Contextual Few-Shot Personalization, and we obtained significantly better user-based predictions. Additional qualitative analysis revealed a ChatGPT bias, most likely due to the rules imposed on human trainers by OpenAI. Our results provide the basis for a fundamental discussion of whether the high quality of recent predictive NLP models can indicate a tool's usefulness to society and how the learning and validation procedures for such systems should be established. ","[{'version': 'v1', 'created': 'Tue, 21 Feb 2023 15:20:37 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 13:33:05 GMT'}, {'version': 'v3', 'created': 'Fri, 2 Jun 2023 12:20:04 GMT'}, {'version': 'v4', 'created': 'Fri, 9 Jun 2023 19:52:34 GMT'}]",2023-06-13,"[['Kocoń', 'Jan', ''], ['Cichecki', 'Igor', ''], ['Kaszyca', 'Oliwier', ''], ['Kochanek', 'Mateusz', ''], ['Szydło', 'Dominika', ''], ['Baran', 'Joanna', ''], ['Bielaniewicz', 'Julita', ''], ['Gruza', 'Marcin', ''], ['Janz', 'Arkadiusz', ''], ['Kanclerz', 'Kamil', ''], ['Kocoń', 'Anna', ''], ['Koptyra', 'Bartłomiej', ''], ['Mieleszczenko-Kowszewicz', 'Wiktoria', ''], ['Miłkowski', 'Piotr', ''], ['Oleksy', 'Marcin', ''], ['Piasecki', 'Maciej', ''], ['Radliński', 'Łukasz', ''], ['Wojtasik', 'Konrad', ''], ['Woźniak', 'Stanisław', ''], ['Kazienko', 'Przemysław', '']]",1,1,2023-02-21,4,20,4,2,0,2,5848737f78397f72ceae2ba6f3419a6a8502b8ba,257050407.0,https://www.semanticscholar.org/paper/5848737f78397f72ceae2ba6f3419a6a8502b8ba,Information Fusion,2023.0,124.0,104.0,8.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2169553526', 'name': ""Jan Koco'n""}, {'authorId': '2208975380', 'name': 'Igor Cichecki'}, {'authorId': '2208975873', 'name': 'Oliwier Kaszyca'}, {'authorId': '2208973923', 'name': 'Mateusz Kochanek'}, {'authorId': '2208973921', 'name': 'Dominika Szydlo'}, {'authorId': '2173806580', 'name': 'Joanna Baran'}, {'authorId': '2151200612', 'name': 'Julita Bielaniewicz'}, {'authorId': '2120757466', 'name': 'Marcin Gruza'}, {'authorId': '32559047', 'name': 'Arkadiusz Janz'}, {'authorId': '2007286374', 'name': 'Kamil Kanclerz'}, {'authorId': '2208972610', 'name': ""Anna Koco'n""}, {'authorId': '2208962106', 'name': 'Bartlomiej Koptyra'}, {'authorId': '1422481396', 'name': 'W. Mieleszczenko-Kowszewicz'}, {'authorId': '1413772109', 'name': 'P. Milkowski'}, {'authorId': '145050858', 'name': 'Marcin Oleksy'}, {'authorId': '144205338', 'name': 'Maciej Piasecki'}, {'authorId': '2208962428', 'name': ""Lukasz Radli'nski""}, {'authorId': '9583418', 'name': 'Konrad Wojtasik'}, {'authorId': '2208975638', 'name': ""Stanislaw Wo'zniak""}, {'authorId': '1724788', 'name': 'Przemyslaw Kazienko'}]",['Wrocław University of Science and Technology'],['Poland'],2023-02
2302.11752,Nghia Hieu Nguyen,"Ngan Luu-Thuy Nguyen, Nghia Hieu Nguyen, Duong T.D Vo, Khanh Quoc
  Tran, Kiet Van Nguyen",VLSP2022-EVJVQA Challenge: Multilingual Visual Question Answering,VLSP2022 EVJVQA challenge,,10.15625/1813-9663/18157,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Visual Question Answering (VQA) is a challenging task of natural language processing (NLP) and computer vision (CV), attracting significant attention from researchers. English is a resource-rich language that has witnessed various developments in datasets and models for visual question answering. Visual question answering in other languages also would be developed for resources and models. In addition, there is no multilingual dataset targeting the visual content of a particular country with its own objects and cultural characteristics. To address the weakness, we provide the research community with a benchmark dataset named EVJVQA, including 33,000+ pairs of question-answer over three languages: Vietnamese, English, and Japanese, on approximately 5,000 images taken from Vietnam for evaluating multilingual VQA systems or models. EVJVQA is used as a benchmark dataset for the challenge of multilingual visual question answering at the 9th Workshop on Vietnamese Language and Speech Processing (VLSP 2022). This task attracted 62 participant teams from various universities and organizations. In this article, we present details of the organization of the challenge, an overview of the methods employed by shared-task participants, and the results. The highest performances are 0.4392 in F1-score and 0.4009 in BLUE on the private test set. The multilingual QA systems proposed by the top 2 teams use ViT for the pre-trained vision model and mT5 for the pre-trained language model, a powerful pre-trained language model based on the transformer architecture. EVJVQA is a challenging dataset that motivates NLP and CV researchers to further explore the multilingual models or systems for visual question answering systems. We released the challenge on the Codalab evaluation system for further research. ","[{'version': 'v1', 'created': 'Thu, 23 Feb 2023 02:38:39 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Feb 2023 02:02:07 GMT'}, {'version': 'v3', 'created': 'Tue, 28 Feb 2023 01:25:52 GMT'}, {'version': 'v4', 'created': 'Wed, 12 Apr 2023 00:44:29 GMT'}]",2023-10-03,"[['Nguyen', 'Ngan Luu-Thuy', ''], ['Nguyen', 'Nghia Hieu', ''], ['Vo', 'Duong T. D', ''], ['Tran', 'Khanh Quoc', ''], ['Van Nguyen', 'Kiet', '']]",0,0,2023-02-23,4,5,1,1,1,0,95f61ef45611d3af031d2a784a6261a552dc4322,257102387.0,https://www.semanticscholar.org/paper/95f61ef45611d3af031d2a784a6261a552dc4322,Journal of Computer Science and Cybernetics,2023.0,43.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2591380', 'name': 'N. Nguyen'}, {'authorId': '2185467742', 'name': 'N. Nguyen'}, {'authorId': '2190424992', 'name': 'Duong T.D. Vo'}, {'authorId': '143703082', 'name': 'K. Tran'}, {'authorId': '10346850', 'name': 'Kiet Van Nguyen'}]","['Vietnam National University Ho Chi Minh City', 'University of Information Technology']",['Vietnam'],2023-02
2302.12173,Sahar Abdelnabi,"Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres,
  Thorsten Holz, Mario Fritz",Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection,,,,,cs.CR cs.AI cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) are increasingly being integrated into various applications. The functionalities of recent LLMs can be flexibly modulated via natural language prompts. This renders them susceptible to targeted adversarial prompting, e.g., Prompt Injection (PI) attacks enable attackers to override original instructions and employed controls. So far, it was assumed that the user is directly prompting the LLM. But, what if it is not the user prompting? We argue that LLM-Integrated Applications blur the line between data and instructions. We reveal new attack vectors, using Indirect Prompt Injection, that enable adversaries to remotely (without a direct interface) exploit LLM-integrated applications by strategically injecting prompts into data likely to be retrieved. We derive a comprehensive taxonomy from a computer security perspective to systematically investigate impacts and vulnerabilities, including data theft, worming, information ecosystem contamination, and other novel security risks. We demonstrate our attacks' practical viability against both real-world systems, such as Bing's GPT-4 powered Chat and code-completion engines, and synthetic applications built on GPT-4. We show how processing retrieved prompts can act as arbitrary code execution, manipulate the application's functionality, and control how and if other APIs are called. Despite the increasing integration and reliance on LLMs, effective mitigations of these emerging threats are currently lacking. By raising awareness of these vulnerabilities and providing key insights into their implications, we aim to promote the safe and responsible deployment of these powerful models and the development of robust defenses that protect users and systems from potential attacks. ","[{'version': 'v1', 'created': 'Thu, 23 Feb 2023 17:14:38 GMT'}, {'version': 'v2', 'created': 'Fri, 5 May 2023 14:26:17 GMT'}]",2023-05-08,"[['Greshake', 'Kai', ''], ['Abdelnabi', 'Sahar', ''], ['Mishra', 'Shailesh', ''], ['Endres', 'Christoph', ''], ['Holz', 'Thorsten', ''], ['Fritz', 'Mario', '']]",0,1,2023-02-23,2,6,4,1,0,1,705e49afd92130f2bc1e0d4d0b1f6cb14e88803f,258546941.0,https://www.semanticscholar.org/paper/705e49afd92130f2bc1e0d4d0b1f6cb14e88803f,,2023.0,77.0,46.0,5.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2209385653', 'name': 'Kai Greshake'}, {'authorId': '1383113350', 'name': 'Sahar Abdelnabi'}, {'authorId': '2112134932', 'name': 'Shailesh Mishra'}, {'authorId': '93808977', 'name': 'C. Endres'}, {'authorId': '144227650', 'name': 'Thorsten Holz'}, {'authorId': '1739548', 'name': 'Mario Fritz'}]","['Helmholtz Center for Information Security', 'sequire technology GmbH', 'Saarland University']",['Germany'],2023-02
2302.12299,Benjamin Muller,"As{\i}m Ersoy, Gerson Vizcarra, Tasmiah Tahsin Mayeesha, Benjamin
  Muller",In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages,17 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Multilingual generative language models (LMs) are increasingly fluent in a large variety of languages. Trained on the concatenation of corpora in multiple languages, they enable powerful transfer from high-resource languages to low-resource ones. However, it is still unknown what cultural biases are induced in the predictions of these models. In this work, we focus on one language property highly influenced by culture: formality. We analyze the formality distributions of XGLM and BLOOM's predictions, two popular generative multilingual language models, in 5 languages. We classify 1,200 generations per language as formal, informal, or incohesive and measure the impact of the prompt formality on the predictions. Overall, we observe a diversity of behaviors across the models and languages. For instance, XGLM generates informal text in Arabic and Bengali when conditioned with informal prompts, much more than BLOOM. In addition, even though both models are highly biased toward the formal style when prompted neutrally, we find that the models generate a significant amount of informal predictions even when prompted with formal text. We release with this work 6,000 annotated samples, paving the way for future work on the formality of generative multilingual LMs. ","[{'version': 'v1', 'created': 'Thu, 23 Feb 2023 19:39:52 GMT'}]",2023-02-27,"[['Ersoy', 'Asım', ''], ['Vizcarra', 'Gerson', ''], ['Mayeesha', 'Tasmiah Tahsin', ''], ['Muller', 'Benjamin', '']]",0,0,2023-02-23,1,4,1,1,1,0,4b8ff5dce5cddce0f868d3ab50bcfe841ea1d725,257206130.0,https://www.semanticscholar.org/paper/4b8ff5dce5cddce0f868d3ab50bcfe841ea1d725,arXiv.org,2023.0,92.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2209878916', 'name': 'Asim Ersoy'}, {'authorId': '51430826', 'name': 'Gerson Vizcarra'}, {'authorId': '2112479281', 'name': 'T. Mayeesha'}, {'authorId': '150045488', 'name': 'Benjamin Muller'}]","['University of Nis', 'Banco de Crédito e Inversiones', 'Huawei Technologies (Turkey)', 'North South University']","['Serbia', 'Turkey', 'Bangladesh']",2023-02
2302.12367,Mian Zhong,"Mian Zhong, Shehzaad Dhuliawala, Niklas Stoehr",Extracting Victim Counts from Text,Long paper accepted at EACL 2023 main conference,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Decision-makers in the humanitarian sector rely on timely and exact information during crisis events. Knowing how many civilians were injured during an earthquake is vital to allocate aids properly. Information about such victim counts is often only available within full-text event descriptions from newspapers and other reports. Extracting numbers from text is challenging: numbers have different formats and may require numeric reasoning. This renders purely string matching-based approaches insufficient. As a consequence, fine-grained counts of injured, displaced, or abused victims beyond fatalities are often not extracted and remain unseen. We cast victim count extraction as a question answering (QA) task with a regression or classification objective. We compare regex, dependency parsing, semantic role labeling-based approaches, and advanced text-to-text models. Beyond model accuracy, we analyze extraction reliability and robustness which are key for this sensitive task. In particular, we discuss model calibration and investigate few-shot and out-of-distribution performance. Ultimately, we make a comprehensive recommendation on which model to select for different desiderata and data domains. Our work is among the first to apply numeracy-focused large language models in a real-world use case with a positive impact. ","[{'version': 'v1', 'created': 'Thu, 23 Feb 2023 23:50:24 GMT'}]",2023-02-27,"[['Zhong', 'Mian', ''], ['Dhuliawala', 'Shehzaad', ''], ['Stoehr', 'Niklas', '']]",0,0,2023-02-23,1,3,3,0,0,0,032962bfc563e2caf986d3b3746f3217303be1b0,257205955.0,https://www.semanticscholar.org/paper/032962bfc563e2caf986d3b3746f3217303be1b0,Conference of the European Chapter of the Association for Computational Linguistics,2023.0,67.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143562289', 'name': 'Mian Zhong'}, {'authorId': '3448411', 'name': 'S. Dhuliawala'}, {'authorId': '2121363803', 'name': 'Niklas Stoehr'}]",['ETH Zurich'],['Switzerland'],2023-02
2302.12834,Chen Cao,Chen Cao,Leveraging Large Language Model and Story-Based Gamification in Intelligent Tutoring System to Scaffold Introductory Programming Courses: A Design-Based Research Study,Doctoral consortium for IUI 2023,,,,cs.HC cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students learning needs and provides scaffolding to support their success in introductory computer programming courses. ","[{'version': 'v1', 'created': 'Sat, 25 Feb 2023 04:07:03 GMT'}]",2023-02-28,"[['Cao', 'Chen', '']]",0,0,2023-02-25,1,1,2,0,0,0,fb9d05e70ca4aace5229eb5b9de9f2f09dfc1fb0,257219587.0,https://www.semanticscholar.org/paper/fb9d05e70ca4aace5229eb5b9de9f2f09dfc1fb0,arXiv.org,2023.0,19.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48319840', 'name': 'Chen Cao'}]",['University of Sheffield'],['United Kingdom'],2023-02
2302.13681,Ali Al-Kaswan,Ali Al-Kaswan and Maliheh Izadi,The (ab)use of Open Source Code to Train Large Language Models,,,,,cs.SE cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In recent years, Large Language Models (LLMs) have gained significant popularity due to their ability to generate human-like text and their potential applications in various fields, such as Software Engineering. LLMs for Code are commonly trained on large unsanitized corpora of source code scraped from the Internet. The content of these datasets is memorized and emitted by the models, often in a verbatim manner. In this work, we will discuss the security, privacy, and licensing implications of memorization. We argue why the use of copyleft code to train LLMs is a legal and ethical dilemma. Finally, we provide four actionable recommendations to address this issue. ","[{'version': 'v1', 'created': 'Mon, 27 Feb 2023 11:34:53 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Feb 2023 10:47:48 GMT'}]",2023-03-01,"[['Al-Kaswan', 'Ali', ''], ['Izadi', 'Maliheh', '']]",0,0,2023-02-27,2,2,2,0,0,0,d51e2cc5332788b87ce8cf70c1131a72a8f78c50,257219963.0,https://www.semanticscholar.org/paper/d51e2cc5332788b87ce8cf70c1131a72a8f78c50,2023 IEEE/ACM 2nd International Workshop on Natural Language-Based Software Engineering (NLBSE),2023.0,5.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2199249915', 'name': 'Ali Al-Kaswan'}, {'authorId': '145774460', 'name': 'M. Izadi'}]",['Delft University of Technology'],['Netherlands'],2023-02
2302.13793,Guido Zuccon,"Guido Zuccon, Bevan Koopman","Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness",,,,,cs.CL cs.AI cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Generative pre-trained language models (GPLMs) like ChatGPT encode in the model's parameters knowledge the models observe during the pre-training phase. This knowledge is then used at inference to address the task specified by the user in their prompt. For example, for the question-answering task, the GPLMs leverage the knowledge and linguistic patterns learned at training to produce an answer to a user question. Aside from the knowledge encoded in the model itself, answers produced by GPLMs can also leverage knowledge provided in the prompts. For example, a GPLM can be integrated into a retrieve-then-generate paradigm where a search engine is used to retrieve documents relevant to the question; the content of the documents is then transferred to the GPLM via the prompt. In this paper we study the differences in answer correctness generated by ChatGPT when leveraging the model's knowledge alone vs. in combination with the prompt knowledge. We study this in the context of consumers seeking health advice from the model. Aside from measuring the effectiveness of ChatGPT in this context, we show that the knowledge passed in the prompt can overturn the knowledge encoded in the model and this is, in our experiments, to the detriment of answer correctness. This work has important implications for the development of more robust and transparent question-answering systems based on generative pre-trained language models. ","[{'version': 'v1', 'created': 'Thu, 23 Feb 2023 22:14:01 GMT'}]",2023-02-28,"[['Zuccon', 'Guido', ''], ['Koopman', 'Bevan', '']]",1,1,2023-02-23,1,2,3,1,0,1,5a91a012dc51db03d6eb3698d2e1c5b00115835f,257219583.0,https://www.semanticscholar.org/paper/5a91a012dc51db03d6eb3698d2e1c5b00115835f,arXiv.org,2023.0,15.0,20.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1692855', 'name': 'G. Zuccon'}, {'authorId': '1783566', 'name': 'B. Koopman'}]","['Brisbane, QLD, Australia', 'University of Queensland']",['Australia'],2023-02
2302.13795,Christoph Leiter,"Christoph Leiter, Ran Zhang, Yanran Chen, Jonas Belouadi, Daniil
  Larionov, Vivian Fresen and Steffen Eger",ChatGPT: A Meta-Analysis after 2.5 Months,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  ChatGPT, a chatbot developed by OpenAI, has gained widespread popularity and media attention since its release in November 2022. However, little hard evidence is available regarding its perception in various sources. In this paper, we analyze over 300,000 tweets and more than 150 scientific papers to investigate how ChatGPT is perceived and discussed. Our findings show that ChatGPT is generally viewed as of high quality, with positive sentiment and emotions of joy dominating in social media. Its perception has slightly decreased since its debut, however, with joy decreasing and (negative) surprise on the rise, and it is perceived more negatively in languages other than English. In recent scientific papers, ChatGPT is characterized as a great opportunity across various fields including the medical domain, but also as a threat concerning ethics and receives mixed assessments for education. Our comprehensive meta-analysis of ChatGPT's current perception after 2.5 months since its release can contribute to shaping the public debate and informing its future development. We make our data available. ","[{'version': 'v1', 'created': 'Mon, 20 Feb 2023 15:43:22 GMT'}]",2023-02-28,"[['Leiter', 'Christoph', ''], ['Zhang', 'Ran', ''], ['Chen', 'Yanran', ''], ['Belouadi', 'Jonas', ''], ['Larionov', 'Daniil', ''], ['Fresen', 'Vivian', ''], ['Eger', 'Steffen', '']]",1,1,2023-02-20,1,7,1,1,0,1,08ea934db9d135a08dddff878536a8b1b3e317c6,257219990.0,https://www.semanticscholar.org/paper/08ea934db9d135a08dddff878536a8b1b3e317c6,arXiv.org,2023.0,18.0,49.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '66122857', 'name': 'Christoph Leiter'}, {'authorId': '2134783333', 'name': 'Ran Zhang'}, {'authorId': '2109307862', 'name': 'Yanran Chen'}, {'authorId': '2138207755', 'name': 'Jonas Belouadi'}, {'authorId': '144748404', 'name': 'Daniil Larionov'}, {'authorId': '2209989436', 'name': 'Vivian Fresen'}, {'authorId': '2620186', 'name': 'Steffen Eger'}]",['Bielefeld University'],['Germany'],2023-02
2302.13817,Sakib Shahriar,Sakib Shahriar and Kadhim Hayawi,"Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations","This manuscript has been accepted by Artificial Intelligence and
  Applications (AIA, ISSN: 2811-0854),
  https://doi.org/10.47852/bonviewAIA3202939, 2023",,10.47852/bonviewAIA3202939,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The emergence of an AI-powered chatbot that can generate human-like sentences and write coherent essays has caught the world's attention. This paper discusses the historical overview of chatbots and the technology behind Chat Generative Pre-trained Transformer, better known as ChatGPT. Moreover, potential applications of ChatGPT in various domains, including healthcare, education, and research, are highlighted. Despite promising results, there are several privacy and ethical concerns surrounding ChatGPT. In addition, we highlight some of the important limitations of the current version of ChatGPT. We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer. ","[{'version': 'v1', 'created': 'Mon, 27 Feb 2023 14:26:29 GMT'}, {'version': 'v2', 'created': 'Thu, 2 Mar 2023 18:27:43 GMT'}, {'version': 'v3', 'created': 'Thu, 1 Jun 2023 14:47:20 GMT'}, {'version': 'v4', 'created': 'Wed, 9 Aug 2023 16:17:08 GMT'}]",2023-08-11,"[['Shahriar', 'Sakib', ''], ['Hayawi', 'Kadhim', '']]",1,1,2023-02-27,4,2,2,1,0,1,505a9c24e58b4510bd6e553c87179b9b5953e82f,257219160.0,https://www.semanticscholar.org/paper/505a9c24e58b4510bd6e553c87179b9b5953e82f,Artificial Intelligence and Applications,2023.0,71.0,33.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143787727', 'name': 'Sakib Shahriar'}, {'authorId': '1915582', 'name': 'Kadhim Hayawi'}]","['University of Guelph', 'Zayed University']","['Canada', 'United Arab Emirates']",2023-02
2302.13942,Gabriele Sarti,"Gabriele Sarti, Nils Feldhus, Ludwig Sickert, Oskar van der Wal,
  Malvina Nissim, Arianna Bisazza",Inseq: An Interpretability Toolkit for Sequence Generation Models,"ACL 2023 Demo Track. Library: https://github.com/inseq-team/inseq,
  Docs: https://inseq.readthedocs.io, v0.4",Proceedings of ACL: System Demonstrations (2023) 421-435,10.18653/v1/2023.acl-demo.40,,cs.CL cs.AI cs.HC cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Past work in natural language processing interpretability focused mainly on popular classification tasks while largely overlooking generation settings, partly due to a lack of dedicated tools. In this work, we introduce Inseq, a Python library to democratize access to interpretability analyses of sequence generation models. Inseq enables intuitive and optimized extraction of models' internal information and feature importance scores for popular decoder-only and encoder-decoder Transformers architectures. We showcase its potential by adopting it to highlight gender biases in machine translation models and locate factual knowledge inside GPT-2. Thanks to its extensible interface supporting cutting-edge techniques such as contrastive feature attribution, Inseq can drive future advances in explainable natural language generation, centralizing good practices and enabling fair and reproducible model evaluations. ","[{'version': 'v1', 'created': 'Mon, 27 Feb 2023 16:45:50 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Apr 2023 15:29:22 GMT'}, {'version': 'v3', 'created': 'Sat, 27 May 2023 09:41:37 GMT'}]",2023-09-08,"[['Sarti', 'Gabriele', ''], ['Feldhus', 'Nils', ''], ['Sickert', 'Ludwig', ''], ['van der Wal', 'Oskar', ''], ['Nissim', 'Malvina', ''], ['Bisazza', 'Arianna', '']]",0,1,2023-02-27,3,6,4,1,1,0,932b9fd1e2aaf3c56841304b7a49e30c804f6234,257219734.0,https://www.semanticscholar.org/paper/932b9fd1e2aaf3c56841304b7a49e30c804f6234,Annual Meeting of the Association for Computational Linguistics,2023.0,88.0,18.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1897770594', 'name': 'Gabriele Sarti'}, {'authorId': '1641658310', 'name': 'Nils Feldhus'}, {'authorId': '2216597387', 'name': 'Ludwig Sickert'}, {'authorId': '1986356851', 'name': 'Oskar van der Wal'}, {'authorId': '2742475', 'name': 'M. Nissim'}, {'authorId': '3242253', 'name': 'Arianna Bisazza'}]",['University of Groningen'],['Netherlands'],2023-02
2302.14035,Aleksandra Piktus,"Aleksandra Piktus, Christopher Akiki, Paulo Villegas, Hugo
  Lauren\c{c}on, G\'erard Dupont, Alexandra Sasha Luccioni, Yacine Jernite,
  Anna Rogers",The ROOTS Search Tool: Data Transparency for LLMs,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  ROOTS is a 1.6TB multilingual text corpus developed for the training of BLOOM, currently the largest language model explicitly accompanied by commensurate data governance efforts. In continuation of these efforts, we present the ROOTS Search Tool: a search engine over the entire ROOTS corpus offering both fuzzy and exact search capabilities. ROOTS is the largest corpus to date that can be investigated this way. The ROOTS Search Tool is open-sourced and available on Hugging Face Spaces. We describe our implementation and the possible use cases of our tool. ","[{'version': 'v1', 'created': 'Mon, 27 Feb 2023 18:45:18 GMT'}]",2023-02-28,"[['Piktus', 'Aleksandra', ''], ['Akiki', 'Christopher', ''], ['Villegas', 'Paulo', ''], ['Laurençon', 'Hugo', ''], ['Dupont', 'Gérard', ''], ['Luccioni', 'Alexandra Sasha', ''], ['Jernite', 'Yacine', ''], ['Rogers', 'Anna', '']]",0,0,2023-02-27,1,8,2,1,1,0,2ed0030d06ac2cc739c8460c102ae4713d10d1e1,257219882.0,https://www.semanticscholar.org/paper/2ed0030d06ac2cc739c8460c102ae4713d10d1e1,Annual Meeting of the Association for Computational Linguistics,2023.0,59.0,12.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '120174856', 'name': 'Aleksandra Piktus'}, {'authorId': '2003696840', 'name': 'Christopher Akiki'}, {'authorId': '2176184659', 'name': 'Paulo Villegas'}, {'authorId': '2172404846', 'name': 'Hugo Laurenccon'}, {'authorId': '13656138', 'name': 'Gérard Dupont'}, {'authorId': '2993731', 'name': 'A. Luccioni'}, {'authorId': '2262249', 'name': 'Yacine Jernite'}, {'authorId': '145046059', 'name': 'Anna Rogers'}]","['University of Copenhagen', 'Leipzig University', 'Sapienza University of Rome']","['Germany', 'Italy', 'Denmark']",2023-02
2302.14389,Alexandre Pasquiou,"Alexandre Pasquiou, Yair Lakretz, Bertrand Thirion, Christophe Pallier","Information-Restricted Neural Language Models Reveal Different Brain Regions' Sensitivity to Semantics, Syntax and Context","19 pages, 8 figures, 10 pages of Appendix, 5 appendix figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  A fundamental question in neurolinguistics concerns the brain regions involved in syntactic and semantic processing during speech comprehension, both at the lexical (word processing) and supra-lexical levels (sentence and discourse processing). To what extent are these regions separated or intertwined? To address this question, we trained a lexical language model, Glove, and a supra-lexical language model, GPT-2, on a text corpus from which we selectively removed either syntactic or semantic information. We then assessed to what extent these information-restricted models were able to predict the time-courses of fMRI signal of humans listening to naturalistic text. We also manipulated the size of contextual information provided to GPT-2 in order to determine the windows of integration of brain regions involved in supra-lexical processing. Our analyses show that, while most brain regions involved in language are sensitive to both syntactic and semantic variables, the relative magnitudes of these effects vary a lot across these regions. Furthermore, we found an asymmetry between the left and right hemispheres, with semantic and syntactic processing being more dissociated in the left hemisphere than in the right, and the left and right hemispheres showing respectively greater sensitivity to short and long contexts. The use of information-restricted NLP models thus shed new light on the spatial organization of syntactic processing, semantic processing and compositionality. ","[{'version': 'v1', 'created': 'Tue, 28 Feb 2023 08:16:18 GMT'}]",2023-03-01,"[['Pasquiou', 'Alexandre', ''], ['Lakretz', 'Yair', ''], ['Thirion', 'Bertrand', ''], ['Pallier', 'Christophe', '']]",0,1,2023-02-28,1,4,1,1,1,0,71226f3f7844de23f6ac464a75597b3e28462933,257232607.0,https://www.semanticscholar.org/paper/71226f3f7844de23f6ac464a75597b3e28462933,Neurobiology of Language,2023.0,93.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '2175249740', 'name': 'Alexandre Pasquiou'}, {'authorId': '3051598', 'name': 'Yair Lakretz'}, {'authorId': '8493461', 'name': 'B. Thirion'}, {'authorId': '7892142', 'name': 'Christophe Pallier'}]","['Inserm', 'French Institute for Research in Computer Science and Automation']",['France'],2023-02
2302.14828,Lorenzo Bertolini,"Lorenzo Bertolini, Valentina Elce, Adriana Michalak, Giulio Bernardi,
  Julie Weeds",Automatic Scoring of Dream Reports' Emotional Content with Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In the field of dream research, the study of dream content typically relies on the analysis of verbal reports provided by dreamers upon awakening from their sleep. This task is classically performed through manual scoring provided by trained annotators, at a great time expense. While a consistent body of work suggests that natural language processing (NLP) tools can support the automatic analysis of dream reports, proposed methods lacked the ability to reason over a report's full context and required extensive data pre-processing. Furthermore, in most cases, these methods were not validated against standard manual scoring approaches. In this work, we address these limitations by adopting large language models (LLMs) to study and replicate the manual annotation of dream reports, using a mixture of off-the-shelf and bespoke approaches, with a focus on references to reports' emotions. Our results show that the off-the-shelf method achieves a low performance probably in light of inherent linguistic differences between reports collected in different (groups of) individuals. On the other hand, the proposed bespoke text classification method achieves a high performance, which is robust against potential biases. Overall, these observations indicate that our approach could find application in the analysis of large dream datasets and may favour reproducibility and comparability of results across studies. ","[{'version': 'v1', 'created': 'Tue, 28 Feb 2023 18:23:17 GMT'}]",2023-03-01,"[['Bertolini', 'Lorenzo', ''], ['Elce', 'Valentina', ''], ['Michalak', 'Adriana', ''], ['Bernardi', 'Giulio', ''], ['Weeds', 'Julie', '']]",0,0,2023-02-28,1,5,1,0,0,0,1c0ce6f1c4cc0f817418a19d01c28f7836a08913,257232592.0,https://www.semanticscholar.org/paper/1c0ce6f1c4cc0f817418a19d01c28f7836a08913,arXiv.org,2023.0,30.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48582037', 'name': 'Lorenzo Bertolini'}, {'authorId': '1902588408', 'name': 'V. Elce'}, {'authorId': '152674849', 'name': 'Adriana Michalak'}, {'authorId': '35259151', 'name': 'G. Bernardi'}, {'authorId': '2500077', 'name': 'Julie Weeds'}]","['University of Sussex', 'IMT School for Advanced Studies Lucca']","['United Kingdom', 'Italy']",2023-02
2303.00077,Conor Houghton,"Conor Houghton, Nina Kazanina, Priyanka Sukumaran",Beyond the limitations of any imaginable mechanism: large language models and psycholinguistics,"This is a commentary on Bowers Et. Al. (2023)
  doi:10.1017/S0140525X22002813",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Large language models are not detailed models of human linguistic processing. They are, however, extremely successful at their primary task: providing a model for language. For this reason and because there are no animal models for language, large language models are important in psycholinguistics: they are useful as a practical tool, as an illustrative comparative, and philosophically, as a basis for recasting the relationship between language and thought. ","[{'version': 'v1', 'created': 'Tue, 28 Feb 2023 20:49:38 GMT'}]",2023-03-02,"[['Houghton', 'Conor', ''], ['Kazanina', 'Nina', ''], ['Sukumaran', 'Priyanka', '']]",0,0,2023-02-28,1,3,2,0,0,0,920fdefeeacff8685b099f63007ac2827c822a73,257255569.0,https://www.semanticscholar.org/paper/920fdefeeacff8685b099f63007ac2827c822a73,arXiv.org,2023.0,19.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2517285', 'name': 'Conor J. Houghton'}, {'authorId': '46846279', 'name': 'N. Kazanina'}, {'authorId': '2189421512', 'name': 'Priyanka Sukumaran'}]","['National Research University Higher School of Economics', 'University of Bristol']","['Russia', 'United Kingdom']",2023-02
2303.00438,Alessio Capitanelli M. Eng.,Alessio Capitanelli and Fulvio Mastrogiovanni,A Framework to Generate Neurosymbolic PDDL-compliant Planners,"Submitted to the IEEE/RSJ International Conference on Intelligent
  Robots and Systems. 7 pages, 2 figures, 3 tables",,,,cs.AI cs.LG cs.RO,http://creativecommons.org/licenses/by/4.0/,"  The problem of integrating high-level task planning in the execution loop of a real-world robot architecture remains challenging, as the planning times of traditional symbolic planners explode combinatorially with the number of symbols to plan upon. In this paper, we present Teriyaki, a framework for training Large Language Models (LLMs), and in particular the now well-known GPT-3 model, into neurosymbolic planners compatible with the Planning Domain Definition Language (PDDL). Unlike symbolic approaches, LLMs require a training process. However, their response time scales with the combined length of the input and the output. Hence, LLM-based planners can potentially provide significant performance gains on complex planning problems as the technology matures and becomes more accessible. In this preliminary work, which to our knowledge is the first using LLMs for planning in robotics, we (i) outline a methodology for training LLMs as PDDL solvers, (ii) generate PDDL-compliant planners for two challenging PDDL domains, and (iii) test the planning times and the plan quality associated with the obtained planners, while also comparing them to a state-of-the-art PDDL planner, namely Probe. Results confirm the viability of the approach, with Teriyaki-based planners being able to solve 95.5% of problems in a test data set of 1000 samples, and even generating plans up to 13.5% shorter on average than the employed traditional planner, depending on the domain. ","[{'version': 'v1', 'created': 'Wed, 1 Mar 2023 11:54:22 GMT'}]",2023-03-02,"[['Capitanelli', 'Alessio', ''], ['Mastrogiovanni', 'Fulvio', '']]",0,1,2023-03-01,1,2,3,1,0,1,5e06c517a9883cdc8266a871d26183cf7aa954cf,257254988.0,https://www.semanticscholar.org/paper/5e06c517a9883cdc8266a871d26183cf7aa954cf,arXiv.org,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2378414', 'name': 'Alessio Capitanelli'}, {'authorId': '1945056', 'name': 'F. Mastrogiovanni'}]",['University of Genoa'],['Italy'],2023-03
2303.00456,Rao Ma,"Rao Ma, Mark J. F. Gales, Kate M. Knill, Mengjie Qian",N-best T5: Robust ASR Error Correction using Multiple Input Hypotheses and Constrained Decoding Space,submitted to INTERSPEECH,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Error correction models form an important part of Automatic Speech Recognition (ASR) post-processing to improve the readability and quality of transcriptions. Most prior works use the 1-best ASR hypothesis as input and therefore can only perform correction by leveraging the context within one sentence. In this work, we propose a novel N-best T5 model for this task, which is fine-tuned from a T5 model and utilizes ASR N-best lists as model input. By transferring knowledge from the pre-trained language model and obtaining richer information from the ASR decoding space, the proposed approach outperforms a strong Conformer-Transducer baseline. Another issue with standard error correction is that the generation process is not well-guided. To address this a constrained decoding process, either based on the N-best list or an ASR lattice, is used which allows additional information to be propagated. ","[{'version': 'v1', 'created': 'Wed, 1 Mar 2023 12:32:34 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Jun 2023 23:56:35 GMT'}]",2023-06-05,"[['Ma', 'Rao', ''], ['Gales', 'Mark J. F.', ''], ['Knill', 'Kate M.', ''], ['Qian', 'Mengjie', '']]",0,0,2023-03-01,2,4,3,1,1,0,740b6c5c8c4ad4892a51bdc9da433f3177dbc6f3,257254986.0,https://www.semanticscholar.org/paper/740b6c5c8c4ad4892a51bdc9da433f3177dbc6f3,Interspeech,2023.0,29.0,7.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50397234', 'name': 'Rao Ma'}, {'authorId': '1740397', 'name': 'M. Gales'}, {'authorId': '145962472', 'name': 'K. Knill'}, {'authorId': '10769548', 'name': 'Mengjie Qian'}]",['University of Cambridge'],['United Kingdom'],2023-03
2303.00973,Scarlett Raine Ms,"Scarlett Raine, Ross Marchant, Brano Kusy, Frederic Maire and Tobias
  Fischer",Image Labels Are All You Need for Coarse Seagrass Segmentation,"10 pages, 4 figures, additional 3 pages of supplementary material","2024 IEEE/CVF Winter Conference on Applications of Computer Vision
  (WACV)",,,cs.CV cs.LG cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Seagrass meadows serve as critical carbon sinks, but estimating the amount of carbon they store requires knowledge of the seagrass species present. Underwater and surface vehicles equipped with machine learning algorithms can help to accurately estimate the composition and extent of seagrass meadows at scale. However, previous approaches for seagrass detection and classification have required supervision from patch-level labels. In this paper, we reframe seagrass classification as a weakly supervised coarse segmentation problem where image-level labels are used during training (25 times fewer labels compared to patch-level labeling) and patch-level outputs are obtained at inference time. To this end, we introduce SeaFeats, an architecture that uses unsupervised contrastive pre-training and feature similarity, and SeaCLIP, a model that showcases the effectiveness of large language models as a supervisory signal in domain-specific applications. We demonstrate that an ensemble of SeaFeats and SeaCLIP leads to highly robust performance. Our method outperforms previous approaches that require patch-level labels on the multi-species 'DeepSeagrass' dataset by 6.8% (absolute) for the class-weighted F1 score, and by 12.1% (absolute) for the seagrass presence/absence F1 score on the 'Global Wetlands' dataset. We also present two case studies for real-world deployment: outlier detection on the Global Wetlands dataset, and application of our method on imagery collected by the FloatyBoat autonomous surface vehicle. ","[{'version': 'v1', 'created': 'Thu, 2 Mar 2023 05:10:57 GMT'}, {'version': 'v2', 'created': 'Wed, 6 Sep 2023 01:48:56 GMT'}]",2023-09-07,"[['Raine', 'Scarlett', ''], ['Marchant', 'Ross', ''], ['Kusy', 'Brano', ''], ['Maire', 'Frederic', ''], ['Fischer', 'Tobias', '']]",0,0,2023-03-02,2,5,3,0,0,0,f6048d733de1dad2f3bac9988630f4b17fcf89ec,257280091.0,https://www.semanticscholar.org/paper/f6048d733de1dad2f3bac9988630f4b17fcf89ec,arXiv.org,2023.0,49.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1955624212', 'name': 'Scarlett Raine'}, {'authorId': '48879783', 'name': 'R. Marchant'}, {'authorId': '98424393', 'name': 'Brano Kusy'}, {'authorId': '1737645', 'name': 'F. Maire'}, {'authorId': '2144029195', 'name': 'Tobias Fischer'}]","['Queensland University of Technology', 'Image Analytics, Australia', 'Data61']",['Australia'],2023-03
2303.01194,Andrianos Michail,"Andrianos Michail, Stefanos Konstantinou, Simon Clematide",UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data Generation for Cross-Lingual Learning in Tweet Intimacy Prediction,Accepted at SemEval-2023,,10.18653/v1/2023.semeval-1.140,2023.semeval-1.140,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9 ""Multilingual Tweet Intimacy Analysis"". We achieved second-best results in all 10 languages according to the official Pearson's correlation regression evaluation measure. Our cross-lingual transfer learning approach explores the benefits of using a Head-First Fine-Tuning method (HeFiT) that first updates only the regression head parameters and then also updates the pre-trained transformer encoder parameters at a reduced learning rate. Additionally, we study the impact of using a small set of automatically generated examples (in our case, from ChatGPT) for low-resource settings where no human-labeled data is available. Our study shows that HeFiT stabilizes training and consistently improves results for pre-trained models that lack domain adaptation to tweets. Our study also shows a noticeable performance increase in cross-lingual learning when synthetic data is used, confirming the usefulness of current text generation systems to improve zero-shot baseline results. Finally, we examine how possible inconsistencies in the annotated data contribute to cross-lingual interference issues. ","[{'version': 'v1', 'created': 'Thu, 2 Mar 2023 12:18:53 GMT'}, {'version': 'v2', 'created': 'Mon, 24 Apr 2023 12:19:56 GMT'}]",2023-08-09,"[['Michail', 'Andrianos', ''], ['Konstantinou', 'Stefanos', ''], ['Clematide', 'Simon', '']]",1,1,2023-03-02,2,3,2,1,0,1,c80ee89a4ad8bf35957eb1dff72921ebc5663a44,257280424.0,https://www.semanticscholar.org/paper/c80ee89a4ad8bf35957eb1dff72921ebc5663a44,International Workshop on Semantic Evaluation,2023.0,17.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2210284045', 'name': 'Andrianos Michail'}, {'authorId': '2181135273', 'name': 'Stefanos Konstantinou'}, {'authorId': '2053272', 'name': 'S. Clematide'}]",['University of Zurich'],['Switzerland'],2023-03
2303.01248,Haocong Rao,"Haocong Rao, Cyril Leung, Chunyan Miao",Can ChatGPT Assess Human Personalities? A General Evaluation Framework,Our codes are available at https://github.com/Kali-Hac/ChatGPT-MBTI,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) especially ChatGPT have produced impressive results in various areas, but their potential human-like psychology is still largely unexplored. Existing works study the virtual personalities of LLMs but rarely explore the possibility of analyzing human personalities via LLMs. This paper presents a generic evaluation framework for LLMs to assess human personalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically, we first devise unbiased prompts by randomly permuting options in MBTI questions and adopt the average testing result to encourage more impartial answer generation. Then, we propose to replace the subject in question statements to enable flexible queries and assessments on different subjects from LLMs. Finally, we re-formulate the question instructions in a manner of correctness evaluation to facilitate LLMs to generate clearer responses. The proposed framework enables LLMs to flexibly assess personalities of different groups of people. We further propose three evaluation metrics to measure the consistency, robustness, and fairness of assessment results from state-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal ChatGPT's ability to assess human personalities, and the average results demonstrate that it can achieve more consistent and fairer assessments in spite of lower robustness against prompt biases compared with InstructGPT. ","[{'version': 'v1', 'created': 'Wed, 1 Mar 2023 06:16:14 GMT'}, {'version': 'v2', 'created': 'Tue, 7 Mar 2023 05:35:39 GMT'}]",2023-03-08,"[['Rao', 'Haocong', ''], ['Leung', 'Cyril', ''], ['Miao', 'Chunyan', '']]",1,1,2023-03-01,2,3,2,2,0,2,c4d65688c54154e01bb4fc18e4a58ef4ed6ea46b,257279816.0,https://www.semanticscholar.org/paper/c4d65688c54154e01bb4fc18e4a58ef4ed6ea46b,arXiv.org,2023.0,93.0,22.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1810691540', 'name': 'Haocong Rao'}, {'authorId': '2047458009', 'name': 'Cyril Leung'}, {'authorId': '1679209', 'name': 'C. Miao'}]","['University of British Columbia', 'Nanyang Technological University']","['Canada', 'Singapore']",2023-03
2303.01255,Pedro Reviriego,"Gonzalo Mart\'inez, Lauren Watson, Pedro Reviriego, Jos\'e Alberto
  Hern\'andez, Marc Juarez, Rik Sarkar",Combining Generative Artificial Intelligence (AI) and the Internet: Heading towards Evolution or Degradation?,First version,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  In the span of a few months, generative Artificial Intelligence (AI) tools that can generate realistic images or text have taken the Internet by storm, making them one of the technologies with fastest adoption ever. Some of these generative AI tools such as DALL-E, MidJourney, or ChatGPT have gained wide public notoriety. Interestingly, these tools are possible because of the massive amount of data (text and images) available on the Internet. The tools are trained on massive data sets that are scraped from Internet sites. And now, these generative AI tools are creating massive amounts of new data that are being fed into the Internet. Therefore, future versions of generative AI tools will be trained with Internet data that is a mix of original and AI-generated data. As time goes on, a mixture of original data and data generated by different versions of AI tools will populate the Internet. This raises a few intriguing questions: how will future versions of generative AI tools behave when trained on a mixture of real and AI generated data? Will they evolve with the new data sets or degenerate? Will evolution introduce biases in subsequent generations of generative AI tools? In this document, we explore these questions and report some very initial simulation results using a simple image-generation AI tool. These results suggest that the quality of the generated images degrades as more AI-generated data is used for training thus suggesting that generative AI may degenerate. Although these results are preliminary and cannot be generalised without further study, they serve to illustrate the potential issues of the interaction between generative AI and the Internet. ","[{'version': 'v1', 'created': 'Fri, 17 Feb 2023 17:39:41 GMT'}]",2023-03-03,"[['Martínez', 'Gonzalo', ''], ['Watson', 'Lauren', ''], ['Reviriego', 'Pedro', ''], ['Hernández', 'José Alberto', ''], ['Juarez', 'Marc', ''], ['Sarkar', 'Rik', '']]",1,1,2023-02-17,1,6,1,1,0,1,a82d3924f488d74af91ba31ff1cf80a6c07ee206,257280389.0,https://www.semanticscholar.org/paper/a82d3924f488d74af91ba31ff1cf80a6c07ee206,arXiv.org,2023.0,11.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2163570875', 'name': 'Gonzalo Martínez Ruiz de Arcaute'}, {'authorId': '2058604454', 'name': 'Lauren Watson'}, {'authorId': '3228297', 'name': 'P. Reviriego'}, {'authorId': '2111084346', 'name': 'José Alberto Hernández'}, {'authorId': '35611333', 'name': 'Marc Juárez'}, {'authorId': '2056781762', 'name': 'Rik Sarkar'}]","['Universidad Politécnica de Madrid', 'University of Edinburgh', 'Carlos III University of Madrid']","['United Kingdom', 'Spain']",2023-02
2303.01911,Rachel Bawden,Rachel Bawden and Fran\c{c}ois Yvon,Investigating the Translation Performance of a Large Multilingual Language Model: the Case of BLOOM,Accepted at EAMT 2023,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  The NLP community recently saw the release of a new large open-access multilingual language model, BLOOM (BigScience et al., 2022) covering 46 languages. We focus on BLOOM's multilingual ability by evaluating its machine translation performance across several datasets (WMT, Flores-101 and DiaBLa) and language pairs (high- and low-resourced). Our results show that 0-shot performance suffers from overgeneration and generating in the wrong language, but this is greatly improved in the few-shot setting, with very good results for a number of language pairs. We study several aspects including prompt design, model sizes, cross-lingual transfer and the use of discursive context. ","[{'version': 'v1', 'created': 'Fri, 3 Mar 2023 13:23:42 GMT'}, {'version': 'v2', 'created': 'Tue, 9 May 2023 12:21:58 GMT'}]",2023-05-10,"[['Bawden', 'Rachel', ''], ['Yvon', 'François', '']]",0,0,2023-03-03,2,2,1,1,1,0,72f1e6509bcfeabeb33e31e10c6926dab05f3e8b,257353790.0,https://www.semanticscholar.org/paper/72f1e6509bcfeabeb33e31e10c6926dab05f3e8b,European Association for Machine Translation Conferences/Workshops,2023.0,60.0,19.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '48983885', 'name': 'Rachel Bawden'}, {'authorId': '1602259700', 'name': 'Franccois Yvon'}]","['University of Paris-Saclay', 'French Institute for Research in Computer Science and Automation']",['France'],2023-03
2303.02155,Daniele Loiacono,Pier Luca Lanzi and Daniele Loiacono,ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design,(Submitted),,,,cs.AI cs.HC cs.LG cs.NE,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large language models (LLMs) have taken the scientific world by storm, changing the landscape of natural language processing and human-computer interaction. These powerful tools can answer complex questions and, surprisingly, perform challenging creative tasks (e.g., generate code and applications to solve problems, write stories, pieces of music, etc.). In this paper, we present a collaborative game design framework that combines interactive evolution and large language models to simulate the typical human design process. We use the former to exploit users' feedback for selecting the most promising ideas and large language models for a very complex creative task - the recombination and variation of ideas. In our framework, the process starts with a brief and a set of candidate designs, either generated using a language model or proposed by the users. Next, users collaborate on the design process by providing feedback to an interactive genetic algorithm that selects, recombines, and mutates the most promising designs. We evaluated our framework on three game design tasks with human designers who collaborated remotely. ","[{'version': 'v1', 'created': 'Thu, 9 Feb 2023 15:44:43 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Apr 2023 16:58:20 GMT'}]",2023-04-14,"[['Lanzi', 'Pier Luca', ''], ['Loiacono', 'Daniele', '']]",1,1,2023-02-09,2,2,4,1,0,1,09239dac5b1cded9414c946333eaf619dca9aaa7,257364995.0,https://www.semanticscholar.org/paper/09239dac5b1cded9414c946333eaf619dca9aaa7,Annual Conference on Genetic and Evolutionary Computation,2023.0,61.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1796949', 'name': 'P. Lanzi'}, {'authorId': '1775166', 'name': 'D. Loiacono'}]","['Politecnico di Milano', 'Daniele Loiacono,']",['Italy'],2023-02
2303.02411,Maria Lymperaiou,"Maria Lymperaiou, Giorgos Stamou",The Contribution of Knowledge in Visiolinguistic Learning: A Survey on Tasks and Challenges,,,,,cs.CL cs.AI cs.CV,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Recent advancements in visiolinguistic (VL) learning have allowed the development of multiple models and techniques that offer several impressive implementations, able to currently resolve a variety of tasks that require the collaboration of vision and language. Current datasets used for VL pre-training only contain a limited amount of visual and linguistic knowledge, thus significantly limiting the generalization capabilities of many VL models. External knowledge sources such as knowledge graphs (KGs) and Large Language Models (LLMs) are able to cover such generalization gaps by filling in missing knowledge, resulting in the emergence of hybrid architectures. In the current survey, we analyze tasks that have benefited from such hybrid approaches. Moreover, we categorize existing knowledge sources and types, proceeding to discussion regarding the KG vs LLM dilemma and its potential impact to future hybrid approaches. ","[{'version': 'v1', 'created': 'Sat, 4 Mar 2023 13:12:18 GMT'}]",2023-03-07,"[['Lymperaiou', 'Maria', ''], ['Stamou', 'Giorgos', '']]",0,0,2023-03-04,1,2,3,0,0,0,0f19e94f30b99d6c4b349900057cdae9262034f9,257365144.0,https://www.semanticscholar.org/paper/0f19e94f30b99d6c4b349900057cdae9262034f9,Make,2023.0,153.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2184294391', 'name': 'Maria Lymperaiou'}, {'authorId': '1719165', 'name': 'G. Stamou'}]",['National Technical University of Athens'],['Greece'],2023-03
2303.02927,Victor Dibia,Victor Dibia,LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models,"Accepted at ACL 2023 (Demonstration track). Fix formatting issues,
  update information on evaluation metrics, prompts and project website
  (https://microsoft.github.io/lida/)",,,,cs.AI cs.HC cs.PL,http://creativecommons.org/licenses/by/4.0/,"  Systems that support users in the automatic creation of visualizations must address several subtasks - understand the semantics of data, enumerate relevant visualization goals and generate visualization specifications. In this work, we pose visualization generation as a multi-stage generation problem and argue that well-orchestrated pipelines based on large language models (LLMs) such as ChatGPT/GPT-4 and image generation models (IGMs) are suitable to addressing these tasks. We present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data into a rich but compact natural language summary, a GOAL EXPLORER that enumerates visualization goals given the data, a VISGENERATOR that generates, refines, executes and filters visualization code and an INFOGRAPHER module that yields data-faithful stylized graphics using IGMs. LIDA provides a python api, and a hybrid user interface (direct manipulation and multilingual natural language) for interactive chart, infographics and data story generation. Learn more about the project here - https://microsoft.github.io/lida/ ","[{'version': 'v1', 'created': 'Mon, 6 Mar 2023 06:47:22 GMT'}, {'version': 'v2', 'created': 'Fri, 2 Jun 2023 21:57:13 GMT'}, {'version': 'v3', 'created': 'Tue, 6 Jun 2023 01:21:41 GMT'}]",2023-06-07,"[['Dibia', 'Victor', '']]",1,1,2023-03-06,3,1,3,2,0,2,1f8efdaa56df0ede1c2b7c6cb55f0640f1ed43df,257365015.0,https://www.semanticscholar.org/paper/1f8efdaa56df0ede1c2b7c6cb55f0640f1ed43df,Annual Meeting of the Association for Computational Linguistics,2023.0,48.0,15.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3353344', 'name': 'Victor C. Dibia'}]",['Microsoft'],['India'],2023-03
2303.03004,M Saiful Bari,"Mohammad Abdullah Matin Khan, M Saiful Bari, Xuan Long Do, Weishi
  Wang, Md Rizwan Parvez, Shafiq Joty","xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval",Data & Code available at https://github.com/ntunlp/xCodeEval,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  AI systems that can create codes as solutions to problems or assist developers in writing codes can increase productivity and make programming more accessible. Recently, pre-trained large language models have shown impressive abilities in generating codes from natural language descriptions, repairing buggy codes, translating codes between languages, and retrieving relevant code segments. However, the evaluation of these models has often been performed in a scattered way on only one or two specific tasks, in a few languages, at a partial granularity (e.g., function) level, and in many cases without proper training data. Even more concerning is that in most cases the evaluation of generated codes has been done in terms of mere lexical overlap with a reference code rather than actual execution. We introduce xCodeEval, the largest executable multilingual multitask benchmark to date consisting of 25M document-level coding examples (16.5B tokens) from about 7.5K unique problems covering up to 11 programming languages with execution-level parallelism. It features a total of seven tasks involving code understanding, generation, translation and retrieval. xCodeEval adopts an execution-based evaluation and offers a multilingual code execution engine, ExecEval that supports unit test based execution in all the 11 languages. To address the challenge of balancing the distributions of text-code samples over multiple attributes in validation/test sets, we further propose a novel data splitting and a data selection schema based on the geometric mean and graph-theoretic principle. Experimental results on all the tasks and languages show xCodeEval is a promising yet challenging benchmark as per the current advancements in language models. ","[{'version': 'v1', 'created': 'Mon, 6 Mar 2023 10:08:51 GMT'}, {'version': 'v2', 'created': 'Mon, 17 Apr 2023 05:27:18 GMT'}, {'version': 'v3', 'created': 'Tue, 13 Jun 2023 11:29:45 GMT'}]",2023-06-14,"[['Khan', 'Mohammad Abdullah Matin', ''], ['Bari', 'M Saiful', ''], ['Do', 'Xuan Long', ''], ['Wang', 'Weishi', ''], ['Parvez', 'Md Rizwan', ''], ['Joty', 'Shafiq', '']]",0,0,2023-03-06,3,6,1,0,0,0,fcda3c77c737efc84a24fa6706d262cde3355e0e,260546394.0,https://www.semanticscholar.org/paper/fcda3c77c737efc84a24fa6706d262cde3355e0e,,2023.0,117.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2210837993', 'name': 'Mohammad Abdullah Matin Khan'}, {'authorId': '31773000', 'name': 'M Saiful Bari'}, {'authorId': None, 'name': 'Xuan Long Do'}, {'authorId': '2108528154', 'name': 'Weishi Wang'}, {'authorId': '3405393', 'name': 'Md. Rizwan Parvez'}, {'authorId': '2708940', 'name': 'Shafiq R. Joty'}]","['Qatar Computing Research Institute', 'Nanyang Technological University', 'Islamic University of Technology']","['Qatar', 'Singapore', 'Bangladesh']",2023-03
2303.03103,Hangyeol Yu,"Hangyeol Yu, Myeongho Jeong, Jamin Shin, Hyeongdon Moon, Juneyoung
  Park, Seungtaek Choi",Towards Zero-Shot Functional Compositionality of Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Pre-trained Language Models (PLM) have become the most desirable starting point in the field of NLP, as they have become remarkably good at solving many individual tasks. Despite such success, in this paper, we argue that current paradigms of working with PLMs are neglecting a critical aspect of modeling human intelligence: functional compositionality. Functional compositionality - the ability to compose learned tasks - has been a long-standing challenge in the field of AI (and many other fields) as it is considered one of the hallmarks of human intelligence. An illustrative example of such is cross-lingual summarization, where a bilingual person (English-French) could directly summarize an English document into French sentences without having to translate the English document or summary into French explicitly. We discuss why this matter is an important open problem that requires further attention from the field. Then, we show that current PLMs (e.g., GPT-2 and T5) don't have functional compositionality yet and it is far from human-level generalizability. Finally, we suggest several research directions that could push the field towards zero-shot functional compositionality of language models. ","[{'version': 'v1', 'created': 'Mon, 6 Mar 2023 13:15:25 GMT'}]",2023-03-07,"[['Yu', 'Hangyeol', ''], ['Jeong', 'Myeongho', ''], ['Shin', 'Jamin', ''], ['Moon', 'Hyeongdon', ''], ['Park', 'Juneyoung', ''], ['Choi', 'Seungtaek', '']]",0,1,2023-03-06,1,6,2,2,2,0,aba36ad7021f615bd350d7e3f7c3218cf7bcd550,253082773.0,https://www.semanticscholar.org/paper/aba36ad7021f615bd350d7e3f7c3218cf7bcd550,arXiv.org,2023.0,65.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50984319', 'name': 'Hangyeol Yu'}, {'authorId': '98089930', 'name': 'Myeongho Jeong'}, {'authorId': '51228826', 'name': 'Jamin Shin'}, {'authorId': '2157044837', 'name': 'Hyeongdon Moon'}, {'authorId': '2115955448', 'name': 'Juneyoung Park'}, {'authorId': '5841595', 'name': 'Seungtaek Choi'}]","['Equal Contribution.', 'NAVER', 'Riiid AI Research.', 'Riiid AI Research']",['South Korea'],2023-03
2303.03186,Mostafa M. Amin,"Mostafa M. Amin, Erik Cambria, Bj\""orn W. Schuller",Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT,"9 Pages (8 pages + 1 page for references), 1 Figure, 3 Tables",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks. In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection. We utilise three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words baseline (BoW). Results show that the RoBERTa trained for a specific downstream task generally has a superior performance. On the other hand, ChatGPT provides decent results, and is relatively comparable to the Word2Vec and BoW baselines. ChatGPT further shows robustness against noisy data, where Word2Vec models achieve worse results due to noise. Results indicate that ChatGPT is a good generalist model that is capable of achieving good results across various problems without any specialised training, however, it is not as good as a specialised model for a downstream task. ","[{'version': 'v1', 'created': 'Fri, 3 Mar 2023 16:11:37 GMT'}]",2023-03-07,"[['Amin', 'Mostafa M.', ''], ['Cambria', 'Erik', ''], ['Schuller', 'Björn W.', '']]",1,1,2023-03-03,1,3,2,1,0,1,da872dfc0934f554311d5f91fa7e5ada44fb8155,257364805.0,https://www.semanticscholar.org/paper/da872dfc0934f554311d5f91fa7e5ada44fb8155,arXiv.org,2023.0,30.0,25.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2162544654', 'name': 'Mostafa M. Amin'}, {'authorId': '49943757', 'name': 'E. Cambria'}, {'authorId': '145411696', 'name': 'Björn Schuller'}]","['Imperial College London', 'University of Augsburg', 'Nanyang Technological University']","['Germany', 'United Kingdom', 'Singapore']",2023-03
2303.03199,Daniel Buschek,"Hai Dang, Sven Goller, Florian Lehmann, Daniel Buschek",Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting,"17 pages, 9 figures, 3 tables, ACM CHI 2023",,10.1145/3544548.3580969,,cs.HC cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose a conceptual perspective on prompts for Large Language Models (LLMs) that distinguishes between (1) diegetic prompts (part of the narrative, e.g. ""Once upon a time, I saw a fox...""), and (2) non-diegetic prompts (external, e.g. ""Write about the adventures of the fox.""). With this lens, we study how 129 crowd workers on Prolific write short texts with different user interfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with GPT-3): When the interface offered multiple suggestions and provided an option for non-diegetic prompting, participants preferred choosing from multiple suggestions over controlling them via non-diegetic prompts. When participants provided non-diegetic prompts it was to ask for inspiration, topics or facts. Single suggestions in particular were guided both with diegetic and non-diegetic information. This work informs human-AI interaction with generative models by revealing that (1) writing non-diegetic prompts requires effort, (2) people combine diegetic and non-diegetic prompting, and (3) they use their draft (i.e. diegetic information) and suggestion timing to strategically guide LLMs. ","[{'version': 'v1', 'created': 'Mon, 6 Mar 2023 14:58:42 GMT'}]",2023-03-07,"[['Dang', 'Hai', ''], ['Goller', 'Sven', ''], ['Lehmann', 'Florian', ''], ['Buschek', 'Daniel', '']]",0,1,2023-03-06,1,4,2,1,0,1,fccf8776d7525627c518a56a1f4db367a4d7120b,257365446.0,https://www.semanticscholar.org/paper/fccf8776d7525627c518a56a1f4db367a4d7120b,International Conference on Human Factors in Computing Systems,2023.0,55.0,15.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2767073', 'name': 'Hai Dang'}, {'authorId': '2184142124', 'name': 'Sven Goller'}, {'authorId': '153451802', 'name': 'Florian Lehmann'}, {'authorId': '1818313605', 'name': 'D. Buschek'}]",['University of Bayreuth'],['Germany'],2023-03
2303.03487,Ankit Vaidya,Ankit Vaidya and Aditya Kane,Two-stage Pipeline for Multilingual Dialect Detection,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,  Dialect Identification is a crucial task for localizing various Large Language Models. This paper outlines our approach to the VarDial 2023 shared task. Here we have to identify three or two dialects from three languages each which results in a 9-way classification for Track-1 and 6-way classification for Track-2 respectively. Our proposed approach consists of a two-stage system and outperforms other participants' systems and previous works in this domain. We achieve a score of 58.54% for Track-1 and 85.61% for Track-2. Our codebase is available publicly (https://github.com/ankit-vaidya19/EACL_VarDial2023). ,"[{'version': 'v1', 'created': 'Mon, 6 Mar 2023 20:35:51 GMT'}, {'version': 'v2', 'created': 'Tue, 28 Mar 2023 17:55:52 GMT'}]",2023-03-29,"[['Vaidya', 'Ankit', ''], ['Kane', 'Aditya', '']]",0,0,2023-03-06,2,2,2,0,0,0,f34864dc393b8f44776bd4ae34efd30b4e4c7afd,257378222.0,https://www.semanticscholar.org/paper/f34864dc393b8f44776bd4ae34efd30b4e4c7afd,"Workshop on NLP for Similar Languages, Varieties and Dialects",2023.0,35.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2210857786', 'name': 'Ankit Vaidya'}, {'authorId': '2159555605', 'name': 'Aditya Kane'}]","['Indian Institute of Information Technology, Pune']",['India'],2023-03
2303.03628,Seungone Kim,"Seungone Kim, Se June Joo, Yul Jang, Hyungjoo Chae, Jinyoung Yeo",CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification,Accepted at EACL 2023 Demo,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Chain-of-thought (CoT) prompting enables large language models (LLMs) to solve complex reasoning tasks by generating an explanation before the final prediction. Despite it's promising ability, a critical downside of CoT prompting is that the performance is greatly affected by the factuality of the generated explanation. To improve the correctness of the explanations, fine-tuning language models with explanation data is needed. However, there exists only a few datasets that can be used for such approaches, and no data collection tool for building them. Thus, we introduce CoTEVer, a tool-kit for annotating the factual correctness of generated explanations and collecting revision data of wrong explanations. Furthermore, we suggest several use cases where the data collected with CoTEVer can be utilized for enhancing the faithfulness of explanations. Our toolkit is publicly available at https://github.com/SeungoneKim/CoTEVer. ","[{'version': 'v1', 'created': 'Tue, 7 Mar 2023 03:23:14 GMT'}]",2023-03-08,"[['Kim', 'Seungone', ''], ['Joo', 'Se June', ''], ['Jang', 'Yul', ''], ['Chae', 'Hyungjoo', ''], ['Yeo', 'Jinyoung', '']]",0,0,2023-03-07,1,5,2,0,0,0,b9d75f361b5310c6ddcddfe7858bb0416eb78de4,257378358.0,https://www.semanticscholar.org/paper/b9d75f361b5310c6ddcddfe7858bb0416eb78de4,Conference of the European Chapter of the Association for Computational Linguistics,2023.0,56.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2184037220', 'name': 'Seungone Kim'}, {'authorId': '102540266', 'name': 'Se June Joo'}, {'authorId': '2210859958', 'name': 'Yul Jang'}, {'authorId': '2184029886', 'name': 'Hyungjoo Chae'}, {'authorId': '1898428', 'name': 'Jinyoung Yeo'}]","['Korea Advanced Institute of Science and Technology', 'Yonsei University']",['South Korea'],2023-03
2303.03953,Taja Kuzman,"Taja Kuzman, Igor Mozeti\v{c}, Nikola Ljube\v{s}i\'c",ChatGPT: Beginning of an End of Manual Linguistic Data Annotation? Use Case of Automatic Genre Identification,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  ChatGPT has shown strong capabilities in natural language generation tasks, which naturally leads researchers to explore where its abilities end. In this paper, we examine whether ChatGPT can be used for zero-shot text classification, more specifically, automatic genre identification. We compare ChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on datasets, manually annotated with genres. The models are compared on test sets in two languages: English and Slovenian. Results show that ChatGPT outperforms the fine-tuned model when applied to the dataset which was not seen before by either of the models. Even when applied on Slovenian language as an under-resourced language, ChatGPT's performance is no worse than when applied to English. However, if the model is fully prompted in Slovenian, the performance drops significantly, showing the current limitations of ChatGPT usage on smaller languages. The presented results lead us to questioning whether this is the beginning of an end of laborious manual annotation campaigns even for smaller languages, such as Slovenian. ","[{'version': 'v1', 'created': 'Tue, 7 Mar 2023 14:59:33 GMT'}, {'version': 'v2', 'created': 'Wed, 8 Mar 2023 09:35:09 GMT'}]",2023-03-09,"[['Kuzman', 'Taja', ''], ['Mozetič', 'Igor', ''], ['Ljubešić', 'Nikola', '']]",1,1,2023-03-07,2,3,2,1,0,1,31f44f0f2124c54e47f4df54dec63118232c25da,257405186.0,https://www.semanticscholar.org/paper/31f44f0f2124c54e47f4df54dec63118232c25da,arXiv.org,2023.0,47.0,24.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '28089460', 'name': 'Taja Kuzman'}, {'authorId': '1715207', 'name': 'I. Mozetič'}, {'authorId': '3358706', 'name': 'Nikola Ljubesic'}]","['Jožef Stefan Institute', 'Center za jezikovne vire in tehnologije Univerze v Ljubljani, Slovenia']",['Slovenia'],2023-03
2303.04142,Rohith Pudari,"Rohith Pudari, Neil A. Ernst",From Copilot to Pilot: Towards AI Supported Software Development,,,,,cs.SE cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  AI-supported programming has arrived, as shown by the introduction and successes of large language models for code, such as Copilot/Codex (Github/OpenAI) and AlphaCode (DeepMind). Above human average performance on programming challenges is now possible. However, software engineering is much more than solving programming contests. Moving beyond code completion to AI-supported software engineering will require an AI system that can, among other things, understand how to avoid code smells, to follow language idioms, and eventually (maybe!) propose rational software designs. In this study, we explore the current limitations of AI-supported code completion tools like Copilot and offer a simple taxonomy for understanding the classification of AI-supported code completion tools in this space. We first perform an exploratory study on Copilot's code suggestions for language idioms and code smells. Copilot does not follow language idioms and avoid code smells in most of our test scenarios. We then conduct additional investigation to determine the current boundaries of AI-supported code completion tools like Copilot by introducing a taxonomy of software abstraction hierarchies where 'basic programming functionality' such as code compilation and syntax checking is at the least abstract level, software architecture analysis and design are at the most abstract level. We conclude by providing a discussion on challenges for future development of AI-supported code completion tools to reach the design level of abstraction in our taxonomy. ","[{'version': 'v1', 'created': 'Tue, 7 Mar 2023 18:56:52 GMT'}]",2023-03-08,"[['Pudari', 'Rohith', ''], ['Ernst', 'Neil A.', '']]",0,0,2023-03-07,1,2,3,2,0,2,35afb57a646592c3a471a4f010d00e1b13dd3c43,257378245.0,https://www.semanticscholar.org/paper/35afb57a646592c3a471a4f010d00e1b13dd3c43,arXiv.org,2023.0,37.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1993542294', 'name': 'Rohith Pudari'}, {'authorId': '1755165', 'name': 'Neil A. Ernst'}]","['University of Toronto', 'University of Victoria']",['Canada'],2023-03
2303.05279,Stephanie Long,"Stephanie Long (1), Tibor Schuster (1), Alexandre Pich\'e (2,3) (1)
  Department of Family Medicine, McGill University, (2) Mila, Universit\'e de
  Montreal, (3) ServiceNow Research",Can large language models build causal graphs?,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Building causal graphs can be a laborious process. To ensure all relevant causal pathways have been captured, researchers often have to discuss with clinicians and experts while also reviewing extensive relevant medical literature. By encoding common and medical knowledge, large language models (LLMs) represent an opportunity to ease this process by automatically scoring edges (i.e., connections between two variables) in potential graphs. LLMs however have been shown to be brittle to the choice of probing words, context, and prompts that the user employs. In this work, we evaluate if LLMs can be a useful tool in complementing causal graph development. ","[{'version': 'v1', 'created': 'Tue, 7 Mar 2023 22:05:31 GMT'}]",2023-03-10,"[['Long', 'Stephanie', ''], ['Schuster', 'Tibor', ''], ['Piché', 'Alexandre', ''], ['Medicine', 'Department of Family', ''], ['University', 'McGill', ''], ['Mila', '', ''], ['de Montreal', 'Université', ''], ['Research', 'ServiceNow', '']]",0,0,2023-03-07,1,8,2,0,0,0,0606bb9a541ce7e57bd78ac680a7df0225ece30c,253065120.0,https://www.semanticscholar.org/paper/0606bb9a541ce7e57bd78ac680a7df0225ece30c,arXiv.org,2023.0,24.0,14.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '47118431', 'name': 'Stephanie Long'}, {'authorId': '2211099809', 'name': 'Tibor Schuster'}, {'authorId': '49504044', 'name': 'Alexandre Piché'}]","['Dept. of Family Medicine,', 'McGill University']",['Canada'],2023-03
2303.05295,Guo Yang,"Guo Yang, Daniel Lo, Robert Mullins, Yiren Zhao",Dynamic Stashing Quantization for Efficient Transformer Training,,,,,cs.LG cs.CL cs.PF,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have demonstrated impressive performance on a range of Natural Language Processing (NLP) tasks. Unfortunately, the immense amount of computations and memory accesses required for LLM training makes them prohibitively expensive in terms of hardware cost, and thus challenging to deploy in use cases such as on-device learning. In this paper, motivated by the observation that LLM training is memory-bound, we propose a novel dynamic quantization strategy, termed Dynamic Stashing Quantization (DSQ), that puts a special focus on reducing the memory operations, but also enjoys the other benefits of low precision training, such as the reduced arithmetic cost. We conduct a thorough study on two translation tasks (trained-from-scratch) and three classification tasks (fine-tuning). DSQ reduces the amount of arithmetic operations by $20.95\times$ and the number of DRAM operations by $2.55\times$ on IWSLT17 compared to the standard 16-bit fixed-point, which is widely used in on-device learning. ","[{'version': 'v1', 'created': 'Thu, 9 Mar 2023 14:44:31 GMT'}]",2023-03-10,"[['Yang', 'Guo', ''], ['Lo', 'Daniel', ''], ['Mullins', 'Robert', ''], ['Zhao', 'Yiren', '']]",0,0,2023-03-09,1,4,3,0,0,0,88134a9d204b45526c828505f7a691b2caa34aae,257427488.0,https://www.semanticscholar.org/paper/88134a9d204b45526c828505f7a691b2caa34aae,arXiv.org,2023.0,29.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109946381', 'name': 'Guofu Yang'}, {'authorId': '7380875', 'name': 'Daniel Lo'}, {'authorId': '2768514', 'name': 'R. Mullins'}, {'authorId': '2109919449', 'name': 'Yiren Zhao'}]","['Imperial College London', 'University of Cambridge']",['United Kingdom'],2023-03
2303.05349,Anna-Carolina Haensch,"Anna-Carolina Haensch, Sarah Ball, Markus Herklotz, Frauke Kreuter",Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data,,,,,stat.AP cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data. ","[{'version': 'v1', 'created': 'Thu, 9 Mar 2023 15:46:54 GMT'}]",2023-03-10,"[['Haensch', 'Anna-Carolina', ''], ['Ball', 'Sarah', ''], ['Herklotz', 'Markus', ''], ['Kreuter', 'Frauke', '']]",1,1,2023-03-09,1,4,3,1,0,1,7deb5d6e5d11b3cd1f3728592da91fd73091ab6c,257427446.0,https://www.semanticscholar.org/paper/7deb5d6e5d11b3cd1f3728592da91fd73091ab6c,arXiv.org,2023.0,32.0,11.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '23107750', 'name': 'Anna Haensch'}, {'authorId': '1759630', 'name': 'Sarah Ball'}, {'authorId': '15550916', 'name': 'Markus Herklotz'}, {'authorId': '4505092', 'name': 'F. Kreuter'}]",['Ludwig-Maximilians-Universität München'],['Germany'],2023-03
2303.05453,Hannah Rose Kirk Miss,"Hannah Rose Kirk, Bertie Vidgen, Paul R\""ottger, Scott A. Hale",Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback,"19 pages, 1 table",,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) are used to generate content for a wide range of tasks, and are set to reach a growing audience in coming years due to integration in product interfaces like ChatGPT or search engines like Bing. This intensifies the need to ensure that models are aligned with human preferences and do not produce unsafe, inaccurate or toxic outputs. While alignment techniques like reinforcement learning with human feedback (RLHF) and red-teaming can mitigate some safety concerns and improve model capabilities, it is unlikely that an aggregate fine-tuning process can adequately represent the full range of users' preferences and values. Different people may legitimately disagree on their preferences for language and conversational norms, as well as on values or ideologies which guide their communication. Personalising LLMs through micro-level preference learning processes may result in models that are better aligned with each user. However, there are several normative challenges in defining the bounds of a societally-acceptable and safe degree of personalisation. In this paper, we ask how, and in what ways, LLMs should be personalised. First, we review literature on current paradigms for aligning LLMs with human feedback, and identify issues including (i) a lack of clarity regarding what alignment means; (ii) a tendency of technology providers to prescribe definitions of inherently subjective preferences and values; and (iii) a 'tyranny of the crowdworker', exacerbated by a lack of documentation in who we are really aligning to. Second, we present a taxonomy of benefits and risks associated with personalised LLMs, for individuals and society at large. Finally, we propose a three-tiered policy framework that allows users to experience the benefits of personalised alignment, while restraining unsafe and undesirable LLM-behaviours within (supra-)national and organisational bounds. ","[{'version': 'v1', 'created': 'Thu, 9 Mar 2023 17:52:07 GMT'}]",2023-03-10,"[['Kirk', 'Hannah Rose', ''], ['Vidgen', 'Bertie', ''], ['Röttger', 'Paul', ''], ['Hale', 'Scott A.', '']]",1,1,2023-03-09,1,4,2,1,0,1,e5174aeda1baa67c17f4ac630ae2e44453954cc3,257427629.0,https://www.semanticscholar.org/paper/e5174aeda1baa67c17f4ac630ae2e44453954cc3,arXiv.org,2023.0,256.0,28.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '90729626', 'name': 'Hannah Rose Kirk'}, {'authorId': '2737827', 'name': 'Bertie Vidgen'}, {'authorId': '2043232919', 'name': 'Paul Röttger'}, {'authorId': '1741886127', 'name': 'Scott A. Hale'}]",['University of Oxford'],['United Kingdom'],2023-03
2303.06074,Lewis Griffin,"Lewis D Griffin, Bennett Kleinberg, Maximilian Mozes, Kimberly T Mai,
  Maria Vau, Matthew Caldwell and Augustine Marvor-Parker",Susceptibility to Influence of Large Language Models,"24 pages, 6 figures, 7 tables, 53 references",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Two studies tested the hypothesis that a Large Language Model (LLM) can be used to model psychological change following exposure to influential input. The first study tested a generic mode of influence - the Illusory Truth Effect (ITE) - where earlier exposure to a statement (through, for example, rating its interest) boosts a later truthfulness test rating. Data was collected from 1000 human participants using an online experiment, and 1000 simulated participants using engineered prompts and LLM completion. 64 ratings per participant were collected, using all exposure-test combinations of the attributes: truth, interest, sentiment and importance. The results for human participants reconfirmed the ITE, and demonstrated an absence of effect for attributes other than truth, and when the same attribute is used for exposure and test. The same pattern of effects was found for LLM-simulated participants. The second study concerns a specific mode of influence - populist framing of news to increase its persuasion and political mobilization. Data from LLM-simulated participants was collected and compared to previously published data from a 15-country experiment on 7286 human participants. Several effects previously demonstrated from the human study were replicated by the simulated study, including effects that surprised the authors of the human study by contradicting their theoretical expectations (anti-immigrant framing of news decreases its persuasion and mobilization); but some significant relationships found in human data (modulation of the effectiveness of populist framing according to relative deprivation of the participant) were not present in the LLM data. Together the two studies support the view that LLMs have potential to act as models of the effect of influence. ","[{'version': 'v1', 'created': 'Fri, 10 Mar 2023 16:53:30 GMT'}]",2023-03-13,"[['Griffin', 'Lewis D', ''], ['Kleinberg', 'Bennett', ''], ['Mozes', 'Maximilian', ''], ['Mai', 'Kimberly T', ''], ['Vau', 'Maria', ''], ['Caldwell', 'Matthew', ''], ['Marvor-Parker', 'Augustine', '']]",0,0,2023-03-10,1,7,1,0,0,0,ab90169f7213482efff246cc5f5f057351265f18,257482410.0,https://www.semanticscholar.org/paper/ab90169f7213482efff246cc5f5f057351265f18,arXiv.org,2023.0,55.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2052553185', 'name': 'L. D. Griffin'}, {'authorId': '6032930', 'name': 'Bennett Kleinberg'}, {'authorId': '37237998', 'name': 'Maximilian Mozes'}, {'authorId': '2080026390', 'name': 'Kimberly T. Mai'}, {'authorId': '2211337108', 'name': 'Maria Vau'}, {'authorId': '2065646864', 'name': 'M. Caldwell'}, {'authorId': '2211337911', 'name': 'Augustine Marvor-Parker'}]","['University College London', 'Tilburg University']","['United Kingdom', 'Netherlands']",2023-03
2303.06233,Iman Saberi,"Iman Saberi, Fatemeh H. Fard",Model-Agnostic Syntactical Information for Pre-Trained Programming Language Models,"11 pages, 5 Figures, Has been accepted on ICSE 2023",,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained Programming Language Models (PPLMs) achieved many recent states of the art results for many code-related software engineering tasks. Though some studies use data flow or propose tree-based models that utilize Abstract Syntax Tree (AST), most PPLMs do not fully utilize the rich syntactical information in source code. Still, the input is considered a sequence of tokens. There are two issues; the first is computational inefficiency due to the quadratic relationship between input length and attention complexity. Second, any syntactical information, when needed as an extra input to the current PPLMs, requires the model to be pre-trained from scratch, wasting all the computational resources already used for pre-training the current models. In this work, we propose Named Entity Recognition (NER) adapters, lightweight modules that can be inserted into Transformer blocks to learn type information extracted from the AST. These adapters can be used with current PPLMs such as CodeBERT, GraphCodeBERT, and CodeT5. We train the NER adapters using a novel Token Type Classification objective function (TTC). We insert our proposed work in CodeBERT, building CodeBERTER, and evaluate the performance on two tasks of code refinement and code summarization. CodeBERTER improves the accuracy of code refinement from 16.4 to 17.8 while using 20% of training parameter budget compared to the fully fine-tuning approach, and the BLEU score of code summarization from 14.75 to 15.90 while reducing 77% of training parameters compared to the fully fine-tuning approach. ","[{'version': 'v1', 'created': 'Fri, 10 Mar 2023 22:47:30 GMT'}]",2023-03-14,"[['Saberi', 'Iman', ''], ['Fard', 'Fatemeh H.', '']]",0,0,2023-03-10,1,2,1,0,0,0,aae61ba5b629eba965b7f49a685b3d9f1bfb358c,257495809.0,https://www.semanticscholar.org/paper/aae61ba5b629eba965b7f49a685b3d9f1bfb358c,IEEE Working Conference on Mining Software Repositories,2023.0,50.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2085891275', 'name': 'Iman Saberi'}, {'authorId': '2619967', 'name': 'F. H. Fard'}]",['University of British Columbia'],['Canada'],2023-03
2303.06273,Myeongjun Jang,"Myeongjun Jang, Thomas Lukasiewicz",Consistency Analysis of ChatGPT,11 pages,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  ChatGPT, a question-and-answer dialogue system based on a large language model, has gained huge popularity since its introduction. Its positive aspects have been reported through many media platforms, and some analyses even showed that ChatGPT achieved a decent grade in professional exams, including the law, medical, and finance domains, adding extra support to the claim that AI now can assist and, even, replace humans in industrial fields. Others, however, doubt its reliability and trustworthiness. In this paper, we investigate ChatGPT's trustworthiness regarding logically consistent behaviours. Our findings suggest that, although ChatGPT seems to achieve an improved language understanding ability, it still fails to generate logically correct predictions frequently. Hence, while it is true that ChatGPT is an impressive and promising new technique, we conclude that its usage in real-world applications without thorough human inspection requires further consideration, especially for risk-sensitive areas. ","[{'version': 'v1', 'created': 'Sat, 11 Mar 2023 01:19:01 GMT'}]",2023-03-14,"[['Jang', 'Myeongjun', ''], ['Lukasiewicz', 'Thomas', '']]",1,1,2023-03-11,1,2,2,1,0,1,f93d5d62a227d0c4ae85c08d7de07d7c2ce28a28,257496270.0,https://www.semanticscholar.org/paper/f93d5d62a227d0c4ae85c08d7de07d7c2ce28a28,arXiv.org,2023.0,59.0,18.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35756238', 'name': 'Myeongjun Jang'}, {'authorId': '1690572', 'name': 'Thomas Lukasiewicz'}]","['TU Wien', 'University of Oxford']","['Austria', 'United Kingdom']",2023-03
2303.06594,Deyao Zhu,"Deyao Zhu, Jun Chen, Kilichbek Haydarov, Xiaoqian Shen, Wenxuan Zhang,
  Mohamed Elhoseiny","ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions",,,,,cs.CV cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Asking insightful questions is crucial for acquiring knowledge and expanding our understanding of the world. However, the importance of questioning has been largely overlooked in AI research, where models have been primarily developed to answer questions. With the recent advancements of large language models (LLMs) like ChatGPT, we discover their capability to ask high-quality questions when provided with a suitable prompt. This discovery presents a new opportunity to develop an automatic questioning system. In this paper, we introduce ChatCaptioner, a novel automatic-questioning method deployed in image captioning. Here, ChatGPT is prompted to ask a series of informative questions about images to BLIP-2, a strong vision question-answering model. By keeping acquiring new visual information from BLIP-2's answers, ChatCaptioner is able to generate more enriched image descriptions. We conduct human-subject evaluations on common image caption datasets such as COCO, Conceptual Caption, and WikiArt, and compare ChatCaptioner with BLIP-2 as well as ground truth. Our results demonstrate that ChatCaptioner's captions are significantly more informative, receiving three times as many votes from human evaluators for providing the most image information. Besides, ChatCaptioner identifies 53% more objects within the image than BLIP-2 alone measured by WordNet synset matching. Code is available at https://github.com/Vision-CAIR/ChatCaptioner ","[{'version': 'v1', 'created': 'Sun, 12 Mar 2023 07:22:08 GMT'}]",2023-03-14,"[['Zhu', 'Deyao', ''], ['Chen', 'Jun', ''], ['Haydarov', 'Kilichbek', ''], ['Shen', 'Xiaoqian', ''], ['Zhang', 'Wenxuan', ''], ['Elhoseiny', 'Mohamed', '']]",1,1,2023-03-12,1,6,3,1,0,1,69cfdc8df16ae63b7acba4ac6f727f78b86893c3,257496234.0,https://www.semanticscholar.org/paper/69cfdc8df16ae63b7acba4ac6f727f78b86893c3,arXiv.org,2023.0,51.0,36.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1388731230', 'name': 'Deyao Zhu'}, {'authorId': '2153417252', 'name': 'Jun Chen'}, {'authorId': '90997182', 'name': 'Kilichbek Haydarov'}, {'authorId': '2151708219', 'name': 'Xiaoqian Shen'}, {'authorId': '150341144', 'name': 'Wenxuan Zhang'}, {'authorId': '1712479', 'name': 'Mohamed Elhoseiny'}]",['King Abdullah University of Science and Technology'],['Saudi Arabia'],2023-03
2303.06748,Arash Dargahi Nobari,Arash Dargahi Nobari and Davood Rafiei,DTT: An Example-Driven Tabular Transformer by Leveraging Large Language Models,,,,,cs.DB,http://creativecommons.org/licenses/by/4.0/,"  Many organizations rely on data from government and third-party sources, and those sources and organizations do not follow the same data formatting. This introduces challenges in integrating data from multiple sources. Commercial database systems do not offer adequate support for integrating data from heterogeneous sources, and manual integration is both time-consuming and inefficient. While state-of-the-art approaches rely on similarity functions and textual transformations, they often fail to handle challenging cases where multiple mappings are required, or the mappings go beyond simple textual transformations. In this paper, we study the potential of deep neural models for transforming tables for joinability. In particular, we cast the problem as a prediction task and develop a framework that leverages large deep-learning language models to transform tabular data from a source formatting to a desired target representation. Our framework can efficiently learn the pattern for mapping the source formatting into the expected target using just a few examples, which can then be used for table joining, filling in missing values, and error detection. Compared to state-of-the-art mapping and joining approaches, our framework delivers noticeably more accurate and scalable performance on both real-world and synthetic datasets. Our experimental evaluation also shows that the performance of the proposed framework using our fine-tuned model is at par or better than large language models such as GPT-3, despite the significant difference in size, and that integrating large language models into our framework improves their performance. ","[{'version': 'v1', 'created': 'Sun, 12 Mar 2023 20:51:26 GMT'}]",2023-03-14,"[['Nobari', 'Arash Dargahi', ''], ['Rafiei', 'Davood', '']]",0,1,2023-03-12,1,2,1,1,0,1,1d405cbbfecd02598bab517a23de50d6d90c0e88,257495879.0,https://www.semanticscholar.org/paper/1d405cbbfecd02598bab517a23de50d6d90c0e88,arXiv.org,2023.0,57.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '22239946', 'name': 'Arash Dargahi Nobari'}, {'authorId': '2144238', 'name': 'Davood Rafiei'}]",['University of Alberta'],['Canada'],2023-03
2303.07304,Stanislav Ivanov,"Nigel Williams, Stanislav Ivanov, Dimitrios Buhalis",Algorithmic Ghost in the Research Shell: Large Language Models and Academic Knowledge Creation in Management Research,14 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The paper looks at the role of large language models in academic knowledge creation based on a scoping review (2018 to January 2023) of how researchers have previously used the language model GPT to assist in the performance of academic knowledge creation tasks beyond data analysis. These tasks include writing, editing, reviewing, dataset creation and curation, which have been difficult to perform using earlier ML tools. Based on a synthesis of these papers, this study identifies pathways for a future academic research landscape that incorporates wider usage of large language models based on the current modes of adoption in published articles as a Co-Writer, Research Assistant and Respondent. ","[{'version': 'v1', 'created': 'Fri, 10 Mar 2023 14:25:29 GMT'}]",2023-03-14,"[['Williams', 'Nigel', ''], ['Ivanov', 'Stanislav', ''], ['Buhalis', 'Dimitrios', '']]",0,1,2023-03-10,1,3,1,0,0,0,bbb6c1d0f6acd23eba24da8dbd474959e4cada0d,257496621.0,https://www.semanticscholar.org/paper/bbb6c1d0f6acd23eba24da8dbd474959e4cada0d,arXiv.org,2023.0,67.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2211426043', 'name': 'Nigel Williams'}, {'authorId': '2054725917', 'name': 'S. Ivanov'}, {'authorId': '1729130', 'name': 'Dimitrios Buhalis'}]","['University of Portsmouth', '. Director, Zangador Research Institute, 9010 Varna, Bulgaria,', 'Bournemouth University', 'Varna University of Management']","['United Kingdom', 'Bulgaria']",2023-03
2303.07351,Wenjun Lin,"Wenjun Lin, Paul Babyn, Yan yan, Wenjun Zhang",Context-based Ontology Modelling for Database: Enabling ChatGPT for Semantic Database Management,,,,,cs.DB,http://creativecommons.org/licenses/by/4.0/,"  This research paper explores the use of ChatGPT in database management. ChatGPT, an AI-powered chatbot, has limitations in performing tasks related to database management due to the lack of standardized vocabulary and grammar for representing database semantics. To address this limitation, the paper proposes a solution that involves developing a set of syntaxes that can represent database semantics in natural language. The syntax is used to convert database schemas into natural language formats, providing a new application of ChatGPT in database management. The proposed solution is demonstrated through a case study where ChatGPT is used to perform two tasks, semantic integration, and tables joining. Results demonstrate that the use of semantic database representations produces more precise outcomes and avoids common mistakes compared to cases with no semantic representation. The proposed method has the potential to speed up the database management process, reduce the level of understanding required for database domain knowledge, and enable automatic database operations without accessing the actual data, thus illuminating privacy protection concerns when using AI. This paper provides a promising new direction for research in the field of AI-based database management. ","[{'version': 'v1', 'created': 'Sat, 11 Mar 2023 23:15:03 GMT'}]",2023-03-15,"[['Lin', 'Wenjun', ''], ['Babyn', 'Paul', ''], ['yan', 'Yan', ''], ['Zhang', 'Wenjun', '']]",1,1,2023-03-11,1,4,1,1,0,1,e93afe882e0e8911a5805c5c9f554d0e97d3060b,257505072.0,https://www.semanticscholar.org/paper/e93afe882e0e8911a5805c5c9f554d0e97d3060b,arXiv.org,2023.0,25.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49661103', 'name': 'Wenjun Lin'}, {'authorId': '14655510', 'name': 'P. Babyn'}, {'authorId': '2117858122', 'name': 'Yan Yan'}, {'authorId': '2118857360', 'name': 'Wenjun Zhang'}]","['University of Saskatchewan', 'Thompson Rivers University']",['Canada'],2023-03
2303.07519,Antonios Liapis,"Theodoros Galanos, Antonios Liapis and Georgios N. Yannakakis",Architext: Language-Driven Generative Architecture Design,21 pages,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Architectural design is a highly complex practice that involves a wide diversity of disciplines, technologies, proprietary design software, expertise, and an almost infinite number of constraints, across a vast array of design tasks. Enabling intuitive, accessible, and scalable design processes is an important step towards performance-driven and sustainable design for all. To that end, we introduce Architext, a novel semantic generation assistive tool. Architext enables design generation with only natural language prompts, given to large-scale Language Models, as input. We conduct a thorough quantitative evaluation of Architext's downstream task performance, focusing on semantic accuracy and diversity for a number of pre-trained language models ranging from 120 million to 6 billion parameters. Architext models are able to learn the specific design task, generating valid residential layouts at a near 100% rate. Accuracy shows great improvement when scaling the models, with the largest model (GPT-J) yielding impressive accuracy ranging between 25% to over 80% for different prompt categories. We open source the finetuned Architext models and our synthetic dataset, hoping to inspire experimentation in this exciting area of design research. ","[{'version': 'v1', 'created': 'Mon, 13 Mar 2023 23:11:05 GMT'}, {'version': 'v2', 'created': 'Wed, 15 Mar 2023 16:07:05 GMT'}, {'version': 'v3', 'created': 'Wed, 3 May 2023 09:29:05 GMT'}]",2023-05-04,"[['Galanos', 'Theodoros', ''], ['Liapis', 'Antonios', ''], ['Yannakakis', 'Georgios N.', '']]",0,1,2023-03-13,3,3,2,0,0,0,7a3f4935d55b8c2cc7fb44d502f128886ccb75c2,257505475.0,https://www.semanticscholar.org/paper/7a3f4935d55b8c2cc7fb44d502f128886ccb75c2,arXiv.org,2023.0,95.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '97764972', 'name': 'Theodoros Galanos'}, {'authorId': '1713331', 'name': 'Antonios Liapis'}, {'authorId': '1686193', 'name': 'Georgios N. Yannakakis'}]",['University of Malta'],['Malta'],2023-03
2303.07678,Liang Wang,"Liang Wang, Nan Yang, Furu Wei",Query2doc: Query Expansion with Large Language Models,9 pages,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper introduces a simple yet effective query expansion approach, denoted as query2doc, to improve both sparse and dense retrieval systems. The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudo-documents. LLMs are trained on web-scale text corpora and are adept at knowledge memorization. The pseudo-documents from LLMs often contain highly relevant information that can aid in query disambiguation and guide the retrievers. Experimental results demonstrate that query2doc boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning. Furthermore, our method also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results. ","[{'version': 'v1', 'created': 'Tue, 14 Mar 2023 07:27:30 GMT'}]",2023-03-15,"[['Wang', 'Liang', ''], ['Yang', 'Nan', ''], ['Wei', 'Furu', '']]",0,0,2023-03-14,1,3,2,0,0,0,ccc772d88c231275f24c4fac9b28bbe0942e1107,257505063.0,https://www.semanticscholar.org/paper/ccc772d88c231275f24c4fac9b28bbe0942e1107,arXiv.org,2023.0,36.0,21.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145769448', 'name': 'Liang Wang'}, {'authorId': '144610884', 'name': 'Nan Yang'}, {'authorId': '49807919', 'name': 'Furu Wei'}]",['Microsoft'],['India'],2023-03
2303.07895,Noam Wies,"Noam Wies, Yoav Levine, Amnon Shashua",The Learnability of In-Context Learning,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In-context learning is a surprising and important phenomenon that emerged when modern language models were scaled to billions of learned parameters. Without modifying a large language model's weights, it can be tuned to perform various downstream natural language tasks simply by including concatenated training examples of these tasks in its input. Though disruptive for many practical applications of large language models, this emergent learning paradigm is not well understood from a theoretical perspective. In this paper, we propose a first-of-its-kind PAC based framework for in-context learnability, and use it to provide the first finite sample complexity results for the in-context learning setup. Our framework includes an initial pretraining phase, which fits a function to the pretraining distribution, and then a second in-context learning phase, which keeps this function constant and concatenates training examples of the downstream task in its input. We use our framework in order to prove that, under mild assumptions, when the pretraining distribution is a mixture of latent tasks (a model often considered for natural language pretraining), these tasks can be efficiently learned via in-context learning, even though the model's weights are unchanged and the input significantly diverges from the pretraining distribution. Our theoretical analysis reveals that in this setting, in-context learning is more about identifying the task than about learning it, a result which is in line with a series of recent empirical findings. We hope that the in-context learnability framework presented in this paper will facilitate future progress towards a deeper understanding of this important new learning paradigm. ","[{'version': 'v1', 'created': 'Tue, 14 Mar 2023 13:28:39 GMT'}]",2023-03-15,"[['Wies', 'Noam', ''], ['Levine', 'Yoav', ''], ['Shashua', 'Amnon', '']]",0,0,2023-03-14,1,3,1,0,0,0,da3aca9d7b50da823f669c983edeb60445720fe0,257505009.0,https://www.semanticscholar.org/paper/da3aca9d7b50da823f669c983edeb60445720fe0,arXiv.org,2023.0,39.0,20.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '69978543', 'name': 'Noam Wies'}, {'authorId': '152754428', 'name': 'Yoav Levine'}, {'authorId': '3140335', 'name': 'A. Shashua'}]",['Hebrew University of Jerusalem'],['Israel'],2023-03
2303.07971,Michael Hahn,"Michael Hahn, Navin Goyal",A Theory of Emergent In-Context Learning as Implicit Structure Induction,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Scaling large language models (LLMs) leads to an emergent capacity to learn in-context from example demonstrations. Despite progress, theoretical understanding of this phenomenon remains limited. We argue that in-context learning relies on recombination of compositional operations found in natural language data. We derive an information-theoretic bound showing how in-context learning abilities arise from generic next-token prediction when the pretraining distribution has sufficient amounts of compositional structure, under linguistically motivated assumptions. A second bound provides a theoretical justification for the empirical success of prompting LLMs to output intermediate steps towards an answer. To validate theoretical predictions, we introduce a controlled setup for inducing in-context learning; unlike previous approaches, it accounts for the compositional nature of language. Trained transformers can perform in-context learning for a range of tasks, in a manner consistent with the theoretical results. Mirroring real-world LLMs in a miniature setup, in-context learning emerges when scaling parameters and data, and models perform better when prompted to output intermediate steps. Probing shows that in-context learning is supported by a representation of the input's compositional structure. Taken together, these results provide a step towards theoretical understanding of emergent behavior in large language models. ","[{'version': 'v1', 'created': 'Tue, 14 Mar 2023 15:24:05 GMT'}]",2023-03-15,"[['Hahn', 'Michael', ''], ['Goyal', 'Navin', '']]",0,0,2023-03-14,1,2,2,0,0,0,0ea7fc93d4947d9024ccaa202987a2070683bc1f,257505037.0,https://www.semanticscholar.org/paper/0ea7fc93d4947d9024ccaa202987a2070683bc1f,arXiv.org,2023.0,87.0,26.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46686009', 'name': 'Michael Hahn'}, {'authorId': '144260125', 'name': 'Navin Goyal'}]","['Saarland University', 'Microsoft']","['Germany', 'India']",2023-03
2303.08233,Timothy Yu,"Rindranirina Ramamonjison, Timothy T. Yu, Raymond Li, Haley Li,
  Giuseppe Carenini, Bissan Ghaddar, Shiqi He, Mahdi Mostajabdaveh, Amin
  Banitalebi-Dehkordi, Zirui Zhou, Yong Zhang",NL4Opt Competition: Formulating Optimization Problems Based on Their Natural Language Descriptions,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Natural Language for Optimization (NL4Opt) Competition was created to investigate methods of extracting the meaning and formulation of an optimization problem based on its text description. Specifically, the goal of the competition is to increase the accessibility and usability of optimization solvers by allowing non-experts to interface with them using natural language. We separate this challenging goal into two sub-tasks: (1) recognize and label the semantic entities that correspond to the components of the optimization problem; (2) generate a meaning representation (i.e., a logical form) of the problem from its detected problem entities. The first task aims to reduce ambiguity by detecting and tagging the entities of the optimization problems. The second task creates an intermediate representation of the linear programming (LP) problem that is converted into a format that can be used by commercial solvers. In this report, we present the LP word problem dataset and shared tasks for the NeurIPS 2022 competition. Furthermore, we investigate and compare the performance of the ChatGPT large language model against the winning solutions. Through this competition, we hope to bring interest towards the development of novel machine learning applications and datasets for optimization modeling. ","[{'version': 'v1', 'created': 'Tue, 14 Mar 2023 20:59:04 GMT'}, {'version': 'v2', 'created': 'Mon, 27 Mar 2023 01:10:12 GMT'}]",2023-03-28,"[['Ramamonjison', 'Rindranirina', ''], ['Yu', 'Timothy T.', ''], ['Li', 'Raymond', ''], ['Li', 'Haley', ''], ['Carenini', 'Giuseppe', ''], ['Ghaddar', 'Bissan', ''], ['He', 'Shiqi', ''], ['Mostajabdaveh', 'Mahdi', ''], ['Banitalebi-Dehkordi', 'Amin', ''], ['Zhou', 'Zirui', ''], ['Zhang', 'Yong', '']]",1,1,2023-03-14,2,11,2,1,0,1,c9a9735216915e9afa0fc97b02b57148a0491bdd,257532906.0,https://www.semanticscholar.org/paper/c9a9735216915e9afa0fc97b02b57148a0491bdd,arXiv.org,2023.0,40.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2511592', 'name': 'Rindranirina Ramamonjison'}, {'authorId': '2186749367', 'name': 'Timothy T. Yu'}, {'authorId': '51169841', 'name': 'Raymond Li'}, {'authorId': '2186795302', 'name': 'Haley Li'}, {'authorId': '1825424', 'name': 'G. Carenini'}, {'authorId': '1821932', 'name': 'Bissan Ghaddar'}, {'authorId': '2115303738', 'name': 'Shiqi He'}, {'authorId': '121967269', 'name': 'Mahdi Mostajabdaveh'}, {'authorId': '1398288379', 'name': 'Amin Banitalebi-Dehkordi'}, {'authorId': '2610961', 'name': 'Zirui Zhou'}, {'authorId': '33603226', 'name': 'Yong Zhang'}]","['University of British Columbia', 'University of Toronto', 'Huawei Technologies (Canada)']",['Canada'],2023-03
2303.08288,Valeria Ruscio,"Valeria Ruscio, Valentino Maiorca, Fabrizio Silvestri",Attention-likelihood relationship in transformers,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We analyze how large language models (LLMs) represent out-of-context words, investigating their reliance on the given context to capture their semantics. Our likelihood-guided text perturbations reveal a correlation between token likelihood and attention values in transformer-based language models. Extensive experiments reveal that unexpected tokens cause the model to attend less to the information coming from themselves to compute their representations, particularly at higher layers. These findings have valuable implications for assessing the robustness of LLMs in real-world scenarios. Fully reproducible codebase at https://github.com/Flegyas/AttentionLikelihood. ","[{'version': 'v1', 'created': 'Wed, 15 Mar 2023 00:23:49 GMT'}]",2023-03-16,"[['Ruscio', 'Valeria', ''], ['Maiorca', 'Valentino', ''], ['Silvestri', 'Fabrizio', '']]",0,0,2023-03-15,1,3,2,0,0,0,d51c94df736ed7916af86f9162eb89f03fc6b0d4,257532523.0,https://www.semanticscholar.org/paper/d51c94df736ed7916af86f9162eb89f03fc6b0d4,Tiny Papers @ ICLR,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2211603121', 'name': 'Valeria Ruscio'}, {'authorId': '2140400495', 'name': 'Valentino Maiorca'}, {'authorId': '2192306989', 'name': 'Fabrizio Silvestri'}]",['Sapienza University of Rome'],['Italy'],2023-03
2303.08559,Yubo Ma,"Yubo Ma, Yixin Cao, YongChing Hong, Aixin Sun","Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have made remarkable strides in various tasks. However, whether they are competitive few-shot solvers for information extraction (IE) tasks and surpass fine-tuned small Pre-trained Language Models (SLMs) remains an open problem. This paper aims to provide a thorough answer to this problem, and moreover, to explore an approach towards effective and economical IE systems that combine the strengths of LLMs and SLMs. Through extensive experiments on eight datasets across three IE tasks, we show that LLMs are not effective few-shot information extractors in general, given their unsatisfactory performance in most settings and the high latency and budget requirements. However, we demonstrate that LLMs can well complement SLMs and effectively solve hard samples that SLMs struggle with. Building on these findings, we propose an adaptive filter-then-rerank paradigm, in which SLMs act as filters and LLMs act as rerankers. By utilizing LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.1% F1-gain on average) on various IE tasks, with acceptable cost of time and money. ","[{'version': 'v1', 'created': 'Wed, 15 Mar 2023 12:20:13 GMT'}]",2023-03-16,"[['Ma', 'Yubo', ''], ['Cao', 'Yixin', ''], ['Hong', 'YongChing', ''], ['Sun', 'Aixin', '']]",0,0,2023-03-15,1,4,2,0,0,0,0100785773b8217c44606ab260e3212f93b0a4fd,257532405.0,https://www.semanticscholar.org/paper/0100785773b8217c44606ab260e3212f93b0a4fd,arXiv.org,2023.0,76.0,26.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143557418', 'name': 'Yubo Ma'}, {'authorId': '145014675', 'name': 'Yixin Cao'}, {'authorId': '2211625121', 'name': 'YongChing Hong'}, {'authorId': '1735962', 'name': 'Aixin Sun'}]","['Nanyang Technological University', 'Singapore Management University']",['Singapore'],2023-03
2303.08652,Nestor Prieto-Chavana,"Nestor Prieto-Chavana, Julie Weeds, David Weir",Automated Query Generation for Evidence Collection from Web Search Engines,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  It is widely accepted that so-called facts can be checked by searching for information on the Internet. This process requires a fact-checker to formulate a search query based on the fact and to present it to a search engine. Then, relevant and believable passages need to be identified in the search results before a decision is made. This process is carried out by sub-editors at many news and media organisations on a daily basis. Here, we ask the question as to whether it is possible to automate the first step, that of query generation. Can we automatically formulate search queries based on factual statements which are similar to those formulated by human experts? Here, we consider similarity both in terms of textual similarity and with respect to relevant documents being returned by a search engine. First, we introduce a moderate-sized evidence collection dataset which includes 390 factual statements together with associated human-generated search queries and search results. Then, we investigate generating queries using a number of rule-based and automatic text generation methods based on pre-trained large language models (LLMs). We show that these methods have different merits and propose a hybrid approach which has superior performance in practice. ","[{'version': 'v1', 'created': 'Wed, 15 Mar 2023 14:32:00 GMT'}]",2023-03-16,"[['Prieto-Chavana', 'Nestor', ''], ['Weeds', 'Julie', ''], ['Weir', 'David', '']]",0,0,2023-03-15,1,3,2,0,0,0,7d09a0c2b0f1aef3d7e9cfcf8e72081f9ed4b89a,257532923.0,https://www.semanticscholar.org/paper/7d09a0c2b0f1aef3d7e9cfcf8e72081f9ed4b89a,arXiv.org,2023.0,23.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2211606362', 'name': 'Nestor Prieto-Chavana'}, {'authorId': '2500077', 'name': 'Julie Weeds'}, {'authorId': '2106279802', 'name': 'David Weir'}]",['University of Sussex'],['United Kingdom'],2023-03
2303.08896,Potsawee Manakul,"Potsawee Manakul, Adian Liusie, Mark J. F. Gales",SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models,"13 pages, update to include additional results and larger dataset",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts. However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output. Existing fact-checking approaches either require access to the output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate, often complex, modules. In this work, we propose ""SelfCheckGPT"", a simple sampling-based approach that can be used to fact-check black-box models in a zero-resource fashion, i.e. without an external database. SelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given concept, sampled responses are likely to be similar and contain consistent facts. However, for hallucinated facts, stochastically sampled responses are likely to diverge and contradict one another. We investigate this approach by using GPT-3 to generate passages about individuals from the WikiBio dataset, and manually annotate the factuality of the generated passages. We demonstrate that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii) rank passages in terms of factuality. We compare our approach to several baselines and show that in sentence hallucination detection, our approach has AUC-PR scores comparable to or better than grey-box methods, while SelfCheckGPT is best at passage factuality assessment. ","[{'version': 'v1', 'created': 'Wed, 15 Mar 2023 19:31:21 GMT'}, {'version': 'v2', 'created': 'Mon, 8 May 2023 00:52:42 GMT'}]",2023-05-09,"[['Manakul', 'Potsawee', ''], ['Liusie', 'Adian', ''], ['Gales', 'Mark J. F.', '']]",1,1,2023-03-15,2,3,1,2,0,2,7c1707db9aafd209aa93db3251e7ebd593d55876,257557820.0,https://www.semanticscholar.org/paper/7c1707db9aafd209aa93db3251e7ebd593d55876,arXiv.org,2023.0,47.0,100.0,14.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '89355510', 'name': 'Potsawee Manakul'}, {'authorId': '2190750613', 'name': 'Adian Liusie'}, {'authorId': '1740397', 'name': 'M. Gales'}]",['University of Cambridge'],['United Kingdom'],2023-03
2303.09384,Nicolas E. Diaz Ferreyra PhD,"Catherine Tony, Markus Mutas, Nicol\'as E. D\'iaz Ferreyra and
  Riccardo Scandariato",LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations,Accepted at MSR '23 Data and Tool Showcase Track,,,,cs.SE cs.IR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications, the security of the code they generate has not been extensively investigated nor documented. In this work, we present LLMSecEval, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE's Top 25 Common Weakness Enumeration (CWE) ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by LLMs. As a practical application, we show how LLMSecEval can be used for evaluating the security of snippets automatically generated from NL descriptions. ","[{'version': 'v1', 'created': 'Thu, 16 Mar 2023 15:13:58 GMT'}]",2023-03-17,"[['Tony', 'Catherine', ''], ['Mutas', 'Markus', ''], ['Ferreyra', 'Nicolás E. Díaz', ''], ['Scandariato', 'Riccardo', '']]",0,0,2023-03-16,1,4,3,1,0,1,8205612a6d15df52b8c3d26aabfd50abc10fdee3,257557620.0,https://www.semanticscholar.org/paper/8205612a6d15df52b8c3d26aabfd50abc10fdee3,IEEE Working Conference on Mining Software Repositories,2023.0,19.0,10.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2164989094', 'name': 'Catherine Tony'}, {'authorId': '2211737182', 'name': 'Markus Mutas'}, {'authorId': '2210729647', 'name': ""Nicol'as E. D'iaz Ferreyra""}, {'authorId': '1723601', 'name': 'R. Scandariato'}]",['Hamburg University of Technology'],['Germany'],2023-03
2303.09461,Sebastian Bordt,"Sebastian Bordt, Ulrike von Luxburg",ChatGPT Participates in a Computer Science Exam,,,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We asked ChatGPT to participate in an undergraduate computer science exam on ''Algorithms and Data Structures''. The program was evaluated on the entire exam as posed to the students. We hand-copied its answers onto an exam sheet, which was subsequently graded in a blind setup alongside those of 200 participating students. We find that ChatGPT narrowly passed the exam, obtaining 20.5 out of 40 points. This impressive performance indicates that ChatGPT can indeed succeed in challenging tasks like university exams. At the same time, the questions in our exam are structurally similar to those of other exams, solved homework problems, and teaching materials that can be found online and might have been part of ChatGPT's training data. Therefore, it would be inadequate to conclude from this experiment that ChatGPT has any understanding of computer science. We also assess the improvements brought by GPT-4. We find that GPT-4 would have obtained about 17\% more exam points than GPT-3.5, reaching the performance of the average student. The transcripts of our conversations with ChatGPT are available at \url{https://github.com/tml-tuebingen/chatgpt-algorithm-exam}, and the entire graded exam is in the appendix of this paper. ","[{'version': 'v1', 'created': 'Wed, 8 Mar 2023 15:46:14 GMT'}, {'version': 'v2', 'created': 'Wed, 22 Mar 2023 11:30:41 GMT'}]",2023-03-23,"[['Bordt', 'Sebastian', ''], ['von Luxburg', 'Ulrike', '']]",1,1,2023-03-08,2,2,2,3,0,3,b92b8a32f89f45cd771359e3351f6ddcad61450c,257557508.0,https://www.semanticscholar.org/paper/b92b8a32f89f45cd771359e3351f6ddcad61450c,arXiv.org,2023.0,25.0,16.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '1802528351', 'name': 'Sebastian Bordt'}, {'authorId': '1728654', 'name': 'U. V. Luxburg'}]",['University of Tübingen'],['Germany'],2023-03
2303.09604,Yizhi Wang,"Maham Tanveer, Yizhi Wang, Ali Mahdavi-Amiri, Hao Zhang",DS-Fusion: Artistic Typography via Discriminated and Stylized Diffusion,Project website: https://ds-fusion.github.io/,,,,cs.CV cs.GR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce a novel method to automatically generate an artistic typography by stylizing one or more letter fonts to visually convey the semantics of an input word, while ensuring that the output remains readable. To address an assortment of challenges with our task at hand including conflicting goals (artistic stylization vs. legibility), lack of ground truth, and immense search space, our approach utilizes large language models to bridge texts and visual images for stylization and build an unsupervised generative model with a diffusion model backbone. Specifically, we employ the denoising generator in Latent Diffusion Model (LDM), with the key addition of a CNN-based discriminator to adapt the input style onto the input text. The discriminator uses rasterized images of a given letter/word font as real samples and output of the denoising generator as fake samples. Our model is coined DS-Fusion for discriminated and stylized diffusion. We showcase the quality and versatility of our method through numerous examples, qualitative and quantitative evaluation, as well as ablation studies. User studies comparing to strong baselines including CLIPDraw and DALL-E 2, as well as artist-crafted typographies, demonstrate strong performance of DS-Fusion. ","[{'version': 'v1', 'created': 'Thu, 16 Mar 2023 19:12:52 GMT'}]",2023-03-20,"[['Tanveer', 'Maham', ''], ['Wang', 'Yizhi', ''], ['Mahdavi-Amiri', 'Ali', ''], ['Zhang', 'Hao', '']]",0,0,2023-03-16,1,4,2,0,0,0,aa0a524204eef1ce9d46dc9521e808b0e3753d37,257622548.0,https://www.semanticscholar.org/paper/aa0a524204eef1ce9d46dc9521e808b0e3753d37,arXiv.org,2023.0,39.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1720747030', 'name': 'Maham Tanveer'}, {'authorId': '2107971586', 'name': 'Yizhi Wang'}, {'authorId': '1399132068', 'name': 'Ali Mahdavi-Amiri'}, {'authorId': '38952862', 'name': 'Hao Zhang'}]",['Simon Fraser University'],['Canada'],2023-03
2303.10131,Hideaki Hata,"Christoph Treude, Hideaki Hata",She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models,"6 pages, MSR 2023",,,,cs.SE cs.AI cs.CY cs.LG,http://creativecommons.org/publicdomain/zero/1.0/,"  Implicit gender bias in software development is a well-documented issue, such as the association of technical roles with men. To address this bias, it is important to understand it in more detail. This study uses data mining techniques to investigate the extent to which 56 tasks related to software development, such as assigning GitHub issues and testing, are affected by implicit gender bias embedded in large language models. We systematically translated each task from English into a genderless language and back, and investigated the pronouns associated with each task. Based on translating each task 100 times in different permutations, we identify a significant disparity in the gendered pronoun associations with different tasks. Specifically, requirements elicitation was associated with the pronoun ""he"" in only 6% of cases, while testing was associated with ""he"" in 100% of cases. Additionally, tasks related to helping others had a 91% association with ""he"" while the same association for tasks related to asking coworkers was only 52%. These findings reveal a clear pattern of gender bias related to software development tasks and have important implications for addressing this issue both in the training of large language models and in broader society. ","[{'version': 'v1', 'created': 'Fri, 17 Mar 2023 17:16:53 GMT'}]",2023-03-20,"[['Treude', 'Christoph', ''], ['Hata', 'Hideaki', '']]",0,0,2023-03-17,1,2,4,0,0,0,1b2740b71a50bd5c0d8350485f0b86672dcee57c,257622664.0,https://www.semanticscholar.org/paper/1b2740b71a50bd5c0d8350485f0b86672dcee57c,IEEE Working Conference on Mining Software Repositories,2023.0,30.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1685418', 'name': 'Christoph Treude'}, {'authorId': '145050815', 'name': 'Hideaki Hata'}]","['University of Melbourne', 'Shinshu University']","['Japan', 'Australia']",2023-03
2303.10612,H.A.Z.Sameen Shahgir,"H.A.Z. Sameen Shahgir, Khondker Salman Sayeed",Bangla Grammatical Error Detection Using T5 Transformer Model,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  This paper presents a method for detecting grammatical errors in Bangla using a Text-to-Text Transfer Transformer (T5) Language Model, using the small variant of BanglaT5, fine-tuned on a corpus of 9385 sentences where errors were bracketed by the dedicated demarcation symbol. The T5 model was primarily designed for translation and is not specifically designed for this task, so extensive post-processing was necessary to adapt it to the task of error detection. Our experiments show that the T5 model can achieve low Levenshtein Distance in detecting grammatical errors in Bangla, but post-processing is essential to achieve optimal performance. The final average Levenshtein Distance after post-processing the output of the fine-tuned model was 1.0394 on a test set of 5000 sentences. This paper also presents a detailed analysis of the errors detected by the model and discusses the challenges of adapting a translation model for grammar. Our approach can be extended to other languages, demonstrating the potential of T5 models for detecting grammatical errors in a wide range of languages. ","[{'version': 'v1', 'created': 'Sun, 19 Mar 2023 09:24:48 GMT'}]",2023-03-21,"[['Shahgir', 'H. A. Z. Sameen', ''], ['Sayeed', 'Khondker Salman', '']]",0,0,2023-03-19,1,2,2,1,1,0,4cc18022d53829bd6c605d7e7c03805b911f27da,257631961.0,https://www.semanticscholar.org/paper/4cc18022d53829bd6c605d7e7c03805b911f27da,arXiv.org,2023.0,13.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2184775655', 'name': 'H.A.Z. Sameen Shahgir'}, {'authorId': '2184774573', 'name': 'Khondker Salman Sayeed'}]",['Bangladesh University of Engineering and Technology'],['Bangladesh'],2023-03
2303.10831,Ned Cooper,Ned Cooper,Bridging Deliberative Democracy and Deployment of Societal-Scale Technology,3 pages,"CHI 2023 Workshop on Designing Technology and Policy
  Simultaneously",,,cs.CY cs.HC,http://creativecommons.org/licenses/by/4.0/,"  This position paper encourages the Human-Computer Interaction (HCI) community to focus on designing deliberative processes to inform and coordinate technology and policy design for large language models (LLMs) -- a `societal-scale technology'. First, I propose a definition for societal-scale technology and locate LLMs within this definition. Next, I argue that existing processes to ensure the safety of LLMs are insufficient and do not give the systems democratic legitimacy. Instead, we require processes of deliberation amongst users and other stakeholders on questions about the safety of outputs and deployment contexts. This shift in AI safety research and practice will require the design of corporate and public policies that determine how to enact deliberation and the design of interfaces and technical features to translate the outcomes of deliberation into technical development processes. To conclude, I propose roles for the HCI community to ensure deliberative processes inform technology and policy design for LLMs and other societal-scale technology. ","[{'version': 'v1', 'created': 'Mon, 20 Mar 2023 02:27:52 GMT'}, {'version': 'v2', 'created': 'Mon, 27 Mar 2023 04:47:19 GMT'}]",2023-05-03,"[['Cooper', 'Ned', '']]",0,0,2023-03-20,2,1,2,0,0,0,807ac9b8e1ac3ad16fae436b5c7ffea060a0e461,257632350.0,https://www.semanticscholar.org/paper/807ac9b8e1ac3ad16fae436b5c7ffea060a0e461,arXiv.org,2023.0,8.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '27741887', 'name': 'Ned Cooper'}]",['Australian National University'],['Australia'],2023-03
2303.11146,Martin Pere\v{s}\'ini,"Kamil Malinka, Martin Pere\v{s}\'ini, Anton Firc, Ond\v{r}ej
  Huj\v{n}\'ak and Filip Janu\v{s}",On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?,,"Proceedings of the 2023 Conference on Innovation and Technology in
  Computer Science Education ITiCSE. June 2023. Pages 47-53",10.1145/3587102.3588827,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion. ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse. In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization. We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers. We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs. While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system. For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process. Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT. ","[{'version': 'v1', 'created': 'Mon, 20 Mar 2023 14:27:37 GMT'}]",2023-07-04,"[['Malinka', 'Kamil', ''], ['Perešíni', 'Martin', ''], ['Firc', 'Anton', ''], ['Hujňák', 'Ondřej', ''], ['Januš', 'Filip', '']]",1,1,2023-03-20,1,5,1,1,0,1,6d3f29545fa059f7d24e27aaa9351750636d12ce,257631490.0,https://www.semanticscholar.org/paper/6d3f29545fa059f7d24e27aaa9351750636d12ce,Annual Conference on Innovation and Technology in Computer Science Education,2023.0,24.0,42.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2271337', 'name': 'K. Malinka'}, {'authorId': '2127510451', 'name': 'Martin Peresíni'}, {'authorId': '2164254243', 'name': 'Anton Firc'}, {'authorId': '32441905', 'name': 'Ondřej Hujňák'}, {'authorId': '2212471426', 'name': 'Filip Janus'}]",['Brno University of Technology'],['Czechia'],2023-03
2303.11192,Vil\'em Zouhar,"Vil\'em Zouhar, Sunit Bhattacharya, Ond\v{r}ej Bojar",Multimodal Shannon Game with Images,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The Shannon game has long been used as a thought experiment in linguistics and NLP, asking participants to guess the next letter in a sentence based on its preceding context. We extend the game by introducing an optional extra modality in the form of image information. To investigate the impact of multimodal information in this game, we use human participants and a language model (LM, GPT-2). We show that the addition of image information improves both self-reported confidence and accuracy for both humans and LM. Certain word classes, such as nouns and determiners, benefit more from the additional modality information. The priming effect in both humans and the LM becomes more apparent as the context size (extra modality information + sentence context) increases. These findings highlight the potential of multimodal information in improving language understanding and modeling. ","[{'version': 'v1', 'created': 'Mon, 20 Mar 2023 15:22:11 GMT'}]",2023-03-21,"[['Zouhar', 'Vilém', ''], ['Bhattacharya', 'Sunit', ''], ['Bojar', 'Ondřej', '']]",0,1,2023-03-20,1,3,1,1,1,0,e0d667314eb87456ec9598b94dc6cfc66426c188,257631586.0,https://www.semanticscholar.org/paper/e0d667314eb87456ec9598b94dc6cfc66426c188,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1429837660', 'name': 'Vilém Zouhar'}, {'authorId': '23111652', 'name': 'Sunit Bhattacharya'}, {'authorId': '151158933', 'name': 'Ondvrej Bojar'}]",['Charles University'],['Czechia'],2023-03
2303.11403,Mustafa Shukor,"Mustafa Shukor, Corentin Dancette, Matthieu Cord",eP-ALM: Efficient Perceptual Augmentation of Language Models,"Accepted at ICCV 2023. Project page:
  https://mshukor.github.io/eP-ALM.github.io/",,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have so far impressed the world, with unprecedented capabilities that emerge in models at large scales. On the vision side, transformer models (i.e., ViT) are following the same trend, achieving the best performance on challenging benchmarks. With the abundance of such unimodal models, a natural question arises; do we need also to follow this trend to tackle multimodal tasks? In this work, we propose to rather direct effort to efficient adaptations of existing models, and propose to augment Language Models with perception. Existing approaches for adapting pretrained models for vision-language tasks still rely on several key components that hinder their efficiency. In particular, they still train a large number of parameters, rely on large multimodal pretraining, use encoders (e.g., CLIP) trained on huge image-text datasets, and add significant inference overhead. In addition, most of these approaches have focused on Zero-Shot and In Context Learning, with little to no effort on direct finetuning. We investigate the minimal computational effort needed to adapt unimodal models for multimodal tasks and propose a new challenging setup, alongside different approaches, that efficiently adapts unimodal pretrained models. We show that by freezing more than 99% of total parameters, training only one linear projection layer, and prepending only one trainable token, our approach (dubbed eP-ALM) significantly outperforms other baselines on VQA and Captioning across Image, Video, and Audio modalities, following the proposed setup. The code is available here: https://github.com/mshukor/eP-ALM. ","[{'version': 'v1', 'created': 'Mon, 20 Mar 2023 19:20:34 GMT'}, {'version': 'v2', 'created': 'Mon, 12 Jun 2023 20:52:37 GMT'}, {'version': 'v3', 'created': 'Sat, 5 Aug 2023 08:25:01 GMT'}]",2023-08-08,"[['Shukor', 'Mustafa', ''], ['Dancette', 'Corentin', ''], ['Cord', 'Matthieu', '']]",0,0,2023-03-20,3,3,3,0,0,0,c5b2243baf88a00db2d4e4f9edb33cde08eb153f,257636922.0,https://www.semanticscholar.org/paper/c5b2243baf88a00db2d4e4f9edb33cde08eb153f,arXiv.org,2023.0,111.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067292515', 'name': 'Mustafa Shukor'}, {'authorId': '41020827', 'name': 'Corentin Dancette'}, {'authorId': '51021910', 'name': 'M. Cord'}]",['Sorbonne Université'],['France'],2023-03
2303.11436,Manmeet Singh,"Sifatkaur Dhingra, Manmeet Singh, Vaisakh SB, Neetiraj Malviya,
  Sukhpal Singh Gill",Mind meets machine: Unravelling GPT-4's cognitive psychology,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Cognitive psychology delves on understanding perception, attention, memory, language, problem-solving, decision-making, and reasoning. Large language models (LLMs) are emerging as potent tools increasingly capable of performing human-level tasks. The recent development in the form of GPT-4 and its demonstrated success in tasks complex to humans exam and complex problems has led to an increased confidence in the LLMs to become perfect instruments of intelligence. Although GPT-4 report has shown performance on some cognitive psychology tasks, a comprehensive assessment of GPT-4, via the existing well-established datasets is required. In this study, we focus on the evaluation of GPT-4's performance on a set of cognitive psychology datasets such as CommonsenseQA, SuperGLUE, MATH and HANS. In doing so, we understand how GPT-4 processes and integrates cognitive psychology with contextual information, providing insight into the underlying cognitive processes that enable its ability to generate the responses. We show that GPT-4 exhibits a high level of accuracy in cognitive psychology tasks relative to the prior state-of-the-art models. Our results strengthen the already available assessments and confidence on GPT-4's cognitive psychology abilities. It has significant potential to revolutionize the field of AI, by enabling machines to bridge the gap between human and machine reasoning. ","[{'version': 'v1', 'created': 'Mon, 20 Mar 2023 20:28:26 GMT'}, {'version': 'v2', 'created': 'Wed, 12 Apr 2023 15:46:20 GMT'}]",2023-04-13,"[['Dhingra', 'Sifatkaur', ''], ['Singh', 'Manmeet', ''], ['SB', 'Vaisakh', ''], ['Malviya', 'Neetiraj', ''], ['Gill', 'Sukhpal Singh', '']]",0,1,2023-03-20,2,5,2,1,0,1,fc3fe217de5d8de1a5814daf94de52e0d941cf21,257636780.0,https://www.semanticscholar.org/paper/fc3fe217de5d8de1a5814daf94de52e0d941cf21,"BenchCouncil Transactions on Benchmarks, Standards and Evaluations",2023.0,29.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2214275065', 'name': 'Sifatkaur Dhingra'}, {'authorId': '2110677193', 'name': 'Manmeet Singh'}, {'authorId': '2237189770', 'name': 'Vaisakh S.B.'}, {'authorId': '2212369015', 'name': 'Neetiraj Malviya'}, {'authorId': '31043248', 'name': 'S. S. Gill'}]","['Queen Mary University of London', 'Indian Institute of Tropical Meteorology', 'Defence Institute of Advanced Technology', 'Department of Psychology, Nowrosjee Wadia College Pune, India']","['India', 'United Kingdom']",2023-03
2303.11708,Gabriel Skantze,"Gabriel Skantze, A. Seza Do\u{g}ru\""oz",The Open-domain Paradox for Chatbots: Common Ground as the Basis for Human-like Dialogue,Accepted at SIGDIAL 2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The ""openness"" of the dialogue is expected to be maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to ""just chat about anything"" results in a very narrow form of dialogue, which we refer to as the ""open-domain paradox"". In this position paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue. ","[{'version': 'v1', 'created': 'Tue, 21 Mar 2023 10:01:49 GMT'}, {'version': 'v2', 'created': 'Fri, 28 Jul 2023 09:22:02 GMT'}]",2023-07-31,"[['Skantze', 'Gabriel', ''], ['Doğruöz', 'A. Seza', '']]",0,0,2023-03-21,2,2,1,0,0,0,60b2cced15208f42f967ef3ab396dd45fea4dbf2,257636531.0,https://www.semanticscholar.org/paper/60b2cced15208f42f967ef3ab396dd45fea4dbf2,SIGDIAL Conferences,2023.0,46.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '103081544', 'name': 'G. Skantze'}, {'authorId': '1904399', 'name': 'A. Seza Doğruöz'}]","['KTH Royal Institute of Technology', 'Ghent University']","['Belgium', 'Sweden']",2023-03
2303.12003,Jennifer Haase,Jennifer Haase and Paul H. P. Hanel,Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity,"17 pages, 3 figures, 1 table",,,,cs.AI cs.HC,http://creativecommons.org/licenses/by/4.0/,"  A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: $alpa.\!ai$, $Copy.\!ai$, ChatGPT (versions 3 and 4), $Studio.\!ai$, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 percent of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being truly creative. ","[{'version': 'v1', 'created': 'Tue, 21 Mar 2023 16:35:01 GMT'}]",2023-03-22,"[['Haase', 'Jennifer', ''], ['Hanel', 'Paul H. P.', '']]",1,1,2023-03-21,1,2,2,2,0,2,10a372a03eaf893f126e17f03f203d60164fce7c,257637118.0,https://www.semanticscholar.org/paper/10a372a03eaf893f126e17f03f203d60164fce7c,Journal of Creativity,2023.0,68.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '144429802', 'name': 'J. Haase'}, {'authorId': '3352153', 'name': 'P. Hanel'}]","['Weizenbaum Institute for the Networked Society', 'University of Essex', 'Department of Computer Science, Humboldt University, Berlin, Germany,']","['Germany', 'United Kingdom']",2023-03
2303.12279,Eason Chen,Eason Chen,Generate labeled training data using Prompt Programming and GPT-3. An example of Big Five Personality Classification,"6 pages, pre-print",,,,cs.HC cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We generated 25000 conversations labeled with Big Five Personality traits using prompt programming at GPT-3. Then we train Big Five classification models with these data and evaluate them with 2500 data from generated dialogues and real conversational datasets labeled in Big Five by human annotators. The results indicated that this approach is promising for creating effective training data. We then compare the performance by different training approaches and models. Our results suggest that using Adapter-Transformers and transfer learning from pre-trained RoBERTa sentiment analysis model will perform best with the generated data. Our best model obtained an accuracy of 0.71 in generated data and 0.65 in real datasets. Finally, we discuss this approach's potential limitations and confidence metric. ","[{'version': 'v1', 'created': 'Wed, 22 Mar 2023 03:12:40 GMT'}]",2023-03-23,"[['Chen', 'Eason', '']]",0,1,2023-03-22,1,1,2,1,0,1,24c6cc7626ffcf10abd4af9738372ed520f11ad9,257663904.0,https://www.semanticscholar.org/paper/24c6cc7626ffcf10abd4af9738372ed520f11ad9,arXiv.org,2023.0,19.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2113753556', 'name': 'Eason Chen'}]",['National Taiwan Normal University'],['Taiwan'],2023-03
2303.12429,Constantinos Patsakis,Constantinos Patsakis and Nikolaos Lykousas,Man vs the machine: The Struggle for Effective Text Anonymisation in the Age of Large Language Models,,,,,cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The collection and use of personal data are becoming more common in today's data-driven culture. While there are many advantages to this, including better decision-making and service delivery, it also poses significant ethical issues around confidentiality and privacy. Text anonymisation tries to prune and/or mask identifiable information from a text while keeping the remaining content intact to alleviate privacy concerns. Text anonymisation is especially important in industries like healthcare, law, as well as research, where sensitive and personal information is collected, processed, and exchanged under high legal and ethical standards.   Although text anonymization is widely adopted in practice, it continues to face considerable challenges. The most significant challenge is striking a balance between removing information to protect individuals' privacy while maintaining the text's usability for future purposes. The question is whether these anonymisation methods sufficiently reduce the risk of re-identification, in which an individual can be identified based on the remaining information in the text.   In this work, we challenge the effectiveness of these methods and how we perceive identifiers. We assess the efficacy of these methods against the elephant in the room, the use of AI over big data. While most of the research is focused on identifying and removing personal information, there is limited discussion on whether the remaining information is sufficient to deanonymise individuals and, more precisely, who can do it. To this end, we conduct an experiment using GPT over anonymised texts of famous people to determine whether such trained networks can deanonymise them. The latter allows us to revise these methods and introduce a novel methodology that employs Large Language Models to improve the anonymity of texts. ","[{'version': 'v1', 'created': 'Wed, 22 Mar 2023 09:59:11 GMT'}]",2023-03-23,"[['Patsakis', 'Constantinos', ''], ['Lykousas', 'Nikolaos', '']]",0,1,2023-03-22,1,2,1,0,0,0,2d3905c1a92c28c056dff1225d89e4ca72ac4d8e,257663470.0,https://www.semanticscholar.org/paper/2d3905c1a92c28c056dff1225d89e4ca72ac4d8e,arXiv.org,2023.0,39.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1714170', 'name': 'C. Patsakis'}, {'authorId': '50999203', 'name': 'Nikolaos Lykousas'}]","['Data Centric Services, Bucharest, Romania', 'Information Management Systems Institute of Athena Research Centre, Greece', 'University of Piraeus']","['Greece', 'Romania']",2023-03
2303.12445,Leo Milecki,"Leo Milecki, Vicky Kalogeiton, Sylvain Bodard, Dany Anglicheau,
  Jean-Michel Correas, Marc-Olivier Timsit, Maria Vakalopoulou",MEDIMP: 3D Medical Images with clinical Prompts from limited tabular data for renal transplantation,,,,,cs.CV cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Renal transplantation emerges as the most effective solution for end-stage renal disease. Occurring from complex causes, a substantial risk of transplant chronic dysfunction persists and may lead to graft loss. Medical imaging plays a substantial role in renal transplant monitoring in clinical practice. However, graft supervision is multi-disciplinary, notably joining nephrology, urology, and radiology, while identifying robust biomarkers from such high-dimensional and complex data for prognosis is challenging. In this work, taking inspiration from the recent success of Large Language Models (LLMs), we propose MEDIMP -- Medical Images with clinical Prompts -- a model to learn meaningful multi-modal representations of renal transplant Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE MRI) by incorporating structural clinicobiological data after translating them into text prompts. MEDIMP is based on contrastive learning from joint text-image paired embeddings to perform this challenging task. Moreover, we propose a framework that generates medical prompts using automatic textual data augmentations from LLMs. Our goal is to learn meaningful manifolds of renal transplant DCE MRI, interesting for the prognosis of the transplant or patient status (2, 3, and 4 years after the transplant), fully exploiting the limited available multi-modal data most efficiently. Extensive experiments and comparisons with other renal transplant representation learning methods with limited data prove the effectiveness of MEDIMP in a relevant clinical setting, giving new directions toward medical prompts. Our code is available at https://github.com/leomlck/MEDIMP. ","[{'version': 'v1', 'created': 'Wed, 22 Mar 2023 10:30:43 GMT'}, {'version': 'v2', 'created': 'Sat, 29 Apr 2023 15:42:49 GMT'}]",2023-05-02,"[['Milecki', 'Leo', ''], ['Kalogeiton', 'Vicky', ''], ['Bodard', 'Sylvain', ''], ['Anglicheau', 'Dany', ''], ['Correas', 'Jean-Michel', ''], ['Timsit', 'Marc-Olivier', ''], ['Vakalopoulou', 'Maria', '']]",0,0,2023-03-22,2,7,2,0,0,0,23e58636960ba3cdd8901d6f60e5752e3cebe79c,258427158.0,https://www.semanticscholar.org/paper/23e58636960ba3cdd8901d6f60e5752e3cebe79c,,2023.0,36.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '2047847631', 'name': 'Léo Milecki'}, {'authorId': '1881509', 'name': 'Vicky S. Kalogeiton'}, {'authorId': '2095120077', 'name': 'S. Bodard'}, {'authorId': '5453139', 'name': 'D. Anglicheau'}, {'authorId': '41129247', 'name': 'J. Correas'}, {'authorId': '144897842', 'name': 'M. Timsit'}, {'authorId': '1893915', 'name': 'M. Vakalopoulou'}]","['UFR Médecine, Paris-', 'Institut Polytechnique de Paris', 'Université Paris Cité', 'Department of Nephrology and Kidney Transplantation, Necker Hospital, APHP, France', 'CentraleSupélec', 'Cité University, France']",['France'],2023-03
2303.12712,Sebastien Bubeck,"S\'ebastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes
  Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott
  Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, Yi Zhang",Sparks of Artificial General Intelligence: Early experiments with GPT-4,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions. ","[{'version': 'v1', 'created': 'Wed, 22 Mar 2023 16:51:28 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Mar 2023 17:07:43 GMT'}, {'version': 'v3', 'created': 'Mon, 27 Mar 2023 22:36:40 GMT'}, {'version': 'v4', 'created': 'Wed, 12 Apr 2023 17:00:10 GMT'}, {'version': 'v5', 'created': 'Thu, 13 Apr 2023 20:41:31 GMT'}]",2023-04-17,"[['Bubeck', 'Sébastien', ''], ['Chandrasekaran', 'Varun', ''], ['Eldan', 'Ronen', ''], ['Gehrke', 'Johannes', ''], ['Horvitz', 'Eric', ''], ['Kamar', 'Ece', ''], ['Lee', 'Peter', ''], ['Lee', 'Yin Tat', ''], ['Li', 'Yuanzhi', ''], ['Lundberg', 'Scott', ''], ['Nori', 'Harsha', ''], ['Palangi', 'Hamid', ''], ['Ribeiro', 'Marco Tulio', ''], ['Zhang', 'Yi', '']]",1,1,2023-03-22,5,14,2,3,0,3,574beee702be3856d60aa482ec725168fe64fc99,257663729.0,https://www.semanticscholar.org/paper/574beee702be3856d60aa482ec725168fe64fc99,arXiv.org,2023.0,0.0,909.0,95.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '121645690', 'name': 'Sébastien Bubeck'}, {'authorId': '143754359', 'name': 'Varun Chandrasekaran'}, {'authorId': '2315830', 'name': 'Ronen Eldan'}, {'authorId': '120962807', 'name': 'John A. Gehrke'}, {'authorId': '2064595436', 'name': 'Eric Horvitz'}, {'authorId': '1783184', 'name': 'Ece Kamar'}, {'authorId': '2212084492', 'name': 'Peter Lee'}, {'authorId': '2109308930', 'name': 'Y. Lee'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}, {'authorId': '23451726', 'name': 'Scott M. Lundberg'}, {'authorId': '40900039', 'name': 'Harsha Nori'}, {'authorId': '2542427', 'name': 'H. Palangi'}, {'authorId': '78846919', 'name': 'Marco Tulio Ribeiro'}, {'authorId': '144884116', 'name': 'Yi Zhang'}]",['Microsoft'],['India'],2023-03
2303.12796,Tohida Rehman Ms.,"Tohida Rehman, Suchandan Das, Debarshi Kumar Sanyal, Samiran
  Chattopadhyay",An Analysis of Abstractive Text Summarization Using Pre-trained Models,"11 Pages, 6 Figures, 3 Tables",https://link.springer.com/chapter/10.1007/978-981-19-1657-1_21(2022),10.1007/978-981-19-1657-1_21,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  People nowadays use search engines like Google, Yahoo, and Bing to find information on the Internet. Due to explosion in data, it is helpful for users if they are provided relevant summaries of the search results rather than just links to webpages. Text summarization has become a vital approach to help consumers swiftly grasp vast amounts of information.In this paper, different pre-trained models for text summarization are evaluated on different datasets. Specifically, we have used three different pre-trained models, namely, google/pegasus-cnn-dailymail, T5-base, facebook/bart-large-cnn. We have considered three different datasets, namely, CNN-dailymail, SAMSum and BillSum to get the output from the above three models. The pre-trained models are compared over these different datasets, each of 2000 examples, through ROUGH and BLEU metrics. ","[{'version': 'v1', 'created': 'Sat, 25 Feb 2023 16:44:37 GMT'}]",2023-03-24,"[['Rehman', 'Tohida', ''], ['Das', 'Suchandan', ''], ['Sanyal', 'Debarshi Kumar', ''], ['Chattopadhyay', 'Samiran', '']]",0,0,2023-02-25,1,4,3,1,1,0,686086f40179b31e54ec6aad70905c9a0fed1d4c,257687578.0,https://www.semanticscholar.org/paper/686086f40179b31e54ec6aad70905c9a0fed1d4c,arXiv.org,2023.0,22.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66695795', 'name': 'Tohida Rehman'}, {'authorId': '2203198173', 'name': 'S. Das'}, {'authorId': '11575056', 'name': 'Debarshi Kumar Sanyal'}, {'authorId': '1379534518', 'name': 'S. Chattopadhyay'}]","['TCG Crest', 'Jadavpur University', 'Indian Association for the Cultivation of Science']",['India'],2023-02
2303.13112,Cheng-Shang Chang,Cheng-Shang Chang,A Simple Explanation for the Phase Transition in Large Language Models with List Decoding,"5 pages, 1 figure",,,,cs.CL cs.AI cs.IT math.IT stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Various recent experimental results show that large language models (LLM) exhibit emergent abilities that are not present in small models. System performance is greatly improved after passing a certain critical threshold of scale. In this letter, we provide a simple explanation for such a phase transition phenomenon. For this, we model an LLM as a sequence-to-sequence random function. Instead of using instant generation at each step, we use a list decoder that keeps a list of candidate sequences at each step and defers the generation of the output sequence at the end. We show that there is a critical threshold such that the expected number of erroneous candidate sequences remains bounded when an LLM is below the threshold, and it grows exponentially when an LLM is above the threshold. Such a threshold is related to the basic reproduction number in a contagious disease. ","[{'version': 'v1', 'created': 'Thu, 23 Mar 2023 09:00:07 GMT'}]",2023-03-24,"[['Chang', 'Cheng-Shang', '']]",0,0,2023-03-23,1,1,5,0,0,0,15145a009d3532b8cfb663805115f5f229396079,257687434.0,https://www.semanticscholar.org/paper/15145a009d3532b8cfb663805115f5f229396079,arXiv.org,2023.0,13.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1678475', 'name': 'Cheng-Shang Chang'}]",['National Tsing Hua University'],['Taiwan'],2023-03
2303.13284,Debayan Banerjee,"Debayan Banerjee, Pranav Ajit Nair, Ricardo Usbeck, Chris Biemann",GETT-QA: Graph Embedding based T2T Transformer for Knowledge Graph Question Answering,16 pages single column format accepted at ESWC 2023 research track,,,,cs.CL cs.DB cs.IR,http://creativecommons.org/licenses/by/4.0/,"  In this work, we present an end-to-end Knowledge Graph Question Answering (KGQA) system named GETT-QA. GETT-QA uses T5, a popular text-to-text pre-trained language model. The model takes a question in natural language as input and produces a simpler form of the intended SPARQL query. In the simpler form, the model does not directly produce entity and relation IDs. Instead, it produces corresponding entity and relation labels. The labels are grounded to KG entity and relation IDs in a subsequent step. To further improve the results, we instruct the model to produce a truncated version of the KG embedding for each entity. The truncated KG embedding enables a finer search for disambiguation purposes. We find that T5 is able to learn the truncated KG embeddings without any change of loss function, improving KGQA performance. As a result, we report strong results for LC-QuAD 2.0 and SimpleQuestions-Wikidata datasets on end-to-end KGQA over Wikidata. ","[{'version': 'v1', 'created': 'Thu, 23 Mar 2023 14:06:26 GMT'}, {'version': 'v2', 'created': 'Fri, 24 Mar 2023 14:59:15 GMT'}, {'version': 'v3', 'created': 'Tue, 28 Mar 2023 09:48:50 GMT'}]",2023-03-29,"[['Banerjee', 'Debayan', ''], ['Nair', 'Pranav Ajit', ''], ['Usbeck', 'Ricardo', ''], ['Biemann', 'Chris', '']]",0,0,2023-03-23,3,4,3,1,1,0,a64167fcaa7a487575c6479510e57795afc9974e,257687289.0,https://www.semanticscholar.org/paper/a64167fcaa7a487575c6479510e57795afc9974e,Extended Semantic Web Conference,2023.0,47.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35635012', 'name': 'Debayan Banerjee'}, {'authorId': '83623712', 'name': 'Pranav Ajit Nair'}, {'authorId': '2370666', 'name': 'Ricardo Usbeck'}, {'authorId': '66911936', 'name': 'Chris Biemann'}]","['Universität Hamburg', 'Indian Institute of Technology BHU']","['Germany', 'India']",2023-03
2303.13521,Luca Caviglione,Enrico Cambiaso and Luca Caviglione,Scamming the Scammers: Using ChatGPT to Reply Mails for Wasting Time and Resources,,,,,cs.CR cs.AI cs.HC,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The use of Artificial Intelligence (AI) to support cybersecurity operations is now a consolidated practice, e.g., to detect malicious code or configure traffic filtering policies. The recent surge of AI, generative techniques and frameworks with efficient natural language processing capabilities dramatically magnifies the number of possible applications aimed at increasing the security of the Internet. Specifically, the ability of ChatGPT to produce textual contents while mimicking realistic human interactions can be used to mitigate the plague of emails containing scams. Therefore, this paper investigates the use of AI to engage scammers in automatized and pointless communications, with the goal of wasting both their time and resources. Preliminary results showcase that ChatGPT is able to decoy scammers, thus confirming that AI is an effective tool to counteract threats delivered via mail. In addition, we highlight the multitude of implications and open research questions to be addressed in the perspective of the ubiquitous adoption of AI. ","[{'version': 'v1', 'created': 'Fri, 10 Feb 2023 08:54:05 GMT'}]",2023-03-27,"[['Cambiaso', 'Enrico', ''], ['Caviglione', 'Luca', '']]",1,1,2023-02-10,1,2,3,1,0,1,9a147712d46d1b01a761987c874b628c34c52cda,257757409.0,https://www.semanticscholar.org/paper/9a147712d46d1b01a761987c874b628c34c52cda,Italian Conference on Cybersecurity,2023.0,33.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2979543', 'name': 'E. Cambiaso'}, {'authorId': '1728002', 'name': 'L. Caviglione'}]",['National Research Council'],['Italy'],2023-02
2303.13988,Thilo Hagendorff,Thilo Hagendorff,Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Due to rapid technological advances and their extreme versatility, LLMs nowadays have millions of users and are at the cusp of being the main go-to technology for information retrieval, content generation, problem-solving, etc. Therefore, it is of great importance to thoroughly assess and scrutinize their capabilities. Due to increasingly complex and novel behavioral patterns in current LLMs, this can be done by treating them as participants in psychology experiments that were originally designed to test humans. For this purpose, the paper introduces a new field of research called ""machine psychology"". The paper outlines how different subfields of psychology can inform behavioral tests for LLMs. It defines methodological standards for machine psychology research, especially by focusing on policies for prompt designs. Additionally, it describes how behavioral patterns discovered in LLMs are to be interpreted. In sum, machine psychology aims to discover emergent abilities in LLMs that cannot be detected by most traditional natural language processing benchmarks. ","[{'version': 'v1', 'created': 'Fri, 24 Mar 2023 13:24:41 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Apr 2023 08:45:59 GMT'}, {'version': 'v3', 'created': 'Wed, 5 Jul 2023 07:48:00 GMT'}]",2023-07-06,"[['Hagendorff', 'Thilo', '']]",0,0,2023-03-24,3,1,2,0,0,0,e661de406d8105e52a5351a2cd66db84cc4af115,257757370.0,https://www.semanticscholar.org/paper/e661de406d8105e52a5351a2cd66db84cc4af115,arXiv.org,2023.0,94.0,24.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2066519239', 'name': 'Thilo Hagendorff'}]",['University of Stuttgart'],['Germany'],2023-03
2303.13989,Jonas Becker,Jonas Becker and Jan Philip Wahle and Terry Ruas and Bela Gipp,Paraphrase Detection: Human vs. Machine Content,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  The growing prominence of large language models, such as GPT-4 and ChatGPT, has led to increased concerns over academic integrity due to the potential for machine-generated content and paraphrasing. Although studies have explored the detection of human- and machine-paraphrased content, the comparison between these types of content remains underexplored. In this paper, we conduct a comprehensive analysis of various datasets commonly employed for paraphrase detection tasks and evaluate an array of detection methods. Our findings highlight the strengths and limitations of different detection methods in terms of performance on individual datasets, revealing a lack of suitable machine-generated datasets that can be aligned with human expectations. Our main finding is that human-authored paraphrases exceed machine-generated ones in terms of difficulty, diversity, and similarity implying that automatically generated texts are not yet on par with human-level performance. Transformers emerged as the most effective method across datasets with TF-IDF excelling on semantically diverse corpora. Additionally, we identify four datasets as the most diverse and challenging for paraphrase detection. ","[{'version': 'v1', 'created': 'Fri, 24 Mar 2023 13:25:46 GMT'}]",2023-03-27,"[['Becker', 'Jonas', ''], ['Wahle', 'Jan Philip', ''], ['Ruas', 'Terry', ''], ['Gipp', 'Bela', '']]",1,1,2023-03-24,1,4,2,2,0,2,e68371b5db6dab7d4a78104d196e466239a0d417,257757302.0,https://www.semanticscholar.org/paper/e68371b5db6dab7d4a78104d196e466239a0d417,arXiv.org,2023.0,54.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2148468885', 'name': 'Jonas Becker'}, {'authorId': '2056772135', 'name': 'Jan Philip Wahle'}, {'authorId': '8837621', 'name': 'Terry Ruas'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]",['University of Göttingen'],['Germany'],2023-03
2303.14292,Paula Maddigan,Paula Maddigan and Teo Susnjak,Chat2VIS: Fine-Tuning Data Visualisations using Multilingual Natural Language Text and Pre-Trained Large Language Models,,,,,cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The explosion of data in recent years is driving individuals to leverage technology to generate insights. Traditional tools bring heavy learning overheads and the requirement for understanding complex charting techniques. Such barriers can hinder those who may benefit from harnessing data for informed decision making. The emerging field of generating data visualisations from natural language text (NL2VIS) addresses this issue. This study showcases Chat2VIS, a state-of-the-art NL2VIS solution. It capitalises on the latest in AI technology with the upsurge in pre-trained large language models (LLMs) such as GPT-3, Codex, and ChatGPT. Furthermore, the rise in natural language interfaces (NLI) and chatbots is taking centre stage. This work illustrates how Chat2VIS leverages similar techniques to fine-tune data visualisation components beyond that demonstrated in previous approaches. In addition, this paper presents the flexibility of Chat2VIS to comprehend multilingual natural language requests. No other NL2VIS system has demonstrated this unique talent. In concluding, this research provides quantitative benchmarking evaluations to contribute to the paucity of NL2VIS standards. ","[{'version': 'v1', 'created': 'Fri, 24 Mar 2023 22:21:32 GMT'}]",2023-03-28,"[['Maddigan', 'Paula', ''], ['Susnjak', 'Teo', '']]",1,1,2023-03-24,1,2,1,3,0,3,061ef5f6897766f0d9f0fa9067058ed77d6f3264,257767418.0,https://www.semanticscholar.org/paper/061ef5f6897766f0d9f0fa9067058ed77d6f3264,arXiv.org,2023.0,34.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2166478496', 'name': 'Paula Maddigan'}, {'authorId': '2656889', 'name': 'Teo Susnjak'}]",['Massey University'],['New Zealand'],2023-03
2303.14342,Steven Coyne,"Steven Coyne, Keisuke Sakaguchi, Diana Galvan-Sosa, Michael Zock,
  Kentaro Inui",Analyzing the Performance of GPT-3.5 and GPT-4 in Grammatical Error Correction,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  GPT-3 and GPT-4 models are powerful, achieving high performance on a variety of Natural Language Processing tasks. However, there is a relative lack of detailed published analysis of their performance on the task of grammatical error correction (GEC). To address this, we perform experiments testing the capabilities of a GPT-3.5 model (text-davinci-003) and a GPT-4 model (gpt-4-0314) on major GEC benchmarks. We compare the performance of different prompts in both zero-shot and few-shot settings, analyzing intriguing or problematic outputs encountered with different prompt formats. We report the performance of our best prompt on the BEA-2019 and JFLEG datasets, finding that the GPT models can perform well in a sentence-level revision setting, with GPT-4 achieving a new high score on the JFLEG benchmark. Through human evaluation experiments, we compare the GPT models' corrections to source, human reference, and baseline GEC system sentences and observe differences in editing strategies and how they are scored by human raters. ","[{'version': 'v1', 'created': 'Sat, 25 Mar 2023 03:08:49 GMT'}, {'version': 'v2', 'created': 'Tue, 30 May 2023 12:27:29 GMT'}]",2023-05-31,"[['Coyne', 'Steven', ''], ['Sakaguchi', 'Keisuke', ''], ['Galvan-Sosa', 'Diana', ''], ['Zock', 'Michael', ''], ['Inui', 'Kentaro', '']]",0,1,2023-03-25,2,5,1,2,0,2,2434df3e2bfd16e1953a025e121125feb39c366d,258967185.0,https://www.semanticscholar.org/paper/2434df3e2bfd16e1953a025e121125feb39c366d,,2023.0,29.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2056162373', 'name': 'Steven Coyne'}, {'authorId': '2325708', 'name': 'Keisuke Sakaguchi'}, {'authorId': '1403486895', 'name': 'Diana Galván-Sosa'}, {'authorId': '1795513', 'name': 'M. Zock'}, {'authorId': '3040648', 'name': 'Kentaro Inui'}]",['Aix-Marseille University'],['France'],2023-03
2303.14542,Junaed Younus Khan,Junaed Younus Khan and Gias Uddin,Combining Contexts from Multiple Sources for Documentation-Specific Code Example Generation,"Accepted in 30th IEEE International Conference on Software Analysis,
  Evolution and Reengineering (SANER 2023) - ERA",,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Code example is a crucial part of good documentation. It helps the developers to understand the documentation easily and use the corresponding code unit (e.g., method) properly. However, many official documentation still lacks (good) code example and it is one of the common documentation issues as found by several studies. Hence in this paper, we consider automatic code example generation for documentation, a direction less explored by the existing research. We employ Codex, a GPT-3 based model, pre-trained on both natural and programming languages to generate code examples from source code and documentation given as input. Our preliminary investigation on 40 scikit-learn methods reveals that this approach is able to generate good code examples where 72.5% code examples were executed without error (passability) and 82.5% properly dealt with the target method and documentation (relevance). We also find that incorporation of error logs (produced by the compiler while executing a failed code example) in the input further improves the passability from 72.5% to 87.5%. Thus, our investigation sets the base of documentation-specific code example generation and warrants in-depth future studies. ","[{'version': 'v1', 'created': 'Sat, 25 Mar 2023 19:25:20 GMT'}]",2023-03-28,"[['Khan', 'Junaed Younus', ''], ['Uddin', 'Gias', '']]",0,1,2023-03-25,1,2,1,2,0,2,645960e8bcb2a55bc7e8816c49e60e8f98303acb,257767014.0,https://www.semanticscholar.org/paper/645960e8bcb2a55bc7e8816c49e60e8f98303acb,"IEEE International Conference on Software Analysis, Evolution, and Reengineering",2023.0,46.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '119233244', 'name': 'Junaed Younus Khan'}, {'authorId': '28334651', 'name': 'Gias Uddin'}]",['University of Calgary'],['Canada'],2023-03
2303.14822,XInlei He,"Xinlei He and Xinyue Shen and Zeyuan Chen and Michael Backes and Yang
  Zhang",MGTBench: Benchmarking Machine-Generated Text Detection,,,,,cs.CR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Nowadays large language models (LLMs) have shown revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. In this way, detecting machine-generated texts (MGTs) is becoming increasingly important as LLMs become more advanced and prevalent. These models can generate human-like language that can be difficult to distinguish from text written by a human, which raises concerns about authenticity, accountability, and potential bias. However, existing detection methods against MGTs are evaluated under different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework across different methodologies   In this paper, we fill this gap by proposing the first benchmark framework for MGT detection, named MGTBench. Extensive evaluations on public datasets with curated answers generated by ChatGPT (the most representative and powerful LLMs thus far) show that most of the current detection methods perform less satisfactorily against MGTs. An exceptional case is ChatGPT Detector, which is trained with ChatGPT-generated texts and shows great performance in detecting MGTs. Nonetheless, we note that only a small fraction of adversarial-crafted perturbations on MGTs can evade the ChatGPT Detector, thus highlighting the need for more robust MGT detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of state-of-the-art MGT detection methods on their respective datasets and the development of more advanced MGT detection methods. Our source code and datasets are available at https://github.com/xinleihe/MGTBench. ","[{'version': 'v1', 'created': 'Sun, 26 Mar 2023 21:12:36 GMT'}, {'version': 'v2', 'created': 'Fri, 9 Jun 2023 06:50:57 GMT'}]",2023-06-12,"[['He', 'Xinlei', ''], ['Shen', 'Xinyue', ''], ['Chen', 'Zeyuan', ''], ['Backes', 'Michael', ''], ['Zhang', 'Yang', '']]",1,1,2023-03-26,2,5,2,1,0,1,e7ba478aad9b9534a9f632b85ad87177f5587189,257766697.0,https://www.semanticscholar.org/paper/e7ba478aad9b9534a9f632b85ad87177f5587189,arXiv.org,2023.0,30.0,24.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2116553732', 'name': 'Xinlei He'}, {'authorId': '2047395411', 'name': 'Xinyue Shen'}, {'authorId': '2111435173', 'name': 'Z. Chen'}, {'authorId': '144588806', 'name': 'M. Backes'}, {'authorId': '1698138', 'name': 'Yang Zhang'}]",['Helmholtz Center for Information Security'],['Germany'],2023-03
2303.15233,Priyank Jaini,"Kevin Clark, Priyank Jaini",Text-to-Image Diffusion Models are Zero-Shot Classifiers,,,,,cs.CV cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The excellent generative capabilities of text-to-image diffusion models suggest they learn informative representations of image-text data. However, what knowledge their representations capture is not fully understood, and they have not been thoroughly explored on downstream tasks. We investigate diffusion models by proposing a method for evaluating them as zero-shot classifiers. The key idea is using a diffusion model's ability to denoise a noised image given a text description of a label as a proxy for that label's likelihood. We apply our method to Stable Diffusion and Imagen, using it to probe fine-grained aspects of the models' knowledge and comparing them with CLIP's zero-shot abilities. They perform competitively with CLIP on a wide range of zero-shot image classification datasets. Additionally, they achieve state-of-the-art results on shape/texture bias tests and can successfully perform attribute binding while CLIP cannot. Although generative pre-training is prevalent in NLP, visual foundation models often use other methods such as contrastive learning. Based on our findings, we argue that generative pre-training should be explored as a compelling alternative for vision-language tasks. ","[{'version': 'v1', 'created': 'Mon, 27 Mar 2023 14:15:17 GMT'}, {'version': 'v2', 'created': 'Tue, 5 Sep 2023 18:21:16 GMT'}]",2023-09-07,"[['Clark', 'Kevin', ''], ['Jaini', 'Priyank', '']]",0,1,2023-03-27,2,2,3,0,0,0,1bba2a9c6db3b356b8ae6ef2efff5645e4d96c2b,257767039.0,https://www.semanticscholar.org/paper/1bba2a9c6db3b356b8ae6ef2efff5645e4d96c2b,arXiv.org,2023.0,53.0,14.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144358401', 'name': 'Kevin Clark'}, {'authorId': '144818264', 'name': 'P. Jaini'}]",['Google'],['Canada'],2023-03
2303.15324,Francesco Stella,"Francesco Stella, Cosimo Della Santina, Josie Hughes",Can Large Language Models design a Robot?,Under review,,,,cs.RO,http://creativecommons.org/licenses/by/4.0/,  Large Language Models can lead researchers in the design of robots. ,"[{'version': 'v1', 'created': 'Wed, 15 Mar 2023 09:41:44 GMT'}]",2023-03-28,"[['Stella', 'Francesco', ''], ['Della Santina', 'Cosimo', ''], ['Hughes', 'Josie', '']]",0,0,2023-03-15,1,3,1,0,0,0,2ce8331b0d85e8c336811a7692e8b105f6a9e373,257767266.0,https://www.semanticscholar.org/paper/2ce8331b0d85e8c336811a7692e8b105f6a9e373,arXiv.org,2023.0,12.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2059484891', 'name': 'F. Stella'}, {'authorId': '35178897', 'name': 'C. D. Santina'}, {'authorId': '143851238', 'name': 'Josie Hughes'}]","['École Polytechnique Fédérale de Lausanne', 'Delft University of Technology', 'German Aerospace Center', '[2,3] Cosimo Della Santina,']","['Germany', 'Netherlands', 'Switzerland']",2023-03
2303.15473,Simon Diemert,"Simon Diemert, Jens H Weber",Can Large Language Models assist in Hazard Analysis?,,,,,cs.HC cs.AI cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks, such as source code generation. This paper explores the potential of integrating LLMs in the hazard analysis for safety-critical systems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a human analyst interacts with an LLM via a context-aware chat session and uses the responses to support elicitation of possible hazard causes. In this experiment, we explore CoHA with three increasingly complex versions of a simple system, using Open AI's ChatGPT service. The quality of ChatGPT's responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology. The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis. ","[{'version': 'v1', 'created': 'Sat, 25 Mar 2023 19:43:27 GMT'}]",2023-03-29,"[['Diemert', 'Simon', ''], ['Weber', 'Jens H', '']]",1,1,2023-03-25,1,2,4,2,0,2,ddc2c19825316a23c59b8ea78ea0edc06f8e73bb,257771740.0,https://www.semanticscholar.org/paper/ddc2c19825316a23c59b8ea78ea0edc06f8e73bb,SAFECOMP Workshops,2023.0,29.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2092000', 'name': 'Simon Diemert'}, {'authorId': '1685123', 'name': 'J. Weber'}]",['University of Victoria'],['Canada'],2023-03
2303.15621,Zheheng Luo,"Zheheng Luo, Qianqian Xie, Sophia Ananiadou",ChatGPT as a Factual Inconsistency Evaluator for Text Summarization,"ongoing work, 12 pages, 4 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The performance of text summarization has been greatly boosted by pre-trained language models. A main concern of existing methods is that most generated summaries are not factually inconsistent with their source documents. To alleviate the problem, many efforts have focused on developing effective factuality evaluation metrics based on natural language inference, question answering, and syntactic dependency et al. However, these approaches are limited by either their high computational complexity or the uncertainty introduced by multi-component pipelines, resulting in only partial agreement with human judgement. Most recently, large language models(LLMs) have shown excellent performance in not only text generation but also language comprehension. In this paper, we particularly explore ChatGPT's ability to evaluate factual inconsistency under a zero-shot setting by examining it on both coarse-grained and fine-grained evaluation tasks including binary entailment inference, summary ranking, and consistency rating. Experimental results indicate that ChatGPT generally outperforms previous evaluation metrics across the three tasks, indicating its great potential for factual inconsistency evaluation. However, a closer inspection of ChatGPT's output reveals certain limitations including its preference for more lexically similar candidates, false reasoning, and inadequate understanding of instructions. ","[{'version': 'v1', 'created': 'Mon, 27 Mar 2023 22:30:39 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Apr 2023 10:59:39 GMT'}]",2023-04-14,"[['Luo', 'Zheheng', ''], ['Xie', 'Qianqian', ''], ['Ananiadou', 'Sophia', '']]",1,1,2023-03-27,2,3,1,1,0,1,039f82bdfac8aef61f64c3dfa4dc54ac75e418b2,258108400.0,https://www.semanticscholar.org/paper/039f82bdfac8aef61f64c3dfa4dc54ac75e418b2,,2023.0,47.0,18.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31689330', 'name': 'Zheheng Luo'}, {'authorId': '145229872', 'name': 'Qianqian Xie'}, {'authorId': '1881965', 'name': 'S. Ananiadou'}]",['University of Manchester'],['United Kingdom'],2023-03
2303.16104,Nuno Miguel Guerreiro,"Nuno M. Guerreiro, Duarte Alves, Jonas Waldendorf, Barry Haddow,
  Alexandra Birch, Pierre Colombo, Andr\'e F. T. Martins",Hallucinations in Large Multilingual Translation Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large-scale multilingual machine translation systems have demonstrated remarkable ability to translate directly between numerous languages, making them increasingly appealing for real-world applications. However, when deployed in the wild, these models may generate hallucinated translations which have the potential to severely undermine user trust and raise safety concerns. Existing research on hallucinations has primarily focused on small bilingual models trained on high-resource languages, leaving a gap in our understanding of hallucinations in massively multilingual models across diverse translation scenarios. In this work, we fill this gap by conducting a comprehensive analysis on both the M2M family of conventional neural machine translation models and ChatGPT, a general-purpose large language model~(LLM) that can be prompted for translation. Our investigation covers a broad spectrum of conditions, spanning over 100 translation directions across various resource levels and going beyond English-centric language pairs. We provide key insights regarding the prevalence, properties, and mitigation of hallucinations, paving the way towards more responsible and reliable machine translation systems. ","[{'version': 'v1', 'created': 'Tue, 28 Mar 2023 16:17:59 GMT'}]",2023-03-29,"[['Guerreiro', 'Nuno M.', ''], ['Alves', 'Duarte', ''], ['Waldendorf', 'Jonas', ''], ['Haddow', 'Barry', ''], ['Birch', 'Alexandra', ''], ['Colombo', 'Pierre', ''], ['Martins', 'André F. T.', '']]",1,1,2023-03-28,1,7,1,1,0,1,44bab2836177f8bf9775e7ca536b8e200757aac7,257771892.0,https://www.semanticscholar.org/paper/44bab2836177f8bf9775e7ca536b8e200757aac7,arXiv.org,2023.0,58.0,29.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144726818', 'name': 'Nuno M. Guerreiro'}, {'authorId': '2184781142', 'name': 'Duarte M. Alves'}, {'authorId': '2123124763', 'name': 'Jonas Waldendorf'}, {'authorId': '2259100', 'name': 'B. Haddow'}, {'authorId': '2539211', 'name': 'Alexandra Birch'}, {'authorId': '46985469', 'name': 'Pierre Colombo'}, {'authorId': '2069905347', 'name': 'André Martins'}]","['University of Paris-Saclay', 'Instituto de Telecomunicações', 'Universidade de Brasília', 'University of Lisbon', 'CentraleSupélec', 'University of Edinburgh']","['United Kingdom', 'France', 'Portugal', 'Brazil']",2023-03
2303.16244,Seif Abukhalaf,"Seif Abukhalaf, Mohammad Hamdaqa, Foutse Khomh",On Codex Prompt Engineering for OCL Generation: An Empirical Study,"10 pages. Full abstract in the pre-print. Accepted to be published to
  the 2023 IEEE/ACM 20th International Conference on Mining Software
  Repositories (MSR)",,,,cs.SE cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to MOF models. Despite its potential to provide precision and conciseness to UML models, the unfamiliar syntax of OCL has hindered its adoption. Recent advancements in LLMs, such as GPT-3, have shown their capability in many NLP tasks, including semantic parsing and text generation. Codex, a GPT-3 descendant, has been fine-tuned on publicly available code from GitHub and can generate code in many programming languages. We investigate the reliability of OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications and crafted a prompt template with slots to populate with UML information and the target task, using both zero- and few-shot learning methods. By measuring the syntactic validity and execution accuracy metrics of the generated OCL constraints, we found that enriching the prompts with UML information and enabling few-shot learning increases the reliability of the generated OCL constraints. Furthermore, the results reveal a close similarity based on sentence embedding between the generated OCL constraints and the human-written ones in the ground truth, implying a level of clarity and understandability in the generated OCL constraints by Codex. ","[{'version': 'v1', 'created': 'Tue, 28 Mar 2023 18:50:51 GMT'}]",2023-03-30,"[['Abukhalaf', 'Seif', ''], ['Hamdaqa', 'Mohammad', ''], ['Khomh', 'Foutse', '']]",0,1,2023-03-28,1,3,2,2,0,2,0a0d6a98bd246a82aaaa9d33ec0eadf4ceae69dc,257804680.0,https://www.semanticscholar.org/paper/0a0d6a98bd246a82aaaa9d33ec0eadf4ceae69dc,IEEE Working Conference on Mining Software Repositories,2023.0,30.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2213030346', 'name': 'Seif Abukhalaf'}, {'authorId': '1770180', 'name': 'Mohammad Hamdaqa'}, {'authorId': '1703493', 'name': 'Foutse Khomh'}]","['Software and Emerging Technologies Lab (SAET),', 'SoftWare Analytics and Technologies Lab (SWAT) Department of Computer and Software Engineering Polytechnique Montréal, Montréal, Canada']",['Canada'],2023-03
2303.16909,Mohammad Shahmeer Ahmad,"Mohammad Shahmeer Ahmad, Zan Ahmad Naeem, Mohamed Eltabakh, Mourad
  Ouzzani, Nan Tang",RetClean: Retrieval-Based Data Cleaning Using Foundation Models and Data Lakes,,,,,cs.DB cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Can foundation models (such as ChatGPT) clean your data? In this proposal, we demonstrate that indeed ChatGPT can assist in data cleaning by suggesting corrections for specific cells in a data table (scenario 1). However, ChatGPT may struggle with datasets it has never encountered before (e.g., local enterprise data) or when the user requires an explanation of the source of the suggested clean values. To address these issues, we developed a retrieval-based method that complements ChatGPT's power with a user-provided data lake. The data lake is first indexed, we then retrieve the top-k relevant tuples to the user's query tuple and finally leverage ChatGPT to infer the correct value (scenario 2). Nevertheless, sharing enterprise data with ChatGPT, an externally hosted model, might not be feasible for privacy reasons. To assist with this scenario, we developed a custom RoBERTa-based foundation model that can be locally deployed. By fine-tuning it on a small number of examples, it can effectively make value inferences based on the retrieved tuples (scenario 3). Our proposed system, RetClean, seamlessly supports all three scenarios and provides a user-friendly GUI that enables the VLDB audience to explore and experiment with the system. ","[{'version': 'v1', 'created': 'Wed, 29 Mar 2023 08:06:22 GMT'}]",2023-03-31,"[['Ahmad', 'Mohammad Shahmeer', ''], ['Naeem', 'Zan Ahmad', ''], ['Eltabakh', 'Mohamed', ''], ['Ouzzani', 'Mourad', ''], ['Tang', 'Nan', '']]",1,1,2023-03-29,1,5,2,1,0,1,d7c9aa432b9e07baa4acf2cdd9975b3df342b1ac,257833878.0,https://www.semanticscholar.org/paper/d7c9aa432b9e07baa4acf2cdd9975b3df342b1ac,arXiv.org,2023.0,6.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2797711', 'name': 'M. Ahmad'}, {'authorId': '1657569580', 'name': 'Zan Naeem'}, {'authorId': '1695161', 'name': 'M. Eltabakh'}, {'authorId': '2168047', 'name': 'M. Ouzzani'}, {'authorId': '8669763', 'name': 'N. Tang'}]",['Hamad bin Khalifa University'],['Qatar'],2023-03
2303.17003,Ramon Pires,"Desnes Nunes, Ricardo Primi, Ramon Pires, Roberto Lotufo, and Rodrigo
  Nogueira",Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The present study aims to explore the capabilities of Language Models (LMs) in tackling high-stakes multiple-choice tests, represented here by the Exame Nacional do Ensino M\'edio (ENEM), a multidisciplinary entrance examination widely adopted by Brazilian universities. This exam poses challenging tasks for LMs, since its questions may span into multiple fields of knowledge, requiring understanding of information from diverse domains. For instance, a question may require comprehension of both statistics and biology to be solved. This work analyzed responses generated by GPT-3.5 and GPT-4 models for questions presented in the 2009-2017 exams, as well as for questions of the 2022 exam, which were made public after the training of the models was completed. Furthermore, different prompt strategies were tested, including the use of Chain-of-Thought (CoT) prompts to generate explanations for answers. On the 2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracy of 87%, largely surpassing GPT-3.5 by 11 points. The code and data used on experiments are available at https://github.com/piresramon/gpt-4-enem. ","[{'version': 'v1', 'created': 'Wed, 29 Mar 2023 20:10:13 GMT'}]",2023-03-31,"[['Nunes', 'Desnes', ''], ['Primi', 'Ricardo', ''], ['Pires', 'Ramon', ''], ['Lotufo', 'Roberto', ''], ['Nogueira', 'Rodrigo', '']]",0,1,2023-03-29,1,5,3,2,0,2,3add55c068fe19bb2e5392cbe994602a91630ec1,257833808.0,https://www.semanticscholar.org/paper/3add55c068fe19bb2e5392cbe994602a91630ec1,arXiv.org,2023.0,23.0,10.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2212983357', 'name': 'Desnes Nunes'}, {'authorId': '2076129712', 'name': 'Ricardo Primi'}, {'authorId': '2150351942', 'name': 'Ramon Pires'}, {'authorId': '2066179820', 'name': 'R. Lotufo'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}]","['Universidade Estadual de Campinas (UNICAMP)', 'University of Santander', 'Universidade de São Paulo']","['Colombia', 'Brazil']",2023-03
2303.17163,Natanael Karjanto,N. Karjanto,Matrix diagonalization and singular value decomposition: Static SageMath and dynamic ChatGPT juxtaposed,"28 pages, 3 figures, 102 references",,,,math.HO cs.AI physics.ed-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigated some difficulties that students often face when studying linear algebra at the undergraduate level, and identified some common mistakes and difficulties they often encountered when dealing with topics that require algorithmic thinking skills such as matrix factorization. In particular, we focused on (orthogonal) diagonalization and singular value decomposition (SVD). We also offered the possibility of exploring these topics using SageMath, a Python-based free open software computer algebra system (CAS) that has been identified to be useful for assisting many students in the computational process even though its output is static by nature. We then explored dynamic ChatGPT by inquiring the chatbot about the topic, either by asking to provide an example or to solve a problem, that is by constructing an (orthogonal) diagonalization or SVD from a particular matrix. By consolidating essential concepts in linear algebra and improving computational skills through effective practice, mastering these topics would become easier and mistakes could be minimized. Static SageMath, in particular, is a great aid for calculation confirmation and handling tedious computations. Although dynamic ChatGPT is relatively unreliable for solving problems in linear algebra, the mistakes it produces could become a valuable tool for improving critical thinking skills. ","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 05:51:27 GMT'}]",2023-03-31,"[['Karjanto', 'N.', '']]",1,1,2023-03-30,1,1,3,1,0,1,af4b8ed0d2b6b1a286148c594adb07162b67bfc1,257833879.0,https://www.semanticscholar.org/paper/af4b8ed0d2b6b1a286148c594adb07162b67bfc1,arXiv.org,2023.0,88.0,0.0,0.0,True,"['Computer Science', 'Mathematics', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2299400', 'name': 'N. Karjanto'}]",['Sungkyunkwan University'],['South Korea'],2023-03
2303.17276,Philipp Koralus,"Philipp Koralus, Vincent Wang-Ma\'scianica",Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure,10 pages,,,,cs.AI cs.CL cs.HC cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and opportunity-cost neglect, among others. GPT-3 showed evidence of ETR-predicted outputs for 59% of these examples, rising to 77% in GPT-3.5 and 75% in GPT-4. Remarkably, the production of human-like fallacious judgments increased from 18% in GPT-3 to 33% in GPT-3.5 and 34% in GPT-4. This suggests that larger and more advanced LLMs may develop a tendency toward more human-like mistakes, as relevant thought patterns are inherent in human-produced training data. According to ETR, the same fundamental patterns are involved both in successful and unsuccessful ordinary reasoning, so that the ""bad"" cases could paradoxically be learned from the ""good"" cases. We further present preliminary evidence that ETR-inspired prompt engineering could reduce instances of these mistakes. ","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 10:32:18 GMT'}]",2023-03-31,"[['Koralus', 'Philipp', ''], ['Wang-Maścianica', 'Vincent', '']]",0,1,2023-03-30,1,2,4,2,0,2,45c46687bc8d2dbdea6f92fc14d4dc7a548ddd12,257833702.0,https://www.semanticscholar.org/paper/45c46687bc8d2dbdea6f92fc14d4dc7a548ddd12,arXiv.org,2023.0,23.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2961216', 'name': 'Philipp E. Koralus'}, {'authorId': '2213256276', 'name': ""Vincent Wang-Ma'scianica""}]",['University of Oxford'],['United Kingdom'],2023-03
2303.17322,Jose G Moreno,"Carlos-Emiliano Gonz\'alez-Gallardo and Emanuela Boros and Nancy
  Girdhar and Ahmed Hamdi and Jose G. Moreno and Antoine Doucet",Yes but.. Can ChatGPT Identify Entities in Historical Documents?,"5 pages, accepted to JCDL2023",,,,cs.DL cs.CL cs.IR,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large language models (LLMs) have been leveraged for several years now, obtaining state-of-the-art performance in recognizing entities from modern documents. For the last few months, the conversational agent ChatGPT has ""prompted"" a lot of interest in the scientific community and public due to its capacity of generating plausible-sounding answers. In this paper, we explore this ability by probing it in the named entity recognition and classification (NERC) task in primary sources (e.g., historical newspapers and classical commentaries) in a zero-shot manner and by comparing it with state-of-the-art LM-based systems. Our findings indicate several shortcomings in identifying entities in historical text that range from the consistency of entity annotation guidelines, entity complexity, and code-switching, to the specificity of prompting. Moreover, as expected, the inaccessibility of historical archives to the public (and thus on the Internet) also impacts its performance. ","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 12:23:39 GMT'}]",2023-03-31,"[['González-Gallardo', 'Carlos-Emiliano', ''], ['Boros', 'Emanuela', ''], ['Girdhar', 'Nancy', ''], ['Hamdi', 'Ahmed', ''], ['Moreno', 'Jose G.', ''], ['Doucet', 'Antoine', '']]",1,1,2023-03-30,1,6,3,1,0,1,d46e5a296afded737544098006529830be799d60,257833707.0,https://www.semanticscholar.org/paper/d46e5a296afded737544098006529830be799d60,ACM/IEEE Joint Conference on Digital Libraries,2023.0,34.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064158826', 'name': ""Carlos-Emiliano Gonz'alez-Gallardo""}, {'authorId': '35101485', 'name': 'Emanuela Boros'}, {'authorId': '51915772', 'name': 'Nancy Girdhar'}, {'authorId': '2924500', 'name': 'Ahmed Hamdi'}, {'authorId': '153230523', 'name': 'José G. Moreno'}, {'authorId': '2174737970', 'name': 'Antoine Doucet'}]","['Université de Toulouse', 'Digital Humanities Laboratory,', 'University of La Rochelle']",['France'],2023-03
2303.17511,Anna Strasser,Anna Strasser,On pitfalls (and advantages) of sophisticated large language models,,,,,cs.CY cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Natural language processing based on large language models (LLMs) is a booming field of AI research. After neural networks have proven to outperform humans in games and practical domains based on pattern recognition, we might stand now at a road junction where artificial entities might eventually enter the realm of human communication. However, this comes with serious risks. Due to the inherent limitations regarding the reliability of neural networks, overreliance on LLMs can have disruptive consequences. Since it will be increasingly difficult to distinguish between human-written and machine-generated text, one is confronted with new ethical challenges. This begins with the no longer undoubtedly verifiable human authorship and continues with various types of fraud, such as a new form of plagiarism. This also concerns the violation of privacy rights, the possibility of circulating counterfeits of humans, and, last but not least, it makes a massive spread of misinformation possible. ","[{'version': 'v1', 'created': 'Sat, 25 Feb 2023 11:14:39 GMT'}]",2023-03-31,"[['Strasser', 'Anna', '']]",0,0,2023-02-25,1,1,3,0,0,0,1fdd87f15411aa76dc03e113293df61ca9181caf,257833697.0,https://www.semanticscholar.org/paper/1fdd87f15411aa76dc03e113293df61ca9181caf,arXiv.org,2023.0,90.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8910659', 'name': 'A. Strasser'}]",['Ludwig-Maximilians-Universität München'],['Germany'],2023-02
2303.17513,Merlin Carl,Merlin Carl,Improving the Diproche CNL through autoformalization via GPT-3,,,,,cs.CL cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Diproche system is an automated proof checker for texts written in a controlled fragment of German, designed for didactical applications in classes introducing students to proofs for the first time. The first version of the system used a controlled natural language for which a Prolog formalization routine was written. In this paper, we explore the possibility of prompting large language models for autoformalization in the context of Diproche, with encouraging first results. ","[{'version': 'v1', 'created': 'Sun, 12 Mar 2023 20:11:25 GMT'}]",2023-03-31,"[['Carl', 'Merlin', '']]",0,1,2023-03-12,1,1,2,1,0,1,79b691c9a4f880127786ea86e4b42502d85a9b9e,257834104.0,https://www.semanticscholar.org/paper/79b691c9a4f880127786ea86e4b42502d85a9b9e,arXiv.org,2023.0,9.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2618125', 'name': 'M. Carl'}]",['Europa-Universität Flensburg'],['Germany'],2023-03
2303.17853,Samuel Timothy Spencer Dr,"Samuel T. Spencer, Vikas Joshi, Alison M.W. Mitchell",Can AI Put Gamma-Ray Astrophysicists Out of a Job?,,,,,physics.pop-ph astro-ph.HE cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In what will likely be a litany of generative-model-themed arXiv submissions celebrating April the 1st, we evaluate the capacity of state-of-the-art transformer models to create a paper detailing the detection of a Pulsar Wind Nebula with a non-existent Imaging Atmospheric Cherenkov Telescope (IACT) Array. We do this to evaluate the ability of such models to interpret astronomical observations and sources based on language information alone, and to assess potential means by which fraudulently generated scientific papers could be identified during peer review (given that reliable generative model watermarking has yet to be deployed for these tools). We conclude that our jobs as astronomers are safe for the time being. From this point on, prompts given to ChatGPT and Stable Diffusion are shown in orange, text generated by ChatGPT is shown in black, whereas analysis by the (human) authors is in blue. ","[{'version': 'v1', 'created': 'Fri, 31 Mar 2023 07:29:47 GMT'}, {'version': 'v2', 'created': 'Tue, 4 Apr 2023 09:30:55 GMT'}]",2023-04-05,"[['Spencer', 'Samuel T.', ''], ['Joshi', 'Vikas', ''], ['Mitchell', 'Alison M. W.', '']]",1,1,2023-03-31,2,3,3,1,0,1,b37eabb5767c9ca7710a8de5c42a0ccc66bdf231,257901031.0,https://www.semanticscholar.org/paper/b37eabb5767c9ca7710a8de5c42a0ccc66bdf231,arXiv.org,2023.0,14.0,1.0,0.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '1478433816', 'name': 'S. Spencer'}, {'authorId': '2259138264', 'name': 'V. Joshi'}, {'authorId': '145294766', 'name': 'A. Mitchell'}]",['Friedrich-Alexander-Universität Erlangen-Nürnberg'],['Germany'],2023-03
2303.18116,Jan G\'orecki,Jan G\'orecki,Pair Programming with Large Language Models for Sampling and Estimation of Copulas,,,,,cs.CL stat.CO,http://creativecommons.org/licenses/by/4.0/,"  Without writing a single line of code by a human, an example Monte Carlo simulation based application for stochastic dependence modeling with copulas is developed using a state-of-the-art large language model (LLM) fine-tuned for conversations. This includes interaction with ChatGPT in natural language and using mathematical formalism, which, under careful supervision by a human-expert, led to producing a working code in MATLAB, Python and R for sampling from a given copula model, evaluation of the model's density, performing maximum likelihood estimation, optimizing the code for parallel computing for CPUs as well as for GPUs, and visualization of the computed results. In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human-expert and artificial intelligence (AI). Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons. It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner. For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a solution that is correct. Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques. ","[{'version': 'v1', 'created': 'Fri, 31 Mar 2023 15:02:48 GMT'}]",2023-04-03,"[['Górecki', 'Jan', '']]",1,1,2023-03-31,1,1,2,1,0,1,975da5bb7fdd800ba577535d8c6ee5a5bc835d52,257900723.0,https://www.semanticscholar.org/paper/975da5bb7fdd800ba577535d8c6ee5a5bc835d52,arXiv.org,2023.0,40.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2213255291', 'name': ""Jan G'orecki""}]","['Univerzitní náměstí 1934/3, 733 40 Karviná, Czech Republic', 'Silesian University in Opava']","['Czechia', 'Czech Republic']",2023-03
2304.00008,Giorgio Franceschelli,"Giorgio Franceschelli, Mirco Musolesi",On the Creativity of Large Language Models,,,,,cs.AI cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) are revolutionizing several areas of Artificial Intelligence. One of the most remarkable applications is creative writing, e.g., poetry or storytelling: the generated outputs are often of astonishing quality. However, a natural question arises: can LLMs be really considered creative? In this article we firstly analyze the development of LLMs under the lens of creativity theories, investigating the key open questions and challenges. In particular, we focus our discussion around the dimensions of value, novelty and surprise as proposed by Margaret Boden in her work. Then, we consider different classic perspectives, namely product, process, press and person. We discuss a set of ``easy'' and ``hard'' problems in machine creativity, presenting them in relation to LLMs. Finally, we examine the societal impact of these technologies with a particular focus on the creative industries, analyzing the opportunities offered by them, the challenges arising by them and the potential associated risks, from both legal and ethical points of view. ","[{'version': 'v1', 'created': 'Mon, 27 Mar 2023 18:00:01 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Apr 2023 18:00:02 GMT'}, {'version': 'v3', 'created': 'Sun, 9 Jul 2023 18:00:02 GMT'}]",2023-07-11,"[['Franceschelli', 'Giorgio', ''], ['Musolesi', 'Mirco', '']]",0,0,2023-03-27,3,2,3,0,0,0,1c7402843d8b586d945b3b030e3edd93f0ae3959,257913327.0,https://www.semanticscholar.org/paper/1c7402843d8b586d945b3b030e3edd93f0ae3959,arXiv.org,2023.0,108.0,10.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067291198', 'name': 'Giorgio Franceschelli'}, {'authorId': '1806767', 'name': 'Mirco Musolesi'}]","['University College London', 'University of Bologna']","['United Kingdom', 'Italy']",2023-03
2304.00116,Mathias Kraus,"Mathias Kraus, Julia Anna Bingler, Markus Leippold, Tobias Schimanski,
  Chiara Colesanti Senni, Dominik Stammbach, Saeid Ashraf Vaghefi, Nicolas
  Webersinke",Enhancing Large Language Models with Climate Resources,,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have significantly transformed the landscape of artificial intelligence by demonstrating their ability in generating human-like text across diverse topics. However, despite their impressive capabilities, LLMs lack recent information and often employ imprecise language, which can be detrimental in domains where accuracy is crucial, such as climate change. In this study, we make use of recent ideas to harness the potential of LLMs by viewing them as agents that access multiple sources, including databases containing recent and precise information about organizations, institutions, and companies. We demonstrate the effectiveness of our method through a prototype agent that retrieves emission data from ClimateWatch (https://www.climatewatchdata.org/) and leverages general Google search. By integrating these resources with LLMs, our approach overcomes the limitations associated with imprecise language and delivers more reliable and accurate information in the critical domain of climate change. This work paves the way for future advancements in LLMs and their application in domains where precision is of paramount importance. ","[{'version': 'v1', 'created': 'Fri, 31 Mar 2023 20:24:14 GMT'}]",2023-04-04,"[['Kraus', 'Mathias', ''], ['Bingler', 'Julia Anna', ''], ['Leippold', 'Markus', ''], ['Schimanski', 'Tobias', ''], ['Senni', 'Chiara Colesanti', ''], ['Stammbach', 'Dominik', ''], ['Vaghefi', 'Saeid Ashraf', ''], ['Webersinke', 'Nicolas', '']]",0,0,2023-03-31,1,8,2,0,0,0,5e3f90417f54ab0738bbf2e0a7e6f803ce0cd445,257913911.0,https://www.semanticscholar.org/paper/5e3f90417f54ab0738bbf2e0a7e6f803ce0cd445,Social Science Research Network,2023.0,29.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2156865999', 'name': 'Mathias Kraus'}, {'authorId': '2006205621', 'name': 'J. Bingler'}, {'authorId': '3073566', 'name': 'Markus Leippold'}, {'authorId': '2213295713', 'name': 'Tobias Schimanski'}, {'authorId': '121813777', 'name': 'C. Senni'}, {'authorId': '146552774', 'name': 'Dominik Stammbach'}, {'authorId': '1989342', 'name': 'S. Vaghefi'}, {'authorId': '2023644816', 'name': 'Nicolas Webersinke'}]","['Friedrich-Alexander-Universität Erlangen-Nürnberg', 'ETH Zurich', 'University of Oxford', 'Council on Economic Policies', 'University of Zurich']","['Germany', 'United Kingdom', 'Switzerland']",2023-03
2304.00399,Maximilian Weiherer,Maximilian Weiherer and Bernhard Egger,From Zero to Hero: Convincing with Extremely Complicated Math,SIGBOVIK'23,,,,cs.CV cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Becoming a (super) hero is almost every kid's dream. During their sheltered childhood, they do whatever it takes to grow up to be one. Work hard, play hard -- all day long. But as they're getting older, distractions are more and more likely to occur. They're getting off track. They start discovering what is feared as simple math. Finally, they end up as a researcher, writing boring, non-impressive papers all day long because they only rely on simple mathematics. No top-tier conferences, no respect, no groupies. Life's over.   To finally put an end to this tragedy, we propose a fundamentally new algorithm, dubbed zero2hero, that turns every research paper into a scientific masterpiece. Given a LaTeX document containing ridiculously simple math, based on next-generation large language models, our system automatically over-complicates every single equation so that no one, including yourself, is able to understand what the hell is going on. Future reviewers will be blown away by the complexity of your equations, immediately leading to acceptance. zero2hero gets you back on track, because you deserve to be a hero$^{\text{TM}}$. Code leaked at \url{https://github.com/mweiherer/zero2hero}. ","[{'version': 'v1', 'created': 'Sat, 1 Apr 2023 22:09:35 GMT'}]",2023-04-04,"[['Weiherer', 'Maximilian', ''], ['Egger', 'Bernhard', '']]",0,0,2023-04-01,1,2,2,0,0,0,3590a37625252f5fcf4d7b566deb678c654a3bfe,257913449.0,https://www.semanticscholar.org/paper/3590a37625252f5fcf4d7b566deb678c654a3bfe,arXiv.org,2023.0,11.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '38073717', 'name': 'Maximilian Weiherer'}, {'authorId': '2053695764', 'name': 'B. Egger'}]",['Friedrich-Alexander-Universität Erlangen-Nürnberg'],['Germany'],2023-04
2304.00477,Pingchuan Ma,"Pingchuan Ma, Rui Ding, Shuai Wang, Shi Han, Dongmei Zhang",Demonstration of InsightPilot: An LLM-Empowered Automated Data Exploration System,,,,,cs.DB cs.AI cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Exploring data is crucial in data analysis, as it helps users understand and interpret the data more effectively. However, performing effective data exploration requires in-depth knowledge of the dataset and expertise in data analysis techniques. Not being familiar with either can create obstacles that make the process time-consuming and overwhelming for data analysts. To address this issue, we introduce InsightPilot, an LLM (Large Language Model)-based, automated data exploration system designed to simplify the data exploration process. InsightPilot automatically selects appropriate analysis intents, such as understanding, summarizing, and explaining. Then, these analysis intents are concretized by issuing corresponding intentional queries (IQueries) to create a meaningful and coherent exploration sequence. In brief, an IQuery is an abstraction and automation of data analysis operations, which mimics the approach of data analysts and simplifies the exploration process for users. By employing an LLM to iteratively collaborate with a state-of-the-art insight engine via IQueries, InsightPilot is effective in analyzing real-world datasets, enabling users to gain valuable insights through natural language inquiries. We demonstrate the effectiveness of InsightPilot in a case study, showing how it can help users gain valuable insights from their datasets. ","[{'version': 'v1', 'created': 'Sun, 2 Apr 2023 07:27:49 GMT'}]",2023-04-04,"[['Ma', 'Pingchuan', ''], ['Ding', 'Rui', ''], ['Wang', 'Shuai', ''], ['Han', 'Shi', ''], ['Zhang', 'Dongmei', '']]",0,0,2023-04-02,1,5,3,0,0,0,3603e74611f1438141af17d4c73af81d8c3bc024,257912912.0,https://www.semanticscholar.org/paper/3603e74611f1438141af17d4c73af81d8c3bc024,arXiv.org,2023.0,9.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1384480816', 'name': 'Pingchuan Ma'}, {'authorId': '145789861', 'name': 'Rui Ding'}, {'authorId': '2118511999', 'name': 'Shuai Wang'}, {'authorId': '123443478', 'name': 'Shi Han'}, {'authorId': '2140415600', 'name': 'Dongmei Zhang'}]",['Microsoft'],['India'],2023-04
2304.00869,Iakovos Evdaimon,"Iakovos Evdaimon, Hadi Abdine, Christos Xypolopoulos, Stamatis
  Outsios, Michalis Vazirgiannis, Giorgos Stamou",GreekBART: The First Pretrained Greek Sequence-to-Sequence Model,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The era of transfer learning has revolutionized the fields of Computer Vision and Natural Language Processing, bringing powerful pretrained models with exceptional performance across a variety of tasks. Specifically, Natural Language Processing tasks have been dominated by transformer-based language models. In Natural Language Inference and Natural Language Generation tasks, the BERT model and its variants, as well as the GPT model and its successors, demonstrated exemplary performance. However, the majority of these models are pretrained and assessed primarily for the English language or on a multilingual corpus. In this paper, we introduce GreekBART, the first Seq2Seq model based on BART-base architecture and pretrained on a large-scale Greek corpus. We evaluate and compare GreekBART against BART-random, Greek-BERT, and XLM-R on a variety of discriminative tasks. In addition, we examine its performance on two NLG tasks from GreekSUM, a newly introduced summarization dataset for the Greek language. The model, the code, and the new summarization dataset will be publicly available. ","[{'version': 'v1', 'created': 'Mon, 3 Apr 2023 10:48:51 GMT'}]",2023-04-04,"[['Evdaimon', 'Iakovos', ''], ['Abdine', 'Hadi', ''], ['Xypolopoulos', 'Christos', ''], ['Outsios', 'Stamatis', ''], ['Vazirgiannis', 'Michalis', ''], ['Stamou', 'Giorgos', '']]",0,1,2023-04-03,1,6,1,0,0,0,c30a4fb51684a8f4b23d899c9fc8c99653d3b0aa,257913408.0,https://www.semanticscholar.org/paper/c30a4fb51684a8f4b23d899c9fc8c99653d3b0aa,arXiv.org,2023.0,36.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2072733395', 'name': 'Iakovos Evdaimon'}, {'authorId': '2088382179', 'name': 'Hadi Abdine'}, {'authorId': '40704095', 'name': 'Christos Xypolopoulos'}, {'authorId': '80564154', 'name': 'Stamatis Outsios'}, {'authorId': '1690383', 'name': 'M. Vazirgiannis'}, {'authorId': '1719165', 'name': 'G. Stamou'}]","['École Polytechnique', 'KTH Royal Institute of Technology', 'Athens University of Economics and Business', 'National Technical University of Athens']","['Greece', 'Sweden', 'France']",2023-04
2304.01204,Jakub Dylag,"Jakub J. Dylag, Victor Suarez, James Wald, Aneesha Amodini Uvara",Automatic Geo-alignment of Artwork in Children's Story Books,Master's project,,,,cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  A study was conducted to prove AI software could be used to translate and generate illustrations without any human intervention. This was done with the purpose of showing and distributing it to the external customer, Pratham Books. The project aligns with the company's vision by leveraging the generalisation and scalability of Machine Learning algorithms, offering significant cost efficiency increases to a wide range of literary audiences in varied geographical locations. A comparative study methodology was utilised to determine the best performant method out of the 3 devised, Prompt Augmentation using Keywords, CLIP Embedding Mask, and Cross Attention Control with Editorial Prompts. A thorough evaluation process was completed using both quantitative and qualitative measures. Each method had its own strengths and weaknesses, but through the evaluation, method 1 was found to have the best yielding results. Promising future advancements may be made to further increase image quality by incorporating Large Language Models and personalised stylistic models. The presented approach can also be adapted to Video and 3D sculpture generation for novel illustrations in digital webbooks. ","[{'version': 'v1', 'created': 'Thu, 16 Mar 2023 06:23:06 GMT'}]",2023-04-05,"[['Dylag', 'Jakub J.', ''], ['Suarez', 'Victor', ''], ['Wald', 'James', ''], ['Uvara', 'Aneesha Amodini', '']]",0,0,2023-03-16,1,4,1,0,0,0,df186dc32216004808dad519c5869e660ed8ff06,257921851.0,https://www.semanticscholar.org/paper/df186dc32216004808dad519c5869e660ed8ff06,arXiv.org,2023.0,85.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2209985714', 'name': 'Jakub J Dylag'}, {'authorId': '2069308603', 'name': 'V. Suarez'}, {'authorId': '2076940657', 'name': 'James Wald'}, {'authorId': '2213462557', 'name': 'Aneesha Amodini Uvara'}]",['University of Southampton'],['United Kingdom'],2023-03
2304.01246,Xingyu Zhao,"Yi Qi, Xingyu Zhao, Xiaowei Huang",Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT,Under Review,,,,cs.CL cs.AI cs.CY cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs), such as ChatGPT and BERT, are leading a new AI heatwave due to its human-like conversations with detailed and articulate answers across many domains of knowledge. While LLMs are being quickly applied to many AI application domains, we are interested in the following question: Can safety analysis for safety-critical systems make use of LLMs? To answer, we conduct a case study of Systems Theoretic Process Analysis (STPA) on Automatic Emergency Brake (AEB) systems using ChatGPT. STPA, one of the most prevalent techniques for hazard analysis, is known to have limitations such as high complexity and subjectivity, which this paper aims to explore the use of ChatGPT to address. Specifically, three ways of incorporating ChatGPT into STPA are investigated by considering its interaction with human experts: one-off simplex interaction, recurring simplex interaction, and recurring duplex interaction. Comparative results reveal that: (i) using ChatGPT without human experts' intervention can be inadequate due to reliability and accuracy issues of LLMs; (ii) more interactions between ChatGPT and human experts may yield better results; and (iii) using ChatGPT in STPA with extra care can outperform human safety experts alone, as demonstrated by reusing an existing comparison method with baselines. In addition to making the first attempt to apply LLMs in safety analysis, this paper also identifies key challenges (e.g., trustworthiness concern of LLMs, the need of standardisation) for future research in this direction. ","[{'version': 'v1', 'created': 'Mon, 3 Apr 2023 16:46:49 GMT'}]",2023-04-05,"[['Qi', 'Yi', ''], ['Zhao', 'Xingyu', ''], ['Huang', 'Xiaowei', '']]",1,1,2023-04-03,1,3,4,1,0,1,5861df95084cf739a6ca3185d6523dd702bd1f10,257921252.0,https://www.semanticscholar.org/paper/5861df95084cf739a6ca3185d6523dd702bd1f10,arXiv.org,2023.0,63.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2117830923', 'name': 'Yi Qi'}, {'authorId': '47039303', 'name': 'Xingyu Zhao'}, {'authorId': '2107903140', 'name': 'Xiaowei Huang'}]","['University of Liverpool', 'University of Warwick']",['United Kingdom'],2023-04
2304.01282,Amirhossein Abaskohi,"Alireza Salemi, Amirhossein Abaskohi, Sara Tavakoli, Yadollah
  Yaghoobzadeh, Azadeh Shakery",PEACH: Pre-Training Sequence-to-Sequence Multilingual Models for Translation with Semi-Supervised Pseudo-Parallel Document Generation,"15 pages, 5 figures, 16 tables, 1 algorithm, LoResMT@EACL 2023",https://aclanthology.org/2023.loresmt-1.3,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Multilingual pre-training significantly improves many multilingual NLP tasks, including machine translation. Most existing methods are based on some variants of masked language modeling and text-denoising objectives on monolingual data. Multilingual pre-training on monolingual data ignores the availability of parallel data in many language pairs. Also, some other works integrate the available human-generated parallel translation data in their pre-training. This kind of parallel data is definitely helpful, but it is limited even in high-resource language pairs. This paper introduces a novel semi-supervised method, SPDG, that generates high-quality pseudo-parallel data for multilingual pre-training. First, a denoising model is pre-trained on monolingual data to reorder, add, remove, and substitute words, enhancing the pre-training documents' quality. Then, we generate different pseudo-translations for each pre-training document using dictionaries for word-by-word translation and applying the pre-trained denoising model. The resulting pseudo-parallel data is then used to pre-train our multilingual sequence-to-sequence model, PEACH. Our experiments show that PEACH outperforms existing approaches used in training mT5 and mBART on various translation tasks, including supervised, zero- and few-shot scenarios. Moreover, PEACH's ability to transfer knowledge between similar languages makes it particularly useful for low-resource languages. Our results demonstrate that with high-quality dictionaries for generating accurate pseudo-parallel, PEACH can be valuable for low-resource languages. ","[{'version': 'v1', 'created': 'Mon, 3 Apr 2023 18:19:26 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Apr 2023 17:54:58 GMT'}]",2023-06-02,"[['Salemi', 'Alireza', ''], ['Abaskohi', 'Amirhossein', ''], ['Tavakoli', 'Sara', ''], ['Yaghoobzadeh', 'Yadollah', ''], ['Shakery', 'Azadeh', '']]",0,0,2023-04-03,2,5,1,1,1,0,c1aeeb5ed9a78dd13093bd889576106f8c830606,257921579.0,https://www.semanticscholar.org/paper/c1aeeb5ed9a78dd13093bd889576106f8c830606,LORESMT,2023.0,46.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2073044451', 'name': 'Alireza Salemi'}, {'authorId': '2159712030', 'name': 'Amirhossein Abaskohi'}, {'authorId': '2213448440', 'name': 'Sara Tavakoli'}, {'authorId': '3261470', 'name': 'Yadollah Yaghoobzadeh'}, {'authorId': '2887988', 'name': 'A. Shakery'}]","['University of Tehran', 'Institute for Research in Fundamental Sciences']",['Iran'],2023-04
2304.01487,Kavita Kumari,"Alessandro Pegoraro, Kavita Kumari, Hossein Fereidooni, Ahmad-Reza
  Sadeghi","To ChatGPT, or not to ChatGPT: That is the question!",,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  ChatGPT has become a global sensation. As ChatGPT and other Large Language Models (LLMs) emerge, concerns of misusing them in various ways increase, such as disseminating fake news, plagiarism, manipulating public opinion, cheating, and fraud. Hence, distinguishing AI-generated from human-generated becomes increasingly essential. Researchers have proposed various detection methodologies, ranging from basic binary classifiers to more complex deep-learning models. Some detection techniques rely on statistical characteristics or syntactic patterns, while others incorporate semantic or contextual information to improve accuracy. The primary objective of this study is to provide a comprehensive and contemporary assessment of the most recent techniques in ChatGPT detection. Additionally, we evaluated other AI-generated text detection tools that do not specifically claim to detect ChatGPT-generated content to assess their performance in detecting ChatGPT-generated content. For our evaluation, we have curated a benchmark dataset consisting of prompts from ChatGPT and humans, including diverse questions from medical, open Q&A, and finance domains and user-generated responses from popular social networking platforms. The dataset serves as a reference to assess the performance of various techniques in detecting ChatGPT-generated content. Our evaluation results demonstrate that none of the existing methods can effectively detect ChatGPT-generated content. ","[{'version': 'v1', 'created': 'Tue, 4 Apr 2023 03:04:28 GMT'}, {'version': 'v2', 'created': 'Wed, 5 Apr 2023 04:28:41 GMT'}]",2023-04-06,"[['Pegoraro', 'Alessandro', ''], ['Kumari', 'Kavita', ''], ['Fereidooni', 'Hossein', ''], ['Sadeghi', 'Ahmad-Reza', '']]",1,1,2023-04-04,2,4,3,1,0,1,756b8fb9d6dec949f236705476e83026f67abe78,257921485.0,https://www.semanticscholar.org/paper/756b8fb9d6dec949f236705476e83026f67abe78,arXiv.org,2023.0,37.0,15.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2213466309', 'name': 'Alessandro Pegoraro'}, {'authorId': '2070363314', 'name': 'Kavita Kumari'}, {'authorId': '2440667', 'name': 'H. Fereidooni'}, {'authorId': '145897166', 'name': 'A. Sadeghi'}]",['Technical University of Darmstadt'],['Germany'],2023-04
2304.01948,Deep Kumar Kirtania,Deep Kumar Kirtania,Network Visualization of ChatGPT Research: a study based on term and keyword co-occurrence network analysis,"10 pages, 5 figures, 1 table",,,,cs.SI cs.AI cs.DL,http://creativecommons.org/licenses/by/4.0/,"  The main objective of this paper is to identify the major research areas of ChatGPT through term and keyword co-occurrence network mapping techniques. For conducting the present study, total of 577 publications were retrieved from the Lens database for the network visualization. The findings of the study showed that chatgpt occurrence in maximum number of times followed by its related terms such as artificial intelligence, large language model, gpt, study etc. This study will be helpful to library and information science as well as computer or information technology professionals. ","[{'version': 'v1', 'created': 'Sat, 1 Apr 2023 06:12:20 GMT'}]",2023-04-05,"[['Kirtania', 'Deep Kumar', '']]",1,1,2023-04-01,1,1,3,1,0,1,e5823924627d207bb514da2c9e9254d5951f91b2,257921317.0,https://www.semanticscholar.org/paper/e5823924627d207bb514da2c9e9254d5951f91b2,Social Science Research Network,2023.0,21.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '117865332', 'name': 'Deep Kumar Kirtania'}]",['Bankura Sammilani Medical College'],['India'],2023-04
2304.02017,Walid Hariri,Walid Hariri,"Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models have revolutionized the field of artificial intelligence and have been used in various applications. Among these models, ChatGPT (Chat Generative Pre-trained Transformer) has been developed by OpenAI, it stands out as a powerful tool that has been widely adopted. ChatGPT has been successfully applied in numerous areas, including chatbots, content generation, language translation, personalized recommendations, and even medical diagnosis and treatment. Its success in these applications can be attributed to its ability to generate human-like responses, understand natural language, and adapt to different contexts. Its versatility and accuracy make it a powerful tool for natural language processing (NLP). However, there are also limitations to ChatGPT, such as its tendency to produce biased responses and its potential to perpetuate harmful language patterns. This article provides a comprehensive overview of ChatGPT, its applications, advantages, and limitations. Additionally, the paper emphasizes the importance of ethical considerations when using this robust tool in real-world scenarios. Finally, This paper contributes to ongoing discussions surrounding artificial intelligence and its impact on vision and NLP domains by providing insights into prompt engineering techniques. ","[{'version': 'v1', 'created': 'Mon, 27 Mar 2023 21:27:58 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Apr 2023 16:33:55 GMT'}, {'version': 'v3', 'created': 'Fri, 7 Apr 2023 16:30:52 GMT'}, {'version': 'v4', 'created': 'Mon, 10 Apr 2023 21:07:40 GMT'}, {'version': 'v5', 'created': 'Wed, 12 Apr 2023 20:54:09 GMT'}]",2023-04-14,"[['Hariri', 'Walid', '']]",1,1,2023-03-27,5,1,1,1,0,1,9e93ab728e3e174ec1492009055885a9123d434f,257952074.0,https://www.semanticscholar.org/paper/9e93ab728e3e174ec1492009055885a9123d434f,arXiv.org,2023.0,95.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3430858', 'name': 'Walid Hariri'}]",['Badji Mokhtar University'],['Algeria'],2023-03
2304.02182,Yuan Gao,"Yuan Gao, Ruili Wang, Feng Hou",How to Design Translation Prompts for ChatGPT: An Empirical Study,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recently released ChatGPT has demonstrated surprising abilities in natural language understanding and natural language generation. Machine translation relies heavily on the abilities of language understanding and generation. Thus, in this paper, we explore how to assist machine translation with ChatGPT. We adopt several translation prompts on a wide range of translations. Our experimental results show that ChatGPT with designed translation prompts can achieve comparable or better performance over commercial translation systems for high-resource language translations. We further evaluate the translation quality using multiple references, and ChatGPT achieves superior performance compared to commercial systems. We also conduct experiments on domain-specific translations, the final results show that ChatGPT is able to comprehend the provided domain keyword and adjust accordingly to output proper translations. At last, we perform few-shot prompts that show consistent improvement across different base prompts. Our work provides empirical evidence that ChatGPT still has great potential in translations. ","[{'version': 'v1', 'created': 'Wed, 5 Apr 2023 01:17:59 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Apr 2023 09:35:44 GMT'}]",2023-04-24,"[['Gao', 'Yuan', ''], ['Wang', 'Ruili', ''], ['Hou', 'Feng', '']]",1,1,2023-04-05,2,3,1,1,0,1,cd77ea482d9245f3fcaeb670261a00c3fb5cabbd,258291367.0,https://www.semanticscholar.org/paper/cd77ea482d9245f3fcaeb670261a00c3fb5cabbd,arXiv.org,2023.0,32.0,10.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2145975550', 'name': 'Yuan Gao'}, {'authorId': '2108681045', 'name': 'Ruili Wang'}, {'authorId': '49272105', 'name': 'Feng Hou'}]",['Massey University'],['New Zealand'],2023-04
2304.02202,Osman Tursun,"Osman Tursun, Simon Denman, Sridha Sridharan, and Clinton Fookes",Towards Self-Explainability of Deep Neural Networks with Heatmap Captioning and Large-Language Models,,,,,cs.CV cs.HC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Heatmaps are widely used to interpret deep neural networks, particularly for computer vision tasks, and the heatmap-based explainable AI (XAI) techniques are a well-researched topic. However, most studies concentrate on enhancing the quality of the generated heatmap or discovering alternate heatmap generation techniques, and little effort has been devoted to making heatmap-based XAI automatic, interactive, scalable, and accessible. To address this gap, we propose a framework that includes two modules: (1) context modelling and (2) reasoning. We proposed a template-based image captioning approach for context modelling to create text-based contextual information from the heatmap and input data. The reasoning module leverages a large language model to provide explanations in combination with specialised knowledge. Our qualitative experiments demonstrate the effectiveness of our framework and heatmap captioning approach. The code for the proposed template-based heatmap captioning approach will be publicly available. ","[{'version': 'v1', 'created': 'Wed, 5 Apr 2023 03:29:37 GMT'}]",2023-04-06,"[['Tursun', 'Osman', ''], ['Denman', 'Simon', ''], ['Sridharan', 'Sridha', ''], ['Fookes', 'Clinton', '']]",0,0,2023-04-05,1,4,3,0,0,0,5d6175fbc5381d91c0d0a85e650a3a68ce6c692e,257952112.0,https://www.semanticscholar.org/paper/5d6175fbc5381d91c0d0a85e650a3a68ce6c692e,arXiv.org,2023.0,22.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3183317', 'name': 'Osman Tursun'}, {'authorId': '1980700', 'name': 'S. Denman'}, {'authorId': '1729760', 'name': 'S. Sridharan'}, {'authorId': '3140440', 'name': 'C. Fookes'}]",['Queensland University of Technology'],['Australia'],2023-04
2304.02796,Xin Hu,"Xin Hu, Yu Tian, Keisuke Nagato, Masayuki Nakao, Ang Liu",Opportunities and challenges of ChatGPT for design knowledge management,"This is a conference paper, 8 pages, 4 figures",,,,cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Recent advancements in Natural Language Processing have opened up new possibilities for the development of large language models like ChatGPT, which can facilitate knowledge management in the design process by providing designers with access to a vast array of relevant information. However, integrating ChatGPT into the design process also presents new challenges. In this paper, we provide a concise review of the classification and representation of design knowledge, and past efforts to support designers in acquiring knowledge. We analyze the opportunities and challenges that ChatGPT presents for knowledge management in design and propose promising future research directions. A case study is conducted to validate the advantages and drawbacks of ChatGPT, showing that designers can acquire targeted knowledge from various domains, but the quality of the acquired knowledge is highly dependent on the prompt. ","[{'version': 'v1', 'created': 'Thu, 6 Apr 2023 00:14:56 GMT'}]",2023-04-07,"[['Hu', 'Xin', ''], ['Tian', 'Yu', ''], ['Nagato', 'Keisuke', ''], ['Nakao', 'Masayuki', ''], ['Liu', 'Ang', '']]",1,1,2023-04-06,1,5,1,1,0,1,6be4fe7f7325bdaa7785ae5faaf96cbfde535810,257985466.0,https://www.semanticscholar.org/paper/6be4fe7f7325bdaa7785ae5faaf96cbfde535810,Procedia CIRP,2023.0,31.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50820619', 'name': 'Xin Hu'}, {'authorId': '2191199507', 'name': 'Yu Tian'}, {'authorId': '13211926', 'name': 'K. Nagato'}, {'authorId': '48597907', 'name': 'M. Nakao'}, {'authorId': '2118791563', 'name': 'Ang Liu'}]","['UNSW Sydney', 'The University of Tokyo']","['Japan', 'Australia']",2023-04
2304.02822,Avinash Bhat,"Avinash Bhat, Disha Shrivastava, Jin L.C. Guo",Approach Intelligent Writing Assistants Usability with Seven Stages of Action,"The Second Workshop on Intelligent and Interactive Writing Assistants
  co-located with The ACM CHI Conference on Human Factors in Computing Systems
  (CHI 2023)",,,,cs.HC cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Despite the potential of Large Language Models (LLMs) as writing assistants, they are plagued by issues like coherence and fluency of the model output, trustworthiness, ownership of the generated content, and predictability of model performance, thereby limiting their usability. In this position paper, we propose to adopt Norman's seven stages of action as a framework to approach the interaction design of intelligent writing assistants. We illustrate the framework's applicability to writing tasks by providing an example of software tutorial authoring. The paper also discusses the framework as a tool to synthesize research on the interaction design of LLM-based tools and presents examples of tools that support the stages of action. Finally, we briefly outline the potential of a framework for human-LLM interaction research. ","[{'version': 'v1', 'created': 'Thu, 6 Apr 2023 02:11:55 GMT'}]",2023-04-12,"[['Bhat', 'Avinash', ''], ['Shrivastava', 'Disha', ''], ['Guo', 'Jin L. C.', '']]",0,0,2023-04-06,1,3,3,0,0,0,94baee04669e51c689357747506aefa33341a559,257984977.0,https://www.semanticscholar.org/paper/94baee04669e51c689357747506aefa33341a559,arXiv.org,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2124987270', 'name': 'Avinash Bhat'}, {'authorId': '36921665', 'name': 'Disha Shrivastava'}, {'authorId': '1994701040', 'name': 'Jin L. C. Guo'}]","['McGill University', 'Université de Montréal']",['Canada'],2023-04
2304.03153,Lei Wang,"Lei Wang, Ee-Peng Lim",Zero-Shot Next-Item Recommendation using Large Pretrained Language Models,Technical Report,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have achieved impressive zero-shot performance in various natural language processing (NLP) tasks, demonstrating their capabilities for inference without training examples. Despite their success, no research has yet explored the potential of LLMs to perform next-item recommendations in the zero-shot setting. We have identified two major challenges that must be addressed to enable LLMs to act effectively as recommenders. First, the recommendation space can be extremely large for LLMs, and LLMs do not know about the target user's past interacted items and preferences. To address this gap, we propose a prompting strategy called Zero-Shot Next-Item Recommendation (NIR) prompting that directs LLMs to make next-item recommendations. Specifically, the NIR-based strategy involves using an external module to generate candidate items based on user-filtering or item-filtering. Our strategy incorporates a 3-step prompting that guides GPT-3 to carry subtasks that capture the user's preferences, select representative previously watched movies, and recommend a ranked list of 10 movies. We evaluate the proposed approach using GPT-3 on MovieLens 100K dataset and show that it achieves strong zero-shot performance, even outperforming some strong sequential recommendation models trained on the entire training dataset. These promising results highlight the ample research opportunities to use LLMs as recommenders. The code can be found at https://github.com/AGI-Edgerunners/LLM-Next-Item-Rec. ","[{'version': 'v1', 'created': 'Thu, 6 Apr 2023 15:35:11 GMT'}]",2023-04-07,"[['Wang', 'Lei', ''], ['Lim', 'Ee-Peng', '']]",0,1,2023-04-06,1,2,2,1,0,1,85dc7c22aaae5d596e0dc4d732b8f8afd51582bd,257985012.0,https://www.semanticscholar.org/paper/85dc7c22aaae5d596e0dc4d732b8f8afd51582bd,arXiv.org,2023.0,27.0,22.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145131956', 'name': 'Lei Wang'}, {'authorId': '1709901', 'name': 'Ee-Peng Lim'}]",['Singapore Management University'],['Singapore'],2023-04
2304.03277,Baolin Peng,"Baolin Peng and Chunyuan Li and Pengcheng He and Michel Galley and
  Jianfeng Gao",Instruction Tuning with GPT-4,"8 pages. Work in progress. Project page:
  https://instruction-tuning-with-gpt-4.github.io",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Prior work has shown that finetuning large language models (LLMs) using machine-generated instruction-following data enables such models to achieve remarkable zero-shot capabilities on new tasks, and no human-written instructions are needed. In this paper, we present the first attempt to use GPT-4 to generate instruction-following data for LLM finetuning. Our early experiments on instruction-tuned LLaMA models show that the 52K English and Chinese instruction-following data generated by GPT-4 leads to superior zero-shot performance on new tasks to the instruction-following data generated by previous state-of-the-art models. We also collect feedback and comparison data from GPT-4 to enable a comprehensive evaluation and reward model training. We make our data generated using GPT-4 as well as our codebase publicly available. ","[{'version': 'v1', 'created': 'Thu, 6 Apr 2023 17:58:09 GMT'}]",2023-04-07,"[['Peng', 'Baolin', ''], ['Li', 'Chunyuan', ''], ['He', 'Pengcheng', ''], ['Galley', 'Michel', ''], ['Gao', 'Jianfeng', '']]",0,1,2023-04-06,1,5,2,2,1,1,9e8cb8c91a0acb6e661b58ad724aa758490f2bea,257985497.0,https://www.semanticscholar.org/paper/9e8cb8c91a0acb6e661b58ad724aa758490f2bea,arXiv.org,2023.0,27.0,217.0,23.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1780690', 'name': 'Baolin Peng'}, {'authorId': '2109737569', 'name': 'Chunyuan Li'}, {'authorId': '50462546', 'name': 'Pengcheng He'}, {'authorId': '1947267', 'name': 'Michel Galley'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}]",['Microsoft'],['India'],2023-04
2304.03287,Ganesh Prasath Ramani,Ganesh Prasath and Shirish Karande,Synthesis of Mathematical programs from Natural Language Specifications,Accepted in ICLR 2023 DL4C stream,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Several decision problems that are encountered in various business domains can be modeled as mathematical programs, i.e. optimization problems. The process of conducting such modeling often requires the involvement of experts trained in operations research and advanced algorithms. Surprisingly, despite the significant advances in the methods for program and code synthesis, AutoML, learning to optimize etc., there has been little or no attention paid to automating the task of synthesizing mathematical programs. We imagine a scenario where the specifications for modeling, i.e. the objective and constraints are expressed in an unstructured form in natural language (NL) and the mathematical program has to be synthesized from such an NL specification. In this work we evaluate the efficacy of employing CodeT5 with data augmentation and post-processing of beams. We utilize GPT-3 with back translation for generation of synthetic examples. Further we apply rules of linear programming to score beams and correct beams based on common error patterns. We observe that with these enhancements CodeT5 base gives an execution accuracy of 0.73 which is significantly better than zero-shot execution accuracy of 0.41 by ChatGPT and 0.36 by Codex. ","[{'version': 'v1', 'created': 'Thu, 30 Mar 2023 06:10:00 GMT'}]",2023-04-10,"[['Prasath', 'Ganesh', ''], ['Karande', 'Shirish', '']]",1,1,2023-03-30,1,2,3,3,0,3,d9bd490aba3a7995f728594403b3358cb79aacd6,258041092.0,https://www.semanticscholar.org/paper/d9bd490aba3a7995f728594403b3358cb79aacd6,arXiv.org,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2084478142', 'name': 'G. Prasath'}, {'authorId': '40151143', 'name': 'S. Karande'}]",['Tata Consultancy Services (India)'],['India'],2023-03
2304.03609,Yulin Zhou,"Yulin Zhou, Yiren Zhao, Ilia Shumailov, Robert Mullins, Yarin Gal",Revisiting Automated Prompting: Are We Actually Doing Better?,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Current literature demonstrates that Large Language Models (LLMs) are great few-shot learners, and prompting significantly increases their performance on a range of downstream tasks in a few-shot learning setting. An attempt to automate human-led prompting followed, with some progress achieved. In particular, subsequent work demonstrates automation can outperform fine-tuning in certain K-shot learning scenarios.   In this paper, we revisit techniques for automated prompting on six different downstream tasks and a larger range of K-shot learning settings. We find that automated prompting does not consistently outperform simple manual prompts. Our work suggests that, in addition to fine-tuning, manual prompts should be used as a baseline in this line of research. ","[{'version': 'v1', 'created': 'Fri, 7 Apr 2023 12:06:44 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Jun 2023 20:17:00 GMT'}]",2023-06-26,"[['Zhou', 'Yulin', ''], ['Zhao', 'Yiren', ''], ['Shumailov', 'Ilia', ''], ['Mullins', 'Robert', ''], ['Gal', 'Yarin', '']]",0,0,2023-04-07,2,5,2,0,0,0,657945a83b062679887c49334f9b47687f6e1d64,258041372.0,https://www.semanticscholar.org/paper/657945a83b062679887c49334f9b47687f6e1d64,Annual Meeting of the Association for Computational Linguistics,2023.0,31.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2213908085', 'name': 'Yulin Zhou'}, {'authorId': '2109919449', 'name': 'Yiren Zhao'}, {'authorId': '47473421', 'name': 'Ilia Shumailov'}, {'authorId': '2768514', 'name': 'R. Mullins'}, {'authorId': '2681954', 'name': 'Y. Gal'}]","['Imperial College London', 'University of Cambridge', 'University of Oxford']",['United Kingdom'],2023-04
2304.03612,Ronald Fischer,"Ronald Fischer, Markus Luczak-Roesch and Johannes A Karl",What does ChatGPT return about human values? Exploring value bias in ChatGPT using a descriptive value theory,"26 pages, 4 Figures, 5 Tables",,,,cs.CL cs.CY cs.HC,http://creativecommons.org/licenses/by/4.0/,"  There has been concern about ideological basis and possible discrimination in text generated by Large Language Models (LLMs). We test possible value biases in ChatGPT using a psychological value theory. We designed a simple experiment in which we used a number of different probes derived from the Schwartz basic value theory (items from the revised Portrait Value Questionnaire, the value type definitions, value names). We prompted ChatGPT via the OpenAI API repeatedly to generate text and then analyzed the generated corpus for value content with a theory-driven value dictionary using a bag of words approach. Overall, we found little evidence of explicit value bias. The results showed sufficient construct and discriminant validity for the generated text in line with the theoretical predictions of the psychological model, which suggests that the value content was carried through into the outputs with high fidelity. We saw some merging of socially oriented values, which may suggest that these values are less clearly differentiated at a linguistic level or alternatively, this mixing may reflect underlying universal human motivations. We outline some possible applications of our findings for both applications of ChatGPT for corporate usage and policy making as well as future research avenues. We also highlight possible implications of this relatively high-fidelity replication of motivational content using a linguistic model for the theorizing about human values. ","[{'version': 'v1', 'created': 'Fri, 7 Apr 2023 12:20:13 GMT'}]",2023-04-10,"[['Fischer', 'Ronald', ''], ['Luczak-Roesch', 'Markus', ''], ['Karl', 'Johannes A', '']]",1,1,2023-04-07,1,3,3,1,0,1,89032c347e69ea232212f4573b97655f6d178f62,258040967.0,https://www.semanticscholar.org/paper/89032c347e69ea232212f4573b97655f6d178f62,arXiv.org,2023.0,39.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2241208766', 'name': 'Ronald Fischer'}, {'authorId': '1403045617', 'name': 'Markus Luczak-Rösch'}, {'authorId': '32045570', 'name': 'J. Karl'}]","['Dublin City University', 'Electronic Arts (United Kingdom)', 'School of Information Management, RH 410, Rutherford House, 23 Lambton Quay, Wellington, 6011, New Zealand;', 'D’Or Institute for Research and Education']","['Ireland', 'United Kingdom', 'New Zealand', 'Brazil']",2023-04
2304.03816,Sarah Fakhoury,"Sarah Fakhoury, Saikat Chakraborty, Madan Musuvathi, and Shuvendu K.
  Lahiri",Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions,,,,,cs.SE cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs), such as OpenAI's Codex, have demonstrated their potential to generate code from natural language descriptions across a wide range of programming tasks. Several benchmarks have recently emerged to evaluate the ability of LLMs to generate functionally correct code from natural language intent with respect to a set of hidden test cases. This has enabled the research community to identify significant and reproducible advancements in LLM capabilities. However, there is currently a lack of benchmark datasets for assessing the ability of LLMs to generate functionally correct code edits based on natural language descriptions of intended changes. This paper aims to address this gap by motivating the problem NL2Fix of translating natural language descriptions of code changes (namely bug fixes described in Issue reports in repositories) into correct code fixes. To this end, we introduce Defects4J-NL2Fix, a dataset of 283 Java programs from the popular Defects4J dataset augmented with high-level descriptions of bug fixes, and empirically evaluate the performance of several state-of-the-art LLMs for the this task. Results show that these LLMS together are capable of generating plausible fixes for 64.6% of the bugs, and the best LLM-based technique can achieve up to 21.20% top-1 and 35.68% top-5 accuracy on this benchmark. ","[{'version': 'v1', 'created': 'Fri, 7 Apr 2023 18:58:33 GMT'}]",2023-04-11,"[['Fakhoury', 'Sarah', ''], ['Chakraborty', 'Saikat', ''], ['Musuvathi', 'Madan', ''], ['Lahiri', 'Shuvendu K.', '']]",0,0,2023-04-07,1,4,2,1,0,1,34d12432af63915caf14eab9a362f7e7d24e4c13,258049098.0,https://www.semanticscholar.org/paper/34d12432af63915caf14eab9a362f7e7d24e4c13,arXiv.org,2023.0,60.0,12.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40895660', 'name': 'Sarah Fakhoury'}, {'authorId': '47570053', 'name': 'Saikat Chakraborty'}, {'authorId': '1702346', 'name': 'M. Musuvathi'}, {'authorId': '145474353', 'name': 'Shuvendu K. Lahiri'}]",['Microsoft'],['India'],2023-04
2304.04083,Donggang Jia,"Donggang Jia, Alexandra Irger, Ondrej Strnad, Johanna Bjorklund,
  Anders Ynnerman, Ivan Viola","VOICE: Visual Oracle for Interaction, Conversation, and Explanation",,,,,cs.HC cs.GR,http://creativecommons.org/licenses/by-sa/4.0/,"  We present VOICE, a novel approach for connecting large language models' (LLM) conversational capabilities with interactive exploratory visualization. VOICE introduces several innovative technical contributions that drive our conversational visualization framework. Our foundation is a pack-of-bots that can perform specific tasks, such as assigning tasks, extracting instructions, and generating coherent content. We employ fine-tuning and prompt engineering techniques to tailor bots' performance to their specific roles and accurately respond to user queries, and a new prompt-based iterative scene-tree generation establishes a coupling with a structural model. Our text-to-visualization method generates a flythrough sequence matching the content explanation. Finally, 3D natural language interaction provides capabilities to navigate and manipulate the 3D models in real-time. The VOICE framework can receive arbitrary voice commands from the user and responds verbally, tightly coupled with corresponding visual representation with low latency and high accuracy. We demonstrate the effectiveness and high generalizability potential of our approach by applying it to two distinct domains: analyzing three 3D molecular models with multi-scale and multi-instance attributes, and showcasing its effectiveness on a cartographic map visualization. A free copy of this paper and all supplemental materials are available at https://osf.io/g7fbr/. ","[{'version': 'v1', 'created': 'Sat, 8 Apr 2023 19:06:36 GMT'}]",2023-04-11,"[['Jia', 'Donggang', ''], ['Irger', 'Alexandra', ''], ['Strnad', 'Ondrej', ''], ['Bjorklund', 'Johanna', ''], ['Ynnerman', 'Anders', ''], ['Viola', 'Ivan', '']]",0,0,2023-04-08,1,6,2,0,0,0,8ca384547bb4b21b7f38d478119bf3168eb9c9cd,258048738.0,https://www.semanticscholar.org/paper/8ca384547bb4b21b7f38d478119bf3168eb9c9cd,arXiv.org,2023.0,56.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2213761788', 'name': 'Donggang Jia'}, {'authorId': '2214044396', 'name': 'Alexandra Irger'}, {'authorId': '2396269', 'name': 'Ondrej Strnad'}, {'authorId': '3998881', 'name': 'Johanna Björklund'}, {'authorId': '1697451', 'name': 'A. Ynnerman'}, {'authorId': '1736888', 'name': 'I. Viola'}]","['TU Wien', 'Linköping University', 'King Abdullah University of Science and Technology', 'Umeå University']","['Saudi Arabia', 'Austria', 'Sweden']",2023-04
2304.04099,Susik Yoon,"Susik Yoon, Dongha Lee, Yunyi Zhang, Jiawei Han",Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding,Accepted by SIGIR'23,,,,cs.IR cs.CL cs.DB cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Unsupervised discovery of stories with correlated news articles in real-time helps people digest massive news streams without expensive human annotations. A common approach of the existing studies for unsupervised online story discovery is to represent news articles with symbolic- or graph-based embedding and incrementally cluster them into stories. Recent large language models are expected to improve the embedding further, but a straightforward adoption of the models by indiscriminately encoding all information in articles is ineffective to deal with text-rich and evolving news streams. In this work, we propose a novel thematic embedding with an off-the-shelf pretrained sentence encoder to dynamically represent articles and stories by considering their shared temporal themes. To realize the idea for unsupervised online story discovery, a scalable framework USTORY is introduced with two main techniques, theme- and time-aware dynamic embedding and novelty-aware adaptive clustering, fueled by lightweight story summaries. A thorough evaluation with real news data sets demonstrates that USTORY achieves higher story discovery performances than baselines while being robust and scalable to various streaming settings. ","[{'version': 'v1', 'created': 'Sat, 8 Apr 2023 20:41:15 GMT'}, {'version': 'v2', 'created': 'Sat, 22 Apr 2023 15:48:07 GMT'}, {'version': 'v3', 'created': 'Thu, 4 May 2023 04:36:23 GMT'}]",2023-05-05,"[['Yoon', 'Susik', ''], ['Lee', 'Dongha', ''], ['Zhang', 'Yunyi', ''], ['Han', 'Jiawei', '']]",0,0,2023-04-08,3,4,4,0,0,0,93a7e45abbc0e4c522bc49953435fb16efa5cea9,258048517.0,https://www.semanticscholar.org/paper/93a7e45abbc0e4c522bc49953435fb16efa5cea9,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,57.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3396235', 'name': 'Susik Yoon'}, {'authorId': '3067773', 'name': 'Dongha Lee'}, {'authorId': '48379289', 'name': 'Yunyi Zhang'}, {'authorId': '2111759643', 'name': 'Jiawei Han'}]",['Yonsei University'],['South Korea'],2023-04
2304.04227,Jun Chen,"Jun Chen, Deyao Zhu, Kilichbek Haydarov, Xiang Li, Mohamed Elhoseiny",Video ChatCaptioner: Towards Enriched Spatiotemporal Descriptions,,,,,cs.CV cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Video captioning aims to convey dynamic scenes from videos using natural language, facilitating the understanding of spatiotemporal information within our environment. Although there have been recent advances, generating detailed and enriched video descriptions continues to be a substantial challenge. In this work, we introduce Video ChatCaptioner, an innovative approach for creating more comprehensive spatiotemporal video descriptions. Our method employs a ChatGPT model as a controller, specifically designed to select frames for posing video content-driven questions. Subsequently, a robust algorithm is utilized to answer these visual queries. This question-answer framework effectively uncovers intricate video details and shows promise as a method for enhancing video content. Following multiple conversational rounds, ChatGPT can summarize enriched video content based on previous conversations. We qualitatively demonstrate that our Video ChatCaptioner can generate captions containing more visual details about the videos. The code is publicly available at https://github.com/Vision-CAIR/ChatCaptioner ","[{'version': 'v1', 'created': 'Sun, 9 Apr 2023 12:46:18 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Apr 2023 11:22:45 GMT'}, {'version': 'v3', 'created': 'Wed, 24 May 2023 14:01:54 GMT'}]",2023-05-25,"[['Chen', 'Jun', ''], ['Zhu', 'Deyao', ''], ['Haydarov', 'Kilichbek', ''], ['Li', 'Xiang', ''], ['Elhoseiny', 'Mohamed', '']]",1,1,2023-04-09,3,5,2,1,0,1,0ebc861f5478561f12941e6b48aad30574e996d8,258048445.0,https://www.semanticscholar.org/paper/0ebc861f5478561f12941e6b48aad30574e996d8,arXiv.org,2023.0,44.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153417252', 'name': 'Jun Chen'}, {'authorId': '1388731230', 'name': 'Deyao Zhu'}, {'authorId': '90997182', 'name': 'Kilichbek Haydarov'}, {'authorId': '2144440192', 'name': 'Xiang Li'}, {'authorId': '1712479', 'name': 'Mohamed Elhoseiny'}]",['King Abdullah University of Science and Technology'],['Saudi Arabia'],2023-04
2304.04309,Maxim Vidgof,"Maxim Vidgof, Stefan Bachhofner, Jan Mendling",Large Language Models for Business Process Management: Opportunities and Challenges,,,,,cs.SE,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large language models are deep learning models with a large number of parameters. The models made noticeable progress on a large number of tasks, and as a consequence allowing them to serve as valuable and versatile tools for a diverse range of applications. Their capabilities also offer opportunities for business process management, however, these opportunities have not yet been systematically investigated. In this paper, we address this research problem by foregrounding various management tasks of the BPM lifecycle. We investigate six research directions highlighting problems that need to be addressed when using large language models, including usage guidelines for practitioners. ","[{'version': 'v1', 'created': 'Sun, 9 Apr 2023 20:32:09 GMT'}]",2023-04-11,"[['Vidgof', 'Maxim', ''], ['Bachhofner', 'Stefan', ''], ['Mendling', 'Jan', '']]",0,0,2023-04-09,1,3,1,0,0,0,fa302c87b1a886f18a62070d744b42f1a6df00ed,258048823.0,https://www.semanticscholar.org/paper/fa302c87b1a886f18a62070d744b42f1a6df00ed,International Conference on Business Process Management,2023.0,32.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1723749426', 'name': 'Maxim Vidgof'}, {'authorId': '19288379', 'name': 'Stefan Bachhofner'}, {'authorId': '1776002', 'name': 'J. Mendling'}]","['Humboldt-Universität zu Berlin', 'Weizenbaum Institute for the Networked Society', 'Vienna University of Economics and Business']","['Germany', 'Austria']",2023-04
2304.05193,Jian Wang Jornbowrl,"Jian Wang, Shangqing Liu, Xiaofei Xie, Yi Li",Evaluating AIGC Detectors on Code Content,,,,,cs.SE,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Artificial Intelligence Generated Content (AIGC) has garnered considerable attention for its impressive performance, with ChatGPT emerging as a leading AIGC model that produces high-quality responses across various applications, including software development and maintenance. Despite its potential, the misuse of ChatGPT poses significant concerns, especially in education and safetycritical domains. Numerous AIGC detectors have been developed and evaluated on natural language data. However, their performance on code-related content generated by ChatGPT remains unexplored. To fill this gap, in this paper, we present the first empirical study on evaluating existing AIGC detectors in the software domain. We created a comprehensive dataset including 492.5K samples comprising code-related content produced by ChatGPT, encompassing popular software activities like Q&A (115K), code summarization (126K), and code generation (226.5K). We evaluated six AIGC detectors, including three commercial and three open-source solutions, assessing their performance on this dataset. Additionally, we conducted a human study to understand human detection capabilities and compare them with the existing AIGC detectors. Our results indicate that AIGC detectors demonstrate lower performance on code-related data compared to natural language data. Fine-tuning can enhance detector performance, especially for content within the same domain; but generalization remains a challenge. The human evaluation reveals that detection by humans is quite challenging. ","[{'version': 'v1', 'created': 'Tue, 11 Apr 2023 12:54:42 GMT'}]",2023-04-12,"[['Wang', 'Jian', ''], ['Liu', 'Shangqing', ''], ['Xie', 'Xiaofei', ''], ['Li', 'Yi', '']]",1,1,2023-04-11,1,4,1,1,0,1,2d51e79d541bb489b07aa4fa691a93a9d4a0498b,258060085.0,https://www.semanticscholar.org/paper/2d51e79d541bb489b07aa4fa691a93a9d4a0498b,arXiv.org,2023.0,56.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152765881', 'name': 'Jian Wang'}, {'authorId': '13877308', 'name': 'Shangqing Liu'}, {'authorId': '49419199', 'name': 'Xiaofei Xie'}, {'authorId': '2153683323', 'name': 'Yi Li'}]","['Nanyang Technological University', 'Singapore Management University']",['Singapore'],2023-04
2304.05253,Ekaterina Svikhnushina,Ekaterina Svikhnushina and Pearl Pu,Approximating Online Human Evaluation of Social Chatbots with Prompting,accepted to SIGDIAL 2023 (long paper),,,,cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  As conversational models become increasingly available to the general public, users are engaging with this technology in social interactions. Such unprecedented interaction experiences may pose considerable social and psychological risks to the users unless the technology is properly controlled. This highlights the need for scalable and robust evaluation metrics for conversational chatbots. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the bots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation leveraging large language models (LLMs) from the GPT family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora. ","[{'version': 'v1', 'created': 'Tue, 11 Apr 2023 14:45:01 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Aug 2023 12:58:41 GMT'}]",2023-08-28,"[['Svikhnushina', 'Ekaterina', ''], ['Pu', 'Pearl', '']]",0,1,2023-04-11,2,2,2,0,0,0,211260fa3827240f55ae2f40d3d9174f2f866828,258060102.0,https://www.semanticscholar.org/paper/211260fa3827240f55ae2f40d3d9174f2f866828,SIGDIAL Conferences,2023.0,56.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '71187509', 'name': 'Ekaterina Svikhnushina'}, {'authorId': '2188780149', 'name': 'Pearl Pu'}]",['École Polytechnique Fédérale de Lausanne'],['Switzerland'],2023-04
2304.05406,Ioana Ciuc\u{a},Ioana Ciuc\u{a} and Yuan-Sen Ting,Galactic ChitChat: Using Large Language Models to Converse with Astronomy Literature,"3 pages, published in RNAAS",,,,cs.CL astro-ph.GA astro-ph.IM,http://creativecommons.org/licenses/by/4.0/,"  We demonstrate the potential of the state-of-the-art OpenAI GPT-4 large language model to engage in meaningful interactions with Astronomy papers using in-context prompting. To optimize for efficiency, we employ a distillation technique that effectively reduces the size of the original input paper by 50\%, while maintaining the paragraph structure and overall semantic integrity. We then explore the model's responses using a multi-document context (ten distilled documents). Our findings indicate that GPT-4 excels in the multi-document domain, providing detailed answers contextualized within the framework of related research findings. Our results showcase the potential of large language models for the astronomical community, offering a promising avenue for further exploration, particularly the possibility of utilizing the models for hypothesis generation. ","[{'version': 'v1', 'created': 'Wed, 12 Apr 2023 03:02:20 GMT'}, {'version': 'v2', 'created': 'Tue, 12 Sep 2023 00:42:21 GMT'}]",2023-09-13,"[['Ciucă', 'Ioana', ''], ['Ting', 'Yuan-Sen', '']]",0,1,2023-04-12,2,2,3,1,0,1,4ed22959e6cd713f1440e4eaee0e454fe9db48b1,258079242.0,https://www.semanticscholar.org/paper/4ed22959e6cd713f1440e4eaee0e454fe9db48b1,Research Notes of the AAS,2023.0,14.0,2.0,0.0,True,"['Physics', 'Computer Science']","[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50062876', 'name': 'I. Ciucă'}, {'authorId': '93622633', 'name': 'Y. Ting'}]",['Australian National University'],['Australia'],2023-04
2304.05454,Chenhan Yuan,"Chenhan Yuan, Qianqian Xie, Sophia Ananiadou",Zero-shot Temporal Relation Extraction with ChatGPT,"12 pages, 4 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The goal of temporal relation extraction is to infer the temporal relation between two events in the document. Supervised models are dominant in this task. In this work, we investigate ChatGPT's ability on zero-shot temporal relation extraction. We designed three different prompt techniques to break down the task and evaluate ChatGPT. Our experiments show that ChatGPT's performance has a large gap with that of supervised methods and can heavily rely on the design of prompts. We further demonstrate that ChatGPT can infer more small relation classes correctly than supervised methods. The current shortcomings of ChatGPT on temporal relation extraction are also discussed in this paper. We found that ChatGPT cannot keep consistency during temporal inference and it fails in actively long-dependency temporal inference. ","[{'version': 'v1', 'created': 'Tue, 11 Apr 2023 18:59:05 GMT'}]",2023-04-13,"[['Yuan', 'Chenhan', ''], ['Xie', 'Qianqian', ''], ['Ananiadou', 'Sophia', '']]",1,1,2023-04-11,1,3,2,1,0,1,2a663560b669a0b8d975675b3ac2546cc7386f3a,258078959.0,https://www.semanticscholar.org/paper/2a663560b669a0b8d975675b3ac2546cc7386f3a,Workshop on Biomedical Natural Language Processing,2023.0,43.0,19.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145341207', 'name': 'Chenhan Yuan'}, {'authorId': '145229872', 'name': 'Qianqian Xie'}, {'authorId': '1881965', 'name': 'S. Ananiadou'}]",['University of Manchester'],['United Kingdom'],2023-04
2304.05534,Wataru Zaitsu,"Wataru Zaitsu, Mingzhe Jin","Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers through Japanese stylometric analysis","17 pages, 5 figures, 5 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the first half of 2023, text-generative artificial intelligence (AI), including ChatGPT, equipped with GPT-3.5 and GPT-4, from OpenAI, has attracted considerable attention worldwide. In this study, first, we compared Japanese stylometric features of texts generated by GPT (-3.5 and -4) and those written by humans. In this work, we performed multi-dimensional scaling (MDS) to confirm the distributions of 216 texts of three classes (72 academic papers written by 36 single authors, 72 texts generated by GPT-3.5, and 72 texts generated by GPT-4 on the basis of the titles of the aforementioned papers) focusing on the following stylometric features: (1) bigrams of parts-of-speech, (2) bigram of postpositional particle words, (3) positioning of commas, and (4) rate of function words. MDS revealed distinct distributions at each stylometric feature of GPT (-3.5 and -4) and human. Although GPT-4 is more powerful than GPT-3.5 because it has more parameters, both GPT (-3.5 and -4) distributions are likely to overlap. These results indicate that although the number of parameters may increase in the future, GPT-generated texts may not be close to that written by humans in terms of stylometric features. Second, we verified the classification performance of random forest (RF) for two classes (GPT and human) focusing on Japanese stylometric features. This study revealed the high performance of RF in each stylometric feature: The RF classifier focusing on the rate of function words achieved 98.1% accuracy. Furthermore the RF classifier focusing on all stylometric features reached 100% in terms of all performance indexes (accuracy, recall, precision, and F1 score). This study concluded that at this stage we human discriminate ChatGPT from human limited to Japanese language. ","[{'version': 'v1', 'created': 'Tue, 11 Apr 2023 23:29:56 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Apr 2023 00:50:59 GMT'}, {'version': 'v3', 'created': 'Sat, 3 Jun 2023 01:52:58 GMT'}]",2023-06-06,"[['Zaitsu', 'Wataru', ''], ['Jin', 'Mingzhe', '']]",1,1,2023-04-11,3,2,1,3,0,3,15906b721cbe5026693f0e3dd5a8df98bf2ac955,258079167.0,https://www.semanticscholar.org/paper/15906b721cbe5026693f0e3dd5a8df98bf2ac955,PLoS ONE,2023.0,13.0,5.0,1.0,True,"['Medicine', 'Computer Science']","[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '6520291', 'name': 'Wataru Zaitsu'}, {'authorId': '9519956', 'name': 'Mingzhe Jin'}]","['Mejiro University', 'Kyoto University of Advanced Science']",['Japan'],2023-04
2304.05774,Michalis Mountantonakis,Michalis Mountantonakis and Yannis Tzitzikas,Using Multiple RDF Knowledge Graphs for Enriching ChatGPT Responses,,,,,cs.DB cs.AI,http://creativecommons.org/licenses/by/4.0/,"  There is a recent trend for using the novel Artificial Intelligence ChatGPT chatbox, which provides detailed responses and articulate answers across many domains of knowledge. However, in many cases it returns plausible-sounding but incorrect or inaccurate responses, whereas it does not provide evidence. Therefore, any user has to further search for checking the accuracy of the answer or/and for finding more information about the entities of the response. At the same time there is a high proliferation of RDF Knowledge Graphs (KGs) over any real domain, that offer high quality structured data. For enabling the combination of ChatGPT and RDF KGs, we present a research prototype, called GPToLODS, which is able to enrich any ChatGPT response with more information from hundreds of RDF KGs. In particular, it identifies and annotates each entity of the response with statistics and hyperlinks to LODsyndesis KG (which contains integrated data from 400 RDF KGs and over 412 million entities). In this way, it is feasible to enrich the content of entities and to perform fact checking and validation for the facts of the response at real time. ","[{'version': 'v1', 'created': 'Wed, 12 Apr 2023 11:33:00 GMT'}]",2023-04-13,"[['Mountantonakis', 'Michalis', ''], ['Tzitzikas', 'Yannis', '']]",1,1,2023-04-12,1,2,2,1,0,1,05a28a275718410d8c799a216d7b16e98cdd9b88,258079290.0,https://www.semanticscholar.org/paper/05a28a275718410d8c799a216d7b16e98cdd9b88,ECML/PKDD,2023.0,17.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2081511', 'name': 'M. Mountantonakis'}, {'authorId': '1801959', 'name': 'Yannis Tzitzikas'}]","['University of Crete', 'FORTH Institute of Computer Science']",['Greece'],2023-04
2304.06123,Tarry Singh,Tarry Singh,The Impact of Large Language Multi-Modal Models on the Future of Job Market,"16 pages, 1 Table",,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  The rapid advancements in artificial intelligence, particularly in large language multi-modal models like GPT-4, have raised concerns about the potential displacement of human workers in various industries. This position paper aims to analyze the current state of job replacement by AI models and explores potential implications and strategies for a balanced coexistence between AI and human workers. ","[{'version': 'v1', 'created': 'Wed, 22 Mar 2023 16:33:57 GMT'}]",2023-04-14,"[['Singh', 'Tarry', '']]",0,1,2023-03-22,1,1,1,1,0,1,b30f09043449b9d55ad7978086359ef6c76fec36,258108234.0,https://www.semanticscholar.org/paper/b30f09043449b9d55ad7978086359ef6c76fec36,arXiv.org,2023.0,3.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '21914709', 'name': 'Tarry Singh'}]","['Department of AI Research deepkapha AI Research 9401 GE, Assen The Netherlands']",['Netherlands'],2023-03
2304.06148,Panagiotis Theocharopoulos,"Panagiotis C. Theocharopoulos, Panagiotis Anagnostou, Anastasia
  Tsoukala, Spiros V. Georgakopoulos, Sotiris K. Tasoulis and Vassilis P.
  Plagianakos",Detection of Fake Generated Scientific Abstracts,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The widespread adoption of Large Language Models and publicly available ChatGPT has marked a significant turning point in the integration of Artificial Intelligence into people's everyday lives. The academic community has taken notice of these technological advancements and has expressed concerns regarding the difficulty of discriminating between what is real and what is artificially generated. Thus, researchers have been working on developing effective systems to identify machine-generated text. In this study, we utilize the GPT-3 model to generate scientific paper abstracts through Artificial Intelligence and explore various text representation methods when combined with Machine Learning models with the aim of identifying machine-written text. We analyze the models' performance and address several research questions that rise during the analysis of the results. By conducting this research, we shed light on the capabilities and limitations of Artificial Intelligence generated text. ","[{'version': 'v1', 'created': 'Wed, 12 Apr 2023 20:20:22 GMT'}]",2023-04-14,"[['Theocharopoulos', 'Panagiotis C.', ''], ['Anagnostou', 'Panagiotis', ''], ['Tsoukala', 'Anastasia', ''], ['Georgakopoulos', 'Spiros V.', ''], ['Tasoulis', 'Sotiris K.', ''], ['Plagianakos', 'Vassilis P.', '']]",1,1,2023-04-12,1,6,1,2,0,2,ff538143e22eaadc13e7351dac0fad233a67af19,258108316.0,https://www.semanticscholar.org/paper/ff538143e22eaadc13e7351dac0fad233a67af19,International Conference on Big Data Computing Service and Applications,2023.0,30.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '91628156', 'name': 'P. Theocharopoulos'}, {'authorId': '51309340', 'name': 'Panagiotis Anagnostou'}, {'authorId': '2174070682', 'name': 'Anastasia Tsoukala'}, {'authorId': '2144739', 'name': 'S. Georgakopoulos'}, {'authorId': '1719550', 'name': 'S. Tasoulis'}, {'authorId': '1742582', 'name': 'V. Plagianakos'}]",['University of Thessaly'],['Greece'],2023-04
2304.06588,"Petter T\""ornberg","Petter T\""ornberg",ChatGPT-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-Shot Learning,"5 pages, 3 figures",,,,cs.CL cs.AI cs.SI,http://creativecommons.org/licenses/by/4.0/,"  This paper assesses the accuracy, reliability and bias of the Large Language Model (LLM) ChatGPT-4 on the text analysis task of classifying the political affiliation of a Twitter poster based on the content of a tweet. The LLM is compared to manual annotation by both expert classifiers and crowd workers, generally considered the gold standard for such tasks. We use Twitter messages from United States politicians during the 2020 election, providing a ground truth against which to measure accuracy. The paper finds that ChatGPT-4 has achieves higher accuracy, higher reliability, and equal or lower bias than the human classifiers. The LLM is able to correctly annotate messages that require reasoning on the basis of contextual knowledge, and inferences around the author's intentions - traditionally seen as uniquely human abilities. These findings suggest that LLM will have substantial impact on the use of textual data in the social sciences, by enabling interpretive research at a scale. ","[{'version': 'v1', 'created': 'Thu, 13 Apr 2023 14:51:40 GMT'}]",2023-04-14,"[['Törnberg', 'Petter', '']]",1,1,2023-04-13,1,1,3,1,0,1,6354f2639d07bf8d5b08a4dcaef4c5db5fe19fdb,258108255.0,https://www.semanticscholar.org/paper/6354f2639d07bf8d5b08a4dcaef4c5db5fe19fdb,arXiv.org,2023.0,26.0,43.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2265518947', 'name': 'Petter Törnberg'}]",['University of Amsterdam'],['Netherlands'],2023-04
2304.06638,Sabina Elkins,"Sabina Elkins, Ekaterina Kochmar, Jackie C.K. Cheung, Iulian Serban",How Useful are Educational Questions Generated by Large Language Models?,"Accepted to AIED Late Breaking Results 2023 - to be published in
  their proceedings",,,,cs.CL cs.AI cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Controllable text generation (CTG) by large language models has a huge potential to transform education for teachers and students alike. Specifically, high quality and diverse question generation can dramatically reduce the load on teachers and improve the quality of their educational content. Recent work in this domain has made progress with generation, but fails to show that real teachers judge the generated questions as sufficiently useful for the classroom setting; or if instead the questions have errors and/or pedagogically unhelpful content. We conduct a human evaluation with teachers to assess the quality and usefulness of outputs from combining CTG and question taxonomies (Bloom's and a difficulty taxonomy). The results demonstrate that the questions generated are high quality and sufficiently useful, showing their promise for widespread use in the classroom setting. ","[{'version': 'v1', 'created': 'Thu, 13 Apr 2023 16:05:25 GMT'}]",2023-04-14,"[['Elkins', 'Sabina', ''], ['Kochmar', 'Ekaterina', ''], ['Cheung', 'Jackie C. K.', ''], ['Serban', 'Iulian', '']]",0,0,2023-04-13,1,4,4,1,1,0,b181a887f4977a58de209edd694ed72237e5f640,258108262.0,https://www.semanticscholar.org/paper/b181a887f4977a58de209edd694ed72237e5f640,International Conference on Artificial Intelligence in Education,2023.0,11.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2077591909', 'name': 'Sabina Elkins'}, {'authorId': '2700917', 'name': 'E. Kochmar'}, {'authorId': '3159752', 'name': 'J. Cheung'}, {'authorId': '35224828', 'name': 'Iulian Serban'}]","['Korbit Technologies Inc.', 'Canadian Institute for Advanced Research', 'McGill University', 'Mohamed bin Zayed University of Artificial Intelligence']","['Canada', 'United Arab Emirates']",2023-04
2304.06712,Aleksandar Shtedritski,"Aleksandar Shtedritski, Christian Rupprecht, Andrea Vedaldi",What does CLIP know about a red circle? Visual prompt engineering for VLMs,ICCV 2023 Oral,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Large-scale Vision-Language Models, such as CLIP, learn powerful image-text representations that have found numerous applications, from zero-shot classification to text-to-image generation. Despite that, their capabilities for solving novel discriminative tasks via prompting fall behind those of large language models, such as GPT-3. Here we explore the idea of visual prompt engineering for solving computer vision tasks beyond classification by editing in image space instead of text. In particular, we discover an emergent ability of CLIP, where, by simply drawing a red circle around an object, we can direct the model's attention to that region, while also maintaining global information. We show the power of this simple approach by achieving state-of-the-art in zero-shot referring expressions comprehension and strong performance in keypoint localization tasks. Finally, we draw attention to some potential ethical concerns of large language-vision models. ","[{'version': 'v1', 'created': 'Thu, 13 Apr 2023 17:58:08 GMT'}, {'version': 'v2', 'created': 'Fri, 18 Aug 2023 05:49:47 GMT'}]",2023-08-21,"[['Shtedritski', 'Aleksandar', ''], ['Rupprecht', 'Christian', ''], ['Vedaldi', 'Andrea', '']]",0,1,2023-04-13,2,3,1,1,0,1,2ba2a875161b6f09815817542f02f1ac9171952a,258108138.0,https://www.semanticscholar.org/paper/2ba2a875161b6f09815817542f02f1ac9171952a,arXiv.org,2023.0,68.0,12.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2258961451', 'name': 'Aleksandar Shtedritski'}, {'authorId': '49359942', 'name': 'C. Rupprecht'}, {'authorId': '1687524', 'name': 'A. Vedaldi'}]",['University of Oxford'],['United Kingdom'],2023-04
2304.06912,Ha Thanh Nguyen,"Ha-Thanh Nguyen, Randy Goebel, Francesca Toni, Kostas Stathis, Ken
  Satoh",How well do SOTA legal reasoning models support abductive reasoning?,"Workshop on Logic Programming and Legal Reasoning, @ICLP 2023",,,,cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We examine how well the state-of-the-art (SOTA) models used in legal reasoning support abductive reasoning tasks. Abductive reasoning is a form of logical inference in which a hypothesis is formulated from a set of observations, and that hypothesis is used to explain the observations. The ability to formulate such hypotheses is important for lawyers and legal scholars as it helps them articulate logical arguments, interpret laws, and develop legal theories. Our motivation is to consider the belief that deep learning models, especially large language models (LLMs), will soon replace lawyers because they perform well on tasks related to legal text processing. But to do so, we believe, requires some form of abductive hypothesis formation. In other words, while LLMs become more popular and powerful, we want to investigate their capacity for abductive reasoning. To pursue this goal, we start by building a logic-augmented dataset for abductive reasoning with 498,697 samples and then use it to evaluate the performance of a SOTA model in the legal field. Our experimental results show that although these models can perform well on tasks related to some aspects of legal text processing, they still fall short in supporting abductive reasoning tasks. ","[{'version': 'v1', 'created': 'Fri, 14 Apr 2023 03:36:24 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Jun 2023 01:27:02 GMT'}]",2023-06-30,"[['Nguyen', 'Ha-Thanh', ''], ['Goebel', 'Randy', ''], ['Toni', 'Francesca', ''], ['Stathis', 'Kostas', ''], ['Satoh', 'Ken', '']]",0,0,2023-04-14,2,5,1,0,0,0,061abff9b402c150a258017c06a7f02b1b6265b5,258170343.0,https://www.semanticscholar.org/paper/061abff9b402c150a258017c06a7f02b1b6265b5,ICLP Workshops,2023.0,34.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2716209', 'name': 'Nguyen Ha Thanh'}, {'authorId': '2063100255', 'name': 'R. Goebel'}, {'authorId': '49973505', 'name': 'Francesca Toni'}, {'authorId': '1802398', 'name': 'Kostas Stathis'}, {'authorId': '2154464229', 'name': 'Ken Satoh'}]","['Imperial College London', 'University of Alberta', 'Royal Holloway University of London', 'National Institute of Informatics']","['Canada', 'Japan', 'United Kingdom']",2023-04
2304.07002,Ciprian-Octavian Truic\u{a},"Ciprian-Octavian Truic\u{a}, Andrei-Ionut Stan, Elena-Simona Apostol",SimpLex: a lexical text simplification architecture,,"Neural Computing and Applications, 35(8):6265-6280, 2023",10.1007/s00521-022-07905-y,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Text simplification (TS) is the process of generating easy-to-understand sentences from a given sentence or piece of text. The aim of TS is to reduce both the lexical (which refers to vocabulary complexity and meaning) and syntactic (which refers to the sentence structure) complexity of a given text or sentence without the loss of meaning or nuance. In this paper, we present \textsc{SimpLex}, a novel simplification architecture for generating simplified English sentences. To generate a simplified sentence, the proposed architecture uses either word embeddings (i.e., Word2Vec) and perplexity, or sentence transformers (i.e., BERT, RoBERTa, and GPT2) and cosine similarity. The solution is incorporated into a user-friendly and simple-to-use software. We evaluate our system using two metrics, i.e., SARI, and Perplexity Decrease. Experimentally, we observe that the transformer models outperform the other models in terms of the SARI score. However, in terms of Perplexity, the Word-Embeddings-based models achieve the biggest decrease. Thus, the main contributions of this paper are: (1) We propose a new Word Embedding and Transformer based algorithm for text simplification; (2) We design \textsc{SimpLex} -- a modular novel text simplification system -- that can provide a baseline for further research; and (3) We perform an in-depth analysis of our solution and compare our results with two state-of-the-art models, i.e., LightLS [19] and NTS-w2v [44]. We also make the code publicly available online. ","[{'version': 'v1', 'created': 'Fri, 14 Apr 2023 08:52:31 GMT'}]",2023-04-17,"[['Truică', 'Ciprian-Octavian', ''], ['Stan', 'Andrei-Ionut', ''], ['Apostol', 'Elena-Simona', '']]",0,1,2023-04-14,1,3,2,1,1,0,3a62908f732c5f09014409421c78bca1f614e48a,253697682.0,https://www.semanticscholar.org/paper/3a62908f732c5f09014409421c78bca1f614e48a,Neural computing & applications (Print),2022.0,79.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '39812162', 'name': 'Ciprian-Octavian Truică'}, {'authorId': '2191469112', 'name': 'Andrei-Ionuţ Stan'}, {'authorId': '3202565', 'name': 'E. Apostol'}]","['Polytechnic University of Bucharest', 'Uppsala University']","['Romania', 'Sweden']",2023-04
2304.07183,Kiran Busch,"Kiran Busch, Alexander Rochlitzer, Diana Sola, Henrik Leopold",Just Tell Me: Prompt Engineering in Business Process Management,accepted for BPMDS 2023,,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  GPT-3 and several other language models (LMs) can effectively address various natural language processing (NLP) tasks, including machine translation and text summarization. Recently, they have also been successfully employed in the business process management (BPM) domain, e.g., for predictive process monitoring and process extraction from text. This, however, typically requires fine-tuning the employed LM, which, among others, necessitates large amounts of suitable training data. A possible solution to this problem is the use of prompt engineering, which leverages pre-trained LMs without fine-tuning them. Recognizing this, we argue that prompt engineering can help bring the capabilities of LMs to BPM research. We use this position paper to develop a research agenda for the use of prompt engineering for BPM research by identifying the associated potentials and challenges. ","[{'version': 'v1', 'created': 'Fri, 14 Apr 2023 14:55:19 GMT'}]",2023-04-17,"[['Busch', 'Kiran', ''], ['Rochlitzer', 'Alexander', ''], ['Sola', 'Diana', ''], ['Leopold', 'Henrik', '']]",0,1,2023-04-14,1,4,3,1,0,1,53e7475a3ed0caee37122a9dbdb53d1da0691a33,258170067.0,https://www.semanticscholar.org/paper/53e7475a3ed0caee37122a9dbdb53d1da0691a33,BPMDS/EMMSAD@CAiSE,2023.0,23.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2214541916', 'name': 'Kiran Busch'}, {'authorId': '2214546154', 'name': 'Alexander Rochlitzer'}, {'authorId': '2073691893', 'name': 'Diana Sola'}, {'authorId': '1785154', 'name': 'H. Leopold'}]","['Kühne Logistics University', 'University of Mannheim', 'Systems, Applications & Products in Data Processing (Germany)']",['Germany'],2023-04
2304.07333,J\'er\^ome Rutinowski,"J\'er\^ome Rutinowski, Sven Franke, Jan Endendyk, Ina Dormuth, Markus
  Pauly",The Self-Perception and Political Biases of ChatGPT,,,,,cs.CY cs.AI cs.CL cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This contribution analyzes the self-perception and political biases of OpenAI's Large Language Model ChatGPT. Taking into account the first small-scale reports and studies that have emerged, claiming that ChatGPT is politically biased towards progressive and libertarian points of view, this contribution aims to provide further clarity on this subject. For this purpose, ChatGPT was asked to answer the questions posed by the political compass test as well as similar questionnaires that are specific to the respective politics of the G7 member states. These eight tests were repeated ten times each and revealed that ChatGPT seems to hold a bias towards progressive views. The political compass test revealed a bias towards progressive and libertarian views, with the average coordinates on the political compass being (-6.48, -5.99) (with (0, 0) the center of the compass, i.e., centrism and the axes ranging from -10 to 10), supporting the claims of prior research. The political questionnaires for the G7 member states indicated a bias towards progressive views but no significant bias between authoritarian and libertarian views, contradicting the findings of prior reports, with the average coordinates being (-3.27, 0.58). In addition, ChatGPT's Big Five personality traits were tested using the OCEAN test and its personality type was queried using the Myers-Briggs Type Indicator (MBTI) test. Finally, the maliciousness of ChatGPT was evaluated using the Dark Factor test. These three tests were also repeated ten times each, revealing that ChatGPT perceives itself as highly open and agreeable, has the Myers-Briggs personality type ENFJ, and is among the 15% of test-takers with the least pronounced dark traits. ","[{'version': 'v1', 'created': 'Fri, 14 Apr 2023 18:06:13 GMT'}]",2023-04-18,"[['Rutinowski', 'Jérôme', ''], ['Franke', 'Sven', ''], ['Endendyk', 'Jan', ''], ['Dormuth', 'Ina', ''], ['Pauly', 'Markus', '']]",1,1,2023-04-14,1,5,4,1,0,1,17606dbe67df42d973015fdd35f2807b0cafc15b,258180220.0,https://www.semanticscholar.org/paper/17606dbe67df42d973015fdd35f2807b0cafc15b,arXiv.org,2023.0,30.0,19.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","[{'authorId': '2142922180', 'name': 'Jérôme Rutinowski'}, {'authorId': '2193556141', 'name': 'Sven Franke'}, {'authorId': '2214581622', 'name': 'Jan Endendyk'}, {'authorId': '1751574427', 'name': 'Ina Dormuth'}, {'authorId': '49347525', 'name': 'Markus Pauly'}]",['TU Dortmund University'],['Germany'],2023-04
2304.07396,Daniel Kapitan,"Danny M. den Hamer, Perry Schoor, Tobias B. Polak and Daniel Kapitan",Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models,"11 pages, 4 tables, 2 figures",,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Physicians considering clinical trials for their patients are met with the laborious process of checking many text based eligibility criteria. Large Language Models (LLMs) have shown to perform well for clinical information extraction and clinical reasoning, including medical tests, but not yet in real-world scenarios. This paper investigates the use of InstructGPT to assist physicians in determining eligibility for clinical trials based on a patient's summarised medical profile. Using a prompting strategy combining one-shot, selection-inference and chain-of-thought techniques, we investigate the performance of LLMs on 10 synthetically created patient profiles. Performance is evaluated at four levels: ability to identify screenable eligibility criteria from a trial given a medical profile; ability to classify for each individual criterion whether the patient qualifies; the overall classification whether a patient is eligible for a clinical trial and the percentage of criteria to be screened by physician. We evaluated against 146 clinical trials and a total of 4,135 eligibility criteria. The LLM was able to correctly identify the screenability of 72% (2,994/4,135) of the criteria. Additionally, 72% (341/471) of the screenable criteria were evaluated correctly. The resulting trial level classification as eligible or ineligible resulted in a recall of 0.5. By leveraging LLMs with a physician-in-the-loop, a recall of 1.0 and precision of 0.71 on clinical trial level can be achieved while reducing the amount of criteria to be checked by an estimated 90%. LLMs can be used to assist physicians with pre-screening of patients for clinical trials. By forcing instruction-tuned LLMs to produce chain-of-thought responses, the reasoning can be made transparent to and the decision process becomes amenable by physicians, thereby making such a system feasible for use in real-world scenarios. ","[{'version': 'v1', 'created': 'Fri, 14 Apr 2023 21:19:46 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Jun 2023 12:59:16 GMT'}]",2023-06-30,"[['Hamer', 'Danny M. den', ''], ['Schoor', 'Perry', ''], ['Polak', 'Tobias B.', ''], ['Kapitan', 'Daniel', '']]",0,1,2023-04-14,2,4,3,1,0,1,2619cb3957040ae9626158ca52675554b4ed2f43,258180303.0,https://www.semanticscholar.org/paper/2619cb3957040ae9626158ca52675554b4ed2f43,arXiv.org,2023.0,21.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '144391588', 'name': 'D. Hamer'}, {'authorId': '79315365', 'name': 'P. Schoor'}, {'authorId': '82126441', 'name': 'T. Polak'}, {'authorId': '2148713620', 'name': 'Daniel Kapitan'}]","['Eindhoven University of Technology', 'Erasmus MC', '1 myTomorrows, Amsterdam, the Netherlands.', 'Erasmus University Rotterdam']",['Netherlands'],2023-04
2304.07774,Muhammad Salman,"Muhammad Salman, Armin Haller, Sergio J. Rodr\'iguez M\'endez","Syntactic Complexity Identification, Measurement, and Reduction Through Controlled Syntactic Simplification","This work is accepted and presented in International workshop on
  Learning with Knowledge Graphs (IWLKG) at WSDM'2023 Conference",,,,cs.CL cs.IR,http://creativecommons.org/publicdomain/zero/1.0/,"  Text simplification is one of the domains in Natural Language Processing (NLP) that offers an opportunity to understand the text in a simplified manner for exploration. However, it is always hard to understand and retrieve knowledge from unstructured text, which is usually in the form of compound and complex sentences. There are state-of-the-art neural network-based methods to simplify the sentences for improved readability while replacing words with plain English substitutes and summarising the sentences and paragraphs. In the Knowledge Graph (KG) creation process from unstructured text, summarising long sentences and substituting words is undesirable since this may lead to information loss. However, KG creation from text requires the extraction of all possible facts (triples) with the same mentions as in the text. In this work, we propose a controlled simplification based on the factual information in a sentence, i.e., triple. We present a classical syntactic dependency-based approach to split and rephrase a compound and complex sentence into a set of simplified sentences. This simplification process will retain the original wording with a simple structure of possible domain facts in each sentence, i.e., triples. The paper also introduces an algorithm to identify and measure a sentence's syntactic complexity (SC), followed by reduction through a controlled syntactic simplification process. Last, an experiment for a dataset re-annotation is also conducted through GPT3; we aim to publish this refined corpus as a resource. This work is accepted and presented in International workshop on Learning with Knowledge Graphs (IWLKG) at WSDM-2023 Conference. The code and data is available at www.github.com/sallmanm/SynSim. ","[{'version': 'v1', 'created': 'Sun, 16 Apr 2023 13:13:58 GMT'}]",2023-04-18,"[['Salman', 'Muhammad', ''], ['Haller', 'Armin', ''], ['Méndez', 'Sergio J. Rodríguez', '']]",0,1,2023-04-16,1,3,2,1,0,1,8d0423677766e11f87124676c4507834df835b80,258180435.0,https://www.semanticscholar.org/paper/8d0423677766e11f87124676c4507834df835b80,arXiv.org,2023.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2189984180', 'name': 'M. Salman'}, {'authorId': '1712453', 'name': 'A. Haller'}, {'authorId': '2125183970', 'name': ""Sergio J. Rodr'iguez M'endez""}]",['Australian National University'],['Australia'],2023-04
2304.08115,Mehrdad Farahani,"Mehrdad Farahani, Richard Johansson",An Empirical Study of Multitask Learning to Improve Open Domain Dialogue Systems,"11 pages, 1 figure, 4 tables, 2 appendices, NoDaLiDa2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Autoregressive models used to generate responses in open-domain dialogue systems often struggle to take long-term context into account and to maintain consistency over a dialogue. Previous research in open-domain dialogue generation has shown that the use of \emph{auxiliary tasks} can introduce inductive biases that encourage the model to improve these qualities. However, most previous research has focused on encoder-only or encoder/decoder models, while the use of auxiliary tasks in \emph{decoder-only} autoregressive models is under-explored. This paper describes an investigation where four different auxiliary tasks are added to small and medium-sized GPT-2 models fine-tuned on the PersonaChat and DailyDialog datasets. The results show that the introduction of the new auxiliary tasks leads to small but consistent improvement in evaluations of the investigated models. ","[{'version': 'v1', 'created': 'Mon, 17 Apr 2023 09:44:56 GMT'}]",2023-04-18,"[['Farahani', 'Mehrdad', ''], ['Johansson', 'Richard', '']]",0,1,2023-04-17,1,2,1,1,1,0,40c93da6c0059560685da3e50b65ed97b8348b53,258179929.0,https://www.semanticscholar.org/paper/40c93da6c0059560685da3e50b65ed97b8348b53,Nordic Conference of Computational Linguistics,2023.0,34.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2055379347', 'name': 'M. Farahani'}, {'authorId': '145341661', 'name': 'Richard Johansson'}]","['Chalmers University of Technology', 'University of Gothenburg']",['Sweden'],2023-04
2304.08442,Jean Kaddour,Jean Kaddour,The MiniPile Challenge for Data-Efficient Language Models,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The ever-growing diversity of pre-training text corpora has equipped language models with generalization capabilities across various downstream tasks. However, such diverse datasets are often too large for academic budgets; hence, most research on Transformer architectures, training procedures, optimizers, etc. gets conducted on smaller, homogeneous datasets. To this end, we present The MiniPile Challenge, where one pre-trains a language model on a diverse text corpus containing at most 1M documents. MiniPile is a 6GB subset of the deduplicated 825GB The Pile corpus. To curate MiniPile, we perform a simple, three-step data filtering process: we (1) infer embeddings for all documents of the Pile, (2) cluster the embedding space using $k$-means, and (3) filter out low-quality clusters. To verify MiniPile's suitability for language model pre-training, we use it to pre-train a BERT and T5 model, yielding a performance drop of only $1.9\%$/$2.5\%$ on the GLUE and SNI benchmarks compared to the original pre-trained checkpoints trained on $2.6$x/$745$x the amount of data. MiniPile is available at https://huggingface.co/datasets/JeanKaddour/minipile. ","[{'version': 'v1', 'created': 'Mon, 17 Apr 2023 17:03:56 GMT'}]",2023-04-18,"[['Kaddour', 'Jean', '']]",0,0,2023-04-17,1,1,2,1,1,0,78f599fbd62dcc4a8dbab9d2f6056815dfc5b84c,258180536.0,https://www.semanticscholar.org/paper/78f599fbd62dcc4a8dbab9d2f6056815dfc5b84c,arXiv.org,2023.0,61.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66914903', 'name': 'Jean Kaddour'}]",['University College London'],['United Kingdom'],2023-04
2304.08968,Andrei Kucharavy,"Da Silva Gameiro Henrique, Andrei Kucharavy and Rachid Guerraoui",Stochastic Parrots Looking for Stochastic Parrots: LLMs are Easy to Fine-Tune and Hard to Detect with other LLMs,"15 pages, 6 figures; 10 pages, 7 figures Supplementary Materials;
  under review at ECML 2023",,,,cs.CL cs.AI cs.CR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The self-attention revolution allowed generative language models to scale and achieve increasingly impressive abilities. Such models - commonly referred to as Large Language Models (LLMs) - have recently gained prominence with the general public, thanks to conversational fine-tuning, putting their behavior in line with public expectations regarding AI. This prominence amplified prior concerns regarding the misuse of LLMs and led to the emergence of numerous tools to detect LLMs in the wild.   Unfortunately, most such tools are critically flawed. While major publications in the LLM detectability field suggested that LLMs were easy to detect with fine-tuned autoencoders, the limitations of their results are easy to overlook. Specifically, they assumed publicly available generative models without fine-tunes or non-trivial prompts. While the importance of these assumptions has been demonstrated, until now, it remained unclear how well such detection could be countered.   Here, we show that an attacker with access to such detectors' reference human texts and output not only evades detection but can fully frustrate the detector training - with a reasonable budget and all its outputs labeled as such. Achieving it required combining common ""reinforcement from critic"" loss function modification and AdamW optimizer, which led to surprisingly good fine-tuning generalization. Finally, we warn against the temptation to transpose the conclusions obtained in RNN-driven text GANs to LLMs due to their better representative ability.   These results have critical implications for the detection and prevention of malicious use of generative language models, and we hope they will aid the designers of generative models and detectors. ","[{'version': 'v1', 'created': 'Tue, 18 Apr 2023 13:05:01 GMT'}]",2023-04-19,"[['Henrique', 'Da Silva Gameiro', ''], ['Kucharavy', 'Andrei', ''], ['Guerraoui', 'Rachid', '']]",0,0,2023-04-18,1,3,4,0,0,0,5ebb98f1f7edcb700266d7dd6ecb48428a70435a,258187341.0,https://www.semanticscholar.org/paper/5ebb98f1f7edcb700266d7dd6ecb48428a70435a,arXiv.org,2023.0,67.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2214623424', 'name': 'Da Silva Gameiro Henrique'}, {'authorId': '6564918', 'name': 'Andrei Kucharavy'}, {'authorId': '1727558', 'name': 'R. Guerraoui'}]","['École Polytechnique Fédérale de Lausanne', 'HES-SO Valais-Wallis']",['Switzerland'],2023-04
2304.08979,Xinyue Shen,Xinyue Shen and Zeyuan Chen and Michael Backes and Yang Zhang,In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT,,,,,cs.CR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The way users acquire information is undergoing a paradigm shift with the advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves knowledge from the model itself and generates answers for users. ChatGPT's impressive question-answering (QA) capability has attracted more than 100 million users within a short period of time but has also raised concerns regarding its reliability. In this paper, we perform the first large-scale measurement of ChatGPT's reliability in the generic QA scenario with a carefully curated set of 5,695 questions across ten datasets and eight domains. We find that ChatGPT's reliability varies across different domains, especially underperforming in law and science questions. We also demonstrate that system roles, originally designed by OpenAI to allow users to steer ChatGPT's behavior, can impact ChatGPT's reliability in an imperceptible way. We further show that ChatGPT is vulnerable to adversarial examples, and even a single character change can negatively affect its reliability in certain cases. We believe that our study provides valuable insights into ChatGPT's reliability and underscores the need for strengthening the reliability and security of large language models (LLMs). ","[{'version': 'v1', 'created': 'Tue, 18 Apr 2023 13:20:45 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Oct 2023 13:27:12 GMT'}]",2023-10-06,"[['Shen', 'Xinyue', ''], ['Chen', 'Zeyuan', ''], ['Backes', 'Michael', ''], ['Zhang', 'Yang', '']]",1,1,2023-04-18,2,4,2,1,0,1,ba82f8aa4526c326dc0e82e7443a017a409b865a,258187122.0,https://www.semanticscholar.org/paper/ba82f8aa4526c326dc0e82e7443a017a409b865a,arXiv.org,2023.0,78.0,26.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2047395411', 'name': 'Xinyue Shen'}, {'authorId': '2111435173', 'name': 'Z. Chen'}, {'authorId': '144588806', 'name': 'M. Backes'}, {'authorId': '1698138', 'name': 'Yang Zhang'}]","['Helmholtz Center for Information Security', 'Individual Researcher']",['Germany'],2023-04
2304.09337,Bryan Wang,"Stephen Brade, Bryan Wang, Mauricio Sousa, Sageev Oore, Tovi Grossman",Promptify: Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models,,,,,cs.HC cs.AI cs.MM,http://creativecommons.org/licenses/by/4.0/,"  Text-to-image generative models have demonstrated remarkable capabilities in generating high-quality images based on textual prompts. However, crafting prompts that accurately capture the user's creative intent remains challenging. It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention. To address the challenges, we present Promptify, an interactive system that supports prompt exploration and refinement for text-to-image generative models. Promptify utilizes a suggestion engine powered by large language models to help users quickly explore and craft diverse prompts. Our interface allows users to organize the generated images flexibly, and based on their preferences, Promptify suggests potential changes to the original prompt. This feedback loop enables users to iteratively refine their prompts and enhance desired features while avoiding unwanted ones. Our user study shows that Promptify effectively facilitates the text-to-image workflow and outperforms an existing baseline tool widely used for text-to-image generation. ","[{'version': 'v1', 'created': 'Tue, 18 Apr 2023 22:59:11 GMT'}]",2023-04-20,"[['Brade', 'Stephen', ''], ['Wang', 'Bryan', ''], ['Sousa', 'Mauricio', ''], ['Oore', 'Sageev', ''], ['Grossman', 'Tovi', '']]",0,0,2023-04-18,1,5,3,0,0,0,421a3f9355c83e30f9b6fd0df2f295430fc1766d,258212979.0,https://www.semanticscholar.org/paper/421a3f9355c83e30f9b6fd0df2f295430fc1766d,ACM Symposium on User Interface Software and Technology,2023.0,61.0,7.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2007691758', 'name': 'Stephen Brade'}, {'authorId': '2144555136', 'name': 'Bryan Wang'}, {'authorId': '145480058', 'name': 'Maurício Sousa'}, {'authorId': '2102511', 'name': 'Sageev Oore'}, {'authorId': '2666589', 'name': 'Tovi Grossman'}]","['University of Toronto', 'Dalhousie University']",['Canada'],2023-04
2304.09655,Raphael Khoury,"Rapha\""el Khoury and Anderson R. Avila and Jacob Brunelle and Baba
  Mamadou Camara",How Secure is Code Generated by ChatGPT?,,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  In recent years, large language models have been responsible for great advances in the field of artificial intelligence (AI). ChatGPT in particular, an AI chatbot developed and recently released by OpenAI, has taken the field to the next level. The conversational model is able not only to process human-like text, but also to translate natural language into code. However, the safety of programs generated by ChatGPT should not be overlooked. In this paper, we perform an experiment to address this issue. Specifically, we ask ChatGPT to generate a number of program and evaluate the security of the resulting source code. We further investigate whether ChatGPT can be prodded to improve the security by appropriate prompts, and discuss the ethical aspects of using AI to generate code. Results suggest that ChatGPT is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks. ","[{'version': 'v1', 'created': 'Wed, 19 Apr 2023 13:45:01 GMT'}]",2023-04-20,"[['Khoury', 'Raphaël', ''], ['Avila', 'Anderson R.', ''], ['Brunelle', 'Jacob', ''], ['Camara', 'Baba Mamadou', '']]",1,1,2023-04-19,1,4,1,1,0,1,f60d3ce156dff3868cf923e03d94eef843eaa13a,258212971.0,https://www.semanticscholar.org/paper/f60d3ce156dff3868cf923e03d94eef843eaa13a,arXiv.org,2023.0,22.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51879462', 'name': 'R. Khoury'}, {'authorId': '36941802', 'name': 'Anderson R. Avila'}, {'authorId': '2214715547', 'name': 'Jacob Brunelle'}, {'authorId': '2214706320', 'name': 'Baba Mamadou Camara'}]","['Université du Québec en Outaouais', 'Institut National de la Recherche Scientifique']",['Canada'],2023-04
2304.09866,Hend Al-Khalifa Prof.,Abeer Alessa and Hend Al-Khalifa,Towards Designing a ChatGPT Conversational Companion for Elderly People,"10 pages, 3 Figures, Workshop paper",,,,cs.HC cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Loneliness and social isolation are serious and widespread problems among older people, affecting their physical and mental health, quality of life, and longevity. In this paper, we propose a ChatGPT-based conversational companion system for elderly people. The system is designed to provide companionship and help reduce feelings of loneliness and social isolation. The system was evaluated with a preliminary study. The results showed that the system was able to generate responses that were relevant to the created elderly personas. However, it is essential to acknowledge the limitations of ChatGPT, such as potential biases and misinformation, and to consider the ethical implications of using AI-based companionship for the elderly, including privacy concerns. ","[{'version': 'v1', 'created': 'Tue, 18 Apr 2023 17:24:14 GMT'}]",2023-04-21,"[['Alessa', 'Abeer', ''], ['Al-Khalifa', 'Hend', '']]",1,1,2023-04-18,1,2,2,1,0,1,84f0982cf20ce172455d2a2c4038c281b404f256,258236454.0,https://www.semanticscholar.org/paper/84f0982cf20ce172455d2a2c4038c281b404f256,Petra,2023.0,21.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2214808732', 'name': 'Abeer Alessa'}, {'authorId': '1390173757', 'name': 'Hend Suliman Al-Khalifa'}]",['King Saud University'],['Saudi Arabia'],2023-04
2304.09873,Mojtaba Eshghie,"Mahshid Eshghie, Mojtaba Eshghie",ChatGPT as a Therapist Assistant: A Suitability Study,,,,,cs.HC cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper proposes using ChatGPT, an innovative technology with various applications, as an assistant for psychotherapy. ChatGPT can serve as a patient information collector, a companion for patients in between therapy sessions, and an organizer of gathered information for therapists to facilitate treatment processes. The research identifies five research questions and discovers useful prompts for fine-tuning the assistant, which shows that ChatGPT can participate in positive conversations, listen attentively, offer validation and potential coping strategies without providing explicit medical advice, and help therapists discover new insights from multiple conversations with the same patient. Using ChatGPT as an assistant for psychotherapy poses several challenges that need to be addressed, including technical as well as human-centric challenges which are discussed. ","[{'version': 'v1', 'created': 'Wed, 19 Apr 2023 13:35:23 GMT'}]",2023-04-21,"[['Eshghie', 'Mahshid', ''], ['Eshghie', 'Mojtaba', '']]",1,1,2023-04-19,1,2,2,1,0,1,71670691f3afc365dc9a3922b0403b553e872be9,258236161.0,https://www.semanticscholar.org/paper/71670691f3afc365dc9a3922b0403b553e872be9,Social Science Research Network,2023.0,15.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2214810325', 'name': 'Mahshid Eshghie'}, {'authorId': '80352534', 'name': 'Mojtaba Eshghie'}]","['KTH Royal Institute of Technology', 'Independent Researcher Gilan, Iran']","['Iran', 'Sweden']",2023-04
2304.09957,Ekaterina Artemova,Ekaterina Artemova and Barbara Plank,Low-resource Bilingual Dialect Lexicon Induction with Large Language Models,Accepted to NoDaLiDa 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Bilingual word lexicons are crucial tools for multilingual natural language understanding and machine translation tasks, as they facilitate the mapping of words in one language to their synonyms in another language. To achieve this, numerous papers have explored bilingual lexicon induction (BLI) in high-resource scenarios, using a typical pipeline consisting of two unsupervised steps: bitext mining and word alignment, both of which rely on pre-trained large language models~(LLMs).   In this paper, we present an analysis of the BLI pipeline for German and two of its dialects, Bavarian and Alemannic. This setup poses several unique challenges, including the scarcity of resources, the relatedness of the languages, and the lack of standardization in the orthography of dialects. To evaluate the BLI outputs, we analyze them with respect to word frequency and pairwise edit distance. Additionally, we release two evaluation datasets comprising 1,500 bilingual sentence pairs and 1,000 bilingual word pairs. They were manually judged for their semantic similarity for each Bavarian-German and Alemannic-German language pair. ","[{'version': 'v1', 'created': 'Wed, 19 Apr 2023 20:20:41 GMT'}]",2023-04-21,"[['Artemova', 'Ekaterina', ''], ['Plank', 'Barbara', '']]",0,0,2023-04-19,1,2,1,0,0,0,e9cc129f259da83672f532b073ca5b2a2e9604d2,258236060.0,https://www.semanticscholar.org/paper/e9cc129f259da83672f532b073ca5b2a2e9604d2,Nordic Conference of Computational Linguistics,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '13033978', 'name': 'E. Artemova'}, {'authorId': '2022124', 'name': 'Barbara Plank'}]",['Ludwig-Maximilians-Universität München'],['Germany'],2023-04
2304.10164,Wonseong Kim,"Wonseong Kim, Jan Frederic Sp\""orer, Siegfried Handschuh",Analyzing FOMC Minutes: Accuracy and Constraints of Language Models,"15pages, 4 figures, 5 tables",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This research article analyzes the language used in the official statements released by the Federal Open Market Committee (FOMC) after its scheduled meetings to gain insights into the impact of FOMC official statements on financial markets and economic forecasting. The study reveals that the FOMC is careful to avoid expressing emotion in their sentences and follows a set of templates to cover economic situations. The analysis employs advanced language modeling techniques such as VADER and FinBERT, and a trial test with GPT-4. The results show that FinBERT outperforms other techniques in predicting negative sentiment accurately. However, the study also highlights the challenges and limitations of using current NLP techniques to analyze FOMC texts and suggests the potential for enhancing language models and exploring alternative approaches. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 08:54:00 GMT'}]",2023-04-21,"[['Kim', 'Wonseong', ''], ['Spörer', 'Jan Frederic', ''], ['Handschuh', 'Siegfried', '']]",0,1,2023-04-20,1,3,1,1,0,1,f35a1ee600589213109d4b8f082d7ce60f494744,258236088.0,https://www.semanticscholar.org/paper/f35a1ee600589213109d4b8f082d7ce60f494744,arXiv.org,2023.0,10.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2214844440', 'name': 'Wonseong Kim'}, {'authorId': '1581783948', 'name': 'J. Spörer'}, {'authorId': '1789102', 'name': 'S. Handschuh'}]","['Korea University', 'University of St. Gallen']","['South Korea', 'Switzerland']",2023-04
2304.10267,Genki Kanda,"Takashi Inagaki, Akari Kato, Koichi Takahashi, Haruka Ozaki, Genki N.
  Kanda",LLMs can generate robotic scripts from goal-oriented instructions in biological laboratory automation,,,,,q-bio.QM,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The use of laboratory automation by all researchers may substantially accelerate scientific activities by humans, including those in the life sciences. However, computer programs to operate robots should be written to implement laboratory automation, which requires technical knowledge and skills that may not be part of a researcher's training or expertise. In the last few years, there has been remarkable development in large language models (LLMs) such as GPT-4, which can generate computer codes based on natural language instructions. In this study, we used LLMs, including GPT-4, to generate scripts for robot operations in biological experiments based on ambiguous instructions. GPT-4 successfully generates scripts for OT-2, an automated liquid-handling robot, from simple instructions in natural language without specifying the robotic actions. Conventionally, translating the nuances of biological experiments into low-level robot actions requires researchers to understand both biology and robotics, imagine robot actions, and write robotic scripts. Our results showed that GPT-4 can connect the context of biological experiments with robot operation through simple prompts with expert-level contextual understanding and inherent knowledge. Replacing robot script programming, which is a tedious task for biological researchers, with natural-language LLM instructions that do not consider robot behavior significantly increases the number of researchers who can benefit from automating biological experiments. ","[{'version': 'v1', 'created': 'Tue, 18 Apr 2023 09:15:37 GMT'}]",2023-04-21,"[['Inagaki', 'Takashi', ''], ['Kato', 'Akari', ''], ['Takahashi', 'Koichi', ''], ['Ozaki', 'Haruka', ''], ['Kanda', 'Genki N.', '']]",0,1,2023-04-18,1,5,1,1,0,1,5ec18c8777e0eaf1411987638040546a22da861e,258236094.0,https://www.semanticscholar.org/paper/5ec18c8777e0eaf1411987638040546a22da861e,,2023.0,10.0,3.0,0.0,False,['Biology'],"[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2054037213', 'name': 'T. Inagaki'}, {'authorId': '2214922490', 'name': 'Akari Kato'}, {'authorId': '2116095075', 'name': 'Koichi Takahashi'}, {'authorId': '50075919', 'name': 'Haruka Ozaki'}, {'authorId': '35226027', 'name': 'G. Kanda'}]","['University of Tsukuba', 'Keio University', ""Laboratory Automation Supplier's Association, Japan"", 'Osaka University', 'RIKEN Center for Biosystems Dynamics Research', 'Nagoya University']",['Japan'],2023-04
2304.10346,Julia Rozanova,"Julia Rozanova, Marco Valentino, Lucas Cordeiro, Andre Freitas",Interventional Probing in High Dimensions: An NLI Case Study,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Probing strategies have been shown to detect the presence of various linguistic features in large language models; in particular, semantic features intermediate to the ""natural logic"" fragment of the Natural Language Inference task (NLI). In the case of natural logic, the relation between the intermediate features and the entailment label is explicitly known: as such, this provides a ripe setting for interventional studies on the NLI models' representations, allowing for stronger causal conjectures and a deeper critical analysis of interventional probing methods. In this work, we carry out new and existing representation-level interventions to investigate the effect of these semantic features on NLI classification: we perform amnesic probing (which removes features as directed by learned linear probes) and introduce the mnestic probing variation (which forgets all dimensions except the probe-selected ones). Furthermore, we delve into the limitations of these methods and outline some pitfalls have been obscuring the effectivity of interventional probing studies. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 14:34:31 GMT'}]",2023-04-21,"[['Rozanova', 'Julia', ''], ['Valentino', 'Marco', ''], ['Cordeiro', 'Lucas', ''], ['Freitas', 'Andre', '']]",0,0,2023-04-20,1,4,1,0,0,0,95fef3a8cd12d3fe9be85c42e94741a6bee03fb1,253082250.0,https://www.semanticscholar.org/paper/95fef3a8cd12d3fe9be85c42e94741a6bee03fb1,Findings,2023.0,29.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8471045', 'name': 'Julia Rozanova'}, {'authorId': '34102057', 'name': 'Marco Valentino'}, {'authorId': '2163521113', 'name': 'Lucas C. Cordeiro'}, {'authorId': '2057619238', 'name': 'André Freitas'}]","['University of Manchester', 'Idiap Research Institute']","['United Kingdom', 'Switzerland']",2023-04
2304.10417,Nikos Athanasiou,"Nikos Athanasiou, Mathis Petrovich, Michael J. Black and G\""ul Varol",SINC: Spatial Composition of 3D Human Motions for Simultaneous Action Generation,ICCV 2023 Camera Ready,,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our goal is to synthesize 3D human motions given textual inputs describing simultaneous actions, for example 'waving hand' while 'walking' at the same time. We refer to generating such simultaneous movements as performing 'spatial compositions'. In contrast to temporal compositions that seek to transition from one action to another, spatial compositing requires understanding which body parts are involved in which action, to be able to move them simultaneously. Motivated by the observation that the correspondence between actions and body parts is encoded in powerful language models, we extract this knowledge by prompting GPT-3 with text such as ""what are the body parts involved in the action <action name>?"", while also providing the parts list and few-shot examples. Given this action-part mapping, we combine body parts from two motions together and establish the first automated method to spatially compose two actions. However, training data with compositional actions is always limited by the combinatorics. Hence, we further create synthetic data with this approach, and use it to train a new state-of-the-art text-to-motion generation model, called SINC (""SImultaneous actioN Compositions for 3D human motions""). In our experiments, that training with such GPT-guided synthetic data improves spatial composition generation over baselines. Our code is publicly available at https://sinc.is.tue.mpg.de/. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 16:01:55 GMT'}, {'version': 'v2', 'created': 'Sat, 19 Aug 2023 20:34:13 GMT'}]",2023-08-22,"[['Athanasiou', 'Nikos', ''], ['Petrovich', 'Mathis', ''], ['Black', 'Michael J.', ''], ['Varol', 'Gül', '']]",0,1,2023-04-20,2,4,1,1,0,1,ff969f811673061e50ba2c384e3034ce30c1d561,258236650.0,https://www.semanticscholar.org/paper/ff969f811673061e50ba2c384e3034ce30c1d561,arXiv.org,2023.0,75.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51174183', 'name': 'Nikos Athanasiou'}, {'authorId': '1562113276', 'name': 'Mathis Petrovich'}, {'authorId': '2105795', 'name': 'Michael J. Black'}, {'authorId': '2668759', 'name': 'Gül Varol'}]","[""Laboratoire d'Informatique Gaspard-Monge"", 'Max Planck Institute for Intelligent Systems']","['Germany', 'France']",2023-04
2304.10423,Leon Moonen,"Vadim Liventsev and Anastasiia Grishina and Aki H\""arm\""a and Leon
  Moonen",Fully Autonomous Programming with Large Language Models,"Accepted for publication in the Genetic and Evolutionary Computation
  Conference (GECCO 2023)",,10.1145/3583131.3590481,,cs.SE cs.AI cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Current approaches to program synthesis with Large Language Models (LLMs) exhibit a ""near miss syndrome"": they tend to generate programs that semantically resemble the correct answer (as measured by text similarity metrics or human evaluation), but achieve a low or even zero accuracy as measured by unit tests due to small imperfections, such as the wrong input or output format. This calls for an approach known as Synthesize, Execute, Debug (SED), whereby a draft of the solution is generated first, followed by a program repair phase addressing the failed tests. To effectively apply this approach to instruction-driven LLMs, one needs to determine which prompts perform best as instructions for LLMs, as well as strike a balance between repairing unsuccessful programs and replacing them with newly generated ones. We explore these trade-offs empirically, comparing replace-focused, repair-focused, and hybrid debug strategies, as well as different template-based and model-based prompt-generation techniques. We use OpenAI Codex as the LLM and Program Synthesis Benchmark 2 as a database of problem descriptions and tests for evaluation. The resulting framework outperforms both conventional usage of Codex without the repair phase and traditional genetic programming approaches. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 16:12:05 GMT'}]",2023-04-21,"[['Liventsev', 'Vadim', ''], ['Grishina', 'Anastasiia', ''], ['Härmä', 'Aki', ''], ['Moonen', 'Leon', '']]",0,0,2023-04-20,1,4,3,1,0,1,fbb5cc9e8a46f61d1543bd17b6eca324fd5bf55c,258236581.0,https://www.semanticscholar.org/paper/fbb5cc9e8a46f61d1543bd17b6eca324fd5bf55c,Annual Conference on Genetic and Evolutionary Computation,2023.0,62.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2066239833', 'name': 'Vadim Liventsev'}, {'authorId': '73569689', 'name': 'Anastasiia Grishina'}, {'authorId': '2701180', 'name': 'Aki Härmä'}, {'authorId': '1762006', 'name': 'L. Moonen'}]","['Eindhoven University of Technology', 'Philips (Netherlands)', 'Simula Metropolitan Center for Digital Engineering']","['Netherlands', 'Norway']",2023-04
2304.10427,Ana Claudia Sima,Ana-Claudia Sima and Tarcisio Mendes de Farias,On the Potential of Artificial Intelligence Chatbots for Data Exploration of Federated Bioinformatics Knowledge Graphs,,,,https://ceur-ws.org/Vol-3466/paper1.pdf,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present work in progress on the role of artificial intelligence (AI) chatbots, such as ChatGPT, in facilitating data access to federated knowledge graphs. In particular, we provide examples from the field of bioinformatics, to illustrate the potential use of Conversational AI to describe datasets, as well as generate and explain (federated) queries across datasets for the benefit of domain experts. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 16:16:40 GMT'}]",2023-09-27,"[['Sima', 'Ana-Claudia', ''], ['de Farias', 'Tarcisio Mendes', '']]",1,1,2023-04-20,1,2,1,1,0,1,2dc6d884562c89514bb10e5a20028bbf0dda9548,258236513.0,https://www.semanticscholar.org/paper/2dc6d884562c89514bb10e5a20028bbf0dda9548,SeWeBMeDA@ESWC,2023.0,12.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2723088', 'name': 'A. Sima'}, {'authorId': '1725471', 'name': 'T. M. Farias'}]",['SIB Swiss Institute of Bioinformatics'],['Switzerland'],2023-04
2304.10548,Ziang Xiao,"Ziang Xiao, Xingdi Yuan, Q. Vera Liao, Rania Abdelghani, Pierre-Yves
  Oudeyer",Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding,"28th International Conference on Intelligent User Interfaces (IUI '23
  Companion), March 27--31, 2023, Sydney, NSW, Australia",,10.1145/3581754.3584136,,cs.CL cs.AI cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Qualitative analysis of textual contents unpacks rich and valuable information by assigning labels to the data. However, this process is often labor-intensive, particularly when working with large datasets. While recent AI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let alone be challenged by the limited generalizability of those task-specific models. In this study, we explored the use of large language models (LLMs) in supporting deductive coding, a major category of qualitative analysis where researchers use pre-determined codebooks to label the data into a fixed set of codes. Instead of training task-specific models, a pre-trained LLM could be used directly for various tasks without fine-tuning through prompt learning. Using a curiosity-driven questions coding task as a case study, we found, by combining GPT-3 with expert-drafted codebooks, our proposed approach achieved fair to substantial agreements with expert-coded results. We lay out challenges and opportunities in using LLMs to support qualitative coding and beyond. ","[{'version': 'v1', 'created': 'Mon, 17 Apr 2023 04:52:43 GMT'}]",2023-04-24,"[['Xiao', 'Ziang', ''], ['Yuan', 'Xingdi', ''], ['Liao', 'Q. Vera', ''], ['Abdelghani', 'Rania', ''], ['Oudeyer', 'Pierre-Yves', '']]",0,1,2023-04-17,1,5,3,1,0,1,6a3d0b11a0b22bafcce7739cc5eb12dad8bd7565,257758261.0,https://www.semanticscholar.org/paper/6a3d0b11a0b22bafcce7739cc5eb12dad8bd7565,IUI Companion,2023.0,16.0,22.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '9605732', 'name': 'Ziang Xiao'}, {'authorId': '2854297', 'name': 'Xingdi Yuan'}, {'authorId': '144921048', 'name': 'Q. Liao'}, {'authorId': '2154047060', 'name': 'Rania Abdelghani'}, {'authorId': '1720664', 'name': 'Pierre-Yves Oudeyer'}]","['PIERRE-YVES OUDEYER, Inria, France']",['France'],2023-04
2304.10592,Deyao Zhu,"Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, Mohamed Elhoseiny",MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models,"Project Website: https://minigpt-4.github.io/; Code, Pretrained
  Model, and Dataset: https://github.com/Vision-CAIR/MiniGPT-4; Deyao Zhu and
  Jun Chen contributed equally to this work",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. However, the technical details behind GPT-4 continue to remain undisclosed. We believe that the enhanced multi-modal generation capabilities of GPT-4 stem from the utilization of sophisticated large language models (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer. Our work, for the first time, uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by GPT-4, such as detailed image description generation and website creation from hand-drawn drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, teaching users how to cook based on food photos, and so on. In our experiment, we found that the model trained on short image caption pairs could produce unnatural language outputs (e.g., repetition and fragmentation). To address this problem, we curate a detailed image description dataset in the second stage to finetune the model, which consequently improves the model's generation reliability and overall usability. Our code, pre-trained model, and collected dataset are available at https://minigpt-4.github.io/. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 18:25:35 GMT'}, {'version': 'v2', 'created': 'Mon, 2 Oct 2023 16:38:35 GMT'}]",2023-10-03,"[['Zhu', 'Deyao', ''], ['Chen', 'Jun', ''], ['Shen', 'Xiaoqian', ''], ['Li', 'Xiang', ''], ['Elhoseiny', 'Mohamed', '']]",0,1,2023-04-20,2,5,1,2,1,1,ca6a2bc279be5a3349a22bfd6866ed633d18734b,258291930.0,https://www.semanticscholar.org/paper/ca6a2bc279be5a3349a22bfd6866ed633d18734b,arXiv.org,2023.0,49.0,301.0,89.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1388731230', 'name': 'Deyao Zhu'}, {'authorId': '2153417252', 'name': 'Jun Chen'}, {'authorId': '2151708219', 'name': 'Xiaoqian Shen'}, {'authorId': '2144440192', 'name': 'Xiang Li'}, {'authorId': '1712479', 'name': 'Mohamed Elhoseiny'}]",['King Abdullah University of Science and Technology'],['Saudi Arabia'],2023-04
2304.10632,Piyush Batra,"Piyush Batra, Gagan Raj Singh, Ritik Gandhi",NFT Marketplace,Report for MULTIMEDIA COMMUNICATIONS course project,,,,cs.MM cs.CR,http://creativecommons.org/licenses/by/4.0/,"  In an increasingly digitized world, the secure management and trade of digital assets have become a pressing issue. This project aims to address this challenge by developing a decentralized application (dApp) that leverages blockchain technology and deep learning models to provide secure and efficient digital asset management, with a focus on NFTs. The dApp includes features such as secure wallet connections, NFT image generation, minting, marketplace, and profile management. The back-end of the dApp is implemented using the Goerli testnet with Solidity-based smart contracts, while IPFS and ReactJS/EtherJS are used for decentralized storage and front-end development, respectively. Additionally, the OpenAI API is integrated to generate unique NFT images based on user input. The project demonstrates the practical application of blockchain technology and deep learning models in developing dApps for secure and decentralized digital asset management. Overall, the project contributes to the ongoing research on blockchain-based solutions for secure digital asset management, while highlighting the potential of blockchain and deep learning technologies to transform the way we manage and trade digital assets. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 20:24:20 GMT'}]",2023-04-24,"[['Batra', 'Piyush', ''], ['Singh', 'Gagan Raj', ''], ['Gandhi', 'Ritik', '']]",0,0,2023-04-20,1,3,2,0,0,0,920b835cf893eba195e8e6f6e5e13fefdcab3827,258291516.0,https://www.semanticscholar.org/paper/920b835cf893eba195e8e6f6e5e13fefdcab3827,arXiv.org,2023.0,10.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2151418950', 'name': 'Piyush Batra'}, {'authorId': '2117029387', 'name': 'Gagandeep Singh'}, {'authorId': '2215167690', 'name': 'Ritik Gandhi'}]",['University of Alberta'],['Canada'],2023-04
2304.10663,Xiaolin Hu,Xiaolin Hu,Meta Semantics: Towards better natural language understanding and reasoning,"10 pages, 8 figures, 2 tables",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language understanding is one of the most challenging topics in artificial intelligence. Deep neural network methods, particularly large language module (LLM) methods such as ChatGPT and GPT-3, have powerful flexibility to adopt informal text but are weak on logical deduction and suffer from the out-of-vocabulary (OOV) problem. On the other hand, rule-based methods such as Mathematica, Semantic web, and Lean, are excellent in reasoning but cannot handle the complex and changeable informal text. Inspired by pragmatics and structuralism, we propose two strategies to solve the OOV problem and a semantic model for better natural language understanding and reasoning. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 22:16:16 GMT'}]",2023-04-24,"[['Hu', 'Xiaolin', '']]",1,1,2023-04-20,1,1,2,2,0,2,6cc0abd3068a7db09aab1e1eb3d528d1b9abf16a,258291834.0,https://www.semanticscholar.org/paper/6cc0abd3068a7db09aab1e1eb3d528d1b9abf16a,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109753361', 'name': 'Xiaoling Hu'}]",['University of Leicester'],['United Kingdom'],2023-04
2304.10778,Burak Yetistiren,"Burak Yeti\c{s}tiren, I\c{s}{\i}k \""Ozsoy, Miray Ayerdem, Eray
  T\""uz\""un","Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT",,,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Context: AI-assisted code generation tools have become increasingly prevalent in software engineering, offering the ability to generate code from natural language prompts or partial code inputs. Notable examples of these tools include GitHub Copilot, Amazon CodeWhisperer, and OpenAI's ChatGPT.   Objective: This study aims to compare the performance of these prominent code generation tools in terms of code quality metrics, such as Code Validity, Code Correctness, Code Security, Code Reliability, and Code Maintainability, to identify their strengths and shortcomings.   Method: We assess the code generation capabilities of GitHub Copilot, Amazon CodeWhisperer, and ChatGPT using the benchmark HumanEval Dataset. The generated code is then evaluated based on the proposed code quality metrics.   Results: Our analysis reveals that the latest versions of ChatGPT, GitHub Copilot, and Amazon CodeWhisperer generate correct code 65.2%, 46.3%, and 31.1% of the time, respectively. In comparison, the newer versions of GitHub CoPilot and Amazon CodeWhisperer showed improvement rates of 18% for GitHub Copilot and 7% for Amazon CodeWhisperer. The average technical debt, considering code smells, was found to be 8.9 minutes for ChatGPT, 9.1 minutes for GitHub Copilot, and 5.6 minutes for Amazon CodeWhisperer.   Conclusions: This study highlights the strengths and weaknesses of some of the most popular code generation tools, providing valuable insights for practitioners. By comparing these generators, our results may assist practitioners in selecting the optimal tool for specific tasks, enhancing their decision-making process. ","[{'version': 'v1', 'created': 'Fri, 21 Apr 2023 07:08:26 GMT'}]",2023-04-24,"[['Yetiştiren', 'Burak', ''], ['Özsoy', 'Işık', ''], ['Ayerdem', 'Miray', ''], ['Tüzün', 'Eray', '']]",1,1,2023-04-21,1,4,1,1,0,1,266d671d5d6bac3c88d7bfb18c5210b46f06e6db,258291698.0,https://www.semanticscholar.org/paper/266d671d5d6bac3c88d7bfb18c5210b46f06e6db,arXiv.org,2023.0,26.0,14.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2190291221', 'name': 'Burak Yetistiren'}, {'authorId': '2216137437', 'name': 'Isik Özsoy'}, {'authorId': '2215167231', 'name': 'Miray Ayerdem'}, {'authorId': '13576179', 'name': 'Eray Tüzün'}]",['Bilkent University'],['Turkey'],2023-04
2304.10977,Matteo Muffo,"Matteo Muffo, Aldo Cocco, Enrico Bertino",Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition,"7 pages, 1 figure, published at LREC 2022","Proceedings of the 13th Conference on Language Resources and
  Evaluation (LREC 2022), pages 291-297",,,cs.CL stat.ML,http://creativecommons.org/licenses/by/4.0/,"  In recent years, Large Language Models such as GPT-3 showed remarkable capabilities in performing NLP tasks in the zero and few shot settings. On the other hand, the experiments highlighted the difficulty of GPT-3 in carrying out tasks that require a certain degree of reasoning, such as arithmetic operations. In this paper we evaluate the ability of Transformer Language Models to perform arithmetic operations following a pipeline that, before performing computations, decomposes numbers in units, tens, and so on. We denote the models fine-tuned with this pipeline with the name Calculon and we test them in the task of performing additions, subtractions and multiplications on the same test sets of GPT-3. Results show an increase of accuracy of 63% in the five-digit addition task. Moreover, we demonstrate the importance of the decomposition pipeline introduced, since fine-tuning the same Language Model without decomposing numbers results in 0% accuracy in the five-digit addition task. ","[{'version': 'v1', 'created': 'Fri, 21 Apr 2023 14:21:52 GMT'}]",2023-04-24,"[['Muffo', 'Matteo', ''], ['Cocco', 'Aldo', ''], ['Bertino', 'Enrico', '']]",0,1,2023-04-21,1,3,2,1,0,1,a5808ccc50f77083bd3be926fb2af05cf34563ff,251406206.0,https://www.semanticscholar.org/paper/a5808ccc50f77083bd3be926fb2af05cf34563ff,International Conference on Language Resources and Evaluation,2023.0,22.0,13.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2038110760', 'name': 'Matteo Muffo'}, {'authorId': '2005057281', 'name': 'A. Cocco'}, {'authorId': '2065641522', 'name': 'Enrico Bertino'}]","['Indigo.ai Via Torino 61, Milan, Italy']",['Italy'],2023-04
2304.11015,Davood Rafiei,"Mohammadreza Pourreza, Davood Rafiei",DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction,,,,,cs.CL cs.AI cs.DB cs.HC,http://creativecommons.org/licenses/by/4.0/,"  We study the problem of decomposing a complex text-to-sql task into smaller sub-tasks and how such a decomposition can significantly improve the performance of Large Language Models (LLMs) in the reasoning process. There is currently a significant gap between the performance of fine-tuned models and prompting approaches using LLMs on challenging text-to-sql datasets such as Spider. We show that SQL queries, despite their declarative structure, can be broken down into sub-problems and the solutions of those sub-problems can be fed into LLMs to significantly improve their performance. Our experiments with three LLMs show that this approach consistently improves their performance by roughly 10%, pushing the accuracy of LLMs towards state-of-the-art, and even beating large fine-tuned models on the holdout Spider dataset. ","[{'version': 'v1', 'created': 'Fri, 21 Apr 2023 15:02:18 GMT'}, {'version': 'v2', 'created': 'Thu, 27 Apr 2023 17:49:23 GMT'}]",2023-04-28,"[['Pourreza', 'Mohammadreza', ''], ['Rafiei', 'Davood', '']]",0,0,2023-04-21,2,2,4,0,0,0,cc0f0cb09a73f82ed44d900f5ca710bec784acc1,258291425.0,https://www.semanticscholar.org/paper/cc0f0cb09a73f82ed44d900f5ca710bec784acc1,arXiv.org,2023.0,80.0,36.0,9.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '15293057', 'name': 'M. Pourreza'}, {'authorId': '2144238', 'name': 'Davood Rafiei'}]",['University of Alberta'],['Canada'],2023-04
2304.11065,Stefanie Rinderle-Ma,"Nataliia Klievtsova, Janik-Vasily Benzin, Timotheus Kampik, Juergen
  Mangler, Stefanie Rinderle-Ma","Conversational Process Modelling: State of the Art, Applications, and Implications in Practice",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Chatbots such as ChatGPT have caused a tremendous hype lately. For BPM applications, it is often not clear how to apply chatbots to generate business value. Hence, this work aims at the systematic analysis of existing chatbots for their support of conversational process modelling as process-oriented capability. Application scenarios are identified along the process life cycle. Then a systematic literature review on conversational process modelling is performed. The resulting taxonomy serves as input for the identification of application scenarios for conversational process modelling, including paraphrasing and improvement of process descriptions. The application scenarios are evaluated for existing chatbots based on a real-world test set from the higher education domain. It contains process descriptions as well as corresponding process models, together with an assessment of the model quality. Based on the literature and application scenario analyses, recommendations for the usage (practical implications) and further development (research directions) of conversational process modelling are derived. ","[{'version': 'v1', 'created': 'Wed, 19 Apr 2023 06:54:14 GMT'}]",2023-04-24,"[['Klievtsova', 'Nataliia', ''], ['Benzin', 'Janik-Vasily', ''], ['Kampik', 'Timotheus', ''], ['Mangler', 'Juergen', ''], ['Rinderle-Ma', 'Stefanie', '']]",1,1,2023-04-19,1,5,2,1,0,1,3c0e6dbcd2d4bdd76067ce7c895200886eadc2cd,258291461.0,https://www.semanticscholar.org/paper/3c0e6dbcd2d4bdd76067ce7c895200886eadc2cd,International Conference on Business Process Management,2023.0,72.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2215169111', 'name': 'Nataliia Klievtsova'}, {'authorId': '122886543', 'name': 'Janik-Vasily Benzin'}, {'authorId': '2437582', 'name': 'Timotheus Kampik'}, {'authorId': '2197167533', 'name': 'Juergen Mangler'}, {'authorId': '1398801378', 'name': 'S. Rinderle-Ma'}]","['Technical University of Munich', 'Systems, Applications & Products in Data Processing (Germany)']",['Germany'],2023-04
2304.11075,Cl\'ement Sicard,"Clement Sicard, Kajetan Pyszkowski, Victor Gillioz",Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects,"8 pages, SwissText conference","Swiss Text Analytics Conference, 2023",,,cs.CL cs.LG cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  Recent breakthroughs in NLP largely increased the presence of ASR systems in our daily lives. However, for many low-resource languages, ASR models still need to be improved due in part to the difficulty of acquiring pertinent data. This project aims to help advance research in ASR models for Swiss German dialects, by providing insights about the performance of state-of-the-art ASR models on recently published Swiss German speech datasets. We propose a novel loss that takes into account the semantic distance between the predicted and the ground-truth labels. We outperform current state-of-the-art results by fine-tuning OpenAI's Whisper model on Swiss-German datasets. ","[{'version': 'v1', 'created': 'Thu, 20 Apr 2023 14:42:54 GMT'}, {'version': 'v2', 'created': 'Wed, 13 Sep 2023 16:12:56 GMT'}]",2023-09-14,"[['Sicard', 'Clement', ''], ['Pyszkowski', 'Kajetan', ''], ['Gillioz', 'Victor', '']]",0,0,2023-04-20,2,3,4,0,0,0,849bb44a67e02269e6668a2374a96d4adaa6f861,258291445.0,https://www.semanticscholar.org/paper/849bb44a67e02269e6668a2374a96d4adaa6f861,arXiv.org,2023.0,25.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2215168485', 'name': ""Cl'ement Sicard""}, {'authorId': '2215168906', 'name': 'Kajetan Pyszkowski'}, {'authorId': '2124394656', 'name': 'Victor Gillioz'}]",['ETH Zurich'],['Switzerland'],2023-04
2304.11079,O\u{g}uz Turan Buruk,O\u{g}uz 'Oz' Buruk,"Academic Writing with GPT-3.5: Reflections on Practices, Efficacy and Transparency","9 Pages, 84 Pages of Appendix",,,,cs.CL cs.AI cs.HC cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The debate around the use of GPT 3.5 has been a popular topic among academics since the release of ChatGPT. Whilst some have argued for the advantages of GPT 3.5 in enhancing academic writing, others have raised concerns such as plagiarism, the spread of false information, and ecological issues. The need for finding ways to use GPT 3.5 models transparently has been voiced, and suggestions have been made on social media as to how to use GPT 3.5 models in a smart way. Nevertheless, to date, there is a lack of literature which clearly outlines how to use GPT 3.5 models in academic writing, how effective they are, and how to use them transparently. To address this, I conducted a personal experience experiment with GPT 3.5, specifically by using OpenAI text davinci 003 model, for writing this article. I identified five ways of using GPT 3.5: Chunk Stylist, Bullet to Paragraph, Talk Textualizer, Research Buddy, and Polisher. I reflected on their efficacy, and commented on their potential impact on writing ethics. Additionally, I provided a comprehensive document which shows the prompts I used, results I got from GPT 3.5, the final edits and visually compares those by showing the differences in percentages. ","[{'version': 'v1', 'created': 'Sun, 12 Feb 2023 22:05:08 GMT'}]",2023-04-24,"[['Buruk', ""Oğuz 'Oz'"", '']]",1,1,2023-02-12,1,1,4,2,0,2,b172bb655988744c2a98439e18164d4ca0dd21c5,258291925.0,https://www.semanticscholar.org/paper/b172bb655988744c2a98439e18164d4ca0dd21c5,arXiv.org,2023.0,19.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2214620828', 'name': ""Ouguz 'Oz' Buruk""}]",['Tampere University'],['Finland'],2023-02
2304.11082,Yotam Wolf,"Yotam Wolf, Noam Wies, Oshri Avnery, Yoav Levine, Amnon Shashua",Fundamental Limitations of Alignment in Large Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  An important aspect in developing language models that interact with humans is aligning their behavior to be useful and unharmful for their human users. This is usually achieved by tuning the model in a way that enhances desired behaviors and inhibits undesired ones, a process referred to as alignment. In this paper, we propose a theoretical approach called Behavior Expectation Bounds (BEB) which allows us to formally investigate several inherent characteristics and limitations of alignment in large language models. Importantly, we prove that for any behavior that has a finite probability of being exhibited by the model, there exist prompts that can trigger the model into outputting this behavior, with probability that increases with the length of the prompt. This implies that any alignment process that attenuates undesired behavior but does not remove it altogether, is not safe against adversarial prompting attacks. Furthermore, our framework hints at the mechanism by which leading alignment approaches such as reinforcement learning from human feedback increase the LLM's proneness to being prompted into the undesired behaviors. Moreover, we include the notion of personas in our BEB framework, and find that behaviors which are generally very unlikely to be exhibited by the model can be brought to the front by prompting the model to behave as specific persona. This theoretical result is being experimentally demonstrated in large scale by the so called contemporary ""chatGPT jailbreaks"", where adversarial users trick the LLM into breaking its alignment guardrails by triggering it into acting as a malicious persona. Our results expose fundamental limitations in alignment of LLMs and bring to the forefront the need to devise reliable mechanisms for ensuring AI safety. ","[{'version': 'v1', 'created': 'Wed, 19 Apr 2023 17:50:09 GMT'}, {'version': 'v2', 'created': 'Mon, 29 May 2023 17:31:12 GMT'}, {'version': 'v3', 'created': 'Tue, 1 Aug 2023 09:18:03 GMT'}]",2023-08-02,"[['Wolf', 'Yotam', ''], ['Wies', 'Noam', ''], ['Avnery', 'Oshri', ''], ['Levine', 'Yoav', ''], ['Shashua', 'Amnon', '']]",1,1,2023-04-19,3,5,2,1,0,1,dbac86036cb5ed4dd6bbdda4a8613b163e20ec90,258291526.0,https://www.semanticscholar.org/paper/dbac86036cb5ed4dd6bbdda4a8613b163e20ec90,arXiv.org,2023.0,50.0,44.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153471082', 'name': 'Yotam Wolf'}, {'authorId': '69978543', 'name': 'Noam Wies'}, {'authorId': '152754428', 'name': 'Yoav Levine'}, {'authorId': '3140335', 'name': 'A. Shashua'}]",['Hebrew University of Jerusalem'],['Israel'],2023-04
2304.11085,Michael V. Reiss,Michael V. Reiss,Testing the Reliability of ChatGPT for Text Annotation and Classification: A Cautionary Remark,"First uploaded on Dropbox on 5th of April. See
  https://twitter.com/mv_reiss/status/1643916531720486913, content was not
  changed except for formatting",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Recent studies have demonstrated promising potential of ChatGPT for various text annotation and classification tasks. However, ChatGPT is non-deterministic which means that, as with human coders, identical input can lead to different outputs. Given this, it seems appropriate to test the reliability of ChatGPT. Therefore, this study investigates the consistency of ChatGPT's zero-shot capabilities for text annotation and classification, focusing on different model parameters, prompt variations, and repetitions of identical inputs. Based on the real-world classification task of differentiating website texts into news and not news, results show that consistency in ChatGPT's classification output can fall short of scientific thresholds for reliability. For example, even minor wording alterations in prompts or repeating the identical input can lead to varying outputs. Although pooling outputs from multiple repetitions can improve reliability, this study advises caution when using ChatGPT for zero-shot text annotation and underscores the need for thorough validation, such as comparison against human-annotated data. The unsupervised application of ChatGPT for text annotation and classification is not recommended. ","[{'version': 'v1', 'created': 'Mon, 17 Apr 2023 00:41:19 GMT'}]",2023-04-24,"[['Reiss', 'Michael V.', '']]",1,1,2023-04-17,1,1,1,1,0,1,3a37a5cb06b2deac73175214f8517b64d9d7d5a0,258291402.0,https://www.semanticscholar.org/paper/3a37a5cb06b2deac73175214f8517b64d9d7d5a0,arXiv.org,2023.0,16.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2069139464', 'name': 'Michael V. Reiss'}]",['University of Zurich'],['Switzerland'],2023-04
2304.11111,Julian Coda-Forno,"Julian Coda-Forno, Kristin Witte, Akshay K. Jagadish, Marcel Binz,
  Zeynep Akata, Eric Schulz",Inducing anxiety in large language models increases exploration and bias,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of computational psychiatry, a framework used to computationally describe and modify aberrant behavior, to the outputs produced by these models. We focus on the Generative Pre-Trained Transformer 3.5 and subject it to tasks commonly studied in psychiatry. Our results show that GPT-3.5 responds robustly to a common anxiety questionnaire, producing higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be predictably changed by using emotion-inducing prompts. Emotion-induction not only influences GPT-3.5's behavior in a cognitive task measuring exploratory decision-making but also influences its behavior in a previously-established task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a strong increase in biases when prompted with anxiety-inducing text. Thus, it is likely that how prompts are communicated to large language models has a strong influence on their behavior in applied settings. These results progress our understanding of prompt engineering and demonstrate the usefulness of methods taken from computational psychiatry for studying the capable algorithms to which we increasingly delegate authority and autonomy. ","[{'version': 'v1', 'created': 'Fri, 21 Apr 2023 16:29:43 GMT'}]",2023-04-24,"[['Coda-Forno', 'Julian', ''], ['Witte', 'Kristin', ''], ['Jagadish', 'Akshay K.', ''], ['Binz', 'Marcel', ''], ['Akata', 'Zeynep', ''], ['Schulz', 'Eric', '']]",0,1,2023-04-21,1,6,3,1,0,1,27c16cca907aa43397cc226a182b73b396c5cf66,258291914.0,https://www.semanticscholar.org/paper/27c16cca907aa43397cc226a182b73b396c5cf66,arXiv.org,2023.0,68.0,19.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2215168951', 'name': 'Julian Coda-Forno'}, {'authorId': '2036327358', 'name': 'Kristin Witte'}, {'authorId': '8341302', 'name': 'A. Jagadish'}, {'authorId': '32354733', 'name': 'Marcel Binz'}, {'authorId': '2893664', 'name': 'Zeynep Akata'}, {'authorId': '49427184', 'name': 'Eric Schulz'}]","['University of Tübingen', 'Max Planck Institute for Biological Cybernetics']",['Germany'],2023-04
2304.11164,Jose Hernandez-Orallo,"Anthony G Cohn, Jose Hernandez-Orallo",Dialectical language model evaluation: An initial appraisal of the commonsense spatial reasoning abilities of LLMs,11 pages in main paper + 71 pages in appendix,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Language models have become very popular recently and many claims have been made about their abilities, including for commonsense reasoning. Given the increasingly better results of current language models on previous static benchmarks for commonsense reasoning, we explore an alternative dialectical evaluation. The goal of this kind of evaluation is not to obtain an aggregate performance value but to find failures and map the boundaries of the system. Dialoguing with the system gives the opportunity to check for consistency and get more reassurance of these boundaries beyond anecdotal evidence. In this paper we conduct some qualitative investigations of this kind of evaluation for the particular case of spatial reasoning (which is a fundamental aspect of commonsense reasoning). We conclude with some suggestions for future work both to improve the capabilities of language models and to systematise this kind of dialectical evaluation. ","[{'version': 'v1', 'created': 'Sat, 22 Apr 2023 06:28:46 GMT'}]",2023-04-25,"[['Cohn', 'Anthony G', ''], ['Hernandez-Orallo', 'Jose', '']]",0,0,2023-04-22,1,2,2,0,0,0,4f1aaee2b06856f5826debf1e177aa5e6dcb5a8c,258301085.0,https://www.semanticscholar.org/paper/4f1aaee2b06856f5826debf1e177aa5e6dcb5a8c,arXiv.org,2023.0,25.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1703235', 'name': 'A. Cohn'}, {'authorId': '1398777358', 'name': 'J. Hernández-Orallo'}]","['Universitat Politècnica de València', 'University of Leeds']","['United Kingdom', 'Spain']",2023-04
2304.11214,Basit Qureshi,Basit Qureshi,Exploring the Use of ChatGPT as a Tool for Learning and Assessment in Undergraduate Computer Science Curriculum: Opportunities and Challenges,"8 pages, 4 figures",,,,cs.CY cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in the computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to text books and notes of programming courses, however no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using PC2 environment. Each team of students address the problem by writing executable code that satisfies certain number of test cases. Student teams were scored based on their performance in terms of number of successful passed testcases. Results show that students using ChatGPT had an advantage in terms of earned scores, however there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper's findings indicate that incorporating AI in higher education brings about various opportunities and challenges. ","[{'version': 'v1', 'created': 'Sun, 16 Apr 2023 21:04:52 GMT'}]",2023-04-25,"[['Qureshi', 'Basit', '']]",1,1,2023-04-16,1,1,2,1,0,1,3520882d33a9279e706e37b5e1d4878722b40fce,258297892.0,https://www.semanticscholar.org/paper/3520882d33a9279e706e37b5e1d4878722b40fce,arXiv.org,2023.0,30.0,7.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '145100089', 'name': 'B. Qureshi'}]",['Prince Sultan University'],['Saudi Arabia'],2023-04
2304.11215,Eduardo C. Garrido-Merch\'an,"Alejo Jose G. Sison, Marco Tulio Daza, Roberto Gozalo-Brizuela and
  Eduardo C. Garrido-Merch\'an","ChatGPT: More than a Weapon of Mass Deception, Ethical challenges and responses from the Human-Centered Artificial Intelligence (HCAI) perspective",,,,,cs.CY cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article explores the ethical problems arising from the use of ChatGPT as a kind of generative AI and suggests responses based on the Human-Centered Artificial Intelligence (HCAI) framework. The HCAI framework is appropriate because it understands technology above all as a tool to empower, augment, and enhance human agency while referring to human wellbeing as a grand challenge, thus perfectly aligning itself with ethics, the science of human flourishing. Further, HCAI provides objectives, principles, procedures, and structures for reliable, safe, and trustworthy AI which we apply to our ChatGPT assessments. The main danger ChatGPT presents is the propensity to be used as a weapon of mass deception (WMD) and an enabler of criminal activities involving deceit. We review technical specifications to better comprehend its potentials and limitations. We then suggest both technical (watermarking, styleme, detectors, and fact-checkers) and non-technical measures (terms of use, transparency, educator considerations, HITL) to mitigate ChatGPT misuse or abuse and recommend best uses (creative writing, non-creative writing, teaching and learning). We conclude with considerations regarding the role of humans in ensuring the proper use of ChatGPT for individual and social wellbeing. ","[{'version': 'v1', 'created': 'Thu, 6 Apr 2023 07:40:12 GMT'}]",2023-04-25,"[['Sison', 'Alejo Jose G.', ''], ['Daza', 'Marco Tulio', ''], ['Gozalo-Brizuela', 'Roberto', ''], ['Garrido-Merchán', 'Eduardo C.', '']]",1,1,2023-04-06,1,4,2,1,0,1,f6d60ef6317a9f6de13e03b38c5c9bb8e6717d49,258298047.0,https://www.semanticscholar.org/paper/f6d60ef6317a9f6de13e03b38c5c9bb8e6717d49,Social Science Research Network,2023.0,158.0,14.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '101132973', 'name': 'A. Sison'}, {'authorId': '2197260949', 'name': 'Marco Tulio Daza'}, {'authorId': '2200162353', 'name': 'Roberto Gozalo-Brizuela'}, {'authorId': '2170361666', 'name': ""Eduardo C. Garrido-Merch'an""}]","['University of Guadalajara', 'University of Navarra', 'Comillas Pontifical University']","['Mexico', 'Spain']",2023-04
2304.11593,Fazl Barez,"Fazl Barez, Hosien Hasanbieg, Alesandro Abbate",System III: Learning with Domain Knowledge for Safety Constraints,,,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Reinforcement learning agents naturally learn from extensive exploration. Exploration is costly and can be unsafe in $\textit{safety-critical}$ domains. This paper proposes a novel framework for incorporating domain knowledge to help guide safe exploration and boost sample efficiency. Previous approaches impose constraints, such as regularisation parameters in neural networks, that rely on large sample sets and often are not suitable for safety-critical domains where agents should almost always avoid unsafe actions. In our approach, called $\textit{System III}$, which is inspired by psychologists' notions of the brain's $\textit{System I}$ and $\textit{System II}$, we represent domain expert knowledge of safety in form of first-order logic. We evaluate the satisfaction of these constraints via p-norms in state vector space. In our formulation, constraints are analogous to hazards, objects, and regions of state that have to be avoided during exploration. We evaluated the effectiveness of the proposed method on OpenAI's Gym and Safety-Gym environments. In all tasks, including classic Control and Safety Games, we show that our approach results in safer exploration and sample efficiency. ","[{'version': 'v1', 'created': 'Sun, 23 Apr 2023 09:44:41 GMT'}]",2023-04-25,"[['Barez', 'Fazl', ''], ['Hasanbieg', 'Hosien', ''], ['Abbate', 'Alesandro', '']]",0,0,2023-04-23,1,3,1,0,0,0,690d89a61023dba64103208c2da09dc1415a15ae,258298740.0,https://www.semanticscholar.org/paper/690d89a61023dba64103208c2da09dc1415a15ae,arXiv.org,2023.0,26.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143198655', 'name': 'Fazl Barez'}, {'authorId': '2215214869', 'name': 'Hosien Hasanbieg'}, {'authorId': '2215214843', 'name': 'Alesandro Abbate'}]","['University of Edinburgh', 'University of Oxford']",['United Kingdom'],2023-04
2304.11852,Didier EL BAZ,Didier El Baz (LAAS-CDA),"Can we Trust Chatbots for now? Accuracy, reproducibility, traceability; a Case Study on Leonardo da Vinci's Contribution to Astronomy",,,,,cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLM) are studied. Applications to chatbots and education are considered. A case study on Leonardo's contribution to astronomy is presented. Major problems with accuracy, reproducibility and traceability of answers are reported for ChatGPT, GPT-4, BLOOM and Google Bard. Possible reasons for problems are discussed and some solutions are proposed. ","[{'version': 'v1', 'created': 'Mon, 24 Apr 2023 06:54:10 GMT'}]",2023-04-25,"[['Baz', 'Didier El', '', 'LAAS-CDA']]",1,1,2023-04-24,1,1,1,3,1,2,956a597f08917ca9d3180e247d00470a38c1c8bc,258298720.0,https://www.semanticscholar.org/paper/956a597f08917ca9d3180e247d00470a38c1c8bc,Advances in Artificial Intelligence and Machine Learning,2023.0,32.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '3009860', 'name': 'D. E. Baz'}]",['Université de Toulouse'],['France'],2023-04
2304.11957,Yixing Huang,"Yixing Huang, Ahmed Gomaa, Sabine Semrau, Marlen Haderlein, Sebastian
  Lettmaier, Thomas Weissmann, Johanna Grigo, Hassen Ben Tkhayat, Benjamin
  Frey, Udo S. Gaipl, Luitpold V. Distel, Andreas Maier, Rainer Fietkau,
  Christoph Bert, and Florian Putz",Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology,,,,,physics.med-ph cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The potential of large language models in medicine for education and decision making purposes has been demonstrated as they achieve decent scores on medical exams such as the United States Medical Licensing Exam (USMLE) and the MedQA exam. In this work, we evaluate the performance of ChatGPT-4 in the specialized field of radiation oncology using the 38th American College of Radiology (ACR) radiation oncology in-training (TXIT) exam and the 2022 Red Journal Gray Zone cases. For the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of 63.65% and 74.57%, respectively, highlighting the advantage of the latest ChatGPT-4 model. Based on the TXIT exam, ChatGPT-4's strong and weak areas in radiation oncology are identified to some extent. Specifically, ChatGPT-4 demonstrates better knowledge of statistics, CNS & eye, pediatrics, biology, and physics than knowledge of bone & soft tissue and gynecology, as per the ACR knowledge domain. Regarding clinical care paths, ChatGPT-4 performs better in diagnosis, prognosis, and toxicity than brachytherapy and dosimetry. It lacks proficiency in in-depth details of clinical trials. For the Gray Zone cases, ChatGPT-4 is able to suggest a personalized treatment approach to each case with high correctness and comprehensiveness. Importantly, it provides novel treatment aspects for many cases, which are not suggested by any human experts. Both evaluations demonstrate the potential of ChatGPT-4 in medical education for the general public and cancer patients, as well as the potential to aid clinical decision-making, while acknowledging its limitations in certain domains. Because of the risk of hallucination, facts provided by ChatGPT always need to be verified. ","[{'version': 'v1', 'created': 'Mon, 24 Apr 2023 09:50:39 GMT'}, {'version': 'v2', 'created': 'Tue, 9 May 2023 08:23:42 GMT'}, {'version': 'v3', 'created': 'Tue, 23 May 2023 10:58:53 GMT'}, {'version': 'v4', 'created': 'Mon, 21 Aug 2023 09:20:48 GMT'}]",2023-08-22,"[['Huang', 'Yixing', ''], ['Gomaa', 'Ahmed', ''], ['Semrau', 'Sabine', ''], ['Haderlein', 'Marlen', ''], ['Lettmaier', 'Sebastian', ''], ['Weissmann', 'Thomas', ''], ['Grigo', 'Johanna', ''], ['Tkhayat', 'Hassen Ben', ''], ['Frey', 'Benjamin', ''], ['Gaipl', 'Udo S.', ''], ['Distel', 'Luitpold V.', ''], ['Maier', 'Andreas', ''], ['Fietkau', 'Rainer', ''], ['Bert', 'Christoph', ''], ['Putz', 'Florian', '']]",1,1,2023-04-24,4,15,2,1,0,1,1a45858d84a3baece50bb690235323ed8579b4c7,258564472.0,https://www.semanticscholar.org/paper/1a45858d84a3baece50bb690235323ed8579b4c7,,2023.0,68.0,1.0,0.0,False,"['Physics', 'Computer Science']","[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '46844678', 'name': 'Yixing Huang'}, {'authorId': '87264299', 'name': 'A. Gomaa'}, {'authorId': '6792689', 'name': 'S. Semrau'}, {'authorId': '6109251', 'name': 'M. Haderlein'}, {'authorId': '3601544', 'name': 'S. Lettmaier'}, {'authorId': '1403921253', 'name': 'T. Weissmann'}, {'authorId': '2166541624', 'name': 'J. Grigo'}, {'authorId': '2214582007', 'name': 'Hassen Ben Tkhayat'}, {'authorId': '144923478', 'name': 'B. Frey'}, {'authorId': '5431653', 'name': 'U. Gaipl'}, {'authorId': '4460659', 'name': 'L. Distel'}, {'authorId': '2216603908', 'name': 'Andreas Maier'}, {'authorId': '2071487779', 'name': 'R. Fietkau'}, {'authorId': '3382560', 'name': 'C. Bert'}, {'authorId': '143966934', 'name': 'F. Putz'}]","['Friedrich-Alexander-Universität Erlangen-Nürnberg', 'Comprehensive Cancer Center Erlangen']",['Germany'],2023-04
2304.12202,Ilias Chalkidis,Ilias Chalkidis,"ChatGPT may Pass the Bar Exam soon, but has a Long Way to Go for the LexGLUE benchmark",Working paper,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Following the hype around OpenAI's ChatGPT conversational agent, the last straw in the recent development of Large Language Models (LLMs) that demonstrate emergent unprecedented zero-shot capabilities, we audit the latest OpenAI's GPT-3.5 model, `gpt-3.5-turbo', the first available ChatGPT model, in the LexGLUE benchmark in a zero-shot fashion providing examples in a templated instruction-following format. The results indicate that ChatGPT achieves an average micro-F1 score of 47.6% across LexGLUE tasks, surpassing the baseline guessing rates. Notably, the model performs exceptionally well in some datasets, achieving micro-F1 scores of 62.8% and 70.2% in the ECtHR B and LEDGAR datasets, respectively. The code base and model predictions are available for review on https://github.com/coastalcph/zeroshot_lexglue. ","[{'version': 'v1', 'created': 'Thu, 9 Mar 2023 16:42:29 GMT'}]",2023-04-25,"[['Chalkidis', 'Ilias', '']]",1,1,2023-03-09,1,1,1,2,0,2,e770bdf8f00beb180a6b6509dd9a09b1bdbaed68,257579048.0,https://www.semanticscholar.org/paper/e770bdf8f00beb180a6b6509dd9a09b1bdbaed68,Social Science Research Network,2023.0,20.0,12.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '10783142', 'name': 'Ilias Chalkidis'}]",['University of Copenhagen'],['Denmark'],2023-03
2304.12203,Simon Kaare Larsen,Simon kaare Larsen,Creating Large Language Model Resistant Exams: Guidelines and Strategies,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  The proliferation of Large Language Models (LLMs), such as ChatGPT, has raised concerns about their potential impact on academic integrity, prompting the need for LLM-resistant exam designs. This article investigates the performance of LLMs on exams and their implications for assessment, focusing on ChatGPT's abilities and limitations. We propose guidelines for creating LLM-resistant exams, including content moderation, deliberate inaccuracies, real-world scenarios beyond the model's knowledge base, effective distractor options, evaluating soft skills, and incorporating non-textual information. The article also highlights the significance of adapting assessments to modern tools and promoting essential skills development in students. By adopting these strategies, educators can maintain academic integrity while ensuring that assessments accurately reflect contemporary professional settings and address the challenges and opportunities posed by artificial intelligence in education. ","[{'version': 'v1', 'created': 'Tue, 18 Apr 2023 18:01:32 GMT'}]",2023-04-25,"[['Larsen', 'Simon kaare', '']]",1,1,2023-04-18,1,1,1,1,0,1,708b27ae78d1dacda95ac927d4dd024df92eb0d3,258298307.0,https://www.semanticscholar.org/paper/708b27ae78d1dacda95ac927d4dd024df92eb0d3,arXiv.org,2023.0,12.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2053808908', 'name': 'Simon Larsén'}]",['Roskilde University'],['Denmark'],2023-04
2304.12269,Tim Van Dam,"Tim van Dam, Maliheh Izadi, Arie van Deursen",Enriching Source Code with Contextual Data for Code Completion Models: An Empirical Study,"13 pages. To appear in the Proceedings of the 20th International
  Conference on Mining Software Repositories (MSR 2023)",,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Transformer-based pre-trained models have recently achieved great results in solving many software engineering tasks including automatic code completion which is a staple in a developer's toolkit. While many have striven to improve the code-understanding abilities of such models, the opposite -- making the code easier to understand -- has not been properly investigated. In this study, we aim to answer whether making code easier to understand through using contextual data improves the performance of pre-trained code language models for the task of code completion. We consider type annotations and comments as two common forms of additional contextual information that often help developers understand code better. For the experiments, we study code completion in two granularity levels; token and line completion and take three recent and large-scale language models for source code: UniXcoder, CodeGPT, and InCoder with five evaluation metrics. Finally, we perform the Wilcoxon Signed Rank test to gauge significance and measure the effect size. Contrary to our expectations, all models perform better if type annotations are removed (albeit the effect sizes are small). For comments, we find that the models perform better in the presence of multi-line comments (again with small effect sizes). Based on our observations, we recommend making proper design choices when training, fine-tuning, or simply selecting such models given the intended data and application. Better evaluations and multi-modal techniques can also be further investigated to improve the practicality and accuracy of auto-completions. ","[{'version': 'v1', 'created': 'Mon, 24 Apr 2023 17:09:14 GMT'}]",2023-04-25,"[['van Dam', 'Tim', ''], ['Izadi', 'Maliheh', ''], ['van Deursen', 'Arie', '']]",0,1,2023-04-24,1,3,1,0,0,0,9d7bee11ccc3490966ffd17ec9a60a45ed391a33,258298223.0,https://www.semanticscholar.org/paper/9d7bee11ccc3490966ffd17ec9a60a45ed391a33,IEEE Working Conference on Mining Software Repositories,2023.0,51.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1581827808', 'name': 'T. V. Dam'}, {'authorId': '145774460', 'name': 'M. Izadi'}, {'authorId': '1737202', 'name': 'A. Deursen'}]",['Delft University of Technology'],['Netherlands'],2023-04
2304.12494,Usmi Mukherjee,Usmi Mukherjee and Mohammad Masudur Rahman,Employing Deep Learning and Structured Information Retrieval to Answer Clarification Questions on Bug Reports,Fixed formatting and typographical errors,,,,cs.SE,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Software bug reports reported on bug-tracking systems often lack crucial information for the developers to promptly resolve them, costing companies billions of dollars. There has been significant research on effectively eliciting information from bug reporters in bug tracking systems using different templates that bug reporters need to use. However, the need for asking follow-up questions persists. Recent studies propose techniques to suggest these follow-up questions to help developers obtain the missing details, but there has been little research on answering these follow up questions, which are often unanswered. In this paper, we propose a novel approach that uses CodeT5 in combination with Lucene, an information retrieval technique that leverages the relevance of different bug reports, their components, and follow-up questions to recommend answers. These top-performing answers, along with their bug report, serve as additional context apart from the deficient bug report to the deep learning model for generating an answer. We evaluate our recommended answers with the manually annotated answers using similarity metrics like Normalized Smooth BLEU Score, METEOR, Word Mover's Distance, and Semantic Similarity. We achieve a BLEU Score of up to 34 and Semantic Similarity of up to 64 which shows that the answers generated are understandable and good according to Google's standard and can outperform multiple baselines. ","[{'version': 'v1', 'created': 'Mon, 24 Apr 2023 23:29:14 GMT'}, {'version': 'v2', 'created': 'Wed, 26 Apr 2023 19:41:02 GMT'}, {'version': 'v3', 'created': 'Sat, 8 Jul 2023 12:16:53 GMT'}]",2023-07-11,"[['Mukherjee', 'Usmi', ''], ['Rahman', 'Mohammad Masudur', '']]",0,0,2023-04-24,3,2,1,0,0,0,0e39f939f7715f750dd2d699a61dbe4b8bb53dd4,259501524.0,https://www.semanticscholar.org/paper/0e39f939f7715f750dd2d699a61dbe4b8bb53dd4,,2023.0,30.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2215270692', 'name': 'Usmi Mukherjee'}, {'authorId': '2210196781', 'name': 'M. M. Rahman'}]",['Dalhousie University'],['Canada'],2023-04
2304.12918,Fazl Barez,"Alex Foote, Neel Nanda, Esben Kran, Ionnis Konstas, Fazl Barez",N2G: A Scalable Approach for Quantifying Interpretable Neuron Representations in Large Language Models,"To be published at ICLR 2023 Workshop on Trustworthy and Reliable
  Large-Scale Machine Learning Models",,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Understanding the function of individual neurons within language models is essential for mechanistic interpretability research. We propose $\textbf{Neuron to Graph (N2G)}$, a tool which takes a neuron and its dataset examples, and automatically distills the neuron's behaviour on those examples to an interpretable graph. This presents a less labour intensive approach to interpreting neurons than current manual methods, that will better scale these methods to Large Language Models (LLMs). We use truncation and saliency methods to only present the important tokens, and augment the dataset examples with more diverse samples to better capture the extent of neuron behaviour. These graphs can be visualised to aid manual interpretation by researchers, but can also output token activations on text to compare to the neuron's ground truth activations for automatic validation. N2G represents a step towards scalable interpretability methods by allowing us to convert neurons in an LLM to interpretable representations of measurable quality. ","[{'version': 'v1', 'created': 'Sat, 22 Apr 2023 19:06:13 GMT'}]",2023-04-26,"[['Foote', 'Alex', ''], ['Nanda', 'Neel', ''], ['Kran', 'Esben', ''], ['Konstas', 'Ionnis', ''], ['Barez', 'Fazl', '']]",0,0,2023-04-22,1,5,1,0,0,0,ff028bc8393ea67c7777e859ffcacf6453f8f268,258309407.0,https://www.semanticscholar.org/paper/ff028bc8393ea67c7777e859ffcacf6453f8f268,arXiv.org,2023.0,30.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067807267', 'name': 'Alex Foote'}, {'authorId': '2051128902', 'name': 'Neel Nanda'}, {'authorId': '2005663935', 'name': 'Esben Kran'}, {'authorId': '2215271586', 'name': 'Ionnis Konstas'}, {'authorId': '2143198655', 'name': 'Fazl Barez'}]",['University of Oxford'],['United Kingdom'],2023-04
2304.13009,Lucas Prado Osco,"Lucas Prado Osco, Eduardo Lopes de Lemos, Wesley Nunes Gon\c{c}alves,
  Ana Paula Marques Ramos and Jos\'e Marcato Junior",The Potential of Visual ChatGPT For Remote Sensing,,,,,cs.CV eess.IV,http://creativecommons.org/licenses/by/4.0/,"  Recent advancements in Natural Language Processing (NLP), particularly in Large Language Models (LLMs), associated with deep learning-based computer vision techniques, have shown substantial potential for automating a variety of tasks. One notable model is Visual ChatGPT, which combines ChatGPT's LLM capabilities with visual computation to enable effective image analysis. The model's ability to process images based on textual inputs can revolutionize diverse fields. However, its application in the remote sensing domain remains unexplored. This is the first paper to examine the potential of Visual ChatGPT, a cutting-edge LLM founded on the GPT architecture, to tackle the aspects of image processing related to the remote sensing domain. Among its current capabilities, Visual ChatGPT can generate textual descriptions of images, perform canny edge and straight line detection, and conduct image segmentation. These offer valuable insights into image content and facilitate the interpretation and extraction of information. By exploring the applicability of these techniques within publicly available datasets of satellite images, we demonstrate the current model's limitations in dealing with remote sensing images, highlighting its challenges and future prospects. Although still in early development, we believe that the combination of LLMs and visual models holds a significant potential to transform remote sensing image processing, creating accessible and practical application opportunities in the field. ","[{'version': 'v1', 'created': 'Tue, 25 Apr 2023 17:29:47 GMT'}, {'version': 'v2', 'created': 'Wed, 5 Jul 2023 14:09:09 GMT'}]",2023-07-06,"[['Osco', 'Lucas Prado', ''], ['de Lemos', 'Eduardo Lopes', ''], ['Gonçalves', 'Wesley Nunes', ''], ['Ramos', 'Ana Paula Marques', ''], ['Junior', 'José Marcato', '']]",1,1,2023-04-25,2,5,2,1,0,1,f6654702479eddb01d6f1bd72d6d56102ebefbfc,258309660.0,https://www.semanticscholar.org/paper/f6654702479eddb01d6f1bd72d6d56102ebefbfc,Remote Sensing,2023.0,48.0,1.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","[{'authorId': '1879063052', 'name': 'L. Osco'}, {'authorId': '2215273732', 'name': 'Eduardo Lopes de Lemos'}, {'authorId': '1685701', 'name': 'W. Gonçalves'}, {'authorId': '50644386', 'name': 'A. P. Ramos'}, {'authorId': '70672707', 'name': 'J. M. Junior'}]","['Universidade Estadual Paulista (Unesp)', 'Universidade Federal de Mato Grosso do Sul', 'Universidade do Oeste Paulista']",['Brazil'],2023-04
2304.13157,Iain Mackie,"Iain Mackie, Shubham Chatterjee, Jeffrey Dalton",Generative Relevance Feedback with Large Language Models,"SIGIR 2023 Preprint, 6 pages",,10.1145/3539618.3591992,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current query expansion models use pseudo-relevance feedback to improve first-pass retrieval effectiveness; however, this fails when the initial results are not relevant. Instead of building a language model from retrieved results, we propose Generative Relevance Feedback (GRF) that builds probabilistic feedback models from long-form text generated from Large Language Models. We study the effective methods for generating text by varying the zero-shot generation subtasks: queries, entities, facts, news articles, documents, and essays. We evaluate GRF on document retrieval benchmarks covering a diverse set of queries and document collections, and the results show that GRF methods significantly outperform previous PRF methods. Specifically, we improve MAP between 5-19% and NDCG@10 17-24% compared to RM3 expansion, and achieve the best R@1k effectiveness on all datasets compared to state-of-the-art sparse, dense, and expansion models. ","[{'version': 'v1', 'created': 'Tue, 25 Apr 2023 21:35:29 GMT'}]",2023-04-27,"[['Mackie', 'Iain', ''], ['Chatterjee', 'Shubham', ''], ['Dalton', 'Jeffrey', '']]",0,0,2023-04-25,1,3,1,0,0,0,2c32a5fcb393df9cc7a978cf35dbe880b0f45622,258332122.0,https://www.semanticscholar.org/paper/2c32a5fcb393df9cc7a978cf35dbe880b0f45622,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,51.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145052856', 'name': 'Iain Mackie'}, {'authorId': '2113355478', 'name': 'Shubham Chatterjee'}, {'authorId': '49694325', 'name': 'Jeffrey Stephen Dalton'}]",['University of Glasgow'],['United Kingdom'],2023-04
2304.13462,Huiyuan Lai,"Huiyuan Lai, Antonio Toral, Malvina Nissim",Multidimensional Evaluation for Text Style Transfer Using ChatGPT,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We investigate the potential of ChatGPT as a multidimensional evaluator for the task of \emph{Text Style Transfer}, alongside, and in comparison to, existing automatic metrics as well as human judgements. We focus on a zero-shot setting, i.e. prompting ChatGPT with specific task instructions, and test its performance on three commonly-used dimensions of text style transfer evaluation: style strength, content preservation, and fluency. We perform a comprehensive correlation analysis for two transfer directions (and overall) at different levels. Compared to existing automatic metrics, ChatGPT achieves competitive correlations with human judgments. These preliminary results are expected to provide a first glimpse into the role of large language models in the multidimensional evaluation of stylized text generation. ","[{'version': 'v1', 'created': 'Wed, 26 Apr 2023 11:33:35 GMT'}]",2023-04-27,"[['Lai', 'Huiyuan', ''], ['Toral', 'Antonio', ''], ['Nissim', 'Malvina', '']]",1,1,2023-04-26,1,3,1,1,0,1,a2b44f12033099d667ae848a28469f633709224b,258332065.0,https://www.semanticscholar.org/paper/a2b44f12033099d667ae848a28469f633709224b,arXiv.org,2023.0,44.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66376493', 'name': 'Huiyuan Lai'}, {'authorId': '2065048323', 'name': 'Antonio Toral'}, {'authorId': '2742475', 'name': 'M. Nissim'}]","['CLCG, University of Groningen / The Netherlands']",['Netherlands'],2023-04
2304.13559,Matthias Urban,Matthias Urban and Carsten Binnig,Towards Multi-Modal DBMSs for Seamless Querying of Texts and Tables,,,,,cs.DB cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we propose Multi-Modal Databases (MMDBs), which is a new class of database systems that can seamlessly query text and tables using SQL. To enable seamless querying of textual data using SQL in an MMDB, we propose to extend relational databases with so-called multi-modal operators (MMOps) which are based on the advances of recent large language models such as GPT-3. The main idea of MMOps is that they allow text collections to be treated as tables without the need to manually transform the data. As we show in our evaluation, our MMDB prototype can not only outperform state-of-the-art approaches such as text-to-table in terms of accuracy and performance but it also requires significantly less training data to fine-tune the model for an unseen text collection. ","[{'version': 'v1', 'created': 'Wed, 26 Apr 2023 13:31:04 GMT'}, {'version': 'v2', 'created': 'Fri, 28 Apr 2023 14:55:48 GMT'}]",2023-05-01,"[['Urban', 'Matthias', ''], ['Binnig', 'Carsten', '']]",0,1,2023-04-26,2,2,2,1,0,1,c8ee58e5f44f650f6d44b58ec7c2d067e187907d,258331780.0,https://www.semanticscholar.org/paper/c8ee58e5f44f650f6d44b58ec7c2d067e187907d,arXiv.org,2023.0,48.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067522077', 'name': 'Matthias Urban'}, {'authorId': '2691974', 'name': 'Carsten Binnig'}]",['Technical University of Darmstadt'],['Germany'],2023-04
2304.13567,Mehdi Ben Amor,"Mehdi Ben Amor, Michael Granitzer, Jelena Mitrovi\'c",Technical Report on Token Position Bias in Transformers,Updated title of the preprint,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Language Models (LMs) have shown state-of-the-art performance in Natural Language Processing (NLP) tasks. Downstream tasks such as Named Entity Recognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data imbalance issues, specifically in terms of the ratio of positive to negative examples, and class imbalance. In this paper, we investigate an additional specific issue for language models, namely the position bias of positive examples in token classification tasks. Therefore, we conduct an in-depth evaluation of the impact of position bias on the performance of LMs when fine-tuned on Token Classification benchmarks. Our study includes CoNLL03 and OntoNote5.0 for NER, English Tree Bank UD_en and TweeBank for POS tagging. We propose an evaluation approach to investigate position bias in Transformer models. We show that encoders like BERT, ERNIE, ELECTRA, and decoders such as GPT2 and BLOOM can suffer from this bias with an average drop of 3\% and 9\% in their performance. To mitigate this effect, we propose two methods: Random Position Shifting and Context Perturbation, that we apply on batches during the training process. The results show an improvement of $\approx$ 2\% in the performance of the model on CoNLL03, UD_en, and TweeBank. ","[{'version': 'v1', 'created': 'Wed, 26 Apr 2023 13:57:25 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Jun 2023 09:11:03 GMT'}]",2023-06-06,"[['Amor', 'Mehdi Ben', ''], ['Granitzer', 'Michael', ''], ['Mitrović', 'Jelena', '']]",0,1,2023-04-26,2,3,2,2,2,0,b5416fc248f3dbcece522ef59f571a1f56e5e9a4,259075945.0,https://www.semanticscholar.org/paper/b5416fc248f3dbcece522ef59f571a1f56e5e9a4,,2023.0,26.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2074055134', 'name': 'Mehdi Ben Amor'}, {'authorId': '2389675', 'name': 'M. Granitzer'}, {'authorId': '2215389297', 'name': ""Jelena Mitrovi'c""}]",['University of Passau'],['Germany'],2023-04
2304.13731,Soujanya Poria,"Deepanway Ghosal, Navonil Majumder, Ambuj Mehrish, Soujanya Poria",Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model,https://github.com/declare-lab/tango,,,,eess.AS cs.AI cs.CL cs.SD,http://creativecommons.org/licenses/by-sa/4.0/,"  The immense scale of the recent large language models (LLM) allows many interesting properties, such as, instruction- and chain-of-thought-based fine-tuning, that has significantly improved zero- and few-shot performance in many natural language processing (NLP) tasks. Inspired by such successes, we adopt such an instruction-tuned LLM Flan-T5 as the text encoder for text-to-audio (TTA) generation -- a task where the goal is to generate an audio from its textual description. The prior works on TTA either pre-trained a joint text-audio encoder or used a non-instruction-tuned model, such as, T5. Consequently, our latent diffusion model (LDM)-based approach TANGO outperforms the state-of-the-art AudioLDM on most metrics and stays comparable on the rest on AudioCaps test set, despite training the LDM on a 63 times smaller dataset and keeping the text encoder frozen. This improvement might also be attributed to the adoption of audio pressure level-based sound mixing for training set augmentation, whereas the prior methods take a random mix. ","[{'version': 'v1', 'created': 'Mon, 24 Apr 2023 07:45:28 GMT'}, {'version': 'v2', 'created': 'Mon, 29 May 2023 12:09:08 GMT'}]",2023-05-30,"[['Ghosal', 'Deepanway', ''], ['Majumder', 'Navonil', ''], ['Mehrish', 'Ambuj', ''], ['Poria', 'Soujanya', '']]",0,0,2023-04-24,2,4,4,3,2,1,f51bc74814a3452009ea5ca262d9768d08149ee6,258352270.0,https://www.semanticscholar.org/paper/f51bc74814a3452009ea5ca262d9768d08149ee6,arXiv.org,2023.0,41.0,31.0,7.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32528506', 'name': 'Deepanway Ghosal'}, {'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '3391951', 'name': 'Ambuj Mehrish'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}]",['Singapore University of Technology and Design'],['Singapore'],2023-04
2304.13765,Alexis Roger,"Alexis Roger, Esma A\""imeur, Irina Rish",Towards ethical multimodal systems,"7 pages, multimodal ethical dataset building",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The impact of artificial intelligence systems on our society is increasing at an unprecedented speed. For instance, ChatGPT is being tested in mental health treatment applications such as Koko, Stable Diffusion generates pieces of art competitive with (or outperforming) human artists, and so on. Ethical concerns regarding the behavior and applications of generative AI systems have been increasing over the past years, and the field of AI alignment - steering the behavior of AI systems towards being aligned with human values - is a rapidly growing subfield of modern AI. In this paper, we address the challenges involved in ethical evaluation of a multimodal artificial intelligence system. The multimodal systems we focus on take both text and an image as input and output text, completing the sentence or answering the question asked as input. We perform the evaluation of these models in two steps: we first discus the creation of a multimodal ethical database and then use this database to construct morality-evaluating algorithms. The creation of the multimodal ethical database is done interactively through human feedback. Users are presented with multiple examples and votes on whether they are ethical or not. Once these answers have been aggregated into a dataset, we built and tested different algorithms to automatically evaluate the morality of multimodal systems. These algorithms aim to classify the answers as ethical or not. The models we tested are a RoBERTa-large classifier and a multilayer perceptron classifier. ","[{'version': 'v1', 'created': 'Wed, 26 Apr 2023 18:11:33 GMT'}]",2023-04-28,"[['Roger', 'Alexis', ''], ['Aïmeur', 'Esma', ''], ['Rish', 'Irina', '']]",1,1,2023-04-26,1,3,1,1,0,1,867f1ad31d77484bf74906fe86fd8c7332889685,258352778.0,https://www.semanticscholar.org/paper/867f1ad31d77484bf74906fe86fd8c7332889685,arXiv.org,2023.0,45.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2187933184', 'name': 'Alexis Roger'}, {'authorId': '9254009', 'name': 'E. Aimeur'}, {'authorId': '2109771', 'name': 'I. Rish'}]",['Université de Montréal'],['Canada'],2023-04
2304.13861,Luca Maria Aiello,"Anders Giovanni M{\o}ller, Jacob Aarup Dalsgaard, Arianna Pera, Luca
  Maria Aiello",Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks,"12 pages, 4 figures, 4 tables",,,,cs.CL cs.CY physics.soc-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Obtaining and annotating data can be expensive and time-consuming, especially in complex, low-resource domains. We use GPT-4 and ChatGPT to augment small labeled datasets with synthetic data via simple prompts, in three different classification tasks with varying complexity. For each task, we randomly select a base sample of 500 texts to generate 5,000 new synthetic samples. We explore two augmentation strategies: one that preserves original label distribution and another that balances the distribution. Using a progressively larger training sample size, we train and evaluate a 110M parameter multilingual language model on the real and synthetic data separately. We also test GPT-4 and ChatGPT in a zero-shot setting on the test sets. We observe that GPT-4 and ChatGPT have strong zero-shot performance across all tasks. We find that data augmented with synthetic samples yields a good downstream performance, and particularly aids in low-resource settings, such as in identifying rare classes. Human-annotated data exhibits a strong predictive power, overtaking synthetic data in two out of the three tasks. This finding highlights the need for more complex prompts for synthetic datasets to consistently surpass human-generated ones. ","[{'version': 'v1', 'created': 'Wed, 26 Apr 2023 23:09:02 GMT'}]",2023-04-28,"[['Møller', 'Anders Giovanni', ''], ['Dalsgaard', 'Jacob Aarup', ''], ['Pera', 'Arianna', ''], ['Aiello', 'Luca Maria', '']]",1,1,2023-04-26,1,4,3,2,0,2,ca3037fed8ed14dea92985b9f288b05185f867d0,258352292.0,https://www.semanticscholar.org/paper/ca3037fed8ed14dea92985b9f288b05185f867d0,arXiv.org,2023.0,24.0,15.0,2.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2008212152', 'name': 'Anders Giovanni Møller'}, {'authorId': '1581551638', 'name': 'Jacob Aarup Dalsgaard'}, {'authorId': '2215477194', 'name': 'Arianna Pera'}, {'authorId': '2905635', 'name': 'L. Aiello'}]",['IT University of Copenhagen'],['Denmark'],2023-04
2304.13994,Dmytro Kalpakchi,"Dmytro Kalpakchi, Johan Boye",SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish,Added information about training tokenizer,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present SweCTRL-Mini, a large Swedish language model that can be used for inference and fine-tuning on a single consumer-grade GPU. The model is based on the CTRL architecture by Keskar, McCann, Varshney, Xiong, and Socher (2019), which means that users of the SweCTRL-Mini model can control the genre of the generated text by inserting special tokens in the generation prompts. SweCTRL-Mini is trained on a subset of the Swedish part of the mC4 corpus and a set of Swedish novels. In this article, we provide (1) a detailed account of the utilized training data and text pre-processing steps, to the extent that it is possible to check whether a specific phrase/source was a part of the training data, and (2) an evaluation of the model on both discriminative tasks, using automatic evaluation methods, and generative tasks, using human referees. We also compare the generative capabilities of the model with those of GPT-3. SweCTRL-Mini is fully open and available for download. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 07:32:37 GMT'}, {'version': 'v2', 'created': 'Sat, 13 May 2023 19:13:51 GMT'}, {'version': 'v3', 'created': 'Thu, 22 Jun 2023 13:02:23 GMT'}]",2023-06-23,"[['Kalpakchi', 'Dmytro', ''], ['Boye', 'Johan', '']]",0,1,2023-04-27,3,2,1,1,0,1,176e8c49c32f4c219857a1853998770927a598c6,258352262.0,https://www.semanticscholar.org/paper/176e8c49c32f4c219857a1853998770927a598c6,arXiv.org,2023.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '102742593', 'name': 'Dmytro Kalpakchi'}, {'authorId': '2386212', 'name': 'Johan Boye'}]",['KTH Royal Institute of Technology'],['Sweden'],2023-04
2304.14031,Nicholas Boucher,"Nicholas Boucher, Luca Pajola, Ilia Shumailov, Ross Anderson, Mauro
  Conti",Boosting Big Brother: Attacking Search Engines with Encodings,"To appear in the 26th Symposium on Research in Attacks, Intrusions
  and Defenses (RAID). Revisions: Adds table summarizing attacks",,10.1145/3607199.3607220,,cs.CR cs.IR,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Search engines are vulnerable to attacks against indexing and searching via text encoding manipulation. By imperceptibly perturbing text using uncommon encoded representations, adversaries can control results across search engines for specific search queries. We demonstrate that this attack is successful against two major commercial search engines - Google and Bing - and one open source search engine - Elasticsearch. We further demonstrate that this attack is successful against LLM chat search including Bing's GPT-4 chatbot and Google's Bard chatbot. We also present a variant of the attack targeting text summarization and plagiarism detection models, two ML tasks closely tied to search. We provide a set of defenses against these techniques and warn that adversaries can leverage these attacks to launch disinformation campaigns against unsuspecting users, motivating the need for search engine maintainers to patch deployed systems. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 08:56:42 GMT'}, {'version': 'v2', 'created': 'Thu, 27 Jul 2023 16:47:28 GMT'}]",2023-07-28,"[['Boucher', 'Nicholas', ''], ['Pajola', 'Luca', ''], ['Shumailov', 'Ilia', ''], ['Anderson', 'Ross', ''], ['Conti', 'Mauro', '']]",0,1,2023-04-27,2,5,2,1,0,1,90b67d69725cbf5a337a8042cfe6d1c27a0c0f78,258352264.0,https://www.semanticscholar.org/paper/90b67d69725cbf5a337a8042cfe6d1c27a0c0f78,International Symposium on Recent Advances in Intrusion Detection,2023.0,46.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2136215568', 'name': 'Nicholas Boucher'}, {'authorId': '27083576', 'name': 'Luca Pajola'}, {'authorId': '47473421', 'name': 'Ilia Shumailov'}, {'authorId': '40171469', 'name': 'Ross Anderson'}, {'authorId': '145746490', 'name': 'M. Conti'}]","['University of Padua', 'University of Cambridge', 'University of Oxford']","['United Kingdom', 'Italy']",2023-04
2304.14104,Morris Alper,Morris Alper and Hadar Averbuch-Elor,Learning Human-Human Interactions in Images from Weak Textual Supervision,"To be presented at ICCV 2023. Project webpage:
  https://learning-interactions.github.io",,,,cs.CV cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Interactions between humans are diverse and context-dependent, but previous works have treated them as categorical, disregarding the heavy tail of possible interactions. We propose a new paradigm of learning human-human interactions as free text from a single still image, allowing for flexibility in modeling the unlimited space of situations and relationships between people. To overcome the absence of data labelled specifically for this task, we use knowledge distillation applied to synthetic caption data produced by a large language model without explicit supervision. We show that the pseudo-labels produced by this procedure can be used to train a captioning model to effectively understand human-human interactions in images, as measured by a variety of metrics that measure textual and semantic faithfulness and factual groundedness of our predictions. We further show that our approach outperforms SOTA image captioning and situation recognition models on this task. We will release our code and pseudo-labels along with Waldo and Wenda, a manually-curated test set for still image human-human interaction understanding. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 11:32:48 GMT'}, {'version': 'v2', 'created': 'Mon, 7 Aug 2023 07:52:35 GMT'}, {'version': 'v3', 'created': 'Sun, 13 Aug 2023 12:17:51 GMT'}, {'version': 'v4', 'created': 'Mon, 18 Sep 2023 17:50:31 GMT'}]",2023-09-19,"[['Alper', 'Morris', ''], ['Averbuch-Elor', 'Hadar', '']]",0,0,2023-04-27,4,2,3,0,0,0,2ff15a4ad608c39ff0bda6ac87a8f6807ab46dc7,258352783.0,https://www.semanticscholar.org/paper/2ff15a4ad608c39ff0bda6ac87a8f6807ab46dc7,arXiv.org,2023.0,104.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '24312899', 'name': 'Morris Alper'}, {'authorId': '1388323535', 'name': 'Hadar Averbuch-Elor'}]",['Tel Aviv University'],['Israel'],2023-04
2304.14177,Roberto Martinez Cruz,"Roberto Mart\'inez-Cruz, Alvaro J. L\'opez-L\'opez, Jos\'e Portela",ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Transformer-based language models, including ChatGPT, have demonstrated exceptional performance in various natural language generation tasks. However, there has been limited research evaluating ChatGPT's keyphrase generation ability, which involves identifying informative phrases that accurately reflect a document's content. This study seeks to address this gap by comparing ChatGPT's keyphrase generation performance with state-of-the-art models, while also testing its potential as a solution for two significant challenges in the field: domain adaptation and keyphrase generation from long documents. We conducted experiments on six publicly available datasets from scientific articles and news domains, analyzing performance on both short and long documents. Our results show that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 13:25:43 GMT'}, {'version': 'v2', 'created': 'Thu, 29 Jun 2023 13:40:42 GMT'}]",2023-06-30,"[['Martínez-Cruz', 'Roberto', ''], ['López-López', 'Alvaro J.', ''], ['Portela', 'José', '']]",1,1,2023-04-27,2,3,2,1,0,1,d803c3096b25a699deafdb229ef6b46d912b99ae,258352743.0,https://www.semanticscholar.org/paper/d803c3096b25a699deafdb229ef6b46d912b99ae,arXiv.org,2023.0,74.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2215482759', 'name': ""Roberto Mart'inez-Cruz""}, {'authorId': '2215480600', 'name': ""Alvaro J. L'opez-L'opez""}, {'authorId': '2053927512', 'name': 'J. Portela'}]","[""Machine Learning Engineer Moody's Analytics Prague, Czech Republic"", 'Comillas Pontifical University']","['Czech Republic', 'Spain']",2023-04
2304.14233,Tao Shen,"Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Tianyi Zhou, Daxin
  Jiang",Large Language Models are Strong Zero-Shot Retriever,Work in progress,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  In this work, we propose a simple method that applies a large language model (LLM) to large-scale retrieval in zero-shot scenarios. Our method, the Language language model as Retriever (LameR), is built upon no other neural models but an LLM, while breaking brute-force combinations of retrievers with LLMs and lifting the performance of zero-shot retrieval to be very competitive on benchmark datasets. Essentially, we propose to augment a query with its potential answers by prompting LLMs with a composition of the query and the query's in-domain candidates. The candidates, regardless of correct or wrong, are obtained by a vanilla retrieval procedure on the target collection. As a part of the prompts, they are likely to help LLM generate more precise answers by pattern imitation or candidate summarization. Even if all the candidates are wrong, the prompts at least make LLM aware of in-collection patterns and genres. Moreover, due to the low performance of a self-supervised retriever, the LLM-based query augmentation becomes less effective as the retriever bottlenecks the whole pipeline. Therefore, we propose to leverage a non-parametric lexicon-based method (e.g., BM25) as the retrieval module to capture query-document overlap in a literal fashion. As such, LameR makes the retrieval procedure transparent to the LLM, thus circumventing the performance bottleneck. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 14:45:55 GMT'}, {'version': 'v2', 'created': 'Wed, 2 Aug 2023 02:06:28 GMT'}]",2023-08-03,"[['Shen', 'Tao', ''], ['Long', 'Guodong', ''], ['Geng', 'Xiubo', ''], ['Tao', 'Chongyang', ''], ['Zhou', 'Tianyi', ''], ['Jiang', 'Daxin', '']]",0,0,2023-04-27,2,6,2,0,0,0,718989761d0dc0f97727470f0dc23de7ea48c26d,258352285.0,https://www.semanticscholar.org/paper/718989761d0dc0f97727470f0dc23de7ea48c26d,arXiv.org,2023.0,46.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143681703', 'name': 'Tao Shen'}, {'authorId': '2062835', 'name': 'Guodong Long'}, {'authorId': '2442662', 'name': 'Xiubo Geng'}, {'authorId': '8801869', 'name': 'Chongyang Tao'}, {'authorId': '2213956781', 'name': 'Tianyi Zhou'}, {'authorId': '2086994543', 'name': 'Daxin Jiang'}]",['Finance and Economics Institute of Tajikistan'],['Tajikistan'],2023-04
2304.14276,Steffen Herbold,"Steffen Herbold, Annette Hautli-Janisz, Ute Heuer, Zlata Kikteva,
  Alexander Trautsch","AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays",Submitted,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Background: Recently, ChatGPT and similar generative AI models have attracted hundreds of millions of users and become part of the public discourse. Many believe that such models will disrupt society and will result in a significant change in the education system and information generation in the future. So far, this belief is based on either colloquial evidence or benchmarks from the owners of the models -- both lack scientific rigour.   Objective: Through a large-scale study comparing human-written versus ChatGPT-generated argumentative student essays, we systematically assess the quality of the AI-generated content.   Methods: A large corpus of essays was rated using standard criteria by a large number of human experts (teachers). We augment the analysis with a consideration of the linguistic characteristics of the generated essays.   Results: Our results demonstrate that ChatGPT generates essays that are rated higher for quality than human-written essays. The writing style of the AI models exhibits linguistic characteristics that are different from those of the human-written essays, e.g., it is characterized by fewer discourse and epistemic markers, but more nominalizations and greater lexical diversity.   Conclusions: Our results clearly demonstrate that models like ChatGPT outperform humans in generating argumentative essays. Since the technology is readily available for anyone to use, educators must act immediately. We must re-invent homework and develop teaching concepts that utilize these AI models in the same way as math utilized the calculator: teach the general concepts first and then use AI tools to free up time for other learning objectives. ","[{'version': 'v1', 'created': 'Mon, 24 Apr 2023 12:58:28 GMT'}]",2023-04-28,"[['Herbold', 'Steffen', ''], ['Hautli-Janisz', 'Annette', ''], ['Heuer', 'Ute', ''], ['Kikteva', 'Zlata', ''], ['Trautsch', 'Alexander', '']]",1,1,2023-04-24,1,5,2,1,0,1,8fb645e51d74244ab93b41788570c958fdcad06a,258352456.0,https://www.semanticscholar.org/paper/8fb645e51d74244ab93b41788570c958fdcad06a,arXiv.org,2023.0,49.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '3063461', 'name': 'S. Herbold'}, {'authorId': '1402188716', 'name': 'Annette Hautli-Janisz'}, {'authorId': '2091813780', 'name': 'Ute Heuer'}, {'authorId': '2174214589', 'name': 'Zlata Kikteva'}, {'authorId': '8058979', 'name': 'Alexander Trautsch'}]",['University of Passau'],['Germany'],2023-04
2304.14317,Terry Yue Zhuo,Terry Yue Zhuo,Large Language Models Are State-of-the-Art Evaluators of Code Generation,Personal weekend project; Work in progress,,,,cs.AI cs.CL cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Recent advancements in the field of natural language generation have facilitated the use of large language models to assess the quality of generated text. Although these models have shown promising results in tasks such as machine translation and summarization, their applicability in code generation tasks remains limited without human involvement. The complexity of programming concepts required for such tasks makes it difficult to develop evaluation metrics that align with human judgment. Token-matching-based metrics, such as BLEU, have demonstrated weak correlations with human practitioners in code generation tasks. Moreover, the utilization of human-written test suites to evaluate functional correctness can be challenging in domains with low resources. To overcome these obstacles, we propose a new evaluation framework based on the GPT-3.5 (\texttt{GPT-3.5-turbo}), for code generation assessments. Our framework addresses the limitations of existing approaches by achieving superior correlations with functional correctness and human preferences, without the need for test oracles or references. We evaluate the efficacy of our framework on two different tasks and four programming languages, comparing its performance with the state-of-the-art CodeBERTScore metric, which relies on a pre-trained model. Our results demonstrate that our framework surpasses CodeBERTScore, delivering high levels of accuracy and consistency across various programming languages and tasks. We also make our evaluation framework and datasets available to the public at \url{https://github.com/terryyz/llm-code-eval}, encouraging further research in the evaluation of code generation. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 16:38:17 GMT'}]",2023-04-28,"[['Zhuo', 'Terry Yue', '']]",0,1,2023-04-27,1,1,3,1,0,1,a6e53935e313caf68a4c51e4ddb90893005fdb3d,258352761.0,https://www.semanticscholar.org/paper/a6e53935e313caf68a4c51e4ddb90893005fdb3d,arXiv.org,2023.0,48.0,13.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2080123731', 'name': 'Terry Yue Zhuo'}]",['Monash University'],['Australia'],2023-04
2304.14352,Johan F. Hoorn,Johan F. Hoorn and Juliet J.-Y. Chen,Epistemic considerations when AI answers questions for us,1 figure,,,,cs.CY cs.AI cs.LO,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In this position paper, we argue that careless reliance on AI to answer our questions and to judge our output is a violation of Grice's Maxim of Quality as well as a violation of Lemoine's legal Maxim of Innocence, performing an (unwarranted) authority fallacy, and while lacking assessment signals, committing Type II errors that result from fallacies of the inverse. What is missing in the focus on output and results of AI-generated and AI-evaluated content is, apart from paying proper tribute, the demand to follow a person's thought process (or a machine's decision processes). In deliberately avoiding Neural Networks that cannot explain how they come to their conclusions, we introduce logic-symbolic inference to handle any possible epistemics any human or artificial information processor may have. Our system can deal with various belief systems and shows how decisions may differ for what is true, false, realistic, unrealistic, literal, or anomalous. As is, stota AI such as ChatGPT is a sorcerer's apprentice. ","[{'version': 'v1', 'created': 'Sun, 23 Apr 2023 08:26:42 GMT'}]",2023-04-28,"[['Hoorn', 'Johan F.', ''], ['Chen', 'Juliet J. -Y.', '']]",1,1,2023-04-23,1,2,3,1,0,1,3914a452ea89cfbfea34aab3e4e322fbea1fbe71,258352803.0,https://www.semanticscholar.org/paper/3914a452ea89cfbfea34aab3e4e322fbea1fbe71,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","[{'authorId': '71825175', 'name': 'J. Hoorn'}, {'authorId': '2215498724', 'name': 'Juliet J.-Y. Chen'}]","['Laboratory for Artificial Intelligence in Design', 'Hong Kong Polytechnic University']",['Hong Kong'],2023-04
2304.14402,Minghao Wu,"Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham
  Fikri Aji",LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions,"Work in progress, 20 pages, 8 figures, 15 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) with instruction fine-tuning demonstrate superior generative capabilities. However, these models are resource-intensive. To alleviate this issue, we explore distilling knowledge from instruction-tuned LLMs into much smaller ones. To this end, we carefully develop a large set of 2.58M instructions based on both existing and newly-generated instructions. In addition to being sizable, we design our instructions to cover a broad set of topics to ensure diversity. Extensive analysis of our instruction dataset confirms its diversity, and we generate responses for these instructions using gpt-3.5-turbo. Leveraging these instructions, we fine-tune a diverse herd of models, collectively referred to as LaMini-LM, which includes models from both the encoder-decoder and decoder-only families, with varying sizes. We evaluate the performance of our models using automatic metrics on 15 different natural language processing (NLP) benchmarks, as well as through human assessment. The results demonstrate that our proposed LaMini-LM models are comparable to competitive baselines, while being nearly 10 times smaller in size. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 17:58:49 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 07:15:26 GMT'}]",2023-05-25,"[['Wu', 'Minghao', ''], ['Waheed', 'Abdul', ''], ['Zhang', 'Chiyu', ''], ['Abdul-Mageed', 'Muhammad', ''], ['Aji', 'Alham Fikri', '']]",0,1,2023-04-27,2,5,1,1,0,1,389ec3e8902a5dcfcde1adec735854e93f845937,258352678.0,https://www.semanticscholar.org/paper/389ec3e8902a5dcfcde1adec735854e93f845937,arXiv.org,2023.0,63.0,30.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2145209409', 'name': 'Minghao Wu'}, {'authorId': '2215440985', 'name': 'Abdul Waheed'}, {'authorId': '50445559', 'name': 'Chiyu Zhang'}, {'authorId': '2065312024', 'name': 'M. Abdul-Mageed'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}]","['Monash University', 'University of British Columbia', 'Mohamed bin Zayed University of Artificial Intelligence']","['Canada', 'United Arab Emirates', 'Australia']",2023-04
2304.14721,Yuchen Xia,"Yuchen Xia, Manthan Shenoy, Nasser Jazdi, Michael Weyrich",Towards autonomous system: flexible modular production system enhanced with large language model agents,"This is the pre-print draft manuscript. The peer-reviewed version
  will be published exclusively by IEEE after the conference, which is set to
  take place from September 12th to 15th, 2023. We've made several improvements
  to the final version of the paper based on valuable feedback and suggestions
  from other researchers",,,,cs.RO cs.CL cs.SE cs.SY eess.SY,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present a novel framework that combines large language models (LLMs), digital twins and industrial automation system to enable intelligent planning and control of production processes. We retrofit the automation system for a modular production facility and create executable control interfaces of fine-granular functionalities and coarse-granular skills. Low-level functionalities are executed by automation components, and high-level skills are performed by automation modules. Subsequently, a digital twin system is developed, registering these interfaces and containing additional descriptive information about the production system. Based on the retrofitted automation system and the created digital twins, LLM-agents are designed to interpret descriptive information in the digital twins and control the physical system through service interfaces. These LLM-agents serve as intelligent agents on different levels within an automation system, enabling autonomous planning and control of flexible production. Given a task instruction as input, the LLM-agents orchestrate a sequence of atomic functionalities and skills to accomplish the task. We demonstrate how our implemented prototype can handle un-predefined tasks, plan a production process, and execute the operations. This research highlights the potential of integrating LLMs into industrial automation systems in the context of smart factory for more agile, flexible, and adaptive production processes, while it also underscores the critical insights and limitations for future work. Demos at: https://github.com/YuchenXia/GPT4IndustrialAutomation ","[{'version': 'v1', 'created': 'Fri, 28 Apr 2023 09:42:18 GMT'}, {'version': 'v2', 'created': 'Mon, 1 May 2023 10:48:04 GMT'}, {'version': 'v3', 'created': 'Tue, 2 May 2023 16:23:13 GMT'}, {'version': 'v4', 'created': 'Mon, 24 Jul 2023 09:49:55 GMT'}]",2023-07-25,"[['Xia', 'Yuchen', ''], ['Shenoy', 'Manthan', ''], ['Jazdi', 'Nasser', ''], ['Weyrich', 'Michael', '']]",0,1,2023-04-28,4,4,5,0,0,0,901f8bc72261a278eda91a2dcf609a21bba2666e,258417925.0,https://www.semanticscholar.org/paper/901f8bc72261a278eda91a2dcf609a21bba2666e,IEEE International Conference on Emerging Technologies and Factory Automation,2023.0,24.0,2.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '152428280', 'name': 'Yuchen Xia'}, {'authorId': '2070664310', 'name': 'Manthan Shenoy'}, {'authorId': '2509708', 'name': 'N. Jazdi'}, {'authorId': '2273478', 'name': 'M. Weyrich'}]",['University of Stuttgart'],['Germany'],2023-04
2304.14746,Siamak Layeghy,"Liam Daly Manocchio, Siamak Layeghy, Wai Weng Lo, Gayan K.
  Kulatilleke, Mohanad Sarhan, Marius Portmann",FlowTransformer: A Transformer Framework for Flow-based Network Intrusion Detection Systems,,,,,cs.CR cs.AI cs.CL cs.NE cs.NI,http://creativecommons.org/licenses/by/4.0/,"  This paper presents the FlowTransformer framework, a novel approach for implementing transformer-based Network Intrusion Detection Systems (NIDSs). FlowTransformer leverages the strengths of transformer models in identifying the long-term behaviour and characteristics of networks, which are often overlooked by most existing NIDSs. By capturing these complex patterns in network traffic, FlowTransformer offers a flexible and efficient tool for researchers and practitioners in the cybersecurity community who are seeking to implement NIDSs using transformer-based models. FlowTransformer allows the direct substitution of various transformer components, including the input encoding, transformer, classification head, and the evaluation of these across any flow-based network dataset. To demonstrate the effectiveness and efficiency of the FlowTransformer framework, we utilise it to provide an extensive evaluation of various common transformer architectures, such as GPT 2.0 and BERT, on three commonly used public NIDS benchmark datasets. We provide results for accuracy, model size and speed. A key finding of our evaluation is that the choice of classification head has the most significant impact on the model performance. Surprisingly, Global Average Pooling, which is commonly used in text classification, performs very poorly in the context of NIDS. In addition, we show that model size can be reduced by over 50\%, and inference and training times improved, with no loss of accuracy, by making specific choices of input encoding and classification head instead of other commonly used alternatives. ","[{'version': 'v1', 'created': 'Fri, 28 Apr 2023 10:40:34 GMT'}]",2023-05-01,"[['Manocchio', 'Liam Daly', ''], ['Layeghy', 'Siamak', ''], ['Lo', 'Wai Weng', ''], ['Kulatilleke', 'Gayan K.', ''], ['Sarhan', 'Mohanad', ''], ['Portmann', 'Marius', '']]",0,1,2023-04-28,1,6,5,1,1,0,b910926526014a62a54fdb0d3fbe98377079ac80,258418307.0,https://www.semanticscholar.org/paper/b910926526014a62a54fdb0d3fbe98377079ac80,arXiv.org,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2158180036', 'name': 'Liam Daly Manocchio'}, {'authorId': '3242014', 'name': 'S. Layeghy'}, {'authorId': '151253960', 'name': 'Wai Weng Lo'}, {'authorId': '1572525032', 'name': 'Gayan K. Kulatilleke'}, {'authorId': '2026368688', 'name': 'Mohanad Sarhan'}, {'authorId': '2105726298', 'name': 'Marius Portmann'}]",['University of Queensland'],['Australia'],2023-04
2304.14844,Miguel \'A. Gonz\'alez-Santamarta,"Miguel A. Gonz\'alez-Santamarta, Laura Fern\'andez-Becerra, David
  Sobr\'in-Hidalgo, \'Angel Manuel Guerrero-Higueras, Irene Gonz\'alez,
  Francisco J. Rodr\'iguez Lera",Using Large Language Models for Interpreting Autonomous Robots Behaviors,,,10.1007/978-3-031-40725-3_45,,cs.RO,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The deployment of autonomous robots in various domains has raised significant concerns about their trustworthiness and accountability. This study explores the potential of Large Language Models (LLMs) in analyzing ROS 2 logs generated by autonomous robots and proposes a framework for log analysis that categorizes log files into different aspects. The study evaluates the performance of three different language models in answering questions related to StartUp, Warning, and PDDL logs. The results suggest that GPT 4, a transformer-based model, outperforms other models, however, their verbosity is not enough to answer why or how questions for all kinds of actors involved in the interaction. ","[{'version': 'v1', 'created': 'Fri, 28 Apr 2023 13:33:47 GMT'}]",2023-09-27,"[['González-Santamarta', 'Miguel A.', ''], ['Fernández-Becerra', 'Laura', ''], ['Sobrín-Hidalgo', 'David', ''], ['Guerrero-Higueras', 'Ángel Manuel', ''], ['González', 'Irene', ''], ['Lera', 'Francisco J. Rodríguez', '']]",0,1,2023-04-28,1,6,1,1,0,1,049af20e556a81ea56755c7f893340336aca3088,258418212.0,https://www.semanticscholar.org/paper/049af20e556a81ea56755c7f893340336aca3088,Hybrid Artificial Intelligence Systems,2023.0,27.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2003275049', 'name': 'Miguel Ángel González Santamarta'}, {'authorId': '2003195124', 'name': 'Laura Fernández-Becerra'}, {'authorId': '2215807275', 'name': 'David Sobrín-Hidalgo'}, {'authorId': '2810240', 'name': 'Ángel Manuel Guerrero Higueras'}, {'authorId': '2215816892', 'name': ""Irene Gonz'alez""}, {'authorId': '2058565950', 'name': 'F. J. R. Lera'}]","['University of Leon', 'King Juan Carlos University']",['Spain'],2023-04
2304.14993,Dhruv Kumar,"Ishika Joshi, Ritvik Budhiraja, Harshal Dev, Jahnvi Kadia, M. Osama
  Ataullah, Sayan Mitra, Dhruv Kumar, Harshal D. Akolekar",ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions,Accepted in SIGCSE TS 2024,,,,cs.HC cs.AI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT is an AI language model developed by OpenAI that can understand and generate human-like text. It can be used for a variety of use cases such as language generation, question answering, text summarization, chatbot development, language translation, sentiment analysis, content creation, personalization, text completion, and storytelling. While ChatGPT has garnered significant positive attention, it has also generated a sense of apprehension and uncertainty in academic circles. There is concern that students may leverage ChatGPT to complete take-home assignments and exams and obtain favorable grades without genuinely acquiring knowledge. This paper adopts a quantitative approach to demonstrate ChatGPT's high degree of unreliability in answering a diverse range of questions pertaining to topics in undergraduate computer science. Our analysis shows that students may risk self-sabotage by blindly depending on ChatGPT to complete assignments and exams. We build upon this analysis to provide constructive recommendations to both students and instructors. ","[{'version': 'v1', 'created': 'Fri, 28 Apr 2023 17:26:32 GMT'}, {'version': 'v2', 'created': 'Wed, 17 May 2023 14:44:32 GMT'}, {'version': 'v3', 'created': 'Thu, 5 Oct 2023 04:18:28 GMT'}]",2023-10-06,"[['Joshi', 'Ishika', ''], ['Budhiraja', 'Ritvik', ''], ['Dev', 'Harshal', ''], ['Kadia', 'Jahnvi', ''], ['Ataullah', 'M. Osama', ''], ['Mitra', 'Sayan', ''], ['Kumar', 'Dhruv', ''], ['Akolekar', 'Harshal D.', '']]",1,1,2023-04-28,3,8,3,1,0,1,08f785f5af169df7f1eaa6a5a827bfa68eec8881,258417916.0,https://www.semanticscholar.org/paper/08f785f5af169df7f1eaa6a5a827bfa68eec8881,,2023.0,31.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2160802763', 'name': 'Ishika Joshi'}, {'authorId': '2215768024', 'name': 'Ritvik Budhiraja'}, {'authorId': '2215768147', 'name': 'Harshal Dev'}, {'authorId': '2215768020', 'name': 'Jahnvi Kadia'}, {'authorId': '2215768088', 'name': 'M. O. Ataullah'}, {'authorId': '33782901', 'name': 'S. Mitra'}, {'authorId': '50271213', 'name': 'Dhruv Kumar'}, {'authorId': '102776796', 'name': 'Harshal D. Akolekar'}]","['Indian Institute of Technology Delhi', 'Indian Institute of Technology Jodhpur']",['India'],2023-04
2305.00237,Mohammad Fraiwan,Mohammad Fraiwan and Natheer Khasawneh,"A Review of ChatGPT Applications in Education, Marketing, Software Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions",,,,,cs.CY cs.AI,http://creativecommons.org/licenses/by/4.0/,"  ChatGPT is a type of artificial intelligence language model that uses deep learning algorithms to generate human-like responses to text-based prompts. The introduction of the latest ChatGPT version in November of 2022 has caused shockwaves in the industrial and academic communities for its powerful capabilities, plethora of possible applications, and the great possibility for abuse. At the time of writing this work, several other language models (e.g., Google Bard and Meta LLaMA) just came out in an attempt to get a foothold in the vast possible market. These models have the ability to revolutionize the way we interact with computers and have potential applications in many fields, including education, software engineering, healthcare, and marketing. In this paper, we will discuss the possible applications, drawbacks, and research directions using advanced language Chatbots (e.g., ChatGPT) in each of these fields. We first start with a brief introduction and the development timeline of artificial intelligence based language models, then we go through possible applications of such models, after that we discuss the limitations and drawbacks of the current technological state of the art, and finally we point out future possible research directions. ","[{'version': 'v1', 'created': 'Sat, 29 Apr 2023 11:25:43 GMT'}]",2023-05-02,"[['Fraiwan', 'Mohammad', ''], ['Khasawneh', 'Natheer', '']]",1,1,2023-04-29,1,2,2,2,1,1,a0dca1c35f698b7b7af91449427ed035d9e4e049,258426630.0,https://www.semanticscholar.org/paper/a0dca1c35f698b7b7af91449427ed035d9e4e049,arXiv.org,2023.0,66.0,11.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145874705', 'name': 'M. Fraiwan'}, {'authorId': '47343240', 'name': 'N. Khasawneh'}]",['Jordan University of Science and Technology'],['Jordan'],2023-04
2305.00821,Yun-Cheng Tsai,Yun-Cheng Tsai,Empowering Learner-Centered Instruction: Integrating ChatGPT Python API and Tinker Learning for Enhanced Creativity and Problem-Solving Skills,"10 pages, 4 figures, 1 table",,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  The ChatGPT Python API plays a crucial role in promoting Learner-Centered Instruction (LCI) and aligns with the principles of Tinker Learning, allowing students to discover their learning strategies. LCI emphasizes the importance of active, hands-on learning experiences and encourages students to take responsibility for their learning journey. By integrating the ChatGPT Python API into the educational process, students can explore various resources, generate new ideas, and create content in a more personalized manner. This innovative approach enables students to engage with the learning material deeper, fostering a sense of ownership and motivation. As they work through the Creative Learning Spiral, students develop essential skills such as critical thinking, problem-solving, and creativity. The ChatGPT Python API is a valuable tool for students to explore different solutions, evaluate alternatives, and make informed decisions, all while encouraging self-directed learning. In Tinker Learning environments, the integration of ChatGPT Python API empowers students to experiment and iterate, allowing them to find the most effective learning strategies that cater to their individual needs and preferences. This personalized approach helps students to become more confident in their abilities, leading to tremendous academic success and long-term skill development. By leveraging the capabilities of the ChatGPT Python API, educational institutions can create a more engaging, supportive, and dynamic learning environment. This approach aligns with the principles of Learner-Centered Instruction and Tinker Learning, promoting a culture of curiosity, exploration, and creativity among students while preparing them for the challenges of the fast-paced, ever-changing world. ","[{'version': 'v1', 'created': 'Mon, 1 May 2023 13:40:25 GMT'}]",2023-05-02,"[['Tsai', 'Yun-Cheng', '']]",1,1,2023-05-01,1,1,1,1,0,1,19af4f8a5f65aa290f571ef2867adee1f6dcabec,258427044.0,https://www.semanticscholar.org/paper/19af4f8a5f65aa290f571ef2867adee1f6dcabec,International Conference on Innovative Technologies and Learning,2023.0,32.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '3130078', 'name': 'Yun-Cheng Tsai'}]",['National Taiwan Normal University'],['Taiwan'],2023-05
2305.00844,Edward Guo,"Eddie Guo, Mehul Gupta, Jiawen Deng, Ye-Jean Park, Mike Paget,
  Christopher Naugler",Automated Paper Screening for Clinical Reviews Using Large Language Models,"15 pages, 2 figures, 4 tables",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Objective: To assess the performance of the OpenAI GPT API in accurately and efficiently identifying relevant titles and abstracts from real-world clinical review datasets and compare its performance against ground truth labelling by two independent human reviewers.   Methods: We introduce a novel workflow using the OpenAI GPT API for screening titles and abstracts in clinical reviews. A Python script was created to make calls to the GPT API with the screening criteria in natural language and a corpus of title and abstract datasets that have been filtered by a minimum of two human reviewers. We compared the performance of our model against human-reviewed papers across six review papers, screening over 24,000 titles and abstracts.   Results: Our results show an accuracy of 0.91, a sensitivity of excluded papers of 0.91, and a sensitivity of included papers of 0.76. On a randomly selected subset of papers, the GPT API demonstrated the ability to provide reasoning for its decisions and corrected its initial decision upon being asked to explain its reasoning for a subset of incorrect classifications.   Conclusion: The GPT API has the potential to streamline the clinical review process, save valuable time and effort for researchers, and contribute to the overall quality of clinical reviews. By prioritizing the workflow and acting as an aid rather than a replacement for researchers and reviewers, the GPT API can enhance efficiency and lead to more accurate and reliable conclusions in medical research. ","[{'version': 'v1', 'created': 'Mon, 1 May 2023 14:16:37 GMT'}]",2023-05-02,"[['Guo', 'Eddie', ''], ['Gupta', 'Mehul', ''], ['Deng', 'Jiawen', ''], ['Park', 'Ye-Jean', ''], ['Paget', 'Mike', ''], ['Naugler', 'Christopher', '']]",0,1,2023-05-01,1,6,2,0,0,0,cccb129527fbe900c6f94dd8a6ad4b408c403152,258427030.0,https://www.semanticscholar.org/paper/cccb129527fbe900c6f94dd8a6ad4b408c403152,Journal of Medical Internet Research,2023.0,32.0,3.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '2149641998', 'name': 'Eddie Guo'}, {'authorId': '51896371', 'name': 'Mehul Gupta'}, {'authorId': '2090444914', 'name': 'Jiawen Deng'}, {'authorId': '2199809137', 'name': 'Ye-Jean Park'}, {'authorId': '40530542', 'name': 'M. Paget'}, {'authorId': '1801698', 'name': 'C. Naugler'}]","['University of Toronto', 'University of Calgary', '3330 Hospital Dr NW, Calgary, AB, Canada T2N 4N1']",['Canada'],2023-05
2305.00905,Maniraman Periyasamy,"Maniraman Periyasamy and Marc H\""olle and Marco Wiedmann and Daniel D.
  Scherer and Axel Plinge and Christopher Mutschler",Batch Quantum Reinforcement Learning,,,,,quant-ph cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Training DRL agents is often a time-consuming process as a large number of samples and environment interactions is required. This effect is even amplified in the case of Batch RL, where the agent is trained without environment interactions solely based on a set of previously collected data. Novel approaches based on quantum computing suggest an advantage compared to classical approaches in terms of sample efficiency. To investigate this advantage, we propose a batch RL algorithm leveraging VQC as function approximators in the discrete BCQ algorithm. Additionally, we present a novel data re-uploading scheme based on cyclically shifting the input variables' order in the data encoding layers. We show the efficiency of our algorithm on the OpenAI CartPole environment and compare its performance to classical neural network-based discrete BCQ. ","[{'version': 'v1', 'created': 'Thu, 27 Apr 2023 16:43:01 GMT'}]",2023-05-02,"[['Periyasamy', 'Maniraman', ''], ['Hölle', 'Marc', ''], ['Wiedmann', 'Marco', ''], ['Scherer', 'Daniel D.', ''], ['Plinge', 'Axel', ''], ['Mutschler', 'Christopher', '']]",0,0,2023-04-27,1,6,2,0,0,0,50f0168cf8b0a48094976142dfc346baef3dbd39,258426588.0,https://www.semanticscholar.org/paper/50f0168cf8b0a48094976142dfc346baef3dbd39,arXiv.org,2023.0,44.0,1.0,0.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152740023', 'name': 'Maniraman Periyasamy'}, {'authorId': '2216332592', 'name': 'Marc Hölle'}, {'authorId': '2130089840', 'name': 'Marco Wiedmann'}, {'authorId': '145134906', 'name': 'D. D. Scherer'}, {'authorId': '2556699', 'name': 'A. Plinge'}, {'authorId': '3058617', 'name': 'Christopher Mutschler'}]",['Fraunhofer Institute for Integrated Circuits'],['Germany'],2023-04
2305.01505,Guijin Son,"Guijin Son, Hanearl Jung, Moonjeong Hahm, Keonju Na, Sol Jin",Beyond Classification: Financial Reasoning in State-of-the-Art Language Models,"Accepted by FinNLP (Financial Technology and Natural Language
  Processing) @ IJCAI2023 as long paper",,,,cs.CL cs.AI cs.CY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large Language Models (LLMs), consisting of 100 billion or more parameters, have demonstrated remarkable ability in complex multi-step reasoning tasks. However, the application of such generic advancements has been limited to a few fields, such as clinical or legal, with the field of financial reasoning remaining largely unexplored. To the best of our knowledge, the ability of LLMs to solve financial reasoning problems has never been dealt with, and whether it can be performed at any scale remains unknown. To address this knowledge gap, this research presents a comprehensive investigation into the potential application of LLMs in the financial domain. The investigation includes a detailed exploration of a range of subjects, including task formulation, synthetic data generation, prompting methods, and evaluation capability. Furthermore, the study benchmarks various GPT variants with parameter scales ranging from 2.8B to 13B, with and without instruction tuning, on diverse dataset sizes. By analyzing the results, we reveal that the ability to generate coherent financial reasoning first emerges at 6B parameters, and continues to improve with better instruction-tuning or larger datasets. Additionally, the study provides a publicly accessible dataset named sFIOG (Synthetic-Financial Investment Opinion Generation), consisting of 11,802 synthetic investment thesis samples, to support further research in the field of financial reasoning. Overall, this research seeks to contribute to the understanding of the efficacy of language models in the field of finance, with a particular emphasis on their ability to engage in sophisticated reasoning and analysis within the context of investment decision-making. ","[{'version': 'v1', 'created': 'Sun, 30 Apr 2023 04:36:05 GMT'}, {'version': 'v2', 'created': 'Sun, 25 Jun 2023 18:06:25 GMT'}]",2023-06-27,"[['Son', 'Guijin', ''], ['Jung', 'Hanearl', ''], ['Hahm', 'Moonjeong', ''], ['Na', 'Keonju', ''], ['Jin', 'Sol', '']]",0,1,2023-04-30,2,5,3,0,0,0,ead8e62b819d5da97786e9905563c427bba5e29d,258437058.0,https://www.semanticscholar.org/paper/ead8e62b819d5da97786e9905563c427bba5e29d,FINNLP,2023.0,55.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146377319', 'name': 'Guijin Son'}, {'authorId': '69531018', 'name': 'Han-Na Jung'}, {'authorId': '10167560', 'name': 'M. Hahm'}, {'authorId': '2215862495', 'name': 'Keonju Na'}, {'authorId': '2111117441', 'name': 'Sol Jin'}]","['Seoul National University of Science and Technology', 'Seoul National University', 'Yonsei University', 'Chung-Ang University']",['South Korea'],2023-04
2305.01547,Kazuki Irie,"Kazuki Irie and J\""urgen Schmidhuber",Accelerating Neural Self-Improvement via Bootstrapping,"Presented at ICLR 2023 Workshop on Mathematical and Empirical
  Understanding of Foundation Models,
  https://openreview.net/forum?id=SDwUYcyOCyP",,,,cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Few-shot learning with sequence-processing neural networks (NNs) has recently attracted a new wave of attention in the context of large language models. In the standard N-way K-shot learning setting, an NN is explicitly optimised to learn to classify unlabelled inputs by observing a sequence of NK labelled examples. This pressures the NN to learn a learning algorithm that achieves optimal performance, given the limited number of training examples. Here we study an auxiliary loss that encourages further acceleration of few-shot learning, by applying recently proposed bootstrapped meta-learning to NN few-shot learners: we optimise the K-shot learner to match its own performance achievable by observing more than NK examples, using only NK examples. Promising results are obtained on the standard Mini-ImageNet dataset. Our code is public. ","[{'version': 'v1', 'created': 'Tue, 2 May 2023 15:52:34 GMT'}]",2023-05-03,"[['Irie', 'Kazuki', ''], ['Schmidhuber', 'Jürgen', '']]",0,0,2023-05-02,1,2,1,0,0,0,847e5a8df8c08cc26165b57966a7cf59ee032a4e,259300767.0,https://www.semanticscholar.org/paper/847e5a8df8c08cc26165b57966a7cf59ee032a4e,arXiv.org,2023.0,42.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2350348', 'name': 'Kazuki Irie'}, {'authorId': '145341374', 'name': 'J. Schmidhuber'}]","['Dalle Molle Institute for Artificial Intelligence Research', 'King Abdullah University of Science and Technology']","['Saudi Arabia', 'Switzerland']",2023-05
2305.01713,Yingji Zhang,"Yingji Zhang, Danilo S. Carvalho, Ian Pratt-Hartmann, Andr\'e Freitas",Learning Disentangled Semantic Spaces of Explanations via Invertible Neural Networks,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Disentangling sentence representations over continuous spaces can be a critical process in improving interpretability and semantic control by localising explicit generative factors. Such process confers to neural-based language models some of the advantages that are characteristic of symbolic models, while keeping their flexibility. This work presents a methodology for disentangling the hidden space of a BERT-GPT2 autoencoder by transforming it into a more separable semantic space with the support of a flow-based invertible neural network (INN). Experimental results indicate that the INN can transform the distributed hidden space into a better semantically disentangled latent space, resulting in better interpretability and controllability, when compared to recent state-of-the-art models. ","[{'version': 'v1', 'created': 'Tue, 2 May 2023 18:27:13 GMT'}]",2023-05-04,"[['Zhang', 'Yingji', ''], ['Carvalho', 'Danilo S.', ''], ['Pratt-Hartmann', 'Ian', ''], ['Freitas', 'André', '']]",0,1,2023-05-02,1,4,2,1,1,0,4ff756807bf2011342e5909d3bc3744031025b9e,258461435.0,https://www.semanticscholar.org/paper/4ff756807bf2011342e5909d3bc3744031025b9e,arXiv.org,2023.0,25.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108307966', 'name': 'Yingji Zhang'}, {'authorId': '38424153', 'name': 'Danilo S. Carvalho'}, {'authorId': '1400949657', 'name': 'Ian Pratt-Hartmann'}, {'authorId': '2146499832', 'name': 'André Freitas'}]","['University of Manchester', 'Idiap Research Institute']","['United Kingdom', 'Switzerland']",2023-05
2305.01901,Yubo Ma,"Yubo Ma, Zehao Wang, Yixin Cao and Aixin Sun",Few-shot Event Detection: An Empirical Study and a Unified View,Accepted by ACL 2023 main conference,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Few-shot event detection (ED) has been widely studied, while this brings noticeable discrepancies, e.g., various motivations, tasks, and experimental settings, that hinder the understanding of models for future progress.This paper presents a thorough empirical study, a unified view of ED models, and a better unified baseline. For fair evaluation, we compare 12 representative methods on three datasets, which are roughly grouped into prompt-based and prototype-based models for detailed analysis. Experiments consistently demonstrate that prompt-based methods, including ChatGPT, still significantly trail prototype-based methods in terms of overall performance. To investigate their superior performance, we break down their design elements along several dimensions and build a unified framework on prototype-based methods. Under such unified view, each prototype-method can be viewed a combination of different modules from these design elements. We further combine all advantageous modules and propose a simple yet effective baseline, which outperforms existing methods by a large margin (e.g., 2.7% F1 gains under low-resource setting). ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 05:31:48 GMT'}, {'version': 'v2', 'created': 'Thu, 25 May 2023 11:50:30 GMT'}]",2023-05-26,"[['Ma', 'Yubo', ''], ['Wang', 'Zehao', ''], ['Cao', 'Yixin', ''], ['Sun', 'Aixin', '']]",1,1,2023-05-03,2,4,2,1,0,1,ac7e270fcd365c84b29a710d58bf1243e850df4c,253082873.0,https://www.semanticscholar.org/paper/ac7e270fcd365c84b29a710d58bf1243e850df4c,Annual Meeting of the Association for Computational Linguistics,2023.0,97.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143557418', 'name': 'Yubo Ma'}, {'authorId': '2118402851', 'name': 'Zehao Wang'}, {'authorId': '145014675', 'name': 'Yixin Cao'}, {'authorId': '1735962', 'name': 'Aixin Sun'}]","['Nanyang Technological University', 'Singapore Management University']",['Singapore'],2023-05
2305.01904,KiYoon Yoo,"KiYoon Yoo, Wonhyuk Ahn, Jiho Jang, Nojun Kwak",Robust Multi-bit Natural Language Watermarking through Invariant Features,ACL 2023 long,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Recent years have witnessed a proliferation of valuable original natural language contents found in subscription-based media outlets, web novel platforms, and outputs of large language models. However, these contents are susceptible to illegal piracy and potential misuse without proper security measures. This calls for a secure watermarking system to guarantee copyright protection through leakage tracing or ownership identification. To effectively combat piracy and protect copyrights, a multi-bit watermarking framework should be able to embed adequate bits of information and extract the watermarks in a robust manner despite possible corruption. In this work, we explore ways to advance both payload and robustness by following a well-known proposition from image watermarking and identify features in natural language that are invariant to minor corruption. Through a systematic analysis of the possible sources of errors, we further propose a corruption-resistant infill model. Our full method improves upon the previous work on robustness by +16.8% point on average on four datasets, three corruption types, and two corruption ratios. Code available at https://github.com/bangawayoo/nlp-watermarking. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 05:37:30 GMT'}, {'version': 'v2', 'created': 'Fri, 9 Jun 2023 07:17:14 GMT'}]",2023-06-12,"[['Yoo', 'KiYoon', ''], ['Ahn', 'Wonhyuk', ''], ['Jang', 'Jiho', ''], ['Kwak', 'Nojun', '']]",0,0,2023-05-03,2,4,2,0,0,0,753dd1be7581e70d65b537e8f62140b8ff8793ac,259129912.0,https://www.semanticscholar.org/paper/753dd1be7581e70d65b537e8f62140b8ff8793ac,Annual Meeting of the Association for Computational Linguistics,2023.0,55.0,15.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1713608836', 'name': 'Kiyoon Yoo'}, {'authorId': '83148084', 'name': 'W. Ahn'}, {'authorId': '2109878510', 'name': 'Jiho Jang'}, {'authorId': '101880623', 'name': 'N. Kwak'}]",['Seoul National University'],['South Korea'],2023-05
2305.01937,Cheng-Han Chiang,Cheng-Han Chiang and Hung-yi Lee,Can Large Language Models Be an Alternative to Human Evaluations?,"ACL 2023 main conference paper. Main content: 10 pages (including
  limitations). Appendix: 13 pages",,,,cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Human evaluation is indispensable and inevitable for assessing the quality of texts generated by machine learning models or written by humans. However, human evaluation is very difficult to reproduce and its quality is notoriously unstable, hindering fair comparisons among different natural language processing (NLP) models and algorithms. Recently, large language models (LLMs) have demonstrated exceptional performance on unseen tasks when only the task instructions are provided. In this paper, we explore if such an ability of the LLMs can be used as an alternative to human evaluation. We present the LLMs with the exact same instructions, samples to be evaluated, and questions used to conduct human evaluation, and then ask the LLMs to generate responses to those questions; we dub this LLM evaluation. We use human evaluation and LLM evaluation to evaluate the texts in two NLP tasks: open-ended story generation and adversarial attacks. We show that the result of LLM evaluation is consistent with the results obtained by expert human evaluation: the texts rated higher by human experts are also rated higher by the LLMs. We also find that the results of LLM evaluation are stable over different formatting of the task instructions and the sampling algorithm used to generate the answer. We are the first to show the potential of using LLMs to assess the quality of texts and discuss the limitations and ethical considerations of LLM evaluation. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 07:28:50 GMT'}]",2023-05-04,"[['Chiang', 'Cheng-Han', ''], ['Lee', 'Hung-yi', '']]",0,0,2023-05-03,1,2,2,0,0,0,03055978e278960de9fbb5c648b1779ef9f26cd1,258461287.0,https://www.semanticscholar.org/paper/03055978e278960de9fbb5c648b1779ef9f26cd1,Annual Meeting of the Association for Computational Linguistics,2023.0,55.0,73.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1992777064', 'name': 'Cheng-Han Chiang'}, {'authorId': '1706104', 'name': 'Hung-yi Lee'}]",['National Taiwan University'],['Taiwan'],2023-05
2305.01941,Noelia Ferruz,"Sergio Romero-Romero, Sebastian Lindner, Noelia Ferruz",Exploring the Protein Sequence Space with Global Generative Models,"16 pages, 4 figures, 2 tables",,,,q-bio.BM cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Recent advancements in specialized large-scale architectures for training image and language have profoundly impacted the field of computer vision and natural language processing (NLP). Language models, such as the recent ChatGPT and GPT4 have demonstrated exceptional capabilities in processing, translating, and generating human languages. These breakthroughs have also been reflected in protein research, leading to the rapid development of numerous new methods in a short time, with unprecedented performance. Language models, in particular, have seen widespread use in protein research, as they have been utilized to embed proteins, generate novel ones, and predict tertiary structures. In this book chapter, we provide an overview of the use of protein generative models, reviewing 1) language models for the design of novel artificial proteins, 2) works that use non-Transformer architectures, and 3) applications in directed evolution approaches. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 07:45:29 GMT'}]",2023-05-04,"[['Romero-Romero', 'Sergio', ''], ['Lindner', 'Sebastian', ''], ['Ferruz', 'Noelia', '']]",1,1,2023-05-03,1,3,2,2,0,2,adee59f22ca43dbab2f646ca509565b78f7e2c06,258461497.0,https://www.semanticscholar.org/paper/adee59f22ca43dbab2f646ca509565b78f7e2c06,Cold Spring Harbor Perspectives in Biology,2023.0,84.0,1.0,0.0,True,"['Computer Science', 'Medicine', 'Biology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1384379337', 'name': 'S. Romero-Romero'}, {'authorId': '2950396', 'name': 'Sebastian Lindner'}, {'authorId': '2810622', 'name': 'Noelia Ferruz'}]","['University of Bayreuth', 'Heidelberg University', 'Institut de Biologia Molecular de Barcelona']","['Germany', 'Spain']",2023-05
2305.02031,Nitay Calderon,"Nitay Calderon, Subhabrata Mukherjee, Roi Reichart and Amir Kantor",A Systematic Study of Knowledge Distillation for Natural Language Generation with Pseudo-Target Training,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Modern Natural Language Generation (NLG) models come with massive computational and storage requirements. In this work, we study the potential of compressing them, which is crucial for real-world applications serving millions of users. We focus on Knowledge Distillation (KD) techniques, in which a small student model learns to imitate a large teacher model, allowing to transfer knowledge from the teacher to the student. In contrast to much of the previous work, our goal is to optimize the model for a specific NLG task and a specific dataset. Typically in real-world applications, in addition to labeled data there is abundant unlabeled task-specific data, which is crucial for attaining high compression rates via KD. In this work, we conduct a systematic study of task-specific KD techniques for various NLG tasks under realistic assumptions. We discuss the special characteristics of NLG distillation and particularly the exposure bias problem. Following, we derive a family of Pseudo-Target (PT) augmentation methods, substantially extending prior work on sequence-level KD. We propose the Joint-Teaching method, which applies word-level KD to multiple PTs generated by both the teacher and the student. Finally, we validate our findings in an extreme setup with no labeled examples using GPT-4 as the teacher. Our study provides practical model design observations and demonstrates the effectiveness of PT training for task-specific KD in NLG. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 10:49:38 GMT'}, {'version': 'v2', 'created': 'Fri, 26 May 2023 11:11:11 GMT'}]",2023-05-29,"[['Calderon', 'Nitay', ''], ['Mukherjee', 'Subhabrata', ''], ['Reichart', 'Roi', ''], ['Kantor', 'Amir', '']]",0,1,2023-05-03,2,4,2,1,0,1,91b95b98cc1a7e974e62d0b8295d3b974b94aa0e,258461336.0,https://www.semanticscholar.org/paper/91b95b98cc1a7e974e62d0b8295d3b974b94aa0e,Annual Meeting of the Association for Computational Linguistics,2023.0,85.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2135910736', 'name': 'Nitay Calderon'}, {'authorId': '2153292652', 'name': 'Subhabrata Mukherjee'}, {'authorId': '1762757', 'name': 'Roi Reichart'}, {'authorId': '1703796', 'name': 'Amir Kantor'}]","['Technion – Israel Institute of Technology', 'Microsoft']","['India', 'Israel']",2023-05
2305.02151,Fred Philippy,"Fred Philippy, Siwen Guo, Shohreh Haddadan",Identifying the Correlation Between Language Distance and Cross-Lingual Transfer in a Multilingual Representation Space,"The paper was accepted at the SIGTYP workshop 2023 (co-located with
  EACL)",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Prior research has investigated the impact of various linguistic features on cross-lingual transfer performance. In this study, we investigate the manner in which this effect can be mapped onto the representation space. While past studies have focused on the impact on cross-lingual alignment in multilingual language models during fine-tuning, this study examines the absolute evolution of the respective language representation spaces produced by MLLMs. We place a specific emphasis on the role of linguistic characteristics and investigate their inter-correlation with the impact on representation spaces and cross-lingual transfer performance. Additionally, this paper provides preliminary evidence of how these findings can be leveraged to enhance transfer to linguistically distant languages. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 14:33:23 GMT'}]",2023-05-04,"[['Philippy', 'Fred', ''], ['Guo', 'Siwen', ''], ['Haddadan', 'Shohreh', '']]",0,0,2023-05-03,1,3,3,0,0,0,ae6359e1738bb00a0fc29beb7da5b856a3ca39fe,258461441.0,https://www.semanticscholar.org/paper/ae6359e1738bb00a0fc29beb7da5b856a3ca39fe,SIGTYP,2023.0,32.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2089836413', 'name': 'Fred Philippy'}, {'authorId': '2110835464', 'name': 'Siwen Guo'}, {'authorId': '121857840', 'name': 'Shohreh Haddadan'}]","['University of Luxembourg', 'Zortify Labs, Zortify S.A. 19, rue du Laboratoire L-1911 Luxembourg']",['Luxembourg'],2023-05
2305.02156,Jimmy Lin,"Xueguang Ma, Xinyu Zhang, Ronak Pradeep, Jimmy Lin",Zero-Shot Listwise Document Reranking with a Large Language Model,,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Supervised ranking methods based on bi-encoder or cross-encoder architectures have shown success in multi-stage text ranking tasks, but they require large amounts of relevance judgments as training data. In this work, we propose Listwise Reranker with a Large Language Model (LRL), which achieves strong reranking effectiveness without using any task-specific training data. Different from the existing pointwise ranking methods, where documents are scored independently and ranked according to the scores, LRL directly generates a reordered list of document identifiers given the candidate documents. Experiments on three TREC web search datasets demonstrate that LRL not only outperforms zero-shot pointwise methods when reranking first-stage retrieval results, but can also act as a final-stage reranker to improve the top-ranked results of a pointwise method for improved efficiency. Additionally, we apply our approach to subsets of MIRACL, a recent multilingual retrieval dataset, with results showing its potential to generalize across different languages. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 14:45:34 GMT'}]",2023-05-04,"[['Ma', 'Xueguang', ''], ['Zhang', 'Xinyu', ''], ['Pradeep', 'Ronak', ''], ['Lin', 'Jimmy', '']]",0,0,2023-05-03,1,4,2,0,0,0,8be0ec99f80710887e3a8e6bac5fba51a8fd7186,258461030.0,https://www.semanticscholar.org/paper/8be0ec99f80710887e3a8e6bac5fba51a8fd7186,arXiv.org,2023.0,28.0,15.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2118895402', 'name': 'Xinyu Crystina Zhang'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '2154743364', 'name': 'Jimmy Lin'}]",['University of Waterloo'],['Canada'],2023-05
2305.02198,Felix Dobslaw,"Felix Dobslaw, Peter Bergh",Experiences with Remote Examination Formats in Light of GPT-4,"9 pages, 3 figures, 1 table",,,,cs.CY cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sudden access to the rapidly improving large language model GPT by open-ai forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT v4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress. ","[{'version': 'v1', 'created': 'Mon, 27 Mar 2023 19:49:06 GMT'}]",2023-05-04,"[['Dobslaw', 'Felix', ''], ['Bergh', 'Peter', '']]",0,1,2023-03-27,1,2,2,1,0,1,d990e1e526dd28e8c911c52488c994ab26118548,258461094.0,https://www.semanticscholar.org/paper/d990e1e526dd28e8c911c52488c994ab26118548,European Conference of Software Engineering Education,2023.0,14.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","[{'authorId': '1814799', 'name': 'Felix Dobslaw'}, {'authorId': '77752763', 'name': 'P. Bergh'}]",['Mid Sweden University'],['Sweden'],2023-03
2305.02202,Renato P. dos Santos,Marco Antonio Rodrigues Vasconcelos and Renato P. dos Santos,Enhancing STEM Learning with ChatGPT and Bing Chat as Objects to Think With: A Case Study,,,10.29333/ejmste/13313,,cs.CY cs.HC,http://creativecommons.org/licenses/by-sa/4.0/,"  This study investigates the potential of ChatGPT and Bing Chat, advanced conversational AIs, as ""objects-to-think-with,"" resources that foster reflective and critical thinking, and concept comprehension in enhancing STEM education, using a constructionist theoretical framework. A single-case study methodology was used to analyse extensive interaction logs between students and both AI systems in simulated STEM learning experiences. The results highlight the ability of ChatGPT and Bing Chat to help learners develop reflective and critical thinking, creativity, problem-solving skills, and concept comprehension. However, integrating AIs with collaborative learning and other educational activities is crucial, as is addressing potential limitations like concerns about AI information accuracy and reliability of the AIs' information and diminished human interaction. The study concludes that ChatGPT and Bing Chat as objects-to-think-with offer promising avenues to revolutionise STEM education through a constructionist lens, fostering engagement in inclusive and accessible learning environments. ","[{'version': 'v1', 'created': 'Mon, 1 May 2023 12:20:18 GMT'}]",2023-06-14,"[['Vasconcelos', 'Marco Antonio Rodrigues', ''], ['Santos', 'Renato P. dos', '']]",1,1,2023-05-01,1,2,2,1,0,1,b1fc87ef398aab4c649bd93fcfd9d746c66370bf,258461598.0,https://www.semanticscholar.org/paper/b1fc87ef398aab4c649bd93fcfd9d746c66370bf,Social Science Research Network,2023.0,38.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2215957944', 'name': 'Marco Antonio Rodrigues Vasconcelos'}, {'authorId': '143749184', 'name': 'R. P. D. Santos'}]",['Universidade Luterana do Brasil'],['Brazil'],2023-05
2305.02558,Sankalok Sen,Sankalok Sen,Analyzing Hong Kong's Legal Judgments from a Computational Linguistics point-of-view,"31 pages, 14 figures, 10 tables",,,,cs.CL cs.IR,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Analysis and extraction of useful information from legal judgments using computational linguistics was one of the earliest problems posed in the domain of information retrieval. Presently, several commercial vendors exist who automate such tasks. However, a crucial bottleneck arises in the form of exorbitant pricing and lack of resources available in analysis of judgements mete out by Hong Kong's Legal System. This paper attempts to bridge this gap by providing several statistical, machine learning, deep learning and zero-shot learning based methods to effectively analyze legal judgments from Hong Kong's Court System. The methods proposed consists of: (1) Citation Network Graph Generation, (2) PageRank Algorithm, (3) Keyword Analysis and Summarization, (4) Sentiment Polarity, and (5) Paragrah Classification, in order to be able to extract key insights from individual as well a group of judgments together. This would make the overall analysis of judgments in Hong Kong less tedious and more automated in order to extract insights quickly using fast inferencing. We also provide an analysis of our results by benchmarking our results using Large Language Models making robust use of the HuggingFace ecosystem. ","[{'version': 'v1', 'created': 'Thu, 4 May 2023 05:23:11 GMT'}]",2023-05-05,"[['Sen', 'Sankalok', '']]",0,0,2023-05-04,1,1,2,0,0,0,000b993633972b81453c47142e8d112be24c922e,258479918.0,https://www.semanticscholar.org/paper/000b993633972b81453c47142e8d112be24c922e,arXiv.org,2023.0,45.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Law', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2180774482', 'name': 'Sankalok Sen'}]",['University of Hong Kong'],['Hong Kong'],2023-05
2305.02897,Matthias Samwald,"Konstantin Hebenstreit, Robert Praas, Louis P Kiesewetter, Matthias
  Samwald",An automatically discovered chain-of-thought prompt generalizes to novel models and datasets,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Emergent chain-of-thought (CoT) reasoning capabilities promise to improve performance and explainability of large language models (LLMs). However, uncertainties remain about how reasoning strategies formulated for previous model generations generalize to new model generations and different datasets. In this small-scale study, we compare different reasoning strategies induced by zero-shot prompting across six recently released LLMs (davinci-002, davinci-003, GPT-3.5-turbo, GPT-4, Flan-T5-xxl and Cohere command-xlarge) on a mixture of six question-answering datasets, including datasets from scientific and medical domains. Our findings demonstrate that while some variations in effectiveness occur, gains from CoT reasoning strategies remain robust across different models and datasets. GPT-4 has the most benefit from current state-of-the-art reasoning strategies and exhibits the best performance by applying a prompt previously discovered through automated discovery. ","[{'version': 'v1', 'created': 'Thu, 4 May 2023 15:07:20 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Aug 2023 14:33:37 GMT'}]",2023-08-04,"[['Hebenstreit', 'Konstantin', ''], ['Praas', 'Robert', ''], ['Kiesewetter', 'Louis P', ''], ['Samwald', 'Matthias', '']]",0,1,2023-05-04,2,4,2,6,2,4,313d3a911d82b054aa47df0ffd7e4c3b4bd5407f,258480076.0,https://www.semanticscholar.org/paper/313d3a911d82b054aa47df0ffd7e4c3b4bd5407f,arXiv.org,2023.0,40.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2203247685', 'name': 'Konstantin Hebenstreit'}, {'authorId': '2203245379', 'name': 'Robert Praas'}, {'authorId': '2216070743', 'name': 'Louis P Kiesewetter'}, {'authorId': '3004898', 'name': 'M. Samwald'}]","['Humboldt-Universität zu Berlin', 'KTH Royal Institute of Technology', 'Johannes Kepler University of Linz', 'Medical University of Vienna']","['Germany', 'Austria', 'Sweden']",2023-05
2305.03017,AmirHossein Naghshzan,"Sajjad Rahmani, AmirHossein Naghshzan, Latifa Guerrouj",Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study,,,,,cs.SE cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Our research investigates the recommendation of code examples to aid software developers, a practice that saves developers significant time by providing ready-to-use code snippets. The focus of our study is Stack Overflow, a commonly used resource for coding discussions and solutions, particularly in the context of the Java programming language. We applied BERT, a powerful Large Language Model (LLM) that enables us to transform code examples into numerical vectors by extracting their semantic information. Once these numerical representations are prepared, we identify Approximate Nearest Neighbors (ANN) using Locality-Sensitive Hashing (LSH). Our research employed two variants of LSH: Random Hyperplane-based LSH and Query-Aware LSH. We rigorously compared these two approaches across four parameters: HitRate, Mean Reciprocal Rank (MRR), Average Execution Time, and Relevance. Our study revealed that the Query-Aware (QA) approach showed superior performance over the Random Hyperplane-based (RH) method. Specifically, it exhibited a notable improvement of 20% to 35% in HitRate for query pairs compared to the RH approach. Furthermore, the QA approach proved significantly more time-efficient, with its speed in creating hashing tables and assigning data samples to buckets being at least four times faster. It can return code examples within milliseconds, whereas the RH approach typically requires several seconds to recommend code examples. Due to the superior performance of the QA approach, we tested it against PostFinder and FaCoY, the state-of-the-art baselines. Our QA method showed comparable efficiency proving its potential for effective code recommendation. ","[{'version': 'v1', 'created': 'Thu, 4 May 2023 17:43:19 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Jul 2023 22:15:31 GMT'}, {'version': 'v3', 'created': 'Thu, 20 Jul 2023 16:05:39 GMT'}]",2023-07-21,"[['Rahmani', 'Sajjad', ''], ['Naghshzan', 'AmirHossein', ''], ['Guerrouj', 'Latifa', '']]",0,0,2023-05-04,3,3,3,0,0,0,d91413b011141a2312e727b8c9ae1a9b2d2b43f9,258479779.0,https://www.semanticscholar.org/paper/d91413b011141a2312e727b8c9ae1a9b2d2b43f9,arXiv.org,2023.0,40.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143785857', 'name': 'Sajjad Rahmani'}, {'authorId': '2141777131', 'name': 'AmirHossein Naghshzan'}, {'authorId': '1782697', 'name': 'Latifa Guerrouj'}]",['École de Technologie Supérieure'],['Canada'],2023-05
2305.03025,Bosheng Ding,"Fangkai Jiao, Bosheng Ding, Tianze Luo, Zhanfeng Mo",Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This project focuses on enhancing open-source large language models through instruction-tuning and providing comprehensive evaluations of their performance. We explore how various training data factors, such as quantity, quality, and linguistic distribution, influence the performance of instruction-tuned models trained on publicly accessible high-quality instruction datasets for both English and Chinese languages. Our goal is to supplement evaluation with quantitative analyses, providing valuable insights for the continued advancement of open-source chat models. Our model, data, and code are publicly available for others to use and build upon. ","[{'version': 'v1', 'created': 'Thu, 4 May 2023 17:49:09 GMT'}]",2023-05-05,"[['Jiao', 'Fangkai', ''], ['Ding', 'Bosheng', ''], ['Luo', 'Tianze', ''], ['Mo', 'Zhanfeng', '']]",0,0,2023-05-04,1,4,2,0,0,0,af0f0972232754215d611ce086c27fd0dbcf41c2,258479799.0,https://www.semanticscholar.org/paper/af0f0972232754215d611ce086c27fd0dbcf41c2,arXiv.org,2023.0,16.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1689176705', 'name': 'Fangkai Jiao'}, {'authorId': '2064493724', 'name': 'Bosheng Ding'}, {'authorId': '101193275', 'name': 'Tianze Luo'}, {'authorId': '2159249903', 'name': 'Zhanfeng Mo'}]",['Nanyang Technological University'],['Singapore'],2023-05
2305.03123,Sunder Ali Khowaja,"Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev","ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review","15 pages, 5 figures, 4 tables",,,,cs.CY cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  ChatGPT is another large language model (LLM) inline but due to its performance and ability to converse effectively, it has gained a huge popularity amongst research as well as industrial community. Recently, many studies have been published to show the effectiveness, efficiency, integration, and sentiments of chatGPT and other LLMs. In contrast, this study focuses on the important aspects that are mostly overlooked, i.e. sustainability, privacy, digital divide, and ethics and suggests that not only chatGPT but every subsequent entry in the category of conversational bots should undergo Sustainability, PrivAcy, Digital divide, and Ethics (SPADE) evaluation. This paper discusses in detail about the issues and concerns raised over chatGPT in line with aforementioned characteristics. We support our hypothesis by some preliminary data collection and visualizations along with hypothesized facts. We also suggest mitigations and recommendations for each of the concerns. Furthermore, we also suggest some policies and recommendations for AI policy act, if designed by the governments. ","[{'version': 'v1', 'created': 'Thu, 13 Apr 2023 16:01:28 GMT'}]",2023-05-08,"[['Khowaja', 'Sunder Ali', ''], ['Khuwaja', 'Parus', ''], ['Dev', 'Kapal', '']]",1,1,2023-04-13,1,3,4,1,0,1,e9085125d7b0d22801199f2010b671f8f6f416e4,258547290.0,https://www.semanticscholar.org/paper/e9085125d7b0d22801199f2010b671f8f6f416e4,arXiv.org,2023.0,43.0,8.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '10779576', 'name': 'Sunder Ali Khowaja'}, {'authorId': '72089929', 'name': 'P. Khuwaja'}, {'authorId': '1845870613', 'name': 'K. Dev'}]","['Munster Technological University', 'University of Sindh']","['Pakistan', 'Ireland']",2023-04
2305.03253,Bin Ji,Bin Ji,VicunaNER: Zero/Few-shot Named Entity Recognition using Vicuna,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs, e.g., ChatGPT) have shown impressive zero- and few-shot capabilities in Named Entity Recognition (NER). However, these models can only be accessed via online APIs, which may cause data leak and non-reproducible problems. In this paper, we propose VicunaNER, a zero/few-shot NER framework based on the newly released open-source LLM -- Vicuna. VicunaNER is a two-phase framework, where each phase leverages multi-turn dialogues with Vicuna to recognize entities from texts. We name the second phase as Re-Recognition, which recognizes those entities not recognized in the first phase (a.k.a. Recognition). Moreover, we set entity correctness check dialogues in each phase to filter out wrong entities. We evaluate VicunaNER's zero-shot capacity on 10 datasets crossing 5 domains and few-shot capacity on Few-NERD. Experimental results demonstrate that VicunaNER achieves superior performance in both shot settings. Additionally, we conduct comprehensive investigations on Vicuna from multiple perspectives. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 02:46:22 GMT'}]",2023-05-08,"[['Ji', 'Bin', '']]",1,1,2023-05-05,1,1,1,2,1,1,3dc7dabc09d007ba0b1c97e7cd0646367758d4c1,258547095.0,https://www.semanticscholar.org/paper/3dc7dabc09d007ba0b1c97e7cd0646367758d4c1,arXiv.org,2023.0,23.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1511715446', 'name': 'Bin Ji'}]",['National University of Singapore'],['Singapore'],2023-05
2305.03353,Damien Sileo,Damien Sileo and Antoine Lernould,MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Theory of Mind (ToM) is a critical component of intelligence, yet accurately measuring it continues to be a subject of debate. Prior research has attempted to apply human ToM assessments to natural language processing models using either human-created standardized tests or rule-based templates. However, these methods primarily focus on simplistic reasoning and require further validation. In this study, we utilize dynamic epistemic logic, which has established overlaps with ToM, to generate more intricate problems. We also introduce novel verbalization techniques to express these problems using natural language. Our findings indicate that certain language model scaling (from 70M to 6B and 350M to 174B) does not consistently yield results better than random chance. While GPT-4 demonstrates improved epistemic reasoning capabilities, there is still room for enhancement. Our code and datasets are publicly available https://github.com/antoinelrnld/modlog https://huggingface.co/datasets/sileod/mindgames ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 08:14:48 GMT'}]",2023-05-08,"[['Sileo', 'Damien', ''], ['Lernould', 'Antoine', '']]",0,1,2023-05-05,1,2,2,1,0,1,b6ccdd0eb776eee6b317d235e457f20175f380ff,258547259.0,https://www.semanticscholar.org/paper/b6ccdd0eb776eee6b317d235e457f20175f380ff,arXiv.org,2023.0,25.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48217073', 'name': 'Damien Sileo'}, {'authorId': '2216486082', 'name': 'Antoine Lernould'}]","['University of Lille', 'École Centrale de Lille']",['France'],2023-05
2305.03403,Noah Hollmann,"Noah Hollmann, Samuel M\""uller and Frank Hutter",Large Language Models for Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering,,,,,cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As the field of automated machine learning (AutoML) advances, it becomes increasingly important to incorporate domain knowledge into these systems. We present an approach for doing so by harnessing the power of large language models (LLMs). Specifically, we introduce Context-Aware Automated Feature Engineering (CAAFE), a feature engineering method for tabular datasets that utilizes an LLM to iteratively generate additional semantically meaningful features for tabular datasets based on the description of the dataset. The method produces both Python code for creating new features and explanations for the utility of the generated features. Despite being methodologically simple, CAAFE improves performance on 11 out of 14 datasets -- boosting mean ROC AUC performance from 0.798 to 0.822 across all dataset - similar to the improvement achieved by using a random forest instead of logistic regression on our datasets. Furthermore, CAAFE is interpretable by providing a textual explanation for each generated feature. CAAFE paves the way for more extensive semi-automation in data science tasks and emphasizes the significance of context-aware solutions that can extend the scope of AutoML systems to semantic AutoML. We release our $\href{https://github.com/automl/CAAFE}{code}$, a simple $\href{https://colab.research.google.com/drive/1mCA8xOAJZ4MaB_alZvyARTMjhl6RZf0a}{demo}$ and a $\href{https://pypi.org/project/caafe/}{python\ package}$. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 09:58:40 GMT'}, {'version': 'v2', 'created': 'Mon, 22 May 2023 13:26:17 GMT'}, {'version': 'v3', 'created': 'Thu, 25 May 2023 11:54:11 GMT'}, {'version': 'v4', 'created': 'Mon, 17 Jul 2023 16:12:20 GMT'}, {'version': 'v5', 'created': 'Thu, 28 Sep 2023 21:13:21 GMT'}]",2023-10-02,"[['Hollmann', 'Noah', ''], ['Müller', 'Samuel', ''], ['Hutter', 'Frank', '']]",0,0,2023-05-05,5,3,2,0,0,0,36877d3608fb391bad5a22fabd81c6669e721e69,258547322.0,https://www.semanticscholar.org/paper/36877d3608fb391bad5a22fabd81c6669e721e69,,2023.0,76.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2073442519', 'name': 'Noah Hollmann'}, {'authorId': '2249527535', 'name': 'Samuel Muller'}, {'authorId': '144661829', 'name': 'F. Hutter'}]","['University of Freiburg', 'Charité - Universitätsmedizin Berlin']",['Germany'],2023-05
2305.03423,Ralph Peeters,"Ralph Peeters, Christian Bizer",Using ChatGPT for Entity Matching,"Accepted and to be published in Proceedings of ADBIS 2023 as short
  paper (https://www.essi.upc.edu/dtim/ADBIS2023/index.html)",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Entity Matching is the task of deciding if two entity descriptions refer to the same real-world entity. State-of-the-art entity matching methods often rely on fine-tuning Transformer models such as BERT or RoBERTa. Two major drawbacks of using these models for entity matching are that (i) the models require significant amounts of fine-tuning data for reaching a good performance and (ii) the fine-tuned models are not robust concerning out-of-distribution entities. In this paper, we investigate using ChatGPT for entity matching as a more robust, training data-efficient alternative to traditional Transformer models. We perform experiments along three dimensions: (i) general prompt design, (ii) in-context learning, and (iii) provision of higher-level matching knowledge. We show that ChatGPT is competitive with a fine-tuned RoBERTa model, reaching a zero-shot performance of 82.35% F1 on a challenging matching task on which RoBERTa requires 2000 training examples for reaching a similar performance. Adding in-context demonstrations to the prompts further improves the F1 by up to 7.85% when using similarity-based example selection. Always using the same set of 10 handpicked demonstrations leads to an improvement of 4.92% over the zero-shot performance. Finally, we show that ChatGPT can also be guided by adding higher-level matching knowledge in the form of rules to the prompts. Providing matching rules leads to similar performance gains as providing in-context demonstrations. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 10:39:32 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Jun 2023 14:09:56 GMT'}]",2023-06-23,"[['Peeters', 'Ralph', ''], ['Bizer', 'Christian', '']]",1,1,2023-05-05,2,2,1,1,0,1,619c3ab944d7786db3ec4078a6b074a0f70a1987,258546894.0,https://www.semanticscholar.org/paper/619c3ab944d7786db3ec4078a6b074a0f70a1987,Symposium on Advances in Databases and Information Systems,2023.0,22.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2055462710', 'name': 'R. Peeters'}, {'authorId': '1729154', 'name': 'Christian Bizer'}]",['University of Mannheim'],['Germany'],2023-05
2305.03429,Eduardo C. Garrido-Merch\'an,"Eduardo C. Garrido-Merch\'an, Jos\'e Luis Arroyo-Barrig\""uete, Roberto
  Gozalo-Brizuela",Simulating H.P. Lovecraft horror literature with the ChatGPT large language model,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we present a novel approach to simulating H.P. Lovecraft's horror literature using the ChatGPT large language model, specifically the GPT-4 architecture. Our study aims to generate text that emulates Lovecraft's unique writing style and themes, while also examining the effectiveness of prompt engineering techniques in guiding the model's output. To achieve this, we curated a prompt containing several specialized literature references and employed advanced prompt engineering methods. We conducted an empirical evaluation of the generated text by administering a survey to a sample of undergraduate students. Utilizing statistical hypothesis testing, we assessed the students ability to distinguish between genuine Lovecraft works and those generated by our model. Our findings demonstrate that the participants were unable to reliably differentiate between the two, indicating the effectiveness of the GPT-4 model and our prompt engineering techniques in emulating Lovecraft's literary style. In addition to presenting the GPT model's capabilities, this paper provides a comprehensive description of its underlying architecture and offers a comparative analysis with related work that simulates other notable authors and philosophers, such as Dennett. By exploring the potential of large language models in the context of literary emulation, our study contributes to the body of research on the applications and limitations of these models in various creative domains. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 11:03:03 GMT'}]",2023-05-17,"[['Garrido-Merchán', 'Eduardo C.', ''], ['Arroyo-Barrigüete', 'José Luis', ''], ['Gozalo-Brizuela', 'Roberto', '']]",1,1,2023-05-05,1,3,1,2,0,2,a7d8a6d8c04bd4554da4219be0f9d3bf87e2e56b,258547276.0,https://www.semanticscholar.org/paper/a7d8a6d8c04bd4554da4219be0f9d3bf87e2e56b,arXiv.org,2023.0,72.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2170361666', 'name': ""Eduardo C. Garrido-Merch'an""}, {'authorId': '1470163622', 'name': 'J. L. Arroyo-Barrigüete'}, {'authorId': '2200162353', 'name': 'Roberto Gozalo-Brizuela'}]",['Comillas Pontifical University'],['Spain'],2023-05
2305.03726,Bo Li,"Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, Ziwei
  Liu",Otter: A Multi-Modal Model with In-Context Instruction Tuning,Technical Report,,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated significant universal capabilities as few/zero-shot learners in various tasks due to their pre-training on vast amounts of text data, as exemplified by GPT-3, which boosted to InstrctGPT and ChatGPT, effectively following natural language instructions to accomplish real-world tasks. In this paper, we propose to introduce instruction tuning into multi-modal models, motivated by the Flamingo model's upstream interleaved format pretraining dataset. We adopt a similar approach to construct our MultI-Modal In-Context Instruction Tuning (MIMIC-IT) dataset. We then introduce Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning. We also optimize OpenFlamingo's implementation for researchers, democratizing the required training resources from 1$\times$ A100 GPU to 4$\times$ RTX-3090 GPUs, and integrate both OpenFlamingo and Otter into Huggingface Transformers for more researchers to incorporate the models into their customized training and inference pipelines. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 17:59:46 GMT'}]",2023-05-08,"[['Li', 'Bo', ''], ['Zhang', 'Yuanhan', ''], ['Chen', 'Liangyu', ''], ['Wang', 'Jinghao', ''], ['Yang', 'Jingkang', ''], ['Liu', 'Ziwei', '']]",1,1,2023-05-05,1,6,2,2,0,2,d6d3604f369bb0415cbe814e43ca3131323b03e2,258547300.0,https://www.semanticscholar.org/paper/d6d3604f369bb0415cbe814e43ca3131323b03e2,arXiv.org,2023.0,38.0,110.0,17.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2165247100', 'name': 'Bo Li'}, {'authorId': '2145784327', 'name': 'Yuanhan Zhang'}, {'authorId': '2146033755', 'name': 'Liangyu Chen'}, {'authorId': '2109644635', 'name': 'Jinghao Wang'}, {'authorId': '2295601', 'name': 'Jingkang Yang'}, {'authorId': '2145254462', 'name': 'Ziwei Liu'}]",['Nanyang Technological University'],['Singapore'],2023-05
2305.03788,"Hazal T\""urkmen","Hazal T\""urkmen, O\u{g}uz Dikenelli, Cenk Eraslan, Mehmet Cem
  \c{C}all{\i}, S\""uha S\""ureyya \""Ozbek",Harnessing the Power of BERT in the Turkish Clinical Domain: Pretraining Approaches for Limited Data Scenarios,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In recent years, major advancements in natural language processing (NLP) have been driven by the emergence of large language models (LLMs), which have significantly revolutionized research and development within the field. Building upon this progress, our study delves into the effects of various pre-training methodologies on Turkish clinical language models' performance in a multi-label classification task involving radiology reports, with a focus on addressing the challenges posed by limited language resources. Additionally, we evaluated the simultaneous pretraining approach by utilizing limited clinical task data for the first time. We developed four models, including TurkRadBERT-task v1, TurkRadBERT-task v2, TurkRadBERT-sim v1, and TurkRadBERT-sim v2. Our findings indicate that the general Turkish BERT model (BERTurk) and TurkRadBERT-task v1, both of which utilize knowledge from a substantial general-domain corpus, demonstrate the best overall performance. Although the task-adaptive pre-training approach has the potential to capture domain-specific patterns, it is constrained by the limited task-specific corpus and may be susceptible to overfitting. Furthermore, our results underscore the significance of domain-specific vocabulary during pre-training for enhancing model performance. Ultimately, we observe that the combination of general-domain knowledge and task-specific fine-tuning is essential for achieving optimal performance across a range of categories. This study offers valuable insights for developing effective Turkish clinical language models and can guide future research on pre-training techniques for other low-resource languages within the clinical domain. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 18:39:07 GMT'}]",2023-05-09,"[['Türkmen', 'Hazal', ''], ['Dikenelli', 'Oğuz', ''], ['Eraslan', 'Cenk', ''], ['Çallı', 'Mehmet Cem', ''], ['Özbek', 'Süha Süreyya', '']]",0,0,2023-05-05,1,5,1,0,0,0,42b6c3f3ab62311d503e6d30233aa96beac689fe,258558191.0,https://www.semanticscholar.org/paper/42b6c3f3ab62311d503e6d30233aa96beac689fe,Clinical Natural Language Processing Workshop,2023.0,27.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '26556900', 'name': 'Hazal Türkmen'}, {'authorId': '2190118039', 'name': 'Oguz Dikenelli'}, {'authorId': '5962427', 'name': 'C. Eraslan'}, {'authorId': '83577243', 'name': 'Mehmet Cem Çalli'}, {'authorId': '19178801', 'name': 'S. Özbek'}]",['Ege University'],['Turkey'],2023-05
2305.03851,Mark Connor,Mark Connor and Michael O'Neill,"Large Language Models in Sport Science & Medicine: Opportunities, Risks and Considerations","4 Pages, 1 Figure",,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This paper explores the potential opportunities, risks, and challenges associated with the use of large language models (LLMs) in sports science and medicine. LLMs are large neural networks with transformer style architectures trained on vast amounts of textual data, and typically refined with human feedback. LLMs can perform a large range of natural language processing tasks. In sports science and medicine, LLMs have the potential to support and augment the knowledge of sports medicine practitioners, make recommendations for personalised training programs, and potentially distribute high-quality information to practitioners in developing countries. However, there are also potential risks associated with the use and development of LLMs, including biases in the dataset used to create the model, the risk of exposing confidential data, the risk of generating harmful output, and the need to align these models with human preferences through feedback. Further research is needed to fully understand the potential applications of LLMs in sports science and medicine and to ensure that their use is ethical and beneficial to athletes, clients, patients, practitioners, and the general public. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 21:20:02 GMT'}]",2023-05-09,"[['Connor', 'Mark', ''], [""O'Neill"", 'Michael', '']]",0,0,2023-05-05,1,2,1,0,0,0,522ddc254bd0e84f4cb28bcd8f0cd7cc529b5b74,258557539.0,https://www.semanticscholar.org/paper/522ddc254bd0e84f4cb28bcd8f0cd7cc529b5b74,arXiv.org,2023.0,9.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2066380119', 'name': 'M. Connor'}, {'authorId': '2216607022', 'name': ""Michael O'Neill""}]",['University College Dublin'],['Ireland'],2023-05
2305.04106,Martin Weyssow,"Martin Weyssow, Xin Zhou, Kisub Kim, David Lo and Houari Sahraoui",On the Usage of Continual Learning for Out-of-Distribution Generalization in Pre-trained Language Models of Code,,ESEC/FSE 2023,,,cs.SE cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Pre-trained language models (PLMs) have become a prevalent technique in deep learning for code, utilizing a two-stage pre-training and fine-tuning procedure to acquire general knowledge about code and specialize in a variety of downstream tasks. However, the dynamic nature of software codebases poses a challenge to the effectiveness and robustness of PLMs. In particular, world-realistic scenarios potentially lead to significant differences between the distribution of the pre-training and test data, i.e., distribution shift, resulting in a degradation of the PLM's performance on downstream tasks. In this paper, we stress the need for adapting PLMs of code to software data whose distribution changes over time, a crucial problem that has been overlooked in previous works. The motivation of this work is to consider the PLM in a non-stationary environment, where fine-tuning data evolves over time according to a software evolution scenario. Specifically, we design a scenario where the model needs to learn from a stream of programs containing new, unseen APIs over time. We study two widely used PLM architectures, i.e., a GPT2 decoder and a RoBERTa encoder, on two downstream tasks, API call and API usage prediction. We demonstrate that the most commonly used fine-tuning technique from prior work is not robust enough to handle the dynamic nature of APIs, leading to the loss of previously acquired knowledge i.e., catastrophic forgetting. To address these issues, we implement five continual learning approaches, including replay-based and regularization-based methods. Our findings demonstrate that utilizing these straightforward methods effectively mitigates catastrophic forgetting in PLMs across both downstream tasks while achieving comparable or superior performance. ","[{'version': 'v1', 'created': 'Sat, 6 May 2023 18:00:21 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Aug 2023 14:10:06 GMT'}]",2023-08-23,"[['Weyssow', 'Martin', ''], ['Zhou', 'Xin', ''], ['Kim', 'Kisub', ''], ['Lo', 'David', ''], ['Sahraoui', 'Houari', '']]",0,1,2023-05-06,2,5,2,1,1,0,fd38e1f3c5fa7e770c327180fd68bf8bbfc33a70,258556987.0,https://www.semanticscholar.org/paper/fd38e1f3c5fa7e770c327180fd68bf8bbfc33a70,arXiv.org,2023.0,77.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1820831988', 'name': 'M. Weyssow'}, {'authorId': '2148928671', 'name': 'Xin Zhou'}, {'authorId': '35276441', 'name': 'Kisub Kim'}, {'authorId': '2150912791', 'name': 'David Lo'}, {'authorId': '9460712', 'name': 'H. Sahraoui'}]","['Université de Montréal', 'University of Alberta', 'Singapore Management University']","['Canada', 'Singapore']",2023-05
2305.04149,Efstratios Chatzoglou,"Efstratios Chatzoglou and Georgios Karopoulos and Georgios Kambourakis
  and Zisis Tsiatsikas","Bypassing antivirus detection: old-school malware, new tricks",,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Being on a mushrooming spree since at least 2013, malware can take a large toll on any system. In a perpetual cat-and-mouse chase with defenders, malware writers constantly conjure new methods to hide their code so as to evade detection by security products. In this context, focusing on the MS Windows platform, this work contributes a comprehensive empirical evaluation regarding the detection capacity of popular, off-the-shelf antivirus and endpoint detection and response engines when facing legacy malware obfuscated via more or less uncommon but publicly known methods. Our experiments exploit a blend of seven traditional AV evasion techniques in 16 executables built in C++, Go, and Rust. Furthermore, we conduct an incipient study regarding the ability of the ChatGPT chatbot in assisting threat actors to produce ready-to-use malware. The derived results in terms of detection rate are highly unexpected: approximately half of the 12 tested AV engines were able to detect less than half of the malware variants, four AVs exactly half of the variants, while only two of the rest detected all but one of the variants. ","[{'version': 'v1', 'created': 'Sat, 6 May 2023 23:57:01 GMT'}]",2023-05-09,"[['Chatzoglou', 'Efstratios', ''], ['Karopoulos', 'Georgios', ''], ['Kambourakis', 'Georgios', ''], ['Tsiatsikas', 'Zisis', '']]",1,1,2023-05-06,1,4,1,1,0,1,3b38a5eb5b8fe8b1ca7bde31eda9ba30691b7646,258557283.0,https://www.semanticscholar.org/paper/3b38a5eb5b8fe8b1ca7bde31eda9ba30691b7646,ARES,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2052101625', 'name': 'Efstratios Chatzoglou'}, {'authorId': '3184699', 'name': 'Georgios Karopoulos'}, {'authorId': '1711613', 'name': 'G. Kambourakis'}, {'authorId': '3227130', 'name': 'Zisis Tsiatsikas'}]","['Joint Research Centre', 'University of the Aegean']","['Greece', 'Italy']",2023-05
2305.04676,Dimitar Trajanov PhD,"Milena Trajanoska (1), Riste Stojanov (2), Dimitar Trajanov (3) ((1)
  Faculty of Computer Science and Engineering - Ss. Cyril and Methodius
  University - Skopje Macedonia)",Enhancing Knowledge Graph Construction Using Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The growing trend of Large Language Models (LLM) development has attracted significant attention, with models for various applications emerging consistently. However, the combined application of Large Language Models with semantic technologies for reasoning and inference is still a challenging task. This paper analyzes how the current advances in foundational LLM, like ChatGPT, can be compared with the specialized pretrained models, like REBEL, for joint entity and relation extraction. To evaluate this approach, we conducted several experiments using sustainability-related text as our use case. We created pipelines for the automatic creation of Knowledge Graphs from raw texts, and our findings indicate that using advanced LLM models can improve the accuracy of the process of creating these graphs from unstructured text. Furthermore, we explored the potential of automatic ontology creation using foundation LLM models, which resulted in even more relevant and accurate knowledge graphs. ","[{'version': 'v1', 'created': 'Mon, 8 May 2023 12:53:06 GMT'}]",2023-05-09,"[['Trajanoska', 'Milena', ''], ['Stojanov', 'Riste', ''], ['Trajanov', 'Dimitar', '']]",1,1,2023-05-08,1,3,1,1,0,1,694d9b45adcffa4bbc130e4ccaa681e275640128,258557103.0,https://www.semanticscholar.org/paper/694d9b45adcffa4bbc130e4ccaa681e275640128,arXiv.org,2023.0,33.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1753951480', 'name': 'M. Trajanoska'}, {'authorId': '2065807', 'name': 'Riste Stojanov'}, {'authorId': '3034066', 'name': 'D. Trajanov'}]",['Saints Cyril and Methodius University of Skopje'],['North Macedonia'],2023-05
2305.04928,Nikola Milo\v{s}evi\'c Dr,"Milo\v{s} Ko\v{s}prdi\'c, Nikola Prodanovi\'c, Adela Ljaji\'c, Bojana
  Ba\v{s}aragin and Nikola Milo\v{s}evi\'c",From Zero to Hero: Harnessing Transformers for Biomedical Named Entity Recognition in Zero- and Few-shot Contexts,"Collaboration between Bayer Pharma R&D and Serbian Institute for
  Artificial Intelligence Research and Development",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Supervised named entity recognition (NER) in the biomedical domain depends on large sets of annotated texts with the given named entities. The creation of such datasets can be time-consuming and expensive, while extraction of new entities requires additional annotation tasks and retraining the model. To address these challenges, this paper proposes a method for zero- and few-shot NER in the biomedical domain. The method is based on transforming the task of multi-class token classification into binary token classification and pre-training on a large amount of datasets and biomedical entities, which allow the model to learn semantic relations between the given and potentially novel named entity labels. We have achieved average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical entities with fine-tuned PubMedBERT-based model. The results demonstrate the effectiveness of the proposed method for recognizing new biomedical entities with no or limited number of examples, outperforming previous transformer-based methods, and being comparable to GPT3-based models using models with over 1000 times fewer parameters. We make models and developed code publicly available. ","[{'version': 'v1', 'created': 'Fri, 5 May 2023 12:14:22 GMT'}, {'version': 'v2', 'created': 'Fri, 12 May 2023 10:10:06 GMT'}, {'version': 'v3', 'created': 'Sat, 27 May 2023 19:52:16 GMT'}]",2023-05-31,"[['Košprdić', 'Miloš', ''], ['Prodanović', 'Nikola', ''], ['Ljajić', 'Adela', ''], ['Bašaragin', 'Bojana', ''], ['Milošević', 'Nikola', '']]",0,1,2023-05-05,3,5,2,1,0,1,76c26e1a30d665c62fe78b7e9c31ed8358915dcc,258967223.0,https://www.semanticscholar.org/paper/76c26e1a30d665c62fe78b7e9c31ed8358915dcc,arXiv.org,2023.0,64.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '118640249', 'name': 'Milos Kosprdic'}, {'authorId': '2216605243', 'name': 'Nikola Prodanović'}, {'authorId': '31302722', 'name': 'A. Ljajić'}, {'authorId': '2186574263', 'name': 'Bojana Bašaragin'}, {'authorId': '143860899', 'name': 'Nikola Milosevic'}]","['BioSense Institute', 'Bayer A.G., Reaserch and Development, Mullerstrasse 173, Berlin, 13342, Germany']","['Germany', 'Serbia']",2023-05
2305.05516,Fulin Guo,Fulin Guo,GPT Agents in Game Theory Experiments,"36 pages, 5 figures",,,,econ.GN q-fin.EC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper explores the potential of using Generative Pre-trained Transformer (GPT)-based agents as participants in strategic game experiments. Specifically, I focus on the finitely repeated ultimatum and prisoner's dilemma games, two well-studied games in economics. I develop prompts to enable GPT agents to understand the game rules and play the games. The results indicate that, given well-crafted prompts, GPT can generate realistic outcomes and exhibit behavior consistent with human behavior in certain important aspects, such as positive relationship between acceptance rates and offered amounts in the ultimatum game and positive cooperation rates in the prisoner's dilemma game. Some differences between the behavior of GPT and humans are observed in aspects like the evolution of choices over rounds. I also study two treatments in which the GPT agents are prompted to either have social preferences or not. The treatment effects are evident in both games. This preliminary exploration indicates that GPT agents can exhibit realistic performance in simple strategic games and shows the potential of using GPT as a valuable tool in social science research. ","[{'version': 'v1', 'created': 'Tue, 9 May 2023 15:11:13 GMT'}]",2023-05-10,"[['Guo', 'Fulin', '']]",0,1,2023-05-09,1,1,2,0,0,0,48ce58a332e3a96c6576a40a52409c0ccbb1b91c,258564218.0,https://www.semanticscholar.org/paper/48ce58a332e3a96c6576a40a52409c0ccbb1b91c,,2023.0,52.0,5.0,0.0,False,['Economics'],"[{'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Economics', 'source': 's2-fos-model'}]","[{'authorId': '2153242753', 'name': 'Fulin Guo'}]",['University of Cambridge'],['United Kingdom'],2023-05
2305.05576,Pratyush Kumar,Pratyush Kumar,Large Language Models Humanize Technology,,,,,cs.CY cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have made rapid progress in recent months and weeks, garnering significant public attention. This has sparked concerns about aligning these models with human values, their impact on labor markets, and the potential need for regulation in further research and development. However, the discourse often lacks a focus on the imperative to widely diffuse the societal benefits of LLMs. To qualify this societal benefit, we assert that LLMs exhibit emergent abilities to humanize technology more effectively than previous technologies, and for people across language, occupation, and accessibility divides. We argue that they do so by addressing three mechanizing bottlenecks in today's computing technologies: creating diverse and accessible content, learning complex digital tools, and personalizing machine learning algorithms. We adopt a case-based approach and illustrate each bottleneck with two examples where current technology imposes bottlenecks that LLMs demonstrate the ability to address. Given this opportunity to humanize technology widely, we advocate for more widespread understanding of LLMs, tools and methods to simplify use of LLMs, and cross-cutting institutional capacity. ","[{'version': 'v1', 'created': 'Tue, 9 May 2023 16:05:36 GMT'}]",2023-05-10,"[['Kumar', 'Pratyush', '']]",0,0,2023-05-09,1,1,2,0,0,0,2c0ed20784dff5ed224ebee9cd2d66c4e598a679,258564298.0,https://www.semanticscholar.org/paper/2c0ed20784dff5ed224ebee9cd2d66c4e598a679,arXiv.org,2023.0,1.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '38724234', 'name': 'Pratyush Kumar'}]",['Microsoft'],['India'],2023-05
2305.05627,Ilias Chalkidis,Yova Kementchedjhieva and Ilias Chalkidis,An Exploration of Encoder-Decoder Approaches to Multi-Label Classification for Legal and Biomedical Text,"9 pages, long paper at ACL 2023 Findings",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Standard methods for multi-label text classification largely rely on encoder-only pre-trained language models, whereas encoder-decoder models have proven more effective in other classification tasks. In this study, we compare four methods for multi-label classification, two based on an encoder only, and two based on an encoder-decoder. We carry out experiments on four datasets -- two in the legal domain and two in the biomedical domain, each with two levels of label granularity -- and always depart from the same pre-trained model, T5. Our results show that encoder-decoder methods outperform encoder-only methods, with a growing advantage on more complex datasets and labeling schemes of finer granularity. Using encoder-decoder models in a non-autoregressive fashion, in particular, yields the best performance overall, so we further study this approach through ablations to better understand its strengths. ","[{'version': 'v1', 'created': 'Tue, 9 May 2023 17:13:53 GMT'}]",2023-05-10,"[['Kementchedjhieva', 'Yova', ''], ['Chalkidis', 'Ilias', '']]",0,0,2023-05-09,1,2,1,1,1,0,ebb855f6120b3ac66d299443ad56185dc437ad0a,258564273.0,https://www.semanticscholar.org/paper/ebb855f6120b3ac66d299443ad56185dc437ad0a,Annual Meeting of the Association for Computational Linguistics,2023.0,31.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51208524', 'name': 'Yova Kementchedjhieva'}, {'authorId': '2125376289', 'name': 'Ilias Chalkidis'}]",['University of Copenhagen'],['Denmark'],2023-05
2305.05811,Boris Almonacid Dr,Boris Almonacid,Towards an Automatic Optimisation Model Generator Assisted with Generative Pre-trained Transformer,,,,,cs.NE cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article presents a framework for generating optimisation models using a pre-trained generative transformer. The framework involves specifying the features that the optimisation model should have and using a language model to generate an initial version of the model. The model is then tested and validated, and if it contains build errors, an automatic edition process is triggered. An experiment was performed using MiniZinc as the target language and two GPT-3.5 language models for generation and debugging. The results show that the use of language models for the generation of optimisation models is feasible, with some models satisfying the requested specifications, while others require further refinement. The study provides promising evidence for the use of language models in the modelling of optimisation problems and suggests avenues for future research. ","[{'version': 'v1', 'created': 'Tue, 9 May 2023 23:51:14 GMT'}]",2023-05-11,"[['Almonacid', 'Boris', '']]",0,1,2023-05-09,1,1,2,1,0,1,16b7265b7cde1b5aa1325cedb07fdcf3677c5412,258587815.0,https://www.semanticscholar.org/paper/16b7265b7cde1b5aa1325cedb07fdcf3677c5412,arXiv.org,2023.0,5.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2703472', 'name': 'B. Almonacid'}]","['Global Change Science Puerto Varas, Chile']",['Chile'],2023-05
2305.05945,Zhiqiang Hu,"Zhiqiang Hu, Roy Ka-Wei Lee, Nancy F. Chen",Adapter-TST: A Parameter Efficient Method for Multiple-Attribute Text Style Transfer,"11 pages, 3 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Adapting a large language model for multiple-attribute text style transfer via fine-tuning can be challenging due to the significant amount of computational resources and labeled data required for the specific task. In this paper, we address this challenge by introducing AdapterTST, a framework that freezes the pre-trained model's original parameters and enables the development of a multiple-attribute text style transfer model. Using BART as the backbone model, Adapter-TST utilizes different neural adapters to capture different attribute information, like a plug-in connected to BART. Our method allows control over multiple attributes, like sentiment, tense, voice, etc., and configures the adapters' architecture to generate multiple outputs respected to attributes or compositional editing on the same sentence. We evaluate the proposed model on both traditional sentiment transfer and multiple-attribute transfer tasks. The experiment results demonstrate that Adapter-TST outperforms all the state-of-the-art baselines with significantly lesser computational resources. We have also empirically shown that each adapter is able to capture specific stylistic attributes effectively and can be configured to perform compositional editing. ","[{'version': 'v1', 'created': 'Wed, 10 May 2023 07:33:36 GMT'}]",2023-05-11,"[['Hu', 'Zhiqiang', ''], ['Lee', 'Roy Ka-Wei', ''], ['Chen', 'Nancy F.', '']]",0,0,2023-05-10,1,3,1,0,0,0,7f6568c5ce838df3176118a9856471f91971b76c,258588300.0,https://www.semanticscholar.org/paper/7f6568c5ce838df3176118a9856471f91971b76c,arXiv.org,2023.0,40.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1557412457', 'name': 'Zhiqiang Hu'}, {'authorId': '38656724', 'name': 'R. Lee'}, {'authorId': '2118768398', 'name': 'Nancy F. Chen'}]","['Singapore University of Technology and Design', 'Institute for Infocomm Research']",['Singapore'],2023-05
2305.06087,Antonello Ceravola,"Frank Joublin, Antonello Ceravola, Joerg Deigmoeller, Michael Gienger,
  Mathias Franzius, Julian Eggert",A Glimpse in ChatGPT Capabilities and its impact for AI research,,,,,cs.AI cs.CL cs.HC cs.LG cs.RO,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have recently become a popular topic in the field of Artificial Intelligence (AI) research, with companies such as Google, Amazon, Facebook, Amazon, Tesla, and Apple (GAFA) investing heavily in their development. These models are trained on massive amounts of data and can be used for a wide range of tasks, including language translation, text generation, and question answering. However, the computational resources required to train and run these models are substantial, and the cost of hardware and electricity can be prohibitive for research labs that do not have the funding and resources of the GAFA. In this paper, we will examine the impact of LLMs on AI research. The pace at which such models are generated as well as the range of domains covered is an indication of the trend which not only the public but also the scientific community is currently experiencing. We give some examples on how to use such models in research by focusing on GPT3.5/ChatGPT3.4 and ChatGPT4 at the current state and show that such a range of capabilities in a single system is a strong sign of approaching general intelligence. Innovations integrating such models will also expand along the maturation of such AI systems and exhibit unforeseeable applications that will have important impacts on several aspects of our societies. ","[{'version': 'v1', 'created': 'Wed, 10 May 2023 12:10:51 GMT'}]",2023-05-11,"[['Joublin', 'Frank', ''], ['Ceravola', 'Antonello', ''], ['Deigmoeller', 'Joerg', ''], ['Gienger', 'Michael', ''], ['Franzius', 'Mathias', ''], ['Eggert', 'Julian', '']]",1,1,2023-05-10,1,6,5,2,0,2,6cec825e32b1790a69893a5b2506818241506217,258588014.0,https://www.semanticscholar.org/paper/6cec825e32b1790a69893a5b2506818241506217,arXiv.org,2023.0,73.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1759554', 'name': 'F. Joublin'}, {'authorId': '2832005', 'name': 'A. Ceravola'}, {'authorId': '2187928830', 'name': 'Joerg Deigmoeller'}, {'authorId': '1713430', 'name': 'M. Gienger'}, {'authorId': '3149655', 'name': 'M. Franzius'}, {'authorId': '2216720120', 'name': 'Julian Eggert'}]",['Honda Research Institute Europe'],['Germany'],2023-05
2305.06133,Chenghao Li,"Chenghao Li, Chaoning Zhang",When ChatGPT for Computer Vision Will Come? From 2D to 3D,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  ChatGPT and its improved variant GPT4 have revolutionized the NLP field with a single model solving almost all text related tasks. However, such a model for computer vision does not exist, especially for 3D vision. This article first provides a brief view on the progress of deep learning in text, image and 3D fields from the model perspective. Moreover, this work further discusses how AIGC evolves from the data perspective. On top of that, this work presents an outlook on the development of AIGC in 3D from the data perspective. ","[{'version': 'v1', 'created': 'Wed, 10 May 2023 13:29:51 GMT'}]",2023-05-11,"[['Li', 'Chenghao', ''], ['Zhang', 'Chaoning', '']]",1,1,2023-05-10,1,2,1,2,0,2,4fef94dbda70b13680a4a5d86f8f2bc34b5610f9,258588212.0,https://www.semanticscholar.org/paper/4fef94dbda70b13680a4a5d86f8f2bc34b5610f9,arXiv.org,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2144124301', 'name': 'Chenghao Li'}, {'authorId': '31044159', 'name': 'Chaoning Zhang'}]",['Kyung Hee University'],['South Korea'],2023-05
2305.06147,Md Tahmid Rahman Laskar,"Md Tahmid Rahman Laskar, Mizanur Rahman, Israt Jahan, Enamul Hoque,
  Jimmy Huang",CQSumDP: A ChatGPT-Annotated Resource for Query-Focused Abstractive Summarization Based on Debatepedia,10 Pages + References,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Debatepedia is a publicly available dataset consisting of arguments and counter-arguments on controversial topics that has been widely used for the single-document query-focused abstractive summarization task in recent years. However, it has been recently found that this dataset is limited by noise and even most queries in this dataset do not have any relevance to the respective document. In this paper, we present a methodology for cleaning the Debatepedia dataset by leveraging the generative power of large language models to make it suitable for query-focused abstractive summarization. More specifically, we harness the language generation capabilities of ChatGPT to regenerate its queries. We evaluate the effectiveness of the proposed ChatGPT annotated version of the Debatepedia dataset using several benchmark summarization models and demonstrate that the newly annotated version of Debatepedia outperforms the original dataset in terms of both query relevance as well as summary generation quality. We will make this annotated and cleaned version of the dataset publicly available. ","[{'version': 'v1', 'created': 'Fri, 31 Mar 2023 15:39:54 GMT'}]",2023-05-11,"[['Laskar', 'Md Tahmid Rahman', ''], ['Rahman', 'Mizanur', ''], ['Jahan', 'Israt', ''], ['Hoque', 'Enamul', ''], ['Huang', 'Jimmy', '']]",1,1,2023-03-31,1,5,1,1,0,1,01fac76c587a5a28c2646d100bc4bc1ae1048679,258587892.0,https://www.semanticscholar.org/paper/01fac76c587a5a28c2646d100bc4bc1ae1048679,arXiv.org,2023.0,62.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46437970', 'name': 'Md Tahmid Rahman Laskar'}, {'authorId': '2218664824', 'name': 'Mizanur Rahman'}, {'authorId': '2216718110', 'name': 'Israt Jahan'}, {'authorId': '2939577', 'name': 'Enamul Hoque'}, {'authorId': '1683391', 'name': 'J. Huang'}]","['Royal Bank of Canada', 'Dialpad Canada Inc.,', 'York University']",['Canada'],2023-03
2305.06156,Nghi D. Q. Bui,"Dung Nguyen Manh, Nam Le Hai, Anh T. V. Dau, Anh Minh Nguyen, Khanh
  Nghiem, Jin Guo, Nghi D. Q. Bui",The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation,,,,,cs.CL cs.AI cs.PL cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present The Vault, an open-source, large-scale code-text dataset designed to enhance the training of code-focused large language models (LLMs). Existing open-source datasets for training code-based LLMs often face challenges in terms of size, quality (due to noisy signals), and format (only containing code function and text explanation pairings). The Vault overcomes these limitations by providing 40 million code-text pairs across 10 popular programming languages, thorough cleaning for 10+ prevalent issues, and various levels of code-text pairings, including class, function, and line levels. Researchers and practitioners can utilize The Vault for training diverse code-focused LLMs or incorporate the provided data cleaning methods and scripts to improve their datasets. By employing The Vault as the training dataset for code-centric LLMs, we anticipate significant advancements in code understanding and generation tasks, fostering progress in both artificial intelligence research and software development practices. ","[{'version': 'v1', 'created': 'Tue, 9 May 2023 09:35:03 GMT'}]",2023-05-11,"[['Manh', 'Dung Nguyen', ''], ['Hai', 'Nam Le', ''], ['Dau', 'Anh T. V.', ''], ['Nguyen', 'Anh Minh', ''], ['Nghiem', 'Khanh', ''], ['Guo', 'Jin', ''], ['Bui', 'Nghi D. Q.', '']]",0,0,2023-05-09,1,7,4,0,0,0,68559b1ee0f8001300aa92f9ccdbb508e5e55e53,258587836.0,https://www.semanticscholar.org/paper/68559b1ee0f8001300aa92f9ccdbb508e5e55e53,arXiv.org,2023.0,67.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2158859899', 'name': 'Dung Nguyen Manh'}, {'authorId': '2125289755', 'name': 'Nam Le Hai'}, {'authorId': '32891912', 'name': 'An Dau'}, {'authorId': '1997993126', 'name': 'A. Nguyen'}, {'authorId': '39882089', 'name': 'Khanh N. Nghiem'}, {'authorId': '2212087965', 'name': 'Jingnan Guo'}, {'authorId': '26910508', 'name': 'Nghi D. Q. Bui'}]","['FPT Software AI Center', 'McGill University', 'Fulbright University Vietnam', 'University of Milan', 'Hanoi University of Science and Technology']","['Canada', 'Vietnam', 'Italy']",2023-05
2305.06166,Charmaine Barker,Charmaine Barker and Dimitar Kazakov,ChatGPT as a Text Simplification Tool to Remove Bias,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The presence of specific linguistic signals particular to a certain sub-group of people can be picked up by language models during training. If the model begins to associate specific language with a distinct group, any decisions made based upon this language would hold a strong correlation to a decision based upon their protected characteristic, leading to possible discrimination. We explore a potential technique for bias mitigation in the form of simplification of text. The driving force of this idea is that simplifying text should standardise language between different sub-groups to one way of speaking while keeping the same meaning. The experiment shows promising results as the classifier accuracy for predicting the sensitive attribute drops by up to 17% for the simplified data. ","[{'version': 'v1', 'created': 'Tue, 9 May 2023 13:10:23 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Jun 2023 09:45:30 GMT'}]",2023-06-02,"[['Barker', 'Charmaine', ''], ['Kazakov', 'Dimitar', '']]",1,1,2023-05-09,2,2,1,1,0,1,f7551c09c1f31ab9b10f3f119c5ba5cd0d504db9,258588075.0,https://www.semanticscholar.org/paper/f7551c09c1f31ab9b10f3f119c5ba5cd0d504db9,arXiv.org,2023.0,13.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2216724250', 'name': 'Charmaine Barker'}, {'authorId': '145061777', 'name': 'D. Kazakov'}]",['University of York'],['United Kingdom'],2023-05
2305.06488,Sebastian Lobentanzer,Sebastian Lobentanzer and Julio Saez-Rodriguez,A Platform for the Biomedical Application of Large Language Models,"14 pages, 1 figure",,,,q-bio.QM,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The wealth of knowledge we have amassed in the context of biomedical science has grown exponentially in the last decades. Consequently, understanding and contextualising scientific results has become increasingly difficult for any single individual. In contrast, current Large Language Models (LLMs) can remember an enormous amount of information, but have notable shortcomings, such as a lack of generalised awareness, logical deficits, and a propensity to hallucinate. To improve biomedical analyses, we propose to combine human ingenuity and machine memory by means of an open and modular conversational platform, biochatter (https://github.com/biocypher/biochatter), exemplified in the web application ChatGSE (https://chat.biocypher.org). We safeguard against common LLM shortcomings using general and biomedicine-specific measures and allow automated integration of popular bioinformatics methods. Ultimately, we aim to improve the AI-readiness of biomedicine and make LLMs more useful and trustworthy in research applications. ","[{'version': 'v1', 'created': 'Wed, 10 May 2023 22:36:27 GMT'}, {'version': 'v2', 'created': 'Tue, 16 May 2023 17:29:26 GMT'}, {'version': 'v3', 'created': 'Fri, 21 Jul 2023 14:02:08 GMT'}]",2023-07-24,"[['Lobentanzer', 'Sebastian', ''], ['Saez-Rodriguez', 'Julio', '']]",0,0,2023-05-10,3,2,1,0,0,0,bcc41813b96f83fbef837bcd3dff76c7624663a0,258615636.0,https://www.semanticscholar.org/paper/bcc41813b96f83fbef837bcd3dff76c7624663a0,,2023.0,21.0,2.0,0.0,False,['Biology'],"[{'category': 'Biology', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '93770443', 'name': 'Sebastian Lobentanzer'}, {'authorId': '1389786323', 'name': 'J. Sáez-Rodríguez'}]","['Heidelberg University', 'Institute for Computational Biomedicine, Heidelberg, Germany']",['Germany'],2023-05
2305.06566,Qijiong Liu,"Qijiong Liu, Nuo Chen, Tetsuya Sakai, Xiao-Ming Wu",ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models,,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Personalized content-based recommender systems have become indispensable tools for users to navigate through the vast amount of content available on platforms like daily news websites and book recommendation services. However, existing recommenders face significant challenges in understanding the content of items. Large language models (LLMs), which possess deep semantic comprehension and extensive knowledge from pretraining, have proven to be effective in various natural language processing tasks. In this study, we explore the potential of leveraging both open- and closed-source LLMs to enhance content-based recommendation. With open-source LLMs, we utilize their deep layers as content encoders, enriching the representation of content at the embedding level. For closed-source LLMs, we employ prompting techniques to enrich the training data at the token level. Through comprehensive experiments, we demonstrate the high effectiveness of both types of LLMs and show the synergistic relationship between them. Notably, we observed a significant relative improvement of up to 19.32% compared to existing state-of-the-art recommendation models. These findings highlight the immense potential of both open- and closed-source of LLMs in enhancing content-based recommendation systems. We will make our code and LLM-generated data available for other researchers to reproduce our results. ","[{'version': 'v1', 'created': 'Thu, 11 May 2023 04:51:21 GMT'}, {'version': 'v2', 'created': 'Sun, 4 Jun 2023 02:43:47 GMT'}, {'version': 'v3', 'created': 'Wed, 30 Aug 2023 06:46:43 GMT'}, {'version': 'v4', 'created': 'Thu, 31 Aug 2023 13:43:43 GMT'}]",2023-09-01,"[['Liu', 'Qijiong', ''], ['Chen', 'Nuo', ''], ['Sakai', 'Tetsuya', ''], ['Wu', 'Xiao-Ming', '']]",0,0,2023-05-11,4,4,2,0,0,0,ef0679f8b3114c339bdf5a0c202403a08d160a88,258615357.0,https://www.semanticscholar.org/paper/ef0679f8b3114c339bdf5a0c202403a08d160a88,,2023.0,52.0,5.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150270469', 'name': 'Qijiong Liu'}, {'authorId': '119895609', 'name': 'Nuo Chen'}, {'authorId': '2187429049', 'name': 'Tetsuya Sakai'}, {'authorId': '2187512110', 'name': 'Xiao-Ming Wu'}]","['Nuo Chen', 'Waseda University', 'Hong Kong Polytechnic University']","['Japan', 'Hong Kong']",2023-05
2305.06841,Michal \v{S}tef\'anik,"Luk\'a\v{s} Mikula, Michal \v{S}tef\'anik, Marek Petrovi\v{c}, Petr
  Sojka",Think Twice: Measuring the Efficiency of Eliminating Prediction Shortcuts of Question Answering Models,"ARR-reviewed paper, to appear at *ACL conference",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  While the Large Language Models (LLMs) dominate a majority of language understanding tasks, previous work shows that some of these results are supported by modelling spurious correlations of training datasets. Authors commonly assess model robustness by evaluating their models on out-of-distribution (OOD) datasets of the same task, but these datasets might share the bias of the training dataset.   We propose a simple method for measuring a scale of models' reliance on any identified spurious feature and assess the robustness towards a large set of known and newly found prediction biases for various pre-trained models and debiasing methods in Question Answering (QA). We find that the reported OOD gains of debiasing methods can not be explained by mitigated reliance on biased features, suggesting that biases are shared among QA datasets. We further evidence this by measuring that performance of OOD models depends on bias features comparably to the ID model, motivating future work to refine the reports of LLMs' robustness to a level of known spurious features. ","[{'version': 'v1', 'created': 'Thu, 11 May 2023 14:35:00 GMT'}]",2023-05-12,"[['Mikula', 'Lukáš', ''], ['Štefánik', 'Michal', ''], ['Petrovič', 'Marek', ''], ['Sojka', 'Petr', '']]",0,0,2023-05-11,1,4,2,0,0,0,60bb08c048d8e4cccb47c6c9f9ab7639fb8f5370,258615593.0,https://www.semanticscholar.org/paper/60bb08c048d8e4cccb47c6c9f9ab7639fb8f5370,arXiv.org,2023.0,44.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2216809060', 'name': ""Luk'avs Mikula""}, {'authorId': '2106506537', 'name': ""Michal vStef'anik""}, {'authorId': '2216809054', 'name': 'Marek Petrovivc'}, {'authorId': '1980208', 'name': 'Petr Sojka'}]",['Masaryk University'],['Czechia'],2023-05
2305.06965,Firas Khader,"Firas Khader, Gustav M\""uller-Franzes, Tianyu Han, Sven Nebelung,
  Christiane Kuhl, Johannes Stegmaier, Daniel Truhn",Transformers for CT Reconstruction From Monoplanar and Biplanar Radiographs,,,,,eess.IV cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Computed Tomography (CT) scans provide detailed and accurate information of internal structures in the body. They are constructed by sending x-rays through the body from different directions and combining this information into a three-dimensional volume. Such volumes can then be used to diagnose a wide range of conditions and allow for volumetric measurements of organs. In this work, we tackle the problem of reconstructing CT images from biplanar x-rays only. X-rays are widely available and even if the CT reconstructed from these radiographs is not a replacement of a complete CT in the diagnostic setting, it might serve to spare the patients from radiation where a CT is only acquired for rough measurements such as determining organ size. We propose a novel method based on the transformer architecture, by framing the underlying task as a language translation problem. Radiographs and CT images are first embedded into latent quantized codebook vectors using two different autoencoder networks. We then train a GPT model, to reconstruct the codebook vectors of the CT image, conditioned on the codebook vectors of the x-rays and show that this approach leads to realistic looking images. To encourage further research in this direction, we make our code publicly available on GitHub: XXX. ","[{'version': 'v1', 'created': 'Thu, 11 May 2023 16:43:39 GMT'}]",2023-05-12,"[['Khader', 'Firas', ''], ['Müller-Franzes', 'Gustav', ''], ['Han', 'Tianyu', ''], ['Nebelung', 'Sven', ''], ['Kuhl', 'Christiane', ''], ['Stegmaier', 'Johannes', ''], ['Truhn', 'Daniel', '']]",0,1,2023-05-11,1,7,2,0,0,0,89a1fdadc4008eeb161e9956c894ad3828477509,258615601.0,https://www.semanticscholar.org/paper/89a1fdadc4008eeb161e9956c894ad3828477509,SASHIMI@MICCAI,2023.0,22.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2047524297', 'name': 'F. Khader'}, {'authorId': '2214619730', 'name': 'Gustav Muller-Franzes'}, {'authorId': '2031129360', 'name': 'T. Han'}, {'authorId': '6280924', 'name': 'S. Nebelung'}, {'authorId': '2064331880', 'name': 'C. Kuhl'}, {'authorId': '3011220', 'name': 'J. Stegmaier'}, {'authorId': '3228050', 'name': 'D. Truhn'}]","['RWTH Aachen University', 'Universitätsklinikum Aachen']",['Germany'],2023-05
2305.06972,Julian Hazell,Julian Hazell,Large Language Models Can Be Used To Effectively Scale Spear Phishing Campaigns,"16 pages, 10 figures",,,,cs.CY cs.AI cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Recent progress in artificial intelligence (AI), particularly in the domain of large language models (LLMs), has resulted in powerful and versatile dual-use systems. Indeed, cognition can be put towards a wide variety of tasks, some of which can result in harm. This study investigates how LLMs can be used for spear phishing, a form of cybercrime that involves manipulating targets into divulging sensitive information. I first explore LLMs' ability to assist with the reconnaissance and message generation stages of a successful spear phishing attack, where I find that advanced LLMs are capable of improving cybercriminals' efficiency during these stages. To explore how LLMs can be used to scale spear phishing campaigns, I then create unique spear phishing messages for over 600 British Members of Parliament using OpenAI's GPT-3.5 and GPT-4 models. My findings reveal that these messages are not only realistic but also cost-effective, with each email costing only a fraction of a cent to generate. Next, I demonstrate how basic prompt engineering can circumvent safeguards installed in LLMs by the reinforcement learning from human feedback fine-tuning process, highlighting the need for more robust governance interventions aimed at preventing misuse. To address these evolving risks, I propose two potential solutions: structured access schemes, such as application programming interfaces, and LLM-based defensive systems. ","[{'version': 'v1', 'created': 'Thu, 11 May 2023 16:55:19 GMT'}, {'version': 'v2', 'created': 'Fri, 12 May 2023 07:48:41 GMT'}]",2023-05-15,"[['Hazell', 'Julian', '']]",0,1,2023-05-11,2,1,3,2,0,2,661e8ac4908a9d2a85835245ea99b6a314cc4a60,258615708.0,https://www.semanticscholar.org/paper/661e8ac4908a9d2a85835245ea99b6a314cc4a60,arXiv.org,2023.0,39.0,28.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2211731086', 'name': 'Julian Hazell'}]",['University of Oxford'],['United Kingdom'],2023-05
2305.06984,Ehsan Kamalloo,"Ehsan Kamalloo, Nouha Dziri, Charles L. A. Clarke, Davood Rafiei",Evaluating Open-Domain Question Answering in the Era of Large Language Models,"ACL 2023; code and data released at
  https://github.com/ehsk/OpenQA-eval",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more challenging. Without accurate evaluation, the true progress in open-domain QA remains unknown. In this paper, we conduct a thorough analysis of various open-domain QA models, including LLMs, by manually evaluating their answers on a subset of NQ-open, a popular benchmark. Our assessments reveal that while the true performance of all models is significantly underestimated, the performance of the InstructGPT (zero-shot) LLM increases by nearly +60%, making it on par with existing top models, and the InstructGPT (few-shot) model actually achieves a new state-of-the-art on NQ-open. We also find that more than 50% of lexical matching failures are attributed to semantically equivalent answers. We further demonstrate that regex matching ranks QA models consistent with human judgments, although still suffering from unnecessary strictness. Finally, we demonstrate that automated evaluation models are a reasonable surrogate for lexical matching in some circumstances, but not for long-form answers generated by LLMs. The automated models struggle in detecting hallucinations in LLM answers and are thus unable to evaluate LLMs. At this time, there appears to be no substitute for human evaluation. ","[{'version': 'v1', 'created': 'Thu, 11 May 2023 17:14:33 GMT'}, {'version': 'v2', 'created': 'Sun, 14 May 2023 21:21:56 GMT'}, {'version': 'v3', 'created': 'Thu, 6 Jul 2023 18:52:08 GMT'}]",2023-07-10,"[['Kamalloo', 'Ehsan', ''], ['Dziri', 'Nouha', ''], ['Clarke', 'Charles L. A.', ''], ['Rafiei', 'Davood', '']]",0,1,2023-05-11,3,4,1,1,0,1,6bef46eccb4c7f521e4f255a01595ebf9994ae22,258615193.0,https://www.semanticscholar.org/paper/6bef46eccb4c7f521e4f255a01595ebf9994ae22,Annual Meeting of the Association for Computational Linguistics,2023.0,51.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2023642', 'name': 'Ehsan Kamalloo'}, {'authorId': '46217681', 'name': 'Nouha Dziri'}, {'authorId': '1751287', 'name': 'C. Clarke'}, {'authorId': '2144238', 'name': 'Davood Rafiei'}]",['University of Waterloo'],['Canada'],2023-05
2305.07378,Gal Yona,"Gal Yona, Or Honovich, Itay Laish, Roee Aharoni",Surfacing Biases in Large Language Models using Contrastive Input Decoding,,,,,cs.CL cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Ensuring that large language models (LMs) are fair, robust and useful requires an understanding of how different modifications to their inputs impact the model's behaviour. In the context of open-text generation tasks, however, such an evaluation is not trivial. For example, when introducing a model with an input text and a perturbed, ""contrastive"" version of it, meaningful differences in the next-token predictions may not be revealed with standard decoding strategies. With this motivation in mind, we propose Contrastive Input Decoding (CID): a decoding algorithm to generate text given two inputs, where the generated text is likely given one input but unlikely given the other. In this way, the contrastive generations can highlight potentially subtle differences in how the LM output differs for the two inputs in a simple and interpretable manner. We use CID to highlight context-specific biases that are hard to detect with standard decoding strategies and quantify the effect of different input perturbations. ","[{'version': 'v1', 'created': 'Fri, 12 May 2023 11:09:49 GMT'}]",2023-05-15,"[['Yona', 'Gal', ''], ['Honovich', 'Or', ''], ['Laish', 'Itay', ''], ['Aharoni', 'Roee', '']]",0,0,2023-05-12,1,4,3,0,0,0,b20e93425a70f4ca3cf68abe921e8c3812e0c471,258676465.0,https://www.semanticscholar.org/paper/b20e93425a70f4ca3cf68abe921e8c3812e0c471,arXiv.org,2023.0,29.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '36825265', 'name': 'G. Yona'}, {'authorId': '1754700648', 'name': 'Or Honovich'}, {'authorId': '40142021', 'name': 'Itay Laish'}, {'authorId': '2335771', 'name': 'Roee Aharoni'}]",['Tel Aviv University'],['Israel'],2023-05
2305.07429,Wadii Boulila Prof.,"Ayyub Alzahem, Shahid Latif, Wadii Boulila, Anis Koubaa",Unlocking the Potential of Medical Imaging with ChatGPT's Intelligent Diagnostics,,,,,eess.IV cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Medical imaging is an essential tool for diagnosing various healthcare diseases and conditions. However, analyzing medical images is a complex and time-consuming task that requires expertise and experience. This article aims to design a decision support system to assist healthcare providers and patients in making decisions about diagnosing, treating, and managing health conditions. The proposed architecture contains three stages: 1) data collection and labeling, 2) model training, and 3) diagnosis report generation. The key idea is to train a deep learning model on a medical image dataset to extract four types of information: the type of image scan, the body part, the test image, and the results. This information is then fed into ChatGPT to generate automatic diagnostics. The proposed system has the potential to enhance decision-making, reduce costs, and improve the capabilities of healthcare providers. The efficacy of the proposed system is analyzed by conducting extensive experiments on a large medical image dataset. The experimental outcomes exhibited promising performance for automatic diagnosis through medical images. ","[{'version': 'v1', 'created': 'Fri, 12 May 2023 12:52:14 GMT'}]",2023-05-15,"[['Alzahem', 'Ayyub', ''], ['Latif', 'Shahid', ''], ['Boulila', 'Wadii', ''], ['Koubaa', 'Anis', '']]",1,1,2023-05-12,1,4,3,1,0,1,94ce0986bc1d58cd8154a48c13e7b70f72922373,258676497.0,https://www.semanticscholar.org/paper/94ce0986bc1d58cd8154a48c13e7b70f72922373,arXiv.org,2023.0,27.0,3.0,0.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2133326426', 'name': 'Ayyub Alzahem'}, {'authorId': '145729901', 'name': 'Shahid Latif'}, {'authorId': '3151219', 'name': 'W. Boulila'}, {'authorId': '1714415', 'name': 'A. Koubâa'}]",['Prince Sultan University'],['Saudi Arabia'],2023-05
2305.07457,Tu Anh Dinh,"Tu Anh Dinh, Jan Niehues","Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation",Accepted to MT Summit 2023,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Quality Estimation (QE) is the task of predicting the quality of Machine Translation (MT) system output, without using any gold-standard translation references. State-of-the-art QE models are supervised: they require human-labeled quality of some MT system output on some datasets for training, making them domain-dependent and MT-system-dependent. There has been research on unsupervised QE, which requires glass-box access to the MT systems, or parallel MT data to generate synthetic errors for training QE models. In this paper, we present Perturbation-based QE - a word-level Quality Estimation approach that works simply by analyzing MT system output on perturbed input source sentences. Our approach is unsupervised, explainable, and can evaluate any type of blackbox MT systems, including the currently prominent large language models (LLMs) with opaque internal processes. For language directions with no labeled QE data, our approach has similar or better performance than the zero-shot supervised approach on the WMT21 shared task. Our approach is better at detecting gender bias and word-sense-disambiguation errors in translation than supervised QE, indicating its robustness to out-of-domain usage. The performance gap is larger when detecting errors on a nontraditional translation-prompting LLM, indicating that our approach is more generalizable to different MT systems. We give examples demonstrating our approach's explainability power, where it shows which input source words have influence on a certain MT output word. ","[{'version': 'v1', 'created': 'Fri, 12 May 2023 13:10:57 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Jul 2023 07:35:09 GMT'}]",2023-07-14,"[['Dinh', 'Tu Anh', ''], ['Niehues', 'Jan', '']]",0,0,2023-05-12,2,2,1,0,0,0,02217d244005d8d67f86b187256870b36fc725f3,258676620.0,https://www.semanticscholar.org/paper/02217d244005d8d67f86b187256870b36fc725f3,Machine Translation Summit,2023.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067507367', 'name': 'Tu Anh Dinh'}, {'authorId': '2920247', 'name': 'J. Niehues'}]",['Karlsruhe Institute of Technology'],['Germany'],2023-05
2305.07477,Iain Mackie,"Iain Mackie, Shubham Chatterjee, Jeffrey Dalton","Generative and Pseudo-Relevant Feedback for Sparse, Dense and Learned Sparse Retrieval",,,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pseudo-relevance feedback (PRF) is a classical approach to address lexical mismatch by enriching the query using first-pass retrieval. Moreover, recent work on generative-relevance feedback (GRF) shows that query expansion models using text generated from large language models can improve sparse retrieval without depending on first-pass retrieval effectiveness. This work extends GRF to dense and learned sparse retrieval paradigms with experiments over six standard document ranking benchmarks. We find that GRF improves over comparable PRF techniques by around 10% on both precision and recall-oriented measures. Nonetheless, query analysis shows that GRF and PRF have contrasting benefits, with GRF providing external context not present in first-pass retrieval, whereas PRF grounds the query to the information contained within the target corpus. Thus, we propose combining generative and pseudo-relevance feedback ranking signals to achieve the benefits of both feedback classes, which significantly increases recall over PRF methods on 95% of experiments. ","[{'version': 'v1', 'created': 'Fri, 12 May 2023 13:46:17 GMT'}]",2023-05-15,"[['Mackie', 'Iain', ''], ['Chatterjee', 'Shubham', ''], ['Dalton', 'Jeffrey', '']]",0,0,2023-05-12,1,3,1,0,0,0,f5448f9e6c3d916cb52ad6b9f9eee0ad379914f7,258676372.0,https://www.semanticscholar.org/paper/f5448f9e6c3d916cb52ad6b9f9eee0ad379914f7,arXiv.org,2023.0,55.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145052856', 'name': 'Iain Mackie'}, {'authorId': '2113355478', 'name': 'Shubham Chatterjee'}, {'authorId': '49694325', 'name': 'Jeffrey Stephen Dalton'}]",['University of Glasgow'],['United Kingdom'],2023-05
2305.07605,Bill Cope,"Anastasia Olga (Olnancy) Tzirides, Akash Saini, Gabriela Zapata, Duane
  Searsmith, Bill Cope, Mary Kalantzis, Vania Castro, Theodora Kourkoulou, John
  Jones, Rodrigo Abrantes da Silva, Jen Whiting, Nikoleta Polyxeni Kastania",Generative AI: Implications and Applications for Education,34 pages,,,,cs.CY cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The launch of ChatGPT in November 2022 precipitated a panic among some educators while prompting qualified enthusiasm from others. Under the umbrella term Generative AI, ChatGPT is an example of a range of technologies for the delivery of computer-generated text, image, and other digitized media. This paper examines the implications for education of one generative AI technology, chatbots responding from large language models, or C-LLM. It reports on an application of a C-LLM to AI review and assessment of complex student work. In a concluding discussion, the paper explores the intrinsic limits of generative AI, bound as it is to language corpora and their textual representation through binary notation. Within these limits, we suggest the range of emerging and potential applications of Generative AI in education. ","[{'version': 'v1', 'created': 'Fri, 12 May 2023 16:52:38 GMT'}, {'version': 'v2', 'created': 'Mon, 15 May 2023 01:50:07 GMT'}, {'version': 'v3', 'created': 'Mon, 22 May 2023 11:42:19 GMT'}]",2023-05-23,"[['Olga', 'Anastasia', '', 'Olnancy'], ['Tzirides', '', ''], ['Saini', 'Akash', ''], ['Zapata', 'Gabriela', ''], ['Searsmith', 'Duane', ''], ['Cope', 'Bill', ''], ['Kalantzis', 'Mary', ''], ['Castro', 'Vania', ''], ['Kourkoulou', 'Theodora', ''], ['Jones', 'John', ''], ['da Silva', 'Rodrigo Abrantes', ''], ['Whiting', 'Jen', ''], ['Kastania', 'Nikoleta Polyxeni', '']]",1,1,2023-05-12,3,13,2,1,0,1,ebae6e48eedf456de10b7e4cf70eab467731fd73,258676570.0,https://www.semanticscholar.org/paper/ebae6e48eedf456de10b7e4cf70eab467731fd73,arXiv.org,2023.0,62.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51163131', 'name': 'A. Tzirides'}, {'authorId': '153204470', 'name': 'A. Saini'}, {'authorId': '144788868', 'name': 'Gabriela C. Zapata'}, {'authorId': '2693295', 'name': 'Duane Searsmith'}, {'authorId': '33955451', 'name': 'B. Cope'}, {'authorId': '2334862', 'name': 'M. Kalantzis'}, {'authorId': '2217098260', 'name': 'Vania Castro'}, {'authorId': '2217190604', 'name': 'Theodora Kourkoulou'}, {'authorId': '2217236433', 'name': 'John Jones'}, {'authorId': '2217680716', 'name': 'Rodrigo Abrantes da Silva'}, {'authorId': '13199118', 'name': 'Jennifer K. Whiting'}, {'authorId': '2217225866', 'name': 'Nikoleta Polyxeni Kastania'}]","['Nikoleta Polyxeni Kastania', 'Silva']",['France'],2023-05
2305.07759,Yuanzhi Li,Ronen Eldan and Yuanzhi Li,TinyStories: How Small Can Language Models Be and Still Speak Coherent English?,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models (LMs) are powerful tools for natural language processing, but they often struggle to produce coherent and fluent text when they are small. Models with around 125M parameters such as GPT-Neo (small) or GPT-2 (small) can rarely generate coherent and consistent English text beyond a few words even after extensive training. This raises the question of whether the emergence of the ability to produce coherent English text only occurs at larger scales (with hundreds of millions of parameters or more) and complex architectures (with many layers of global attention).   In this work, we introduce TinyStories, a synthetic dataset of short stories that only contain words that a typical 3 to 4-year-olds usually understand, generated by GPT-3.5 and GPT-4. We show that TinyStories can be used to train and evaluate LMs that are much smaller than the state-of-the-art models (below 10 million total parameters), or have much simpler architectures (with only one transformer block), yet still produce fluent and consistent stories with several paragraphs that are diverse and have almost perfect grammar, and demonstrate reasoning capabilities.   We also introduce a new paradigm for the evaluation of language models: We suggest a framework which uses GPT-4 to grade the content generated by these models as if those were stories written by students and graded by a (human) teacher. This new paradigm overcomes the flaws of standard benchmarks which often requires the model's output to be very structures, and moreover provides a multidimensional score for the model, providing scores for different capabilities such as grammar, creativity and consistency.   We hope that TinyStories can facilitate the development, analysis and research of LMs, especially for low-resource or specialized domains, and shed light on the emergence of language capabilities in LMs. ","[{'version': 'v1', 'created': 'Fri, 12 May 2023 20:56:48 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 23:30:43 GMT'}]",2023-05-26,"[['Eldan', 'Ronen', ''], ['Li', 'Yuanzhi', '']]",0,1,2023-05-12,2,2,3,3,1,2,28085f480ce456a376ebace9b899e3bc93dbc048,258686446.0,https://www.semanticscholar.org/paper/28085f480ce456a376ebace9b899e3bc93dbc048,arXiv.org,2023.0,36.0,31.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2315830', 'name': 'Ronen Eldan'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}]",['Microsoft'],['India'],2023-05
2305.07868,Davut Emre Ta\c{s}ar,"Davut Emre Tasar, Ceren Ocal Tasar","Bridging History with AI A Comparative Evaluation of GPT 3.5, GPT4, and GoogleBARD in Predictive Accuracy and Fact Checking",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  The rapid proliferation of information in the digital era underscores the importance of accurate historical representation and interpretation. While artificial intelligence has shown promise in various fields, its potential for historical fact-checking and gap-filling remains largely untapped. This study evaluates the performance of three large language models LLMs GPT 3.5, GPT 4, and GoogleBARD in the context of predicting and verifying historical events based on given data. A novel metric, Distance to Reality (DTR), is introduced to assess the models' outputs against established historical facts. The results reveal a substantial potential for AI in historical studies, with GPT 4 demonstrating superior performance. This paper underscores the need for further research into AI's role in enriching our understanding of the past and bridging historical knowledge gaps. ","[{'version': 'v1', 'created': 'Sat, 13 May 2023 08:58:37 GMT'}]",2023-05-16,"[['Tasar', 'Davut Emre', ''], ['Tasar', 'Ceren Ocal', '']]",0,1,2023-05-13,1,2,2,2,0,2,49efa0629ef9f32932948bd42487420296fd0067,258686405.0,https://www.semanticscholar.org/paper/49efa0629ef9f32932948bd42487420296fd0067,arXiv.org,2023.0,12.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2111243698', 'name': 'D. E. Tasar'}, {'authorId': '66230491', 'name': 'Ceren Ocal Tasar'}]",['Karabük University'],['Turkey'],2023-05
2305.07871,Sahan Bulathwela,"Sahan Bulathwela, Hamze Muse and Emine Yilmaz",Scalable Educational Question Generation with Pre-trained Language Models,"To be published at the Int. Conf. on Artificial Intelligence in
  Education (Tokyo, 2023)",,,,cs.AI cs.CY cs.IR cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  The automatic generation of educational questions will play a key role in scaling online education, enabling self-assessment at scale when a global population is manoeuvring their personalised learning journeys. We develop \textit{EduQG}, a novel educational question generation model built by adapting a large language model. Our extensive experiments demonstrate that \textit{EduQG} can produce superior educational questions by further pre-training and fine-tuning a pre-trained language model on the scientific text and science question data. ","[{'version': 'v1', 'created': 'Sat, 13 May 2023 09:08:27 GMT'}]",2023-05-16,"[['Bulathwela', 'Sahan', ''], ['Muse', 'Hamze', ''], ['Yilmaz', 'Emine', '']]",0,0,2023-05-13,1,3,4,0,0,0,c0ae4e9062f60cd2f9038e6e3fadc3fbf298c964,258685703.0,https://www.semanticscholar.org/paper/c0ae4e9062f60cd2f9038e6e3fadc3fbf298c964,International Conference on Artificial Intelligence in Education,2023.0,21.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143115611', 'name': 'Sahan Bulathwela'}, {'authorId': '2194647884', 'name': 'Hamze Muse'}, {'authorId': '2084638888', 'name': 'Emine Yilmaz'}]",['University College London'],['United Kingdom'],2023-05
2305.07882,Alexei Grinbaum,Alexei Grinbaum and Laurynas Adomaitis,Dual Use Concerns of Generative AI and Large Language Models,,,,,cs.CY cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We suggest the implementation of the Dual Use Research of Concern (DURC) framework, originally designed for life sciences, to the domain of generative AI, with a specific focus on Large Language Models (LLMs). With its demonstrated advantages and drawbacks in biological research, we believe the DURC criteria can be effectively redefined for LLMs, potentially contributing to improved AI governance. Acknowledging the balance that must be struck when employing the DURC framework, we highlight its crucial political role in enhancing societal awareness of the impact of generative AI. As a final point, we offer a series of specific recommendations for applying the DURC approach to LLM research. ","[{'version': 'v1', 'created': 'Sat, 13 May 2023 10:08:57 GMT'}]",2023-05-16,"[['Grinbaum', 'Alexei', ''], ['Adomaitis', 'Laurynas', '']]",0,0,2023-05-13,1,2,2,0,0,0,10a08160be0b42d5785b80ec4f5ccf8aeb61780d,258686553.0,https://www.semanticscholar.org/paper/10a08160be0b42d5785b80ec4f5ccf8aeb61780d,arXiv.org,2023.0,71.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40371965', 'name': 'A. Grinbaum'}, {'authorId': '108814448', 'name': 'Laurynas Adomaitis'}]",['CEA Saclay'],['France'],2023-05
2305.08005,Erik Derner,Erik Derner and Kristina Batisti\v{c},Beyond the Safeguards: Exploring the Security Risks of ChatGPT,,,,,cs.CR cs.AI cs.CL cs.CY cs.HC,http://creativecommons.org/licenses/by/4.0/,"  The increasing popularity of large language models (LLMs) such as ChatGPT has led to growing concerns about their safety, security risks, and ethical implications. This paper aims to provide an overview of the different types of security risks associated with ChatGPT, including malicious text and code generation, private data disclosure, fraudulent services, information gathering, and producing unethical content. We present an empirical study examining the effectiveness of ChatGPT's content filters and explore potential ways to bypass these safeguards, demonstrating the ethical implications and security risks that persist in LLMs even when protections are in place. Based on a qualitative analysis of the security implications, we discuss potential strategies to mitigate these risks and inform researchers, policymakers, and industry professionals about the complex security challenges posed by LLMs like ChatGPT. This study contributes to the ongoing discussion on the ethical and security implications of LLMs, underscoring the need for continued research in this area. ","[{'version': 'v1', 'created': 'Sat, 13 May 2023 21:01:14 GMT'}]",2023-05-16,"[['Derner', 'Erik', ''], ['Batistič', 'Kristina', '']]",1,1,2023-05-13,1,2,5,1,0,1,7b418b7c5c3df1f22fa04a31727c945df8501556,258686688.0,https://www.semanticscholar.org/paper/7b418b7c5c3df1f22fa04a31727c945df8501556,arXiv.org,2023.0,41.0,14.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31533806', 'name': 'Erik Derner'}, {'authorId': '101720110', 'name': 'Kristina Batistic'}]","['Independent Researcher, Ljubljana, Slovenia', 'Czech Technical University in Prague']","['Czechia', 'Slovenia']",2023-05
2305.08088,Qiushi Sun,"Qiushi Sun, Chengcheng Han, Nuo Chen, Renyu Zhu, Jingyang Gong, Xiang
  Li, Ming Gao",Make Prompt-based Black-Box Tuning Colorful: Boosting Model Generalization from Three Orthogonal Perspectives,Work in progress,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have shown increasing power on various natural language processing (NLP) tasks. However, tuning these models for downstream tasks usually needs exorbitant costs or is unavailable due to commercial considerations. Recently, black-box tuning has been proposed to address this problem by optimizing task-specific prompts without accessing the gradients and hidden representations. However, most existing works have yet fully exploited the potential of gradient-free optimization under the scenario of few-shot learning. In this paper, we describe BBT-RGB, a suite of straightforward and complementary techniques for enhancing the efficiency and performance of black-box optimization. Specifically, our method includes three plug-and-play components: (1) Two-stage derivative-free optimization strategy that facilitates fast convergence and mitigates overfitting; (2) Automatic verbalizer construction with its novel usage under few-shot settings; (3) Better prompt initialization policy based on instruction search and auto-selected demonstration. Extensive experiments across various tasks on natural language understanding and inference demonstrate the effectiveness of our method. Our codes are publicly available at https://github.com/QiushiSun/BBT-RGB. ","[{'version': 'v1', 'created': 'Sun, 14 May 2023 07:33:59 GMT'}]",2023-05-16,"[['Sun', 'Qiushi', ''], ['Han', 'Chengcheng', ''], ['Chen', 'Nuo', ''], ['Zhu', 'Renyu', ''], ['Gong', 'Jingyang', ''], ['Li', 'Xiang', ''], ['Gao', 'Ming', '']]",0,0,2023-05-14,1,7,2,0,0,0,41c271154cb8be6e36ce97ca06cbbadf15c82538,258685392.0,https://www.semanticscholar.org/paper/41c271154cb8be6e36ce97ca06cbbadf15c82538,arXiv.org,2023.0,45.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112455065', 'name': 'Qiushi Sun'}, {'authorId': '2118641672', 'name': 'Chengcheng Han'}, {'authorId': '119895609', 'name': 'Nuo Chen'}, {'authorId': '2029491250', 'name': 'Renyu Zhu'}, {'authorId': '2112951890', 'name': 'Jing Gong'}, {'authorId': '32551341', 'name': 'Xiang Lisa Li'}, {'authorId': '2147415336', 'name': 'Ming Gao'}]","['National University of Singapore', 'University of Wollongong']","['Singapore', 'Australia']",2023-05
2305.08495,Moritz Plenz,"Moritz Plenz, Juri Opitz, Philipp Heinisch, Philipp Cimiano, Anette
  Frank",Similarity-weighted Construction of Contextualized Commonsense Knowledge Graphs for Knowledge-intense Argumentation Tasks,Accepted at ACL 2023,,,,cs.CL cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Arguments often do not make explicit how a conclusion follows from its premises. To compensate for this lack, we enrich arguments with structured background knowledge to support knowledge-intense argumentation tasks. We present a new unsupervised method for constructing Contextualized Commonsense Knowledge Graphs (CCKGs) that selects contextually relevant knowledge from large knowledge graphs (KGs) efficiently and at high quality. Our work goes beyond context-insensitive knowledge extraction heuristics by computing semantic similarity between KG triplets and textual arguments. Using these triplet similarities as weights, we extract contextualized knowledge paths that connect a conclusion to its premise, while maximizing similarity to the argument. We combine multiple paths into a CCKG that we optionally prune to reduce noise and raise precision. Intrinsic evaluation of the quality of our graphs shows that our method is effective for (re)constructing human explanation graphs. Manual evaluations in a large-scale knowledge selection setup confirm high recall and precision of implicit CSK in the CCKGs. Finally, we demonstrate the effectiveness of CCKGs in a knowledge-insensitive argument quality rating task, outperforming strong baselines and rivaling a GPT-3 based system. ","[{'version': 'v1', 'created': 'Mon, 15 May 2023 09:52:36 GMT'}]",2023-05-16,"[['Plenz', 'Moritz', ''], ['Opitz', 'Juri', ''], ['Heinisch', 'Philipp', ''], ['Cimiano', 'Philipp', ''], ['Frank', 'Anette', '']]",0,1,2023-05-15,1,5,2,1,0,1,354fbd86ee53a0b3f9dd7155b871de6ee634f78d,258685674.0,https://www.semanticscholar.org/paper/354fbd86ee53a0b3f9dd7155b871de6ee634f78d,Annual Meeting of the Association for Computational Linguistics,2023.0,69.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2044581521', 'name': 'Moritz Plenz'}, {'authorId': '32781138', 'name': 'J. Opitz'}, {'authorId': '2145327410', 'name': 'Philipp Heinisch'}, {'authorId': '1748977', 'name': 'P. Cimiano'}, {'authorId': '143876555', 'name': 'A. Frank'}]",['Bielefeld University'],['Germany'],2023-05
2305.08714,Chengguang Gan,Chengguang Gan and Tatsunori Mori,Sensitivity and Robustness of Large Language Models to Prompt Template in Japanese Text Classification Tasks,"Under Review. 11 pages, 8 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prompt engineering relevance research has seen a notable surge in recent years, primarily driven by advancements in pre-trained language models and large language models. However, a critical issue has been identified within this domain: the inadequate of sensitivity and robustness of these models towards Prompt Templates, particularly in lesser-studied languages such as Japanese. This paper explores this issue through a comprehensive evaluation of several representative Large Language Models (LLMs) and a widely-utilized pre-trained model(PLM). These models are scrutinized using a benchmark dataset in Japanese, with the aim to assess and analyze the performance of the current multilingual models in this context. Our experimental results reveal startling discrepancies. A simple modification in the sentence structure of the Prompt Template led to a drastic drop in the accuracy of GPT-4 from 49.21 to 25.44. This observation underscores the fact that even the highly performance GPT-4 model encounters significant stability issues when dealing with diverse Japanese prompt templates, rendering the consistency of the model's output results questionable. In light of these findings, we conclude by proposing potential research trajectories to further enhance the development and performance of Large Language Models in their current stage. ","[{'version': 'v1', 'created': 'Mon, 15 May 2023 15:19:08 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Jun 2023 02:14:20 GMT'}]",2023-06-09,"[['Gan', 'Chengguang', ''], ['Mori', 'Tatsunori', '']]",0,1,2023-05-15,2,2,2,1,0,1,de11dd9386518012fec7d6f564755b6e6cdbd241,259108969.0,https://www.semanticscholar.org/paper/de11dd9386518012fec7d6f564755b6e6cdbd241,,2023.0,17.0,3.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2180661276', 'name': 'Chengguang Gan'}, {'authorId': '1696127', 'name': 'Tatsunori Mori'}]",['Yokohama National University'],['Japan'],2023-05
2305.09402,Giuseppe Destefanis,"Giuseppe Destefanis, Silvia Bartolucci, Marco Ortu",A Preliminary Analysis on the Code Generation Capabilities of GPT-3.5 and Bard AI Models for Java Functions,,,,,cs.SE cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper evaluates the capability of two state-of-the-art artificial intelligence (AI) models, GPT-3.5 and Bard, in generating Java code given a function description. We sourced the descriptions from CodingBat.com, a popular online platform that provides practice problems to learn programming. We compared the Java code generated by both models based on correctness, verified through the platform's own test cases. The results indicate clear differences in the capabilities of the two models. GPT-3.5 demonstrated superior performance, generating correct code for approximately 90.6% of the function descriptions, whereas Bard produced correct code for 53.1% of the functions. While both models exhibited strengths and weaknesses, these findings suggest potential avenues for the development and refinement of more advanced AI-assisted code generation tools. The study underlines the potential of AI in automating and supporting aspects of software development, although further research is required to fully realize this potential. ","[{'version': 'v1', 'created': 'Tue, 16 May 2023 12:44:39 GMT'}]",2023-05-17,"[['Destefanis', 'Giuseppe', ''], ['Bartolucci', 'Silvia', ''], ['Ortu', 'Marco', '']]",0,1,2023-05-16,1,3,2,1,0,1,62f4ff467f8df260096300945e4e175da59dfe77,258714564.0,https://www.semanticscholar.org/paper/62f4ff467f8df260096300945e4e175da59dfe77,arXiv.org,2023.0,10.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2048851', 'name': 'Giuseppe Destefanis'}, {'authorId': '29027031', 'name': 'S. Bartolucci'}, {'authorId': '3348154', 'name': 'Marco Ortu'}]","['Brunel University London', 'University College London', 'University of Cagliari']","['United Kingdom', 'Italy']",2023-05
2305.10321,Atli Sigurgeirsson,"Atli Thor Sigurgeirsson, Simon King",Controllable Speaking Styles Using a Large Language Model,Submitted to ICASSP 2024,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reference-based Text-to-Speech (TTS) models can generate multiple, prosodically-different renditions of the same target text. Such models jointly learn a latent acoustic space during training, which can be sampled from during inference. Controlling these models during inference typically requires finding an appropriate reference utterance, which is non-trivial.   Large generative language models (LLMs) have shown excellent performance in various language-related tasks. Given only a natural language query text (the prompt), such models can be used to solve specific, context-dependent tasks. Recent work in TTS has attempted similar prompt-based control of novel speaking style generation. Those methods do not require a reference utterance and can, under ideal conditions, be controlled with only a prompt. But existing methods typically require a prompt-labelled speech corpus for jointly training a prompt-conditioned encoder.   In contrast, we instead employ an LLM to directly suggest prosodic modifications for a controllable TTS model, using contextual information provided in the prompt. The prompt can be designed for a multitude of tasks. Here, we give two demonstrations: control of speaking style; prosody appropriate for a given dialogue context. The proposed method is rated most appropriate in 50% of cases vs. 31% for a baseline model. ","[{'version': 'v1', 'created': 'Wed, 17 May 2023 16:01:50 GMT'}, {'version': 'v2', 'created': 'Tue, 19 Sep 2023 16:35:57 GMT'}]",2023-09-20,"[['Sigurgeirsson', 'Atli Thor', ''], ['King', 'Simon', '']]",0,0,2023-05-17,2,2,3,0,0,0,e9b949a558bb243653c3be5cb8b03b4dae19a605,258741295.0,https://www.semanticscholar.org/paper/e9b949a558bb243653c3be5cb8b03b4dae19a605,,2023.0,25.0,1.0,0.0,False,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '1725471992', 'name': 'A. Sigurgeirsson'}, {'authorId': '144783569', 'name': 'Simon King'}]",['University of Edinburgh'],['United Kingdom'],2023-05
2305.10449,Khubaib Ahmed,"Ahsan Adeel, Junaid Muzaffar, Khubaib Ahmed, Mohsin Raza",Cooperation Is All You Need,,,,,cs.LG cs.AI cs.NE,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Going beyond 'dendritic democracy', we introduce a 'democracy of local processors', termed Cooperator. Here we compare their capabilities when used in permutation-invariant neural networks for reinforcement learning (RL), with machine learning algorithms based on Transformers, such as ChatGPT. Transformers are based on the long-standing conception of integrate-and-fire 'point' neurons, whereas Cooperator is inspired by recent neurobiological breakthroughs suggesting that the cellular foundations of mental life depend on context-sensitive pyramidal neurons in the neocortex which have two functionally distinct points. We show that when used for RL, an algorithm based on Cooperator learns far quicker than that based on Transformer, even while having the same number of parameters. ","[{'version': 'v1', 'created': 'Tue, 16 May 2023 16:48:12 GMT'}]",2023-05-19,"[['Adeel', 'Ahsan', ''], ['Muzaffar', 'Junaid', ''], ['Ahmed', 'Khubaib', ''], ['Raza', 'Mohsin', '']]",1,1,2023-05-16,1,4,3,1,0,1,d2a870d79c0a233a87f2caa068cdd5ea22ecc78e,258762338.0,https://www.semanticscholar.org/paper/d2a870d79c0a233a87f2caa068cdd5ea22ecc78e,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064500', 'name': 'A. Adeel'}, {'authorId': '51331437', 'name': 'Junaid Muzaffar'}, {'authorId': '1455867573', 'name': 'Khubaib Ahmed'}, {'authorId': '2145517370', 'name': 'Mohsin Raza'}]","['University of Stirling', 'University of Wolverhampton', 'deepCI.org, Parkside Terrace, Edinburgh, UK.', 'University of Oxford']",['United Kingdom'],2023-05
2305.10475,Jonas Spinner,"Anja Butter, Nathan Huetsch, Sofia Palacios Schweitzer, Tilman Plehn,
  Peter Sorrenson, Jonas Spinner",Jet Diffusion versus JetGPT -- Modern Networks for the LHC,"37 pages, 17 figures",,,,hep-ph,http://creativecommons.org/licenses/by/4.0/,"  We introduce two diffusion models and an autoregressive transformer for LHC physics simulations. Bayesian versions allow us to control the networks and capture training uncertainties. After illustrating their different density estimation methods for simple toy models, we discuss their advantages for Z plus jets event generation. While diffusion networks excel through their precision, the transformer scales best with the phase space dimensionality. Given the different training and evaluation speed, we expect LHC physics to benefit from dedicated use cases for normalizing flows, diffusion models, and autoregressive transformers. ","[{'version': 'v1', 'created': 'Wed, 17 May 2023 18:00:00 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Jun 2023 13:52:55 GMT'}]",2023-06-23,"[['Butter', 'Anja', ''], ['Huetsch', 'Nathan', ''], ['Schweitzer', 'Sofia Palacios', ''], ['Plehn', 'Tilman', ''], ['Sorrenson', 'Peter', ''], ['Spinner', 'Jonas', '']]",0,1,2023-05-17,2,6,1,0,0,0,adfac60845f7d20b9630ae75139cad0b816f384f,258762569.0,https://www.semanticscholar.org/paper/adfac60845f7d20b9630ae75139cad0b816f384f,,2023.0,84.0,10.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '80350870', 'name': 'A. Butter'}, {'authorId': '2217761547', 'name': 'Nathan Huetsch'}, {'authorId': '2217536008', 'name': 'Sofia Palacios Schweitzer'}, {'authorId': '3578208', 'name': 'T. Plehn'}, {'authorId': '147845044', 'name': 'P. Sorrenson'}, {'authorId': '2076563099', 'name': 'Jonas Spinner'}]","['Université Paris Cité', 'Heidelberg University']","['Germany', 'France']",2023-05
2305.10568,Vered Shwartz,Jordan Coil and Vered Shwartz,From chocolate bunny to chocolate crocodile: Do Language Models Understand Noun Compounds?,Findings of ACL 2023,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Noun compound interpretation is the task of expressing a noun compound (e.g. chocolate bunny) in a free-text paraphrase that makes the relationship between the constituent nouns explicit (e.g. bunny-shaped chocolate). We propose modifications to the data and evaluation setup of the standard task (Hendrickx et al., 2013), and show that GPT-3 solves it almost perfectly. We then investigate the task of noun compound conceptualization, i.e. paraphrasing a novel or rare noun compound. E.g., chocolate crocodile is a crocodile-shaped chocolate. This task requires creativity, commonsense, and the ability to generalize knowledge about similar concepts. While GPT-3's performance is not perfect, it is better than that of humans -- likely thanks to its access to vast amounts of knowledge, and because conceptual processing is effortful for people (Connell and Lynott, 2012). Finally, we estimate the extent to which GPT-3 is reasoning about the world vs. parroting its training data. We find that the outputs from GPT-3 often have significant overlap with a large web corpus, but that the parroting strategy is less beneficial for novel noun compounds. ","[{'version': 'v1', 'created': 'Wed, 17 May 2023 21:05:23 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 21:30:11 GMT'}]",2023-05-26,"[['Coil', 'Jordan', ''], ['Shwartz', 'Vered', '']]",0,1,2023-05-17,2,2,1,1,0,1,1cc45dd8a190a4a0aae44ddd100c797965853d78,258762197.0,https://www.semanticscholar.org/paper/1cc45dd8a190a4a0aae44ddd100c797965853d78,Annual Meeting of the Association for Computational Linguistics,2023.0,42.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2217756936', 'name': 'Jordan Coil'}, {'authorId': '3103343', 'name': 'Vered Shwartz'}]","['University of British Columbia', 'Vector Institute']",['Canada'],2023-05
2305.10645,Peter Ochieng,Peter Ochieng,Are Large Language Models Fit For Guided Reading?,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper looks at the ability of large language models to participate in educational guided reading. We specifically, evaluate their ability to generate meaningful questions from the input text, generate diverse questions both in terms of content coverage and difficulty of the questions and evaluate their ability to recommend part of the text that a student should re-read based on the student's responses to the questions. Based on our evaluation of ChatGPT and Bard, we report that,   1) Large language models are able to generate high quality meaningful questions that have high correlation with the input text, 2) They generate diverse question that cover most topics in the input text even though this ability is significantly degraded as the input text increases, 3)The large language models are able to generate both low and high cognitive questions even though they are significantly biased toward low cognitive question, 4) They are able to effectively summarize responses and extract a portion of text that should be re-read. ","[{'version': 'v1', 'created': 'Thu, 18 May 2023 02:03:55 GMT'}, {'version': 'v2', 'created': 'Fri, 19 May 2023 10:47:56 GMT'}]",2023-05-22,"[['Ochieng', 'Peter', '']]",1,1,2023-05-18,2,1,1,1,0,1,758398ee88208cd32fcf86e37e56ba9ae257d8d0,258762487.0,https://www.semanticscholar.org/paper/758398ee88208cd32fcf86e37e56ba9ae257d8d0,arXiv.org,2023.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145989909', 'name': 'Peter Ochieng'}]",['University of Cambridge'],['United Kingdom'],2023-05
2305.10646,Jianlong Zhou,"Jianlong Zhou, Heimo M\""uller, Andreas Holzinger and Fang Chen","Ethical ChatGPT: Concerns, Challenges, and Commandments","8 pages, 2 figures",,,,cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Large language models, e.g. ChatGPT are currently contributing enormously to make artificial intelligence even more popular, especially among the general population. However, such chatbot models were developed as tools to support natural language communication between humans. Problematically, it is very much a ``statistical correlation machine"" (correlation instead of causality) and there are indeed ethical concerns associated with the use of AI language models such as ChatGPT, such as Bias, Privacy, and Abuse. This paper highlights specific ethical concerns on ChatGPT and articulates key challenges when ChatGPT is used in various applications. Practical commandments for different stakeholders of ChatGPT are also proposed that can serve as checklist guidelines for those applying ChatGPT in their applications. These commandment examples are expected to motivate the ethical use of ChatGPT. ","[{'version': 'v1', 'created': 'Thu, 18 May 2023 02:04:13 GMT'}]",2023-05-19,"[['Zhou', 'Jianlong', ''], ['Müller', 'Heimo', ''], ['Holzinger', 'Andreas', ''], ['Chen', 'Fang', '']]",1,1,2023-05-18,1,4,2,1,0,1,aa4fdaf3a6e8e01ff32bb8d35792601ecc35b119,258762840.0,https://www.semanticscholar.org/paper/aa4fdaf3a6e8e01ff32bb8d35792601ecc35b119,arXiv.org,2023.0,20.0,12.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51239629', 'name': 'Jianlong Zhou'}, {'authorId': '2151194287', 'name': 'Heimo Müller'}, {'authorId': '47596587', 'name': 'Andreas Holzinger'}, {'authorId': '145093625', 'name': 'Fang Chen'}]","['University of Technology Sydney', 'Medical University of Graz', 'University of Natural Resources and Life Sciences, Vienna']","['Austria', 'Australia']",2023-05
2305.10833,Damith Premasiri Dola Mullage,"Amal Haddad Haddad, Damith Premasiri, Tharindu Ranasinghe, Ruslan
  Mitkov",Deep Learning Methods for Extracting Metaphorical Names of Flowers and Plants,Accepted for SEPLN 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The domain of Botany is rich with metaphorical terms. Those terms play an important role in the description and identification of flowers and plants. However, the identification of such terms in discourse is an arduous task. This leads in some cases to committing errors during translation processes and lexicographic tasks. The process is even more challenging when it comes to machine translation, both in the cases of single-word terms and multi-word terms. One of the recent concerns of Natural Language Processing (NLP) applications and Machine Translation (MT) technologies is the automatic identification of metaphor-based words in discourse through Deep Learning (DL). In this study, we seek to fill this gap through the use of thirteen popular transformer based models, as well as ChatGPT, and we show that discriminative models perform better than GPT-3.5 model with our best performer reporting 92.2349% F1 score in metaphoric flower and plant names identification task. ","[{'version': 'v1', 'created': 'Thu, 18 May 2023 09:22:29 GMT'}, {'version': 'v2', 'created': 'Sun, 21 May 2023 16:01:02 GMT'}, {'version': 'v3', 'created': 'Thu, 1 Jun 2023 13:59:23 GMT'}]",2023-06-02,"[['Haddad', 'Amal Haddad', ''], ['Premasiri', 'Damith', ''], ['Ranasinghe', 'Tharindu', ''], ['Mitkov', 'Ruslan', '']]",1,1,2023-05-18,3,4,1,2,0,2,44790aba0b113540ff3146c816b88ebf62605e51,258762393.0,https://www.semanticscholar.org/paper/44790aba0b113540ff3146c816b88ebf62605e51,Proces. del Leng. Natural,2023.0,61.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144477956', 'name': 'A. Haddad'}, {'authorId': '2082137995', 'name': 'Damith Premasiri'}, {'authorId': '134805041', 'name': 'Tharindu Ranasinghe'}, {'authorId': '1746371', 'name': 'R. Mitkov'}]","['University of Granada', 'University of Wolverhampton', 'Lancaster University', 'Aston University']","['United Kingdom', 'Spain']",2023-05
2305.10945,Christian Becker-Asano,Marcel Heisler and Christian Becker-Asano,An Android Robot Head as Embodied Conversational Agent,,,,,cs.RO,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper describes, how current Machine Learning (ML) techniques combined with simple rule-based animation routines make an android robot head an embodied conversational agent with ChatGPT as its core component. The android robot head is described, technical details are given of how lip-sync animation is being achieved, and general software design decisions are presented. A public presentation of the system revealed improvement opportunities that are reported and that lead our iterative implementation approach. ","[{'version': 'v1', 'created': 'Thu, 18 May 2023 13:05:10 GMT'}]",2023-05-19,"[['Heisler', 'Marcel', ''], ['Becker-Asano', 'Christian', '']]",1,1,2023-05-18,1,2,1,1,0,1,f85379c07b6abb25483db79410a96762bba7f552,258762170.0,https://www.semanticscholar.org/paper/f85379c07b6abb25483db79410a96762bba7f552,arXiv.org,2023.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2217471473', 'name': 'Marcel Heisler'}, {'authorId': '1403827243', 'name': 'C. Becker-Asano'}]",['Stuttgart Media University'],['Germany'],2023-05
2305.11023,Harshil Shah,"Harshil Shah, Arthur Wilcke, Marius Cobzarenco, Cristi Cobzarenco,
  Edward Challis, David Barber",Generalized Multiple Intent Conditioned Slot Filling,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Natural language understanding includes the tasks of intent detection (identifying a user's objectives) and slot filling (extracting the entities relevant to those objectives). Prior slot filling methods assume that each intent type cannot occur more than once within a message, however this is often not a valid assumption for real-world settings. In this work, we generalize slot filling by removing the constraint of unique intents in a message. We cast this as a JSON generation task and approach it using a language model. We create a pre-training dataset by combining DBpedia and existing slot filling datasets that we convert for JSON generation. We also generate an in-domain dataset using GPT-3. We train T5 models for this task (with and without exemplars in the prompt) and find that both training datasets improve performance, and that the model is able to generalize to intent types not seen during training. ","[{'version': 'v1', 'created': 'Thu, 18 May 2023 15:04:52 GMT'}]",2023-05-19,"[['Shah', 'Harshil', ''], ['Wilcke', 'Arthur', ''], ['Cobzarenco', 'Marius', ''], ['Cobzarenco', 'Cristi', ''], ['Challis', 'Edward', ''], ['Barber', 'David', '']]",0,1,2023-05-18,1,6,1,2,1,1,dad59b4e020de299607e221a1f9f432198d94a75,258762722.0,https://www.semanticscholar.org/paper/dad59b4e020de299607e221a1f9f432198d94a75,arXiv.org,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46797601', 'name': 'Harshil Shah'}, {'authorId': '2217532850', 'name': 'Arthur Wilcke'}, {'authorId': '3238115', 'name': 'Marius Cobzarenco'}, {'authorId': '2080822756', 'name': 'Cristian C Cobzarenco'}, {'authorId': '2061185', 'name': 'Edward Challis'}, {'authorId': '2056214882', 'name': 'David Barber'}]",['University College London'],['United Kingdom'],2023-05
2305.11064,Piotr Sawicki,"Piotr Sawicki, Marek Grzes, Fabricio Goes, Dan Brown, Max Peeperkorn,
  Aisha Khatun",Bits of Grass: Does GPT already know how to write like Whitman?,short paper 5 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This study examines the ability of GPT-3.5, GPT-3.5-turbo (ChatGPT) and GPT-4 models to generate poems in the style of specific authors using zero-shot and many-shot prompts (which use the maximum context length of 8192 tokens). We assess the performance of models that are not fine-tuned for generating poetry in the style of specific authors, via automated evaluation. Our findings indicate that without fine-tuning, even when provided with the maximum number of 17 poem examples (8192 tokens) in the prompt, these models do not generate poetry in the desired style. ","[{'version': 'v1', 'created': 'Wed, 10 May 2023 09:02:34 GMT'}]",2023-05-19,"[['Sawicki', 'Piotr', ''], ['Grzes', 'Marek', ''], ['Goes', 'Fabricio', ''], ['Brown', 'Dan', ''], ['Peeperkorn', 'Max', ''], ['Khatun', 'Aisha', '']]",1,1,2023-05-10,1,6,1,3,0,3,0fb6ce7f5d73d7121ff7c36488f070d41e3779a5,258762462.0,https://www.semanticscholar.org/paper/0fb6ce7f5d73d7121ff7c36488f070d41e3779a5,arXiv.org,2023.0,12.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2185736769', 'name': 'Piotr Sawicki'}, {'authorId': '2186376', 'name': 'M. Grzes'}, {'authorId': '2074488337', 'name': 'Fabrício Góes'}, {'authorId': '2185791771', 'name': 'Daniel Brown'}, {'authorId': '1396460590', 'name': 'M. Peeperkorn'}, {'authorId': '2063969212', 'name': 'Aisha Khatun'}]","['University of Leicester', 'University of Waterloo', 'University of Kent']","['Canada', 'United Kingdom']",2023-05
2305.11067,Ze Jin,"Ze Jin, Zorina Song",Generating coherent comic with rich story using ChatGPT and Stable Diffusion,,,,,cs.CV cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Past work demonstrated that using neural networks, we can extend unfinished music pieces while maintaining the music style of the musician. With recent advancements in large language models and diffusion models, we are now capable of generating comics with an interesting storyline while maintaining the art style of the artist. In this paper, we used ChatGPT to generate storylines and dialogue and then generated the comic using stable diffusion. We introduced a novel way to evaluate AI-generated stories, and we achieved SOTA performance on character fidelity and art style by fine-tuning stable diffusion using LoRA, ControlNet, etc. ","[{'version': 'v1', 'created': 'Tue, 16 May 2023 13:11:45 GMT'}, {'version': 'v2', 'created': 'Fri, 19 May 2023 02:04:56 GMT'}]",2023-05-22,"[['Jin', 'Ze', ''], ['Song', 'Zorina', '']]",1,1,2023-05-16,2,2,3,1,0,1,7787efaf502421eac9b6b0fd946a82e1ecf4c8c9,258762379.0,https://www.semanticscholar.org/paper/7787efaf502421eac9b6b0fd946a82e1ecf4c8c9,arXiv.org,2023.0,23.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2217457477', 'name': 'Ze Jin'}, {'authorId': '2217457760', 'name': 'Zorina Song'}]",['University of Toronto'],['Canada'],2023-05
2305.11262,Jiaxu Zhao,"Jiaxu Zhao, Meng Fang, Zijing Shi, Yitong Li, Ling Chen, Mykola
  Pechenizkiy",CHBias: Bias Evaluation and Mitigation of Chinese Conversational Language Models,Accepted by ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  \textit{\textbf{\textcolor{red}{Warning}:} This paper contains content that may be offensive or upsetting.} Pretrained conversational agents have been exposed to safety issues, exhibiting a range of stereotypical human biases such as gender bias. However, there are still limited bias categories in current research, and most of them only focus on English. In this paper, we introduce a new Chinese dataset, CHBias, for bias evaluation and mitigation of Chinese conversational language models. Apart from those previous well-explored bias categories, CHBias includes under-explored bias categories, such as ageism and appearance biases, which received less attention. We evaluate two popular pretrained Chinese conversational models, CDial-GPT and EVA2.0, using CHBias. Furthermore, to mitigate different biases, we apply several debiasing methods to the Chinese pretrained models. Experimental results show that these Chinese pretrained models are potentially risky for generating texts that contain social biases, and debiasing methods using the proposed dataset can make response generation less biased while preserving the models' conversational capabilities. ","[{'version': 'v1', 'created': 'Thu, 18 May 2023 18:58:30 GMT'}]",2023-05-22,"[['Zhao', 'Jiaxu', ''], ['Fang', 'Meng', ''], ['Shi', 'Zijing', ''], ['Li', 'Yitong', ''], ['Chen', 'Ling', ''], ['Pechenizkiy', 'Mykola', '']]",0,1,2023-05-18,1,6,1,0,0,0,839cc546b58968e2a8cb968337fb2e3a279e2b00,258823380.0,https://www.semanticscholar.org/paper/839cc546b58968e2a8cb968337fb2e3a279e2b00,Annual Meeting of the Association for Computational Linguistics,2023.0,47.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '1481819499', 'name': 'Jiaxu Zhao'}, {'authorId': '2111764425', 'name': 'Meng Fang'}, {'authorId': '2110009929', 'name': 'Zijing Shi'}, {'authorId': '50024168', 'name': 'Yitong Li'}, {'authorId': '2145142074', 'name': 'Ling Chen'}, {'authorId': '1691997', 'name': 'Mykola Pechenizkiy'}]","['University of Technology Sydney', 'University of Liverpool', 'Eindhoven University of Technology']","['United Kingdom', 'Netherlands', 'Australia']",2023-05
2305.11334,Giorgi Kokaia,"Giorgi Kokaia, Pratyush Sinha, Yutong Jiang, Nozha Boujemaa",Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We introduce two novel methods, Tree-Search and Self-contextualizing QA, designed to enhance the performance of large language models (LLMs) in question-answering tasks. Tree-Search is a sampling technique specifically created to extract diverse information from an LLM for a given prompt. Self-contextualizing QA leverages Tree-Search to enable the model to create its own context using a wide range of information relevant to the prompt, evaluate it explicitly and return a open book answer to the initial prompt . We demonstrate that the quality of generated answers improves according to various metrics, including accuracy, informativeness, coherence, and consistency, as evaluated by GPT3.5(text-davinci-003). Furthermore, we show that our methods result in increased robustness and that performance is positively correlated with tree size, benefiting both answer quality and robustness. Finally, we discuss other promising applications of Tree-Search, highlighting its potential to enhance a broad range of tasks beyond question-answering.   \noindent We also discuss several areas for future work, including refining the Tree-Search and Self-Contextualizing QA methods, improving the coherence of the generated context, and investigating the impact of bootstrapping on model robustness ","[{'version': 'v1', 'created': 'Thu, 18 May 2023 22:47:06 GMT'}]",2023-05-22,"[['Kokaia', 'Giorgi', ''], ['Sinha', 'Pratyush', ''], ['Jiang', 'Yutong', ''], ['Boujemaa', 'Nozha', '']]",0,1,2023-05-18,1,4,2,1,0,1,a9fa994e1d0638c4291ceb4a429951d53fcb8f69,258822844.0,https://www.semanticscholar.org/paper/a9fa994e1d0638c4291ceb4a429951d53fcb8f69,arXiv.org,2023.0,3.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '88727637', 'name': 'Giorgi Kokaia'}, {'authorId': '2055128513', 'name': 'Pratyush Sinha'}, {'authorId': '2116204040', 'name': 'Yutong Jiang'}, {'authorId': '1741155', 'name': 'N. Boujemaa'}]","['KTH Royal Institute of Technology', 'Ingka (IKEA)']",['Sweden'],2023-05
2305.11554,Shibo Hao,"Shibo Hao, Tianyang Liu, Zhen Wang, Zhiting Hu",ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings,"Add code link and appendix. Code:
  https://github.com/Ber666/ToolkenGPT",,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Augmenting large language models (LLMs) with external tools has emerged as a promising approach to solving complex problems. However, traditional methods, which finetune LLMs with tool demonstration data, can be both costly and restricted to a predefined set of tools. Recent in-context learning paradigm alleviates these issues, but the limited context length only allows for a few shots of demonstrations, leading to suboptimal understandings of the tools. Moreover, when there are numerous tools to choose from, in-context learning could completely fail to work. In this paper, we propose an alternative approach, $\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our approach represents each $\underline{tool}$ as a to$\underline{ken}$ ($\textit{toolken}$) and learns an embedding for it, enabling tool calls in the same way as generating a regular word token. Once a toolken is triggered, the LLM is prompted to complete arguments for the tool to execute. ToolkenGPT offers the flexibility to plug in an arbitrary number of tools by expanding the set of toolkens on the fly. In addition, it improves tool use by allowing extensive demonstration data for learning the toolken embeddings. In diverse domains, including numerical reasoning, knowledge-based question answering, and embodied plan generation, our approach effectively augments LLMs with tools and substantially outperforms various latest baselines. ToolkenGPT demonstrates the promising ability to use relevant tools from a large tool set in complex scenarios. ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 09:54:21 GMT'}, {'version': 'v2', 'created': 'Thu, 22 Jun 2023 07:58:56 GMT'}]",2023-06-23,"[['Hao', 'Shibo', ''], ['Liu', 'Tianyang', ''], ['Wang', 'Zhen', ''], ['Hu', 'Zhiting', '']]",0,1,2023-05-19,2,4,2,0,0,0,c7a3f9cc61cfafdc307f8ae24430b6b1121f9b2c,258823133.0,https://www.semanticscholar.org/paper/c7a3f9cc61cfafdc307f8ae24430b6b1121f9b2c,arXiv.org,2023.0,86.0,25.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2128965713', 'name': 'Shibo Hao'}, {'authorId': '2115347044', 'name': 'Tianyang Liu'}, {'authorId': '47197370', 'name': 'Zhen Wang'}, {'authorId': '2749311', 'name': 'Zhiting Hu'}]",['Mohamed bin Zayed University of Artificial Intelligence'],['United Arab Emirates'],2023-05
2305.11627,Xinyin Ma,"Xinyin Ma, Gongfan Fang, Xinchao Wang",LLM-Pruner: On the Structural Pruning of Large Language Models,Accepted at NeurIPS 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have shown remarkable capabilities in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges in both the deployment, inference, and training stages. With LLM being a general-purpose task solver, we explore its compression in a task-agnostic manner, which aims to preserve the multi-task solving and language generation ability of the original LLM. One challenge to achieving this is the enormous size of the training corpus of LLM, which makes both data transfer and model post-training over-burdensome. Thus, we tackle the compression of LLMs within the bound of two constraints: being task-agnostic and minimizing the reliance on the original training dataset. Our method, named LLM-Pruner, adopts structural pruning that selectively removes non-critical coupled structures based on gradient information, maximally preserving the majority of the LLM's functionality. To this end, the performance of pruned models can be efficiently recovered through tuning techniques, LoRA, in merely 3 hours, requiring only 50K data. We validate the LLM-Pruner on three LLMs, including LLaMA, Vicuna, and ChatGLM, and demonstrate that the compressed models still exhibit satisfactory capabilities in zero-shot classification and generation. The code is available at: https://github.com/horseee/LLM-Pruner ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 12:10:53 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Jun 2023 08:05:02 GMT'}, {'version': 'v3', 'created': 'Thu, 28 Sep 2023 03:59:27 GMT'}]",2023-09-29,"[['Ma', 'Xinyin', ''], ['Fang', 'Gongfan', ''], ['Wang', 'Xinchao', '']]",0,0,2023-05-19,3,3,1,3,3,0,017010b941d902a467f6d329ae5e74fd67e67912,258823276.0,https://www.semanticscholar.org/paper/017010b941d902a467f6d329ae5e74fd67e67912,arXiv.org,2023.0,70.0,34.0,5.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '15532066', 'name': 'Xinyin Ma'}, {'authorId': '150110431', 'name': 'Gongfan Fang'}, {'authorId': '48631088', 'name': 'Xinchao Wang'}]",['National University of Singapore'],['Singapore'],2023-05
2305.11662,Xenia Ohmer,"Xenia Ohmer, Elia Bruni, Dieuwke Hupkes",Separating form and meaning: Using self-consistency to quantify task understanding across multiple senses,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  At the staggering pace with which the capabilities of large language models (LLMs) are increasing, creating future-proof evaluation sets to assess their understanding becomes more and more challenging. In this paper, we propose a novel paradigm for evaluating LLMs which leverages the idea that correct world understanding should be consistent across different (Fregean) senses of the same meaning. Accordingly, we measure understanding not in terms of correctness but by evaluating consistency across multiple senses that are generated by the model itself. We showcase our approach by instantiating a test where the different senses are different languages, hence using multilingual self-consistency as a litmus test for the model's understanding and simultaneously addressing the important topic of multilingualism. Taking one of the latest versions of ChatGPT as our object of study, we evaluate multilingual consistency for two different tasks across three different languages. We show that its multilingual consistency is still lacking, and that its task and world understanding are thus not language-independent. As our approach does not require any static evaluation corpora in languages other than English, it can easily and cheaply be extended to different languages and tasks and could become an integral part of future benchmarking efforts. ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 13:23:51 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 15:12:45 GMT'}]",2023-05-24,"[['Ohmer', 'Xenia', ''], ['Bruni', 'Elia', ''], ['Hupkes', 'Dieuwke', '']]",1,1,2023-05-19,2,3,2,1,0,1,fe351626811e31e9352e7ea497f139eb09ae20d1,258840917.0,https://www.semanticscholar.org/paper/fe351626811e31e9352e7ea497f139eb09ae20d1,arXiv.org,2023.0,41.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '4573107', 'name': 'Xenia Ohmer'}, {'authorId': '2552871', 'name': 'Elia Bruni'}, {'authorId': '3449411', 'name': 'D. Hupkes'}]",['Osnabrück University'],['Germany'],2023-05
2305.11837,Nathalia Nascimento,Nathalia Nascimento and Paulo Alencar and Donald Cowan,Comparing Software Developers with ChatGPT: An Empirical Investigation,12 pages,,,,cs.SE cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The advent of automation in particular Software Engineering (SE) tasks has transitioned from theory to reality. Numerous scholarly articles have documented the successful application of Artificial Intelligence to address issues in areas such as project management, modeling, testing, and development. A recent innovation is the introduction of ChatGPT, an ML-infused chatbot, touted as a resource proficient in generating programming codes and formulating software testing strategies for developers and testers respectively. Although there is speculation that AI-based computation can increase productivity and even substitute software engineers in software development, there is currently a lack of empirical evidence to verify this. Moreover, despite the primary focus on enhancing the accuracy of AI systems, non-functional requirements including energy efficiency, vulnerability, fairness (i.e., human bias), and safety frequently receive insufficient attention. This paper posits that a comprehensive comparison of software engineers and AI-based solutions, considering various evaluation criteria, is pivotal in fostering human-machine collaboration, enhancing the reliability of AI-based methods, and understanding task suitability for humans or AI. Furthermore, it facilitates the effective implementation of cooperative work structures and human-in-the-loop processes. This paper conducts an empirical investigation, contrasting the performance of software engineers and AI systems, like ChatGPT, across different evaluation metrics. The empirical study includes a case of assessing ChatGPT-generated code versus code produced by developers and uploaded in Leetcode. ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 17:25:54 GMT'}, {'version': 'v2', 'created': 'Thu, 25 May 2023 14:58:39 GMT'}]",2023-05-26,"[['Nascimento', 'Nathalia', ''], ['Alencar', 'Paulo', ''], ['Cowan', 'Donald', '']]",1,1,2023-05-19,2,3,2,1,0,1,593f09d45febc552b22d0073909693975c443f79,258823292.0,https://www.semanticscholar.org/paper/593f09d45febc552b22d0073909693975c443f79,arXiv.org,2023.0,27.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2658311', 'name': 'N. Nascimento'}, {'authorId': '143937733', 'name': 'P. Alencar'}, {'authorId': '2149928782', 'name': 'Donald D. Cowan'}]",['University of Waterloo'],['Canada'],2023-05
2305.11854,Hiroki Furuta,"Hiroki Furuta, Kuang-Huei Lee, Ofir Nachum, Yutaka Matsuo, Aleksandra
  Faust, Shixiang Shane Gu, Izzeddin Gur",Multimodal Web Navigation with Instruction-Finetuned Foundation Models,Website: https://sites.google.com/view/mm-webnav/,,,,cs.LG cs.AI stat.ML,http://creativecommons.org/licenses/by/4.0/,"  The progress of autonomous web navigation has been hindered by the dependence on billions of exploratory interactions via online reinforcement learning, and domain-specific model designs that make it difficult to leverage generalization from rich out-of-domain data. In this work, we study data-driven offline training for web agents with vision-language foundation models. We propose an instruction-following multimodal agent, WebGUM, that observes both webpage screenshots and HTML pages and outputs web navigation actions, such as click and type. WebGUM is trained by jointly finetuning an instruction-finetuned language model and a vision encoder with temporal and local perception on a large corpus of demonstrations. We empirically demonstrate this recipe improves the agent's ability of grounded multimodal perception, HTML comprehension, and multi-step reasoning, outperforming prior works by a significant margin. On the MiniWoB, we improve over the previous best offline methods by more than 45.8%, even outperforming online-finetuned SoTA, humans, and GPT-4-based agent. On the WebShop benchmark, our 3-billion-parameter model achieves superior performance to the existing SoTA, PaLM-540B. Furthermore, WebGUM exhibits strong positive transfer to the real-world planning tasks on the Mind2Web. We also collect 347K high-quality demonstrations using our trained models, 38 times larger than prior work, and make them available to promote future research in this direction. ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 17:44:34 GMT'}, {'version': 'v2', 'created': 'Sun, 1 Oct 2023 10:15:01 GMT'}]",2023-10-03,"[['Furuta', 'Hiroki', ''], ['Lee', 'Kuang-Huei', ''], ['Nachum', 'Ofir', ''], ['Matsuo', 'Yutaka', ''], ['Faust', 'Aleksandra', ''], ['Gu', 'Shixiang Shane', ''], ['Gur', 'Izzeddin', '']]",0,1,2023-05-19,2,7,3,2,0,2,5692501c10d0c1762842f92c66fcf0bffe2c0342,258823350.0,https://www.semanticscholar.org/paper/5692501c10d0c1762842f92c66fcf0bffe2c0342,arXiv.org,2023.0,110.0,8.0,2.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2052903664', 'name': 'Hiroki Furuta'}, {'authorId': '7624658', 'name': 'Ofir Nachum'}, {'authorId': '2145145412', 'name': 'Kuang-Huei Lee'}, {'authorId': '2153732825', 'name': 'Yutaka Matsuo'}, {'authorId': '2046135', 'name': 'S. Gu'}, {'authorId': '3737312', 'name': 'Izzeddin Gur'}]","['Google', 'The University of Tokyo']","['Japan', 'United Kingdom']",2023-05
2305.11862,Masahiro Kaneko,"Masahiro Kaneko, Naoaki Okazaki",Reducing Sequence Length by Predicting Edit Operations with Large Language Models,Work in progress,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have demonstrated remarkable performance in various tasks and gained significant attention. LLMs are also used for local sequence transduction tasks, including grammatical error correction (GEC) and formality style transfer, where most tokens in a source text are kept unchanged. However, it is inefficient to generate all target tokens because a prediction error of a target token may cause a catastrophe in predicting subsequent tokens and because the computational cost grows quadratically with the target sequence length. This paper proposes to predict a set of edit operations for the source text for local sequence transduction tasks. Representing an edit operation with a span of the source text and changed tokens, we can reduce the length of the target sequence and thus the computational cost for inference. We apply instruction tuning for LLMs on the supervision data of edit operations. Experiments show that the proposed method achieves comparable performance to the baseline in four tasks, paraphrasing, formality style transfer, GEC, and text simplification, despite reducing the length of the target text by as small as 21\%. Furthermore, we report that the instruction tuning with the proposed method achieved the state-of-the-art performance in the four tasks. ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 17:51:05 GMT'}]",2023-05-22,"[['Kaneko', 'Masahiro', ''], ['Okazaki', 'Naoaki', '']]",0,0,2023-05-19,1,2,1,0,0,0,417edcd9dc4a4ad6de36810bfb44c7871d8c8633,258823266.0,https://www.semanticscholar.org/paper/417edcd9dc4a4ad6de36810bfb44c7871d8c8633,arXiv.org,2023.0,83.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143655216', 'name': 'Masahiro Kaneko'}, {'authorId': '1764004', 'name': 'Naoaki Okazaki'}]",['Tokyo Institute of Technology'],['Japan'],2023-05
2305.11873,Pawe{\l} Niszczota,"Pawe{\l} Niszczota, Paul Conway",Judgments of research co-created by generative AI: experimental evidence,"10 pages, 2 tables, 1 figure",,,,cs.HC cs.AI cs.CL cs.CY econ.GN q-fin.EC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The introduction of ChatGPT has fuelled a public debate on the use of generative AI (large language models; LLMs), including its use by researchers. In the current work, we test whether delegating parts of the research process to LLMs leads people to distrust and devalue researchers and scientific output. Participants (N=402) considered a researcher who delegates elements of the research process to a PhD student or LLM, and rated (1) moral acceptability, (2) trust in the scientist to oversee future projects, and (3) the accuracy and quality of the output. People judged delegating to an LLM as less acceptable than delegating to a human (d = -0.78). Delegation to an LLM also decreased trust to oversee future research projects (d = -0.80), and people thought the results would be less accurate and of lower quality (d = -0.85). We discuss how this devaluation might transfer into the underreporting of generative AI use. ","[{'version': 'v1', 'created': 'Wed, 3 May 2023 15:57:39 GMT'}]",2023-05-23,"[['Niszczota', 'Paweł', ''], ['Conway', 'Paul', '']]",1,1,2023-05-03,1,2,6,1,0,1,eed442fa65e2923872b471b0784247d54c681ed3,258833386.0,https://www.semanticscholar.org/paper/eed442fa65e2923872b471b0784247d54c681ed3,Social Science Research Network,2023.0,26.0,0.0,0.0,True,"['Computer Science', 'Economics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '21726720', 'name': 'Paweł Niszczota'}, {'authorId': '72794383', 'name': 'P. Conway'}]","['University of Southampton', 'Poznań University of Economics and Business']","['United Kingdom', 'Poland']",2023-05
2305.11991,Ren\'e Peinl,Ren\'e Peinl and Johannes Wirth,Evaluation of medium-large Language Models at zero-shot closed book generative question answering,,Under review in ARIA 2023,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Large language models (LLMs) have garnered significant attention, but the definition of ""large"" lacks clarity. This paper focuses on medium-sized language models (MLMs), defined as having at least six billion parameters but less than 100 billion. The study evaluates MLMs regarding zero-shot generative question answering, which requires models to provide elaborate answers without external document retrieval. The paper introduces an own test dataset and presents results from human evaluation. Results show that combining the best answers from different MLMs yielded an overall correct answer rate of 82.7% which is better than the 60.9% of ChatGPT. The best MLM achieved 71.8% and has 33B parameters, which highlights the importance of using appropriate training data for fine-tuning rather than solely relying on the number of parameters. More fine-grained feedback should be used to further improve the quality of answers. The open source community is quickly closing the gap to the best commercial models. ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 20:33:19 GMT'}, {'version': 'v2', 'created': 'Mon, 3 Jul 2023 18:26:23 GMT'}]",2023-07-06,"[['Peinl', 'René', ''], ['Wirth', 'Johannes', '']]",1,1,2023-05-19,2,2,1,1,0,1,68ab1c79158000db6deccb1509c58d2e1f1f8633,258833348.0,https://www.semanticscholar.org/paper/68ab1c79158000db6deccb1509c58d2e1f1f8633,arXiv.org,2023.0,59.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1936717', 'name': 'R. Peinl'}, {'authorId': '2182181551', 'name': 'Johannes Wirth'}]",['Hof University of Applied Sciences'],['Germany'],2023-05
2305.11993,Andrey Kutuzov,"Mario Giulianelli, Iris Luden, Raquel Fernandez, Andrey Kutuzov",Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis,ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We propose using automatically generated natural language definitions of contextualised word usages as interpretable word and word sense representations. Given a collection of usage examples for a target word, and the corresponding data-driven usage clusters (i.e., word senses), a definition is generated for each usage with a specialised Flan-T5 language model, and the most prototypical definition in a usage cluster is chosen as the sense label.   We demonstrate how the resulting sense labels can make existing approaches to semantic change analysis more interpretable, and how they can allow users -- historical linguists, lexicographers, or social scientists -- to explore and intuitively explain diachronic trajectories of word meaning. Semantic change analysis is only one of many possible applications of the `definitions as representations' paradigm. Beyond being human-readable, contextualised definitions also outperform token or usage sentence embeddings in word-in-context semantic similarity judgements, making them a new promising type of lexical representation for NLP. ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 20:36:21 GMT'}, {'version': 'v2', 'created': 'Tue, 25 Jul 2023 11:50:48 GMT'}]",2023-07-26,"[['Giulianelli', 'Mario', ''], ['Luden', 'Iris', ''], ['Fernandez', 'Raquel', ''], ['Kutuzov', 'Andrey', '']]",0,0,2023-05-19,2,4,1,3,2,1,a2fb308508afbe00aab0709f6563719bd86e256a,258833586.0,https://www.semanticscholar.org/paper/a2fb308508afbe00aab0709f6563719bd86e256a,Annual Meeting of the Association for Computational Linguistics,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '24068173', 'name': 'Mario Giulianelli'}, {'authorId': '2218113101', 'name': 'Iris Luden'}, {'authorId': '2147411708', 'name': 'Raquel Fernández'}, {'authorId': '2689095', 'name': 'Andrey Kutuzov'}]",['University of Oslo'],['Norway'],2023-05
2305.12031,Augustin Toma,"Augustin Toma, Patrick R. Lawler, Jimmy Ba, Rahul G. Krishnan, Barry
  B. Rubin, Bo Wang",Clinical Camel: An Open Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding,"for model weights, see https://huggingface.co/wanglab/",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  We present Clinical Camel, an open large language model (LLM) explicitly tailored for clinical research. Fine-tuned from LLaMA-2 using QLoRA, Clinical Camel achieves state-of-the-art performance across medical benchmarks among openly available medical LLMs. Leveraging efficient single-GPU training, Clinical Camel surpasses GPT-3.5 in five-shot evaluations on all assessed benchmarks, including 64.3% on the USMLE Sample Exam (compared to 58.5% for GPT-3.5), 77.9% on PubMedQA (compared to 60.2%), 60.7% on MedQA (compared to 53.6%), and 54.2% on MedMCQA (compared to 51.0%). In addition to these benchmarks, Clinical Camel demonstrates its broader capabilities, such as synthesizing plausible clinical notes. This work introduces dialogue-based knowledge encoding, a novel method to synthesize conversational data from dense medical texts. While benchmark results are encouraging, extensive and rigorous human evaluation across diverse clinical scenarios is imperative to ascertain safety before implementation. By openly sharing Clinical Camel, we hope to foster transparent and collaborative research, working towards the safe integration of LLMs within the healthcare domain. Significant challenges concerning reliability, bias, and the potential for outdated knowledge persist. Nonetheless, the transparency provided by an open approach reinforces the scientific rigor essential for future clinical applications. ","[{'version': 'v1', 'created': 'Fri, 19 May 2023 23:07:09 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Aug 2023 17:19:02 GMT'}]",2023-08-21,"[['Toma', 'Augustin', ''], ['Lawler', 'Patrick R.', ''], ['Ba', 'Jimmy', ''], ['Krishnan', 'Rahul G.', ''], ['Rubin', 'Barry B.', ''], ['Wang', 'Bo', '']]",0,1,2023-05-19,2,6,2,2,1,1,74904727717df91e7f380b186eb1d004fb49a534,261030221.0,https://www.semanticscholar.org/paper/74904727717df91e7f380b186eb1d004fb49a534,,2023.0,15.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2159811443', 'name': 'Augustin Toma'}, {'authorId': '36128664', 'name': 'P. Lawler'}, {'authorId': '2220840742', 'name': 'Jimmy Ba'}, {'authorId': '145253891', 'name': 'R. G. Krishnan'}, {'authorId': '50333580', 'name': 'B. Rubin'}, {'authorId': '2164832469', 'name': 'Bo Wang'}]","['University of Toronto', 'University Health Network', 'McGill University', 'Vector Institute']",['Canada'],2023-05
2305.12143,Raoul Koudijs,"Sophie Blum, Raoul Koudijs, Ana Ozaki and Samia Touileb",Learning Horn Envelopes via Queries from Large Language Models,"35 pages, 2 figures; manuscript accepted for publication in the
  International Journal of Approximate Reasoning (IJAR)",,,,cs.LG cs.LO,http://creativecommons.org/licenses/by/4.0/,"  We investigate an approach for extracting knowledge from trained neural networks based on Angluin's exact learning model with membership and equivalence queries to an oracle. In this approach, the oracle is a trained neural network. We consider Angluin's classical algorithm for learning Horn theories and study the necessary changes to make it applicable to learn from neural networks. In particular, we have to consider that trained neural networks may not behave as Horn oracles, meaning that their underlying target theory may not be Horn. We propose a new algorithm that aims at extracting the ""tightest Horn approximation"" of the target theory and that is guaranteed to terminate in exponential time (in the worst case) and in polynomial time if the target has polynomially many non-Horn examples. To showcase the applicability of the approach, we perform experiments on pre-trained language models and extract rules that expose occupation-based gender biases. ","[{'version': 'v1', 'created': 'Sat, 20 May 2023 09:01:33 GMT'}, {'version': 'v2', 'created': 'Wed, 13 Sep 2023 11:49:29 GMT'}]",2023-09-14,"[['Blum', 'Sophie', ''], ['Koudijs', 'Raoul', ''], ['Ozaki', 'Ana', ''], ['Touileb', 'Samia', '']]",0,0,2023-05-20,2,4,2,0,0,0,1f822428428482ca1bf6bbe09169a65304e1f1fb,258832430.0,https://www.semanticscholar.org/paper/1f822428428482ca1bf6bbe09169a65304e1f1fb,International Journal of Approximate Reasoning,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218044885', 'name': 'Sophie Blum'}, {'authorId': '91958435', 'name': 'R. Koudijs'}, {'authorId': '2383803', 'name': 'A. Ozaki'}, {'authorId': '3083347', 'name': 'Samia Touileb'}]","['University of Bergen', 'University of Oslo']",['Norway'],2023-05
2305.12167,Ran Gilad-Bachrach,"Hofit Wasserman Rozen, Niva Elkin-Koren, Ran Gilad-Bachrach",The Case Against Explainability,,,,,cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  As artificial intelligence (AI) becomes more prevalent there is a growing demand from regulators to accompany decisions made by such systems with explanations. However, a persistent gap exists between the need to execute a meaningful right to explanation vs. the ability of Machine Learning systems to deliver on such a legal requirement. The regulatory appeal towards ""a right to explanation"" of AI systems can be attributed to the significant role of explanations, part of the notion called reason-giving, in law. Therefore, in this work we examine reason-giving's purposes in law to analyze whether reasons provided by end-user Explainability can adequately fulfill them.   We find that reason-giving's legal purposes include: (a) making a better and more just decision, (b) facilitating due-process, (c) authenticating human agency, and (d) enhancing the decision makers' authority. Using this methodology, we demonstrate end-user Explainabilty's inadequacy to fulfil reason-giving's role in law, given reason-giving's functions rely on its impact over a human decision maker. Thus, end-user Explainability fails, or is unsuitable, to fulfil the first, second and third legal function. In contrast we find that end-user Explainability excels in the fourth function, a quality which raises serious risks considering recent end-user Explainability research trends, Large Language Models' capabilities, and the ability to manipulate end-users by both humans and machines. Hence, we suggest that in some cases the right to explanation of AI systems could bring more harm than good to end users. Accordingly, this study carries some important policy ramifications, as it calls upon regulators and Machine Learning practitioners to reconsider the widespread pursuit of end-user Explainability and a right to explanation of AI systems. ","[{'version': 'v1', 'created': 'Sat, 20 May 2023 10:56:19 GMT'}]",2023-05-23,"[['Rozen', 'Hofit Wasserman', ''], ['Elkin-Koren', 'Niva', ''], ['Gilad-Bachrach', 'Ran', '']]",0,0,2023-05-20,1,3,1,0,0,0,ca63e2dbfef969a7ee147045d6df9351b04ea517,258832406.0,https://www.semanticscholar.org/paper/ca63e2dbfef969a7ee147045d6df9351b04ea517,arXiv.org,2023.0,77.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Law', 'source': 's2-fos-model'}]","[{'authorId': '2218042234', 'name': 'Hofit Wasserman Rozen'}, {'authorId': '1414087091', 'name': 'N. Elkin-Koren'}, {'authorId': '1388775848', 'name': 'Ran Gilad-Bachrach'}]",['Tel Aviv University'],['Israel'],2023-05
2305.12182,Peiqin Lin,"Ayyoob Imani and Peiqin Lin and Amir Hossein Kargaran and Silvia
  Severini and Masoud Jalili Sabet and Nora Kassner and Chunlan Ma and Helmut
  Schmid and Andr\'e F. T. Martins and Fran\c{c}ois Yvon and Hinrich Sch\""utze",Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages,ACL 2023,,10.18653/v1/2023.acl-long.61,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The NLP community has mainly focused on scaling Large Language Models (LLMs) vertically, i.e., making them better for about 100 languages. We instead scale LLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM that covers 511 predominantly low-resource languages. An important part of this effort is to collect and clean Glot500-c, a corpus that covers these 511 languages and allows us to train Glot500-m. We evaluate Glot500-m on five diverse tasks across these languages. We observe large improvements for both high-resource and low-resource languages compared to an XLM-R baseline. Our analysis shows that no single factor explains the quality of multilingual LLM representations. Rather, a combination of factors determines quality including corpus size, script, ""help"" from related languages and the total capacity of the model. Our work addresses an important goal of NLP research: we should not limit NLP to a small fraction of the world's languages and instead strive to support as many languages as possible to bring the benefits of NLP technology to all languages and cultures. Code, data and models are available at https://github.com/cisnlp/Glot500. ","[{'version': 'v1', 'created': 'Sat, 20 May 2023 12:26:41 GMT'}, {'version': 'v2', 'created': 'Fri, 26 May 2023 11:30:08 GMT'}]",2023-08-31,"[['Imani', 'Ayyoob', ''], ['Lin', 'Peiqin', ''], ['Kargaran', 'Amir Hossein', ''], ['Severini', 'Silvia', ''], ['Sabet', 'Masoud Jalili', ''], ['Kassner', 'Nora', ''], ['Ma', 'Chunlan', ''], ['Schmid', 'Helmut', ''], ['Martins', 'André F. T.', ''], ['Yvon', 'François', ''], ['Schütze', 'Hinrich', '']]",0,0,2023-05-20,2,11,1,0,0,0,767dcc48c7ad2c943f3c1a25c46b873e7b8b3bc8,258832427.0,https://www.semanticscholar.org/paper/767dcc48c7ad2c943f3c1a25c46b873e7b8b3bc8,Annual Meeting of the Association for Computational Linguistics,2023.0,92.0,12.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '51894641', 'name': 'Ayyoob Imani'}, {'authorId': '152178958', 'name': 'Peiqin Lin'}, {'authorId': '98623604', 'name': 'Amir Hossein Kargaran'}, {'authorId': '51894872', 'name': 'Silvia Severini'}, {'authorId': '33014152', 'name': 'Masoud Jalili Sabet'}, {'authorId': '9529535', 'name': 'Nora Kassner'}, {'authorId': '2217563675', 'name': 'Chunlan Ma'}, {'authorId': '40360495', 'name': 'Helmut Schmid'}, {'authorId': '1400227478', 'name': 'André F. T. Martins'}, {'authorId': '1602259700', 'name': 'Franccois Yvon'}, {'authorId': '144418438', 'name': 'Hinrich Schütze'}]","['Ludwig-Maximilians-Universität München', 'French National Centre for Scientific Research', 'Institut Systèmes Intelligents et de Robotique', 'Instituto Superior Técnico']","['Germany', 'France', 'Portugal']",2023-05
2305.12199,Xuan-Quy Dao,"Xuan-Quy Dao, Ngoc-Bich Le, The-Duy Vo, Xuan-Dung Phan, Bac-Bien Ngo,
  Van-Tien Nguyen, Thi-My-Thanh Nguyen, and Hong-Phuoc Nguyen",VNHSGE: VietNamese High School Graduation Examination Dataset for Large Language Models,"74 pages, 44 figures",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The VNHSGE (VietNamese High School Graduation Examination) dataset, developed exclusively for evaluating large language models (LLMs), is introduced in this article. The dataset, which covers nine subjects, was generated from the Vietnamese National High School Graduation Examination and comparable tests. 300 literary essays have been included, and there are over 19,000 multiple-choice questions on a range of topics. The dataset assesses LLMs in multitasking situations such as question answering, text generation, reading comprehension, visual question answering, and more by including both textual data and accompanying images. Using ChatGPT and BingChat, we evaluated LLMs on the VNHSGE dataset and contrasted their performance with that of Vietnamese students to see how well they performed. The results show that ChatGPT and BingChat both perform at a human level in a number of areas, including literature, English, history, geography, and civics education. They still have space to grow, though, especially in the areas of mathematics, physics, chemistry, and biology. The VNHSGE dataset seeks to provide an adequate benchmark for assessing the abilities of LLMs with its wide-ranging coverage and variety of activities. We intend to promote future developments in the creation of LLMs by making this dataset available to the scientific community, especially in resolving LLMs' limits in disciplines involving mathematics and the natural sciences. ","[{'version': 'v1', 'created': 'Sat, 20 May 2023 14:13:08 GMT'}]",2023-07-06,"[['Dao', 'Xuan-Quy', ''], ['Le', 'Ngoc-Bich', ''], ['Vo', 'The-Duy', ''], ['Phan', 'Xuan-Dung', ''], ['Ngo', 'Bac-Bien', ''], ['Nguyen', 'Van-Tien', ''], ['Nguyen', 'Thi-My-Thanh', ''], ['Nguyen', 'Hong-Phuoc', '']]",1,1,2023-05-20,1,8,1,1,0,1,1563cff13dfa53e571641d108f2fec6b2bf77767,258832747.0,https://www.semanticscholar.org/paper/1563cff13dfa53e571641d108f2fec6b2bf77767,arXiv.org,2023.0,66.0,10.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2218325521', 'name': 'Dao Xuan-Quy'}, {'authorId': '2218301144', 'name': 'Le Ngoc-Bich'}, {'authorId': '2218270404', 'name': 'Vo The-Duy'}, {'authorId': '2218325523', 'name': 'Phan Xuan-Dung'}, {'authorId': '2218354936', 'name': 'Ngo Bac-Bien'}, {'authorId': '2218324546', 'name': 'Nguyen Van-Tien'}, {'authorId': '2218332837', 'name': 'Nguyen Thi-My-Thanh'}, {'authorId': '2218301241', 'name': 'Nguyen Hong-Phuoc'}]","['International University', 'Eastern International University']","['Cambodia', 'Vietnam']",2023-05
2305.12392,Jiuzhou Han,"Jiuzhou Han, Nigel Collier, Wray Buntine, Ehsan Shareghi",PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have shown great abilities of solving various natural language tasks in different domains. Due to the training objective of LLMs and their pretraining data, LLMs are not very well equipped for tasks involving structured data generation. We propose a framework, Prompting with Iterative Verification (PiVe), to improve graphbased generative capability of LLMs. We show how a small language model could be trained to act as a verifier module for the output of an LLM (i.e., ChatGPT), and to iteratively improve its performance via fine-grained corrective instructions. Additionally, we show how the verifier module could apply iterative corrections offline for a more cost-effective solution to the text-to-graph generation task. Experiments on three graph-based datasets show consistent improvement gained via PiVe. Additionally, we highlight how the proposed verifier module can be used as a data augmentation tool to help improve the quality of automatically generated parallel text-graph datasets. Our code and data are available at https://github.com/Jiuzhouh/PiVe. ","[{'version': 'v1', 'created': 'Sun, 21 May 2023 08:11:24 GMT'}]",2023-05-23,"[['Han', 'Jiuzhou', ''], ['Collier', 'Nigel', ''], ['Buntine', 'Wray', ''], ['Shareghi', 'Ehsan', '']]",1,1,2023-05-21,1,4,1,1,0,1,c7ae496ae37b5c1fca5c0f7e277bc9356172efd1,258832958.0,https://www.semanticscholar.org/paper/c7ae496ae37b5c1fca5c0f7e277bc9356172efd1,arXiv.org,2023.0,40.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2133405108', 'name': 'Jiuzhou Han'}, {'authorId': '50638196', 'name': 'Nigel Collier'}, {'authorId': '70219052', 'name': 'Wray L. Buntine'}, {'authorId': '2888926', 'name': 'Ehsan Shareghi'}]","['Monash University', 'University of Cambridge']","['United Kingdom', 'Australia']",2023-05
2305.12487,C\'edric Colas,"C\'edric Colas, Laetitia Teodorescu, Pierre-Yves Oudeyer, Xingdi Yuan,
  Marc-Alexandre C\^ot\'e",Augmenting Autotelic Agents with Large Language Models,,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Humans learn to master open-ended repertoires of skills by imagining and practicing their own goals. This autotelic learning process, literally the pursuit of self-generated (auto) goals (telos), becomes more and more open-ended as the goals become more diverse, abstract and creative. The resulting exploration of the space of possible skills is supported by an inter-individual exploration: goal representations are culturally evolved and transmitted across individuals, in particular using language. Current artificial agents mostly rely on predefined goal representations corresponding to goal spaces that are either bounded (e.g. list of instructions), or unbounded (e.g. the space of possible visual inputs) but are rarely endowed with the ability to reshape their goal representations, to form new abstractions or to imagine creative goals. In this paper, we introduce a language model augmented autotelic agent (LMA3) that leverages a pretrained language model (LM) to support the representation, generation and learning of diverse, abstract, human-relevant goals. The LM is used as an imperfect model of human cultural transmission; an attempt to capture aspects of humans' common-sense, intuitive physics and overall interests. Specifically, it supports three key components of the autotelic architecture: 1)~a relabeler that describes the goals achieved in the agent's trajectories, 2)~a goal generator that suggests new high-level goals along with their decomposition into subgoals the agent already masters, and 3)~reward functions for each of these goals. Without relying on any hand-coded goal representations, reward functions or curriculum, we show that LMA3 agents learn to master a large diversity of skills in a task-agnostic text-based environment. ","[{'version': 'v1', 'created': 'Sun, 21 May 2023 15:42:41 GMT'}]",2023-05-23,"[['Colas', 'Cédric', ''], ['Teodorescu', 'Laetitia', ''], ['Oudeyer', 'Pierre-Yves', ''], ['Yuan', 'Xingdi', ''], ['Côté', 'Marc-Alexandre', '']]",0,0,2023-05-21,1,5,3,0,0,0,98c328c9a48b2a404e2704c1d73f2daef3da854e,258832563.0,https://www.semanticscholar.org/paper/98c328c9a48b2a404e2704c1d73f2daef3da854e,arXiv.org,2023.0,60.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '102281182', 'name': 'Cédric Colas'}, {'authorId': '1585810093', 'name': 'Laetitia Teodorescu'}, {'authorId': '1720664', 'name': 'Pierre-Yves Oudeyer'}, {'authorId': '2854297', 'name': 'Xingdi Yuan'}, {'authorId': '40638665', 'name': 'Marc-Alexandre Côté'}]",['Microsoft'],['India'],2023-05
2305.12739,Aman Saggu,"Aman Saggu, Lennart Ante",The Influence of ChatGPT on Artificial Intelligence Related Crypto Assets: Evidence from a Synthetic Control Analysis,"26 pages, 4 tables, 1 figure, 2 appendix figures","Finance Research Letters, 103993 (2023)",10.1016/j.frl.2023.103993,,q-fin.GN q-fin.PR,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The introduction of OpenAI's large language model, ChatGPT, catalyzed investor attention towards artificial intelligence (AI) technologies, including AI-related crypto assets not directly related to ChatGPT. Utilizing the synthetic difference-in-difference methodology, we identify significant 'ChatGPT effects' with returns of AI-related crypto assets experiencing average returns ranging between 10.7% and 15.6% (35.5% to 41.3%) in the one-month (two-month) period after the ChatGPT launch. Furthermore, Google search volumes, a proxy for attention to AI, emerged as critical pricing indicators for AI-related crypto post-launch. We conclude that investors perceived AI-assets as possessing heightened potential or value after the launch, resulting in higher market valuations. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 05:59:51 GMT'}]",2023-05-23,"[['Saggu', 'Aman', ''], ['Ante', 'Lennart', '']]",1,1,2023-05-22,1,2,2,1,0,1,2ca6a4aa4459d1dc4da800db62a4fc46f8924ec5,258573881.0,https://www.semanticscholar.org/paper/2ca6a4aa4459d1dc4da800db62a4fc46f8924ec5,Finance Research Letters,2023.0,43.0,4.0,0.0,True,['Economics'],"[{'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '119365225', 'name': 'Aman Saggu'}, {'authorId': '113611772', 'name': 'Lennart Ante'}]","['Mahidol University', 'Blockchain Research Lab']",['Thailand'],2023-05
2305.12907,Julian Coda-Forno,"Julian Coda-Forno, Marcel Binz, Zeynep Akata, Matthew Botvinick, Jane
  X. Wang, Eric Schulz",Meta-in-context learning in large language models,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models have shown tremendous performance in a variety of tasks. In-context learning -- the ability to improve at a task after being provided with a number of demonstrations -- is seen as one of the main contributors to their success. In the present paper, we demonstrate that the in-context learning abilities of large language models can be recursively improved via in-context learning itself. We coin this phenomenon meta-in-context learning. Looking at two idealized domains, a one-dimensional regression task and a two-armed bandit task, we show that meta-in-context learning adaptively reshapes a large language model's priors over expected tasks. Furthermore, we find that meta-in-context learning modifies the in-context learning strategies of such models. Finally, we extend our approach to a benchmark of real-world regression problems where we observe competitive performance to traditional learning algorithms. Taken together, our work improves our understanding of in-context learning and paves the way toward adapting large language models to the environment they are applied purely through meta-in-context learning rather than traditional finetuning. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 10:40:36 GMT'}]",2023-05-23,"[['Coda-Forno', 'Julian', ''], ['Binz', 'Marcel', ''], ['Akata', 'Zeynep', ''], ['Botvinick', 'Matthew', ''], ['Wang', 'Jane X.', ''], ['Schulz', 'Eric', '']]",0,0,2023-05-22,1,6,3,0,0,0,286c3587f2616839286748461cbc90261ea49caf,258832364.0,https://www.semanticscholar.org/paper/286c3587f2616839286748461cbc90261ea49caf,arXiv.org,2023.0,31.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2215168951', 'name': 'Julian Coda-Forno'}, {'authorId': '32354733', 'name': 'Marcel Binz'}, {'authorId': '2893664', 'name': 'Zeynep Akata'}, {'authorId': '46378362', 'name': 'M. Botvinick'}, {'authorId': '2116439278', 'name': 'Jane X. Wang'}, {'authorId': '49427184', 'name': 'Eric Schulz'}]","['University of Tübingen', 'Google', 'Max Planck Institute for Biological Cybernetics']","['Germany', 'United Kingdom']",2023-05
2305.12962,Jiazheng Li,"Jiazheng Li, Lin Gui, Yuxiang Zhou, David West, Cesare Aloisi, Yulan
  He",Distilling ChatGPT for Explainable Automated Student Answer Assessment,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Assessing student answers and providing valuable feedback is crucial for effective learning, but it can be a time-consuming task. Traditional methods of automating student answer assessment through text classification often suffer from issues such as lack of trustworthiness, transparency, and the ability to provide a rationale for the automated assessment process. These limitations hinder their usefulness in practice. In this paper, we explore using ChatGPT, a cutting-edge large language model, for the concurrent tasks of student answer scoring and rationale generation under both the zero-shot and few-shot settings. We introduce a critic module which automatically filters incorrect outputs from ChatGPT and utilizes the remaining ChtaGPT outputs as noisy labelled data to fine-tune a smaller language model, enabling it to perform student answer scoring and rationale generation. Moreover, by drawing multiple samples from ChatGPT outputs, we are able to compute predictive confidence scores, which in turn can be used to identify corrupted data and human label errors in the training set. Our experimental results demonstrate that despite being a few orders of magnitude smaller than ChatGPT, the fine-tuned language model achieves better performance in student answer scoring. Furthermore, it generates more detailed and comprehensible assessments than traditional text classification methods. Our approach provides a viable solution to achieve explainable automated assessment in education. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 12:11:39 GMT'}]",2023-05-23,"[['Li', 'Jiazheng', ''], ['Gui', 'Lin', ''], ['Zhou', 'Yuxiang', ''], ['West', 'David', ''], ['Aloisi', 'Cesare', ''], ['He', 'Yulan', '']]",1,1,2023-05-22,1,6,1,1,0,1,c329ddddc53b9df84cf174d49a37c0bae585ea7a,258832881.0,https://www.semanticscholar.org/paper/c329ddddc53b9df84cf174d49a37c0bae585ea7a,arXiv.org,2023.0,24.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '92861741', 'name': 'Jiazheng Li'}, {'authorId': '145096580', 'name': 'Lin Gui'}, {'authorId': '2218087424', 'name': 'Yuxiang Zhou'}, {'authorId': '2218327140', 'name': 'David West'}, {'authorId': '117934075', 'name': 'Cesare Aloisi'}, {'authorId': '1390509967', 'name': 'Yulan He'}]","['AQA, UK', 'The Alan Turing Institute', ""King's College London""]",['United Kingdom'],2023-05
2305.12987,Magnus Sahlgren,"Ariel Ekgren, Amaru Cuba Gyllensten, Felix Stollenwerk, Joey \""Ohman,
  Tim Isbister, Evangelia Gogoulou, Fredrik Carlsson, Alice Heiman, Judit
  Casademont, Magnus Sahlgren",GPT-SW3: An Autoregressive Language Model for the Nordic Languages,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper details the process of developing the first native large generative language model for the Nordic languages, GPT-SW3. We cover all parts of the development process, from data collection and processing, training configuration and instruction finetuning, to evaluation and considerations for release strategies. We hope that this paper can serve as a guide and reference for other researchers that undertake the development of large generative models for smaller languages. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 12:47:48 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 06:59:16 GMT'}]",2023-05-24,"[['Ekgren', 'Ariel', ''], ['Gyllensten', 'Amaru Cuba', ''], ['Stollenwerk', 'Felix', ''], ['Öhman', 'Joey', ''], ['Isbister', 'Tim', ''], ['Gogoulou', 'Evangelia', ''], ['Carlsson', 'Fredrik', ''], ['Heiman', 'Alice', ''], ['Casademont', 'Judit', ''], ['Sahlgren', 'Magnus', '']]",0,1,2023-05-22,2,10,2,0,0,0,66e53ba87f201a2ba8bcf09966f16ae068933e77,258832435.0,https://www.semanticscholar.org/paper/66e53ba87f201a2ba8bcf09966f16ae068933e77,arXiv.org,2023.0,35.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1926146', 'name': 'Ariel Ekgren'}, {'authorId': '2701223', 'name': 'Amaru Cuba Gyllensten'}, {'authorId': '102551585', 'name': 'F. Stollenwerk'}, {'authorId': '1582211914', 'name': 'Joey Öhman'}, {'authorId': '32168146', 'name': 'T. Isbister'}, {'authorId': '2029654671', 'name': 'Evangelia Gogoulou'}, {'authorId': '49715476', 'name': 'F. Carlsson'}, {'authorId': '2185525871', 'name': 'Alice Heiman'}, {'authorId': '2218270024', 'name': 'Judit Casademont'}, {'authorId': '2068514641', 'name': 'Magnus Sahlgren'}]","['RISE Research Institutes of Sweden', 'AI Sweden']",['Sweden'],2023-05
2305.13014,Stefano De Paoli Prof,Stefano De Paoli,Can Large Language Models emulate an inductive Thematic Analysis of semi-structured interviews? An exploration and provocation on the limits of the approach and the model,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large Language Models (LLMs) have emerged as powerful generative Artificial Intelligence solutions which can be applied to several fields and areas of work. This paper presents results and reflection of an experiment done to use the model GPT 3.5-Turbo to emulate some aspects of an inductive Thematic Analysis. Previous research on this subject has largely worked on conducting deductive analysis. Thematic Analysis is a qualitative method for analysis commonly used in social sciences and it is based on interpretations made by the human analyst(s) and the identification of explicit and latent meanings in qualitative data. Attempting an analysis based on human interpretation with an LLM clearly is a provocation but also a way to learn something about how these systems can or cannot be used in qualitative research. The paper presents the motivations for attempting this emulation, it reflects on how the six steps to a Thematic Analysis proposed by Braun and Clarke can at least partially be reproduced with the LLM and it also reflects on what are the outputs produced by the model. The paper used two existing datasets of open access semi-structured interviews, previously analysed with Thematic Analysis by other researchers. It used the previously produced analysis (and the related themes) to compare with the results produced by the LLM. The results show that the model can infer at least partially some of the main Themes. The objective of the paper is not to replace human analysts in qualitative analysis but to learn if some elements of LLM data manipulation can to an extent be of support for qualitative research. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 13:16:07 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 14:01:51 GMT'}, {'version': 'v3', 'created': 'Mon, 18 Sep 2023 07:36:55 GMT'}]",2023-09-19,"[['De Paoli', 'Stefano', '']]",0,1,2023-05-22,3,1,1,1,0,1,099212b4fee2daf4df1bc7577b58cc1e4ec9e054,258832411.0,https://www.semanticscholar.org/paper/099212b4fee2daf4df1bc7577b58cc1e4ec9e054,arXiv.org,2023.0,33.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '1774708', 'name': 'S. Paoli'}]",['Abertay University'],['United Kingdom'],2023-05
2305.13047,Mark Mets,"Mark Mets, Andres Karjus, Indrek Ibrus, Maximilian Schich",Automated stance detection in complex topics and small languages: the challenging case of immigration in polarizing news media,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Automated stance detection and related machine learning methods can provide useful insights for media monitoring and academic research. Many of these approaches require annotated training datasets, which limits their applicability for languages where these may not be readily available. This paper explores the applicability of large language models for automated stance detection in a challenging scenario, involving a morphologically complex, lower-resource language, and a socio-culturally complex topic, immigration. If the approach works in this case, it can be expected to perform as well or better in less demanding scenarios. We annotate a large set of pro and anti-immigration examples, and compare the performance of multiple language models as supervised learners. We also probe the usability of ChatGPT as an instructable zero-shot classifier for the same task. Supervised achieves acceptable performance, and ChatGPT yields similar accuracy. This is promising as a potentially simpler and cheaper alternative for text classification tasks, including in lower-resource languages. We further use the best-performing model to investigate diachronic trends over seven years in two corpora of Estonian mainstream and right-wing populist news sources, demonstrating the applicability of the approach for news analytics and media monitoring settings, and discuss correspondences between stance changes and real-world events. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 13:56:35 GMT'}]",2023-05-23,"[['Mets', 'Mark', ''], ['Karjus', 'Andres', ''], ['Ibrus', 'Indrek', ''], ['Schich', 'Maximilian', '']]",1,1,2023-05-22,1,4,1,1,0,1,c7809011e1f5f52c08b424f8f9a693d1ac694830,258832441.0,https://www.semanticscholar.org/paper/c7809011e1f5f52c08b424f8f9a693d1ac694830,arXiv.org,2023.0,53.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '147537687', 'name': 'Marko Mets'}, {'authorId': '50994722', 'name': 'Andres Karjus'}, {'authorId': '2710595', 'name': 'Indrek Ibrus'}, {'authorId': '2143922', 'name': 'Maximilian Schich'}]",['Tallinn University'],['Estonia'],2023-05
2305.13085,Ratish Puduppully,"Ratish Puduppully, Raj Dabre, Ai Ti Aw, Nancy F. Chen",Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models,work-in-progress,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study investigates machine translation between related languages i.e., languages within the same family that share similar linguistic traits such as word order and lexical similarity. Machine translation through few-shot prompting leverages a small set of translation pair examples to generate translations for test sentences. This requires the model to learn how to generate translations while simultaneously ensuring that token ordering is maintained to produce a fluent and accurate translation. We propose that for related languages, the task of machine translation can be simplified by leveraging the monotonic alignment characteristic of such languages. We introduce a novel approach of few-shot prompting that decomposes the translation process into a sequence of word chunk translations. Through evaluations conducted on multiple related language pairs across various language families, we demonstrate that our novel approach of decomposed prompting surpasses multiple established few-shot baseline models, thereby verifying its effectiveness. For example, our model outperforms the strong few-shot prompting BLOOM model with an average improvement of 4.2 chrF++ scores across the examined languages. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 14:52:47 GMT'}]",2023-05-23,"[['Puduppully', 'Ratish', ''], ['Dabre', 'Raj', ''], ['Aw', 'Ai Ti', ''], ['Chen', 'Nancy F.', '']]",0,0,2023-05-22,1,4,1,1,1,0,b6e5855b6a4e425ba251a93516f2bccffe5ba403,258833688.0,https://www.semanticscholar.org/paper/b6e5855b6a4e425ba251a93516f2bccffe5ba403,arXiv.org,2023.0,36.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2990638', 'name': 'Ratish Puduppully'}, {'authorId': '3209719', 'name': 'Raj Dabre'}, {'authorId': '2113601787', 'name': 'A. Aw'}, {'authorId': '2118768398', 'name': 'Nancy F. Chen'}]","['French National Centre for Scientific Research', 'National Institute of Information and Communications Technology', 'Microsoft', 'Institute for Infocomm Research']","['India', 'Japan', 'Singapore', 'France']",2023-05
2305.13102,Sumit Soman,"Sumit Soman, Ranjani H G",Observations on LLMs for Telecom Domain: Capabilities and Limitations,"11 pages, 2 figures, 8 tables",,,,cs.HC cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The landscape for building conversational interfaces (chatbots) has witnessed a paradigm shift with recent developments in generative Artificial Intelligence (AI) based Large Language Models (LLMs), such as ChatGPT by OpenAI (GPT3.5 and GPT4), Google's Bard, Large Language Model Meta AI (LLaMA), among others. In this paper, we analyze capabilities and limitations of incorporating such models in conversational interfaces for the telecommunication domain, specifically for enterprise wireless products and services. Using Cradlepoint's publicly available data for our experiments, we present a comparative analysis of the responses from such models for multiple use-cases including domain adaptation for terminology and product taxonomy, context continuity, robustness to input perturbations and errors. We believe this evaluation would provide useful insights to data scientists engaged in building customized conversational interfaces for domain-specific requirements. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 15:04:16 GMT'}]",2023-05-23,"[['Soman', 'Sumit', ''], ['G', 'Ranjani H', '']]",1,1,2023-05-22,1,2,4,4,1,3,506f571f4c3ef3c5c52761cd6b99400acd22ebd6,258833510.0,https://www.semanticscholar.org/paper/506f571f4c3ef3c5c52761cd6b99400acd22ebd6,arXiv.org,2023.0,19.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3336244', 'name': 'Sumit Soman'}, {'authorId': '1410704775', 'name': 'G. RanjaniH.'}]","['Ranjani H G Global AI Accelerator Ericsson Bangalore, India', 'Ericsson']",['India'],2023-05
2305.13168,Ningyu Zhang,"Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao,
  Shumin Deng, Huajun Chen, Ningyu Zhang",LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities,Work in progress,,,,cs.CL cs.AI cs.DB cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We employ eight distinct datasets that encompass aspects including entity, relation and event extraction, link prediction, and question answering. Empirically, our findings suggest that GPT-4 outperforms ChatGPT in the majority of tasks and even surpasses fine-tuned models in certain reasoning and question-answering datasets. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, which culminates in the presentation of the Virtual Knowledge Extraction task and the development of the VINE dataset. Drawing on these empirical findings, we further propose AutoKG, a multi-agent-based approach employing LLMs for KG construction and reasoning, which aims to chart the future of this field and offer exciting opportunities for advancement. We anticipate that our research can provide invaluable insights for future undertakings of KG\footnote{Code and datasets will be available in https://github.com/zjunlp/AutoKG. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 15:56:44 GMT'}]",2023-05-23,"[['Zhu', 'Yuqi', ''], ['Wang', 'Xiaohan', ''], ['Chen', 'Jing', ''], ['Qiao', 'Shuofei', ''], ['Ou', 'Yixin', ''], ['Yao', 'Yunzhi', ''], ['Deng', 'Shumin', ''], ['Chen', 'Huajun', ''], ['Zhang', 'Ningyu', '']]",1,1,2023-05-22,1,9,5,2,0,2,35631fd55c2545615811fa8072015356ac8198e7,258833039.0,https://www.semanticscholar.org/paper/35631fd55c2545615811fa8072015356ac8198e7,arXiv.org,2023.0,56.0,13.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2127757530', 'name': 'Yuqi Zhu'}, {'authorId': '2141660877', 'name': 'Xiaohan Wang'}, {'authorId': '2215142021', 'name': 'Jing Chen'}, {'authorId': '2190751119', 'name': 'Shuofei Qiao'}, {'authorId': '2196928874', 'name': 'Yixin Ou'}, {'authorId': '4841460', 'name': 'Yunzhi Yao'}, {'authorId': '152931849', 'name': 'Shumin Deng'}, {'authorId': '2144200945', 'name': 'Huajun Chen'}, {'authorId': '2608639', 'name': 'Ningyu Zhang'}]",['National University of Singapore'],['Singapore'],2023-05
2305.13235,Oana-Maria Camburu,"Jesus Solano, Oana-Maria Camburu, Pasquale Minervini",SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Explaining the decisions of neural models is crucial for ensuring their trustworthiness at deployment time. Using Natural Language Explanations (NLEs) to justify a model's predictions has recently gained increasing interest. However, this approach usually demands large datasets of human-written NLEs for the ground-truth answers, which are expensive and potentially infeasible for some applications. For models to generate high-quality NLEs when only a few NLEs are available, the fine-tuning of Pre-trained Language Models (PLMs) in conjunction with prompt-based learning recently emerged. However, PLMs typically have billions of parameters, making fine-tuning expensive. We propose SparseFit, a sparse few-shot fine-tuning strategy that leverages discrete prompts to jointly generate predictions and NLEs. We experiment with SparseFit on the T5 model and four datasets and compare it against state-of-the-art parameter-efficient fine-tuning techniques. We perform automatic and human evaluations to assess the quality of the model-generated NLEs, finding that fine-tuning only 6.8% of the model parameters leads to competitive results for both the task performance and the quality of the NLEs. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 17:06:41 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 09:26:37 GMT'}]",2023-05-24,"[['Solano', 'Jesus', ''], ['Camburu', 'Oana-Maria', ''], ['Minervini', 'Pasquale', '']]",0,0,2023-05-22,2,3,2,1,1,0,22cc280a0a239da49db0bec745b8fb3caa0e7a67,258832919.0,https://www.semanticscholar.org/paper/22cc280a0a239da49db0bec745b8fb3caa0e7a67,arXiv.org,2023.0,66.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2190173304', 'name': 'Jesus Solano'}, {'authorId': '3317152', 'name': 'Oana-Maria Camburu'}, {'authorId': '3051815', 'name': 'Pasquale Minervini'}]","['University College London', 'University of Edinburgh']",['United Kingdom'],2023-05
2305.13276,Mithun Das,"Mithun Das, Saurabh Kumar Pandey, Animesh Mukherjee",Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate Speech Detection,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Hate speech is a severe issue that affects many online platforms. So far, several studies have been performed to develop robust hate speech detection systems. Large language models like ChatGPT have recently shown a great promise in performing several tasks, including hate speech detection. However, it is crucial to comprehend the limitations of these models to build robust hate speech detection systems. To bridge this gap, our study aims to evaluate the strengths and weaknesses of the ChatGPT model in detecting hate speech at a granular level across 11 languages. Our evaluation employs a series of functionality tests that reveals various intricate failures of the model which the aggregate metrics like macro F1 or accuracy are not able to unfold. In addition, we investigate the influence of complex emotions, such as the use of emojis in hate speech, on the performance of the ChatGPT model. Our analysis highlights the shortcomings of the generative models in detecting certain types of hate speech and highlighting the need for further research and improvements in the workings of these models. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 17:36:58 GMT'}, {'version': 'v2', 'created': 'Tue, 23 May 2023 03:39:44 GMT'}]",2023-05-24,"[['Das', 'Mithun', ''], ['Pandey', 'Saurabh Kumar', ''], ['Mukherjee', 'Animesh', '']]",1,1,2023-05-22,2,3,2,1,0,1,6b8ab7a964d32f3828f9ca30c210c21ca2eda43b,258833018.0,https://www.semanticscholar.org/paper/6b8ab7a964d32f3828f9ca30c210c21ca2eda43b,arXiv.org,2023.0,39.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2000633372', 'name': 'Mithun Das'}, {'authorId': '2069693219', 'name': 'Saurabh Kumar Pandey'}, {'authorId': '46405816', 'name': 'Animesh Mukherjee'}]",['Indian Institute of Technology Kharagpur'],['India'],2023-05
2305.13286,Rochelle Choenni,"Rochelle Choenni, Dan Garrette, Ekaterina Shutova",How do languages influence each other? Studying cross-lingual data sharing during LLM fine-tuning,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multilingual large language models (MLLMs) are jointly trained on data from many different languages such that representation of individual languages can benefit from other languages' data. Impressive performance on zero-shot cross-lingual transfer shows that these models are capable of exploiting data from other languages. Yet, it remains unclear to what extent, and under which conditions, languages rely on each other's data. In this study, we use TracIn (Pruthi et al., 2020), a training data attribution (TDA) method, to retrieve the most influential training samples seen during multilingual fine-tuning for a particular test language. This allows us to analyse cross-lingual sharing mechanisms of MLLMs from a new perspective. While previous work studied cross-lingual sharing at the level of model parameters, we present the first approach to study cross-lingual sharing at the data level. We find that MLLMs rely on data from multiple languages from the early stages of fine-tuning and that this reliance gradually increases as fine-tuning progresses. We further study how different fine-tuning languages influence model performance on a given test language and find that they can both reinforce and complement the knowledge acquired from data of the test language itself. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 17:47:41 GMT'}]",2023-05-23,"[['Choenni', 'Rochelle', ''], ['Garrette', 'Dan', ''], ['Shutova', 'Ekaterina', '']]",0,0,2023-05-22,1,3,1,0,0,0,e6d1139f185acf6a08260190d4dba138f918e1df,258832559.0,https://www.semanticscholar.org/paper/e6d1139f185acf6a08260190d4dba138f918e1df,arXiv.org,2023.0,46.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2067163164', 'name': 'Rochelle Choenni'}, {'authorId': '2758616', 'name': 'Dan Garrette'}, {'authorId': '2362276', 'name': 'Ekaterina Shutova'}]",['University of Amsterdam'],['Netherlands'],2023-05
2305.13304,Wangchunshu Zhou,"Wangchunshu Zhou, Yuchen Eleanor Jiang, Peng Cui, Tiannan Wang,
  Zhenxin Xiao, Yifan Hou, Ryan Cotterell, Mrinmaya Sachan",RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text,Under review,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The fixed-size context of Transformer makes GPT models incapable of generating arbitrarily long text. In this paper, we introduce RecurrentGPT, a language-based simulacrum of the recurrence mechanism in RNNs. RecurrentGPT is built upon a large language model (LLM) such as ChatGPT and uses natural language to simulate the Long Short-Term Memory mechanism in an LSTM. At each timestep, RecurrentGPT generates a paragraph of text and updates its language-based long-short term memory stored on the hard drive and the prompt, respectively. This recurrence mechanism enables RecurrentGPT to generate texts of arbitrary length without forgetting. Since human users can easily observe and edit the natural language memories, RecurrentGPT is interpretable and enables interactive generation of long text. RecurrentGPT is an initial step towards next-generation computer-assisted writing systems beyond local editing suggestions. In addition to producing AI-generated content (AIGC), we also demonstrate the possibility of using RecurrentGPT as an interactive fiction that directly interacts with consumers. We call this usage of generative models by ``AI As Contents'' (AIAC), which we believe is the next form of conventional AIGC. We further demonstrate the possibility of using RecurrentGPT to create personalized interactive fiction that directly interacts with readers instead of interacting with writers. More broadly, RecurrentGPT demonstrates the utility of borrowing ideas from popular model designs in cognitive science and deep learning for prompting LLMs. Our code is available at https://github.com/aiwaves-cn/RecurrentGPT and an online demo is available at https://www.aiwaves.org/recurrentgpt. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 17:58:10 GMT'}]",2023-05-23,"[['Zhou', 'Wangchunshu', ''], ['Jiang', 'Yuchen Eleanor', ''], ['Cui', 'Peng', ''], ['Wang', 'Tiannan', ''], ['Xiao', 'Zhenxin', ''], ['Hou', 'Yifan', ''], ['Cotterell', 'Ryan', ''], ['Sachan', 'Mrinmaya', '']]",1,1,2023-05-22,1,8,2,1,0,1,d9964ab436eefd21f923a4bc833c6b66692c7f00,258832617.0,https://www.semanticscholar.org/paper/d9964ab436eefd21f923a4bc833c6b66692c7f00,arXiv.org,2023.0,37.0,10.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '150341221', 'name': 'Wangchunshu Zhou'}, {'authorId': '2134457930', 'name': 'Yuchen Jiang'}, {'authorId': '2153522384', 'name': 'Peng Cui'}, {'authorId': '2118916175', 'name': 'Tiannan Wang'}, {'authorId': '123034558', 'name': 'Zhenxin Xiao'}, {'authorId': '2088768581', 'name': 'Yifan Hou'}, {'authorId': '2070989574', 'name': 'Ryan Cotterell'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]","['ETH Zurich', 'Equal Contribution Preprint. Work In Progress.']",['Switzerland'],2023-05
2305.13342,Katerina Margatina,Katerina Margatina and Nikolaos Aletras,On the Limitations of Simulating Active Learning,To appear at Findings of ACL 2023,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Active learning (AL) is a human-and-model-in-the-loop paradigm that iteratively selects informative unlabeled data for human annotation, aiming to improve over random sampling. However, performing AL experiments with human annotations on-the-fly is a laborious and expensive process, thus unrealistic for academic research. An easy fix to this impediment is to simulate AL, by treating an already labeled and publicly available dataset as the pool of unlabeled data. In this position paper, we first survey recent literature and highlight the challenges across all different steps within the AL loop. We further unveil neglected caveats in the experimental setup that can significantly affect the quality of AL research. We continue with an exploration of how the simulation setting can govern empirical findings, arguing that it might be one of the answers behind the ever posed question ``why do active learning algorithms sometimes fail to outperform random sampling?''. We argue that evaluating AL algorithms on available labeled datasets might provide a lower bound as to their effectiveness in real data. We believe it is essential to collectively shape the best practices for AL research, particularly as engineering advancements in LLMs push the research focus towards data-driven approaches (e.g., data efficiency, alignment, fairness). In light of this, we have developed guidelines for future work. Our aim is to draw attention to these limitations within the community, in the hope of finding ways to address them. ","[{'version': 'v1', 'created': 'Sun, 21 May 2023 22:52:13 GMT'}]",2023-05-24,"[['Margatina', 'Katerina', ''], ['Aletras', 'Nikolaos', '']]",0,0,2023-05-21,1,2,2,0,0,0,299b3b03252c631d91eeefe6c9102b7a60307f59,258841754.0,https://www.semanticscholar.org/paper/299b3b03252c631d91eeefe6c9102b7a60307f59,Annual Meeting of the Association for Computational Linguistics,2023.0,112.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '82259306', 'name': 'Katerina Margatina'}, {'authorId': '3238627', 'name': 'Nikolaos Aletras'}]",['University of Sheffield'],['United Kingdom'],2023-05
2305.13386,Nadir Durrani Dr,"Basel Mousi, Nadir Durrani, Fahim Dalvi",Can LLMs facilitate interpretation of pre-trained language models?,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Work done to uncover the knowledge encoded within pre-trained language models, rely on annotated corpora or human-in-the-loop methods. However, these approaches are limited in terms of scalability and the scope of interpretation. We propose using a large language model, ChatGPT, as an annotator to enable fine-grained interpretation analysis of pre-trained language models. We discover latent concepts within pre-trained language models by applying hierarchical clustering over contextualized representations and then annotate these concepts using GPT annotations. Our findings demonstrate that ChatGPT produces accurate and semantically richer annotations compared to human-annotated concepts. Additionally, we showcase how GPT-based annotations empower interpretation analysis methodologies of which we demonstrate two: probing framework and neuron interpretation. To facilitate further exploration and experimentation in this field, we have made available a substantial ConceptNet dataset comprising 39,000 annotated latent concepts. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 18:03:13 GMT'}]",2023-05-24,"[['Mousi', 'Basel', ''], ['Durrani', 'Nadir', ''], ['Dalvi', 'Fahim', '']]",1,1,2023-05-22,1,3,1,1,0,1,6c340ff334beac9524629d19f84544ed2bb29e85,258841771.0,https://www.semanticscholar.org/paper/6c340ff334beac9524629d19f84544ed2bb29e85,arXiv.org,2023.0,54.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2171367840', 'name': 'Basel Mousi'}, {'authorId': '145938140', 'name': 'Nadir Durrani'}, {'authorId': '6415321', 'name': 'Fahim Dalvi'}]",['Qatar Computing Research Institute'],['Qatar'],2023-05
2305.13417,Shahar Katz,"Shahar Katz, Yonatan Belinkov",Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent advances in interpretability suggest we can project weights and hidden states of transformer-based language models (LMs) to their vocabulary, a transformation that makes them human interpretable and enables us to assign semantics to what was seen only as numerical vectors. In this paper, we interpret LM attention heads and memory values, the vectors the models dynamically create and recall while processing a given input. By analyzing the tokens they represent through this projection, we identify patterns in the information flow inside the attention mechanism. Based on these discoveries, we create a tool to visualize a forward pass of Generative Pre-trained Transformers (GPTs) as an interactive flow graph, with nodes representing neurons or hidden states and edges representing the interactions between them. Our visualization simplifies huge amounts of data into easy-to-read plots that reflect why models output their results. We demonstrate the utility of our modeling by identifying the effect LM components have on the intermediate processing in the model before outputting a prediction. For instance, we discover that layer norms are used as semantic filters and find neurons that act as regularization vectors. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 19:04:56 GMT'}]",2023-05-24,"[['Katz', 'Shahar', ''], ['Belinkov', 'Yonatan', '']]",0,1,2023-05-22,1,2,1,0,0,0,89caec1d5179c3415699919570d85988266691d9,258841183.0,https://www.semanticscholar.org/paper/89caec1d5179c3415699919570d85988266691d9,arXiv.org,2023.0,27.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '121254633', 'name': 'Shahar Katz'}, {'authorId': '2083259', 'name': 'Yonatan Belinkov'}]",['Technion – Israel Institute of Technology'],['Israel'],2023-05
2305.13455,David Schlangen,"Kranti Chalamalasetti and Jana G\""otze and Sherzod Hakimov and Brielen
  Madureira and Philipp Sadler and David Schlangen",clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents,Work in progress,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent work has proposed a methodology for the systematic evaluation of ""Situated Language Understanding Agents""-agents that operate in rich linguistic and non-linguistic contexts-through testing them in carefully constructed interactive settings. Other recent work has argued that Large Language Models (LLMs), if suitably set up, can be understood as (simulators of) such agents. A connection suggests itself, which this paper explores: Can LLMs be evaluated meaningfully by exposing them to constrained game-like settings that are built to challenge specific capabilities? As a proof of concept, this paper investigates five interaction settings, showing that current chat-optimised LLMs are, to an extent, capable to follow game-play instructions. Both this capability and the quality of the game play, measured by how well the objectives of the different games are met, follows the development cycle, with newer models performing better. The metrics even for the comparatively simple example games are far from being saturated, suggesting that the proposed instrument will remain to have diagnostic value. Our general framework for implementing and evaluating games with LLMs is available at https://github.com/clp-research/clembench. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 19:56:10 GMT'}]",2023-05-24,"[['Chalamalasetti', 'Kranti', ''], ['Götze', 'Jana', ''], ['Hakimov', 'Sherzod', ''], ['Madureira', 'Brielen', ''], ['Sadler', 'Philipp', ''], ['Schlangen', 'David', '']]",0,0,2023-05-22,1,6,1,0,0,0,f52af5abe78ca2af836f70ce193f0161bc2e6264,258841392.0,https://www.semanticscholar.org/paper/f52af5abe78ca2af836f70ce193f0161bc2e6264,arXiv.org,2023.0,44.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2046531185', 'name': 'Kranti Chalamalasetti'}, {'authorId': '1594732196', 'name': 'Jana Gotze'}, {'authorId': '2079305', 'name': 'Sherzod Hakimov'}, {'authorId': '1823518201', 'name': 'Brielen Madureira'}, {'authorId': '84039136', 'name': 'P. Sadler'}, {'authorId': '1817455', 'name': 'David Schlangen'}]","['German Research Centre for Artificial Intelligence', 'University of Potsdam']",['Germany'],2023-05
2305.13512,Mutian He,"Mutian He, Philip N. Garner",Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding,"6 pages, 2 figures; Accepted by Interspeech 2023",,,,cs.CL cs.AI cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, large pretrained language models have demonstrated strong language understanding capabilities. This is particularly reflected in their zero-shot and in-context learning abilities on downstream tasks through prompting. To assess their impact on spoken language understanding (SLU), we evaluate several such models like ChatGPT and OPT of different sizes on multiple benchmarks. We verify the emergent ability unique to the largest models as they can reach intent classification accuracy close to that of supervised models with zero or few shots on various languages given oracle transcripts. By contrast, the results for smaller models fitting a single GPU fall far behind. We note that the error cases often arise from the annotation scheme of the dataset; responses from ChatGPT are still reasonable. We show, however, that the model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 21:59:26 GMT'}, {'version': 'v2', 'created': 'Thu, 17 Aug 2023 19:23:20 GMT'}]",2023-08-21,"[['He', 'Mutian', ''], ['Garner', 'Philip N.', '']]",1,1,2023-05-22,2,2,4,2,1,1,daf9e24adbba3d1aead91cbac26502d3043db069,258841217.0,https://www.semanticscholar.org/paper/daf9e24adbba3d1aead91cbac26502d3043db069,Interspeech,2023.0,47.0,8.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51056597', 'name': 'Mutian He'}, {'authorId': '144342894', 'name': 'Philip N. Garner'}]","['École Polytechnique Fédérale de Lausanne', 'Idiap Research Institute']",['Switzerland'],2023-05
2305.13677,Chu Fei Luo,"Chu Fei Luo, Rohan Bhambhoria, Xiaodan Zhu, Samuel Dahan",Towards Legally Enforceable Hate Speech Detection for Public Forums,4 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Hate speech is a serious issue on public forums, and proper enforcement of hate speech laws is key for protecting groups of people against harmful and discriminatory language. However, determining what constitutes hate speech is a complex task that is highly open to subjective interpretations. Existing works do not align their systems with enforceable definitions of hate speech, which can make their outputs inconsistent with the goals of regulators. Our work introduces a new task for enforceable hate speech detection centred around legal definitions, and a dataset annotated on violations of eleven possible definitions by legal experts. Given the challenge of identifying clear, legally enforceable instances of hate speech, we augment the dataset with expert-generated samples and an automatically mined challenge set. We experiment with grounding the model decision in these definitions using zero-shot and few-shot prompting. We then report results on several large language models (LLMs). With this task definition, automatic hate speech detection can be more closely aligned to enforceable laws, and hence assist in more rigorous enforcement of legal protections against harmful speech in public forums. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 04:34:41 GMT'}]",2023-05-24,"[['Luo', 'Chu Fei', ''], ['Bhambhoria', 'Rohan', ''], ['Zhu', 'Xiaodan', ''], ['Dahan', 'Samuel', '']]",0,0,2023-05-23,1,4,1,0,0,0,895f3c9e452ae51fb02786de424ce6d2bba11c3b,258841019.0,https://www.semanticscholar.org/paper/895f3c9e452ae51fb02786de424ce6d2bba11c3b,arXiv.org,2023.0,55.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Law', 'source': 's2-fos-model'}]","[{'authorId': '2089528608', 'name': 'Chunyan Luo'}, {'authorId': '2008160154', 'name': 'R. Bhambhoria'}, {'authorId': '2130251018', 'name': 'Xiao-Dan Zhu'}, {'authorId': '119208875', 'name': 'Samuel Dahan'}]","[""Queen's University"", 'Cornell Law School']",['Canada'],2023-05
2305.13698,Frederick Riemenschneider,Frederick Riemenschneider and Anette Frank,Exploring Large Language Models for Classical Philology,"Paper accepted for publication at ACL 2023 Main; 10 pages, 7 appendix
  pages, 4 figures, 13 tables",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advances in NLP have led to the creation of powerful language models for many languages including Ancient Greek and Latin. While prior work on Classical languages unanimously uses BERT, in this work we create four language models for Ancient Greek that vary along two dimensions to study their versatility for tasks of interest for Classical languages: we explore (i) encoder-only and encoder-decoder architectures using RoBERTa and T5 as strong model types, and create for each of them (ii) a monolingual Ancient Greek and a multilingual instance that includes Latin and English. We evaluate all models on morphological and syntactic tasks, including lemmatization, which demonstrates the added value of T5's decoding abilities. We further define two probing tasks to investigate the knowledge acquired by models pre-trained on Classical texts. Our experiments provide the first benchmarking analysis of existing models of Ancient Greek. Results show that our models provide significant improvements over the SoTA. The systematic analysis of model types can inform future research in designing language models for Classical languages, including the development of novel generative tasks. We make all our models available as community resources, along with a large curated pre-training corpus for Ancient Greek, to support the creation of a larger, comparable model zoo for Classical Philology. Our models and resources are available at https://github.com/Heidelberg-NLP/ancient-language-models. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 05:21:02 GMT'}]",2023-05-24,"[['Riemenschneider', 'Frederick', ''], ['Frank', 'Anette', '']]",0,0,2023-05-23,1,2,1,1,1,0,2cfb1f44b34204213d789731871e599c756bdb83,258841841.0,https://www.semanticscholar.org/paper/2cfb1f44b34204213d789731871e599c756bdb83,Annual Meeting of the Association for Computational Linguistics,2023.0,38.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218455244', 'name': 'Frederick Riemenschneider'}, {'authorId': '143876555', 'name': 'A. Frank'}]",['Heidelberg University'],['Germany'],2023-05
2305.13711,Yen-Ting Lin,"Yen-Ting Lin, Yun-Nung Chen",LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models,Accepted at 5th NLP4ConvAI,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We propose LLM-Eval, a unified multi-dimensional automatic evaluation method for open-domain conversations with large language models (LLMs). Existing evaluation methods often rely on human annotations, ground-truth responses, or multiple LLM prompts, which can be expensive and time-consuming. To address these issues, we design a single prompt-based evaluation method that leverages a unified evaluation schema to cover multiple dimensions of conversation quality in a single model call. We extensively evaluate the performance of LLM-Eval on various benchmark datasets, demonstrating its effectiveness, efficiency, and adaptability compared to state-of-the-art evaluation methods. Our analysis also highlights the importance of choosing suitable LLMs and decoding strategies for accurate evaluation results. LLM-Eval offers a versatile and robust solution for evaluating open-domain conversation systems, streamlining the evaluation process and providing consistent performance across diverse scenarios. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 05:57:09 GMT'}]",2023-05-24,"[['Lin', 'Yen-Ting', ''], ['Chen', 'Yun-Nung', '']]",0,0,2023-05-23,1,2,2,0,0,0,4f480bae3196dbbc27ab383bce33478ea963f9b3,258841681.0,https://www.semanticscholar.org/paper/4f480bae3196dbbc27ab383bce33478ea963f9b3,NLP4CONVAI,2023.0,40.0,18.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1557269413', 'name': 'Yen-Ting Lin'}, {'authorId': '1725643', 'name': 'Yun-Nung (Vivian) Chen'}]",['National Taiwan University'],['Taiwan'],2023-05
2305.13718,Fangkai Jiao,"Fangkai Jiao, Zhiyang Teng, Shafiq Joty, Bosheng Ding, Aixin Sun,
  Zhengyuan Liu, Nancy F. Chen",LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large Language Models,11 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Existing efforts to improve logical reasoning ability of language models have predominantly relied on supervised fine-tuning, hindering generalization to new domains and/or tasks. The development of Large Langauge Models (LLMs) has demonstrated the capacity of compressing abundant knowledge into a single proxy, enabling them to tackle multiple tasks effectively. Our preliminary experiments, nevertheless, show that LLMs do not show capability on logical reasoning. The performance of LLMs on logical reasoning benchmarks is far behind the existing state-of-the-art baselines. In this paper, we make the first attempt to investigate the feasibility of incorporating logical knowledge through self-supervised post-training, and activating it via in-context learning, which we termed as LogicLLM. Specifically, we devise an auto-regressive objective variant of MERIt and integrate it with two LLM series, i.e., FLAN-T5 and LLaMA, with parameter size ranging from 3 billion to 13 billion. The results on two challenging logical reasoning benchmarks demonstrate the effectiveness of LogicLLM. Besides, we conduct extensive ablation studies to analyze the key factors in designing logic-oriented proxy tasks. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 06:13:10 GMT'}, {'version': 'v2', 'created': 'Wed, 24 May 2023 06:38:41 GMT'}]",2023-05-25,"[['Jiao', 'Fangkai', ''], ['Teng', 'Zhiyang', ''], ['Joty', 'Shafiq', ''], ['Ding', 'Bosheng', ''], ['Sun', 'Aixin', ''], ['Liu', 'Zhengyuan', ''], ['Chen', 'Nancy F.', '']]",0,0,2023-05-23,2,7,1,4,3,1,de0593223973eccfee04d598a68bc55784c7fc17,258841216.0,https://www.semanticscholar.org/paper/de0593223973eccfee04d598a68bc55784c7fc17,arXiv.org,2023.0,55.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1689176705', 'name': 'Fangkai Jiao'}, {'authorId': '2272668', 'name': 'Zhiyang Teng'}, {'authorId': '2708940', 'name': 'Shafiq R. Joty'}, {'authorId': '2064493724', 'name': 'Bosheng Ding'}, {'authorId': '1735962', 'name': 'Aixin Sun'}, {'authorId': '49293155', 'name': 'Zhengyuan Liu'}, {'authorId': '2118768398', 'name': 'Nancy F. Chen'}]","['Agency for Science, Technology and Research', 'Nanyang Technological University', 'Salesforce AI']",['Singapore'],2023-05
2305.13724,Yuki Saito,"Yuki Saito, Shinnosuke Takamichi, Eiji Iimori, Kentaro Tachibana,
  Hiroshi Saruwatari",ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from ChatGPT-derived Context Word Embeddings,"5 pages, accepted for INTERSPEECH 2023",,,,cs.SD cs.CL cs.LG eess.AS,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We propose ChatGPT-EDSS, an empathetic dialogue speech synthesis (EDSS) method using ChatGPT for extracting dialogue context. ChatGPT is a chatbot that can deeply understand the content and purpose of an input prompt and appropriately respond to the user's request. We focus on ChatGPT's reading comprehension and introduce it to EDSS, a task of synthesizing speech that can empathize with the interlocutor's emotion. Our method first gives chat history to ChatGPT and asks it to generate three words representing the intention, emotion, and speaking style for each line in the chat. Then, it trains an EDSS model using the embeddings of ChatGPT-derived context words as the conditioning features. The experimental results demonstrate that our method performs comparably to ones using emotion labels or neural network-derived context embeddings learned from chat histories. The collected ChatGPT-derived context information is available at https://sarulab-speech.github.io/demo_ChatGPT_EDSS/. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 06:19:37 GMT'}]",2023-05-24,"[['Saito', 'Yuki', ''], ['Takamichi', 'Shinnosuke', ''], ['Iimori', 'Eiji', ''], ['Tachibana', 'Kentaro', ''], ['Saruwatari', 'Hiroshi', '']]",1,1,2023-05-23,1,5,4,1,0,1,00554edbbe20423cbf7a2f7e3a130c1cb4f56203,258841292.0,https://www.semanticscholar.org/paper/00554edbbe20423cbf7a2f7e3a130c1cb4f56203,Interspeech,2023.0,34.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2053879375', 'name': 'Yuki Saito'}, {'authorId': '2424104', 'name': 'Shinnosuke Takamichi'}, {'authorId': '103675901', 'name': 'Eiji Iimori'}, {'authorId': '2940047', 'name': 'Kentaro Tachibana'}, {'authorId': '1685827', 'name': 'H. Saruwatari'}]","['Line Corporation (Japan)', 'The University of Tokyo']",['Japan'],2023-05
2305.13735,Sungdong Kim,"Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak,
  Kang Min Yoo, Minjoon Seo",Aligning Large Language Models through Synthetic Feedback,"Preprint, 9 pages (with 10 pages of supplementary)",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Aligning large language models (LLMs) to human values has become increasingly important as it enables sophisticated steering of LLMs, e.g., making them follow given instructions while keeping them less toxic. However, it requires a significant amount of human demonstrations and feedback. Recently, open-sourced models have attempted to replicate the alignment learning process by distilling data from already aligned LLMs like InstructGPT or ChatGPT. While this process reduces human efforts, constructing these datasets has a heavy dependency on the teacher models. In this work, we propose a novel framework for alignment learning with almost no human labor and no dependency on pre-aligned LLMs. First, we perform reward modeling (RM) with synthetic feedback by contrasting responses from vanilla LLMs with various sizes and prompts. Then, we use the RM for simulating high-quality demonstrations to train a supervised policy and for further optimizing the model with reinforcement learning. Our resulting model, Aligned Language Model with Synthetic Training dataset (ALMoST), outperforms open-sourced models, including Alpaca, Dolly, and OpenAssistant, which are trained on the outputs of InstructGPT or human-annotated instructions. Our 7B-sized model outperforms the 12-13B models in the A/B tests using GPT-4 as the judge with about 75% winning rate on average. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 06:41:16 GMT'}]",2023-05-24,"[['Kim', 'Sungdong', ''], ['Bae', 'Sanghwan', ''], ['Shin', 'Jamin', ''], ['Kang', 'Soyoung', ''], ['Kwak', 'Donghyun', ''], ['Yoo', 'Kang Min', ''], ['Seo', 'Minjoon', '']]",1,1,2023-05-23,1,7,3,4,0,4,5b8f0460d408a8688d9ee0cba127c779d3291d99,258841835.0,https://www.semanticscholar.org/paper/5b8f0460d408a8688d9ee0cba127c779d3291d99,arXiv.org,2023.0,40.0,16.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2829848', 'name': 'Sungdong Kim'}, {'authorId': '152846184', 'name': 'Sanghwan Bae'}, {'authorId': '51228826', 'name': 'Jamin Shin'}, {'authorId': '2149085001', 'name': 'Soyoung Kang'}, {'authorId': '10469987', 'name': 'Donghyun Kwak'}, {'authorId': '31760501', 'name': 'Kang Min Yoo'}, {'authorId': '4418074', 'name': 'Minjoon Seo'}]",['Seoul National University'],['South Korea'],2023-05
2305.13782,Sherzod Hakimov,"Sherzod Hakimov, David Schlangen",Images in Language Space: Exploring the Suitability of Large Language Models for Vision & Language Tasks,Accepted at ACL 2023 Findings,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Large language models have demonstrated robust performance on various language tasks using zero-shot or few-shot learning paradigms. While being actively researched, multimodal models that can additionally handle images as input have yet to catch up in size and generality with language-only models. In this work, we ask whether language-only models can be utilised for tasks that require visual input -- but also, as we argue, often require a strong reasoning component. Similar to some recent related work, we make visual information accessible to the language model using separate verbalisation models. Specifically, we investigate the performance of open-source, open-access language models against GPT-3 on five vision-language tasks when given textually-encoded visual information. Our results suggest that language models are effective for solving vision-language tasks even with limited samples. This approach also enhances the interpretability of a model's output by providing a means of tracing the output back through the verbalised image content. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 07:50:36 GMT'}]",2023-05-24,"[['Hakimov', 'Sherzod', ''], ['Schlangen', 'David', '']]",0,1,2023-05-23,1,2,1,1,0,1,c82e95e282e85f649f901f16e3cbf434b582ba74,258841626.0,https://www.semanticscholar.org/paper/c82e95e282e85f649f901f16e3cbf434b582ba74,Annual Meeting of the Association for Computational Linguistics,2023.0,51.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2079305', 'name': 'Sherzod Hakimov'}, {'authorId': '1817455', 'name': 'David Schlangen'}]","['German Research Centre for Artificial Intelligence', 'University of Potsdam']",['Germany'],2023-05
2305.13821,Chaoran Chen,"Chaoran Chen, Tanja Stadler",GenSpectrum Chat: Data Exploration in Public Health Using Large Language Models,,,,,q-bio.GN cs.AI cs.IR,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Introduction: The COVID-19 pandemic highlighted the importance of making epidemiological data and scientific insights easily accessible and explorable for public health agencies, the general public, and researchers. State-of-the-art approaches for sharing data and insights included regularly updated reports and web dashboards. However, they face a trade-off between the simplicity and flexibility of data exploration. With the capabilities of recent large language models (LLMs) such as GPT-4, this trade-off can be overcome.   Results: We developed the chatbot ""GenSpectrum Chat"" (https://cov-spectrum.org/chat) which uses GPT-4 as the underlying large language model (LLM) to explore SARS-CoV-2 genomic sequencing data. Out of 500 inputs from real-world users, the chatbot provided a correct answer for 453 prompts; an incorrect answer for 13 prompts, and no answer although the question was within scope for 34 prompts. We also tested the chatbot with inputs from 10 different languages, and despite being provided solely with English instructions and examples, it successfully processed prompts in all tested languages.   Conclusion: LLMs enable new ways of interacting with information systems. In the field of public health, GenSpectrum Chat can facilitate the analysis of real-time pathogen genomic data. With our chatbot supporting interactive exploration in different languages, we envision quick and direct access to the latest evidence for policymakers around the world. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 08:43:43 GMT'}]",2023-05-24,"[['Chen', 'Chaoran', ''], ['Stadler', 'Tanja', '']]",0,1,2023-05-23,1,2,3,1,0,1,4c6a4f29f65f63ad438e7ef6bc844b3b0f301f0f,258841387.0,https://www.semanticscholar.org/paper/4c6a4f29f65f63ad438e7ef6bc844b3b0f301f0f,arXiv.org,2023.0,49.0,0.0,0.0,True,"['Biology', 'Computer Science']","[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2145765023', 'name': 'C. Chen'}, {'authorId': '2580290', 'name': 'T. Stadler'}]","['ETH Zurich', 'SIB Swiss Institute of Bioinformatics']",['Switzerland'],2023-05
2305.13862,Leonardo Ranaldi Mr,"Leonardo Ranaldi, Elena Sofia Ruzzetti, Davide Venditti, Dario
  Onorati, Fabio Massimo Zanzotto",A Trip Towards Fairness: Bias and De-Biasing in Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Cheap-to-Build Very Large-Language Models (CtB-LLMs) with affordable training are emerging as the next big revolution in natural language processing and understanding. These CtB-LLMs are democratizing access to trainable Very Large-Language Models (VLLMs) and, thus, may represent the building blocks of many NLP systems solving downstream tasks. Hence, a little or a large bias in CtB-LLMs may cause huge harm. In this paper, we performed a large investigation of the bias of three families of CtB-LLMs, and we showed that debiasing techniques are effective and usable. Indeed, according to current tests, the LLaMA and the OPT families have an important bias in gender, race, religion, and profession. In contrast to the analysis for other LLMs, we discovered that bias depends not on the number of parameters but on the perplexity. Finally, the debiasing of OPT using LoRA reduces bias up to 4.12 points in the normalized stereotype score. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 09:35:37 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Aug 2023 13:55:13 GMT'}]",2023-08-30,"[['Ranaldi', 'Leonardo', ''], ['Ruzzetti', 'Elena Sofia', ''], ['Venditti', 'Davide', ''], ['Onorati', 'Dario', ''], ['Zanzotto', 'Fabio Massimo', '']]",0,0,2023-05-23,2,5,1,2,2,0,6ab06565288cd2bd20e701a2daab192f71c0f7e7,258840972.0,https://www.semanticscholar.org/paper/6ab06565288cd2bd20e701a2daab192f71c0f7e7,arXiv.org,2023.0,47.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2008183566', 'name': 'Leonardo Ranaldi'}, {'authorId': '2128108433', 'name': 'Elena Sofia Ruzzetti'}, {'authorId': '97919126', 'name': 'D. Venditti'}, {'authorId': '37066537', 'name': 'Dario Onorati'}, {'authorId': '103839825', 'name': 'F. M. Zanzotto'}]","['University of Rome Tor Vergata', 'Sapienza University of Rome', 'Idiap Research Institute']","['Switzerland', 'Italy']",2023-05
2305.13863,Alexandre Pasquiou,"Alexandre Pasquiou, Yair Lakretz, Bertrand Thirion, Christophe Pallier",Probing Brain Context-Sensitivity with Masked-Attention Generation,"2 pages, 2 figures, CCN 2023",CCN 2023,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Two fundamental questions in neurolinguistics concerns the brain regions that integrate information beyond the lexical level, and the size of their window of integration. To address these questions we introduce a new approach named masked-attention generation. It uses GPT-2 transformers to generate word embeddings that capture a fixed amount of contextual information. We then tested whether these embeddings could predict fMRI brain activity in humans listening to naturalistic text. The results showed that most of the cortex within the language network is sensitive to contextual information, and that the right hemisphere is more sensitive to longer contexts than the left. Masked-attention generation supports previous analyses of context-sensitivity in the brain, and complements them by quantifying the window size of context integration per voxel. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 09:36:21 GMT'}]",2023-05-24,"[['Pasquiou', 'Alexandre', ''], ['Lakretz', 'Yair', ''], ['Thirion', 'Bertrand', ''], ['Pallier', 'Christophe', '']]",0,1,2023-05-23,1,4,1,1,1,0,5ee7bf90583bff5eb96812964da462114bd318f5,258841107.0,https://www.semanticscholar.org/paper/5ee7bf90583bff5eb96812964da462114bd318f5,2023 Conference on Cognitive Computational Neuroscience,2023.0,15.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2175249740', 'name': 'Alexandre Pasquiou'}, {'authorId': '3051598', 'name': 'Yair Lakretz'}, {'authorId': '8493461', 'name': 'B. Thirion'}, {'authorId': '7892142', 'name': 'Christophe Pallier'}]","['Cognitive Neuroimaging Lab', 'French Institute for Research in Computer Science and Automation']",['France'],2023-05
2305.13917,Jiacheng Ye,"Jiacheng Ye, Chengzu Li, Lingpeng Kong, Tao Yu",Generating Data for Symbolic Language with Large Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While large language models (LLMs) bring not only performance but also complexity, recent work has started to turn LLMs into data generators rather than task inferencers, where another affordable task model is trained for efficient deployment and inference. However, such an approach has primarily been applied to natural language tasks and has not yet been explored for symbolic language tasks with complex structured outputs (e.g., semantic parsing and code generation). In this paper, we propose SymGen which utilizes LLMs for generating various annotation-expensive symbolic language data. SymGen consists of an informative prompt to steer generation and an agreement-based verifier to improve data correctness. We conduct extensive experiments on six symbolic language tasks across various settings. Compared with the LLMs, we demonstrate the 1\%-sized task model can achieve comparable or better performance, largely cutting inference and deployment costs. We also show that generated data with only a few human demonstrations can be as effective as over 10 times the amount of human-annotated data when training the task model, saving a considerable amount of annotation effort. SymGen sheds new light on data generation for complex tasks, and we release the code at \href{https://github.com/HKUNLP/SymGen}{https://github.com/HKUNLP/SymGen}. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 10:44:00 GMT'}]",2023-05-24,"[['Ye', 'Jiacheng', ''], ['Li', 'Chengzu', ''], ['Kong', 'Lingpeng', ''], ['Yu', 'Tao', '']]",0,0,2023-05-23,1,4,2,0,0,0,6bf981314d81ca838d2cc55fc6f6265717792b67,258841402.0,https://www.semanticscholar.org/paper/6bf981314d81ca838d2cc55fc6f6265717792b67,arXiv.org,2023.0,81.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '65846898', 'name': 'Jiacheng Ye'}, {'authorId': '2155795167', 'name': 'Chengzu Li'}, {'authorId': '47648549', 'name': 'Lingpeng Kong'}, {'authorId': '2117900202', 'name': 'Tao Yu'}]",['University of Hong Kong'],['Hong Kong'],2023-05
2305.13934,Yasir Zaki,"Hazem Ibrahim, Fengyuan Liu, Rohail Asim, Balaraju Battu, Sidahmed
  Benabderrahmane, Bashar Alhafni, Wifag Adnan, Tuka Alhanai, Bedoor AlShebli,
  Riyadh Baghdadi, Jocelyn J. B\'elanger, Elena Beretta, Kemal Celik, Moumena
  Chaqfeh, Mohammed F. Daqaq, Zaynab El Bernoussi, Daryl Fougnie, Borja Garcia
  de Soto, Alberto Gandolfi, Andras Gyorgy, Nizar Habash, J. Andrew Harris,
  Aaron Kaufman, Lefteris Kirousis, Korhan Kocak, Kangsan Lee, Seungah S. Lee,
  Samreen Malik, Michail Maniatakos, David Melcher, Azzam Mourad, Minsu Park,
  Mahmoud Rasras, Alicja Reuben, Dania Zantout, Nancy W. Gleason, Kinga Makovi,
  Talal Rahwan, Yasir Zaki","Perception, performance, and detectability of conversational artificial intelligence across 32 university courses","17 pages, 4 figures",,10.1038/s41598-023-38964-3,,cs.CY cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The emergence of large language models has led to the development of powerful tools such as ChatGPT that can produce text indistinguishable from human-generated work. With the increasing accessibility of such technology, students across the globe may utilize it to help with their school work -- a possibility that has sparked discussions on the integrity of student evaluations in the age of artificial intelligence (AI). To date, it is unclear how such tools perform compared to students on university-level courses. Further, students' perspectives regarding the use of such tools, and educators' perspectives on treating their use as plagiarism, remain unknown. Here, we compare the performance of ChatGPT against students on 32 university-level courses. We also assess the degree to which its use can be detected by two classifiers designed specifically for this purpose. Additionally, we conduct a survey across five countries, as well as a more in-depth survey at the authors' institution, to discern students' and educators' perceptions of ChatGPT's use. We find that ChatGPT's performance is comparable, if not superior, to that of students in many courses. Moreover, current AI-text classifiers cannot reliably detect ChatGPT's use in school work, due to their propensity to classify human-written answers as AI-generated, as well as the ease with which AI-generated text can be edited to evade detection. Finally, we find an emerging consensus among students to use the tool, and among educators to treat this as plagiarism. Our findings offer insights that could guide policy discussions addressing the integration of AI into educational frameworks. ","[{'version': 'v1', 'created': 'Sun, 7 May 2023 10:37:51 GMT'}]",2023-08-30,"[['Ibrahim', 'Hazem', ''], ['Liu', 'Fengyuan', ''], ['Asim', 'Rohail', ''], ['Battu', 'Balaraju', ''], ['Benabderrahmane', 'Sidahmed', ''], ['Alhafni', 'Bashar', ''], ['Adnan', 'Wifag', ''], ['Alhanai', 'Tuka', ''], ['AlShebli', 'Bedoor', ''], ['Baghdadi', 'Riyadh', ''], ['Bélanger', 'Jocelyn J.', ''], ['Beretta', 'Elena', ''], ['Celik', 'Kemal', ''], ['Chaqfeh', 'Moumena', ''], ['Daqaq', 'Mohammed F.', ''], ['Bernoussi', 'Zaynab El', ''], ['Fougnie', 'Daryl', ''], ['de Soto', 'Borja Garcia', ''], ['Gandolfi', 'Alberto', ''], ['Gyorgy', 'Andras', ''], ['Habash', 'Nizar', ''], ['Harris', 'J. Andrew', ''], ['Kaufman', 'Aaron', ''], ['Kirousis', 'Lefteris', ''], ['Kocak', 'Korhan', ''], ['Lee', 'Kangsan', ''], ['Lee', 'Seungah S.', ''], ['Malik', 'Samreen', ''], ['Maniatakos', 'Michail', ''], ['Melcher', 'David', ''], ['Mourad', 'Azzam', ''], ['Park', 'Minsu', ''], ['Rasras', 'Mahmoud', ''], ['Reuben', 'Alicja', ''], ['Zantout', 'Dania', ''], ['Gleason', 'Nancy W.', ''], ['Makovi', 'Kinga', ''], ['Rahwan', 'Talal', ''], ['Zaki', 'Yasir', '']]",1,1,2023-05-07,1,39,2,1,0,1,1ffc9d5ebfbc9596aa6c4b9072c60dc12858a718,258841401.0,https://www.semanticscholar.org/paper/1ffc9d5ebfbc9596aa6c4b9072c60dc12858a718,Scientific Reports,2023.0,51.0,6.0,0.0,False,"['Medicine', 'Computer Science']","[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2054762578', 'name': 'Hazem Ibrahim'}, {'authorId': '2174816842', 'name': 'Fengyuan Liu'}, {'authorId': '2157646582', 'name': 'Rohail Asim'}, {'authorId': '15669259', 'name': 'B. Battu'}, {'authorId': '2783720', 'name': 'Sidahmed Benabderrahmane'}, {'authorId': '66589548', 'name': 'Bashar Alhafni'}, {'authorId': '145511893', 'name': 'W. Adnan'}, {'authorId': '27618394', 'name': 'Tuka Alhanai'}, {'authorId': '2446400', 'name': 'Bedoor K. AlShebli'}, {'authorId': '1758245', 'name': 'Riyadh Baghdadi'}, {'authorId': '2219047908', 'name': ""Jocelyn J. B'elanger""}, {'authorId': '2218435482', 'name': 'Elena Beretta'}, {'authorId': '2073452257', 'name': 'Kemal Çelik'}, {'authorId': '2342421', 'name': 'Moumena Chaqfeh'}, {'authorId': '46723347', 'name': 'M. Daqaq'}, {'authorId': '66685801', 'name': 'Zaynab El Bernoussi'}, {'authorId': '3952504', 'name': 'Daryl Fougnie'}, {'authorId': '98018377', 'name': 'Borja García de Soto'}, {'authorId': '145471767', 'name': 'A. Gandolfi'}, {'authorId': '2090601385', 'name': ""Andr'as Gyorgy""}, {'authorId': '1696645', 'name': 'Nizar Habash'}, {'authorId': '145556319', 'name': 'J. Harris'}, {'authorId': '1664881015', 'name': 'A. Kaufman'}, {'authorId': '1705808', 'name': 'L. Kirousis'}, {'authorId': '121020801', 'name': 'Korhan Kocak'}, {'authorId': '2219388577', 'name': 'Kangsan Lee'}, {'authorId': '2108007313', 'name': 'Seungah S. Lee'}, {'authorId': '52177246', 'name': 'Samreen Malik'}, {'authorId': '1686192', 'name': 'M. Maniatakos'}, {'authorId': '145727633', 'name': 'D. Melcher'}, {'authorId': '144378341', 'name': 'A. Mourad'}, {'authorId': '2149272690', 'name': 'Minsu Park'}, {'authorId': '2553088', 'name': 'M. Rasras'}, {'authorId': '153479887', 'name': 'A. Reuben'}, {'authorId': '103097407', 'name': 'Dania Zantout'}, {'authorId': '107766040', 'name': 'N. Gleason'}, {'authorId': '3237368', 'name': 'K. Makovi'}, {'authorId': '1775071', 'name': 'Talal Rahwan'}, {'authorId': '1749350', 'name': 'Y. Zaki'}]",['New York University Abu Dhabi'],['United Arab Emirates'],2023-05
2305.14072,Samarth Bhargav,"Samarth Bhargav, Anne Schuth, Claudia Hauff",When the Music Stops: Tip-of-the-Tongue Retrieval for Music,,,10.1145/3539618.3592086,,cs.IR,http://creativecommons.org/licenses/by/4.0/,"  We present a study of Tip-of-the-tongue (ToT) retrieval for music, where a searcher is trying to find an existing music entity, but is unable to succeed as they cannot accurately recall important identifying information. ToT information needs are characterized by complexity, verbosity, uncertainty, and possible false memories. We make four contributions. (1) We collect a dataset - $ToT_{Music}$ - of 2,278 information needs and ground truth answers. (2) We introduce a schema for these information needs and show that they often involve multiple modalities encompassing several Music IR subtasks such as lyric search, audio-based search, audio fingerprinting, and text search. (3) We underscore the difficulty of this task by benchmarking a standard text retrieval approach on this dataset. (4) We investigate the efficacy of query reformulations generated by a large language model (LLM), and show that they are not as effective as simply employing the entire information need as a query - leaving several open questions for future research. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 13:50:06 GMT'}]",2023-05-24,"[['Bhargav', 'Samarth', ''], ['Schuth', 'Anne', ''], ['Hauff', 'Claudia', '']]",0,0,2023-05-23,1,3,1,0,0,0,12fd187de4ad5eec24f01e75689a2498cf1b727f,258841576.0,https://www.semanticscholar.org/paper/12fd187de4ad5eec24f01e75689a2498cf1b727f,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,43.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '81679142', 'name': 'Samarth Bhargav'}, {'authorId': '2210188', 'name': 'Anne Schuth'}, {'authorId': '2731925', 'name': 'C. Hauff'}]",['University of Amsterdam'],['Netherlands'],2023-05
2305.14078,Zirui Zhao,"Zirui Zhao, Wee Sun Lee, David Hsu",Large Language Models as Commonsense Knowledge for Large-Scale Task Planning,"20 pages, 6 figures",,,,cs.RO,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Natural language provides a natural interface for human communication, yet it is challenging for robots to comprehend due to its abstract nature and inherent ambiguity. Large language models (LLMs) contain commonsense knowledge that can help resolve language ambiguity and generate possible solutions to abstract specifications. While LLMs have shown promise as few-shot planning policies, their potential for planning complex tasks is not fully tapped. This paper shows that LLMs can be used as both the commonsense model of the world and the heuristic policy in search algorithms such as Monte Carlo Tree Search (MCTS). MCTS explores likely world states sampled from LLMs to facilitate better-reasoned decision-making. The commonsense policy from LLMs guides the search to relevant parts of the tree, substantially reducing the search complexity. We demonstrate the effectiveness of our method in daily task-planning experiments and highlight its advantages over using LLMs solely as policies. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 13:56:31 GMT'}]",2023-05-24,"[['Zhao', 'Zirui', ''], ['Lee', 'Wee Sun', ''], ['Hsu', 'David', '']]",0,0,2023-05-23,1,3,1,0,0,0,5d32c364088733c6e8dadc9cf0baa26e10506d61,258841057.0,https://www.semanticscholar.org/paper/5d32c364088733c6e8dadc9cf0baa26e10506d61,arXiv.org,2023.0,75.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '13869425', 'name': 'Zirui Zhao'}, {'authorId': '46605464', 'name': 'W. Lee'}, {'authorId': '145463096', 'name': 'David Hsu'}]",['National University of Singapore'],['Singapore'],2023-05
2305.14106,Xingchen Wan,"Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan O. Arik, Tomas Pfister",Better Zero-Shot Reasoning with Self-Adaptive Prompting,"Findings of the Association for Computational Linguistics: ACL 2023.
  10 pages, 2 tables, 4 figures (20 pages, 8 tables, 7 figures including
  references and appendices)",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modern large language models (LLMs) have demonstrated impressive capabilities at sophisticated tasks, often through step-by-step reasoning similar to humans. This is made possible by their strong few and zero-shot abilities -- they can effectively learn from a handful of handcrafted, completed responses (""in-context examples""), or are prompted to reason spontaneously through specially designed triggers. Nonetheless, some limitations have been observed. First, performance in the few-shot setting is sensitive to the choice of examples, whose design requires significant human effort. Moreover, given the diverse downstream tasks of LLMs, it may be difficult or laborious to handcraft per-task labels. Second, while the zero-shot setting does not require handcrafting, its performance is limited due to the lack of guidance to the LLMs. To address these limitations, we propose Consistency-based Self-adaptive Prompting (COSP), a novel prompt design method for LLMs. Requiring neither handcrafted responses nor ground-truth labels, COSP selects and builds the set of examples from the LLM zero-shot outputs via carefully designed criteria that combine consistency, diversity and repetition. In the zero-shot setting for three different LLMs, we show that using only LLM predictions, COSP improves performance up to 15% compared to zero-shot baselines and matches or exceeds few-shot baselines for a range of reasoning tasks. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 14:27:16 GMT'}]",2023-05-24,"[['Wan', 'Xingchen', ''], ['Sun', 'Ruoxi', ''], ['Dai', 'Hanjun', ''], ['Arik', 'Sercan O.', ''], ['Pfister', 'Tomas', '']]",0,0,2023-05-23,1,5,3,0,0,0,717392dac099d1506b766787382d61b277863163,258840955.0,https://www.semanticscholar.org/paper/717392dac099d1506b766787382d61b277863163,Annual Meeting of the Association for Computational Linguistics,2023.0,48.0,12.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1470501980', 'name': 'Xingchen Wan'}, {'authorId': '2068169921', 'name': 'Ruoxi Sun'}, {'authorId': '2791430', 'name': 'H. Dai'}, {'authorId': '2676352', 'name': 'Sercan Ö. Arik'}, {'authorId': '1945962', 'name': 'Tomas Pfister'}]",['University of Oxford'],['United Kingdom'],2023-05
2305.14201,Tiedong Liu,Tiedong Liu and Bryan Kian Hsiang Low,Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks,,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We introduce Goat, a fine-tuned LLaMA model that significantly outperforms GPT-4 on a range of arithmetic tasks. Fine-tuned on a synthetically generated dataset, Goat achieves state-of-the-art performance on BIG-bench arithmetic sub-task. In particular, the zero-shot Goat-7B matches or even surpasses the accuracy achieved by the few-shot PaLM-540B. Surprisingly, Goat can achieve near-perfect accuracy on large-number addition and subtraction through supervised fine-tuning only, which is almost impossible with previous pretrained language models, such as Bloom, OPT, GPT-NeoX, etc. We attribute Goat's exceptional performance to LLaMA's consistent tokenization of numbers. To tackle more challenging tasks like large-number multiplication and division, we propose an approach that classifies tasks based on their learnability, and subsequently decomposes unlearnable tasks, such as multi-digit multiplication and division, into a series of learnable tasks by leveraging basic arithmetic principles. We thoroughly examine the performance of our model, offering a comprehensive evaluation of the effectiveness of our proposed decomposition steps. Additionally, Goat-7B can be easily trained using LoRA on a 24GB VRAM GPU, facilitating reproducibility for other researchers. We release our model, dataset, and the Python script for dataset generation. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 16:20:30 GMT'}]",2023-05-24,"[['Liu', 'Tiedong', ''], ['Low', 'Bryan Kian Hsiang', '']]",0,1,2023-05-23,1,2,3,5,3,2,8c7846c9805834dbe2fb0c8f48253b8d65b79d6a,258840942.0,https://www.semanticscholar.org/paper/8c7846c9805834dbe2fb0c8f48253b8d65b79d6a,arXiv.org,2023.0,36.0,19.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218306619', 'name': 'Tiedong Liu'}, {'authorId': '145454065', 'name': 'K. H. Low'}]",['National University of Singapore'],['Singapore'],2023-05
2305.14214,Benjamin Minixhofer,"Benjamin Minixhofer, Jonas Pfeiffer, Ivan Vuli\'c",CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While many languages possess processes of joining two or more words to create compound words, previous studies have been typically limited only to languages with excessively productive compound formation (e.g., German, Dutch) and there is no public dataset containing compound and non-compound words across a large number of languages. In this work, we systematically study decompounding, the task of splitting compound words into their constituents, at a wide scale. We first address the data gap by introducing a dataset of 255k compound and non-compound words across 56 diverse languages obtained from Wiktionary. We then use this dataset to evaluate an array of Large Language Models (LLMs) on the decompounding task. We find that LLMs perform poorly, especially on words which are tokenized unfavorably by subword tokenization. We thus introduce a novel methodology to train dedicated models for decompounding. The proposed two-stage procedure relies on a fully self-supervised objective in the first stage, while the second, supervised learning stage optionally fine-tunes the model on the annotated Wiktionary data. Our self-supervised models outperform the prior best unsupervised decompounding models by 13.9% accuracy on average. Our fine-tuned models outperform all prior (language-specific) decompounding tools. Furthermore, we use our models to leverage decompounding during the creation of a subword tokenizer, which we refer to as CompoundPiece. CompoundPiece tokenizes compound words more favorably on average, leading to improved performance on decompounding over an otherwise equivalent model using SentencePiece tokenization. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 16:32:27 GMT'}]",2023-05-24,"[['Minixhofer', 'Benjamin', ''], ['Pfeiffer', 'Jonas', ''], ['Vulić', 'Ivan', '']]",0,0,2023-05-23,1,3,1,0,0,0,b3cff6abe401a244c21d4706b0931e48acaeeb4e,258841534.0,https://www.semanticscholar.org/paper/b3cff6abe401a244c21d4706b0931e48acaeeb4e,arXiv.org,2023.0,69.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2090357303', 'name': 'Benjamin Minixhofer'}, {'authorId': '153733568', 'name': 'Jonas Pfeiffer'}, {'authorId': '1747849', 'name': 'Ivan Vulic'}]","['University of Cambridge', 'Google']",['United Kingdom'],2023-05
2305.14288,Chenxi Whitehouse,"Chenxi Whitehouse, Monojit Choudhury, Alham Fikri Aji",LLM-powered Data Augmentation for Enhanced Crosslingual Performance,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper aims to explore the potential of leveraging Large Language Models (LLMs) for data augmentation in crosslingual commonsense reasoning datasets, where the available training data is extremely limited. To achieve this, we employ several LLMs including Dolly-v2, StableVicuna, ChatGPT, and GPT-4 to augment three datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we assess the effectiveness of fine-tuning smaller crosslingual models, mBERT and XLMR, using the synthesised data. We compare the performance of training with data generated in English and target languages, as well as translating the English-generated data into the target languages. Our experiments reveal the overall advantages of incorporating data generated by LLMs. Training on synthetic data generated by GPT-4, whether English or multilingual, improves performance consistently compared to the baseline. Other models also exhibit an overall increase in performance, however, their effectiveness decreases in some settings. We also ask native speakers to evaluate the naturalness and logical soundness of the generated examples for different languages. Human evaluation reveals that LLMs like ChatGPT and GPT-4 excel at generating natural text in most languages, except a few such as Tamil. Moreover, ChatGPT trails behind in generating plausible alternatives in comparison to the original dataset, while GPT-4 demonstrates competitive logic consistency in the synthesised data. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 17:33:27 GMT'}]",2023-05-24,"[['Whitehouse', 'Chenxi', ''], ['Choudhury', 'Monojit', ''], ['Aji', 'Alham Fikri', '']]",1,1,2023-05-23,1,3,1,2,0,2,91b2b47cabd800ef658b65bfe1f52b7293a740c3,258840943.0,https://www.semanticscholar.org/paper/91b2b47cabd800ef658b65bfe1f52b7293a740c3,arXiv.org,2023.0,43.0,17.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2161240241', 'name': 'Chenxi Whitehouse'}, {'authorId': '143990839', 'name': 'M. Choudhury'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}]","['City, University of London']",['United Kingdom'],2023-05
2305.14322,Ali Modarressi,"Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, Hinrich Sch\""utze",RET-LLM: Towards a General Read-Write Memory for Large Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have significantly advanced the field of natural language processing (NLP) through their extensive parameters and comprehensive data utilization. However, existing LLMs lack a dedicated memory unit, limiting their ability to explicitly store and retrieve knowledge for various tasks. In this paper, we propose RET-LLM a novel framework that equips LLMs with a general write-read memory unit, allowing them to extract, store, and recall knowledge from the text as needed for task performance. Inspired by Davidsonian semantics theory, we extract and save knowledge in the form of triplets. The memory unit is designed to be scalable, aggregatable, updatable, and interpretable. Through qualitative evaluations, we demonstrate the superiority of our proposed framework over baseline approaches in question answering tasks. Moreover, our framework exhibits robust performance in handling temporal-based question answering tasks, showcasing its ability to effectively manage time-dependent information. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 17:53:38 GMT'}]",2023-05-24,"[['Modarressi', 'Ali', ''], ['Imani', 'Ayyoob', ''], ['Fayyaz', 'Mohsen', ''], ['Schütze', 'Hinrich', '']]",0,0,2023-05-23,1,4,1,0,0,0,a22f3398ea865426c89ee66f4824ec626e56a864,258841042.0,https://www.semanticscholar.org/paper/a22f3398ea865426c89ee66f4824ec626e56a864,arXiv.org,2023.0,12.0,7.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2054744', 'name': 'Ali Modarressi'}, {'authorId': '51894641', 'name': 'Ayyoob Imani'}, {'authorId': '2133037029', 'name': 'Mohsen Fayyaz'}, {'authorId': '144418438', 'name': 'Hinrich Schütze'}]","['Ludwig-Maximilians-Universität München', 'Microsoft']",['Germany'],2023-05
2305.14387,Tianyi Zhang,"Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani,
  Jimmy Ba, Carlos Guestrin, Percy Liang, Tatsunori B. Hashimoto",AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback,,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) such as ChatGPT have seen widespread adoption due to their ability to follow user instructions well. Developing these LLMs involves a complex yet poorly understood workflow requiring training with human feedback. Replicating and understanding this instruction-following process faces three major challenges: the high cost of data collection, the lack of trustworthy evaluation, and the absence of reference method implementations. We address these challenges with AlpacaFarm, a simulator that enables research and development for learning from feedback at a low cost. First, we design LLM prompts to simulate human feedback that are 45x cheaper than crowdworkers and display high agreement with humans. Second, we propose an automatic evaluation and validate it against human instructions obtained on real-world interactions. Third, we contribute reference implementations for several methods (PPO, best-of-n, expert iteration, and more) that learn from pairwise feedback. Finally, as an end-to-end validation of AlpacaFarm, we train and evaluate eleven models on 10k pairs of real human feedback and show that rankings of models trained in AlpacaFarm match rankings of models trained on human data. As a demonstration of the research possible in AlpacaFarm, we find that methods that use a reward model can substantially improve over supervised fine-tuning and that our reference PPO implementation leads to a +10% improvement in win-rate against Davinci003. We release all components of AlpacaFarm at https://github.com/tatsu-lab/alpaca_farm. ","[{'version': 'v1', 'created': 'Mon, 22 May 2023 17:55:50 GMT'}, {'version': 'v2', 'created': 'Tue, 1 Aug 2023 05:46:21 GMT'}]",2023-08-02,"[['Dubois', 'Yann', ''], ['Li', 'Xuechen', ''], ['Taori', 'Rohan', ''], ['Zhang', 'Tianyi', ''], ['Gulrajani', 'Ishaan', ''], ['Ba', 'Jimmy', ''], ['Guestrin', 'Carlos', ''], ['Liang', 'Percy', ''], ['Hashimoto', 'Tatsunori B.', '']]",1,1,2023-05-22,2,9,3,1,0,1,cb6cc7d28d06a0d7c0d3f0d7ee551bbc86dbc3aa,258865545.0,https://www.semanticscholar.org/paper/cb6cc7d28d06a0d7c0d3f0d7ee551bbc86dbc3aa,arXiv.org,2023.0,71.0,79.0,19.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '47367640', 'name': 'Yann Dubois'}, {'authorId': '2145429039', 'name': 'Xuechen Li'}, {'authorId': '46199305', 'name': 'Rohan Taori'}, {'authorId': '2146332594', 'name': 'Tianyi Zhang'}, {'authorId': '2708454', 'name': 'Ishaan Gulrajani'}, {'authorId': '2503659', 'name': 'Jimmy Ba'}, {'authorId': '1730156', 'name': 'Carlos Guestrin'}, {'authorId': '145419642', 'name': 'Percy Liang'}, {'authorId': '2117567142', 'name': 'Tatsunori Hashimoto'}]",['University of Toronto'],['Canada'],2023-05
2305.14453,Subba Reddy Oota,"Pavan Kalyan Reddy Neerudu, Subba Reddy Oota, Mounika Marreddy,
  Venkateswara Rao Kagita, Manish Gupta",On Robustness of Finetuned Transformer-based NLP Models,"16 pages, 8 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Transformer-based pretrained models like BERT, GPT-2 and T5 have been finetuned for a large number of natural language processing (NLP) tasks, and have been shown to be very effective. However, while finetuning, what changes across layers in these models with respect to pretrained checkpoints is under-studied. Further, how robust are these models to perturbations in input text? Does the robustness vary depending on the NLP task for which the models have been finetuned? While there exists some work on studying robustness of BERT finetuned for a few NLP tasks, there is no rigorous study which compares this robustness across encoder only, decoder only and encoder-decoder models.   In this paper, we study the robustness of three language models (BERT, GPT-2 and T5) with eight different text perturbations on the General Language Understanding Evaluation (GLUE) benchmark. Also, we use two metrics (CKA and STIR) to quantify changes between pretrained and finetuned language model representations across layers. GPT-2 representations are more robust than BERT and T5 across multiple types of input perturbation. Although models exhibit good robustness broadly, dropping nouns, verbs or changing characters are the most impactful. Overall, this study provides valuable insights into perturbation-specific weaknesses of popular Transformer-based models which should be kept in mind when passing inputs. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 18:25:18 GMT'}]",2023-05-25,"[['Neerudu', 'Pavan Kalyan Reddy', ''], ['Oota', 'Subba Reddy', ''], ['Marreddy', 'Mounika', ''], ['Kagita', 'Venkateswara Rao', ''], ['Gupta', 'Manish', '']]",0,1,2023-05-23,1,5,1,2,2,0,a2007c352e2051475844aa8ff95f63202b728e79,258865491.0,https://www.semanticscholar.org/paper/a2007c352e2051475844aa8ff95f63202b728e79,arXiv.org,2023.0,43.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218867355', 'name': 'Pavan Kalyan Reddy Neerudu'}, {'authorId': '8307724', 'name': 'S. Oota'}, {'authorId': '25910248', 'name': 'Mounika Marreddy'}, {'authorId': '2366818', 'name': 'Venkateswara Rao Kagita'}, {'authorId': '2152950492', 'name': 'Manish Gupta'}]","['International Institute of Information Technology, Hyderabad', 'French Institute for Research in Computer Science and Automation', 'Microsoft']","['India', 'France']",2023-05
2305.14536,Jakub Macina,"Jakub Macina, Nico Daheim, Sankalan Pal Chowdhury, Tanmay Sinha, Manu
  Kapur, Iryna Gurevych, Mrinmaya Sachan",MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems,"Jakub Macina, Nico Daheim, and Sankalan Pal Chowdhury contributed
  equally to this work. Code and dataset available:
  https://github.com/eth-nlped/mathdial",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Although automatic dialogue tutors hold great potential in making education personalized and more accessible, research on such systems has been hampered by a lack of sufficiently large and high-quality datasets. However, collecting such datasets remains challenging, as recording tutoring sessions raises privacy concerns and crowdsourcing leads to insufficient data quality. To address this problem, we propose a framework to semi-synthetically generate such dialogues by pairing real teachers with a large language model (LLM) scaffolded to represent common student errors. In this paper, we describe our ongoing efforts to use this framework to collect MathDial, a dataset of currently ca. 1.5k tutoring dialogues grounded in multi-step math word problems. We show that our dataset exhibits rich pedagogical properties, focusing on guiding students using sense-making questions to let them explore problems. Moreover, we outline that MathDial and its grounding annotations can be used to finetune language models to be more effective tutors (and not just solvers) and highlight remaining challenges that need to be addressed by the research community. We will release our dataset publicly to foster research in this socially important area of NLP. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 21:44:56 GMT'}]",2023-05-25,"[['Macina', 'Jakub', ''], ['Daheim', 'Nico', ''], ['Chowdhury', 'Sankalan Pal', ''], ['Sinha', 'Tanmay', ''], ['Kapur', 'Manu', ''], ['Gurevych', 'Iryna', ''], ['Sachan', 'Mrinmaya', '']]",0,0,2023-05-23,1,7,1,0,0,0,6cd26d124ffeb6ce301ef351aada27fa0852f81b,258865403.0,https://www.semanticscholar.org/paper/6cd26d124ffeb6ce301ef351aada27fa0852f81b,arXiv.org,2023.0,72.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '23126830', 'name': 'Jakub Macina'}, {'authorId': '2048028927', 'name': 'Nico Daheim'}, {'authorId': '2105636395', 'name': 'Sankalan Pal Chowdhury'}, {'authorId': '145679048', 'name': 'Tanmay Sinha'}, {'authorId': '2465316', 'name': 'Manu Kapur'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}, {'authorId': '2790926', 'name': 'Mrinmaya Sachan'}]",['ETH Zurich'],['Switzerland'],2023-05
2305.14556,Tiziano Labruna,"Tiziano Labruna, Sofia Brenna, Andrea Zaninello, Bernardo Magnini",Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented Dialogues and Annotations,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large pre-trained language models have exhibited unprecedented capabilities in producing high-quality text via prompting techniques. This fact introduces new possibilities for data collection and annotation, particularly in situations where such data is scarce, complex to gather, expensive, or even sensitive. In this paper, we explore the potential of these models to generate and annotate goal-oriented dialogues, and conduct an in-depth analysis to evaluate their quality. Our experiments employ ChatGPT, and encompass three categories of goal-oriented dialogues (task-oriented, collaborative, and explanatory), two generation modes (interactive and one-shot), and two languages (English and Italian). Based on extensive human-based evaluations, we demonstrate that the quality of generated dialogues and annotations is on par with those generated by humans. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 22:31:01 GMT'}]",2023-05-25,"[['Labruna', 'Tiziano', ''], ['Brenna', 'Sofia', ''], ['Zaninello', 'Andrea', ''], ['Magnini', 'Bernardo', '']]",1,1,2023-05-23,1,4,2,1,0,1,7307ee3c819c34b7c93ccbbd330a4c889956b36f,258866115.0,https://www.semanticscholar.org/paper/7307ee3c819c34b7c93ccbbd330a4c889956b36f,International Conference of the Italian Association for Artificial Intelligence,2023.0,67.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2140073142', 'name': 'Tiziano Labruna'}, {'authorId': '2218802788', 'name': 'Sofia Brenna'}, {'authorId': '3261343', 'name': 'Andrea Zaninello'}, {'authorId': '1712352', 'name': 'B. Magnini'}]","['Fondazione Bruno Kessler', 'Free University of Bozen-Bolzano']",['Italy'],2023-05
2305.14752,Norbert Tihanyi Dr.,"Yiannis Charalambous, Norbert Tihanyi, Ridhi Jain, Youcheng Sun,
  Mohamed Amine Ferrag, Lucas C. Cordeiro",A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification,,,,,cs.SE cs.AI cs.FL cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this paper we present a novel solution that combines the capabilities of Large Language Models (LLMs) with Formal Verification strategies to verify and automatically repair software vulnerabilities. Initially, we employ Bounded Model Checking (BMC) to locate the software vulnerability and derive a counterexample. The counterexample provides evidence that the system behaves incorrectly or contains a vulnerability. The counterexample that has been detected, along with the source code, are provided to the LLM engine. Our approach involves establishing a specialized prompt language for conducting code debugging and generation to understand the vulnerability's root cause and repair the code. Finally, we use BMC to verify the corrected version of the code generated by the LLM. As a proof of concept, we create ESBMC-AI based on the Efficient SMT-based Context-Bounded Model Checker (ESBMC) and a pre-trained Transformer model, specifically gpt-3.5-turbo, to detect and fix errors in C programs. Our experimentation involved generating a dataset comprising 1000 C code samples, each consisting of 20 to 50 lines of code. Notably, our proposed method achieved an impressive success rate of up to 80% in repairing vulnerable code encompassing buffer overflow and pointer dereference failures. We assert that this automated approach can effectively incorporate into the software development lifecycle's continuous integration and deployment (CI/CD) process. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 05:54:10 GMT'}]",2023-05-25,"[['Charalambous', 'Yiannis', ''], ['Tihanyi', 'Norbert', ''], ['Jain', 'Ridhi', ''], ['Sun', 'Youcheng', ''], ['Ferrag', 'Mohamed Amine', ''], ['Cordeiro', 'Lucas C.', '']]",0,1,2023-05-24,1,6,4,1,0,1,f542c184eec4c3252d678118a7f32cf327b6f23a,258865418.0,https://www.semanticscholar.org/paper/f542c184eec4c3252d678118a7f32cf327b6f23a,arXiv.org,2023.0,62.0,10.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218867854', 'name': 'Yiannis Charalambous'}, {'authorId': '2752349', 'name': 'Norbert Tihanyi'}, {'authorId': '2113688343', 'name': 'Ridhi Jain'}, {'authorId': '2116605723', 'name': 'Youcheng Sun'}, {'authorId': '2864573', 'name': 'M. Ferrag'}, {'authorId': '144040212', 'name': 'L. Cordeiro'}]","['Technology Innovation Institute', 'University of Manchester']","['United Kingdom', 'United Arab Emirates']",2023-05
2305.14877,Sohee Yang,"Sohee Yang, Jonghyeon Kim, Joel Jang, Seonghyeon Ye, Hyunji Lee,
  Minjoon Seo",Improving Probability-based Prompt Selection Through Unified Evaluation and Analysis,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have demonstrated great capabilities in solving a wide range of tasks in a resource-efficient manner through prompting, which does not require task-specific training, but suffers from performance fluctuation when there are multiple prompt candidates. Previous works have introduced gradient-free probability-based prompt selection methods that aim to choose the optimal prompt among the candidates for a given task but fail to provide a comprehensive and fair comparison between each other. In this paper, we propose a unified framework to interpret and evaluate the existing probability-based prompt selection methods by performing extensive experiments on 13 common NLP tasks. We find that all existing methods can be unified into some variant of the method that maximizes the mutual information between the input and the corresponding model output (denoted as MI). Using the finding, we develop several variants of MI and increases the effectiveness of the best prompt selection method from 87.79% to 94.98%, measured as the ratio of the performance of the selected prompt to that of the optimal oracle prompt. Furthermore, we propose a novel calibration method called Calibration by Marginalization (CBM) that is orthogonal to existing methods and helps increase the prompt selection effectiveness of the best method by 99.44%. The code and datasets used in our work will be released at https://github.com/soheeyang/unified-prompt-selection. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 08:29:50 GMT'}]",2023-05-25,"[['Yang', 'Sohee', ''], ['Kim', 'Jonghyeon', ''], ['Jang', 'Joel', ''], ['Ye', 'Seonghyeon', ''], ['Lee', 'Hyunji', ''], ['Seo', 'Minjoon', '']]",0,0,2023-05-24,1,6,1,0,0,0,ab322bef985895df5ebeab6b38d63456e1e38e86,258865455.0,https://www.semanticscholar.org/paper/ab322bef985895df5ebeab6b38d63456e1e38e86,arXiv.org,2023.0,33.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '16110760', 'name': 'Sohee Yang'}, {'authorId': '2117146187', 'name': 'Jonghyeon Kim'}, {'authorId': '2000091730', 'name': 'Joel Jang'}, {'authorId': '2152111477', 'name': 'Seonghyeon Ye'}, {'authorId': '2140191673', 'name': 'Hyunji Lee'}, {'authorId': '4418074', 'name': 'Minjoon Seo'}]","['University College London', 'Korea Advanced Institute of Science and Technology', 'Dongguk University']","['South Korea', 'United Kingdom']",2023-05
2305.14902,Yuxia Wang,"Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem
  Shelmanov, Akim Tsvigun, Chenxi Whitehouse, Osama Mohammed Afzal, Tarek
  Mahmoud, Alham Fikri Aji, Preslav Nakov","M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection",11 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries, but this has also resulted in concerns regarding the potential misuse of such texts in journalism, educational, and academic context. In this work, we aim to develop automatic systems to identify machine-generated text and to detect potential misuse. We first introduce a large-scale benchmark M4, which is multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Using the dataset, we experiment with a number of methods and we show that it is challenging for detectors to generalize well on unseen examples if they are either from different domains or are generated by different large language models. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and there is a lot of room for improvement. We believe that our dataset M4, which covers different generators, domains and languages, will enable future research towards more robust approaches for this pressing societal problem. The M4 dataset is available at https://github.com/mbzuai-nlp/M4. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 08:55:11 GMT'}]",2023-05-25,"[['Wang', 'Yuxia', ''], ['Mansurov', 'Jonibek', ''], ['Ivanov', 'Petar', ''], ['Su', 'Jinyan', ''], ['Shelmanov', 'Artem', ''], ['Tsvigun', 'Akim', ''], ['Whitehouse', 'Chenxi', ''], ['Afzal', 'Osama Mohammed', ''], ['Mahmoud', 'Tarek', ''], ['Aji', 'Alham Fikri', ''], ['Nakov', 'Preslav', '']]",0,0,2023-05-24,1,11,1,0,0,0,60730c7baeeabf4ff2fd824effc40bca465b1334,258866053.0,https://www.semanticscholar.org/paper/60730c7baeeabf4ff2fd824effc40bca465b1334,arXiv.org,2023.0,35.0,12.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2115829571', 'name': 'Yuxia Wang'}, {'authorId': '2218861055', 'name': 'Jonibek Mansurov'}, {'authorId': '2058455381', 'name': 'Petar Ivanov'}, {'authorId': '2116966710', 'name': 'Jinyan Su'}, {'authorId': '1967424', 'name': 'Artem Shelmanov'}, {'authorId': '2164381839', 'name': 'Akim Tsvigun'}, {'authorId': '2161240241', 'name': 'Chenxi Whitehouse'}, {'authorId': '49843300', 'name': 'Osama Mohammed Afzal'}, {'authorId': '2218209429', 'name': 'Tarek Mahmoud'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]",['Mohamed bin Zayed University of Artificial Intelligence'],['United Arab Emirates'],2023-05
2305.14926,Xingchen Wan,"Xingchen Wan, Ruoxi Sun, Hootan Nakhost, Hanjun Dai, Julian Martin
  Eisenschlos, Sercan O. Arik, Tomas Pfister",Universal Self-adaptive Prompting,"10 pages, 3 figures, 4 tables (19 pages, 5 figures and 9 tables
  including references and appendices)",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  A hallmark of modern large language models (LLMs) is their impressive general zero-shot and few-shot abilities, often elicited through prompt-based and/or in-context learning. However, while highly coveted and being the most general, zero-shot performances in LLMs are still typically weaker due to the lack of guidance and the difficulty of applying existing automatic prompt design methods in general tasks when ground-truth labels are unavailable. In this study, we address this by presenting Universal Self-adaptive Prompting (USP), an automatic prompt design approach specifically tailored for zero-shot learning (while compatible with few-shot). Requiring only a small amount of unlabeled data & an inference-only LLM, USP is highly versatile: to achieve universal prompting, USP categorizes a possible NLP task into one of the three possible task types, and then uses a corresponding selector to select the most suitable queries & zero-shot model-generated responses as pseudo-demonstrations, thereby generalizing ICL to the zero-shot setup in a fully automated way. We evaluate zero-shot USP with two PaLM models, and demonstrate performances that are considerably stronger than standard zero-shot baselines and are comparable to or even superior than few-shot baselines across more than 20 natural language understanding (NLU) and natural language generation (NLG) tasks. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 09:09:48 GMT'}]",2023-05-25,"[['Wan', 'Xingchen', ''], ['Sun', 'Ruoxi', ''], ['Nakhost', 'Hootan', ''], ['Dai', 'Hanjun', ''], ['Eisenschlos', 'Julian Martin', ''], ['Arik', 'Sercan O.', ''], ['Pfister', 'Tomas', '']]",0,0,2023-05-24,1,7,3,1,0,1,930e86d49477c9d3305cd1f9d01b93749f85bb8b,258866077.0,https://www.semanticscholar.org/paper/930e86d49477c9d3305cd1f9d01b93749f85bb8b,arXiv.org,2023.0,91.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1470501980', 'name': 'Xingchen Wan'}, {'authorId': '2068169921', 'name': 'Ruoxi Sun'}, {'authorId': '3346298', 'name': 'Hootan Nakhost'}, {'authorId': '2791430', 'name': 'H. Dai'}, {'authorId': '117595858', 'name': 'Julian Martin Eisenschlos'}, {'authorId': '2676352', 'name': 'Sercan Ö. Arik'}, {'authorId': '1945962', 'name': 'Tomas Pfister'}]",['University of Oxford'],['United Kingdom'],2023-05
2305.14973,Jiazheng Li,"Jiazheng Li, Runcong Zhao, Yulan He, Lin Gui",OverPrompt: Enhancing ChatGPT Capabilities through an Efficient In-Context Learning Approach,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The exceptional performance of pre-trained large language models has revolutionised various applications, but their adoption in production environments is hindered by prohibitive costs and inefficiencies, particularly when utilising long prompts. This paper proposes OverPrompt, an in-context learning method aimed at improving LLM efficiency and performance by processing multiple inputs in parallel. Evaluated across diverse datasets, OverPrompt enhances task efficiency and integrates a diverse range of examples for improved performance. Particularly, it amplifies fact-checking and sentiment analysis tasks when supplemented with contextual information. Synthetic data grouping further enhances performance, suggesting a viable approach for data augmentation. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 10:08:04 GMT'}]",2023-05-25,"[['Li', 'Jiazheng', ''], ['Zhao', 'Runcong', ''], ['He', 'Yulan', ''], ['Gui', 'Lin', '']]",1,1,2023-05-24,1,4,1,1,0,1,bdb0cc86a8dd8f3a1558b7f3a1d001eea521c6c1,258865715.0,https://www.semanticscholar.org/paper/bdb0cc86a8dd8f3a1558b7f3a1d001eea521c6c1,arXiv.org,2023.0,17.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '92861741', 'name': 'Jiazheng Li'}, {'authorId': '2047279522', 'name': 'Runcong Zhao'}, {'authorId': '1390509967', 'name': 'Yulan He'}, {'authorId': '145096580', 'name': 'Lin Gui'}]","['Queen Mary University of London', ""King's College London"", 'The Alan Turing Institute']",['United Kingdom'],2023-05
2305.14976,Md Tawkat Islam Khondaker,"Md Tawkat Islam Khondaker, Abdul Waheed, El Moatez Billah Nagoudi,
  Muhammad Abdul-Mageed",GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP,Work in progress,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recent emergence of ChatGPT has brought a revolutionary change in the landscape of NLP. Although ChatGPT has consistently shown impressive performance on English benchmarks, its exact capabilities on most other languages remain largely unknown. To better understand ChatGPT's capabilities on Arabic, we present a large-scale evaluation of the model on a broad range of Arabic NLP tasks. Namely, we evaluate ChatGPT on 32 diverse natural language understanding and generation tasks on over 60 different datasets. To the best of our knowledge, our work offers the first performance analysis of ChatGPT on Arabic NLP at such a massive scale. Our results show that, despite its success on English benchmarks, ChatGPT trained in-context (few-shot) is consistently outperformed by much smaller dedicated models finetuned on Arabic. These results suggest that there is significant place for improvement for instruction-tuned LLMs such as ChatGPT. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 10:12:39 GMT'}]",2023-05-25,"[['Khondaker', 'Md Tawkat Islam', ''], ['Waheed', 'Abdul', ''], ['Nagoudi', 'El Moatez Billah', ''], ['Abdul-Mageed', 'Muhammad', '']]",1,1,2023-05-24,1,4,2,1,0,1,7782055e33ee248ef47b1415624c2efb7a7e8410,258865928.0,https://www.semanticscholar.org/paper/7782055e33ee248ef47b1415624c2efb7a7e8410,arXiv.org,2023.0,96.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '118865912', 'name': 'Md. Tawkat Islam Khondaker'}, {'authorId': '2053570954', 'name': 'Abdul Waheed'}, {'authorId': '17771023', 'name': 'El Moatez Billah Nagoudi'}, {'authorId': '2065312024', 'name': 'M. Abdul-Mageed'}]","['University of British Columbia', 'Mohamed bin Zayed University of Artificial Intelligence']","['Canada', 'United Arab Emirates']",2023-05
2305.14982,Firoj Alam,"Ahmed Abdelali, Hamdy Mubarak, Shammur Absar Chowdhury, Maram
  Hasanain, Basel Mousi, Sabri Boughorbel, Yassine El Kheir, Daniel Izham,
  Fahim Dalvi, Majd Hawasly, Nizi Nazar, Yousseif Elshahawy, Ahmed Ali, Nadir
  Durrani, Natasa Milic-Frayling, Firoj Alam",Benchmarking Arabic AI with Large Language Models,"Foundation Models, Large Language Models, Arabic NLP, Arabic Speech,
  Arabic AI, , CHatGPT Evaluation, USM Evaluation, Whisper Evaluation",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  With large Foundation Models (FMs), language technologies (AI in general) are entering a new paradigm: eliminating the need for developing large-scale task-specific datasets and supporting a variety of tasks through set-ups ranging from zero-shot to few-shot learning. However, understanding FMs capabilities requires a systematic benchmarking effort by comparing FMs performance with the state-of-the-art (SOTA) task-specific models. With that goal, past work focused on the English language and included a few efforts with multiple languages. Our study contributes to ongoing research by evaluating FMs performance for standard Arabic NLP and Speech processing, including a range of tasks from sequence tagging to content classification across diverse domains. We start with zero-shot learning using GPT-3.5-turbo, Whisper, and USM, addressing 33 unique tasks using 59 publicly available datasets resulting in 96 test setups. For a few tasks, FMs performs on par or exceeds the performance of the SOTA models but for the majority it under-performs. Given the importance of prompt for the FMs performance, we discuss our prompt strategies in detail and elaborate on our findings. Our future work on Arabic AI will explore few-shot prompting, expand the range of tasks, and investigate additional open-source models. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 10:16:16 GMT'}]",2023-05-25,"[['Abdelali', 'Ahmed', ''], ['Mubarak', 'Hamdy', ''], ['Chowdhury', 'Shammur Absar', ''], ['Hasanain', 'Maram', ''], ['Mousi', 'Basel', ''], ['Boughorbel', 'Sabri', ''], ['Kheir', 'Yassine El', ''], ['Izham', 'Daniel', ''], ['Dalvi', 'Fahim', ''], ['Hawasly', 'Majd', ''], ['Nazar', 'Nizi', ''], ['Elshahawy', 'Yousseif', ''], ['Ali', 'Ahmed', ''], ['Durrani', 'Nadir', ''], ['Milic-Frayling', 'Natasa', ''], ['Alam', 'Firoj', '']]",0,1,2023-05-24,1,16,2,1,0,1,c5fa70db839fd05b1111f3586a601d8a93e78d0c,258865657.0,https://www.semanticscholar.org/paper/c5fa70db839fd05b1111f3586a601d8a93e78d0c,arXiv.org,2023.0,125.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1683403', 'name': 'Ahmed Abdelali'}, {'authorId': '143779235', 'name': 'Hamdy Mubarak'}, {'authorId': '1725417821', 'name': 'Shammur A. Chowdhury'}, {'authorId': '2905745', 'name': 'Maram Hasanain'}, {'authorId': '2171367840', 'name': 'Basel Mousi'}, {'authorId': '2466162', 'name': 'S. Boughorbel'}, {'authorId': '2189476655', 'name': 'Yassine El Kheir'}, {'authorId': '2177436744', 'name': 'Daniel Izham'}, {'authorId': '6415321', 'name': 'Fahim Dalvi'}, {'authorId': '2762811', 'name': 'Majd Hawasly'}, {'authorId': '2218353460', 'name': 'Nizi Nazar'}, {'authorId': '2218145245', 'name': 'Yousseif Elshahawy'}, {'authorId': '2109102523', 'name': 'Ahmed M. Ali'}, {'authorId': '145938140', 'name': 'Nadir Durrani'}, {'authorId': '1398136050', 'name': 'Natasa Milic-Frayling'}, {'authorId': '37784060', 'name': 'Firoj Alam'}]","['Kanari AI, Doha, Qatar', 'Qatar Computing Research Institute']",['Qatar'],2023-05
2305.14992,Shibo Hao,"Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe
  Wang, Zhiting Hu",Reasoning with Language Model is Planning with World Model,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have shown remarkable reasoning capabilities, especially when prompted to generate intermediate reasoning steps (e.g., Chain-of-Thought, CoT). However, LLMs can still struggle with problems that are easy for humans, such as generating action plans for executing tasks in a given environment, or performing complex math, logical, and commonsense reasoning. The deficiency stems from the key fact that LLMs lack an internal $\textit{world model}$ to predict the world $\textit{state}$ (e.g., environment status, intermediate variable values) and simulate long-term outcomes of actions. This prevents LLMs from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new LLM reasoning framework, $\underline{R}\textit{easoning vi}\underline{a} \underline{P}\textit{lanning}$ $\textbf{(RAP)}$. RAP repurposes the LLM as both a world model and a reasoning agent, and incorporates a principled planning algorithm (based on Monto Carlo Tree Search) for strategic exploration in the vast reasoning space. During reasoning, the LLM (as agent) incrementally builds a reasoning tree under the guidance of the LLM (as world model) and task-specific rewards, and obtains a high-reward reasoning path efficiently with a proper balance between exploration $\textit{vs.}$ exploitation. We apply RAP to a variety of challenging reasoning problems including plan generation, math reasoning, and logical inference. Empirical results on these tasks demonstrate the superiority of RAP over various strong baselines, including CoT and least-to-most prompting with self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33% relative improvement in a plan generation setting. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 10:28:28 GMT'}]",2023-05-25,"[['Hao', 'Shibo', ''], ['Gu', 'Yi', ''], ['Ma', 'Haodi', ''], ['Hong', 'Joshua Jiahua', ''], ['Wang', 'Zhen', ''], ['Wang', 'Daisy Zhe', ''], ['Hu', 'Zhiting', '']]",0,1,2023-05-24,1,7,3,2,1,1,5dbffedcabe3fa43060ebbe2b1789500edfd871f,258865812.0,https://www.semanticscholar.org/paper/5dbffedcabe3fa43060ebbe2b1789500edfd871f,arXiv.org,2023.0,90.0,47.0,8.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2128965713', 'name': 'Shibo Hao'}, {'authorId': '2112578816', 'name': 'Yi Gu'}, {'authorId': '2110816708', 'name': 'Haodi Ma'}, {'authorId': '2218162745', 'name': 'Joshua Jiahua Hong'}, {'authorId': '47197370', 'name': 'Zhen Wang'}, {'authorId': '2111220343', 'name': 'D. Wang'}, {'authorId': '2749311', 'name': 'Zhiting Hu'}]",['Mohamed bin Zayed University of Artificial Intelligence'],['United Arab Emirates'],2023-05
2305.15002,Asahi Ushio,Asahi Ushio and Jose Camacho Collados and Steven Schockaert,A RelEntLess Benchmark for Modelling Graded Relations between Named Entities,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Relations such as ""is influenced by"", ""is known for"" or ""is a competitor of"" are inherently graded: we can rank entity pairs based on how well they satisfy these relations, but it is hard to draw a line between those pairs that satisfy them and those that do not. Such graded relations play a central role in many applications, yet they are typically not covered by existing Knowledge Graphs. In this paper, we consider the possibility of using Large Language Models (LLMs) to fill this gap. To this end, we introduce a new benchmark, in which entity pairs have to be ranked according to how much they satisfy a given graded relation. The task is formulated as a few-shot ranking problem, where models only have access to a description of the relation and five prototypical instances. We use the proposed benchmark to evaluate state-of-the-art relation embedding strategies as well as several recent LLMs, covering both publicly available LLMs and closed models such as GPT-4. Overall, we find a strong correlation between model size and performance, with smaller Language Models struggling to outperform a naive baseline. The results of the largest Flan-T5 and OPT models are remarkably strong, although a clear gap with human performance remains. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 10:41:24 GMT'}]",2023-05-25,"[['Ushio', 'Asahi', ''], ['Collados', 'Jose Camacho', ''], ['Schockaert', 'Steven', '']]",0,1,2023-05-24,1,3,2,5,3,2,a396176a31194976d4676c3f830209c129bac57c,258866213.0,https://www.semanticscholar.org/paper/a396176a31194976d4676c3f830209c129bac57c,arXiv.org,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '27044733', 'name': 'Asahi Ushio'}, {'authorId': '1387447871', 'name': 'José Camacho-Collados'}, {'authorId': '2265382', 'name': 'S. Schockaert'}]",['Cardiff University'],['United Kingdom'],2023-05
2305.15035,Wei-Lin Chen,"Wei-Lin Chen, Cheng-Kuang Wu, Hsin-Hsi Chen",Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations,Work in progress,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LMs) have exhibited superior in-context learning (ICL) ability to adopt to target tasks by prompting with a few input-output demonstrations. Towards better ICL, different methods are proposed to select representative demonstrations from existing training corpora. However, such a setting is not aligned with real-world practices, as end-users usually query LMs without accesses to demonstration pools. Inspired by evidence suggesting LMs' zero-shot capabilities are underrated, and the role of demonstrations are primarily for exposing models' intrinsic functionalities, we introduce Self-ICL, a simple framework for zero-shot ICL. Given a test input, Self-ICL first prompts the model to generate pseudo-inputs. Next, the model predicts pseudo-labels for the pseudo-inputs via zero-shot prompting. Finally, we construct pseudo-demonstrations from pseudo-input-label pairs, and perform ICL for the test input. Evaluation on BIG-Bench Hard shows Self-ICL steadily surpasses zero-shot and zero-shot chain-of-thought baselines on head-to-head and all-task average performance. Our findings suggest the possibility to bootstrap LMs' intrinsic capabilities towards better zero-shot performance. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 11:22:34 GMT'}]",2023-05-25,"[['Chen', 'Wei-Lin', ''], ['Wu', 'Cheng-Kuang', ''], ['Chen', 'Hsin-Hsi', '']]",0,0,2023-05-24,1,3,1,0,0,0,fe425e341cf646689e42adead17f14eeac5d03e6,258865679.0,https://www.semanticscholar.org/paper/fe425e341cf646689e42adead17f14eeac5d03e6,arXiv.org,2023.0,43.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2128184431', 'name': 'Wei-Lin Chen'}, {'authorId': '2217944277', 'name': 'Cheng-Kuang Wu'}, {'authorId': '2145279517', 'name': 'Hsin-Hsi Chen'}]","['https://github.com/ntunlplab/Self-ICL', 'National Taiwan University']",['Taiwan'],2023-05
2305.15041,Veniamin Veselovsky,"Veniamin Veselovsky, Manoel Horta Ribeiro, Akhil Arora, Martin
  Josifoski, Ashton Anderson, Robert West",Generating Faithful Synthetic Data with Large Language Models: A Case Study in Computational Social Science,8 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have democratized synthetic data generation, which in turn has the potential to simplify and broaden a wide gamut of NLP tasks. Here, we tackle a pervasive problem in synthetic data generation: its generative distribution often differs from the distribution of real-world data researchers care about (in other words, it is unfaithful). In a case study on sarcasm detection, we study three strategies to increase the faithfulness of synthetic data: grounding, filtering, and taxonomy-based generation. We evaluate these strategies using the performance of classifiers trained with generated synthetic data on real-world data. While all three strategies improve the performance of classifiers, we find that grounding works best for the task at hand. As synthetic data generation plays an ever-increasing role in NLP research, we expect this work to be a stepping stone in improving its utility. We conclude this paper with some recommendations on how to generate high(er)-fidelity synthetic data for specific tasks. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 11:27:59 GMT'}]",2023-05-25,"[['Veselovsky', 'Veniamin', ''], ['Ribeiro', 'Manoel Horta', ''], ['Arora', 'Akhil', ''], ['Josifoski', 'Martin', ''], ['Anderson', 'Ashton', ''], ['West', 'Robert', '']]",0,0,2023-05-24,1,6,1,0,0,0,5af9cf0b695faf2eb94d74bf76dab1a311638ca3,258866005.0,https://www.semanticscholar.org/paper/5af9cf0b695faf2eb94d74bf76dab1a311638ca3,arXiv.org,2023.0,26.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '93258626', 'name': 'V. Veselovsky'}, {'authorId': '2164356774', 'name': 'Manoel Horta Ribeiro'}, {'authorId': '2644814', 'name': 'Akhil Arora'}, {'authorId': '65826567', 'name': 'Martin Josifoski'}, {'authorId': '32071555', 'name': 'Ashton Anderson'}, {'authorId': '145387102', 'name': 'Robert West'}]",['University of Toronto'],['Canada'],2023-05
2305.15186,Tetsu Kasanishi,"Tetsu Kasanishi, Masaru Isonuma, Junichiro Mori, Ichiro Sakata",SciReviewGen: A Large-scale Dataset for Automatic Literature Review Generation,"ACL findings 2023 (to be appeared). arXiv admin note: text overlap
  with arXiv:1810.04020 by other authors",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic literature review generation is one of the most challenging tasks in natural language processing. Although large language models have tackled literature review generation, the absence of large-scale datasets has been a stumbling block to the progress. We release SciReviewGen, consisting of over 10,000 literature reviews and 690,000 papers cited in the reviews. Based on the dataset, we evaluate recent transformer-based summarization models on the literature review generation task, including Fusion-in-Decoder extended for literature review generation. Human evaluation results show that some machine-generated summaries are comparable to human-written reviews, while revealing the challenges of automatic literature review generation such as hallucinations and a lack of detailed information. Our dataset and code are available at https://github.com/tetsu9923/SciReviewGen. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 14:26:30 GMT'}]",2023-05-25,"[['Kasanishi', 'Tetsu', ''], ['Isonuma', 'Masaru', ''], ['Mori', 'Junichiro', ''], ['Sakata', 'Ichiro', '']]",0,0,2023-05-24,1,4,2,0,0,0,b00fafe7afdde9f8e015b1e1a7fb5204d02786fa,258866124.0,https://www.semanticscholar.org/paper/b00fafe7afdde9f8e015b1e1a7fb5204d02786fa,Annual Meeting of the Association for Computational Linguistics,2023.0,68.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2136165064', 'name': 'Tetsu Kasanishi'}, {'authorId': '24905917', 'name': 'Masaru Isonuma'}, {'authorId': '49010536', 'name': 'Junichiro Mori'}, {'authorId': '2850710', 'name': 'I. Sakata'}]","['RIKEN Center for Advanced Intelligence Project', 'The University of Tokyo']",['Japan'],2023-05
2305.15282,Rohan Bhambhoria,"Rohan Bhambhoria, Lei Chen, Xiaodan Zhu",A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification,Accepted at ACL 2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, large language models (LLMs) have achieved strong performance on benchmark tasks, especially in zero or few-shot settings. However, these benchmarks often do not adequately address the challenges posed in the real-world, such as that of hierarchical classification. In order to address this challenge, we propose refactoring conventional tasks on hierarchical datasets into a more indicative long-tail prediction task. We observe LLMs are more prone to failure in these cases. To address these limitations, we propose the use of entailment-contradiction prediction in conjunction with LLMs, which allows for strong performance in a strict zero-shot setting. Importantly, our method does not require any parameter updates, a resource-intensive process and achieves strong performance across multiple datasets. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 16:04:26 GMT'}, {'version': 'v2', 'created': 'Fri, 26 May 2023 13:57:52 GMT'}]",2023-05-29,"[['Bhambhoria', 'Rohan', ''], ['Chen', 'Lei', ''], ['Zhu', 'Xiaodan', '']]",0,0,2023-05-24,2,3,2,0,0,0,5412e54947f6574095174d7b85da67a5bfba4e46,258866099.0,https://www.semanticscholar.org/paper/5412e54947f6574095174d7b85da67a5bfba4e46,Annual Meeting of the Association for Computational Linguistics,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2008160154', 'name': 'R. Bhambhoria'}, {'authorId': '144595980', 'name': 'L. Chen'}, {'authorId': '2130251018', 'name': 'Xiao-Dan Zhu'}]","[""Queen's University"", 'Rakuten Institute of Technology (RIT) Boston, MA']",['Canada'],2023-05
2305.15299,Evangelos Pournaras,Evangelos Pournaras,"Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond",,,,,cs.CY cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models of artificial intelligence (AI), such as ChatGPT, find remarkable but controversial applicability in science and research. This paper reviews epistemological challenges, ethical and integrity risks in science conduct in the advent of generative AI. This is with the aim to lay new timely foundations for a high-quality research ethics review. The role of AI language models as a research instrument and subject is scrutinized along with ethical implications for scientists, participants and reviewers. New emerging practices for research ethics review are discussed, concluding with ten recommendations that shape a response for a more responsible research conduct in the era of AI. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 16:23:46 GMT'}, {'version': 'v2', 'created': 'Thu, 20 Jul 2023 10:43:57 GMT'}, {'version': 'v3', 'created': 'Wed, 26 Jul 2023 20:35:40 GMT'}, {'version': 'v4', 'created': 'Sat, 29 Jul 2023 12:54:20 GMT'}]",2023-08-01,"[['Pournaras', 'Evangelos', '']]",1,1,2023-05-24,4,1,3,1,0,1,10d44cf3fee9b859cea327ea0c22ed03303605eb,259991256.0,https://www.semanticscholar.org/paper/10d44cf3fee9b859cea327ea0c22ed03303605eb,,2023.0,49.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3129259', 'name': 'Evangelos Pournaras'}]",['University of Leeds'],['United Kingdom'],2023-05
2305.15323,Sukhpal Singh Gill,Sukhpal Singh Gill and Rupinder Kaur,ChatGPT: Vision and Challenges,,"Internet of Things and Cyber-Physical Systems Volume 3, 2023,
  Pages 262-271",10.1016/j.iotcps.2023.05.004,,cs.CY cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Artificial intelligence (AI) and machine learning have changed the nature of scientific inquiry in recent years. Of these, the development of virtual assistants has accelerated greatly in the past few years, with ChatGPT becoming a prominent AI language model. In this study, we examine the foundations, vision, research challenges of ChatGPT. This article investigates into the background and development of the technology behind it, as well as its popular applications. Moreover, we discuss the advantages of bringing everything together through ChatGPT and Internet of Things (IoT). Further, we speculate on the future of ChatGPT by considering various possibilities for study and development, such as energy-efficiency, cybersecurity, enhancing its applicability to additional technologies (Robotics and Computer Vision), strengthening human-AI communications, and bridging the technological gap. Finally, we discuss the important ethics and current trends of ChatGPT. ","[{'version': 'v1', 'created': 'Mon, 8 May 2023 14:54:44 GMT'}]",2023-05-25,"[['Gill', 'Sukhpal Singh', ''], ['Kaur', 'Rupinder', '']]",1,1,2023-05-08,1,2,2,1,0,1,385644adf8fc0d79a093ec4552035987c28cbd49,258644689.0,https://www.semanticscholar.org/paper/385644adf8fc0d79a093ec4552035987c28cbd49,Internet of Things and Cyber-Physical Systems,2023.0,63.0,26.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31043248', 'name': 'S. S. Gill'}, {'authorId': '2130749816', 'name': 'Rupinder Kaur'}]","['Queen Mary University of London', ""King's College Hospital""]",['United Kingdom'],2023-05
2305.15334,Shishir G. Patil,"Shishir G. Patil, Tianjun Zhang, Xin Wang, Joseph E. Gonzalez",Gorilla: Large Language Model Connected with Massive APIs,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis. However, their potential to effectively use tools via API calls remains unfulfilled. This is a challenging task even for today's state-of-the-art LLMs such as GPT-4, largely due to their inability to generate accurate input arguments and their tendency to hallucinate the wrong usage of an API call. We release Gorilla, a finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls. When combined with a document retriever, Gorilla demonstrates a strong capability to adapt to test-time document changes, enabling flexible user updates or version changes. It also substantially mitigates the issue of hallucination, commonly encountered when prompting LLMs directly. To evaluate the model's ability, we introduce APIBench, a comprehensive dataset consisting of HuggingFace, TorchHub, and TensorHub APIs. The successful integration of the retrieval system with Gorilla demonstrates the potential for LLMs to use tools more accurately, keep up with frequently updated documentation, and consequently increase the reliability and applicability of their outputs. Gorilla's code, model, data, and demo are available at https://gorilla.cs.berkeley.edu ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 16:48:11 GMT'}]",2023-05-25,"[['Patil', 'Shishir G.', ''], ['Zhang', 'Tianjun', ''], ['Wang', 'Xin', ''], ['Gonzalez', 'Joseph E.', '']]",0,1,2023-05-24,1,4,2,2,1,1,7d8905a1fd288068f12c8347caeabefd36d0dd6c,258865184.0,https://www.semanticscholar.org/paper/7d8905a1fd288068f12c8347caeabefd36d0dd6c,arXiv.org,2023.0,48.0,64.0,6.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '80887461', 'name': 'Shishir G. Patil'}, {'authorId': '1993655237', 'name': 'Tianjun Zhang'}, {'authorId': '2153692009', 'name': 'Xin Wang'}, {'authorId': '49988044', 'name': 'Joseph E. Gonzalez'}]",['Microsoft'],['India'],2023-05
2305.15336,Venkata Sai Charan Putrevu,"P.V. Sai Charan, Hrushikesh Chunduri, P. Mohan Anand, and Sandeep K
  Shukla",From Text to MITRE Techniques: Exploring the Malicious Use of Large Language Models for Generating Cyber Attack Payloads,,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  This research article critically examines the potential risks and implications arising from the malicious utilization of large language models(LLM), focusing specifically on ChatGPT and Google's Bard. Although these large language models have numerous beneficial applications, the misuse of this technology by cybercriminals for creating offensive payloads and tools is a significant concern. In this study, we systematically generated implementable code for the top-10 MITRE Techniques prevalent in 2022, utilizing ChatGPT, and conduct a comparative analysis of its performance with Google's Bard. Our experimentation reveals that ChatGPT has the potential to enable attackers to accelerate the operation of more targeted and sophisticated attacks. Additionally, the technology provides amateur attackers with more capabilities to perform a wide range of attacks and empowers script kiddies to develop customized tools that contribute to the acceleration of cybercrime. Furthermore, LLMs significantly benefits malware authors, particularly ransomware gangs, in generating sophisticated variants of wiper and ransomware attacks with ease. On a positive note, our study also highlights how offensive security researchers and pentesters can make use of LLMs to simulate realistic attack scenarios, identify potential vulnerabilities, and better protect organizations. Overall, we conclude by emphasizing the need for increased vigilance in mitigating the risks associated with LLMs. This includes implementing robust security measures, increasing awareness and education around the potential risks of this technology, and collaborating with security experts to stay ahead of emerging threats. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 16:49:51 GMT'}]",2023-05-25,"[['Charan', 'P. V. Sai', ''], ['Chunduri', 'Hrushikesh', ''], ['Anand', 'P. Mohan', ''], ['Shukla', 'Sandeep K', '']]",1,1,2023-05-24,1,4,1,1,0,1,1b49a819c01df5a4b7868335daab509b0fbdc5d1,258865215.0,https://www.semanticscholar.org/paper/1b49a819c01df5a4b7868335daab509b0fbdc5d1,arXiv.org,2023.0,15.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144628191', 'name': 'P. Charan'}, {'authorId': '2122020644', 'name': 'Hrushikesh Chunduri'}, {'authorId': '48425718', 'name': 'P. Anand'}, {'authorId': '2068180985', 'name': 'S. Shukla'}]",['Indian Institute of Technology Kanpur'],['India'],2023-05
2305.15507,Antonio Valerio Miceli Barone,"Antonio Valerio Miceli-Barone, Fazl Barez, Ioannis Konstas, Shay B.
  Cohen","The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python","17 pages, 5 figure, ACL 2023",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have successfully been applied to code generation tasks, raising the question of how well these models understand programming. Typical programming languages have invariances and equivariances in their semantics that human programmers intuitively understand and exploit, such as the (near) invariance to the renaming of identifiers. We show that LLMs not only fail to properly generate correct Python code when default function names are swapped, but some of them even become more confident in their incorrect predictions as the model size increases, an instance of the recently discovered phenomenon of Inverse Scaling, which runs contrary to the commonly observed trend of increasing prediction quality with increasing model size. Our findings indicate that, despite their astonishing typical-case performance, LLMs still lack a deep, abstract understanding of the content they manipulate, making them unsuitable for tasks that statistically deviate from their training data, and that mere scaling is not enough to achieve such capability. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 18:54:39 GMT'}]",2023-05-26,"[['Miceli-Barone', 'Antonio Valerio', ''], ['Barez', 'Fazl', ''], ['Konstas', 'Ioannis', ''], ['Cohen', 'Shay B.', '']]",0,0,2023-05-24,1,4,2,0,0,0,4631398b0d61061b9ca9489d76ded4dd05bcf1ec,258887624.0,https://www.semanticscholar.org/paper/4631398b0d61061b9ca9489d76ded4dd05bcf1ec,Annual Meeting of the Association for Computational Linguistics,2023.0,38.0,10.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1738698794', 'name': 'Antonio Valerio Miceli-Barone'}, {'authorId': '2143198655', 'name': 'Fazl Barez'}, {'authorId': '2621022', 'name': 'Ioannis Konstas'}, {'authorId': '40146204', 'name': 'Shay B. Cohen'}]","['University of Edinburgh', 'Heriot-Watt University']",['United Kingdom'],2023-05
2305.15594,Haonan Duan,"Haonan Duan, Adam Dziedzic, Nicolas Papernot, Franziska Boenisch",Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models,,,,,cs.LG cs.CL cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) are excellent in-context learners. However, the sensitivity of data contained in prompts raises privacy concerns. Our work first shows that these concerns are valid: we instantiate a simple but highly effective membership inference attack against the data used to prompt LLMs. To address this vulnerability, one could forego prompting and resort to fine-tuning LLMs with known algorithms for private gradient descent. However, this comes at the expense of the practicality and efficiency offered by prompting. Therefore, we propose to privately learn to prompt. We first show that soft prompts can be obtained privately through gradient descent on downstream data. However, this is not the case for discrete prompts. Thus, we orchestrate a noisy vote among an ensemble of LLMs presented with different prompts, i.e., a flock of stochastic parrots. The vote privately transfers the flock's knowledge into a single public prompt. We show that LLMs prompted with our private algorithms closely match the non-private baselines. For example, using GPT3 as the base model, we achieve a downstream accuracy of 92.7% on the sst2 dataset with ($\epsilon=0.147, \delta=10^{-6}$)-differential privacy vs. 95.2% for the non-private baseline. Through our experiments, we also show that our prompt-based approach is easily deployed with existing commercial APIs. ","[{'version': 'v1', 'created': 'Wed, 24 May 2023 22:06:08 GMT'}]",2023-05-26,"[['Duan', 'Haonan', ''], ['Dziedzic', 'Adam', ''], ['Papernot', 'Nicolas', ''], ['Boenisch', 'Franziska', '']]",0,1,2023-05-24,1,4,3,1,0,1,2f2a430ba6c93bcfaf4818316ff8a27b1e034b1a,258887717.0,https://www.semanticscholar.org/paper/2f2a430ba6c93bcfaf4818316ff8a27b1e034b1a,arXiv.org,2023.0,58.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '9747676', 'name': 'Haonan Duan'}, {'authorId': '7485473', 'name': 'Adam Dziedzic'}, {'authorId': '1967156', 'name': 'Nicolas Papernot'}, {'authorId': '1389731564', 'name': 'Franziska Boenisch'}]",['University of Toronto'],['Canada'],2023-05
2305.15805,Sotiris Anagnostidis,"Sotiris Anagnostidis, Dario Pavllo, Luca Biggio, Lorenzo Noci,
  Aurelien Lucchi, Thomas Hofmann",Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Autoregressive Transformers adopted in Large Language Models (LLMs) are hard to scale to long sequences. Despite several works trying to reduce their computational cost, most of LLMs still adopt attention layers between all pairs of tokens in the sequence, thus incurring a quadratic cost. In this study, we present a novel approach that dynamically prunes contextual information while preserving the model's expressiveness, resulting in reduced memory and computational requirements during inference. Our method employs a learnable mechanism that determines which uninformative tokens can be dropped from the context at any point across the generation process. By doing so, our approach not only addresses performance concerns but also enhances interpretability, providing valuable insight into the model's decision-making process. Our technique can be applied to existing pre-trained models through a straightforward fine-tuning process, and the pruning strength can be specified by a sparsity parameter. Notably, our empirical findings demonstrate that we can effectively prune up to 80\% of the context without significant performance degradation on downstream tasks, offering a valuable tool for mitigating inference costs. Our reference implementation achieves up to $2\times$ increase in inference throughput and even greater memory savings. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 07:39:41 GMT'}, {'version': 'v2', 'created': 'Sun, 28 May 2023 12:11:11 GMT'}]",2023-05-30,"[['Anagnostidis', 'Sotiris', ''], ['Pavllo', 'Dario', ''], ['Biggio', 'Luca', ''], ['Noci', 'Lorenzo', ''], ['Lucchi', 'Aurelien', ''], ['Hofmann', 'Thomas', '']]",0,0,2023-05-25,2,6,2,0,0,0,c193eb176985a81ae64f63c5e50b2f11cfb7c4e6,258888224.0,https://www.semanticscholar.org/paper/c193eb176985a81ae64f63c5e50b2f11cfb7c4e6,arXiv.org,2023.0,64.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2051417741', 'name': 'Sotiris Anagnostidis'}, {'authorId': '41018093', 'name': 'Dario Pavllo'}, {'authorId': '2008318441', 'name': 'L. Biggio'}, {'authorId': '1781789550', 'name': 'Lorenzo Noci'}, {'authorId': '40401747', 'name': 'Aurélien Lucchi'}, {'authorId': '143936663', 'name': 'Thomas Hofmann'}]",['University of Basel'],['Switzerland'],2023-05
2305.15809,Heiko Koziolek,"Heiko Koziolek, Sten Gruener, Virendra Ashiwal",ChatGPT for PLC/DCS Control Logic Generation,"8 pages, 6 figures",,,,cs.SE cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) providing generative AI have become popular to support software engineers in creating, summarizing, optimizing, and documenting source code. It is still unknown how LLMs can support control engineers using typical control programming languages in programming tasks. Researchers have explored GitHub CoPilot or DeepMind AlphaCode for source code generation but did not yet tackle control logic programming. The contribution of this paper is an exploratory study, for which we created 100 LLM prompts in 10 representative categories to analyze control logic generation for of PLCs and DCS from natural language. We tested the prompts by generating answers with ChatGPT using the GPT-4 LLM. It generated syntactically correct IEC 61131-3 Structured Text code in many cases and demonstrated useful reasoning skills that could boost control engineer productivity. Our prompt collection is the basis for a more formal LLM benchmark to test and compare such models for control logic generation. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 07:46:53 GMT'}]",2023-05-26,"[['Koziolek', 'Heiko', ''], ['Gruener', 'Sten', ''], ['Ashiwal', 'Virendra', '']]",1,1,2023-05-25,1,3,2,3,0,3,1c1b83df13de4334e48a4c2039bc7ddfa374c486,258887360.0,https://www.semanticscholar.org/paper/1c1b83df13de4334e48a4c2039bc7ddfa374c486,IEEE International Conference on Emerging Technologies and Factory Automation,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","[{'authorId': '2566995', 'name': 'H. Koziolek'}, {'authorId': '2154315802', 'name': 'Sten Gruener'}, {'authorId': '2142749704', 'name': 'Virendra Ashiwal'}]","['ABB Research, Ladenburg, Germany']",['Germany'],2023-05
2305.15852,Jingxuan He,"Niels M\""undler, Jingxuan He, Slobodan Jenko, Martin Vechev","Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation",,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models (large LMs) are susceptible to producing text that contains hallucinated content. An important instance of this problem is self-contradiction, where the LM generates two contradictory sentences within the same context. In this work, we present a comprehensive investigation into self-contradiction for various instruction-tuned LMs, covering evaluation, detection, and mitigation. Our analysis reveals the prevalence of self-contradictions when LMs generate text for open-domain topics, e.g., in 17.7% of all sentences produced by ChatGPT. Self-contradiction also complements retrieval-based methods, as a large portion of them (e.g., 35.8% for ChatGPT) cannot be verified using Wikipedia. We then propose a novel prompting-based framework designed to effectively detect and mitigate self-contradictions. Our detector achieves high accuracy, e.g., around 80% F1 score when prompting ChatGPT. The mitigation algorithm iteratively refines the generated text to remove contradictory information while preserving text fluency and informativeness. Importantly, our entire framework is applicable to black-box LMs and does not require external grounded knowledge. Our approach is practically effective and has been released as a push-button tool to benefit the public, available at https://chatprotect.ai/. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 08:43:46 GMT'}, {'version': 'v2', 'created': 'Sun, 1 Oct 2023 07:22:39 GMT'}]",2023-10-03,"[['Mündler', 'Niels', ''], ['He', 'Jingxuan', ''], ['Jenko', 'Slobodan', ''], ['Vechev', 'Martin', '']]",1,1,2023-05-25,2,4,3,1,0,1,c26689282088f7e20c91f29658dc83c7ae9b1929,258887694.0,https://www.semanticscholar.org/paper/c26689282088f7e20c91f29658dc83c7ae9b1929,arXiv.org,2023.0,85.0,24.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151351924', 'name': 'Niels Mündler'}, {'authorId': '8516542', 'name': 'Jingxuan He'}, {'authorId': '2219029757', 'name': 'Slobodan Jenko'}, {'authorId': '1736447', 'name': 'Martin T. Vechev'}]",['ETH Zurich'],['Switzerland'],2023-05
2305.15908,Seyed Mahed Mousavi,"Seyed Mahed Mousavi, Simone Caldarella, Giuseppe Riccardi",Response Generation in Longitudinal Dialogues: Which Knowledge Representation Helps?,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Longitudinal Dialogues (LD) are the most challenging type of conversation for human-machine dialogue systems. LDs include the recollections of events, personal thoughts, and emotions specific to each individual in a sparse sequence of dialogue sessions. Dialogue systems designed for LDs should uniquely interact with the users over multiple sessions and long periods of time (e.g. weeks), and engage them in personal dialogues to elaborate on their feelings, thoughts, and real-life events. In this paper, we study the task of response generation in LDs. We evaluate whether general-purpose Pre-trained Language Models (PLM) are appropriate for this purpose. We fine-tune two PLMs, GePpeTto (GPT-2) and iT5, using a dataset of LDs. We experiment with different representations of the personal knowledge extracted from LDs for grounded response generation, including the graph representation of the mentioned events and participants. We evaluate the performance of the models via automatic metrics and the contribution of the knowledge via the Integrated Gradients technique. We categorize the natural language generation errors via human evaluations of contextualization, appropriateness and engagement of the user. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 10:13:53 GMT'}]",2023-05-26,"[['Mousavi', 'Seyed Mahed', ''], ['Caldarella', 'Simone', ''], ['Riccardi', 'Giuseppe', '']]",0,1,2023-05-25,1,3,1,1,1,0,b3735b8014ed455fb40aa5030ab9bc0da25c4ae1,258887837.0,https://www.semanticscholar.org/paper/b3735b8014ed455fb40aa5030ab9bc0da25c4ae1,NLP4CONVAI,2023.0,32.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2101322593', 'name': 'Seyed Mahed Mousavi'}, {'authorId': '2203788344', 'name': 'Simone Caldarella'}, {'authorId': '1719162', 'name': 'G. Riccardi'}]",['University of Trento'],['Italy'],2023-05
2305.15929,Juan Manuel Toro,Juan Manuel Toro,Emergence of a phonological bias in ChatGPT,"15 pages, 1 figure, corrected typo",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Current large language models, such as OpenAI's ChatGPT, have captured the public's attention because how remarkable they are in the use of language. Here, I demonstrate that ChatGPT displays phonological biases that are a hallmark of human language processing. More concretely, just like humans, ChatGPT has a consonant bias. That is, the chatbot has a tendency to use consonants over vowels to identify words. This is observed across languages that differ in their relative distribution of consonants and vowels such as English and Spanish. Despite the differences in how current artificial intelligence language models are trained to process linguistic stimuli and how human infants acquire language, such training seems to be enough for the emergence of a phonological bias in ChatGPT ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 10:57:43 GMT'}, {'version': 'v2', 'created': 'Sat, 27 May 2023 09:19:54 GMT'}]",2023-05-30,"[['Toro', 'Juan Manuel', '']]",1,1,2023-05-25,2,1,1,1,0,1,b500a6232527e3576e8677985be81a93b32987e6,258887418.0,https://www.semanticscholar.org/paper/b500a6232527e3576e8677985be81a93b32987e6,arXiv.org,2023.0,14.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '144200460', 'name': 'J. M. Toro'}]","['Pompeu Fabra University', 'Institució Catalana de Recerca i Estudis Avançats']",['Spain'],2023-05
2305.16366,Xueliang Zhao,"Xueliang Zhao, Wenda Li, Lingpeng Kong",Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving,,,,,cs.CL cs.AI cs.LG cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models~(LLMs) present an intriguing avenue of exploration in the domain of formal theorem proving. Nonetheless, the full utilization of these models, particularly in terms of demonstration formatting and organization, remains an underexplored area. In an endeavor to enhance the efficacy of LLMs, we introduce a subgoal-based demonstration learning framework, consisting of two primary elements: Firstly, drawing upon the insights of subgoal learning from the domains of reinforcement learning and robotics, we propose the construction of distinct subgoals for each demonstration example and refine these subgoals in accordance with the pertinent theories of subgoal learning. Secondly, we build upon recent advances in diffusion models to predict the optimal organization, simultaneously addressing two intricate issues that persist within the domain of demonstration organization: subset selection and order determination. Through the integration of subgoal-based learning methodologies, we have successfully increased the prevailing proof accuracy from 38.9\% to 44.3\% on the miniF2F benchmark. Furthermore, the adoption of diffusion models for demonstration organization can lead to an additional enhancement in accuracy to 45.5\%, or a $5\times$ improvement in sampling efficiency compared with the long-standing state-of-the-art method. Our code is available at \url{https://github.com/HKUNLP/subgoal-theorem-prover}. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 11:35:52 GMT'}]",2023-05-29,"[['Zhao', 'Xueliang', ''], ['Li', 'Wenda', ''], ['Kong', 'Lingpeng', '']]",0,0,2023-05-25,1,3,4,0,0,0,b8fe9d7b5762f7c9c3789cff2bdbe968ff0f0ed6,258947160.0,https://www.semanticscholar.org/paper/b8fe9d7b5762f7c9c3789cff2bdbe968ff0f0ed6,arXiv.org,2023.0,52.0,5.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2878414', 'name': 'Xueliang Zhao'}, {'authorId': '3172944', 'name': 'Wenda Li'}, {'authorId': '47648549', 'name': 'Lingpeng Kong'}]","['University of Cambridge', 'University of Hong Kong']","['United Kingdom', 'Hong Kong']",2023-05
2305.16426,Isabelle Lorge PhD,Isabelle Lorge and Janet Pierrehumbert,Not wacky vs. definitely wacky: A study of scalar adverbs in pretrained language models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Vector space models of word meaning all share the assumption that words occurring in similar contexts have similar meanings. In such models, words that are similar in their topical associations but differ in their logical force tend to emerge as semantically close, creating well-known challenges for NLP applications that involve logical reasoning. Modern pretrained language models, such as BERT, RoBERTa and GPT-3 hold the promise of performing better on logical tasks than classic static word embeddings. However, reports are mixed about their success. In the current paper, we advance this discussion through a systematic study of scalar adverbs, an under-explored class of words with strong logical force. Using three different tasks, involving both naturalistic social media data and constructed examples, we investigate the extent to which BERT, RoBERTa, GPT-2 and GPT-3 exhibit general, human-like, knowledge of these common words. We ask: 1) Do the models distinguish amongst the three semantic categories of MODALITY, FREQUENCY and DEGREE? 2) Do they have implicit representations of full scales from maximally negative to maximally positive? 3) How do word frequency and contextual factors impact model performance? We find that despite capturing some aspects of logical meaning, the models fall far short of human performance. ","[{'version': 'v1', 'created': 'Thu, 25 May 2023 18:56:26 GMT'}]",2023-05-29,"[['Lorge', 'Isabelle', ''], ['Pierrehumbert', 'Janet', '']]",0,1,2023-05-25,1,2,1,2,1,1,604149ebaa727cb0840e0117a59f6fc13ca66690,258947109.0,https://www.semanticscholar.org/paper/604149ebaa727cb0840e0117a59f6fc13ca66690,arXiv.org,2023.0,44.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '113540265', 'name': 'Isabelle Lorge'}, {'authorId': '1970864', 'name': 'J. Pierrehumbert'}]",['University of Oxford'],['United Kingdom'],2023-05
2305.16598,Farhad Moghimifar,"Farhad Moghimifar, Shilin Qu, Tongtong Wu, Yuan-Fang Li, Gholamreza
  Haffari",NormMark: A Weakly Supervised Markov Model for Socio-cultural Norm Discovery,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Norms, which are culturally accepted guidelines for behaviours, can be integrated into conversational models to generate utterances that are appropriate for the socio-cultural context. Existing methods for norm recognition tend to focus only on surface-level features of dialogues and do not take into account the interactions within a conversation. To address this issue, we propose NormMark, a probabilistic generative Markov model to carry the latent features throughout a dialogue. These features are captured by discrete and continuous latent variables conditioned on the conversation history, and improve the model's ability in norm recognition. The model is trainable on weakly annotated data using the variational technique. On a dataset with limited norm annotations, we show that our approach achieves higher F1 score, outperforming current state-of-the-art methods, including GPT3. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 03:03:37 GMT'}]",2023-05-29,"[['Moghimifar', 'Farhad', ''], ['Qu', 'Shilin', ''], ['Wu', 'Tongtong', ''], ['Li', 'Yuan-Fang', ''], ['Haffari', 'Gholamreza', '']]",0,1,2023-05-26,1,5,1,1,0,1,f8b3e43d8b4e7028f7cb83198f0bee732909d5a5,258947096.0,https://www.semanticscholar.org/paper/f8b3e43d8b4e7028f7cb83198f0bee732909d5a5,Annual Meeting of the Association for Computational Linguistics,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2804001', 'name': 'Farhad Moghimifar'}, {'authorId': '2061177223', 'name': 'Shilin Qu'}, {'authorId': '3357184', 'name': 'Tongtong Wu'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}, {'authorId': '2561045', 'name': 'Gholamreza Haffari'}]",['Monash University'],['Australia'],2023-05
2305.16755,Hiba Arnaout,"Hiba Arnaout, Simon Razniewski",Can large language models generate salient negative statements?,"For data, see
  https://www.mpi-inf.mpg.de/fileadmin/inf/d5/research/negation_in_KBs/data.csv",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 09:13:59 GMT'}, {'version': 'v2', 'created': 'Thu, 21 Sep 2023 13:36:03 GMT'}]",2023-09-22,"[['Arnaout', 'Hiba', ''], ['Razniewski', 'Simon', '']]",0,0,2023-05-26,2,2,2,0,0,0,524a781fba2fc08fbfcd58262064ad9f37164b40,258947467.0,https://www.semanticscholar.org/paper/524a781fba2fc08fbfcd58262064ad9f37164b40,arXiv.org,2023.0,18.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40434178', 'name': 'Hiba Arnaout'}, {'authorId': '2066327465', 'name': 'S. Razniewski'}]","['Max Planck Institute for Informatics', 'Robert Bosch (Taiwan)']","['Germany', 'Taiwan']",2023-05
2305.16756,Nicolo' Tamagnone,"Nicol\`o Tamagnone, Selim Fekih, Ximena Contla, Nayid Orozco, Navid
  Rekabsaz",Leveraging Domain Knowledge for Inclusive and Bias-aware Humanitarian Response Entry Classification,Accepted at IJCAI 2023,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Accurate and rapid situation analysis during humanitarian crises is critical to delivering humanitarian aid efficiently and is fundamental to humanitarian imperatives and the Leave No One Behind (LNOB) principle. This data analysis can highly benefit from language processing systems, e.g., by classifying the text data according to a humanitarian ontology. However, approaching this by simply fine-tuning a generic large language model (LLM) involves considerable practical and ethical issues, particularly the lack of effectiveness on data-sparse and complex subdomains, and the encoding of societal biases and unwanted associations. In this work, we aim to provide an effective and ethically-aware system for humanitarian data analysis. We approach this by (1) introducing a novel architecture adjusted to the humanitarian analysis framework, (2) creating and releasing a novel humanitarian-specific LLM called HumBert, and (3) proposing a systematic way to measure and mitigate biases. Our experiments' results show the better performance of our approach on zero-shot and full-training settings in comparison with strong baseline models, while also revealing the existence of biases in the resulting LLMs. Utilizing a targeted counterfactual data augmentation approach, we significantly reduce these biases without compromising performance. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 09:15:05 GMT'}, {'version': 'v2', 'created': 'Tue, 30 May 2023 13:16:33 GMT'}]",2023-05-31,"[['Tamagnone', 'Nicolò', ''], ['Fekih', 'Selim', ''], ['Contla', 'Ximena', ''], ['Orozco', 'Nayid', ''], ['Rekabsaz', 'Navid', '']]",0,0,2023-05-26,2,5,2,0,0,0,f45bee9da1655320b7fc290d2abc20903bd12545,258947713.0,https://www.semanticscholar.org/paper/f45bee9da1655320b7fc290d2abc20903bd12545,International Joint Conference on Artificial Intelligence,2023.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1993591232', 'name': 'Nicolò Tamagnone'}, {'authorId': '2187300092', 'name': 'Selim Fekih'}, {'authorId': '2187301044', 'name': 'Ximena Contla'}, {'authorId': '2218715958', 'name': 'Nayid Orozco'}, {'authorId': '2844293', 'name': 'Navid Rekabsaz'}]","['Institute for Scientific Interchange', 'Johannes Kepler University of Linz']","['Austria', 'Italy']",2023-05
2305.16768,Fred Philippy,"Fred Philippy, Siwen Guo, Shohreh Haddadan",Towards a Common Understanding of Contributing Factors for Cross-Lingual Transfer in Multilingual Language Models: A Review,Accepted at ACL 2023 (Main conference),,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In recent years, pre-trained Multilingual Language Models (MLLMs) have shown a strong ability to transfer knowledge across different languages. However, given that the aspiration for such an ability has not been explicitly incorporated in the design of the majority of MLLMs, it is challenging to obtain a unique and straightforward explanation for its emergence. In this review paper, we survey literature that investigates different factors contributing to the capacity of MLLMs to perform zero-shot cross-lingual transfer and subsequently outline and discuss these factors in detail. To enhance the structure of this review and to facilitate consolidation with future studies, we identify five categories of such factors. In addition to providing a summary of empirical evidence from past studies, we identify consensuses among studies with consistent findings and resolve conflicts among contradictory ones. Our work contextualizes and unifies existing research streams which aim at explaining the cross-lingual potential of MLLMs. This review provides, first, an aligned reference point for future research and, second, guidance for a better-informed and more efficient way of leveraging the cross-lingual capacity of MLLMs. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 09:31:12 GMT'}]",2023-05-29,"[['Philippy', 'Fred', ''], ['Guo', 'Siwen', ''], ['Haddadan', 'Shohreh', '']]",0,0,2023-05-26,1,3,2,0,0,0,f4f5c747dbb09a0846b600987379148ca5e1b167,258947231.0,https://www.semanticscholar.org/paper/f4f5c747dbb09a0846b600987379148ca5e1b167,Annual Meeting of the Association for Computational Linguistics,2023.0,47.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2089836413', 'name': 'Fred Philippy'}, {'authorId': '2110835464', 'name': 'Siwen Guo'}, {'authorId': '121857840', 'name': 'Shohreh Haddadan'}]","['University of Luxembourg', 'Zortify Labs, Zortify S.A. 19, rue du Laboratoire L-1911 Luxembourg']",['Luxembourg'],2023-05
2305.16837,Giriprasad Sridhara,Giriprasad Sridhara and Ranjani H.G. and Sourav Mazumdar,ChatGPT: A Study on its Utility for Ubiquitous Software Engineering Tasks,,,,,cs.SE cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot launched by OpenAI on November 30, 2022. OpenAI's GPT-3 family of large language models serve as the foundation for ChatGPT. ChatGPT is fine-tuned with both supervised and reinforcement learning techniques and has received widespread attention for its articulate responses across diverse domains of knowledge. In this study, we explore how ChatGPT can be used to help with common software engineering tasks. Many of the ubiquitous tasks covering the breadth of software engineering such as ambiguity resolution in software requirements, method name suggestion, test case prioritization, code review, log summarization can potentially be performed using ChatGPT. In this study, we explore fifteen common software engineering tasks using ChatGPT. We juxtapose and analyze ChatGPT's answers with the respective state of the art outputs (where available) and/or human expert ground truth. Our experiments suggest that for many tasks, ChatGPT does perform credibly and the response from it is detailed and often better than the human expert output or the state of the art output. However, for a few other tasks, ChatGPT in its present form provides incorrect answers and hence is not suited for such tasks. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 11:29:06 GMT'}]",2023-05-29,"[['Sridhara', 'Giriprasad', ''], ['G.', 'Ranjani H.', ''], ['Mazumdar', 'Sourav', '']]",1,1,2023-05-26,1,3,3,2,0,2,49f8a40aea0e945bd8b15019a3e4b1bb1c9279ea,258947110.0,https://www.semanticscholar.org/paper/49f8a40aea0e945bd8b15019a3e4b1bb1c9279ea,arXiv.org,2023.0,41.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3023667', 'name': 'G. Sridhara'}, {'authorId': '1652016160', 'name': 'Ranjani H.G.'}, {'authorId': '3315501', 'name': 'Sourav Mazumdar'}]","['Global AI Accelerator (GAIA) Ericsson Bangalore, India']",['India'],2023-05
2305.16849,Jai Kannan,"Jai Kannan, Scott Barnett, Anj Simmons, Taylan Selvi, Luis Cruz",Green Runner: A tool for efficient model selection from model repositories,,,,,cs.SE cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Deep learning models have become essential in software engineering, enabling intelligent features like image captioning and document generation. However, their popularity raises concerns about environmental impact and inefficient model selection. This paper introduces GreenRunnerGPT, a novel tool for efficiently selecting deep learning models based on specific use cases. It employs a large language model to suggest weights for quality indicators, optimizing resource utilization. The tool utilizes a multi-armed bandit framework to evaluate models against target datasets, considering tradeoffs. We demonstrate that GreenRunnerGPT is able to identify a model suited to a target use case without wasteful computations that would occur under a brute-force approach to model selection. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 12:00:37 GMT'}]",2023-05-29,"[['Kannan', 'Jai', ''], ['Barnett', 'Scott', ''], ['Simmons', 'Anj', ''], ['Selvi', 'Taylan', ''], ['Cruz', 'Luis', '']]",0,1,2023-05-26,1,5,2,0,0,0,043f69731b4b3053c1d3962d4f0033b1821891b6,258947508.0,https://www.semanticscholar.org/paper/043f69731b4b3053c1d3962d4f0033b1821891b6,arXiv.org,2023.0,7.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '123251740', 'name': 'Jai Kannan'}, {'authorId': '2052845461', 'name': 'Scott Barnett'}, {'authorId': '2155271803', 'name': 'Anj Simmons'}, {'authorId': '2218768594', 'name': 'Taylan Selvi'}, {'authorId': '101422506', 'name': 'Luís Cruz'}]","['Deakin University', 'Delft University of Technology']","['Netherlands', 'Australia']",2023-05
2305.16867,Elif Akata,"Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias
  Bethge, Eric Schulz",Playing repeated games with Large Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) are transforming society and permeating into diverse applications. As a result, LLMs will frequently interact with us and other agents. It is, therefore, of great societal value to understand how LLMs behave in interactive social settings. Here, we propose to use behavioral game theory to study LLM's cooperation and coordination behavior. To do so, we let different LLMs (GPT-3, GPT-3.5, and GPT-4) play finitely repeated games with each other and with other, human-like strategies. Our results show that LLMs generally perform well in such tasks and also uncover persistent behavioral signatures. In a large set of two players-two strategies games, we find that LLMs are particularly good at games where valuing their own self-interest pays off, like the iterated Prisoner's Dilemma family. However, they behave sub-optimally in games that require coordination. We, therefore, further focus on two games from these distinct families. In the canonical iterated Prisoner's Dilemma, we find that GPT-4 acts particularly unforgivingly, always defecting after another agent has defected only once. In the Battle of the Sexes, we find that GPT-4 cannot match the behavior of the simple convention to alternate between options. We verify that these behavioral signatures are stable across robustness checks. Finally, we show how GPT-4's behavior can be modified by providing further information about the other player as well as by asking it to predict the other player's actions before making a choice. These results enrich our understanding of LLM's social behavior and pave the way for a behavioral game theory for machines. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 12:17:59 GMT'}]",2023-05-29,"[['Akata', 'Elif', ''], ['Schulz', 'Lion', ''], ['Coda-Forno', 'Julian', ''], ['Oh', 'Seong Joon', ''], ['Bethge', 'Matthias', ''], ['Schulz', 'Eric', '']]",0,1,2023-05-26,1,6,1,2,0,2,3f98cf521222c65522200037c0eb95a17081b2dd,258947115.0,https://www.semanticscholar.org/paper/3f98cf521222c65522200037c0eb95a17081b2dd,arXiv.org,2023.0,61.0,24.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","[{'authorId': '2219036074', 'name': 'Elif Akata'}, {'authorId': '2027222653', 'name': 'Lion Schulz'}, {'authorId': '2215168951', 'name': 'Julian Coda-Forno'}, {'authorId': '2390510', 'name': 'Seong Joon Oh'}, {'authorId': '1731199', 'name': 'M. Bethge'}, {'authorId': '49427184', 'name': 'Eric Schulz'}]","['University of Tübingen', 'Max Planck Institute for Biological Cybernetics']",['Germany'],2023-05
2305.16876,Aitor Ormazabal,"Aitor Ormazabal, Mikel Artetxe and Eneko Agirre",CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models,"This previously appeared as arXiv:2205.12213v2, which was submitted
  as new by mistake",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Methods for adapting language models (LMs) to new tasks and domains have traditionally assumed white-box access to the model, and work by modifying its parameters. However, this is incompatible with a recent trend in the field, where the highest quality models are only available as black-boxes through inference APIs. Even when the model weights are available, the computational cost of fine-tuning large LMs can be prohibitive for most practitioners. In this work, we present a lightweight method for adapting large LMs to new domains and tasks, assuming no access to their weights or intermediate activations. Our approach fine-tunes a small white-box LM and combines it with the large black-box LM at the probability level through a small network, learned on a small validation set. We validate our approach by adapting a large LM (OPT-30B) to several domains and a downstream task (machine translation), observing improved performance in all cases, of up to 9%, while using a domain expert 23x smaller. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 06:32:55 GMT'}]",2023-05-29,"[['Ormazabal', 'Aitor', ''], ['Artetxe', 'Mikel', ''], ['Agirre', 'Eneko', '']]",0,0,2023-05-23,1,3,1,1,1,0,e55fff3d7e59a7192b59b4b497c17ea9c77a9d16,258832731.0,https://www.semanticscholar.org/paper/e55fff3d7e59a7192b59b4b497c17ea9c77a9d16,arXiv.org,2023.0,34.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '146150609', 'name': 'Aitor Ormazabal'}, {'authorId': '2347956', 'name': 'Mikel Artetxe'}, {'authorId': '2064112151', 'name': 'Eneko Agirre'}]","['Reka AI', 'University of the Basque Country']",['Spain'],2023-05
2305.16896,Tatsuro Inaba,"Tatsuro Inaba, Hirokazu Kiyomaru, Fei Cheng, Sadao Kurohashi",MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting,"ACL2023. Our code is available at
  https://github.com/InabaTatsuro/MultiTool-CoT",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have achieved impressive performance on various reasoning tasks. To further improve the performance, we propose MultiTool-CoT, a novel framework that leverages chain-of-thought (CoT) prompting to incorporate multiple external tools, such as a calculator and a knowledge retriever, during the reasoning process. We apply MultiTool-CoT to the Task 2 dataset of NumGLUE, which requires both numerical reasoning and domain-specific knowledge. The experiments show that our method significantly outperforms strong baselines and achieves state-of-the-art performance. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 13:00:58 GMT'}]",2023-05-29,"[['Inaba', 'Tatsuro', ''], ['Kiyomaru', 'Hirokazu', ''], ['Cheng', 'Fei', ''], ['Kurohashi', 'Sadao', '']]",0,1,2023-05-26,1,4,3,1,0,1,2502311c66b11b3d5551e13a0095f2b1a5c5455d,258947061.0,https://www.semanticscholar.org/paper/2502311c66b11b3d5551e13a0095f2b1a5c5455d,Annual Meeting of the Association for Computational Linguistics,2023.0,12.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218404694', 'name': 'Tatsuro Inaba'}, {'authorId': '51195367', 'name': 'Hirokazu Kiyomaru'}, {'authorId': '49412583', 'name': 'Fei Cheng'}, {'authorId': '1795664', 'name': 'S. Kurohashi'}]","['Kyoto University', 'National Institute of Informatics']",['Japan'],2023-05
2305.16986,Gengze Zhou,"Gengze Zhou, Yicong Hong, Qi Wu",NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models,,,,,cs.CV cs.AI cs.CL cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling. Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent. In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN). At each step, NavGPT takes the textual descriptions of visual observations, navigation history, and future explorable directions as inputs to reason the agent's current status, and makes the decision to approach the target. Through comprehensive experiments, we demonstrate NavGPT can explicitly perform high-level planning for navigation, including decomposing instruction into sub-goal, integrating commonsense knowledge relevant to navigation task resolution, identifying landmarks from observed scenes, tracking navigation progress, and adapting to exceptions with plan adjustment. Furthermore, we show that LLMs is capable of generating high-quality navigational instructions from observations and actions along a path, as well as drawing accurate top-down metric trajectory given the agent's navigation history. Despite the performance of using NavGPT to zero-shot R2R tasks still falling short of trained models, we suggest adapting multi-modality inputs for LLMs to use as visual navigation agents and applying the explicit reasoning of LLMs to benefit learning-based models. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 14:41:06 GMT'}, {'version': 'v2', 'created': 'Mon, 29 May 2023 04:49:00 GMT'}]",2023-05-30,"[['Zhou', 'Gengze', ''], ['Hong', 'Yicong', ''], ['Wu', 'Qi', '']]",1,1,2023-05-26,2,3,4,2,0,2,8199c9d55dd998f69f703e0ad250ca0697e3ad27,258947250.0,https://www.semanticscholar.org/paper/8199c9d55dd998f69f703e0ad250ca0697e3ad27,arXiv.org,2023.0,77.0,13.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218747386', 'name': 'Gengze Zhou'}, {'authorId': '1612421029', 'name': 'Yicong Hong'}, {'authorId': '2143599088', 'name': 'Qi Wu'}]","['University of Adelaide', 'Australian National University']",['Australia'],2023-05
2305.17306,Yao Fu,"Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng and Tushar Khot",Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance,Preprint. Code at https://github.com/FranxYao/chain-of-thought-hub,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  As large language models (LLMs) are continuously being developed, their evaluation becomes increasingly important yet challenging. This work proposes Chain-of-Thought Hub, an open-source evaluation suite on the multi-step reasoning capabilities of large language models. We are interested in this setting for two reasons: (1) from the behavior of GPT and PaLM model family, we observe that complex reasoning is likely to be a key differentiator between weaker and stronger LLMs; (2) we envisage large language models to become the next-generation computational platform and foster an ecosystem of LLM-based new applications, this naturally requires the foundation models to perform complex tasks that often involve the composition of linguistic and logical operations. Our approach is to compile a suite of challenging reasoning benchmarks to track the progress of LLMs. Our current results show that: (1) model scale clearly correlates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 and PaLM-2 are the only two models that are comparable with GPT-4, while open-sourced models still lag behind; (3) LLaMA-65B performs closely to code-davinci-002, indicating that with successful further development such as reinforcement learning from human feedback (RLHF), it has great potential to be close to GPT-3.5-Turbo. Our results also suggest that for the open-source efforts to catch up, the community may focus more on building better base models and exploring RLHF. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 23:46:42 GMT'}]",2023-05-30,"[['Fu', 'Yao', ''], ['Ou', 'Litu', ''], ['Chen', 'Mingyu', ''], ['Wan', 'Yuhao', ''], ['Peng', 'Hao', ''], ['Khot', 'Tushar', '']]",0,1,2023-05-26,1,6,3,5,1,4,ea75117f34b168a20f2a4309ac2eb685ca6b1436,258959433.0,https://www.semanticscholar.org/paper/ea75117f34b168a20f2a4309ac2eb685ca6b1436,arXiv.org,2023.0,35.0,31.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46956602', 'name': 'Yao Fu'}, {'authorId': '2203370918', 'name': 'Litu Ou'}, {'authorId': '2218855303', 'name': 'Mingyu Chen'}, {'authorId': '2218462633', 'name': 'Yuhao Wan'}, {'authorId': '2293471', 'name': 'Hao-Chun Peng'}, {'authorId': '2236429', 'name': 'Tushar Khot'}]",['University of Edinburgh'],['United Kingdom'],2023-05
2305.17422,Gabriel Roccabruna,"Gabriel Roccabruna, Seyed Mahed Mousavi, Giuseppe Riccardi",Understanding Emotion Valence is a Joint Deep Learning Task,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The valence analysis of speakers' utterances or written posts helps to understand the activation and variations of the emotional state throughout the conversation. More recently, the concept of Emotion Carriers (EC) has been introduced to explain the emotion felt by the speaker and its manifestations. In this work, we investigate the natural inter-dependency of valence and ECs via a multi-task learning approach. We experiment with Pre-trained Language Models (PLM) for single-task, two-step, and joint settings for the valence and EC prediction tasks. We compare and evaluate the performance of generative (GPT-2) and discriminative (BERT) architectures in each setting. We observed that providing the ground truth label of one task improves the prediction performance of the models in the other task. We further observed that the discriminative model achieves the best trade-off of valence and EC prediction tasks in the joint prediction setting. As a result, we attain a single model that performs both tasks, thus, saving computation resources at training and inference times. ","[{'version': 'v1', 'created': 'Sat, 27 May 2023 09:07:18 GMT'}]",2023-05-30,"[['Roccabruna', 'Gabriel', ''], ['Mousavi', 'Seyed Mahed', ''], ['Riccardi', 'Giuseppe', '']]",0,1,2023-05-27,1,3,2,1,1,0,40e2e1f47e03ca8b57624945ccc20e5a8f380f3a,258959505.0,https://www.semanticscholar.org/paper/40e2e1f47e03ca8b57624945ccc20e5a8f380f3a,"Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",2023.0,40.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2038117205', 'name': 'G. Roccabruna'}, {'authorId': '2101322593', 'name': 'Seyed Mahed Mousavi'}, {'authorId': '1719162', 'name': 'G. Riccardi'}]",['University of Trento'],['Italy'],2023-05
2305.17491,Jasivan Alex Sivakumar,Jasivan Alex Sivakumar and Nafise Sadat Moosavi,FERMAT: An Alternative to Accuracy for Numerical Reasoning,ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  While pre-trained language models achieve impressive performance on various NLP benchmarks, they still struggle with tasks that require numerical reasoning. Recent advances in improving numerical reasoning are mostly achieved using very large language models that contain billions of parameters and are not accessible to everyone. In addition, numerical reasoning is measured using a single score on existing datasets. As a result, we do not have a clear understanding of the strengths and shortcomings of existing models on different numerical reasoning aspects and therefore, potential ways to improve them apart from scaling them up. Inspired by CheckList (Ribeiro et al., 2020), we introduce a multi-view evaluation set for numerical reasoning in English, called FERMAT. Instead of reporting a single score on a whole dataset, FERMAT evaluates models on various key numerical reasoning aspects such as number understanding, mathematical operations, and training dependency. Apart from providing a comprehensive evaluation of models on different numerical reasoning aspects, FERMAT enables a systematic and automated generation of an arbitrarily large training or evaluation set for each aspect.The datasets and codes are publicly available to generate further multi-view data for ulterior tasks and languages. ","[{'version': 'v1', 'created': 'Sat, 27 May 2023 15:00:45 GMT'}]",2023-05-30,"[['Sivakumar', 'Jasivan Alex', ''], ['Moosavi', 'Nafise Sadat', '']]",0,0,2023-05-27,1,2,1,0,0,0,24a285b1e7ee9acfec9a82f7123563b62f532203,258959201.0,https://www.semanticscholar.org/paper/24a285b1e7ee9acfec9a82f7123563b62f532203,Annual Meeting of the Association for Computational Linguistics,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2150505224', 'name': 'Jasivan Sivakumar'}, {'authorId': '2182290', 'name': 'N. Moosavi'}]",['University of Sheffield'],['United Kingdom'],2023-05
2305.17493,Ilia Shumailov,"Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas
  Papernot, Ross Anderson",The Curse of Recursion: Training on Generated Data Makes Models Forget,,,,,cs.LG cs.AI cs.CL cs.CR cs.CV,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Stable Diffusion revolutionised image creation from descriptive text. GPT-2, GPT-3(.5) and GPT-4 demonstrated astonishing performance across a variety of language tasks. ChatGPT introduced such language models to the general public. It is now clear that large language models (LLMs) are here to stay, and will bring about drastic change in the whole ecosystem of online text and images. In this paper we consider what the future might hold. What will happen to GPT-{n} once LLMs contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We refer to this effect as Model Collapse and show that it can occur in Variational Autoencoders, Gaussian Mixture Models and LLMs. We build theoretical intuition behind the phenomenon and portray its ubiquity amongst all learned generative models. We demonstrate that it has to be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of content generated by LLMs in data crawled from the Internet. ","[{'version': 'v1', 'created': 'Sat, 27 May 2023 15:10:41 GMT'}, {'version': 'v2', 'created': 'Wed, 31 May 2023 10:39:26 GMT'}]",2023-06-01,"[['Shumailov', 'Ilia', ''], ['Shumaylov', 'Zakhar', ''], ['Zhao', 'Yiren', ''], ['Gal', 'Yarin', ''], ['Papernot', 'Nicolas', ''], ['Anderson', 'Ross', '']]",1,1,2023-05-27,2,6,5,4,1,3,155aec5cff650263a4c71136f97570611d1bba7a,258987240.0,https://www.semanticscholar.org/paper/155aec5cff650263a4c71136f97570611d1bba7a,arXiv.org,2023.0,30.0,43.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '47473421', 'name': 'Ilia Shumailov'}, {'authorId': '1863627577', 'name': 'Zakhar Shumaylov'}, {'authorId': '2109919449', 'name': 'Yiren Zhao'}, {'authorId': '2681954', 'name': 'Y. Gal'}, {'authorId': '1967156', 'name': 'Nicolas Papernot'}, {'authorId': '40171469', 'name': 'Ross Anderson'}]","['Imperial College London', 'University of Toronto', 'University of Cambridge', 'University of Oxford']","['Canada', 'United Kingdom']",2023-05
2305.17553,Jason Hoelscher-Obermaier,"Jason Hoelscher-Obermaier, Julia Persson, Esben Kran, Ioannis Konstas
  and Fazl Barez",Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark,"To be published in ACL Findings 2023; for code see
  https://github.com/apartresearch/specificityplus; for a homepage see
  https://specificityplus.apartresearch.com/; updated Figures to uniform style",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent model editing techniques promise to mitigate the problem of memorizing false or outdated associations during LLM training. However, we show that these techniques can introduce large unwanted side effects which are not detected by existing specificity benchmarks. We extend the existing CounterFact benchmark to include a dynamic component and dub our benchmark CounterFact+. Additionally, we extend the metrics used for measuring specificity by a principled KL divergence-based metric. We use this improved benchmark to evaluate recent model editing techniques and find that they suffer from low specificity. Our findings highlight the need for improved specificity benchmarks that identify and prevent unwanted side effects. ","[{'version': 'v1', 'created': 'Sat, 27 May 2023 19:08:04 GMT'}, {'version': 'v2', 'created': 'Sat, 3 Jun 2023 08:01:11 GMT'}]",2023-06-06,"[['Hoelscher-Obermaier', 'Jason', ''], ['Persson', 'Julia', ''], ['Kran', 'Esben', ''], ['Konstas', 'Ioannis', ''], ['Barez', 'Fazl', '']]",0,0,2023-05-27,2,5,3,0,0,0,cc57a02307b77585f69779cca2937dedc69006d6,258960406.0,https://www.semanticscholar.org/paper/cc57a02307b77585f69779cca2937dedc69006d6,Annual Meeting of the Association for Computational Linguistics,2023.0,19.0,16.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1388392024', 'name': 'J. Hoelscher-Obermaier'}, {'authorId': '2218886081', 'name': 'Julia Persson'}, {'authorId': '2005663935', 'name': 'Esben Kran'}, {'authorId': '2621022', 'name': 'Ioannis Konstas'}, {'authorId': '2143198655', 'name': 'Fazl Barez'}]","['Apart Research', 'University of Edinburgh', 'University of Oxford']",['United Kingdom'],2023-05
2305.17679,Nicolay Rusnachenko,"Anton Golubev, Nicolay Rusnachenko, Natalia Loukachevitch",RuSentNE-2023: Evaluating Entity-Oriented Sentiment Analysis on Russian News Texts,"12 pages, 5 tables, 3 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The paper describes the RuSentNE-2023 evaluation devoted to targeted sentiment analysis in Russian news texts. The task is to predict sentiment towards a named entity in a single sentence. The dataset for RuSentNE-2023 evaluation is based on the Russian news corpus RuSentNE having rich sentiment-related annotation. The corpus is annotated with named entities and sentiments towards these entities, along with related effects and emotional states. The evaluation was organized using the CodaLab competition framework. The main evaluation measure was macro-averaged measure of positive and negative classes. The best results achieved were of 66% Macro F-measure (Positive+Negative classes). We also tested ChatGPT on the test set from our evaluation and found that the zero-shot answers provided by ChatGPT reached 60% of the F-measure, which corresponds to 4th place in the evaluation. ChatGPT also provided detailed explanations of its conclusion. This can be considered as quite high for zero-shot application. ","[{'version': 'v1', 'created': 'Sun, 28 May 2023 10:04:15 GMT'}]",2023-05-30,"[['Golubev', 'Anton', ''], ['Rusnachenko', 'Nicolay', ''], ['Loukachevitch', 'Natalia', '']]",1,1,2023-05-28,1,3,1,1,0,1,82e47dcadc418366576373a5064f99f9b619a4ae,258960182.0,https://www.semanticscholar.org/paper/82e47dcadc418366576373a5064f99f9b619a4ae,arXiv.org,2023.0,33.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1838006298', 'name': 'A. Golubev'}, {'authorId': '51234969', 'name': 'Nicolay Rusnachenko'}, {'authorId': '2067109040', 'name': 'N. Loukachevitch'}]","['Lomonosov Moscow State University', 'Bauman Moscow State Technical University']",['Russia'],2023-05
2305.17819,Magdalena Wysocka,"Magdalena Wysocka, Oskar Wysocki, Maxime Delmas, Vincent Mutel, Andre
  Freitas","Large Language Models, scientific knowledge and factuality: A systematic analysis in antibiotic discovery","23 pages, 3 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Inferring over and extracting information from Large Language Models (LLMs) trained on a large corpus of scientific literature can potentially drive a new era in biomedical research, reducing the barriers for accessing existing medical evidence. This work examines the potential of LLMs for dialoguing with biomedical background knowledge, using the context of antibiotic discovery as an exemplar motivational scenario. The context of biomedical discovery from natural products entails understanding the relational evidence between an organism, an associated chemical and its associated antibiotic properties. We provide a systematic assessment on the ability of LLMs to encode and express these relations, verifying for fluency, prompt-alignment, semantic coherence, factual knowledge and specificity of generated responses. The systematic analysis is applied to nine state-of-the-art models (including ChatGPT and GPT-4) in two prompting-based tasks: chemical compound definition generation and chemical compound-fungus relation determination. Results show that while recent models have improved in fluency, factual accuracy is still low and models are biased towards over-represented entities. The ability of LLMs to serve as biomedical knowledge bases is questioned, and the need for additional systematic evaluation frameworks is highlighted. The best performing GPT-4 produced a factual definition for 70% of chemical compounds and 43.6% factual relations to fungi, whereas the best open source model BioGPT-large 30% of the compounds and 30% of the relations for the best-performing prompt. The results show that while LLMs are currently not fit for purpose to be used as biomedical factual knowledge bases, there is a promising emerging property in the direction of factuality as the models become domain specialised, scale-up in size and level of human feedback. ","[{'version': 'v1', 'created': 'Sun, 28 May 2023 22:46:21 GMT'}]",2023-05-30,"[['Wysocka', 'Magdalena', ''], ['Wysocki', 'Oskar', ''], ['Delmas', 'Maxime', ''], ['Mutel', 'Vincent', ''], ['Freitas', 'Andre', '']]",1,1,2023-05-28,1,5,2,2,0,2,3aa200f562346a5e312767e5e9c1333a4f2c951b,258959248.0,https://www.semanticscholar.org/paper/3aa200f562346a5e312767e5e9c1333a4f2c951b,arXiv.org,2023.0,61.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '33352491', 'name': 'M. Wysocka'}, {'authorId': '100748878', 'name': 'Oskar Wysocki'}, {'authorId': '152651935', 'name': 'M. Delmas'}, {'authorId': '4862067', 'name': 'V. Mutel'}, {'authorId': '2121530561', 'name': 'Andre Freitas'}]","['Inflamalps SA, Monthey, Switzerland', 'University of Manchester', 'Idiap Research Institute']","['United Kingdom', 'Switzerland']",2023-05
2305.18081,Mike Perkins,"Mike Perkins (1), Jasper Roe (2), Darius Postma (1), James McGaughran
  (1), Don Hickerson (1) ((1) British University Vietnam, Vietnam, (2) James
  Cook University Singapore, Singapore)",Game of Tones: Faculty detection of GPT-4 generated content in university assessments,,,,,cs.CY cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This study explores the robustness of university assessments against the use of Open AI's Generative Pre-Trained Transformer 4 (GPT-4) generated content and evaluates the ability of academic staff to detect its use when supported by the Turnitin Artificial Intelligence (AI) detection tool. The research involved twenty-two GPT-4 generated submissions being created and included in the assessment process to be marked by fifteen different faculty members. The study reveals that although the detection tool identified 91% of the experimental submissions as containing some AI-generated content, the total detected content was only 54.8%. This suggests that the use of adversarial techniques regarding prompt engineering is an effective method in evading AI detection tools and highlights that improvements to AI detection software are needed. Using the Turnitin AI detect tool, faculty reported 54.5% of the experimental submissions to the academic misconduct process, suggesting the need for increased awareness and training into these tools. Genuine submissions received a mean score of 54.4, whereas AI-generated content scored 52.3, indicating the comparable performance of GPT-4 in real-life situations. Recommendations include adjusting assessment strategies to make them more resistant to the use of AI tools, using AI-inclusive assessment where possible, and providing comprehensive training programs for faculty and students. This research contributes to understanding the relationship between AI-generated content and academic assessment, urging further investigation to preserve academic integrity. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 13:31:58 GMT'}]",2023-05-30,"[['Perkins', 'Mike', ''], ['Roe', 'Jasper', ''], ['Postma', 'Darius', ''], ['McGaughran', 'James', ''], ['Hickerson', 'Don', '']]",0,1,2023-05-29,1,5,2,1,0,1,496dab67b98785b46867173f0d777eaa9a32ca9c,258960319.0,https://www.semanticscholar.org/paper/496dab67b98785b46867173f0d777eaa9a32ca9c,Journal of Academic Ethics,2023.0,65.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '48765116', 'name': 'Mike Perkins'}, {'authorId': '114397354', 'name': 'Jasper Roe'}, {'authorId': '2219037344', 'name': 'Darius Postma'}, {'authorId': '2219036833', 'name': 'James McGaughran'}, {'authorId': '2219037444', 'name': 'Don Hickerson British University Vietnam'}, {'authorId': '2219036829', 'name': 'Vietnam'}, {'authorId': '2219031933', 'name': 'James Cook University Singapore'}, {'authorId': '2174735545', 'name': 'Singapore'}]","['James Cook University Singapore', 'British University Vietnam']","['Singapore', 'Vietnam']",2023-05
2305.18099,Stefano De Paoli Prof,Stefano De Paoli,Writing user personas with Large Language Models: Testing phase 6 of a Thematic Analysis of semi-structured interviews,,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The goal of this paper is establishing if we can satisfactorily perform a Thematic Analysis (TA) of semi-structured interviews using a Large Language Model (more precisely GPT3.5-Turbo). Building on previous work by the author, which established an embryonal process for conducting a TA with the model, this paper will perform a further analysis and then cover the last phase of a TA (phase 6), which entails the writing up of the result. This phase was not covered by the previous work. In particular, the focus will be on using the results of a TA done with the LLM on a dataset of user interviews, for writing user personas, with the model building on the TA to produce the personas narratives. User personas are models of real users, usually built from a data analysis like interviews with a sample of users. User personas are tools often used in User Centered Design processes. The paper shows that the model can build basic user personas with an acceptable quality deriving them from themes, and that the model can serve for the generation of ideas for user personas. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 14:09:14 GMT'}]",2023-05-30,"[['De Paoli', 'Stefano', '']]",0,1,2023-05-29,1,1,2,1,0,1,1e0b6544fa931420d323a62b477cb00a3f40360b,258959113.0,https://www.semanticscholar.org/paper/1e0b6544fa931420d323a62b477cb00a3f40360b,arXiv.org,2023.0,24.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1774708', 'name': 'S. Paoli'}]",['Abertay University'],['United Kingdom'],2023-05
2305.18156,Mengsay Loem,"Mengsay Loem, Masahiro Kaneko, Sho Takase, Naoaki Okazaki",Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods,Accepted in BEA 2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale pre-trained language models such as GPT-3 have shown remarkable performance across various natural language processing tasks. However, applying prompt-based methods with GPT-3 for Grammatical Error Correction (GEC) tasks and their controllability remains underexplored. Controllability in GEC is crucial for real-world applications, particularly in educational settings, where the ability to tailor feedback according to learner levels and specific error types can significantly enhance the learning process. This paper investigates the performance and controllability of prompt-based methods with GPT-3 for GEC tasks using zero-shot and few-shot setting. We explore the impact of task instructions and examples on GPT-3's output, focusing on controlling aspects such as minimal edits, fluency edits, and learner levels. Our findings demonstrate that GPT-3 could effectively perform GEC tasks, outperforming existing supervised and unsupervised approaches. We also showed that GPT-3 could achieve controllability when appropriate task instructions and examples are given. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 15:31:29 GMT'}]",2023-05-30,"[['Loem', 'Mengsay', ''], ['Kaneko', 'Masahiro', ''], ['Takase', 'Sho', ''], ['Okazaki', 'Naoaki', '']]",0,1,2023-05-29,1,4,2,1,0,1,db0d67057b41927b5b51d3a393c250be64a405ae,258960366.0,https://www.semanticscholar.org/paper/db0d67057b41927b5b51d3a393c250be64a405ae,Workshop on Innovative Use of NLP for Building Educational Applications,2023.0,52.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2150167420', 'name': 'Mengsay Loem'}, {'authorId': '143655216', 'name': 'Masahiro Kaneko'}, {'authorId': '33544449', 'name': 'Sho Takase'}, {'authorId': '1764004', 'name': 'Naoaki Okazaki'}]",['Tokyo Institute of Technology'],['Japan'],2023-05
2305.18169,Amirhossein Abaskohi,"Amirhossein Abaskohi, Sascha Rothe, Yadollah Yaghoobzadeh",LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive Prompt-Based Few-Shot Fine-Tuning,"10 pages, 1 figure, 8 tables, 1 algorithm Proceedings of the 61st
  Annual Meeting of the Association for Computational Linguistics",https://aclanthology.org/2023.acl-short,10.18653/v1/2023.acl-short.59,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In recent years, there has been significant progress in developing pre-trained language models for NLP. However, these models often struggle when fine-tuned on small datasets. To address this issue, researchers have proposed various adaptation approaches. Prompt-based tuning is arguably the most common way, especially for larger models. Previous research shows that adding contrastive learning to prompt-based fine-tuning is effective as it helps the model generate embeddings that are more distinguishable between classes, and it can also be more sample-efficient as the model learns from positive and negative examples simultaneously. One of the most important components of contrastive learning is data augmentation, but unlike computer vision, effective data augmentation for NLP is still challenging. This paper proposes LM-CPPF, Contrastive Paraphrasing-guided Prompt-based Fine-tuning of Language Models, which leverages prompt-based few-shot paraphrasing using generative language models, especially large language models such as GPT-3 and OPT-175B, for data augmentation. Our experiments on multiple text classification benchmarks show that this augmentation method outperforms other methods, such as easy data augmentation, back translation, and multiple templates. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 15:59:51 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Jun 2023 09:02:21 GMT'}, {'version': 'v3', 'created': 'Wed, 5 Jul 2023 09:15:55 GMT'}]",2023-08-25,"[['Abaskohi', 'Amirhossein', ''], ['Rothe', 'Sascha', ''], ['Yaghoobzadeh', 'Yadollah', '']]",0,1,2023-05-29,3,3,1,2,1,1,10b0cbc35fa2e53a9b2db66de7af65b3212d9f11,258959304.0,https://www.semanticscholar.org/paper/10b0cbc35fa2e53a9b2db66de7af65b3212d9f11,Annual Meeting of the Association for Computational Linguistics,2023.0,46.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2159712030', 'name': 'Amirhossein Abaskohi'}, {'authorId': '2204815', 'name': 'S. Rothe'}, {'authorId': '3261470', 'name': 'Yadollah Yaghoobzadeh'}]","['University of Tehran', 'Google', 'Khatam University']","['Iran', 'Switzerland']",2023-05
2305.18226,Christoforos Vasilatos,"Christoforos Vasilatos, Manaar Alam, Talal Rahwan, Yasir Zaki and
  Michail Maniatakos",HowkGPT: Investigating the Detection of ChatGPT-generated University Student Homework through Context-Aware Perplexity Analysis,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As the use of Large Language Models (LLMs) in text generation tasks proliferates, concerns arise over their potential to compromise academic integrity. The education sector currently tussles with distinguishing student-authored homework assignments from AI-generated ones. This paper addresses the challenge by introducing HowkGPT, designed to identify homework assignments generated by AI. HowkGPT is built upon a dataset of academic assignments and accompanying metadata [17] and employs a pretrained LLM to compute perplexity scores for student-authored and ChatGPT-generated responses. These scores then assist in establishing a threshold for discerning the origin of a submitted assignment. Given the specificity and contextual nature of academic work, HowkGPT further refines its analysis by defining category-specific thresholds derived from the metadata, enhancing the precision of the detection. This study emphasizes the critical need for effective strategies to uphold academic integrity amidst the growing influence of LLMs and provides an approach to ensuring fair and accurate grading in educational institutions. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 11:07:25 GMT'}, {'version': 'v2', 'created': 'Wed, 7 Jun 2023 11:43:44 GMT'}]",2023-06-08,"[['Vasilatos', 'Christoforos', ''], ['Alam', 'Manaar', ''], ['Rahwan', 'Talal', ''], ['Zaki', 'Yasir', ''], ['Maniatakos', 'Michail', '']]",1,1,2023-05-26,2,5,2,1,0,1,3b732c83e12948fb665094181f552f32d8a37a31,258960155.0,https://www.semanticscholar.org/paper/3b732c83e12948fb665094181f552f32d8a37a31,arXiv.org,2023.0,29.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219049611', 'name': 'Christoforos Vasilatos'}, {'authorId': '2109936241', 'name': 'Manaar Alam'}, {'authorId': '1775071', 'name': 'Talal Rahwan'}, {'authorId': '1749350', 'name': 'Y. Zaki'}, {'authorId': '1686192', 'name': 'M. Maniatakos'}]",['New York University Abu Dhabi'],['United Arab Emirates'],2023-05
2305.18279,Yuhang Zang,"Yuhang Zang, Wei Li, Jun Han, Kaiyang Zhou, Chen Change Loy",Contextual Object Detection with Multimodal Large Language Models,"Github: https://github.com/yuhangzang/ContextDET, Project Page:
  https://www.mmlab-ntu.com/project/contextdet/index.html",,,,cs.CV cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Recent Multimodal Large Language Models (MLLMs) are remarkable in vision-language tasks, such as image captioning and question answering, but lack the essential perception ability, i.e., object detection. In this work, we address this limitation by introducing a novel research problem of contextual object detection -- understanding visible objects within different human-AI interactive contexts. Three representative scenarios are investigated, including the language cloze test, visual captioning, and question answering. Moreover, we present ContextDET, a unified multimodal model that is capable of end-to-end differentiable modeling of visual-language contexts, so as to locate, identify, and associate visual objects with language inputs for human-AI interaction. Our ContextDET involves three key submodels: (i) a visual encoder for extracting visual representations, (ii) a pre-trained LLM for multimodal context decoding, and (iii) a visual decoder for predicting bounding boxes given contextual object words. The new generate-then-detect framework enables us to detect object words within human vocabulary. Extensive experiments show the advantages of ContextDET on our proposed CODE benchmark, open-vocabulary detection, and referring image segmentation. Github: https://github.com/yuhangzang/ContextDET. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 17:50:33 GMT'}]",2023-05-30,"[['Zang', 'Yuhang', ''], ['Li', 'Wei', ''], ['Han', 'Jun', ''], ['Zhou', 'Kaiyang', ''], ['Loy', 'Chen Change', '']]",0,0,2023-05-29,1,5,2,0,0,0,50c1414fe41d0cb9db6f0933c9319aa124beac5d,258959011.0,https://www.semanticscholar.org/paper/50c1414fe41d0cb9db6f0933c9319aa124beac5d,arXiv.org,2023.0,88.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '12862495', 'name': 'Yuhang Zang'}, {'authorId': '2157337253', 'name': 'Wei Li'}, {'authorId': '2109488551', 'name': 'Jun Han'}, {'authorId': '9368124', 'name': 'Kaiyang Zhou'}, {'authorId': '1717179', 'name': 'Chen Change Loy'}]",['Nanyang Technological University'],['Singapore'],2023-05
2305.18324,Yifan Nie,"Vanessa Liao, Syed Shariyar Murtaza, Yifan Nie, Jimmy Lin",Regex-augmented Domain Transfer Topic Classification based on a Pre-trained Language Model: An application in Financial Domain,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  A common way to use large pre-trained language models for downstream tasks is to fine tune them using additional layers. This may not work well if downstream domain is a specialized domain whereas the large language model has been pre-trained on a generic corpus. In this paper, we discuss the use of regular expression patterns employed as features for domain knowledge during the process of fine tuning, in addition to domain specific text. Our experiments on real scenario production data show that this method of fine tuning improves the downstream text classification tasks as compared to fine tuning only on domain specific text. We also show that the use of attention network for fine tuning improves results compared to simple linear layers. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 03:26:32 GMT'}]",2023-05-31,"[['Liao', 'Vanessa', ''], ['Murtaza', 'Syed Shariyar', ''], ['Nie', 'Yifan', ''], ['Lin', 'Jimmy', '']]",0,0,2023-05-23,1,4,2,0,0,0,a74c49d96ab32c9bf398a23c9b46f36bfeb6ec4b,258967722.0,https://www.semanticscholar.org/paper/a74c49d96ab32c9bf398a23c9b46f36bfeb6ec4b,arXiv.org,2023.0,25.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2218487887', 'name': 'Vanessa Liao'}, {'authorId': '2307843', 'name': 'Syed Shariyar Murtaza'}, {'authorId': '152972511', 'name': 'Yifan Nie'}, {'authorId': '2154743364', 'name': 'Jimmy Lin'}]","['University of Toronto', 'University of Waterloo']",['Canada'],2023-05
2305.18342,Adish Singla,"Victor-Alexandru P\u{a}durean, Georgios Tzannetos, Adish Singla",Neural Task Synthesis for Visual Programming,,,,,cs.LG cs.AI cs.CL cs.CY cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative neural models hold great promise in enhancing programming education by synthesizing new content for students. We seek to design neural models that can automatically generate programming tasks for a given specification in the context of visual programming domains. Despite the recent successes of large generative models like GPT-4, our initial results show that these models are ineffective in synthesizing visual programming tasks and struggle with logical and spatial reasoning. We propose a novel neuro-symbolic technique, NeurTaskSyn, that can synthesize programming tasks for a specification given in the form of desired programming concepts exercised by its solution code and constraints on the visual task. NeurTaskSyn has two components: the first component is trained via imitation learning procedure to generate possible solution codes, and the second component is trained via reinforcement learning procedure to guide an underlying symbolic execution engine that generates visual tasks for these codes. We demonstrate the effectiveness of NeurTaskSyn through an extensive empirical evaluation and a qualitative study on reference tasks taken from the Hour of Code: Classic Maze challenge by Code-dot-org and the Intro to Programming with Karel course by CodeHS-dot-com. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 01:08:18 GMT'}, {'version': 'v2', 'created': 'Thu, 1 Jun 2023 14:05:10 GMT'}]",2023-06-02,"[['Pădurean', 'Victor-Alexandru', ''], ['Tzannetos', 'Georgios', ''], ['Singla', 'Adish', '']]",0,1,2023-05-26,2,3,5,1,0,1,59a4a5db0a913b99b7afe1c6b2bf6e24f0d31857,258968122.0,https://www.semanticscholar.org/paper/59a4a5db0a913b99b7afe1c6b2bf6e24f0d31857,arXiv.org,2023.0,60.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2086749177', 'name': 'Victor-Alexandru Pădurean'}, {'authorId': '2215269869', 'name': 'Georgios Tzannetos'}, {'authorId': '1703727', 'name': 'A. Singla'}]",['Max Planck Institute for Software Systems'],['Germany'],2023-05
2305.18354,Yudong Xu,"Yudong Xu, Wenhao Li, Pashootan Vaezipoor, Scott Sanner, Elias B.
  Khalil","LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and the Importance of Object-based Representations","17 pages, 11 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Can a Large Language Model (LLM) solve simple abstract reasoning problems? We explore this broad question through a systematic analysis of GPT on the Abstraction and Reasoning Corpus (ARC), a representative benchmark of abstract reasoning ability from limited examples in which solutions require some ""core knowledge"" of concepts such as objects, goal states, counting, and basic geometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when using textual encodings for their two-dimensional input-output grids. Our failure analysis reveals that GPT-4's capacity to identify objects and reason about them is significantly influenced by the sequential nature of the text that represents an object within a text encoding of a task. To test this hypothesis, we design a new benchmark, the 1D-ARC, which consists of one-dimensional (array-like) tasks that are more conducive to GPT-based reasoning, and where it indeed performs better than on the (2D) ARC. To alleviate this issue, we propose an object-based representation that is obtained through an external tool, resulting in nearly doubling the performance on solved ARC tasks and near-perfect scores on the easier 1D-ARC. Although the state-of-the-art GPT-4 is unable to ""reason"" perfectly within non-language domains such as the 1D-ARC or a simple ARC subset, our study reveals that the use of object-based representations can significantly improve its reasoning ability. Visualizations, GPT logs, and data are available at https://khalil-research.github.io/LLM4ARC. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 16:32:17 GMT'}]",2023-05-31,"[['Xu', 'Yudong', ''], ['Li', 'Wenhao', ''], ['Vaezipoor', 'Pashootan', ''], ['Sanner', 'Scott', ''], ['Khalil', 'Elias B.', '']]",0,1,2023-05-26,1,5,2,1,0,1,8826311d922135dbf0cfdb4a661ebab347e3b826,258968016.0,https://www.semanticscholar.org/paper/8826311d922135dbf0cfdb4a661ebab347e3b826,arXiv.org,2023.0,24.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '47103635', 'name': 'Yudong Xu'}, {'authorId': '2108769877', 'name': 'Wenhao Li'}, {'authorId': '1947192', 'name': 'Pashootan Vaezipoor'}, {'authorId': '1732536', 'name': 'S. Sanner'}, {'authorId': '35252180', 'name': 'Elias Boutros Khalil'}]","['University of Toronto', 'Scale AI Research Chair in Data-Driven Algorithms for Modern Supply Chains', 'Vector Institute']",['Canada'],2023-05
2305.18395,Minki Kang,"Minki Kang, Seanie Lee, Jinheon Baek, Kenji Kawaguchi, Sung Ju Hwang",Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks,Preprint. Under review,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have shown promising performance in knowledge-intensive reasoning tasks that require a compound understanding of knowledge. However, deployment of the LLMs in real-world applications can be challenging due to their high computational requirements and concerns on data privacy. Previous studies have focused on building task-specific small language models (LMs) by fine-tuning them with labeled data or distilling LLMs. However, these approaches are ill-suited for knowledge-intensive reasoning tasks due to the limited capacity of small LMs in memorizing the knowledge required. Motivated by our theoretical analysis on memorization, we propose Knowledge-Augmented Reasoning Distillation (KARD), a novel method that fine-tunes small LMs to generate rationales with augmented knowledge retrieved from an external knowledge base. Moreover, we further propose a neural reranker to obtain documents relevant to rationale generation. We empirically show that KARD significantly improves the performance of small T5 and Flan-T5 models on the challenging knowledge-intensive reasoning datasets, namely MedQA-USMLE and StrategyQA. Notably, our method makes the 250M models achieve superior performance against the fine-tuned 3B models, having 12 times larger parameters, on both MedQA-USMLE and StrategyQA benchmarks. ","[{'version': 'v1', 'created': 'Sun, 28 May 2023 13:00:00 GMT'}]",2023-05-31,"[['Kang', 'Minki', ''], ['Lee', 'Seanie', ''], ['Baek', 'Jinheon', ''], ['Kawaguchi', 'Kenji', ''], ['Hwang', 'Sung Ju', '']]",0,0,2023-05-28,1,5,3,3,2,1,ebf3a59aacdd9982283d7f41229ee2a93800d6ef,258967252.0,https://www.semanticscholar.org/paper/ebf3a59aacdd9982283d7f41229ee2a93800d6ef,arXiv.org,2023.0,59.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '120434407', 'name': 'Minki Kang'}, {'authorId': '1472875852', 'name': 'Seanie Lee'}, {'authorId': '90765684', 'name': 'Jinheon Baek'}, {'authorId': '1392876047', 'name': 'Kenji Kawaguchi'}, {'authorId': '35788904', 'name': 'Sung Ju Hwang'}]","['Pamukkale University', 'National University of Singapore']","['Turkey', 'Singapore']",2023-05
2305.18486,Md Tahmid Rahman Laskar,"Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran
  Hossen Bhuiyan, Shafiq Joty, Jimmy Xiangji Huang",A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets,"Accepted by ACL 2023 Findings. The first three authors contributed
  equally",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT's performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instructions that we mostly found in ChatGPT and other instruction-tuned models. Our extensive evaluation shows that even though ChatGPT is capable of performing a wide variety of tasks, and may obtain impressive performance in several benchmark datasets, it is still far from achieving the ability to reliably solve many challenging tasks. By providing a thorough assessment of ChatGPT's performance across diverse NLP tasks, this paper sets the stage for a targeted deployment of ChatGPT-like LLMs in real-world applications. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 12:37:21 GMT'}, {'version': 'v2', 'created': 'Mon, 5 Jun 2023 16:21:40 GMT'}, {'version': 'v3', 'created': 'Thu, 8 Jun 2023 03:27:16 GMT'}, {'version': 'v4', 'created': 'Wed, 5 Jul 2023 16:19:38 GMT'}]",2023-07-07,"[['Laskar', 'Md Tahmid Rahman', ''], ['Bari', 'M Saiful', ''], ['Rahman', 'Mizanur', ''], ['Bhuiyan', 'Md Amran Hossen', ''], ['Joty', 'Shafiq', ''], ['Huang', 'Jimmy Xiangji', '']]",1,1,2023-05-29,4,6,3,1,0,1,d3060876d9ad4e4e50e1c88a8c04186df00f24e2,258967462.0,https://www.semanticscholar.org/paper/d3060876d9ad4e4e50e1c88a8c04186df00f24e2,Annual Meeting of the Association for Computational Linguistics,2023.0,232.0,37.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46437970', 'name': 'Md Tahmid Rahman Laskar'}, {'authorId': '31773000', 'name': 'M Saiful Bari'}, {'authorId': '2218664824', 'name': 'Mizanur Rahman'}, {'authorId': '145505476', 'name': 'Md Amran Hossen Bhuiyan'}, {'authorId': '2708940', 'name': 'Shafiq R. Joty'}, {'authorId': '1683391', 'name': 'J. Huang'}]","['Nanyang Technological University', 'York University']","['Canada', 'Singapore']",2023-05
2305.18616,Gaoxia Zhu,"Gaoxia Zhu, Xiuyi Fan, Chenyu Hou, Tianlong Zhong, Peter Seow, Annabel
  Chen Shen-Hsing, Preman Rajalingam, Low Kin Yew, Tan Lay Poh",Embrace Opportunities and Face Challenges: Using ChatGPT in Undergraduate Students' Collaborative Interdisciplinary Learning,"33 pages, 2 figures, 5 tables",,,,cs.CY cs.AI,http://creativecommons.org/licenses/by/4.0/,"  ChatGPT, launched in November 2022, has gained widespread attention from students and educators globally, with an online report by Hu (2023) stating it as the fastest-growing consumer application in history. While discussions on the use of ChatGPT in higher education are abundant, empirical studies on its impact on collaborative interdisciplinary learning are rare. To investigate its potential, we conducted a quasi-experimental study with 130 undergraduate students (STEM and non-STEM) learning digital literacy with or without ChatGPT over two weeks. Weekly surveys were conducted on collaborative interdisciplinary problem-solving, physical and cognitive engagement, and individual reflections on ChatGPT use. Analysis of survey responses showed significant main effects of topics on collaborative interdisciplinary problem-solving and physical and cognitive engagement, a marginal interaction effect between disciplinary backgrounds and ChatGPT conditions for cognitive engagement, and a significant interaction effect for physical engagement. Sentiment analysis of student reflections suggested no significant difference between STEM and non-STEM students' opinions towards ChatGPT. Qualitative analysis of reflections generated eight positive themes, including efficiency, addressing knowledge gaps, and generating human-like responses, and eight negative themes, including generic responses, lack of innovation, and counterproductive to self-discipline and thinking. Our findings suggest that ChatGPT use needs to be optimized by considering the topics being taught and the disciplinary backgrounds of students rather than applying it uniformly. These findings have implications for both pedagogical research and practices. ","[{'version': 'v1', 'created': 'Tue, 23 May 2023 13:14:49 GMT'}]",2023-05-31,"[['Zhu', 'Gaoxia', ''], ['Fan', 'Xiuyi', ''], ['Hou', 'Chenyu', ''], ['Zhong', 'Tianlong', ''], ['Seow', 'Peter', ''], ['Shen-Hsing', 'Annabel Chen', ''], ['Rajalingam', 'Preman', ''], ['Yew', 'Low Kin', ''], ['Poh', 'Tan Lay', '']]",1,1,2023-05-23,1,9,2,1,0,1,e9326da3244c5e84591c43dfdf06d51d7bc2af57,258967446.0,https://www.semanticscholar.org/paper/e9326da3244c5e84591c43dfdf06d51d7bc2af57,arXiv.org,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2931817', 'name': 'Gaoxia Zhu'}, {'authorId': '33853958', 'name': 'Xiuyi Fan'}, {'authorId': '3364327', 'name': 'Chenyu Hou'}, {'authorId': '2205391266', 'name': 'Tianlong Zhong'}, {'authorId': '2135841', 'name': 'P. Seow'}, {'authorId': '1451674073', 'name': 'Annabel Chen Shen-Hsing'}, {'authorId': '27793890', 'name': 'Preman Rajalingam'}, {'authorId': '2218921651', 'name': 'Low Kin Yew'}, {'authorId': '11440793', 'name': 'Tan Lay Poh'}]","['National Institute of Education', 'Nanyang Technological University']",['Singapore'],2023-05
2305.18618,Vagelis Plevris,"Vagelis Plevris, George Papazafeiropoulos, Alejandro Jim\'enez Rios","Chatbots put to the test in math and logic problems: A preliminary comparison and assessment of ChatGPT-3.5, ChatGPT-4, and Google Bard",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  A comparison between three chatbots which are based on large language models, namely ChatGPT-3.5, ChatGPT-4 and Google Bard is presented, focusing on their ability to give correct answers to mathematics and logic problems. In particular, we check their ability to Understand the problem at hand; Apply appropriate algorithms or methods for its solution; and Generate a coherent response and a correct answer. We use 30 questions that are clear, without any ambiguities, fully described with plain text only, and have a unique, well defined correct answer. The questions are divided into two sets of 15 each. The questions of Set A are 15 ""Original"" problems that cannot be found online, while Set B contains 15 ""Published"" problems that one can find online, usually with their solution. Each question is posed three times to each chatbot. The answers are recorded and discussed, highlighting their strengths and weaknesses. It has been found that for straightforward arithmetic, algebraic expressions, or basic logic puzzles, chatbots may provide accurate solutions, although not in every attempt. However, for more complex mathematical problems or advanced logic tasks, their answers, although written in a usually ""convincing"" way, may not be reliable. Consistency is also an issue, as many times a chatbot will provide conflicting answers when given the same question more than once. A comparative quantitative evaluation of the three chatbots is made through scoring their final answers based on correctness. It was found that ChatGPT-4 outperforms ChatGPT-3.5 in both sets of questions. Bard comes third in the original questions of Set A, behind the other two chatbots, while it has the best performance (first place) in the published questions of Set B. This is probably because Bard has direct access to the internet, in contrast to ChatGPT chatbots which do not have any communication with the outside world. ","[{'version': 'v1', 'created': 'Tue, 30 May 2023 11:18:05 GMT'}]",2023-05-31,"[['Plevris', 'Vagelis', ''], ['Papazafeiropoulos', 'George', ''], ['Rios', 'Alejandro Jiménez', '']]",1,1,2023-05-30,1,3,2,1,0,1,d0a153cdd34451b007ef1d0ba3cf54e963969486,258967412.0,https://www.semanticscholar.org/paper/d0a153cdd34451b007ef1d0ba3cf54e963969486,arXiv.org,2023.0,20.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2360803', 'name': 'V. Plevris'}, {'authorId': '9552676', 'name': 'G. Papazafeiropoulos'}, {'authorId': '145988907', 'name': 'Alejandro Ríos'}]","['National Technical University of Athens', 'Qatar University', 'OsloMet – Oslo Metropolitan University']","['Greece', 'Qatar', 'Norway']",2023-05
2305.18638,Su Youn Yoon Ms,Su-Youn Yoon,Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model,"7 pages, 2 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this study, we developed an automated short answer grading (ASAG) model that provided both analytic scores and final holistic scores. Short answer items typically consist of multiple sub-questions, and providing an analytic score and the text span relevant to each sub-question can increase the interpretability of the automated scores. Furthermore, they can be used to generate actionable feedback for students. Despite these advantages, most studies have focused on predicting only holistic scores due to the difficulty in constructing dataset with manual annotations. To address this difficulty, we used large language model (LLM)-based one-shot prompting and a text similarity scoring model with domain adaptation using small manually annotated dataset. The accuracy and quadratic weighted kappa of our model were 0.67 and 0.71 on a subset of the publicly available ASAG dataset. The model achieved a substantial improvement over the majority baseline. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 22:05:29 GMT'}]",2023-05-31,"[['Yoon', 'Su-Youn', '']]",0,0,2023-05-29,1,1,1,0,0,0,d1aa858644154af50e36860e6761ae52ae655bd3,258967783.0,https://www.semanticscholar.org/paper/d1aa858644154af50e36860e6761ae52ae655bd3,arXiv.org,2023.0,17.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2669255', 'name': 'Su-Youn Yoon'}]","['EduLab, Inc., Shibuya city, Tokyo, Japan']",['Japan'],2023-05
2305.18997,Abdullahi Saka PhD,"Abdullahi Saka, Ridwan Taiwo, Nurudeen Saka, Babatunde Salami, Saheed
  Ajayi, Kabiru Akande, and Hadi Kazemi","GPT Models in Construction Industry: Opportunities, Limitations, and a Use Case Validation","58 pages, 20 figures",,,,cs.HC cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models(LLMs) trained on large data sets came into prominence in 2018 after Google introduced BERT. Subsequently, different LLMs such as GPT models from OpenAI have been released. These models perform well on diverse tasks and have been gaining widespread applications in fields such as business and education. However, little is known about the opportunities and challenges of using LLMs in the construction industry. Thus, this study aims to assess GPT models in the construction industry. A critical review, expert discussion and case study validation are employed to achieve the study objectives. The findings revealed opportunities for GPT models throughout the project lifecycle. The challenges of leveraging GPT models are highlighted and a use case prototype is developed for materials selection and optimization. The findings of the study would be of benefit to researchers, practitioners and stakeholders, as it presents research vistas for LLMs in the construction industry. ","[{'version': 'v1', 'created': 'Tue, 30 May 2023 12:50:51 GMT'}]",2023-05-31,"[['Saka', 'Abdullahi', ''], ['Taiwo', 'Ridwan', ''], ['Saka', 'Nurudeen', ''], ['Salami', 'Babatunde', ''], ['Ajayi', 'Saheed', ''], ['Akande', 'Kabiru', ''], ['Kazemi', 'Hadi', '']]",0,1,2023-05-30,1,7,3,0,0,0,d7515e658c69223e26324be6143443cb1f7bbc0b,258967639.0,https://www.semanticscholar.org/paper/d7515e658c69223e26324be6143443cb1f7bbc0b,arXiv.org,2023.0,149.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '101271239', 'name': 'A. Saka'}, {'authorId': '2186491295', 'name': 'Ridwan Taiwo'}, {'authorId': '2218467518', 'name': 'Nurudeen Saka'}, {'authorId': '101298311', 'name': 'B. Salami'}, {'authorId': '38330224', 'name': 'Saheed Ajayi'}, {'authorId': '2294254', 'name': 'Kabiru O. Akande'}, {'authorId': '145096229', 'name': 'Hadi Kazemi'}]","['OVO Energy, UK', 'Management; Construction Informatics and Digital Enterprise Laboratory (CIDEL))', 'Leeds Beckett University', 'Hong Kong Polytechnic University', 'Teesside University']","['United Kingdom', 'Hong Kong']",2023-05
2305.19148,Yu Fei,"Yu Fei, Yifan Hou, Zeming Chen, Antoine Bosselut",Mitigating Label Biases for In-context Learning,Accepted to ACL 2023,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Various design settings for in-context learning (ICL), such as the choice and order of the in-context examples, can bias a model toward a particular prediction without being reflective of an understanding of the task. While many studies discuss these design choices, there have been few systematic investigations into categorizing them and mitigating their impact. In this work, we define a typology for three types of label biases in ICL for text classification: vanilla-label bias, context-label bias, and domain-label bias (which we conceptualize and detect for the first time).   Our analysis demonstrates that prior label bias calibration methods fall short of addressing all three types of biases. Specifically, domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples. To mitigate the effect of these biases, we propose a simple bias calibration method that estimates a language model's label bias using random in-domain words from the task corpus. After controlling for this estimated bias when making predictions, our novel domain-context calibration significantly improves the ICL performance of GPT-J and GPT-3 on a wide range of tasks. The gain is substantial on tasks with large domain-label bias (up to 37% in Macro-F1). Furthermore, our results generalize to models with different scales, pretraining methods, and manually-designed task instructions, showing the prevalence of label biases in ICL. ","[{'version': 'v1', 'created': 'Sun, 28 May 2023 15:37:39 GMT'}, {'version': 'v2', 'created': 'Sat, 10 Jun 2023 07:31:42 GMT'}, {'version': 'v3', 'created': 'Fri, 4 Aug 2023 15:43:19 GMT'}]",2023-08-07,"[['Fei', 'Yu', ''], ['Hou', 'Yifan', ''], ['Chen', 'Zeming', ''], ['Bosselut', 'Antoine', '']]",0,1,2023-05-28,3,4,3,1,0,1,28a7ced384549eaae74ea9ad3ee21189a0625afe,258967265.0,https://www.semanticscholar.org/paper/28a7ced384549eaae74ea9ad3ee21189a0625afe,Annual Meeting of the Association for Computational Linguistics,2023.0,44.0,13.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2121536275', 'name': 'Yu Fei'}, {'authorId': '2088768581', 'name': 'Yifan Hou'}, {'authorId': '2111435018', 'name': 'Zeming Chen'}, {'authorId': '2691021', 'name': 'Antoine Bosselut'}]",['École Polytechnique Fédérale de Lausanne'],['Switzerland'],2023-05
2305.19352,Artem Lykov,Artem Lykov and Dzmitry Tsetserukou,LLM-BRAIn: AI-driven Fast Generation of Robot Behaviour Tree based on Large Language Model,"10 pages, 5 figures",,,,cs.RO,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This paper presents a novel approach in autonomous robot control, named LLM-BRAIn, that makes possible robot behavior generation, based on operator's commands. LLM-BRAIn is a transformer-based Large Language Model (LLM) fine-tuned from Stanford Alpaca 7B model to generate robot behavior tree (BT) from the text description. We train the LLM-BRAIn on 8,5k instruction-following demonstrations, generated in the style of self-instruct using text-davinchi-003. The developed model accurately builds complex robot behavior while remaining small enough to be run on the robot's onboard microcomputer. The model gives structural and logical correct BTs and can successfully manage instructions that were not presented in training set. The experiment did not reveal any significant subjective differences between BTs generated by LLM-BRAIn and those created by humans (on average, participants were able to correctly distinguish between LLM-BRAIn generated BTs and human-created BTs in only 4.53 out of 10 cases, indicating that their performance was close to random chance). The proposed approach potentially can be applied to mobile robotics, drone operation, robot manipulator systems and Industry 4.0. ","[{'version': 'v1', 'created': 'Tue, 30 May 2023 18:28:54 GMT'}]",2023-06-01,"[['Lykov', 'Artem', ''], ['Tsetserukou', 'Dzmitry', '']]",0,0,2023-05-30,1,2,1,1,0,1,73b2dee720ebc9014dfe57d9b73da60ca7645c86,258987995.0,https://www.semanticscholar.org/paper/73b2dee720ebc9014dfe57d9b73da60ca7645c86,arXiv.org,2023.0,23.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2189477580', 'name': 'Artem Lykov'}, {'authorId': '48470616', 'name': 'D. Tsetserukou'}]",['Skolkovo Institute of Science and Technology'],['Russia'],2023-05
2305.19783,Maarten De Raedt,"Maarten De Raedt, Fr\'ederic Godin, Thomas Demeester, Chris Develder",IDAS: Intent Discovery with Abstractive Summarization,The 5th Workshop on NLP for Conversational AI (NLP4ConvAI@ACL),,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Intent discovery is the task of inferring latent intents from a set of unlabeled utterances, and is a useful step towards the efficient creation of new conversational agents. We show that recent competitive methods in intent discovery can be outperformed by clustering utterances based on abstractive summaries, i.e., ""labels"", that retain the core elements while removing non-essential information. We contribute the IDAS approach, which collects a set of descriptive utterance labels by prompting a Large Language Model, starting from a well-chosen seed set of prototypical utterances, to bootstrap an In-Context Learning procedure to generate labels for non-prototypical utterances. The utterances and their resulting noisy labels are then encoded by a frozen pre-trained encoder, and subsequently clustered to recover the latent intents. For the unsupervised task (without any intent labels) IDAS outperforms the state-of-the-art by up to +7.42% in standard cluster metrics for the Banking, StackOverflow, and Transport datasets. For the semi-supervised task (with labels for a subset of intents) IDAS surpasses 2 recent methods on the CLINC benchmark without even using labeled data. ","[{'version': 'v1', 'created': 'Wed, 31 May 2023 12:19:40 GMT'}]",2023-06-01,"[['De Raedt', 'Maarten', ''], ['Godin', 'Fréderic', ''], ['Demeester', 'Thomas', ''], ['Develder', 'Chris', '']]",0,0,2023-05-31,1,4,1,0,0,0,b9c263500281e05fddfe1f84839491f605815230,258987814.0,https://www.semanticscholar.org/paper/b9c263500281e05fddfe1f84839491f605815230,NLP4CONVAI,2023.0,43.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067792829', 'name': 'Maarten De Raedt'}, {'authorId': '73770372', 'name': 'Fréderic Godin'}, {'authorId': '1388296896', 'name': 'Thomas Demeester'}, {'authorId': '2067842103', 'name': 'Chris Develder'}]",['Ghent University'],['Belgium'],2023-05
2305.19911,Fazl Barez,"Alex Foote, Neel Nanda, Esben Kran, Ioannis Konstas, Shay Cohen, Fazl
  Barez",Neuron to Graph: Interpreting Language Model Neurons at Scale,,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Advances in Large Language Models (LLMs) have led to remarkable capabilities, yet their inner mechanisms remain largely unknown. To understand these models, we need to unravel the functions of individual neurons and their contribution to the network. This paper introduces a novel automated approach designed to scale interpretability techniques across a vast array of neurons within LLMs, to make them more interpretable and ultimately safe. Conventional methods require examination of examples with strong neuron activation and manual identification of patterns to decipher the concepts a neuron responds to. We propose Neuron to Graph (N2G), an innovative tool that automatically extracts a neuron's behaviour from the dataset it was trained on and translates it into an interpretable graph. N2G uses truncation and saliency methods to emphasise only the most pertinent tokens to a neuron while enriching dataset examples with diverse samples to better encompass the full spectrum of neuron behaviour. These graphs can be visualised to aid researchers' manual interpretation, and can generate token activations on text for automatic validation by comparison with the neuron's ground truth activations, which we use to show that the model is better at predicting neuron activation than two baseline methods. We also demonstrate how the generated graph representations can be flexibly used to facilitate further automation of interpretability research, by searching for neurons with particular properties, or programmatically comparing neurons to each other to identify similar neurons. Our method easily scales to build graph representations for all neurons in a 6-layer Transformer model using a single Tesla T4 GPU, allowing for wide usability. We release the code and instructions for use at https://github.com/alexjfoote/Neuron2Graph. ","[{'version': 'v1', 'created': 'Wed, 31 May 2023 14:44:33 GMT'}]",2023-06-01,"[['Foote', 'Alex', ''], ['Nanda', 'Neel', ''], ['Kran', 'Esben', ''], ['Konstas', 'Ioannis', ''], ['Cohen', 'Shay', ''], ['Barez', 'Fazl', '']]",0,0,2023-05-31,1,6,2,0,0,0,61039ce0c0f079b90ecca7d8c659340aee9ee932,258987572.0,https://www.semanticscholar.org/paper/61039ce0c0f079b90ecca7d8c659340aee9ee932,arXiv.org,2023.0,29.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2067807267', 'name': 'Alex Foote'}, {'authorId': '2051128902', 'name': 'Neel Nanda'}, {'authorId': '2005663935', 'name': 'Esben Kran'}, {'authorId': '2621022', 'name': 'Ioannis Konstas'}, {'authorId': '40146204', 'name': 'Shay B. Cohen'}, {'authorId': '2143198655', 'name': 'Fazl Barez'}]","['University of Edinburgh', 'Heriot-Watt University', 'University of Oxford']",['United Kingdom'],2023-05
2305.20062,Matan Levy,"Matan Levy, Rami Ben-Ari, Nir Darshan, Dani Lischinski",Chatting Makes Perfect: Chat-based Image Retrieval,Camera Ready version for NeurIPS 2023,,,,cs.CV,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Chats emerge as an effective user-friendly approach for information retrieval, and are successfully employed in many domains, such as customer service, healthcare, and finance. However, existing image retrieval approaches typically address the case of a single query-to-image round, and the use of chats for image retrieval has been mostly overlooked. In this work, we introduce ChatIR: a chat-based image retrieval system that engages in a conversation with the user to elicit information, in addition to an initial query, in order to clarify the user's search intent. Motivated by the capabilities of today's foundation models, we leverage Large Language Models to generate follow-up questions to an initial image description. These questions form a dialog with the user in order to retrieve the desired image from a large corpus. In this study, we explore the capabilities of such a system tested on a large dataset and reveal that engaging in a dialog yields significant gains in image retrieval. We start by building an evaluation pipeline from an existing manually generated dataset and explore different modules and training strategies for ChatIR. Our comparison includes strong baselines derived from related applications trained with Reinforcement Learning. Our system is capable of retrieving the target image from a pool of 50K images with over 78% success rate after 5 dialogue rounds, compared to 75% when questions are asked by humans, and 64% for a single shot text-to-image retrieval. Extensive evaluations reveal the strong capabilities and examine the limitations of CharIR under different settings. Project repository is available at https://github.com/levymsn/ChatIR. ","[{'version': 'v1', 'created': 'Wed, 31 May 2023 17:38:08 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Oct 2023 16:40:02 GMT'}]",2023-10-06,"[['Levy', 'Matan', ''], ['Ben-Ari', 'Rami', ''], ['Darshan', 'Nir', ''], ['Lischinski', 'Dani', '']]",0,0,2023-05-31,2,4,1,0,0,0,461437e165fa8236373bdcc4db5f09667863bc29,258987679.0,https://www.semanticscholar.org/paper/461437e165fa8236373bdcc4db5f09667863bc29,,2023.0,61.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '14364010', 'name': 'Matan Levy'}, {'authorId': '1397958297', 'name': 'Rami Ben-Ari'}, {'authorId': '8684542', 'name': 'N. Darshan'}, {'authorId': '70018371', 'name': 'D. Lischinski'}]","['Hebrew University of Jerusalem', 'OriginAI, Israel']",['Israel'],2023-05
2306.00168,Nitay Calderon,"Nitay Calderon, Naveh Porat, Eyal Ben-David, Zorik Gekhman, Nadav
  Oved, Roi Reichart",Measuring the Robustness of Natural Language Processing Models to Domain Shifts,,,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Existing research on Domain Robustness (DR) suffers from disparate setups, lack of evaluation task variety, and reliance on challenge sets. In this paper, we pose a fundamental question: What is the state of affairs of the DR challenge in the era of Large Language Models (LLMs)? To this end, we construct a DR benchmark comprising diverse NLP tasks, including sentence and token-level classification, QA, and generation, each task consists of several domains. We explore the DR challenge of fine-tuned and few-shot learning models in natural domain shift settings and devise two diagnostic metrics of Out-of-Distribution (OOD) performance degradation: The commonly used Source Drop (SD) and the overlooked Target Drop (TD). Our findings reveal important insights: First, despite their capabilities, zero-to-few shot LLMs and fine-tuning approaches still fail to meet satisfactory performance in the OOD context; Second, TD approximates better than SD the average OOD degradation; Third, in a significant proportion of domain shifts, either SD or TD is positive, but not both, and therefore disregarding one can lead to incorrect DR conclusions. ","[{'version': 'v1', 'created': 'Wed, 31 May 2023 20:25:08 GMT'}, {'version': 'v2', 'created': 'Sat, 1 Jul 2023 18:05:19 GMT'}]",2023-07-04,"[['Calderon', 'Nitay', ''], ['Porat', 'Naveh', ''], ['Ben-David', 'Eyal', ''], ['Gekhman', 'Zorik', ''], ['Oved', 'Nadav', ''], ['Reichart', 'Roi', '']]",0,0,2023-05-31,2,6,1,0,0,0,104c878d17a179e86ba094b221993cfdd3277943,258999218.0,https://www.semanticscholar.org/paper/104c878d17a179e86ba094b221993cfdd3277943,arXiv.org,2023.0,73.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2135910736', 'name': 'Nitay Calderon'}, {'authorId': '2219403829', 'name': 'Naveh Porat'}, {'authorId': '2031088828', 'name': 'Eyal Ben-David'}, {'authorId': '2158816391', 'name': 'Zorik Gekhman'}, {'authorId': '1382650252', 'name': 'Nadav Oved'}, {'authorId': '1762757', 'name': 'Roi Reichart'}]",['Technion – Israel Institute of Technology'],['Israel'],2023-05
2306.00317,Jeonghoon Kim,"Jung Hyun Lee, Jeonghoon Kim, Se Jung Kwon, Dongsoo Lee",FlexRound: Learnable Rounding based on Element-wise Division for Post-Training Quantization,Accepted to ICML 2023,,,,cs.LG cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Post-training quantization (PTQ) has been gaining popularity for the deployment of deep neural networks on resource-limited devices since unlike quantization-aware training, neither a full training dataset nor end-to-end training is required at all. As PTQ schemes based on reconstructing each layer or block output turn out to be effective to enhance quantized model performance, recent works have developed algorithms to devise and learn a new weight-rounding scheme so as to better reconstruct each layer or block output. In this work, we propose a simple yet effective new weight-rounding mechanism for PTQ, coined FlexRound, based on element-wise division instead of typical element-wise addition such that FlexRound enables jointly learning a common quantization grid size as well as a different scale for each pre-trained weight. Thanks to the reciprocal rule of derivatives induced by element-wise division, FlexRound is inherently able to exploit pre-trained weights when updating their corresponding scales, and thus, flexibly quantize pre-trained weights depending on their magnitudes. We empirically validate the efficacy of FlexRound on a wide range of models and tasks. To the best of our knowledge, our work is the first to carry out comprehensive experiments on not only image classification and natural language understanding but also natural language generation, assuming a per-tensor uniform PTQ setting. Moreover, we demonstrate, for the first time, that large language models can be efficiently quantized, with only a negligible impact on performance compared to half-precision baselines, achieved by reconstructing the output in a block-by-block manner. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 03:31:12 GMT'}]",2023-06-02,"[['Lee', 'Jung Hyun', ''], ['Kim', 'Jeonghoon', ''], ['Kwon', 'Se Jung', ''], ['Lee', 'Dongsoo', '']]",0,0,2023-06-01,1,4,2,0,0,0,1b31882e60aaae3ac696e4f24f5cd93275c591f7,258999931.0,https://www.semanticscholar.org/paper/1b31882e60aaae3ac696e4f24f5cd93275c591f7,International Conference on Machine Learning,2023.0,59.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2119171752', 'name': 'J. H. Lee'}, {'authorId': '2144193082', 'name': 'Jeonghoon Kim'}, {'authorId': '12693169', 'name': 'Se Jung Kwon'}, {'authorId': '122808525', 'name': 'Dongsoo Lee'}]","['NAVER', 'Knowledge Innovation Market']","['South Korea', 'Spain']",2023-06
2306.00597,Antonello Ceravola,"Ahmed R. Sadik, Antonello Ceravola, Frank Joublin, Jibesh Patra",Analysis of ChatGPT on Source Code,"40 pages, examples provided for each experiment. arXiv admin note:
  text overlap with arXiv:2107.03374 by other authors",,,,cs.SE cs.AI cs.PL,http://creativecommons.org/licenses/by/4.0/,"  This paper explores the use of Large Language Models (LLMs) and in particular ChatGPT in programming, source code analysis, and code generation. LLMs and ChatGPT are built using machine learning and artificial intelligence techniques, and they offer several benefits to developers and programmers. While these models can save time and provide highly accurate results, they are not yet advanced enough to replace human programmers entirely. The paper investigates the potential applications of LLMs and ChatGPT in various areas, such as code creation, code documentation, bug detection, refactoring, and more. The paper also suggests that the usage of LLMs and ChatGPT is expected to increase in the future as they offer unparalleled benefits to the programming community. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 12:12:59 GMT'}, {'version': 'v2', 'created': 'Tue, 6 Jun 2023 09:49:36 GMT'}]",2023-06-12,"[['Sadik', 'Ahmed R.', ''], ['Ceravola', 'Antonello', ''], ['Joublin', 'Frank', ''], ['Patra', 'Jibesh', '']]",1,1,2023-06-01,2,4,3,1,0,1,4775ba882c4bddf9e7c656a12fcf78b674af439a,258999138.0,https://www.semanticscholar.org/paper/4775ba882c4bddf9e7c656a12fcf78b674af439a,arXiv.org,2023.0,16.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '39719279', 'name': 'Ahmed R. Sadik'}, {'authorId': '2832005', 'name': 'A. Ceravola'}, {'authorId': '1759554', 'name': 'F. Joublin'}, {'authorId': '1954023', 'name': 'Jibesh Patra'}]",['Honda Research Institute Europe'],['Germany'],2023-06
2306.00665,Francois Remy,"Fran\c{c}ois Remy, Thomas Demeester",Automatic Glossary of Clinical Terminology: a Large-Scale Dictionary of Biomedical Definitions Generated from Ontological Knowledge,Accepted at the BioNLP 2023 workshop,,,,cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  Background: More than 400,000 biomedical concepts and some of their relationships are contained in SnomedCT, a comprehensive biomedical ontology. However, their concept names are not always readily interpretable by non-experts, or patients looking at their own electronic health records (EHR). Clear definitions or descriptions in understandable language are often not available. Therefore, generating human-readable definitions for biomedical concepts might help make the information they encode more accessible and understandable to a wider public.   Objective: In this article, we introduce the Automatic Glossary of Clinical Terminology (AGCT), a large-scale biomedical dictionary of clinical concepts generated using high-quality information extracted from the biomedical knowledge contained in SnomedCT.   Methods: We generate a novel definition for every SnomedCT concept, after prompting the OpenAI Turbo model, a variant of GPT 3.5, using a high-quality verbalization of the SnomedCT relationships of the to-be-defined concept. A significant subset of the generated definitions was subsequently judged by NLP researchers with biomedical expertise on 5-point scales along the following three axes: factuality, insight, and fluency.   Results: AGCT contains 422,070 computer-generated definitions for SnomedCT concepts, covering various domains such as diseases, procedures, drugs, and anatomy. The average length of the definitions is 49 words. The definitions were assigned average scores of over 4.5 out of 5 on all three axes, indicating a majority of factual, insightful, and fluent definitions.   Conclusion: AGCT is a novel and valuable resource for biomedical tasks that require human-readable definitions for SnomedCT concepts. It can also serve as a base for developing robust biomedical retrieval models or other applications that leverage natural language understanding of biomedical knowledge. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 13:37:55 GMT'}]",2023-06-02,"[['Remy', 'François', ''], ['Demeester', 'Thomas', '']]",0,1,2023-06-01,1,2,1,1,0,1,36b15e8c222b8e85458a464911b852f3e4beeabc,258999730.0,https://www.semanticscholar.org/paper/36b15e8c222b8e85458a464911b852f3e4beeabc,Workshop on Biomedical Natural Language Processing,2023.0,16.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2188652700', 'name': 'François Remy'}, {'authorId': '1388296896', 'name': 'Thomas Demeester'}]",['Ghent University'],['Belgium'],2023-06
2306.00724,Renato P. dos Santos,Renato P. dos Santos,"Enhancing Physics Learning with ChatGPT, Bing Chat, and Bard as Agents-to-Think-With: A Comparative Case Study",,,,,physics.ed-ph,http://creativecommons.org/licenses/by-sa/4.0/,"  The rise of AI has brought remarkable advancements in education, with AI models demonstrating their ability to analyse and provide instructive solutions to complex problems. This study compared and analysed the responses of four Generative AI-powered chatbots (GenAIbots) - ChatGPT-3.5, ChatGPT-4, Bing Chat, and Bard - within the constructivist theoretical framework. Using a single-case study methodology, interaction logs between the GenAIbots and a simulated student in Physics learning scenarios were analysed. The GenAIbots were presented with conceptually dense Physics problems to promote deep understanding. The qualitative analysis focused on tutor traits such as subject-matter knowledge, empathy, assessment emphasis, facilitation skills, and comprehension of the learning process. Findings showed that all GenAIbots functioned as agents-to-think-with, fostering critical thinking, problem-solving, and subject-matter knowledge. ChatGPT-4 stood out for demonstrating empathy and a deep understanding of the learning process. However, inconsistencies and shortcomings were observed, highlighting the need for human intervention in AI-assisted learning. In conclusion, while GenAIbots have limitations, their potential as agents-to-think-with in Physics education offers promising prospects for revolutionising instruction. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 14:24:21 GMT'}]",2023-06-02,"[['Santos', 'Renato P. dos', '']]",1,1,2023-06-01,1,1,1,1,0,1,7d8f8aed551401ebc17c26e0948f08835c53ac00,258999944.0,https://www.semanticscholar.org/paper/7d8f8aed551401ebc17c26e0948f08835c53ac00,Social Science Research Network,2023.0,61.0,5.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '143749184', 'name': 'R. P. D. Santos'}]",['Universidade Luterana do Brasil'],['Brazil'],2023-06
2306.00745,Keti Korini,"Keti Korini, Christian Bizer",Column Type Annotation using ChatGPT,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Column type annotation is the task of annotating the columns of a relational table with the semantic type of the values contained in each column. Column type annotation is an important pre-processing step for data search and data integration in the context of data lakes. State-of-the-art column type annotation methods either rely on matching table columns to properties of a knowledge graph or fine-tune pre-trained language models such as BERT for column type annotation. In this work, we take a different approach and explore using ChatGPT for column type annotation. We evaluate different prompt designs in zero- and few-shot settings and experiment with providing task definitions and detailed instructions to the model. We further implement a two-step table annotation pipeline which first determines the class of the entities described in the table and depending on this class asks ChatGPT to annotate columns using only the relevant subset of the overall vocabulary. Using instructions as well as the two-step pipeline, ChatGPT reaches F1 scores of over 85% in zero- and one-shot setups. To reach a similar F1 score a RoBERTa model needs to be fine-tuned with 356 examples. This comparison shows that ChatGPT is able deliver competitive results for the column type annotation task given no or only a minimal amount of task-specific demonstrations. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 14:40:52 GMT'}, {'version': 'v2', 'created': 'Sun, 30 Jul 2023 12:07:34 GMT'}]",2023-08-01,"[['Korini', 'Keti', ''], ['Bizer', 'Christian', '']]",1,1,2023-06-01,2,2,1,1,0,1,5651919e1d7704a4bc388a66b60b607b6990bfc3,258999580.0,https://www.semanticscholar.org/paper/5651919e1d7704a4bc388a66b60b607b6990bfc3,VLDB Workshops,2023.0,37.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2201336961', 'name': 'Keti Korini'}, {'authorId': '1729154', 'name': 'Christian Bizer'}]",['University of Mannheim'],['Germany'],2023-06
2306.00774,Silvia Terragni,"Silvia Terragni, Modestas Filipavicius, Nghia Khau, Bruna Guedes,
  Andr\'e Manso, Roland Mathis",In-Context Learning User Simulators for Task-Oriented Dialog Systems,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents a novel application of large language models in user simulation for task-oriented dialog systems, specifically focusing on an in-context learning approach. By harnessing the power of these models, the proposed approach generates diverse utterances based on user goals and limited dialog examples. Unlike traditional simulators, this method eliminates the need for labor-intensive rule definition or extensive annotated data, making it more efficient and accessible. Additionally, an error analysis of the interaction between the user simulator and dialog system uncovers common mistakes, providing valuable insights into areas that require improvement. Our implementation is available at https://github.com/telepathylabsai/prompt-based-user-simulator. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 15:06:11 GMT'}]",2023-06-02,"[['Terragni', 'Silvia', ''], ['Filipavicius', 'Modestas', ''], ['Khau', 'Nghia', ''], ['Guedes', 'Bruna', ''], ['Manso', 'André', ''], ['Mathis', 'Roland', '']]",0,0,2023-06-01,1,6,2,0,0,0,15fcd80193d1c446bc3d37fcc30f5475b9ebd5b0,258999410.0,https://www.semanticscholar.org/paper/15fcd80193d1c446bc3d37fcc30f5475b9ebd5b0,arXiv.org,2023.0,44.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1392653707', 'name': 'Silvia Terragni'}, {'authorId': '12821153', 'name': 'Modestas Filipavicius'}, {'authorId': '2187455173', 'name': 'Nghia Khau'}, {'authorId': '2187455164', 'name': 'Bruna Guedes'}, {'authorId': '2187455283', 'name': ""Andr'e Manso""}, {'authorId': '2187455262', 'name': 'Roland Mathis'}]",['University of Zurich'],['Switzerland'],2023-06
2306.00915,Jaan Aru,"Jaan Aru, Matthew Larkum, James M. Shine",The feasibility of artificial consciousness through the lens of neuroscience,,,,,q-bio.NC cs.AI cs.LG cs.RO,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Interactions with large language models have led to the suggestion that these models may soon be conscious. From the perspective of neuroscience, this position is difficult to defend. For one, the inputs to large language models lack the embodied, embedded information content characteristic of our sensory contact with the world around us. Secondly, the architecture of large language models is missing key features of the thalamocortical system that have been linked to conscious awareness in mammals. Finally, the evolutionary and developmental trajectories that led to the emergence of living conscious organisms arguably have no parallels in artificial systems as envisioned today. The existence of living organisms depends on their actions, and their survival is intricately linked to multi-level cellular, inter-cellular, and organismal processes culminating in agency and consciousness. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 17:18:15 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Jun 2023 12:13:59 GMT'}, {'version': 'v3', 'created': 'Mon, 28 Aug 2023 16:36:31 GMT'}]",2023-08-29,"[['Aru', 'Jaan', ''], ['Larkum', 'Matthew', ''], ['Shine', 'James M.', '']]",0,0,2023-06-01,3,3,4,0,0,0,b2cad5ae3b2c7a9d90c2050cf37402b01725446a,258999584.0,https://www.semanticscholar.org/paper/b2cad5ae3b2c7a9d90c2050cf37402b01725446a,Trends in Neurosciences,2023.0,119.0,2.0,0.0,True,"['Biology', 'Computer Science', 'Medicine']","[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '2075928', 'name': 'Jaan Aru'}, {'authorId': '2746867', 'name': 'M. Larkum'}, {'authorId': '48815577', 'name': 'J. Shine'}]","['Humboldt-Universität zu Berlin', 'University of Sydney', 'University of Tartu']","['Germany', 'Estonia', 'Australia']",2023-06
2306.01169,Guang Lu,"Guang Lu, Sylvia B. Larcher, Tu Tran",Hybrid Long Document Summarization using C2F-FAR and ChatGPT: A Practical Study,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Text summarization is a downstream natural language processing (NLP) task that challenges the understanding and generation capabilities of language models. Considerable progress has been made in automatically summarizing short texts, such as news articles, often leading to satisfactory results. However, summarizing long documents remains a major challenge. This is due to the complex contextual information in the text and the lack of open-source benchmarking datasets and evaluation frameworks that can be used to develop and test model performance. In this work, we use ChatGPT, the latest breakthrough in the field of large language models (LLMs), together with the extractive summarization model C2F-FAR (Coarse-to-Fine Facet-Aware Ranking) to propose a hybrid extraction and summarization pipeline for long documents such as business articles and books. We work with the world-renowned company getAbstract AG and leverage their expertise and experience in professional book summarization. A practical study has shown that machine-generated summaries can perform at least as well as human-written summaries when evaluated using current automated evaluation metrics. However, a closer examination of the texts generated by ChatGPT through human evaluations has shown that there are still critical issues in terms of text coherence, faithfulness, and style. Overall, our results show that the use of ChatGPT is a very promising but not yet mature approach for summarizing long documents and can at best serve as an inspiration for human editors. We anticipate that our work will inform NLP researchers about the extent to which ChatGPT's capabilities for summarizing long documents overlap with practitioners' needs. Further work is needed to test the proposed hybrid summarization pipeline, in particular involving GPT-4, and to propose a new evaluation framework tailored to the task of summarizing long documents. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 21:58:33 GMT'}]",2023-06-05,"[['Lu', 'Guang', ''], ['Larcher', 'Sylvia B.', ''], ['Tran', 'Tu', '']]",1,1,2023-06-01,1,3,1,2,0,2,96b25fe7054b2390c3ea96c5f00046dd8e7c2452,259064158.0,https://www.semanticscholar.org/paper/96b25fe7054b2390c3ea96c5f00046dd8e7c2452,arXiv.org,2023.0,58.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153669294', 'name': 'Guang Lu'}, {'authorId': '2218794911', 'name': 'Sylvia B. Larcher'}, {'authorId': '2072581674', 'name': 'Tu-Anh Tran'}]","['getAbstract AG Alpenquai 12, 6005 Lucerne, Switzerland', 'Lucerne University of Applied Sciences and Arts']",['Switzerland'],2023-06
2306.01208,Rao Ma,"Rao Ma, Mengjie Qian, Mark J. F. Gales, Kate M. Knill",Adapting an Unadaptable ASR System,submitted to INTERSPEECH,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As speech recognition model sizes and training data requirements grow, it is increasingly common for systems to only be available via APIs from online service providers rather than having direct access to models themselves. In this scenario it is challenging to adapt systems to a specific target domain. To address this problem we consider the recently released OpenAI Whisper ASR as an example of a large-scale ASR system to assess adaptation methods. An error correction based approach is adopted, as this does not require access to the model, but can be trained from either 1-best or N-best outputs that are normally available via the ASR API. LibriSpeech is used as the primary target domain for adaptation. The generalization ability of the system in two distinct dimensions are then evaluated. First, whether the form of correction model is portable to other speech recognition domains, and secondly whether it can be used for ASR models having a different architecture. ","[{'version': 'v1', 'created': 'Thu, 1 Jun 2023 23:54:11 GMT'}]",2023-06-05,"[['Ma', 'Rao', ''], ['Qian', 'Mengjie', ''], ['Gales', 'Mark J. F.', ''], ['Knill', 'Kate M.', '']]",0,0,2023-06-01,1,4,3,0,0,0,6137cff058ee8d34b45839ddd228b042c9c2a072,259063905.0,https://www.semanticscholar.org/paper/6137cff058ee8d34b45839ddd228b042c9c2a072,Interspeech,2023.0,33.0,2.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50397234', 'name': 'Rao Ma'}, {'authorId': '10769548', 'name': 'Mengjie Qian'}, {'authorId': '1740397', 'name': 'M. Gales'}, {'authorId': '145962472', 'name': 'K. Knill'}]",['University of Cambridge'],['United Kingdom'],2023-06
2306.01248,Saptarshi Ghosh Dr.,"Aniket Deroy, Kripabandhu Ghosh, Saptarshi Ghosh",How Ready are Pre-trained Abstractive Models and LLMs for Legal Case Judgement Summarization?,"Accepted for presentation at the 3rd Workshop on Artificial
  Intelligence and Intelligent Assistance for Legal Professionals in the
  Digital Workplace (LegalAIIA 2023), co-located with the ICAIL 2023 conference",,,,cs.CL cs.IR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic summarization of legal case judgements has traditionally been attempted by using extractive summarization methods. However, in recent years, abstractive summarization models are gaining popularity since they can generate more natural and coherent summaries. Legal domain-specific pre-trained abstractive summarization models are now available. Moreover, general-domain pre-trained Large Language Models (LLMs), such as ChatGPT, are known to generate high-quality text and have the capacity for text summarization. Hence it is natural to ask if these models are ready for off-the-shelf application to automatically generate abstractive summaries for case judgements. To explore this question, we apply several state-of-the-art domain-specific abstractive summarization models and general-domain LLMs on Indian court case judgements, and check the quality of the generated summaries. In addition to standard metrics for summary quality, we check for inconsistencies and hallucinations in the summaries. We see that abstractive summarization models generally achieve slightly higher scores than extractive models in terms of standard summary evaluation metrics such as ROUGE and BLEU. However, we often find inconsistent or hallucinated information in the generated abstractive summaries. Overall, our investigation indicates that the pre-trained abstractive summarization models and LLMs are not yet ready for fully automatic deployment for case judgement summarization; rather a human-in-the-loop approach including manual checks for inconsistencies is more suitable at present. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 03:16:19 GMT'}, {'version': 'v2', 'created': 'Wed, 14 Jun 2023 07:25:42 GMT'}]",2023-06-16,"[['Deroy', 'Aniket', ''], ['Ghosh', 'Kripabandhu', ''], ['Ghosh', 'Saptarshi', '']]",1,1,2023-06-02,2,3,3,1,0,1,8835de81a3b18971eb7495ca32f71c10d7b8e367,259064225.0,https://www.semanticscholar.org/paper/8835de81a3b18971eb7495ca32f71c10d7b8e367,LegalAIIA@ICAIL,2023.0,25.0,11.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2144085844', 'name': 'Aniket Deroy'}, {'authorId': '153408379', 'name': 'Kripabandhu Ghosh'}, {'authorId': '2143032900', 'name': 'Saptarshi Ghosh'}]","['Indian Institute of Science Education and Research Kolkata', 'Indian Institute of Technology Kharagpur']",['India'],2023-06
2306.01386,Michael Heck,"Michael Heck, Nurul Lubis, Benjamin Ruppik, Renato Vukovic, Shutong
  Feng, Christian Geishauser, Hsien-Chin Lin, Carel van Niekerk, Milica
  Ga\v{s}i\'c",ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an Opportunity?,"13 pages, 3 figures, accepted at ACL 2023",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent research on dialogue state tracking (DST) focuses on methods that allow few- and zero-shot transfer to new domains or schemas. However, performance gains heavily depend on aggressive data augmentation and fine-tuning of ever larger language model based architectures. In contrast, general purpose language models, trained on large amounts of diverse data, hold the promise of solving any kind of task without task-specific training. We present preliminary experimental results on the ChatGPT research preview, showing that ChatGPT achieves state-of-the-art performance in zero-shot DST. Despite our findings, we argue that properties inherent to general purpose models limit their ability to replace specialized systems. We further theorize that the in-context learning capabilities of such models will likely become powerful tools to support the development of dedicated and dynamic dialogue state trackers. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 09:15:01 GMT'}]",2023-06-05,"[['Heck', 'Michael', ''], ['Lubis', 'Nurul', ''], ['Ruppik', 'Benjamin', ''], ['Vukovic', 'Renato', ''], ['Feng', 'Shutong', ''], ['Geishauser', 'Christian', ''], ['Lin', 'Hsien-Chin', ''], ['van Niekerk', 'Carel', ''], ['Gašić', 'Milica', '']]",1,1,2023-06-02,1,9,2,1,0,1,214fbadc57e954e325dc055fee5ac0e224dfde11,259063822.0,https://www.semanticscholar.org/paper/214fbadc57e954e325dc055fee5ac0e224dfde11,Annual Meeting of the Association for Computational Linguistics,2023.0,46.0,11.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '113469882', 'name': 'Michael Heck'}, {'authorId': '143604111', 'name': 'Nurul Lubis'}, {'authorId': '1666232939', 'name': 'Benjamin Matthias Ruppik'}, {'authorId': '2182290500', 'name': 'Renato Vukovic'}, {'authorId': '2113511651', 'name': 'Shutong Feng'}, {'authorId': '1676966139', 'name': 'Christian Geishauser'}, {'authorId': '2116102483', 'name': 'Hsien-chin Lin'}, {'authorId': '113869710', 'name': 'Carel van Niekerk'}, {'authorId': '1676892968', 'name': ""Milica Gavsi'c""}]",['Heinrich Heine University Düsseldorf'],['Germany'],2023-06
2306.01579,Hsien-Chin Lin,"Hsien-Chin Lin, Shutong Feng, Christian Geishauser, Nurul Lubis, Carel
  van Niekerk, Michael Heck, Benjamin Ruppik, Renato Vukovic, Milica
  Ga\v{s}i\'c",EmoUS: Simulating User Emotions in Task-Oriented Dialogues,accepted by SIGIR2023,,10.1145/3539618.3592092,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Existing user simulators (USs) for task-oriented dialogue systems only model user behaviour on semantic and natural language levels without considering the user persona and emotions. Optimising dialogue systems with generic user policies, which cannot model diverse user behaviour driven by different emotional states, may result in a high drop-off rate when deployed in the real world. Thus, we present EmoUS, a user simulator that learns to simulate user emotions alongside user behaviour. EmoUS generates user emotions, semantic actions, and natural language responses based on the user goal, the dialogue history, and the user persona. By analysing what kind of system behaviour elicits what kind of user emotions, we show that EmoUS can be used as a probe to evaluate a variety of dialogue systems and in particular their effect on the user's emotional state. Developing such methods is important in the age of large language model chat-bots and rising ethical concerns. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 14:48:19 GMT'}]",2023-06-05,"[['Lin', 'Hsien-Chin', ''], ['Feng', 'Shutong', ''], ['Geishauser', 'Christian', ''], ['Lubis', 'Nurul', ''], ['van Niekerk', 'Carel', ''], ['Heck', 'Michael', ''], ['Ruppik', 'Benjamin', ''], ['Vukovic', 'Renato', ''], ['Gašić', 'Milica', '']]",0,0,2023-06-02,1,9,1,0,0,0,97ea4e0d9fd7af3387f3119bd58f891720511a85,259063909.0,https://www.semanticscholar.org/paper/97ea4e0d9fd7af3387f3119bd58f891720511a85,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,41.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2116102483', 'name': 'Hsien-chin Lin'}, {'authorId': '2113511651', 'name': 'Shutong Feng'}, {'authorId': '1676966139', 'name': 'Christian Geishauser'}, {'authorId': '143604111', 'name': 'Nurul Lubis'}, {'authorId': '113869710', 'name': 'Carel van Niekerk'}, {'authorId': '113469882', 'name': 'Michael Heck'}, {'authorId': '1666232939', 'name': 'Benjamin Matthias Ruppik'}, {'authorId': '2182290500', 'name': 'Renato Vukovic'}, {'authorId': '1676892968', 'name': ""Milica Gavsi'c""}]",['Heinrich Heine University Düsseldorf'],['Germany'],2023-06
2306.01685,Mohammad Mozaffari,"Mohammad Mozaffari, Sikan Li, Zhao Zhang, Maryam Mehri Dehnavi",MKOR: Momentum-Enabled Kronecker-Factor-Based Optimizer Using Rank-1 Updates,,,,,cs.LG cs.AI cs.CV math.OC,http://creativecommons.org/licenses/by/4.0/,"  This work proposes a Momentum-Enabled Kronecker-Factor-Based Optimizer Using Rank-1 updates, called MKOR, that improves the training time and convergence properties of deep neural networks (DNNs). Second-order techniques, while enjoying higher convergence rates vs first-order counterparts, have cubic complexity with respect to either the model size and/or the training batch size. Hence they exhibit poor scalability and performance in transformer models, e.g. large language models (LLMs), because the batch sizes in these models scale by the attention mechanism sequence length, leading to large model size and batch sizes. MKOR's complexity is quadratic with respect to the model size, alleviating the computation bottlenecks in second-order methods. Because of their high computation complexity, state-of-the-art implementations of second-order methods can only afford to update the second order information infrequently, and thus do not fully exploit the promise of better convergence from these updates. By reducing the communication complexity of the second-order updates as well as achieving a linear communication complexity, MKOR increases the frequency of second order updates. We also propose a hybrid version of MKOR (called MKOR-H) that mid-training falls backs to a first order optimizer if the second order updates no longer accelerate convergence. Our experiments show that MKOR outperforms state -of-the-art first order methods, e.g. the LAMB optimizer, and best implementations of second-order methods, i.e. KAISA/KFAC, up to 2.57x and 1.85x respectively on BERT-Large-Uncased on 64 GPUs. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 17:00:19 GMT'}]",2023-06-05,"[['Mozaffari', 'Mohammad', ''], ['Li', 'Sikan', ''], ['Zhang', 'Zhao', ''], ['Dehnavi', 'Maryam Mehri', '']]",0,0,2023-06-02,1,4,4,0,0,0,2b1c86705e329e80cac96b6bf5df353d079ff10b,259064163.0,https://www.semanticscholar.org/paper/2b1c86705e329e80cac96b6bf5df353d079ff10b,arXiv.org,2023.0,32.0,1.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '38927377', 'name': 'M. Mozaffari'}, {'authorId': '2155993249', 'name': 'Sikan Li'}, {'authorId': '2156122736', 'name': 'Zhao Zhang'}, {'authorId': '2917750', 'name': 'M. Dehnavi'}]",['University of Toronto'],['Canada'],2023-06
2306.01761,Niful Islam,"Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin Tasnim Raya,
  Monowara Tabassum Maisha, Dewan Md Farid",Distinguishing Human Generated Text From ChatGPT Generated Text Using Machine Learning,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT is a conversational artificial intelligence that is a member of the generative pre-trained transformer of the large language model family. This text generative model was fine-tuned by both supervised learning and reinforcement learning so that it can produce text documents that seem to be written by natural intelligence. Although there are numerous advantages of this generative model, it comes with some reasonable concerns as well. This paper presents a machine learning-based solution that can identify the ChatGPT delivered text from the human written text along with the comparative analysis of a total of 11 machine learning and deep learning algorithms in the classification process. We have tested the proposed model on a Kaggle dataset consisting of 10,000 texts out of which 5,204 texts were written by humans and collected from news and social media. On the corpus generated by GPT-3.5, the proposed algorithm presents an accuracy of 77%. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 09:27:43 GMT'}]",2023-06-06,"[['Islam', 'Niful', ''], ['Sutradhar', 'Debopom', ''], ['Noor', 'Humaira', ''], ['Raya', 'Jarin Tasnim', ''], ['Maisha', 'Monowara Tabassum', ''], ['Farid', 'Dewan Md', '']]",1,1,2023-05-26,1,6,3,2,0,2,56d3d9aa983876102931e6b0f2b61afa90677731,259075804.0,https://www.semanticscholar.org/paper/56d3d9aa983876102931e6b0f2b61afa90677731,arXiv.org,2023.0,27.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2214769892', 'name': 'Niful Islam'}, {'authorId': '2219549743', 'name': 'Debopom Sutradhar'}, {'authorId': '72984822', 'name': 'Humaira Noor'}, {'authorId': '2219552496', 'name': 'Jarin Tasnim Raya'}, {'authorId': '2219562201', 'name': 'Monowara Tabassum Maisha'}, {'authorId': '1771095', 'name': 'D. Farid'}]","['University of Asia Pacific', 'United International University']",['Bangladesh'],2023-05
2306.01771,Amin Beheshti,"Amin Beheshti, Jian Yang, Quan Z. Sheng, Boualem Benatallah, Fabio
  Casati, Schahram Dustdar, Hamid Reza Motahari Nezhad, Xuyun Zhang, Shan Xue",ProcessGPT: Transforming Business Process Management with Generative Artificial Intelligence,"Accepted in: 2023 IEEE International Conference on Web Services
  (ICWS); Corresponding author: Prof. Amin Beheshti (amin.beheshti@mq.edu.au)",,,,cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Generative Pre-trained Transformer (GPT) is a state-of-the-art machine learning model capable of generating human-like text through natural language processing (NLP). GPT is trained on massive amounts of text data and uses deep learning techniques to learn patterns and relationships within the data, enabling it to generate coherent and contextually appropriate text. This position paper proposes using GPT technology to generate new process models when/if needed. We introduce ProcessGPT as a new technology that has the potential to enhance decision-making in data-centric and knowledge-intensive processes. ProcessGPT can be designed by training a generative pre-trained transformer model on a large dataset of business process data. This model can then be fine-tuned on specific process domains and trained to generate process flows and make decisions based on context and user input. The model can be integrated with NLP and machine learning techniques to provide insights and recommendations for process improvement. Furthermore, the model can automate repetitive tasks and improve process efficiency while enabling knowledge workers to communicate analysis findings, supporting evidence, and make decisions. ProcessGPT can revolutionize business process management (BPM) by offering a powerful tool for process augmentation, automation and improvement. Finally, we demonstrate how ProcessGPT can be a powerful tool for augmenting data engineers in maintaining data ecosystem processes within large bank organizations. Our scenario highlights the potential of this approach to improve efficiency, reduce costs, and enhance the quality of business operations through the automation of data-centric and knowledge-intensive processes. These results underscore the promise of ProcessGPT as a transformative technology for organizations looking to improve their process workflows. ","[{'version': 'v1', 'created': 'Mon, 29 May 2023 02:27:46 GMT'}]",2023-06-06,"[['Beheshti', 'Amin', ''], ['Yang', 'Jian', ''], ['Sheng', 'Quan Z.', ''], ['Benatallah', 'Boualem', ''], ['Casati', 'Fabio', ''], ['Dustdar', 'Schahram', ''], ['Nezhad', 'Hamid Reza Motahari', ''], ['Zhang', 'Xuyun', ''], ['Xue', 'Shan', '']]",0,1,2023-05-29,1,9,1,0,0,0,d4d108b8b6a017cc51972d114773e2d4f49c9692,259076468.0,https://www.semanticscholar.org/paper/d4d108b8b6a017cc51972d114773e2d4f49c9692,2023 IEEE International Conference on Web Services (ICWS),2023.0,21.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '24901061', 'name': 'A. Beheshti'}, {'authorId': '40243319', 'name': 'Jian Yang'}, {'authorId': '120607997', 'name': 'Quan.Z Sheng'}, {'authorId': '1734279', 'name': 'B. Benatallah'}, {'authorId': '145866446', 'name': 'F. Casati'}, {'authorId': '1691109', 'name': 'S. Dustdar'}, {'authorId': '7191589', 'name': 'H. M. Nezhad'}, {'authorId': '1992681025', 'name': 'Xuyun Zhang'}, {'authorId': '2057237074', 'name': 'Shan Xue'}]","['Dublin City University', 'Macquarie University', 'TU Wien']","['Ireland', 'Austria', 'Australia']",2023-05
2306.01857,Aida Ramezani,"Aida Ramezani, Yang Xu",Knowledge of cultural moral norms in large language models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Moral norms vary across cultures. A recent line of work suggests that English large language models contain human-like moral biases, but these studies typically do not examine moral variation in a diverse cultural setting. We investigate the extent to which monolingual English language models contain knowledge about moral norms in different countries. We consider two levels of analysis: 1) whether language models capture fine-grained moral variation across countries over a variety of topics such as ``homosexuality'' and ``divorce''; 2) whether language models capture cultural diversity and shared tendencies in which topics people around the globe tend to diverge or agree on in their moral judgment. We perform our analyses with two public datasets from the World Values Survey (across 55 countries) and PEW global surveys (across 40 countries) on morality. We find that pre-trained English language models predict empirical moral norms across countries worse than the English moral norms reported previously. However, fine-tuning language models on the survey data improves inference across countries at the expense of a less accurate estimate of the English moral norms. We discuss the relevance and challenges of incorporating cultural knowledge into the automated inference of moral norms. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 18:23:35 GMT'}]",2023-06-06,"[['Ramezani', 'Aida', ''], ['Xu', 'Yang', '']]",0,0,2023-06-02,1,2,1,0,0,0,8ea24b1dbb3e690ebc64543c03f0552a6c1fb49d,259075607.0,https://www.semanticscholar.org/paper/8ea24b1dbb3e690ebc64543c03f0552a6c1fb49d,Annual Meeting of the Association for Computational Linguistics,2023.0,45.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2125381154', 'name': 'Aida Ramezani'}, {'authorId': '1698958205', 'name': 'Yang Xu'}]",['University of Toronto'],['Canada'],2023-06
2306.01872,Mengjiao Yang,"Mengjiao Yang, Yilun Du, Bo Dai, Dale Schuurmans, Joshua B. Tenenbaum,
  Pieter Abbeel",Probabilistic Adaptation of Text-to-Video Models,"Project website https://video-adapter.github.io/. First two authors
  contributed equally",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large text-to-video models trained on internet-scale data have demonstrated exceptional capabilities in generating high-fidelity videos from arbitrary textual descriptions. However, adapting these models to tasks with limited domain-specific data, such as animation or robotics videos, poses a significant computational challenge, since finetuning a pretrained large model can be prohibitively expensive. Inspired by how a small modifiable component (e.g., prompts, prefix-tuning) can adapt a large language model to perform new tasks without requiring access to the model weights, we investigate how to adapt a large pretrained text-to-video model to a variety of downstream domains and tasks without finetuning. In answering this question, we propose Video Adapter, which leverages the score function of a large pretrained video diffusion model as a probabilistic prior to guide the generation of a task-specific small video model. Our experiments show that Video Adapter is capable of incorporating the broad knowledge and preserving the high fidelity of a large pretrained video model in a task-specific small video model that is able to generate high-quality yet specialized videos on a variety of tasks such as animation, egocentric modeling, and modeling of simulated and real-world robotics data. More videos can be found on the website https://video-adapter.github.io/. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 19:00:17 GMT'}]",2023-06-06,"[['Yang', 'Mengjiao', ''], ['Du', 'Yilun', ''], ['Dai', 'Bo', ''], ['Schuurmans', 'Dale', ''], ['Tenenbaum', 'Joshua B.', ''], ['Abbeel', 'Pieter', '']]",0,0,2023-06-02,1,6,1,0,0,0,7820f9e98c9d064a0402685be2cf875a916edd27,259075709.0,https://www.semanticscholar.org/paper/7820f9e98c9d064a0402685be2cf875a916edd27,arXiv.org,2023.0,69.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2111076891', 'name': 'Mengjiao Yang'}, {'authorId': '15394275', 'name': 'Yilun Du'}, {'authorId': '144445937', 'name': 'Bo Dai'}, {'authorId': '50319359', 'name': 'D. Schuurmans'}, {'authorId': '1763295', 'name': 'J. Tenenbaum'}, {'authorId': '1689992', 'name': 'P. Abbeel'}]",['University of Alberta'],['Canada'],2023-06
2306.01941,Q.Vera Liao,Q. Vera Liao and Jennifer Wortman Vaughan,AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap,,,,,cs.HC cs.AI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The rise of powerful large language models (LLMs) brings about tremendous opportunities for innovation but also looming risks for individuals and society at large. We have reached a pivotal moment for ensuring that LLMs and LLM-infused applications are developed and deployed responsibly. However, a central pillar of responsible AI -- transparency -- is largely missing from the current discourse around LLMs. It is paramount to pursue new approaches to provide transparency for LLMs, and years of research at the intersection of AI and human-computer interaction (HCI) highlight that we must do so with a human-centered perspective: Transparency is fundamentally about supporting appropriate human understanding, and this understanding is sought by different stakeholders with different goals in different contexts. In this new era of LLMs, we must develop and design approaches to transparency by considering the needs of stakeholders in the emerging LLM ecosystem, the novel types of LLM-infused applications being built, and the new usage patterns and challenges around LLMs, all while building on lessons learned about how people process, interact with, and make use of information. We reflect on the unique challenges that arise in providing transparency for LLMs, along with lessons learned from HCI and responsible AI research that has taken a human-centered perspective on AI transparency. We then lay out four common approaches that the community has taken to achieve transparency -- model reporting, publishing evaluation results, providing explanations, and communicating uncertainty -- and call out open questions around how these approaches may or may not be applied to LLMs. We hope this provides a starting point for discussion and a useful roadmap for future research. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 22:51:26 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Aug 2023 01:41:22 GMT'}]",2023-08-09,"[['Liao', 'Q. Vera', ''], ['Vaughan', 'Jennifer Wortman', '']]",0,0,2023-06-02,2,2,3,0,0,0,3dcf2db20082b480c6c091eea025465cc4fe57a6,259075521.0,https://www.semanticscholar.org/paper/3dcf2db20082b480c6c091eea025465cc4fe57a6,arXiv.org,2023.0,208.0,14.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144921048', 'name': 'Q. Liao'}, {'authorId': '144950416', 'name': 'J. Vaughan'}]",['Microsoft'],['India'],2023-06
2306.01942,Guangzhi Sun,"Guangzhi Sun, Xianrui Zheng, Chao Zhang, Philip C. Woodland",Can Contextual Biasing Remain Effective with Whisper and GPT-2?,To appear in Interspeech 2023,,,,cs.CL cs.SD eess.AS,http://creativecommons.org/licenses/by/4.0/,"  End-to-end automatic speech recognition (ASR) and large language models, such as Whisper and GPT-2, have recently been scaled to use vast amounts of training data. Despite the large amount of training data, infrequent content words that occur in a particular task may still exhibit poor ASR performance, with contextual biasing a possible remedy. This paper investigates the effectiveness of neural contextual biasing for Whisper combined with GPT-2. Specifically, this paper proposes integrating an adapted tree-constrained pointer generator (TCPGen) component for Whisper and a dedicated training scheme to dynamically adjust the final output without modifying any Whisper model parameters. Experiments across three datasets show a considerable reduction in errors on biasing words with a biasing list of 1000 words. Contextual biasing was more effective when applied to domain-specific data and can boost the performance of Whisper and GPT-2 without losing their generality. ","[{'version': 'v1', 'created': 'Fri, 2 Jun 2023 22:56:01 GMT'}]",2023-06-06,"[['Sun', 'Guangzhi', ''], ['Zheng', 'Xianrui', ''], ['Zhang', 'Chao', ''], ['Woodland', 'Philip C.', '']]",0,1,2023-06-02,1,4,3,1,1,0,44c05783a548cd91110d901eb51b2b529c4b4fbc,259075553.0,https://www.semanticscholar.org/paper/44c05783a548cd91110d901eb51b2b529c4b4fbc,Interspeech,2023.0,25.0,2.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2107310187', 'name': 'Guangzhi Sun'}, {'authorId': '2152197497', 'name': 'Xianrui Zheng'}, {'authorId': '50445747', 'name': 'C. Zhang'}, {'authorId': '1716393', 'name': 'P. Woodland'}]",['University of Cambridge'],['United Kingdom'],2023-06
2306.01987,Sidong Feng,"Sidong Feng, Chunyang Chen",Prompting Is All You Need: Automated Android Bug Replay with Large Language Models,"Accepted to 46th International Conference on Software Engineering
  (ICSE 2024)",,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Bug reports are vital for software maintenance that allow users to inform developers of the problems encountered while using the software. As such, researchers have committed considerable resources toward automating bug replay to expedite the process of software maintenance. Nonetheless, the success of current automated approaches is largely dictated by the characteristics and quality of bug reports, as they are constrained by the limitations of manually-crafted patterns and pre-defined vocabulary lists. Inspired by the success of Large Language Models (LLMs) in natural language understanding, we propose AdbGPT, a new lightweight approach to automatically reproduce the bugs from bug reports through prompt engineering, without any training and hard-coding effort. AdbGPT leverages few-shot learning and chain-of-thought reasoning to elicit human knowledge and logical reasoning from LLMs to accomplish the bug replay in a manner similar to a developer. Our evaluations demonstrate the effectiveness and efficiency of our AdbGPT to reproduce 81.3% of bug reports in 253.6 seconds, outperforming the state-of-the-art baselines and ablation studies. We also conduct a small-scale user study to confirm the usefulness of AdbGPT in enhancing developers' bug replay capabilities. ","[{'version': 'v1', 'created': 'Sat, 3 Jun 2023 03:03:52 GMT'}, {'version': 'v2', 'created': 'Tue, 18 Jul 2023 06:20:51 GMT'}]",2023-07-19,"[['Feng', 'Sidong', ''], ['Chen', 'Chunyang', '']]",0,1,2023-06-03,2,2,1,0,0,0,48385ded07af641da331c05f6ea3f93694a08425,259950715.0,https://www.semanticscholar.org/paper/48385ded07af641da331c05f6ea3f93694a08425,,2023.0,84.0,6.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1406333777', 'name': 'Sidong Feng'}, {'authorId': '46729152', 'name': 'Chunyang Chen'}]",['Monash University'],['Australia'],2023-06
2306.02077,Georgios Peikos,"Georgios Peikos, Symeon Symeonidis, Pranav Kasela, Gabriella Pasi",Utilizing ChatGPT to Enhance Clinical Trial Enrollment,Under Review,,,,cs.IR cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Clinical trials are a critical component of evaluating the effectiveness of new medical interventions and driving advancements in medical research. Therefore, timely enrollment of patients is crucial to prevent delays or premature termination of trials. In this context, Electronic Health Records (EHRs) have emerged as a valuable tool for identifying and enrolling eligible participants. In this study, we propose an automated approach that leverages ChatGPT, a large language model, to extract patient-related information from unstructured clinical notes and generate search queries for retrieving potentially eligible clinical trials. Our empirical evaluation, conducted on two benchmark retrieval collections, shows improved retrieval performance compared to existing approaches when several general-purposed and task-specific prompts are used. Notably, ChatGPT-generated queries also outperform human-generated queries in terms of retrieval performance. These findings highlight the potential use of ChatGPT to enhance clinical trial enrollment while ensuring the quality of medical service and minimizing direct risks to patients. ","[{'version': 'v1', 'created': 'Sat, 3 Jun 2023 10:54:23 GMT'}]",2023-06-12,"[['Peikos', 'Georgios', ''], ['Symeonidis', 'Symeon', ''], ['Kasela', 'Pranav', ''], ['Pasi', 'Gabriella', '']]",1,1,2023-06-03,1,4,2,1,0,1,362d4e00506f9bb39d42185a0b128f8602e139a8,259075335.0,https://www.semanticscholar.org/paper/362d4e00506f9bb39d42185a0b128f8602e139a8,arXiv.org,2023.0,108.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '46227908', 'name': 'Georgios Peikos'}, {'authorId': '2194711', 'name': 'S. Symeonidis'}, {'authorId': '2187856026', 'name': 'Pranav Kasela'}, {'authorId': '2065794132', 'name': 'G. Pasi'}]","['University of Milano-Bicocca', 'Democritus University of Thrace']","['Greece', 'Italy']",2023-06
2306.02207,Kai-Wei Chang,"Haibin Wu, Kai-Wei Chang, Yuan-Kuei Wu, Hung-yi Lee",SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts,Work in progress. The first three authors contributed equally,,,,eess.AS cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have gained considerable attention for Artificial Intelligence Generated Content (AIGC), particularly with the emergence of ChatGPT. However, the direct adaptation of continuous speech to LLMs that process discrete tokens remains an unsolved challenge, hindering the application of LLMs for speech generation. The advanced speech LMs are in the corner, as that speech signals encapsulate a wealth of information, including speaker and emotion, beyond textual data alone. Prompt tuning has demonstrated notable gains in parameter efficiency and competitive performance on some speech classification tasks. However, the extent to which prompts can effectively elicit generation tasks from speech LMs remains an open question. In this paper, we present pioneering research that explores the application of prompt tuning to stimulate speech LMs for various generation tasks, within a unified framework called SpeechGen, with around 10M trainable parameters. The proposed unified framework holds great promise for efficiency and effectiveness, particularly with the imminent arrival of advanced speech LMs, which will significantly enhance the capabilities of the framework. The code and demos of SpeechGen will be available on the project website: \url{https://ga642381.github.io/SpeechPrompt/speechgen} ","[{'version': 'v1', 'created': 'Sat, 3 Jun 2023 22:35:27 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Jun 2023 20:53:25 GMT'}, {'version': 'v3', 'created': 'Fri, 25 Aug 2023 16:10:18 GMT'}]",2023-08-28,"[['Wu', 'Haibin', ''], ['Chang', 'Kai-Wei', ''], ['Wu', 'Yuan-Kuei', ''], ['Lee', 'Hung-yi', '']]",1,1,2023-06-03,3,4,4,1,0,1,49f4ce7a3e5f060b4012a165cc4ab416e4b3fd0b,259075185.0,https://www.semanticscholar.org/paper/49f4ce7a3e5f060b4012a165cc4ab416e4b3fd0b,arXiv.org,2023.0,58.0,9.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1430766392', 'name': 'Haibin Wu'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}, {'authorId': '1452683427', 'name': 'Yuan-Kuei Wu'}, {'authorId': '1706104', 'name': 'Hung-yi Lee'}]",['National Taiwan University'],['Taiwan'],2023-06
2306.02258,Kazushi Kondo,"Kazushi Kondo, Saku Sugawara, Akiko Aizawa",Probing Physical Reasoning with Counter-Commonsense Context,Accepted to ACL 2023(Short Paper),,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this study, we create a CConS (Counter-commonsense Contextual Size comparison) dataset to investigate how physical commonsense affects the contextualized size comparison task; the proposed dataset consists of both contexts that fit physical commonsense and those that do not. This dataset tests the ability of language models to predict the size relationship between objects under various contexts generated from our curated noun list and templates. We measure the ability of several masked language models and generative models. The results show that while large language models can use prepositions such as ``in'' and ``into'' in the provided context to infer size relationships, they fail to use verbs and thus make incorrect judgments led by their prior physical commonsense. ","[{'version': 'v1', 'created': 'Sun, 4 Jun 2023 04:24:43 GMT'}]",2023-06-06,"[['Kondo', 'Kazushi', ''], ['Sugawara', 'Saku', ''], ['Aizawa', 'Akiko', '']]",0,0,2023-06-04,1,3,1,0,0,0,56267168c5f1cea5049c0f1724e39166988d32b7,259075832.0,https://www.semanticscholar.org/paper/56267168c5f1cea5049c0f1724e39166988d32b7,Annual Meeting of the Association for Computational Linguistics,2023.0,28.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219267106', 'name': 'Kazushi Kondo'}, {'authorId': '2673984', 'name': 'Saku Sugawara'}, {'authorId': '1705519', 'name': 'Akiko Aizawa'}]","['National Institute of Informatics', 'The University of Tokyo']",['Japan'],2023-06
2306.02272,Eunhyeok Park,"Changhun Lee, Jungyu Jin, Taesu Kim, Hyungjun Kim, Eunhyeok Park",OWQ: Lessons learned from activation outliers for weight quantization in large language models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) with hundreds of billions of parameters show impressive results across various language tasks using simple prompt tuning and few-shot examples, without the need for task-specific fine-tuning. However, their enormous size requires multiple server-grade GPUs even for inference, creating a significant cost barrier. To address this limitation, we introduce a novel post-training quantization method for weights with minimal quality degradation. While activation outliers are known to be problematic in activation quantization, our theoretical analysis suggests that we can identify factors contributing to weight quantization errors by considering activation outliers. We propose an innovative PTQ scheme called outlier-aware weight quantization (OWQ), which identifies vulnerable weights and allocates high-precision to them. Our extensive experiments demonstrate that the 3.01-bit models produced by OWQ exhibit comparable quality to the 4-bit models generated by OPTQ. ","[{'version': 'v1', 'created': 'Sun, 4 Jun 2023 06:33:13 GMT'}, {'version': 'v2', 'created': 'Tue, 13 Jun 2023 07:31:38 GMT'}]",2023-06-14,"[['Lee', 'Changhun', ''], ['Jin', 'Jungyu', ''], ['Kim', 'Taesu', ''], ['Kim', 'Hyungjun', ''], ['Park', 'Eunhyeok', '']]",0,0,2023-06-04,2,5,1,0,0,0,343d24c4dcfaff2132373d218561a23fbd53e934,259076427.0,https://www.semanticscholar.org/paper/343d24c4dcfaff2132373d218561a23fbd53e934,arXiv.org,2023.0,33.0,8.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2115470609', 'name': 'Changhun Lee'}, {'authorId': '2219667934', 'name': 'Jungyu Jin'}, {'authorId': '2115689933', 'name': 'Taesu Kim'}, {'authorId': '2218829555', 'name': 'Hyungjun Kim'}, {'authorId': '2292315', 'name': 'Eunhyeok Park'}]","['Pohang University of Science and Technology', 'SqueezeBits Inc.']",['South Korea'],2023-06
2306.02294,Lukas Pfahler,Celine Wald and Lukas Pfahler,Exposing Bias in Online Communities through Large-Scale Language Models,,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Progress in natural language generation research has been shaped by the ever-growing size of language models. While large language models pre-trained on web data can generate human-sounding text, they also reproduce social biases and contribute to the propagation of harmful stereotypes. This work utilises the flaw of bias in language models to explore the biases of six different online communities. In order to get an insight into the communities' viewpoints, we fine-tune GPT-Neo 1.3B with six social media datasets. The bias of the resulting models is evaluated by prompting the models with different demographics and comparing the sentiment and toxicity values of these generations. Together, these methods reveal that bias differs in type and intensity for the various models. This work not only affirms how easily bias is absorbed from training data but also presents a scalable method to identify and compare the bias of different datasets or communities. Additionally, the examples generated for this work demonstrate the limitations of using automated sentiment and toxicity classifiers in bias research. ","[{'version': 'v1', 'created': 'Sun, 4 Jun 2023 08:09:26 GMT'}]",2023-06-06,"[['Wald', 'Celine', ''], ['Pfahler', 'Lukas', '']]",0,1,2023-06-04,1,2,3,0,0,0,dab05c972fe4537e362b262b33dffc00de5f5311,259075978.0,https://www.semanticscholar.org/paper/dab05c972fe4537e362b262b33dffc00de5f5311,arXiv.org,2023.0,59.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219550842', 'name': 'Celine Wald'}, {'authorId': '32421394', 'name': 'Lukas Pfahler'}]",['TU Dortmund University'],['Germany'],2023-06
2306.02451,Scott Fujimoto,"Scott Fujimoto, Wei-Di Chang, Edward J. Smith, Shixiang Shane Gu,
  Doina Precup, David Meger",For SALE: State-Action Representation Learning for Deep Reinforcement Learning,,,,,cs.LG cs.AI stat.ML,http://creativecommons.org/licenses/by/4.0/,"  In the field of reinforcement learning (RL), representation learning is a proven tool for complex image-based tasks, but is often overlooked for environments with low-level states, such as physical control problems. This paper introduces SALE, a novel approach for learning embeddings that model the nuanced interaction between state and action, enabling effective representation learning from low-level states. We extensively study the design space of these embeddings and highlight important design considerations. We integrate SALE and an adaptation of checkpoints for RL into TD3 to form the TD7 algorithm, which significantly outperforms existing continuous control algorithms. On OpenAI gym benchmark tasks, TD7 has an average performance gain of 276.7% and 50.7% over TD3 at 300k and 5M time steps, respectively, and works in both the online and offline settings. ","[{'version': 'v1', 'created': 'Sun, 4 Jun 2023 19:47:46 GMT'}]",2023-06-06,"[['Fujimoto', 'Scott', ''], ['Chang', 'Wei-Di', ''], ['Smith', 'Edward J.', ''], ['Gu', 'Shixiang Shane', ''], ['Precup', 'Doina', ''], ['Meger', 'David', '']]",0,0,2023-06-04,1,6,3,0,0,0,487b7090af70989dde3a0e16bc5d014eb5dfd498,259075901.0,https://www.semanticscholar.org/paper/487b7090af70989dde3a0e16bc5d014eb5dfd498,arXiv.org,2023.0,80.0,2.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '14637819', 'name': 'Scott Fujimoto'}, {'authorId': '24064144', 'name': 'Wei-Di Chang'}, {'authorId': '143757896', 'name': 'Edward James Smith'}, {'authorId': '2046135', 'name': 'S. Gu'}, {'authorId': '144368601', 'name': 'Doina Precup'}, {'authorId': '2462512', 'name': 'D. Meger'}]",['McGill University'],['Canada'],2023-06
2306.02569,Fengzhu Zeng,Fengzhu Zeng and Wei Gao,Prompt to be Consistent is Better than Self-Consistent? Few-Shot and Zero-Shot Fact Verification with Pre-trained Language Models,Accepted as ACL 2023 Findings,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Few-shot or zero-shot fact verification only relies on a few or no labeled training examples. In this paper, we propose a novel method called ProToCo, to \underline{Pro}mpt pre-trained language models (PLMs) \underline{To} be \underline{Co}nsistent, for improving the factuality assessment capability of PLMs in the few-shot and zero-shot settings. Given a claim-evidence pair, ProToCo generates multiple variants of the claim with different relations and frames a simple consistency mechanism as constraints for making compatible predictions across these variants. We update PLMs by using parameter-efficient fine-tuning (PEFT), leading to more accurate predictions in few-shot and zero-shot fact verification tasks. Our experiments on three public verification datasets show that ProToCo significantly outperforms state-of-the-art few-shot fact verification baselines. With a small number of unlabeled instances, ProToCo also outperforms the strong zero-shot learner T0 on zero-shot verification. Compared to large PLMs using in-context learning (ICL) method, ProToCo outperforms OPT-30B and the Self-Consistency-enabled OPT-6.7B model in both few- and zero-shot settings. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 03:49:13 GMT'}]",2023-06-06,"[['Zeng', 'Fengzhu', ''], ['Gao', 'Wei', '']]",0,0,2023-06-05,1,2,1,2,2,0,3cebb93c399db7e1434741338b0a24db19786b15,259076388.0,https://www.semanticscholar.org/paper/3cebb93c399db7e1434741338b0a24db19786b15,Annual Meeting of the Association for Computational Linguistics,2023.0,55.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1490766549', 'name': 'Fengzhu Zeng'}, {'authorId': '2153576124', 'name': 'Wei Gao'}]",['Singapore Management University'],['Singapore'],2023-06
2306.02697,Viktoriia Chekalina,"Viktoriia Chekalina, Georgii Novikov, Julia Gusak, Ivan Oseledets,
  Alexander Panchenko",Efficient GPT Model Pre-training using Tensor Train Matrix Representation,,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large-scale transformer models have shown remarkable performance in language modelling tasks. However, such models feature billions of parameters, leading to difficulties in their deployment and prohibitive training costs from scratch. To reduce the number of the parameters in the GPT-2 architecture, we replace the matrices of fully-connected layers with the corresponding Tensor Train Matrix~(TTM) structure. Finally, we customize forward and backward operations through the TTM-based layer for simplicity and the stableness of further training. % The resulting GPT-2-based model stores up to 40% fewer parameters, showing the perplexity comparable to the original model. On the downstream tasks, including language understanding and text summarization, the model performs similarly to the original GPT-2 model. The proposed tensorized layers could be used to efficiently pre-training other Transformer models. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 08:38:25 GMT'}]",2023-06-06,"[['Chekalina', 'Viktoriia', ''], ['Novikov', 'Georgii', ''], ['Gusak', 'Julia', ''], ['Oseledets', 'Ivan', ''], ['Panchenko', 'Alexander', '']]",0,1,2023-06-05,1,5,1,1,1,0,cf59882f25cacb1b688388ca46e6d306dd9fbd41,259075112.0,https://www.semanticscholar.org/paper/cf59882f25cacb1b688388ca46e6d306dd9fbd41,arXiv.org,2023.0,18.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '95677025', 'name': 'V. Chekalina'}, {'authorId': '2122345733', 'name': 'Georgii Sergeevich Novikov'}, {'authorId': '3397802', 'name': 'Julia Gusak'}, {'authorId': '1738205', 'name': 'I. Oseledets'}, {'authorId': '2027664756', 'name': 'A. Panchenko'}]",['Skolkovo Institute of Science and Technology'],['Russia'],2023-06
2306.02707,Arindam Mitra,"Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal,
  Hamid Palangi, Ahmed Awadallah",Orca: Progressive Learning from Complex Explanation Traces of GPT-4,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Recent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small model's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at https://aka.ms/orca-lm), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 08:58:39 GMT'}]",2023-06-06,"[['Mukherjee', 'Subhabrata', ''], ['Mitra', 'Arindam', ''], ['Jawahar', 'Ganesh', ''], ['Agarwal', 'Sahaj', ''], ['Palangi', 'Hamid', ''], ['Awadallah', 'Ahmed', '']]",1,1,2023-06-05,1,6,2,4,2,2,0244aeb7c6927e2fb0c2e668687e160a00737dbe,259075316.0,https://www.semanticscholar.org/paper/0244aeb7c6927e2fb0c2e668687e160a00737dbe,arXiv.org,2023.0,32.0,60.0,7.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2153292652', 'name': 'Subhabrata Mukherjee'}, {'authorId': '2146720788', 'name': 'Arindam Mitra'}, {'authorId': '2065043351', 'name': 'Ganesh Jawahar'}, {'authorId': '2211923024', 'name': 'Sahaj Agarwal'}, {'authorId': '2542427', 'name': 'H. Palangi'}, {'authorId': '2072795428', 'name': 'A. Awadallah'}]",['Microsoft'],['India'],2023-06
2306.02864,Alejandro Pe\~na Almansa,"Alejandro Pe\~na, Aythami Morales, Julian Fierrez, Ignacio Serna,
  Javier Ortega-Garcia, I\~nigo Puente, Jorge Cordova, Gonzalo Cordova",Leveraging Large Language Models for Topic Classification in the Domain of Public Affairs,"Accepted in ICDAR 2023 Workshop on Automatic Domain-Adapted and
  Personalized Document Analysis","Document Analysis and Recognition - ICDAR 2023 Workshops. ICDAR
  2023. Lecture Notes in Computer Science, vol 14194",10.1007/978-3-031-41498-5_2,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The analysis of public affairs documents is crucial for citizens as it promotes transparency, accountability, and informed decision-making. It allows citizens to understand government policies, participate in public discourse, and hold representatives accountable. This is crucial, and sometimes a matter of life or death, for companies whose operation depend on certain regulations. Large Language Models (LLMs) have the potential to greatly enhance the analysis of public affairs documents by effectively processing and understanding the complex language used in such documents. In this work, we analyze the performance of LLMs in classifying public affairs documents. As a natural multi-label task, the classification of these documents presents important challenges. In this work, we use a regex-powered tool to collect a database of public affairs documents with more than 33K samples and 22.5M tokens. Our experiments assess the performance of 4 different Spanish LLMs to classify up to 30 different topics in the data in different configurations. The results shows that LLMs can be of great use to process domain-specific documents, such as those in the domain of public affairs. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 13:35:01 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Aug 2023 09:48:36 GMT'}]",2023-09-06,"[['Peña', 'Alejandro', ''], ['Morales', 'Aythami', ''], ['Fierrez', 'Julian', ''], ['Serna', 'Ignacio', ''], ['Ortega-Garcia', 'Javier', ''], ['Puente', 'Iñigo', ''], ['Cordova', 'Jorge', ''], ['Cordova', 'Gonzalo', '']]",0,0,2023-06-05,2,8,2,0,0,0,661e64593fca437e41d4b90bcbc440ba76d988d2,259076261.0,https://www.semanticscholar.org/paper/661e64593fca437e41d4b90bcbc440ba76d988d2,ICDAR Workshops,2023.0,23.0,4.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2052946731', 'name': 'Alejandro Pena'}, {'authorId': '144083995', 'name': 'A. Morales'}, {'authorId': '1701431', 'name': 'Julian Fierrez'}, {'authorId': '98849914', 'name': 'Ignacio Serna'}, {'authorId': '1397258551', 'name': 'J. Ortega-Garcia'}, {'authorId': '2219555154', 'name': 'Inigo Puente'}, {'authorId': '2218940807', 'name': 'Jorge Cordova'}, {'authorId': '2219550808', 'name': 'Gonzalo Cordova'}]","['Autonomous University of Madrid', 'VINCES Consulting, Madrid 28010, Spain']",['Spain'],2023-06
2306.02978,Dami\'an Furman,"Dami\'an Furman, Pablo Torres, Jos\'e A. Rodr\'iguez, Diego Letzen,
  Vanina Mart\'inez, Laura Alonso Alemany",Which Argumentative Aspects of Hate Speech in Social Media can be reliably identified?,9 Pages plus reference and appendix,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  With the increasing diversity of use cases of large language models, a more informative treatment of texts seems necessary. An argumentative analysis could foster a more reasoned usage of chatbots, text completion mechanisms or other applications. However, it is unclear which aspects of argumentation can be reliably identified and integrated in language models. In this paper, we present an empirical assessment of the reliability with which different argumentative aspects can be automatically identified in hate speech in social media. We have enriched the Hateval corpus (Basile et al. 2019) with a manual annotation of some argumentative components, adapted from Wagemans (2016)'s Periodic Table of Arguments. We show that some components can be identified with reasonable reliability. For those that present a high error ratio, we analyze the patterns of disagreement between expert annotators and errors in automatic procedures, and we propose adaptations of those categories that can be more reliably reproduced. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 15:50:57 GMT'}]",2023-06-06,"[['Furman', 'Damián', ''], ['Torres', 'Pablo', ''], ['Rodríguez', 'José A.', ''], ['Letzen', 'Diego', ''], ['Martínez', 'Vanina', ''], ['Alemany', 'Laura Alonso', '']]",0,0,2023-06-05,1,6,2,0,0,0,77a1eebdaca74f75d77671965a17a1f924534669,259075624.0,https://www.semanticscholar.org/paper/77a1eebdaca74f75d77671965a17a1f924534669,DMR,2023.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2121898803', 'name': 'D. Furman'}, {'authorId': '145814264', 'name': 'Pablo E. Torres'}, {'authorId': '50388497', 'name': 'José Raúl Rodríguez Rodríguez'}, {'authorId': '2081987049', 'name': 'Diego Letzen'}, {'authorId': '2149062067', 'name': 'María Vanina Martínez'}, {'authorId': '2276687', 'name': 'L. A. Alemany'}]","['Universidad Nacional de Córdoba', 'Artificial Intelligence Research Institute', 'Fundación Vía Libre', 'Consejo Nacional de Investigaciones Científicas y Técnicas', 'University of Buenos Aires']","['Spain', 'Argentina']",2023-06
2306.03055,Ryo Sekizawa,Ryo Sekizawa and Hitomi Yanaka,Analyzing Syntactic Generalization Capacity of Pre-trained Language Models on Japanese Honorific Conversion,"To appear in the Proceedings of the 12th Joint Conference on Lexical
  and Computational Semantics (*SEM2023) with ACL2023",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Using Japanese honorifics is challenging because it requires not only knowledge of the grammatical rules but also contextual information, such as social relationships. It remains unclear whether pre-trained large language models (LLMs) can flexibly handle Japanese honorifics like humans. To analyze this, we introduce an honorific conversion task that considers social relationships among people mentioned in a conversation. We construct a Japanese honorifics dataset from problem templates of various sentence structures to investigate the syntactic generalization capacity of GPT-3, one of the leading LLMs, on this task under two settings: fine-tuning and prompt learning. Our results showed that the fine-tuned GPT-3 performed better in a context-aware honorific conversion task than the prompt-based one. The fine-tuned model demonstrated overall syntactic generalizability towards compound honorific sentences, except when tested with the data involving direct speech. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 17:27:48 GMT'}]",2023-06-06,"[['Sekizawa', 'Ryo', ''], ['Yanaka', 'Hitomi', '']]",0,1,2023-06-05,1,2,1,1,0,1,3fcc2799d1920723e6f3c9abf79774568a1a20df,259075843.0,https://www.semanticscholar.org/paper/3fcc2799d1920723e6f3c9abf79774568a1a20df,STARSEM,2023.0,11.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219555464', 'name': 'Ryo Sekizawa'}, {'authorId': '3486313', 'name': 'Hitomi Yanaka'}]",['The University of Tokyo'],['Japan'],2023-06
2306.03264,Sanjeev Kumar Karn,"Sanjeev Kumar Karn, Rikhiya Ghosh, Kusuma P and Oladimeji Farri",shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned LLMs for Radiology Report Impression Generation,1st Place in Task 1B: Radiology Report Summarization at BioNLP 2023,"BioNLP 2023, Co-located with ACL 2023",,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Instruction-tuned generative Large language models (LLMs) like ChatGPT and Bloomz possess excellent generalization abilities, but they face limitations in understanding radiology reports, particularly in the task of generating the IMPRESSIONS section from the FINDINGS section. They tend to generate either verbose or incomplete IMPRESSIONS, mainly due to insufficient exposure to medical text data during training. We present a system which leverages large-scale medical text data for domain-adaptive pre-training of instruction-tuned LLMs to enhance its medical knowledge and performance on specific medical tasks. We show that this system performs better in a zero-shot setting than a number of pretrain-and-finetune adaptation methods on the IMPRESSIONS generation task, and ranks 1st among participating systems in Task 1B: Radiology Report Summarization at the BioNLP 2023 workshop. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 21:33:04 GMT'}]",2023-06-07,"[['Karn', 'Sanjeev Kumar', ''], ['Ghosh', 'Rikhiya', ''], ['P', 'Kusuma', ''], ['Farri', 'Oladimeji', '']]",1,1,2023-06-05,1,4,1,2,1,1,f63a02601c7c3fdabcfff118d98e815697c42e0f,259089323.0,https://www.semanticscholar.org/paper/f63a02601c7c3fdabcfff118d98e815697c42e0f,Workshop on Biomedical Natural Language Processing,2023.0,31.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '34112357', 'name': 'Sanjeev Kumar Karn'}, {'authorId': '2555257', 'name': 'Rikhiya Ghosh'}, {'authorId': '2071432082', 'name': 'P. Kusuma'}, {'authorId': '2211973', 'name': 'Oladimeji Farri'}]",['Siemens Healthcare (Germany)'],['Germany'],2023-06
2306.03314,Amirhossein Nadiri,Yashar Talebirad and Amirhossein Nadiri,Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents,,,,,cs.AI cs.LG cs.MA,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present a novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems. Our framework introduces a collaborative environment where multiple intelligent agent components, each with distinctive attributes and roles, work together to handle complex tasks more efficiently and effectively. We demonstrate the practicality and versatility of our framework through case studies in artificial general intelligence (AGI), specifically focusing on the Auto-GPT and BabyAGI models. We also examine the ""Gorilla"" model, which integrates external APIs into the LLM. Our framework addresses limitations and challenges such as looping issues, security risks, scalability, system evaluation, and ethical considerations. By modeling various domains such as courtroom simulations and software development scenarios, we showcase the potential applications and benefits of our proposed multi-agent system. Our framework provides an avenue for advancing the capabilities and performance of LLMs through collaboration and knowledge exchange among intelligent agents. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 23:55:37 GMT'}]",2023-06-07,"[['Talebirad', 'Yashar', ''], ['Nadiri', 'Amirhossein', '']]",0,1,2023-06-05,1,2,3,0,0,0,ead6121fbc787d508dc6a6d7106f72bf0d647d03,259088724.0,https://www.semanticscholar.org/paper/ead6121fbc787d508dc6a6d7106f72bf0d647d03,arXiv.org,2023.0,14.0,15.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237440339', 'name': 'Yashar Talebirad'}, {'authorId': '2163313042', 'name': 'Amirhossein Nadiri'}]","['University of Alberta', 'York University']",['Canada'],2023-06
2306.03553,John Chong Min Tan,Tan John Chong Min,An Approach to Solving the Abstraction and Reasoning Corpus (ARC) Challenge,14 pages,,,,cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  We utilise the power of Large Language Models (LLMs), in particular GPT4, to be prompt engineered into performing an arbitrary task. Here, we give the model some human priors via text, along with some typical procedures for solving the ARC tasks, and ask it to generate the i) broad description of the input-output relation, ii) detailed steps of the input-output mapping, iii) use the detailed steps to perform manipulation on the test input and derive the test output. The current GPT3.5/GPT4 prompt solves 2 out of 4 tested small ARC challenges (those with small grids of 8x8 and below). With tweaks to the prompt to make it more specific for the use case, it can solve more. We posit that when scaled to a multi-agent system with usage of past memory and equipped with an image interpretation tool via Visual Question Answering, we may actually be able to solve the majority of the ARC challenge ","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 10:08:12 GMT'}]",2023-06-07,"[['Min', 'Tan John Chong', '']]",0,1,2023-06-06,1,1,1,2,0,2,e85ffdf9a797dc1584838ad00330f98ebfe8e50c,259088676.0,https://www.semanticscholar.org/paper/e85ffdf9a797dc1584838ad00330f98ebfe8e50c,,2023.0,26.0,1.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219388103', 'name': 'Tan John Chong Min'}]",['National University of Singapore'],['Singapore'],2023-06
2306.03917,Marcel Binz,"Marcel Binz, Eric Schulz",Turning large language models into cognitive models,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large language models are powerful systems that excel at many tasks, ranging from translation to mathematical reasoning. Yet, at the same time, these models often show unhuman-like characteristics. In the present paper, we address this gap and ask whether large language models can be turned into cognitive models. We find that -- after finetuning them on data from psychological experiments -- these models offer accurate representations of human behavior, even outperforming traditional cognitive models in two decision-making domains. In addition, we show that their representations contain the information necessary to model behavior on the level of individual subjects. Finally, we demonstrate that finetuning on multiple tasks enables large language models to predict human behavior in a previously unseen task. Taken together, these results suggest that large, pre-trained models can be adapted to become generalist cognitive models, thereby opening up new research directions that could transform cognitive psychology and the behavioral sciences as a whole. ","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 18:00:01 GMT'}]",2023-06-08,"[['Binz', 'Marcel', ''], ['Schulz', 'Eric', '']]",0,0,2023-06-06,1,2,3,0,0,0,56caaf598c1bf36a24385f30ca775b94cf215b6b,259095948.0,https://www.semanticscholar.org/paper/56caaf598c1bf36a24385f30ca775b94cf215b6b,arXiv.org,2023.0,40.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '32354733', 'name': 'Marcel Binz'}, {'authorId': '49427184', 'name': 'Eric Schulz'}]",['Max Planck Institute for Biological Cybernetics'],['Germany'],2023-06
2306.03921,Stefanie Czischek,Kyle Sprague and Stefanie Czischek,Variational Monte Carlo with Large Patched Transformers,"6+5 pages, 4+1 figures",,,,quant-ph cond-mat.dis-nn physics.comp-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models, like transformers, have recently demonstrated immense powers in text and image generation. This success is driven by the ability to capture long-range correlations between elements in a sequence. The same feature makes the transformer a powerful wavefunction ansatz that addresses the challenge of describing correlations in simulations of qubit systems. We consider two-dimensional Rydberg atom arrays to demonstrate that transformers reach higher accuracies than conventional recurrent neural networks for variational ground state searches. We further introduce large, patched transformer models, which consider a sequence of large atom patches, and show that this architecture significantly accelerates the simulations. The proposed architectures reconstruct ground states with accuracies beyond state-of-the-art quantum Monte Carlo methods, allowing for the study of large Rydberg systems in different phases of matter and at phase transitions. Our high-accuracy ground state representations at reasonable computational costs promise new insights into general large-scale quantum many-body systems. ","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 18:00:02 GMT'}]",2023-06-08,"[['Sprague', 'Kyle', ''], ['Czischek', 'Stefanie', '']]",0,0,2023-06-06,1,2,3,0,0,0,e7c7799ac3b290150863b1d70f1fc6cd29b8470a,259095994.0,https://www.semanticscholar.org/paper/e7c7799ac3b290150863b1d70f1fc6cd29b8470a,,2023.0,58.0,2.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '1522053348', 'name': 'Kyle Sprague'}, {'authorId': '103327293', 'name': 'Stefanie Czischek'}]",['University of Ottawa'],['Canada'],2023-06
2306.04067,Zhongbin Xie,"Zhongbin Xie, Thomas Lukasiewicz",An Empirical Analysis of Parameter-Efficient Methods for Debiasing Pre-Trained Language Models,accepted to ACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The increasingly large size of modern pretrained language models not only makes them inherit more human-like biases from the training corpora, but also makes it computationally expensive to mitigate such biases. In this paper, we investigate recent parameter-efficient methods in combination with counterfactual data augmentation (CDA) for bias mitigation. We conduct extensive experiments with prefix tuning, prompt tuning, and adapter tuning on different language models and bias types to evaluate their debiasing performance and abilities to preserve the internal knowledge of a pre-trained model. We find that the parameter-efficient methods (i) are effective in mitigating gender bias, where adapter tuning is consistently the most effective one and prompt tuning is more suitable for GPT-2 than BERT, (ii) are less effective when it comes to racial and religious bias, which may be attributed to the limitations of CDA, and (iii) can perform similarly to or sometimes better than full fine-tuning with improved time and memory efficiency, as well as maintain the internal knowledge in BERT and GPT-2, evaluated via fact retrieval and downstream fine-tuning. ","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 23:56:18 GMT'}]",2023-06-08,"[['Xie', 'Zhongbin', ''], ['Lukasiewicz', 'Thomas', '']]",0,1,2023-06-06,1,2,1,1,1,0,2f130a320798dba1b13fa2e2822d42273e453038,259095584.0,https://www.semanticscholar.org/paper/2f130a320798dba1b13fa2e2822d42273e453038,Annual Meeting of the Association for Computational Linguistics,2023.0,50.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '123639116', 'name': 'Zhongbin Xie'}, {'authorId': '1690572', 'name': 'Thomas Lukasiewicz'}]","['TU Wien', 'University of Oxford']","['Austria', 'United Kingdom']",2023-06
2306.04308,Ljubisa Bojic,"Bojana Bodroza (1), Bojana M. Dinic (1) and Ljubisa Bojic (2) ((1)
  Department of Psychology, Faculty of Philosophy, University of Novi Sad,
  Serbia, (2) Digital Society Lab, Institute for Philosophy and Social Theory,
  University of Belgrade, Serbia)","Personality testing of GPT-3: Limited temporal reliability, but highlighted social desirability of GPT-3's personality instruments results","18 pages, 1 table",,,,cs.AI cs.CL cs.HC,http://creativecommons.org/licenses/by-sa/4.0/,"  To assess the potential applications and limitations of chatbot GPT-3 Davinci-003, this study explored the temporal reliability of personality questionnaires applied to the chatbot and its personality profile. Psychological questionnaires were administered to the chatbot on two separate occasions, followed by a comparison of the responses to human normative data. The findings revealed varying levels of agreement in the chatbot's responses over time, with some scales displaying excellent while others demonstrated poor agreement. Overall, Davinci-003 displayed a socially desirable and pro-social personality profile, particularly in the domain of communion. However, the underlying basis of the chatbot's responses, whether driven by conscious self-reflection or predetermined algorithms, remains uncertain. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 10:14:17 GMT'}]",2023-06-08,"[['Bodroza', 'Bojana', ''], ['Dinic', 'Bojana M.', ''], ['Bojic', 'Ljubisa', '']]",0,1,2023-06-07,1,3,3,1,0,1,73f31601114e037f71b9645c5932856484be3dbb,259095544.0,https://www.semanticscholar.org/paper/73f31601114e037f71b9645c5932856484be3dbb,arXiv.org,2023.0,42.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2527670', 'name': 'Bojana Bodroža'}, {'authorId': '87145517', 'name': 'Bojana M. Dinić'}, {'authorId': '2219270917', 'name': 'Ljubisa Bojic Department of Psychology'}, {'authorId': '2089044959', 'name': 'Faculty of Philosophy'}, {'authorId': '93640890', 'name': 'Universityof Novi Sad'}, {'authorId': '88144297', 'name': 'Serbia'}, {'authorId': '2219268711', 'name': 'Digital Society Lab'}, {'authorId': '2219269052', 'name': 'Institute for Philosophy'}, {'authorId': '1412344436', 'name': 'Social Theory'}, {'authorId': '102909589', 'name': 'U. Belgrade'}]","['ORCID: 0000-0003-4165-0678 Dr Zorana Đinđića 2, 21000 Novi Sad, Serbia', 'University of Novi Sad', 'University of Belgrade', 'ORCID: 0000-0002-5371-7975 Fruskogorska 1, 21000 Novi Sad, Serbia', 'ORCID: 0000-0002-5492-2188 Dr Zorana Đinđića 2, 21000 Novi Sad, Serbia', 'Dalle Molle Institute for Artificial Intelligence Research']","['Serbia', 'Switzerland']",2023-06
2306.04349,Xiaohuan Pei,"Xiaohuan Pei, Yanxi Li, Chang Xu",GPT Self-Supervision for a Better Data Annotator,,,,,cs.CL cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The task of annotating data into concise summaries poses a significant challenge across various domains, frequently requiring the allocation of significant time and specialized knowledge by human experts. Despite existing efforts to use large language models for annotation tasks, significant problems such as limited applicability to unlabeled data, the absence of self-supervised methods, and the lack of focus on complex structured data still persist. In this work, we propose a GPT self-supervision annotation method, which embodies a generating-recovering paradigm that leverages the one-shot learning capabilities of the Generative Pretrained Transformer (GPT). The proposed approach comprises a one-shot tuning phase followed by a generation phase. In the one-shot tuning phase, we sample a data from the support set as part of the prompt for GPT to generate a textual summary, which is then used to recover the original data. The alignment score between the recovered and original data serves as a self-supervision navigator to refine the process. In the generation stage, the optimally selected one-shot sample serves as a template in the prompt and is applied to generating summaries from challenging datasets. The annotation performance is evaluated by tuning several human feedback reward networks and by calculating alignment scores between original and recovered data at both sentence and structure levels. Our self-supervised annotation method consistently achieves competitive scores, convincingly demonstrating its robust strength in various data-to-summary annotation tasks. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 11:33:14 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Jun 2023 05:45:45 GMT'}]",2023-06-09,"[['Pei', 'Xiaohuan', ''], ['Li', 'Yanxi', ''], ['Xu', 'Chang', '']]",0,1,2023-06-07,2,3,2,0,0,0,2382cf12d4dd5c7b1529967836ce70e7ed1b3f4c,259096129.0,https://www.semanticscholar.org/paper/2382cf12d4dd5c7b1529967836ce70e7ed1b3f4c,arXiv.org,2023.0,32.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2203812724', 'name': 'Xiaohuan Pei'}, {'authorId': '50025043', 'name': 'Yanxi Li'}, {'authorId': '144962258', 'name': 'Chang Xu'}]",['University of Sydney'],['Australia'],2023-06
2306.04384,Xavier Fontaine,"Xavier Fontaine, F\'elix Gaschi, Parisa Rastin and Yannick Toussaint",Multilingual Clinical NER: Translation or Cross-lingual Transfer?,"23 pages, Proceedings of the 5th Clinical Natural Language Processing
  Workshop",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Natural language tasks like Named Entity Recognition (NER) in the clinical domain on non-English texts can be very time-consuming and expensive due to the lack of annotated data. Cross-lingual transfer (CLT) is a way to circumvent this issue thanks to the ability of multilingual large language models to be fine-tuned on a specific task in one language and to provide high accuracy for the same task in another language. However, other methods leveraging translation models can be used to perform NER without annotated data in the target language, by either translating the training set or test set. This paper compares cross-lingual transfer with these two alternative methods, to perform clinical NER in French and in German without any training data in those languages. To this end, we release MedNERF a medical NER test set extracted from French drug prescriptions and annotated with the same guidelines as an English dataset. Through extensive experiments on this dataset and on a German medical dataset (Frei and Kramer, 2021), we show that translation-based methods can achieve similar performance to CLT but require more care in their design. And while they can take advantage of monolingual clinical language models, those do not guarantee better results than large general-purpose multilingual models, whether with cross-lingual transfer or translation. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 12:31:07 GMT'}]",2023-06-08,"[['Fontaine', 'Xavier', ''], ['Gaschi', 'Félix', ''], ['Rastin', 'Parisa', ''], ['Toussaint', 'Yannick', '']]",0,0,2023-06-07,1,4,3,0,0,0,d7879de2cad2f69d6361ac46baa3f83e88ae6613,259095791.0,https://www.semanticscholar.org/paper/d7879de2cad2f69d6361ac46baa3f83e88ae6613,Clinical Natural Language Processing Workshop,2023.0,47.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50026293', 'name': 'X. Fontaine'}, {'authorId': '2145326851', 'name': 'Félix Gaschi'}, {'authorId': '3109851', 'name': 'Parisa Rastin'}, {'authorId': '1802166', 'name': 'Y. Toussaint'}]","['Soil Agro and Hydrosystems Spatialization', 'Lorraine Research Laboratory in Computer Science and its Applications']",['France'],2023-06
2306.04538,Xuan-Quy Dao,"Dao Xuan-Quy and Le Ngoc-Bich and Phan Xuan-Dung and Ngo Bac-Bien and
  Vo The-Duy",Evaluation of ChatGPT and Microsoft Bing AI Chat Performances on Physics Exams of Vietnamese National High School Graduation Examination,"13 pages, 8 figures, 3 tables",,,,physics.ed-ph,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The promise and difficulties of language model-based approaches for physics teaching were assessed in this study. This study evaluates how well ChatGPT and BingChat, two state-of-the-art (SOTA) large language models (LLMs), perform when answering high school physics questions on Vietnamese exams from 2019 to 2023. When we compared the results of the LLMs with the scores of Vietnamese students, we discovered that ChatGPT and BingChat both perform worse than Vietnamese students, proving that LLMs are not yet capable of fully replacing human intellect in the field of physics teaching. The outcomes also showed that neither LLM is capable of responding to questions at the high application levels. In terms of accuracy, BingChat typically surpassed ChatGPT, although ChatGPT showed more stability. Our research suggests that LLMs can help students and teachers during learning and teaching activities, particularly by offering immediate feedback and individualized learning experiences. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 15:44:14 GMT'}, {'version': 'v2', 'created': 'Thu, 8 Jun 2023 06:02:31 GMT'}, {'version': 'v3', 'created': 'Wed, 21 Jun 2023 12:19:09 GMT'}]",2023-06-22,"[['Xuan-Quy', 'Dao', ''], ['Ngoc-Bich', 'Le', ''], ['Xuan-Dung', 'Phan', ''], ['Bac-Bien', 'Ngo', ''], ['The-Duy', 'Vo', '']]",1,1,2023-06-07,3,5,1,1,0,1,03a622e853ae7a96e3a00e65edd7d6dc2a0a835e,259095528.0,https://www.semanticscholar.org/paper/03a622e853ae7a96e3a00e65edd7d6dc2a0a835e,,2023.0,17.0,5.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2218325521', 'name': 'Dao Xuan-Quy'}, {'authorId': '2218301144', 'name': 'Le Ngoc-Bich'}, {'authorId': '2218325523', 'name': 'Phan Xuan-Dung'}, {'authorId': '2218354936', 'name': 'Ngo Bac-Bien'}, {'authorId': '2218270404', 'name': 'Vo The-Duy'}]","['Vietnam National University Ho Chi Minh City', 'Eastern International University']",['Vietnam'],2023-06
2306.04563,Sophie Jentzsch,"Sophie Jentzsch, Kristian Kersting","ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models",,,,,cs.AI cs.CL cs.HC cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Humor is a central aspect of human communication that has not been solved for artificial agents so far. Large language models (LLMs) are increasingly able to capture implicit and contextual information. Especially, OpenAI's ChatGPT recently gained immense public attention. The GPT3-based model almost seems to communicate on a human level and can even tell jokes. Humor is an essential component of human communication. But is ChatGPT really funny? We put ChatGPT's sense of humor to the test. In a series of exploratory experiments around jokes, i.e., generation, explanation, and detection, we seek to understand ChatGPT's capability to grasp and reproduce human humor. Since the model itself is not accessible, we applied prompt-based experiments. Our empirical evidence indicates that jokes are not hard-coded but mostly also not newly generated by the model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system accurately explains valid jokes but also comes up with fictional explanations for invalid jokes. Joke-typical characteristics can mislead ChatGPT in the classification of jokes. ChatGPT has not solved computational humor yet but it can be a big leap toward ""funny"" machines. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 16:10:21 GMT'}]",2023-06-08,"[['Jentzsch', 'Sophie', ''], ['Kersting', 'Kristian', '']]",1,1,2023-06-07,1,2,4,2,0,2,d962b6772dab0ce2573370e72a477665dfe5ab08,259095915.0,https://www.semanticscholar.org/paper/d962b6772dab0ce2573370e72a477665dfe5ab08,"Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",2023.0,60.0,11.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151209594', 'name': 'Sophie F. Jentzsch'}, {'authorId': '2066493115', 'name': 'K. Kersting'}]","['Hessian Center for AI (hessian.AI', 'German Aerospace Center', 'Technical University of Darmstadt']",['Germany'],2023-06
2306.04667,Francesco Ceccarelli Mr,"Francesco Ceccarelli, Lorenzo Giusti, Sean B. Holden, Pietro Li\`o",Neural Embeddings for Protein Graphs,"10 pages, 5 figures",,,,q-bio.QM cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Proteins perform much of the work in living organisms, and consequently the development of efficient computational methods for protein representation is essential for advancing large-scale biological research. Most current approaches struggle to efficiently integrate the wealth of information contained in the protein sequence and structure. In this paper, we propose a novel framework for embedding protein graphs in geometric vector spaces, by learning an encoder function that preserves the structural distance between protein graphs. Utilizing Graph Neural Networks (GNNs) and Large Language Models (LLMs), the proposed framework generates structure- and sequence-aware protein representations. We demonstrate that our embeddings are successful in the task of comparing protein structures, while providing a significant speed-up compared to traditional approaches based on structural alignment. Our framework achieves remarkable results in the task of protein structure classification; in particular, when compared to other work, the proposed method shows an average F1-Score improvement of 26% on out-of-distribution (OOD) samples and of 32% when tested on samples coming from the same distribution as the training data. Our approach finds applications in areas such as drug prioritization, drug re-purposing, disease sub-type analysis and elsewhere. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 14:50:34 GMT'}]",2023-06-09,"[['Ceccarelli', 'Francesco', ''], ['Giusti', 'Lorenzo', ''], ['Holden', 'Sean B.', ''], ['Liò', 'Pietro', '']]",0,0,2023-06-07,1,4,2,0,0,0,c6a781b22da56af807d0e12c4e2061be27cc189f,259108706.0,https://www.semanticscholar.org/paper/c6a781b22da56af807d0e12c4e2061be27cc189f,arXiv.org,2023.0,69.0,0.0,0.0,True,"['Computer Science', 'Biology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2144604863', 'name': 'Francesco Ceccarelli'}, {'authorId': '50274714', 'name': 'Lorenzo Giusti'}, {'authorId': '2732041', 'name': 'S. Holden'}, {'authorId': '2075355155', 'name': ""Pietro Lio'""}]","['University of Cambridge', 'Sapienza University of Rome']","['United Kingdom', 'Italy']",2023-06
2306.04735,Faiza Khattak Dr.,"Jacob-Junqi Tian, David Emerson, Sevil Zanjani Miyandoab, Deval
  Pandya, Laleh Seyyed-Kalantari, Faiza Khan Khattak",Soft-prompt Tuning for Large Language Models to Evaluate Bias,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Prompting large language models has gained immense popularity in recent years due to the advantage of producing good results even without the need for labelled data. However, this requires prompt tuning to get optimal prompts that lead to better model performances. In this paper, we explore the use of soft-prompt tuning on sentiment classification task to quantify the biases of large language models (LLMs) such as Open Pre-trained Transformers (OPT) and Galactica language model. Since these models are trained on real-world data that could be prone to bias toward certain groups of populations, it is important to identify these underlying issues. Using soft-prompts to evaluate bias gives us the extra advantage of avoiding the human-bias injection that can be caused by manually designed prompts. We check the model biases on different sensitive attributes using the group fairness (bias) and find interesting bias patterns. Since LLMs have been used in the industry in various applications, it is crucial to identify the biases before deploying these models in practice. We open-source our pipeline and encourage industry researchers to adapt our work to their use cases. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 19:11:25 GMT'}]",2023-06-09,"[['Tian', 'Jacob-Junqi', ''], ['Emerson', 'David', ''], ['Miyandoab', 'Sevil Zanjani', ''], ['Pandya', 'Deval', ''], ['Seyyed-Kalantari', 'Laleh', ''], ['Khattak', 'Faiza Khan', '']]",0,0,2023-06-07,1,6,3,1,1,0,14f16ff865945885c638f107d4b0619dddf4a82e,259108572.0,https://www.semanticscholar.org/paper/14f16ff865945885c638f107d4b0619dddf4a82e,arXiv.org,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2220028602', 'name': 'Jacob-Junqi Tian'}, {'authorId': '2055879362', 'name': 'David B. Emerson'}, {'authorId': '2219689826', 'name': 'Sevil Zanjani Miyandoab'}, {'authorId': '93533703', 'name': 'D. Pandya'}, {'authorId': '1450822685', 'name': 'L. Seyyed-Kalantari'}, {'authorId': '2374769', 'name': 'Faiza Khan Khattak'}]","['Amirkabir University of Technology', 'McGill University', 'Vector Institute', 'York University']","['Iran', 'Canada']",2023-06
2306.04743,Yi Zhang,"Yi Zhang, Jan Deriu, George Katsogiannis-Meimarakis, Catherine Kosten,
  Georgia Koutrika, Kurt Stockinger",ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural Language to SQL Systems,"12 pages, 2 figures, 5 tables",,,,cs.DB cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Natural Language to SQL systems (NL-to-SQL) have recently shown a significant increase in accuracy for natural language to SQL query translation. This improvement is due to the emergence of transformer-based language models, and the popularity of the Spider benchmark - the de-facto standard for evaluating NL-to-SQL systems. The top NL-to-SQL systems reach accuracies of up to 85\%. However, Spider mainly contains simple databases with few tables, columns, and entries, which does not reflect a realistic setting. Moreover, complex real-world databases with domain-specific content have little to no training data available in the form of NL/SQL-pairs leading to poor performance of existing NL-to-SQL systems.   In this paper, we introduce ScienceBenchmark, a new complex NL-to-SQL benchmark for three real-world, highly domain-specific databases. For this new benchmark, SQL experts and domain experts created high-quality NL/SQL-pairs for each domain. To garner more data, we extended the small amount of human-generated data with synthetic data generated using GPT-3. We show that our benchmark is highly challenging, as the top performing systems on Spider achieve a very low performance on our benchmark. Thus, the challenge is many-fold: creating NL-to-SQL systems for highly complex domains with a small amount of hand-made training data augmented with synthetic data. To our knowledge, ScienceBenchmark is the first NL-to-SQL benchmark designed with complex real-world scientific databases, containing challenging training and test data carefully validated by domain experts. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 19:37:55 GMT'}]",2023-06-09,"[['Zhang', 'Yi', ''], ['Deriu', 'Jan', ''], ['Katsogiannis-Meimarakis', 'George', ''], ['Kosten', 'Catherine', ''], ['Koutrika', 'Georgia', ''], ['Stockinger', 'Kurt', '']]",0,1,2023-06-07,1,6,3,1,0,1,e7a4e7b349b70b1681978cd57a59a6e1684b219f,259108708.0,https://www.semanticscholar.org/paper/e7a4e7b349b70b1681978cd57a59a6e1684b219f,arXiv.org,2023.0,47.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46867002', 'name': 'Yi Zhang'}, {'authorId': '145116511', 'name': 'Jan Deriu'}, {'authorId': '2055401797', 'name': 'George Katsogiannis-Meimarakis'}, {'authorId': '2072251887', 'name': 'Catherine Kosten'}, {'authorId': '1680709', 'name': 'G. Koutrika'}, {'authorId': '2113917675', 'name': 'Kurt Stockinger'}]","['Athens Technology Center (Greece)', 'Zurich University of Applied Sciences in Business Administration']","['Greece', 'Switzerland']",2023-06
2306.04757,Soujanya Poria,"Yew Ken Chia, Pengfei Hong, Lidong Bing, Soujanya Poria",INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models,"Github: https://github.com/declare-lab/instruct-eval Leaderboard:
  https://declare-lab.github.io/instruct-eval/",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Instruction-tuned large language models have revolutionized natural language processing and have shown great potential in applications such as conversational agents. These models, such as GPT-4, can not only master language but also solve complex tasks in areas like mathematics, coding, medicine, and law. Despite their impressive capabilities, there is still a lack of comprehensive understanding regarding their full potential, primarily due to the black-box nature of many models and the absence of holistic evaluation studies. To address these challenges, we present INSTRUCTEVAL, a more comprehensive evaluation suite designed specifically for instruction-tuned large language models. Unlike previous works, our evaluation involves a rigorous assessment of models based on problem-solving, writing ability, and alignment to human values. We take a holistic approach to analyze various factors affecting model performance, including the pretraining foundation, instruction-tuning data, and training methods. Our findings reveal that the quality of instruction data is the most crucial factor in scaling model performance. While open-source models demonstrate impressive writing abilities, there is substantial room for improvement in problem-solving and alignment. We are encouraged by the rapid development of models by the open-source community, but we also highlight the need for rigorous evaluation to support claims made about these models. Through INSTRUCTEVAL, we aim to foster a deeper understanding of instruction-tuned models and advancements in their capabilities. INSTRUCTEVAL is publicly available at https://github.com/declare-lab/instruct-eval. ","[{'version': 'v1', 'created': 'Wed, 7 Jun 2023 20:12:29 GMT'}, {'version': 'v2', 'created': 'Sun, 11 Jun 2023 01:47:26 GMT'}, {'version': 'v3', 'created': 'Thu, 15 Jun 2023 05:08:56 GMT'}]",2023-06-16,"[['Chia', 'Yew Ken', ''], ['Hong', 'Pengfei', ''], ['Bing', 'Lidong', ''], ['Poria', 'Soujanya', '']]",0,1,2023-06-07,3,4,2,1,0,1,17f247649498f5fe5a35a61f5b1cb238cbed70e0,259108199.0,https://www.semanticscholar.org/paper/17f247649498f5fe5a35a61f5b1cb238cbed70e0,arXiv.org,2023.0,42.0,20.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2066312627', 'name': 'Yew Ken Chia'}, {'authorId': '144656297', 'name': 'Pengfei Hong'}, {'authorId': '1996394', 'name': 'Lidong Bing'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}]","['Alibaba', 'Singapore University of Technology and Design']",['Singapore'],2023-06
2306.04891,Kabir Ahuja,"Kabir Ahuja, Madhur Panwar, Navin Goyal",In-Context Learning through the Bayesian Prism,,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In-context learning is one of the surprising and useful features of large language models. How it works is an active area of research. Recently, stylized meta-learning-like setups have been devised that train these models on a sequence of input-output pairs $(x, f(x))$ from a function class using the language modeling loss and observe generalization to unseen functions from the same class. One of the main discoveries in this line of research has been that for several problems such as linear regression, trained transformers learn algorithms for learning functions in context. However, the inductive biases of these models resulting in this behavior are not clearly understood. A model with unlimited training data and compute is a Bayesian predictor: it learns the pretraining distribution. It has been shown that high-capacity transformers mimic the Bayesian predictor for linear regression. In this paper, we show empirical evidence of transformers exhibiting the behavior of this ideal learner across different linear and non-linear function classes. We also extend the previous setups to work in the multitask setting and verify that transformers can do in-context learning in this setup as well and the Bayesian perspective sheds light on this setting also. Finally, via the example of learning Fourier series, we study the inductive bias for in-context learning. We find that in-context learning may or may not have simplicity bias depending on the pretraining data distribution. ","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 02:38:23 GMT'}]",2023-06-09,"[['Ahuja', 'Kabir', ''], ['Panwar', 'Madhur', ''], ['Goyal', 'Navin', '']]",0,0,2023-06-08,1,3,2,0,0,0,f4d543ff431359947bf41152ac01233b8062221f,259108565.0,https://www.semanticscholar.org/paper/f4d543ff431359947bf41152ac01233b8062221f,arXiv.org,2023.0,51.0,6.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '52154863', 'name': 'Kabir Ahuja'}, {'authorId': '48248617', 'name': 'Madhuri Panwar'}, {'authorId': '144260125', 'name': 'Navin Goyal'}]",['Microsoft'],['India'],2023-06
2306.05052,Andrija Petrovic,"Aleksa Bisercic, Mladen Nikolic, Mihaela van der Schaar, Boris
  Delibasic, Pietro Lio, Andrija Petrovic",Interpretable Medical Diagnostics with Structured Data Extraction by Large Language Models,,,,,cs.LG cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Tabular data is often hidden in text, particularly in medical diagnostic reports. Traditional machine learning (ML) models designed to work with tabular data, cannot effectively process information in such form. On the other hand, large language models (LLMs) which excel at textual tasks, are probably not the best tool for modeling tabular data. Therefore, we propose a novel, simple, and effective methodology for extracting structured tabular data from textual medical reports, called TEMED-LLM. Drawing upon the reasoning capabilities of LLMs, TEMED-LLM goes beyond traditional extraction techniques, accurately inferring tabular features, even when their names are not explicitly mentioned in the text. This is achieved by combining domain-specific reasoning guidelines with a proposed data validation and reasoning correction feedback loop. By applying interpretable ML models such as decision trees and logistic regression over the extracted and validated data, we obtain end-to-end interpretable predictions. We demonstrate that our approach significantly outperforms state-of-the-art text classification models in medical diagnostics. Given its predictive performance, simplicity, and interpretability, TEMED-LLM underscores the potential of leveraging LLMs to improve the performance and trustworthiness of ML models in medical applications. ","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 09:12:28 GMT'}]",2023-06-09,"[['Bisercic', 'Aleksa', ''], ['Nikolic', 'Mladen', ''], ['van der Schaar', 'Mihaela', ''], ['Delibasic', 'Boris', ''], ['Lio', 'Pietro', ''], ['Petrovic', 'Andrija', '']]",0,0,2023-06-08,1,6,3,0,0,0,542308ad5c1c0b5ad88e76e6c8d941a6d08ccd01,259108470.0,https://www.semanticscholar.org/paper/542308ad5c1c0b5ad88e76e6c8d941a6d08ccd01,arXiv.org,2023.0,50.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2165291618', 'name': 'Aleksa Bisercic'}, {'authorId': '145888108', 'name': 'Mladen Nikolic'}, {'authorId': '1729969', 'name': 'M. Schaar'}, {'authorId': '1726756', 'name': 'Boris Delibasic'}, {'authorId': '2075355152', 'name': ""P. Lio'""}, {'authorId': '39095636', 'name': 'A. Petrović'}]","['The Alan Turing Institute', 'University of Cambridge', 'University of Belgrade', 'Singidunum University']","['Serbia', 'United Kingdom']",2023-06
2306.05115,Adriana Iamnitchi,"Thales Bertaglia, Stefan Huber, Catalina Goanta, Gerasimos Spanakis,
  Adriana Iamnitchi",Closing the Loop: Testing ChatGPT to Generate Model Explanations to Improve Human Labelling of Sponsored Content on Social Media,"Accepted to The World Conference on eXplainable Artificial
  Intelligence, Lisbon, Portugal, July 2023",,,,cs.CL cs.SI,http://creativecommons.org/licenses/by/4.0/,"  Regulatory bodies worldwide are intensifying their efforts to ensure transparency in influencer marketing on social media through instruments like the Unfair Commercial Practices Directive (UCPD) in the European Union, or Section 5 of the Federal Trade Commission Act. Yet enforcing these obligations has proven to be highly problematic due to the sheer scale of the influencer market. The task of automatically detecting sponsored content aims to enable the monitoring and enforcement of such regulations at scale. Current research in this field primarily frames this problem as a machine learning task, focusing on developing models that achieve high classification performance in detecting ads. These machine learning tasks rely on human data annotation to provide ground truth information. However, agreement between annotators is often low, leading to inconsistent labels that hinder the reliability of models. To improve annotation accuracy and, thus, the detection of sponsored content, we propose using chatGPT to augment the annotation process with phrases identified as relevant features and brief explanations. Our experiments show that this approach consistently improves inter-annotator agreement and annotation accuracy. Additionally, our survey of user experience in the annotation task indicates that the explanations improve the annotators' confidence and streamline the process. Our proposed methods can ultimately lead to more transparency and alignment with regulatory requirements in sponsored content detection. ","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 11:29:58 GMT'}]",2023-06-09,"[['Bertaglia', 'Thales', ''], ['Huber', 'Stefan', ''], ['Goanta', 'Catalina', ''], ['Spanakis', 'Gerasimos', ''], ['Iamnitchi', 'Adriana', '']]",1,1,2023-06-08,1,5,2,1,0,1,c2061bc805785dab28374676993ac9632625e09e,259108958.0,https://www.semanticscholar.org/paper/c2061bc805785dab28374676993ac9632625e09e,arXiv.org,2023.0,37.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '10698348', 'name': 'Thales Bertaglia'}, {'authorId': '2057961300', 'name': 'Stefan Huber'}, {'authorId': '103492671', 'name': 'Catalina Goanta'}, {'authorId': '3266578', 'name': 'Gerasimos Spanakis'}, {'authorId': '1986996', 'name': 'Adriana Iamnitchi'}]","['Utrecht University', 'Erasmus University Rotterdam', 'Maastricht University']",['Netherlands'],2023-06
2306.05152,Sungmin Kang,"Robert Feldt, Sungmin Kang, Juyeon Yoon, Shin Yoo",Towards Autonomous Testing Agents via Conversational Large Language Models,,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Software testing is an important part of the development cycle, yet it requires specialized expertise and substantial developer effort to adequately test software. Recent discoveries of the capabilities of large language models (LLMs) suggest that they can be used as automated testing assistants, and thus provide helpful information and even drive the testing process. To highlight the potential of this technology, we present a taxonomy of LLM-based testing agents based on their level of autonomy, and describe how a greater level of autonomy can benefit developers in practice. An example use of LLMs as a testing assistant is provided to demonstrate how a conversational framework for testing can help developers. This also highlights how the often criticized hallucination of LLMs can be beneficial for testing. We identify other tangible benefits that LLM-driven testing agents can bestow, and also discuss potential limitations. ","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 12:22:38 GMT'}, {'version': 'v2', 'created': 'Tue, 5 Sep 2023 14:34:15 GMT'}]",2023-09-06,"[['Feldt', 'Robert', ''], ['Kang', 'Sungmin', ''], ['Yoon', 'Juyeon', ''], ['Yoo', 'Shin', '']]",0,0,2023-06-08,2,4,1,0,0,0,beca17564ef9a03d42ce9db4e303689fba3ffcc1,259108951.0,https://www.semanticscholar.org/paper/beca17564ef9a03d42ce9db4e303689fba3ffcc1,International Conference on Automated Software Engineering,2023.0,37.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145278906', 'name': 'R. Feldt'}, {'authorId': '2115515341', 'name': 'Sungmin Kang'}, {'authorId': '2118110297', 'name': 'Juyeon Yoon'}, {'authorId': '2147408161', 'name': 'Shin Yoo'}]",['Chalmers University of Technology'],['Sweden'],2023-06
2306.05182,Krishna Sri Ipsit Mantri,Krishna Sri Ipsit Mantri and Nevasini Sasikumar,Interactive Fashion Content Generation Using LLMs and Latent Diffusion Models,"Third Workshop on Ethical Considerations in Creative applications of
  Computer Vision (EC3V) at CVPR 2023. arXiv admin note: substantial text
  overlap with arXiv:2301.02110, arXiv:2112.10752 by other authors",,,,cs.CV cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Fashionable image generation aims to synthesize images of diverse fashion prevalent around the globe, helping fashion designers in real-time visualization by giving them a basic customized structure of how a specific design preference would look in real life and what further improvements can be made for enhanced customer satisfaction. Moreover, users can alone interact and generate fashionable images by just giving a few simple prompts. Recently, diffusion models have gained popularity as generative models owing to their flexibility and generation of realistic images from Gaussian noise. Latent diffusion models are a type of generative model that use diffusion processes to model the generation of complex data, such as images, audio, or text. They are called ""latent"" because they learn a hidden representation, or latent variable, of the data that captures its underlying structure. We propose a method exploiting the equivalence between diffusion models and energy-based models (EBMs) and suggesting ways to compose multiple probability distributions. We describe a pipeline on how our method can be used specifically for new fashionable outfit generation and virtual try-on using LLM-guided text-to-image generation. Our results indicate that using an LLM to refine the prompts to the latent diffusion model assists in generating globally creative and culturally diversified fashion styles and reducing bias. ","[{'version': 'v1', 'created': 'Mon, 15 May 2023 18:38:25 GMT'}]",2023-06-14,"[['Mantri', 'Krishna Sri Ipsit', ''], ['Sasikumar', 'Nevasini', '']]",0,0,2023-05-15,1,2,2,0,0,0,6a08b8f17002df3e4f695e0944728069633016c9,259108619.0,https://www.semanticscholar.org/paper/6a08b8f17002df3e4f695e0944728069633016c9,arXiv.org,2023.0,78.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2209207087', 'name': 'Krishna Sri Ipsit Mantri'}, {'authorId': '2219692593', 'name': 'Nevasini Sasikumar'}]",['PES University'],['India'],2023-05
2306.05323,Tommaso Mario Buonocore,"Claudio Crema, Tommaso Mario Buonocore, Silvia Fostinelli, Enea
  Parimbelli, Federico Verde, Cira Fundar\`o, Marina Manera, Matteo Cotta
  Ramusino, Marco Capelli, Alfredo Costa, Giuliano Binetti, Riccardo Bellazzi
  and Alberto Redolfi",Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The introduction of computerized medical records in hospitals has reduced burdensome operations like manual writing and information fetching. However, the data contained in medical records are still far underutilized, primarily because extracting them from unstructured textual medical records takes time and effort. Information Extraction, a subfield of Natural Language Processing, can help clinical practitioners overcome this limitation, using automated text-mining pipelines. In this work, we created the first Italian neuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to develop a Large Language Model for this task. Moreover, we conducted several experiments with three external independent datasets to implement an effective multicenter model, with overall F1-score 84.77%, Precision 83.16%, Recall 86.44%. The lessons learned are: (i) the crucial role of a consistent annotation process and (ii) a fine-tuning strategy that combines classical methods with a ""few-shot"" approach. This allowed us to establish methodological guidelines that pave the way for future implementations in this field and allow Italian hospitals to tap into important research opportunities. ","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 16:15:46 GMT'}]",2023-06-09,"[['Crema', 'Claudio', ''], ['Buonocore', 'Tommaso Mario', ''], ['Fostinelli', 'Silvia', ''], ['Parimbelli', 'Enea', ''], ['Verde', 'Federico', ''], ['Fundarò', 'Cira', ''], ['Manera', 'Marina', ''], ['Ramusino', 'Matteo Cotta', ''], ['Capelli', 'Marco', ''], ['Costa', 'Alfredo', ''], ['Binetti', 'Giuliano', ''], ['Bellazzi', 'Riccardo', ''], ['Redolfi', 'Alberto', '']]",0,0,2023-06-08,1,13,3,0,0,0,4ef3562c52ff0e1d1ffc978c4715edff5a586cda,259108396.0,https://www.semanticscholar.org/paper/4ef3562c52ff0e1d1ffc978c4715edff5a586cda,arXiv.org,2023.0,43.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40544464', 'name': 'C. Crema'}, {'authorId': '2168894378', 'name': 'T. M. Buonocore'}, {'authorId': '4921539', 'name': 'Silvia Fostinelli'}, {'authorId': '2135731778', 'name': 'Enea Parimbelli'}, {'authorId': '32640018', 'name': 'F. Verde'}, {'authorId': '47613139', 'name': 'C. Fundarò'}, {'authorId': '50698759', 'name': 'M. Manera'}, {'authorId': '6547064', 'name': 'M. C. Ramusino'}, {'authorId': '32351259', 'name': 'M. Capelli'}, {'authorId': '2107483370', 'name': 'A. Costa'}, {'authorId': '145103919', 'name': 'G. Binetti'}, {'authorId': '2206794409', 'name': 'Riccardo Bellazzi'}, {'authorId': '2462812', 'name': 'A. Redolfi'}]","['Istituto Auxologico Italiano', 'University of Pavia', 'Centro San Giovanni di Dio Fatebenefratelli', 'Istituti Clinici Scientifici Maugeri', 'University of Milan']",['Italy'],2023-06
2306.05424,Muhammad Maaz Mr,"Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad Shahbaz Khan",Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Conversation agents fueled by Large Language Models (LLMs) are providing a new way to interact with visual data. While there have been initial attempts for image-based conversation models, this work addresses the underexplored field of video-based conversation by introducing Video-ChatGPT. It is a multimodal model that merges a video-adapted visual encoder with a LLM. The model is capable of understanding and generating human-like conversations about videos. We introduce a new dataset of 100,000 video-instruction pairs used to train Video-ChatGPT acquired via manual and semi-automated pipeline that is easily scalable and robust to label noise. We also develop a quantiative evaluation framework for video-based dialogue models to objectively analyse the strengths and weaknesses of proposed models. Our code, models, instruction-sets and demo are released at https://github.com/mbzuai-oryx/Video-ChatGPT. ","[{'version': 'v1', 'created': 'Thu, 8 Jun 2023 17:59:56 GMT'}]",2023-06-09,"[['Maaz', 'Muhammad', ''], ['Rasheed', 'Hanoona', ''], ['Khan', 'Salman', ''], ['Khan', 'Fahad Shahbaz', '']]",1,1,2023-06-08,1,4,1,1,0,1,bf7025a2e5dbb3c09deae02a1aa98a256ca559e2,259108333.0,https://www.semanticscholar.org/paper/bf7025a2e5dbb3c09deae02a1aa98a256ca559e2,arXiv.org,2023.0,36.0,41.0,12.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32437679', 'name': 'Muhammad Maaz'}, {'authorId': '2097712964', 'name': 'H. Rasheed'}, {'authorId': '2111181927', 'name': 'Salman Khan'}, {'authorId': '2358803', 'name': 'F. Khan'}]",['Mohamed bin Zayed University of Artificial Intelligence'],['United Arab Emirates'],2023-06
2306.05431,Jieh-Sheng Lee,Jieh-Sheng Lee,LexGPT 0.1: pre-trained GPT-J models with Pile of Law,"10 pages and 2 figures. To be published in the Proceedings of the
  Seventeenth International Workshop on Juris-informatics (JURISIN 2023),
  hosted by JSAI International Symposia on AI 2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This research aims to build generative language models specialized for the legal domain. The manuscript presents the development of LexGPT models based on GPT-J models and pre-trained with Pile of Law. The foundation model built in this manuscript is the initial step for the development of future applications in the legal domain, such as further training with reinforcement learning from human feedback. Another objective of this manuscript is to assist legal professionals in utilizing language models through the ``No Code'' approach. By fine-tuning models with specialized data and without modifying any source code, legal professionals can create custom language models for downstream tasks with minimum effort and technical knowledge. The downstream task in this manuscript is to turn a LexGPT model into a classifier, although the performance is notably lower than the state-of-the-art result. How to enhance downstream task performance without modifying the model or its source code is a research topic for future exploration. ","[{'version': 'v1', 'created': 'Mon, 5 Jun 2023 08:42:59 GMT'}]",2023-06-12,"[['Lee', 'Jieh-Sheng', '']]",0,1,2023-06-05,1,1,1,0,0,0,6f2b45846939267457abf13f2bc8618d23c7a2a4,259129689.0,https://www.semanticscholar.org/paper/6f2b45846939267457abf13f2bc8618d23c7a2a4,arXiv.org,2023.0,21.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108319166', 'name': 'Jieh-Sheng Lee'}]",['National Yang Ming Chiao Tung University'],['Taiwan'],2023-06
2306.05432,Raul Monteiro,Raul Monteiro and Diogo Pernes,Towards End-to-end Speech-to-text Summarization,"Accepted to the 26th International Conference of Text, Speech and
  Dialogue (TSD2023)",,,,cs.CL cs.AI cs.LG eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Speech-to-text (S2T) summarization is a time-saving technique for filtering and keeping up with the broadcast news uploaded online on a daily basis. The rise of large language models from deep learning with impressive text generation capabilities has placed the research focus on summarization systems that produce paraphrased compact versions of the document content, also known as abstractive summaries. End-to-end (E2E) modelling of S2T abstractive summarization is a promising approach that offers the possibility of generating rich latent representations that leverage non-verbal and acoustic information, as opposed to the use of only linguistic information from automatically generated transcripts in cascade systems. However, the few literature on E2E modelling of this task fails on exploring different domains, namely broadcast news, which is challenging domain where large and diversified volumes of data are presented to the user every day. We model S2T summarization both with a cascade and an E2E system for a corpus of broadcast news in French. Our novel E2E model leverages external data by resorting to transfer learning from a pre-trained T2T summarizer. Experiments show that both our cascade and E2E abstractive summarizers are stronger than an extractive baseline. However, the performance of the E2E model still lies behind the cascade one, which is object of an extensive analysis that includes future directions to close that gap. ","[{'version': 'v1', 'created': 'Tue, 6 Jun 2023 15:22:16 GMT'}]",2023-06-12,"[['Monteiro', 'Raul', ''], ['Pernes', 'Diogo', '']]",0,0,2023-06-06,1,2,4,0,0,0,39ba38fbe7e1dc4c1af07c160e46b0a655d7133e,259129860.0,https://www.semanticscholar.org/paper/39ba38fbe7e1dc4c1af07c160e46b0a655d7133e,"International Conference on Text, Speech and Dialogue",2023.0,26.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219862725', 'name': 'Raul Monteiro'}, {'authorId': '2022615', 'name': 'Diogo Pernes'}]","['University of Porto', 'University of Lisbon', 'Priberam, Alameda D. Afonso Henriques 41, 1000-123 Lisboa']",['Portugal'],2023-06
2306.05537,Guan Wang,"Guan Wang, Weihua Li, Edmund M-K. Lai, Quan Bai",AaKOS: Aspect-adaptive Knowledge-based Opinion Summarization,"21 pages, 4 figures, 7 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The rapid growth of information on the Internet has led to an overwhelming amount of opinions and comments on various activities, products, and services. This makes it difficult and time-consuming for users to process all the available information when making decisions. Text summarization, a Natural Language Processing (NLP) task, has been widely explored to help users quickly retrieve relevant information by generating short and salient content from long or multiple documents. Recent advances in pre-trained language models, such as ChatGPT, have demonstrated the potential of Large Language Models (LLMs) in text generation. However, LLMs require massive amounts of data and resources and are challenging to implement as offline applications. Furthermore, existing text summarization approaches often lack the ``adaptive"" nature required to capture diverse aspects in opinion summarization, which is particularly detrimental to users with specific requirements or preferences. In this paper, we propose an Aspect-adaptive Knowledge-based Opinion Summarization model for product reviews, which effectively captures the adaptive nature required for opinion summarization. The model generates aspect-oriented summaries given a set of reviews for a particular product, efficiently providing users with useful information on specific aspects they are interested in, ensuring the generated summaries are more personalized and informative. Extensive experiments have been conducted using real-world datasets to evaluate the proposed model. The results demonstrate that our model outperforms state-of-the-art approaches and is adaptive and efficient in generating summaries that focus on particular aspects, enabling users to make well-informed decisions and catering to their diverse interests and preferences. ","[{'version': 'v1', 'created': 'Fri, 26 May 2023 03:44:35 GMT'}]",2023-06-12,"[['Wang', 'Guan', ''], ['Li', 'Weihua', ''], ['Lai', 'Edmund M-K.', ''], ['Bai', 'Quan', '']]",1,1,2023-05-26,1,4,1,1,0,1,c5aeb6358b9ba7e02e3149428e550fa147cf8ddc,259129368.0,https://www.semanticscholar.org/paper/c5aeb6358b9ba7e02e3149428e550fa147cf8ddc,arXiv.org,2023.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152584752', 'name': 'Guan-Hua Wang'}, {'authorId': '2187784939', 'name': 'Weihua Li'}, {'authorId': '2075378060', 'name': 'E. Lai'}, {'authorId': '71203570', 'name': 'Quan-wei Bai'}]","['Auckland University of Technology', 'University of Tasmania']","['New Zealand', 'Australia']",2023-05
2306.05816,Takashi Koide,"Takashi Koide, Naoki Fukushi, Hiroki Nakano, Daiki Chiba",Detecting Phishing Sites Using ChatGPT,,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  The rise of large language models (LLMs) has had a significant impact on various domains, including natural language processing and artificial intelligence. While LLMs such as ChatGPT have been extensively researched for tasks such as code generation and text synthesis, their application in detecting malicious web content, particularly phishing sites, has been largely unexplored. To combat the rising tide of automated cyber attacks facilitated by LLMs, it is imperative to automate the detection of malicious web content, which requires approaches that leverage the power of LLMs to analyze and classify phishing sites. In this paper, we propose a novel method that utilizes ChatGPT to detect phishing sites. Our approach involves leveraging a web crawler to gather information from websites and generate prompts based on this collected data. This approach enables us to detect various phishing sites without the need for fine-tuning machine learning models and identify social engineering techniques from the context of entire websites and URLs. To evaluate the performance of our proposed method, we conducted experiments using a dataset. The experimental results using GPT-4 demonstrated promising performance, with a precision of 98.3% and a recall of 98.4%. Comparative analysis between GPT-3.5 and GPT-4 revealed an enhancement in the latter's capability to reduce false negatives. These findings not only highlight the potential of LLMs in efficiently identifying phishing sites but also have significant implications for enhancing cybersecurity measures and protecting users from the dangers of online fraudulent activities. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 11:30:08 GMT'}]",2023-06-12,"[['Koide', 'Takashi', ''], ['Fukushi', 'Naoki', ''], ['Nakano', 'Hiroki', ''], ['Chiba', 'Daiki', '']]",1,1,2023-06-09,1,4,1,3,0,3,838b2f66aa07dd97a473be59921e2cd7d39461e2,259129611.0,https://www.semanticscholar.org/paper/838b2f66aa07dd97a473be59921e2cd7d39461e2,arXiv.org,2023.0,42.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1799400183', 'name': 'Takashi Koide'}, {'authorId': '2099859973', 'name': 'Naoki Fukushi'}, {'authorId': '2067744577', 'name': 'Hiroki Nakano'}, {'authorId': '2455751', 'name': 'Daiki Chiba'}]",['The University of Tokyo'],['Japan'],2023-06
2306.05827,Rabee AL-Qasem,"Rabee Qasem, Banan Tantour, Mohammed Maree",Towards the Exploitation of LLM-based Chatbot for Providing Legal Support to Palestinian Cooperatives,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  With the ever-increasing utilization of natural language processing (NLP), we started to witness over the past few years a significant transformation in our interaction with legal texts. This technology has advanced the analysis and enhanced the understanding of complex legal terminology and contexts. The development of recent large language models (LLMs), particularly ChatGPT, has also introduced a revolutionary contribution to the way that legal texts can be processed and comprehended. In this paper, we present our work on a cooperative-legal question-answering LLM-based chatbot, where we developed a set of legal questions about Palestinian cooperatives, associated with their regulations and compared the auto-generated answers by the chatbot to their correspondences that are designed by a legal expert. To evaluate the proposed chatbot, we have used 50 queries generated by the legal expert and compared the answers produced by the chart to their relevance judgments. Finding demonstrated that an overall accuracy rate of 82% has been achieved when answering the queries, while exhibiting an F1 score equivalent to 79%. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 11:57:57 GMT'}]",2023-06-12,"[['Qasem', 'Rabee', ''], ['Tantour', 'Banan', ''], ['Maree', 'Mohammed', '']]",1,1,2023-06-09,1,3,1,1,0,1,2e541d7579bfd91892d8dc901aa48b1276a5ec1b,259129504.0,https://www.semanticscholar.org/paper/2e541d7579bfd91892d8dc901aa48b1276a5ec1b,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219861650', 'name': 'Rabee Qasem'}, {'authorId': '2219861646', 'name': 'Banan Tantour'}, {'authorId': '145190214', 'name': 'Mohammed Maree'}]","['Arab American University', 'Department of Information Technology, Biotechnology and Science and Technology']","['India', 'Palestinian Territory']",2023-06
2306.06264,Pouya Pezeshkpour,Pouya Pezeshkpour,Measuring and Modifying Factual Knowledge in Large Language Models,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) store an extensive amount of factual knowledge obtained from vast collections of text. To effectively utilize these models for downstream tasks, it is crucial to have reliable methods for measuring their knowledge. However, existing approaches for knowledge measurement have certain limitations, and despite recent efforts, they fail to provide accurate measurements and the necessary insights for modifying the knowledge within LLMs. In this work, we employ information theory-based measurements to provide a framework estimating the factual knowledge contained within large language models. More specifically, we measure knowledge by analyzing the LLM's prediction probability distribution before and after instilling the target knowledge, employing metrics such as entropy and KL-divergence. Introducing our metrics, we first assess their accuracy in comparison to previous ranking-based methods, surpassing them by over $35\%$ in a synthetic experiment. Then, we explore two prominent methods of knowledge instillation, discovering that LLMs exhibit limitations in capturing new knowledge under specific circumstances for one of these methods. Lastly, we demonstrate the applicability of our methods in extracting unlearned and mislearned facts in LLMs through their application to in-context learning. We make code and data for all methods and experiments in this paper publicly available. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 21:25:48 GMT'}]",2023-06-13,"[['Pezeshkpour', 'Pouya', '']]",0,0,2023-06-09,1,1,2,0,0,0,5e096f65139e789fd3aa41de7e11bc9c04da79d5,259138387.0,https://www.semanticscholar.org/paper/5e096f65139e789fd3aa41de7e11bc9c04da79d5,arXiv.org,2023.0,22.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1713436', 'name': 'Pouya Pezeshkpour'}]",['Laboratori Guglielmo Marconi (Italy)'],['Italy'],2023-06
2306.06297,"Micha\""el Antonie van Wyk","M.A. van Wyk, M. Bekker, X.L. Richards, K.J. Nixon",Protect Your Prompts: Protocols for IP Protection in LLM Applications,"5 pages, 2 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  With the rapid adoption of AI in the form of large language models (LLMs), the potential value of carefully engineered prompts has become significant. However, to realize this potential, prompts should be tradable on an open market. Since prompts are, at present, generally economically non-excludable, by virtue of their nature as text, no general competitive market has yet been established. This note discusses two protocols intended to provide protection of prompts, elevating their status as intellectual property, thus confirming the intellectual property rights of prompt engineers, and potentially supporting the flourishing of an open market for LLM prompts. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 23:23:26 GMT'}]",2023-06-13,"[['van Wyk', 'M. A.', ''], ['Bekker', 'M.', ''], ['Richards', 'X. L.', ''], ['Nixon', 'K. J.', '']]",0,0,2023-06-09,1,4,2,0,0,0,08fd45ac85916b95f734cc75af8660cff73c33ca,259137775.0,https://www.semanticscholar.org/paper/08fd45ac85916b95f734cc75af8660cff73c33ca,arXiv.org,2023.0,10.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '1520369834', 'name': 'M. V. Wyk'}, {'authorId': '47532429', 'name': 'M. Bekker'}, {'authorId': '2219923932', 'name': 'X. L. Richards'}, {'authorId': '143758334', 'name': 'K. Nixon'}]",['University of the Witwatersrand'],['South Africa'],2023-06
2306.06331,Xuan-Quy Dao,Xuan-Quy Dao and Ngoc-Bich Le,Investigating the Effectiveness of ChatGPT in Mathematical Reasoning and Problem Solving: Evidence from the Vietnamese National High School Graduation Examination,"17 pages, 13 images",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  This study offers a complete analysis of ChatGPT's mathematics abilities in responding to multiple-choice questions for the Vietnamese National High School Graduation Examination (VNHSGE) on a range of subjects and difficulty levels. The dataset included 250 questions divided into four levels: knowledge (K), comprehension (C), application (A), and high application (H), and it included ten themes that covered diverse mathematical concepts. The outcomes demonstrate that ChatGPT's performance varies depending on the difficulty level and subject. It performed best on questions at Level (K), with an accuracy rate of $83\%$; but, as the difficulty level rose, it scored poorly, with an accuracy rate of $10\%$. The study has also shown that ChatGPT significantly succeeds in providing responses to questions on subjects including exponential and logarithmic functions, geometric progression, and arithmetic progression. The study found that ChatGPT had difficulty correctly answering questions on topics including derivatives and applications, spatial geometry, and Oxyz spatial calculus. Additionally, this study contrasted ChatGPT outcomes with Vietnamese students in VNHSGE and in other math competitions. ChatGPT dominated in the SAT Math competition with a success rate of $70\%$, followed by VNHSGE mathematics ($58.8\%)$. However, its success rates were lower on other exams, such as AP Statistics, the GRE Quantitative, AMC 10, AMC 12, and AP Calculus BC. These results suggest that ChatGPT has the potential to be an effective teaching tool for mathematics, but more work is needed to enhance its handling of graphical data and address the challenges presented by questions that are getting more challenging. ","[{'version': 'v1', 'created': 'Sat, 10 Jun 2023 02:01:02 GMT'}, {'version': 'v2', 'created': 'Wed, 12 Jul 2023 01:56:52 GMT'}]",2023-07-13,"[['Dao', 'Xuan-Quy', ''], ['Le', 'Ngoc-Bich', '']]",1,1,2023-06-10,2,2,2,1,0,1,d8e924cd982adef0944634044c8ed2e5c0e65c4c,259137620.0,https://www.semanticscholar.org/paper/d8e924cd982adef0944634044c8ed2e5c0e65c4c,arXiv.org,2023.0,33.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '2134798816', 'name': 'Xuan-Quy Dao'}, {'authorId': '2082348114', 'name': 'Ngoc-Bich Le'}]","['Vietnam National University Ho Chi Minh City', 'Eastern International University']",['Vietnam'],2023-06
2306.06548,Jerome Han,"Simon J. Han, Keith Ransom, Andrew Perfors, Charles Kemp",Inductive reasoning in humans and large language models,"61 pages, 5 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The impressive recent performance of large language models has led many to wonder to what extent they can serve as models of general intelligence or are similar to human cognition. We address this issue by applying GPT-3.5 and GPT-4 to a classic problem in human inductive reasoning known as property induction. Over two experiments, we elicit human judgments on a range of property induction tasks spanning multiple domains. Although GPT-3.5 struggles to capture many aspects of human behaviour, GPT-4 is much more successful: for the most part, its performance qualitatively matches that of humans, and the only notable exception is its failure to capture the phenomenon of premise non-monotonicity. Our work demonstrates that property induction allows for interesting comparisons between human and machine intelligence and provides two large datasets that can serve as benchmarks for future work in this vein. ","[{'version': 'v1', 'created': 'Sun, 11 Jun 2023 00:23:25 GMT'}, {'version': 'v2', 'created': 'Thu, 3 Aug 2023 15:26:55 GMT'}, {'version': 'v3', 'created': 'Fri, 4 Aug 2023 01:36:56 GMT'}]",2023-08-07,"[['Han', 'Simon J.', ''], ['Ransom', 'Keith', ''], ['Perfors', 'Andrew', ''], ['Kemp', 'Charles', '']]",0,1,2023-06-11,3,4,2,2,0,2,1727c04a73ca205bf9fbfd56466f8e0da6d11433,259138322.0,https://www.semanticscholar.org/paper/1727c04a73ca205bf9fbfd56466f8e0da6d11433,Cognitive Systems Research,2023.0,75.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2186245005', 'name': 'Simon J. Han'}, {'authorId': '2774072', 'name': 'Keith Ransom'}, {'authorId': '2005906112', 'name': 'Andrew Perfors'}, {'authorId': '145300792', 'name': 'Charles Kemp'}]",['University of Melbourne'],['Australia'],2023-06
2306.06688,Jiacheng Ye,"Jiacheng Ye, Xijia Tao, Lingpeng Kong",Language Versatilists vs. Specialists: An Empirical Revisiting on Multilingual Transfer Ability,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Multilingual transfer ability, which reflects how well the models fine-tuned on one source language can be applied to other languages, has been well studied in multilingual pre-trained models (e.g., BLOOM). However, such ability has not been investigated for English-centric models (e.g., LLaMA). To fill this gap, we study the following research questions. First, does multilingual transfer ability exist in English-centric models and how does it compare with multilingual pretrained models? Second, does it only appears when English is the source language for the English-centric model? Third, how does it vary in different tasks? We take multilingual reasoning ability as our focus and conduct extensive experiments across four types of reasoning tasks. We find that the multilingual pretrained model does not always outperform an English-centric model. Furthermore, English appears to be a less suitable source language, and the choice of source language becomes less important when the English-centric model scales up. In addition, different types of tasks exhibit different multilingual transfer abilities. These findings demonstrate that English-centric models not only possess multilingual transfer ability but may even surpass the transferability of multilingual pretrained models if well-trained. By showing the strength and weaknesses, the experiments also provide valuable insights into enhancing multilingual reasoning abilities for the English-centric models. ","[{'version': 'v1', 'created': 'Sun, 11 Jun 2023 14:03:09 GMT'}]",2023-06-13,"[['Ye', 'Jiacheng', ''], ['Tao', 'Xijia', ''], ['Kong', 'Lingpeng', '']]",0,0,2023-06-11,1,3,2,2,2,0,a8b5a20e3a983d96f9dea6fc38e77b155e7bd94f,259137398.0,https://www.semanticscholar.org/paper/a8b5a20e3a983d96f9dea6fc38e77b155e7bd94f,arXiv.org,2023.0,46.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '65846898', 'name': 'Jiacheng Ye'}, {'authorId': '2199259358', 'name': 'Xijia Tao'}, {'authorId': '47648549', 'name': 'Lingpeng Kong'}]",['University of Hong Kong'],['Hong Kong'],2023-06
2306.06891,Soochan Lee,Soochan Lee and Gunhee Kim,Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models,"ACL 2023 (short, findings)",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Generating intermediate steps, or Chain of Thought (CoT), is an effective way to significantly improve language models' (LM) multi-step reasoning capability. However, the CoT lengths can grow rapidly with the problem complexity, easily exceeding the maximum context size. Instead of increasing the context limit, which has already been heavily investigated, we explore an orthogonal direction: making LMs divide a problem into multiple contexts. We propose a new inference framework, called Recursion of Thought (RoT), which introduces several special tokens that the models can output to trigger context-related operations. Extensive experiments with multiple architectures including GPT-3 show that RoT dramatically improves LMs' inference capability to solve problems, whose solution consists of hundreds of thousands of tokens. ","[{'version': 'v1', 'created': 'Mon, 12 Jun 2023 06:34:16 GMT'}]",2023-06-13,"[['Lee', 'Soochan', ''], ['Kim', 'Gunhee', '']]",0,1,2023-06-12,1,2,2,1,0,1,ef5f7cd21b5d34797636239a7b9c8ba6af440aab,259137462.0,https://www.semanticscholar.org/paper/ef5f7cd21b5d34797636239a7b9c8ba6af440aab,Annual Meeting of the Association for Computational Linguistics,2023.0,20.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31273037', 'name': 'Soochan Lee'}, {'authorId': '70308241', 'name': 'Gunhee Kim'}]",['Seoul National University'],['South Korea'],2023-06
2306.06892,Aravind Krishnan,"Aravind Krishnan, Jesujoba Alabi, Dietrich Klakow",On the N-gram Approximation of Pre-trained Language Models,Accepted at Interspeech 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large pre-trained language models (PLMs) have shown remarkable performance across various natural language understanding (NLU) tasks, particularly in low-resource settings. Nevertheless, their potential in Automatic Speech Recognition (ASR) remains largely unexplored. This study investigates the potential usage of PLMs for language modelling in ASR. We compare the application of large-scale text sampling and probability conversion for approximating GPT-2 into an n-gram model. Furthermore, we introduce a vocabulary-restricted decoding method for random sampling, and evaluate the effects of domain difficulty and data size on the usability of generated text. Our findings across eight domain-specific corpora support the use of sampling-based approximation and show that interpolating with a large sampled corpus improves test perplexity over a baseline trigram by 15%. Our vocabulary-restricted decoding method pushes this improvement further by 5% in domain-specific settings. ","[{'version': 'v1', 'created': 'Mon, 12 Jun 2023 06:42:08 GMT'}]",2023-06-13,"[['Krishnan', 'Aravind', ''], ['Alabi', 'Jesujoba', ''], ['Klakow', 'Dietrich', '']]",0,1,2023-06-12,1,3,1,1,1,0,821d918fd7c316a1d48579979fa7bde2f7a63c50,259138393.0,https://www.semanticscholar.org/paper/821d918fd7c316a1d48579979fa7bde2f7a63c50,Interspeech,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064366683', 'name': 'Aravind Krishnan'}, {'authorId': '122367036', 'name': 'Jesujoba Oluwadara Alabi'}, {'authorId': '2561225', 'name': 'D. Klakow'}]","['Saarland Informatics Campus, Germany', 'German Research Centre for Artificial Intelligence', 'Saarland University']",['Germany'],2023-06
2306.07486,Minghan Wang,"Hao Yang, Min Zhang, Shimin Tao, Minghan Wang, Daimeng Wei, Yanfei
  Jiang",Knowledge-Prompted Estimator: A Novel Approach to Explainable Machine Translation Assessment,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Cross-lingual Machine Translation (MT) quality estimation plays a crucial role in evaluating translation performance. GEMBA, the first MT quality assessment metric based on Large Language Models (LLMs), employs one-step prompting to achieve state-of-the-art (SOTA) in system-level MT quality estimation; however, it lacks segment-level analysis. In contrast, Chain-of-Thought (CoT) prompting outperforms one-step prompting by offering improved reasoning and explainability. In this paper, we introduce Knowledge-Prompted Estimator (KPE), a CoT prompting method that combines three one-step prompting techniques, including perplexity, token-level similarity, and sentence-level similarity. This method attains enhanced performance for segment-level estimation compared with previous deep learning models and one-step prompting approaches. Furthermore, supplementary experiments on word-level visualized alignment demonstrate that our KPE method significantly improves token alignment compared with earlier models and provides better interpretability for MT quality estimation. Code will be released upon publication. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 01:18:32 GMT'}]",2023-06-14,"[['Yang', 'Hao', ''], ['Zhang', 'Min', ''], ['Tao', 'Shimin', ''], ['Wang', 'Minghan', ''], ['Wei', 'Daimeng', ''], ['Jiang', 'Yanfei', '']]",0,0,2023-06-13,1,6,1,0,0,0,d1bd7ae97588eccfbcd31ffce4fc924d12a5de4d,259145071.0,https://www.semanticscholar.org/paper/d1bd7ae97588eccfbcd31ffce4fc924d12a5de4d,arXiv.org,2023.0,20.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2115537856', 'name': 'Hao Yang'}, {'authorId': '40093418', 'name': 'Min Zhang'}, {'authorId': '1978838820', 'name': 'Shimin Tao'}, {'authorId': '1628331115', 'name': 'Minghan Wang'}, {'authorId': '8884457', 'name': 'Daimeng Wei'}, {'authorId': '2203256236', 'name': 'Yanfei Jiang'}]",['Laboratori Guglielmo Marconi (Italy)'],['Italy'],2023-06
2306.07591,Raz Lapid,"Raz Lapid, Moshe Sipper",I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models,,"Proceedings of the European Conference on Machine Learning and
  Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD 2023)",,,cs.CV cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Modern image-to-text systems typically adopt the encoder-decoder framework, which comprises two main components: an image encoder, responsible for extracting image features, and a transformer-based decoder, used for generating captions. Taking inspiration from the analysis of neural networks' robustness against adversarial perturbations, we propose a novel gray-box algorithm for creating adversarial examples in image-to-text models. Unlike image classification tasks that have a finite set of class labels, finding visually similar adversarial examples in an image-to-text task poses greater challenges because the captioning system allows for a virtually infinite space of possible captions. In this paper, we present a gray-box adversarial attack on image-to-text, both untargeted and targeted. We formulate the process of discovering adversarial perturbations as an optimization problem that uses only the image-encoder component, meaning the proposed attack is language-model agnostic. Through experiments conducted on the ViT-GPT2 model, which is the most-used image-to-text model in Hugging Face, and the Flickr30k dataset, we demonstrate that our proposed attack successfully generates visually similar adversarial examples, both with untargeted and targeted captions. Notably, our attack operates in a gray-box manner, requiring no knowledge about the decoder module. We also show that our attacks fool the popular open-source platform Hugging Face. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 07:35:28 GMT'}, {'version': 'v2', 'created': 'Wed, 12 Jul 2023 09:45:54 GMT'}, {'version': 'v3', 'created': 'Wed, 19 Jul 2023 12:04:59 GMT'}]",2023-07-20,"[['Lapid', 'Raz', ''], ['Sipper', 'Moshe', '']]",0,1,2023-06-13,3,2,2,1,1,0,16ee0769691513af53c58d610aca0f9ac37ea189,259144914.0,https://www.semanticscholar.org/paper/16ee0769691513af53c58d610aca0f9ac37ea189,arXiv.org,2023.0,40.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2173526660', 'name': 'Raz Lapid'}, {'authorId': '1707878', 'name': 'M. Sipper'}]","['DeepKeep, Tel-Aviv, Israel', 'Ben-Gurion University of the Negev']",['Israel'],2023-06
2306.07629,Sehoon Kim,"Sehoon Kim, Coleman Hooper, Amir Gholami, Zhen Dong, Xiuyu Li, Sheng
  Shen, Michael W. Mahoney, Kurt Keutzer",SqueezeLLM: Dense-and-Sparse Quantization,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative Large Language Models (LLMs) have demonstrated remarkable results for a wide range of tasks. However, deploying these models for inference has been a significant challenge due to their unprecedented resource requirements. This has forced existing deployment frameworks to use multi-GPU inference pipelines, which are often complex and costly, or to use smaller and less performant models. In this work, we demonstrate that the main bottleneck for generative inference with LLMs is memory bandwidth, rather than compute, specifically for single batch inference. While quantization has emerged as a promising solution by representing model weights with reduced precision, previous efforts have often resulted in notable performance degradation. To address this, we introduce SqueezeLLM, a post-training quantization framework that not only enables lossless compression to ultra-low precisions of up to 3-bit, but also achieves higher quantization performance under the same memory constraint. Our framework incorporates two novel ideas: (i) sensitivity-based non-uniform quantization, which searches for the optimal bit precision assignment based on second-order information; and (ii) the Dense-and-Sparse decomposition that stores outliers and sensitive weight values in an efficient sparse format. When applied to the LLaMA models, our 3-bit quantization significantly reduces the perplexity gap from the FP16 baseline by up to 2.1x as compared to the state-of-the-art methods with the same memory requirement. Furthermore, when deployed on an A6000 GPU, our quantized models achieve up to 2.3x speedup compared to the baseline. Our code is open-sourced and available online. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 08:57:54 GMT'}, {'version': 'v2', 'created': 'Wed, 4 Oct 2023 22:40:01 GMT'}]",2023-10-06,"[['Kim', 'Sehoon', ''], ['Hooper', 'Coleman', ''], ['Gholami', 'Amir', ''], ['Dong', 'Zhen', ''], ['Li', 'Xiuyu', ''], ['Shen', 'Sheng', ''], ['Mahoney', 'Michael W.', ''], ['Keutzer', 'Kurt', '']]",0,0,2023-06-13,2,8,2,1,1,0,3b7ef6f9f27e33e6a4e3bfac90dcb01ab09718bc,259144954.0,https://www.semanticscholar.org/paper/3b7ef6f9f27e33e6a4e3bfac90dcb01ab09718bc,arXiv.org,2023.0,93.0,15.0,4.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109586102', 'name': 'Sehoon Kim'}, {'authorId': '2029486869', 'name': 'Coleman Hooper'}, {'authorId': '10419477', 'name': 'A. Gholami'}, {'authorId': '143879884', 'name': 'Zhen Dong'}, {'authorId': '2141625113', 'name': 'Xiuyu Li'}, {'authorId': '2191455', 'name': 'Sheng Shen'}, {'authorId': '1717098', 'name': 'Michael W. Mahoney'}, {'authorId': '1732330', 'name': 'K. Keutzer'}]","['University of British Columbia', 'Queensland University of Technology']","['Canada', 'Australia']",2023-06
2306.07799,Dongqi Pu,"Dongqi Pu, Vera Demberg",ChatGPT vs Human-authored Text: Insights into Controllable Text Summarization and Sentence Style Transfer,ACL-SRW 2023,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large-scale language models, like ChatGPT, have garnered significant media attention and stunned the public with their remarkable capacity for generating coherent text from short natural language prompts. In this paper, we aim to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, with respect to ChatGPT's ability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal). Additionally, we evaluate the faithfulness of the generated text, and compare the model's performance with human-authored texts. Our findings indicate that the stylistic variations produced by humans are considerably larger than those demonstrated by ChatGPT, and the generated texts diverge from human samples in several characteristics, such as the distribution of word types. Moreover, we observe that ChatGPT sometimes incorporates factual errors or hallucinations when adapting the text to suit a specific style. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 14:21:35 GMT'}]",2023-06-14,"[['Pu', 'Dongqi', ''], ['Demberg', 'Vera', '']]",1,1,2023-06-13,1,2,3,1,0,1,fe50667e1bea4c6f63909b90986231240818c1d6,259145296.0,https://www.semanticscholar.org/paper/fe50667e1bea4c6f63909b90986231240818c1d6,Annual Meeting of the Association for Computational Linguistics,2023.0,86.0,14.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2167123387', 'name': 'Dongqi Pu'}, {'authorId': '2869436', 'name': 'Vera Demberg'}]",['Saarland University'],['Germany'],2023-06
2306.07875,Dake Zhang,Dake Zhang and Ronak Pradeep,ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support Lateral Reading,,,,,cs.IR cs.AI cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the rapid growth and spread of online misinformation, people need tools to help them evaluate the credibility and accuracy of online information. Lateral reading, a strategy that involves cross-referencing information with multiple sources, may be an effective approach to achieving this goal. In this paper, we present ReadProbe, a tool to support lateral reading, powered by generative large language models from OpenAI and the Bing search engine. Our tool is able to generate useful questions for lateral reading, scour the web for relevant documents, and generate well-attributed answers to help people better evaluate online information. We made a web-based application to demonstrate how ReadProbe can help reduce the risk of being misled by false information. The code is available at https://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won the first prize in a national AI misinformation hackathon. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 16:10:10 GMT'}]",2023-06-14,"[['Zhang', 'Dake', ''], ['Pradeep', 'Ronak', '']]",0,0,2023-06-13,1,2,4,0,0,0,8dec602dcd4df3db500ad36d01fffd53ec92701a,259145284.0,https://www.semanticscholar.org/paper/8dec602dcd4df3db500ad36d01fffd53ec92701a,arXiv.org,2023.0,21.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2160876279', 'name': 'Dake Zhang'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}]",['University of Waterloo'],['Canada'],2023-06
2306.07933,Lina Bariah,"Lina Bariah and Hang Zou and Qiyang Zhao and Belkacem Mouhouche and
  Faouzi Bader and Merouane Debbah",Understanding Telecom Language Through Large Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the 3rd Generation Partnership Project (3GPP) standard working groups. We consider training the selected models on 3GPP technical documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP working groups. The distilled BERT model with around 50% less parameters achieves similar performance as others. This corroborates that fine-tuning pretrained LLM can effectively identify the categories of Telecom language. The developed framework shows a stepping stone towards realizing intent-driven and self-evolving wireless networks from Telecom languages, and paves the way for the implementation of generative AI in the Telecom domain. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 15:44:41 GMT'}]",2023-06-14,"[['Bariah', 'Lina', ''], ['Zou', 'Hang', ''], ['Zhao', 'Qiyang', ''], ['Mouhouche', 'Belkacem', ''], ['Bader', 'Faouzi', ''], ['Debbah', 'Merouane', '']]",0,1,2023-06-09,1,6,2,1,1,0,6a3ed569d47b4ea08aca4f69ec7da5e8d87734b0,259145106.0,https://www.semanticscholar.org/paper/6a3ed569d47b4ea08aca4f69ec7da5e8d87734b0,arXiv.org,2023.0,22.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2579970', 'name': 'Lina Bariah'}, {'authorId': '2180261014', 'name': 'Han Zou'}, {'authorId': '40538512', 'name': 'Qiyang Zhao'}, {'authorId': '1968720', 'name': 'B. Mouhouche'}, {'authorId': '1691061', 'name': 'F. Bader'}, {'authorId': '145118318', 'name': 'M. Debbah'}]",['Technology Innovation Institute'],['United Arab Emirates'],2023-06
2306.07941,Itzik Malkiel,"Itzik Malkiel, Uri Alon, Yakir Yehuda, Shahar Keren, Oren Barkan, Royi
  Ronen, Noam Koenigstein",GPT-Calls: Enhancing Call Segmentation and Tagging by Generating Synthetic Conversations via Large Language Models,,,,,cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Transcriptions of phone calls are of significant value across diverse fields, such as sales, customer service, healthcare, and law enforcement. Nevertheless, the analysis of these recorded conversations can be an arduous and time-intensive process, especially when dealing with extended or multifaceted dialogues. In this work, we propose a novel method, GPT-distilled Calls Segmentation and Tagging (GPT-Calls), for efficient and accurate call segmentation and topic extraction. GPT-Calls is composed of offline and online phases. The offline phase is applied once to a given list of topics and involves generating a distribution of synthetic sentences for each topic using a GPT model and extracting anchor vectors. The online phase is applied to every call separately and scores the similarity between the transcripted conversation and the topic anchors found in the offline phase. Then, time domain analysis is applied to the similarity scores to group utterances into segments and tag them with topics. The proposed paradigm provides an accurate and efficient method for call segmentation and topic extraction that does not require labeled data, thus making it a versatile approach applicable to various domains. Our algorithm operates in production under Dynamics 365 Sales Conversation Intelligence, and our research is based on real sales conversations gathered from various Dynamics 365 Sales tenants. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 15:47:22 GMT'}]",2023-06-14,"[['Malkiel', 'Itzik', ''], ['Alon', 'Uri', ''], ['Yehuda', 'Yakir', ''], ['Keren', 'Shahar', ''], ['Barkan', 'Oren', ''], ['Ronen', 'Royi', ''], ['Koenigstein', 'Noam', '']]",0,1,2023-06-09,1,7,2,0,0,0,34a46d7988ea4d0014989f441d38993ee4de095f,259145354.0,https://www.semanticscholar.org/paper/34a46d7988ea4d0014989f441d38993ee4de095f,arXiv.org,2023.0,13.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46252132', 'name': 'Itzik Malkiel'}, {'authorId': '47051926', 'name': 'Uri Alon'}, {'authorId': '2191186315', 'name': 'Yakir Yehuda'}, {'authorId': '48660908', 'name': 'Shahar Keren'}, {'authorId': '48797862', 'name': 'Oren Barkan'}, {'authorId': '2445296', 'name': 'Royi Ronen'}, {'authorId': '1683070', 'name': 'Noam Koenigstein'}]","['Tel Aviv University', 'The Open University']","['United Kingdom', 'Israel']",2023-06
2306.07951,Ricardo Dominguez-Olmedo,"Ricardo Dominguez-Olmedo, Moritz Hardt, Celestine Mendler-D\""unner",Questioning the Survey Responses of Large Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As large language models increase in capability, researchers have started to conduct surveys of all kinds on these models with varying scientific motivations. In this work, we examine what we can learn from a model's survey responses on the basis of the well-established American Community Survey (ACS) by the U.S. Census Bureau. Evaluating more than a dozen different models, varying in size from a few hundred million to ten billion parameters, hundreds of thousands of times each on questions from the ACS, we systematically establish two dominant patterns. First, smaller models have a significant position and labeling bias, for example, towards survey responses labeled with the letter ""A"". This A-bias diminishes, albeit slowly, as model size increases. Second, when adjusting for this labeling bias through randomized answer ordering, models still do not trend toward US population statistics or those of any cognizable population. Rather, models across the board trend toward uniformly random aggregate statistics over survey responses. This pattern is robust to various different ways of prompting the model, including what is the de-facto standard. Our findings demonstrate that aggregate statistics of a language model's survey responses lack the signals found in human populations. This absence of statistical signal cautions about the use of survey responses from large language models at present time. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 17:48:27 GMT'}]",2023-06-14,"[['Dominguez-Olmedo', 'Ricardo', ''], ['Hardt', 'Moritz', ''], ['Mendler-Dünner', 'Celestine', '']]",0,0,2023-06-13,1,3,1,0,0,0,a86e12654376323b712dd3d39d5ff22283f87a7b,259145127.0,https://www.semanticscholar.org/paper/a86e12654376323b712dd3d39d5ff22283f87a7b,arXiv.org,2023.0,55.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","[{'authorId': '2146535357', 'name': 'Ricardo Dominguez-Olmedo'}, {'authorId': '1775622', 'name': 'Moritz Hardt'}, {'authorId': '2114722043', 'name': 'Celestine Mendler-Dunner'}]","['University of Tübingen', 'Max Planck Institute for Intelligent Systems']",['Germany'],2023-06
2306.07971,Abdelrahman Shaker,"Omkar Thawkar, Abdelrahman Shaker, Sahal Shaji Mullappilly, Hisham
  Cholakkal, Rao Muhammad Anwer, Salman Khan, Jorma Laaksonen, Fahad Shahbaz
  Khan",XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models,Technical report,,,,cs.CV,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The latest breakthroughs in large vision-language models, such as Bard and GPT-4, have showcased extraordinary abilities in performing a wide range of tasks. Such models are trained on massive datasets comprising billions of public image-text pairs with diverse tasks. However, their performance on task-specific domains, such as radiology, is still under-investigated and potentially limited due to a lack of sophistication in understanding biomedical images. On the other hand, conversational medical models have exhibited remarkable success but have mainly focused on text-based analysis. In this paper, we introduce XrayGPT, a novel conversational medical vision-language model that can analyze and answer open-ended questions about chest radiographs. Specifically, we align both medical visual encoder (MedClip) with a fine-tuned large language model (Vicuna), using a simple linear transformation. This alignment enables our model to possess exceptional visual conversation abilities, grounded in a deep understanding of radiographs and medical domain knowledge. To enhance the performance of LLMs in the medical context, we generate ~217k interactive and high-quality summaries from free-text radiology reports. These summaries serve to enhance the performance of LLMs through the fine-tuning process. Our approach opens up new avenues the research for advancing the automated analysis of chest radiographs. Our open-source demos, models, and instruction sets are available at: https://github.com/mbzuai-oryx/XrayGPT. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 17:59:59 GMT'}]",2023-06-14,"[['Thawkar', 'Omkar', ''], ['Shaker', 'Abdelrahman', ''], ['Mullappilly', 'Sahal Shaji', ''], ['Cholakkal', 'Hisham', ''], ['Anwer', 'Rao Muhammad', ''], ['Khan', 'Salman', ''], ['Laaksonen', 'Jorma', ''], ['Khan', 'Fahad Shahbaz', '']]",0,1,2023-06-13,1,8,1,2,1,1,66d7d8dc54ea3dff10a11df2f29dc2104df86a57,259145194.0,https://www.semanticscholar.org/paper/66d7d8dc54ea3dff10a11df2f29dc2104df86a57,arXiv.org,2023.0,22.0,10.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1396268305', 'name': 'Omkar Thawakar'}, {'authorId': '1388529476', 'name': 'Abdelrahman M. Shaker'}, {'authorId': '2162188337', 'name': 'Sahal Shaji Mullappilly'}, {'authorId': '2951229', 'name': 'Hisham Cholakkal'}, {'authorId': '3288214', 'name': 'R. Anwer'}, {'authorId': '2111180748', 'name': 'Salman Siddique Khan'}, {'authorId': '144376259', 'name': 'J. Laaksonen'}, {'authorId': '2086745054', 'name': 'F. Khan'}]","['Aalto University', 'Mohamed bin Zayed University of Artificial Intelligence']","['United Arab Emirates', 'Finland']",2023-06
2306.08058,Robert Helmeczi,"Robert Kraig Helmeczi, Mucahit Cevik, Savas Y{\i}ld{\i}r{\i}m",Few-shot learning for sentence pair classification and its applications in software engineering,"31 pages, 4 figures",,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Few-shot learning-the ability to train models with access to limited data-has become increasingly popular in the natural language processing (NLP) domain, as large language models such as GPT and T0 have been empirically shown to achieve high performance in numerous tasks with access to just a handful of labeled examples. Smaller language models such as BERT and its variants have also been shown to achieve strong performance with just a handful of labeled examples when combined with few-shot learning algorithms like pattern-exploiting training (PET) and SetFit. The focus of this work is to investigate the performance of alternative few-shot learning approaches with BERT-based models. Specifically, vanilla fine-tuning, PET and SetFit are compared for numerous BERT-based checkpoints over an array of training set sizes. To facilitate this investigation, applications of few-shot learning are considered in software engineering. For each task, high-performance techniques and their associated model checkpoints are identified through detailed empirical analysis. Our results establish PET as a strong few-shot learning approach, and our analysis shows that with just a few hundred labeled examples it can achieve performance near that of fine-tuning on full-sized data sets. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 18:23:52 GMT'}]",2023-06-16,"[['Helmeczi', 'Robert Kraig', ''], ['Cevik', 'Mucahit', ''], ['Yıldırım', 'Savas', '']]",0,1,2023-06-13,1,3,1,1,1,0,8a2c3f2cd5083d888d2a7d44759b23341a3984b7,259164447.0,https://www.semanticscholar.org/paper/8a2c3f2cd5083d888d2a7d44759b23341a3984b7,arXiv.org,2023.0,28.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2170077353', 'name': 'Robert K. Helmeczi'}, {'authorId': '1941800', 'name': 'Mucahit Cevik'}, {'authorId': '2237039', 'name': 'Savaş Yıldırım'}]",['Toronto Metropolitan University'],['Canada'],2023-06
2306.08107,Alexander Tornede,"Alexander Tornede, Difan Deng, Theresa Eimer, Joseph Giovanelli,
  Aditya Mohan, Tim Ruhkopf, Sarah Segel, Daphne Theodorakopoulos, Tanja
  Tornede, Henning Wachsmuth, Marius Lindauer","AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks",,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The fields of both Natural Language Processing (NLP) and Automated Machine Learning (AutoML) have achieved remarkable results over the past years. In NLP, especially Large Language Models (LLMs) have experienced a rapid series of breakthroughs very recently. We envision that the two fields can radically push the boundaries of each other through tight integration. To showcase this vision, we explore the potential of a symbiotic relationship between AutoML and LLMs, shedding light on how they can benefit each other. In particular, we investigate both the opportunities to enhance AutoML approaches with LLMs from different perspectives and the challenges of leveraging AutoML to further improve LLMs. To this end, we survey existing work, and we critically assess risks. We strongly believe that the integration of the two fields has the potential to disrupt both fields, NLP and AutoML. By highlighting conceivable synergies, but also risks, we aim to foster further exploration at the intersection of AutoML and LLMs. ","[{'version': 'v1', 'created': 'Tue, 13 Jun 2023 19:51:22 GMT'}, {'version': 'v2', 'created': 'Mon, 21 Aug 2023 15:01:46 GMT'}]",2023-08-22,"[['Tornede', 'Alexander', ''], ['Deng', 'Difan', ''], ['Eimer', 'Theresa', ''], ['Giovanelli', 'Joseph', ''], ['Mohan', 'Aditya', ''], ['Ruhkopf', 'Tim', ''], ['Segel', 'Sarah', ''], ['Theodorakopoulos', 'Daphne', ''], ['Tornede', 'Tanja', ''], ['Wachsmuth', 'Henning', ''], ['Lindauer', 'Marius', '']]",0,0,2023-06-13,2,11,2,0,0,0,9afa0c3227fd0ec3a76928784e59c4205cbace24,259164600.0,https://www.semanticscholar.org/paper/9afa0c3227fd0ec3a76928784e59c4205cbace24,arXiv.org,2023.0,170.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1409342574', 'name': 'Alexander Tornede'}, {'authorId': '25309765', 'name': 'Difan Deng'}, {'authorId': '1944688061', 'name': 'Theresa Eimer'}, {'authorId': '2077517396', 'name': 'Joseph Giovanelli'}, {'authorId': '2064332188', 'name': 'Aditya Mohan'}, {'authorId': '2168452911', 'name': 'Tim Ruhkopf'}, {'authorId': '2220099047', 'name': 'Sarah Segel'}, {'authorId': '1818287855', 'name': 'Daphne Theodorakopoulos'}, {'authorId': '148248730', 'name': 'Tanja Tornede'}, {'authorId': '2626599', 'name': 'Henning Wachsmuth'}, {'authorId': '145963266', 'name': 'M. Lindauer'}]","['Leibniz University Hannover', 'German Research Centre for Artificial Intelligence', 'University of Bologna']","['Germany', 'Italy']",2023-06
2306.08456,Zhiyuan Hu,"Zhiyuan Hu, Chumin Liu, Yue Feng, Anh Tuan Luu, Bryan Hooi",PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in Poetry Generation,9 Pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Controllable text generation is a challenging and meaningful field in natural language generation (NLG). Especially, poetry generation is a typical one with well-defined and strict conditions for text generation which is an ideal playground for the assessment of current methodologies. While prior works succeeded in controlling either semantic or metrical aspects of poetry generation, simultaneously addressing both remains a challenge. In this paper, we pioneer the use of the Diffusion model for generating sonnets and Chinese SongCi poetry to tackle such challenges. In terms of semantics, our PoetryDiffusion model, built upon the Diffusion model, generates entire sentences or poetry by comprehensively considering the entirety of sentence information. This approach enhances semantic expression, distinguishing it from autoregressive and large language models (LLMs). For metrical control, the separation feature of diffusion generation and its constraint control module enable us to flexibly incorporate a novel metrical controller to manipulate and evaluate metrics (format and rhythm). The denoising process in PoetryDiffusion allows for gradual enhancement of semantics and flexible integration of the metrical controller which can calculate and impose penalties on states that stray significantly from the target control distribution. Experimental results on two datasets demonstrate that our model outperforms existing models in automatic evaluation of semantic, metrical, and overall performance as well as human evaluation. ","[{'version': 'v1', 'created': 'Wed, 14 Jun 2023 11:57:31 GMT'}, {'version': 'v2', 'created': 'Tue, 15 Aug 2023 16:21:47 GMT'}]",2023-08-16,"[['Hu', 'Zhiyuan', ''], ['Liu', 'Chumin', ''], ['Feng', 'Yue', ''], ['Luu', 'Anh Tuan', ''], ['Hooi', 'Bryan', '']]",0,0,2023-06-14,2,5,1,0,0,0,256ac7f8b1b7fe81e41b5b2af28c179f56611576,259165503.0,https://www.semanticscholar.org/paper/256ac7f8b1b7fe81e41b5b2af28c179f56611576,arXiv.org,2023.0,44.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48430820', 'name': 'Zhiyuan Hu'}, {'authorId': '2220129802', 'name': 'Chumin Liu'}, {'authorId': '2047904135', 'name': 'Yue Feng'}, {'authorId': '2019961', 'name': 'Bryan Hooi'}]","['National University of Singapore', 'University College London', 'Nanyang Technological University']","['United Kingdom', 'Singapore']",2023-06
2306.08486,Giorgio Gonnella,Serena Lam and Giorgio Gonnella,Collection of prokaryotic genome contents expectation rules from scientific literature,,,,,q-bio.GN,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Shaped by natural selection and other evolutionary forces, an organism's evolutionary history is reflected through its genome sequence, content of functional elements and organization. Consequently, organisms connected through phylogeny, metabolic or morphological traits, geographical proximity, or habitat features are likely to exhibit similarities in their genomes. These similarities give rise to expectations about the content of genomes within these organism groups.   Such expectations are often informally expressed in scientific literature, focusing on the analysis of individual genomes or comparisons among related groups of organisms. Our objective is to develop a system for formalized expectations as rules, facilitating automated verification, and evaluation of newly sequenced genomes.   In this study, we present a database comprising rules manually extracted from scientific literature. Furthermore, we explore the feasibility of automatizing the extraction and analysis process using large language models, such as GPT3.5 and GPT4.   We have developed a web application, EGCWebApp, which enables users to visualize and edit the rules. Additionally, we provided a Python library and command-line tools collection, egctools, to further extend the functionality for processing and managing these rules. ","[{'version': 'v1', 'created': 'Wed, 14 Jun 2023 13:03:48 GMT'}]",2023-06-16,"[['Lam', 'Serena', ''], ['Gonnella', 'Giorgio', '']]",0,1,2023-06-14,1,2,1,2,0,2,6165171bf9692fd50766b9605d79dfe3f181f6ed,259165631.0,https://www.semanticscholar.org/paper/6165171bf9692fd50766b9605d79dfe3f181f6ed,,2023.0,66.0,1.0,0.0,False,['Biology'],"[{'category': 'Biology', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '121862671', 'name': 'S. Lam'}, {'authorId': '39148472', 'name': 'Giorgio Gonnella'}]","['University of Göttingen', 'Universität Hamburg']",['Germany'],2023-06
2306.08833,Chaofan Wang,"Chaofan Wang, Samuel Kernan Freire, Mo Zhang, Jing Wei, Jorge
  Goncalves, Vassilis Kostakos, Zhanna Sarsenbayeva, Christina Schneegass,
  Alessandro Bozzon, Evangelos Niforatos",Safeguarding Crowdsourcing Surveys from ChatGPT with Prompt Injection,,,,,cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  ChatGPT and other large language models (LLMs) have proven useful in crowdsourcing tasks, where they can effectively annotate machine learning training data. However, this means that they also have the potential for misuse, specifically to automatically answer surveys. LLMs can potentially circumvent quality assurance measures, thereby threatening the integrity of methodologies that rely on crowdsourcing surveys. In this paper, we propose a mechanism to detect LLM-generated responses to surveys. The mechanism uses ""prompt injection"", such as directions that can mislead LLMs into giving predictable responses. We evaluate our technique against a range of question scenarios, types, and positions, and find that it can reliably detect LLM-generated responses with more than 93% effectiveness. We also provide an open-source software to help survey designers use our technique to detect LLM responses. Our work is a step in ensuring that survey methodologies remain rigorous vis-a-vis LLMs. ","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 03:30:13 GMT'}]",2023-06-16,"[['Wang', 'Chaofan', ''], ['Freire', 'Samuel Kernan', ''], ['Zhang', 'Mo', ''], ['Wei', 'Jing', ''], ['Goncalves', 'Jorge', ''], ['Kostakos', 'Vassilis', ''], ['Sarsenbayeva', 'Zhanna', ''], ['Schneegass', 'Christina', ''], ['Bozzon', 'Alessandro', ''], ['Niforatos', 'Evangelos', '']]",1,1,2023-06-15,1,10,1,1,0,1,8c035150f883007b5af9e5bb753b78d9c0b75a55,259165387.0,https://www.semanticscholar.org/paper/8c035150f883007b5af9e5bb753b78d9c0b75a55,arXiv.org,2023.0,36.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2214205064', 'name': 'Chaofan Wang'}, {'authorId': '2186120882', 'name': 'Samuel Kernan Freire'}, {'authorId': '2220133939', 'name': 'Mo Zhang'}, {'authorId': '2141565118', 'name': 'Jing Wei'}, {'authorId': '144769817', 'name': 'Jorge Gonçalves'}, {'authorId': '1781697', 'name': 'V. Kostakos'}, {'authorId': '3455464', 'name': 'Zhanna Sarsenbayeva'}, {'authorId': '2898519', 'name': 'Christina Schneegass'}, {'authorId': '1710630', 'name': 'A. Bozzon'}, {'authorId': '1699294', 'name': 'E. Niforatos'}]","['University of Melbourne', 'University of Sydney', 'Delft University of Technology']","['Netherlands', 'Australia']",2023-06
2306.09169,"Jan G\""opfert","Jan G\""opfert, Jann M. Weinand, Patrick Kuckertz, Detlef Stolten",Opportunities for Large Language Models and Discourse in Engineering Design,,,,,cs.CL cs.AI cs.CE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In recent years, large language models have achieved breakthroughs on a wide range of benchmarks in natural language processing and continue to increase in performance. Recently, the advances of large language models have raised interest outside the natural language processing community and could have a large impact on daily life. In this paper, we pose the question: How will large language models and other foundation models shape the future product development process? We provide the reader with an overview of the subject by summarizing both recent advances in natural language processing and the use of information technology in the engineering design process. We argue that discourse should be regarded as the core of engineering design processes, and therefore should be represented in a digital artifact. On this basis, we describe how foundation models such as large language models could contribute to the design discourse by automating parts thereof that involve creativity and reasoning, and were previously reserved for humans. We describe how simulations, experiments, topology optimizations, and other process steps can be integrated into a machine-actionable, discourse-centric design process. Finally, we outline the future research that will be necessary for the implementation of the conceptualized framework. ","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 14:46:44 GMT'}]",2023-06-16,"[['Göpfert', 'Jan', ''], ['Weinand', 'Jann M.', ''], ['Kuckertz', 'Patrick', ''], ['Stolten', 'Detlef', '']]",0,0,2023-06-15,1,4,3,0,0,0,3ca8655d4147ec6443c0c90dac7c29d4df0eab99,259165061.0,https://www.semanticscholar.org/paper/3ca8655d4147ec6443c0c90dac7c29d4df0eab99,arXiv.org,2023.0,58.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '82805132', 'name': 'Jan Göpfert'}, {'authorId': '101166098', 'name': 'J. Weinand'}, {'authorId': '31073721', 'name': 'Patrick Kuckertz'}, {'authorId': '2852152', 'name': 'D. Stolten'}]","['RWTH Aachen University', 'Forschungszentrum Jülich']",['Germany'],2023-06
2306.09752,Victor Steinborn,"Victor Steinborn and Antonis Maronikolakis and Hinrich Sch\""utze",Politeness Stereotypes and Attack Vectors: Gender Stereotypes in Japanese and Korean Language Models,,,,,cs.CL cs.AI cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In efforts to keep up with the rapid progress and use of large language models, gender bias research is becoming more prevalent in NLP. Non-English bias research, however, is still in its infancy with most work focusing on English. In our work, we study how grammatical gender bias relating to politeness levels manifests in Japanese and Korean language models. Linguistic studies in these languages have identified a connection between gender bias and politeness levels, however it is not yet known if language models reproduce these biases. We analyze relative prediction probabilities of the male and female grammatical genders using templates and find that informal polite speech is most indicative of the female grammatical gender, while rude and formal speech is most indicative of the male grammatical gender. Further, we find politeness levels to be an attack vector for allocational gender bias in cyberbullying detection models. Cyberbullies can evade detection through simple techniques abusing politeness levels. We introduce an attack dataset to (i) identify representational gender bias across politeness levels, (ii) demonstrate how gender biases can be abused to bypass cyberbullying detection models and (iii) show that allocational biases can be mitigated via training on our proposed dataset. Through our findings we highlight the importance of bias research moving beyond its current English-centrism. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 10:36:18 GMT'}]",2023-06-19,"[['Steinborn', 'Victor', ''], ['Maronikolakis', 'Antonis', ''], ['Schütze', 'Hinrich', '']]",0,0,2023-06-16,1,3,4,0,0,0,b85ad29d40a3292863f3d2358c04b8e1c6fa43f3,259187663.0,https://www.semanticscholar.org/paper/b85ad29d40a3292863f3d2358c04b8e1c6fa43f3,arXiv.org,2023.0,85.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2176399629', 'name': 'Victor Steinborn'}, {'authorId': '1661214231', 'name': 'Antonis Maronikolakis'}, {'authorId': '144418438', 'name': 'Hinrich Schütze'}]",['Ludwig-Maximilians-Universität München'],['Germany'],2023-06
2306.09814,Sofoklis Kakouros,"Sofoklis Kakouros, Juraj \v{S}imko, Martti Vainio, Antti Suni",Investigating the Utility of Surprisal from Large Language Models for Speech Synthesis Prosody,Accepted at SSW 2023,,,,eess.AS cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper investigates the use of word surprisal, a measure of the predictability of a word in a given context, as a feature to aid speech synthesis prosody. We explore how word surprisal extracted from large language models (LLMs) correlates with word prominence, a signal-based measure of the salience of a word in a given discourse. We also examine how context length and LLM size affect the results, and how a speech synthesizer conditioned with surprisal values compares with a baseline system. To evaluate these factors, we conducted experiments using a large corpus of English text and LLMs of varying sizes. Our results show that word surprisal and word prominence are moderately correlated, suggesting that they capture related but distinct aspects of language use. We find that length of context and size of the LLM impact the correlations, but not in the direction anticipated, with longer contexts and larger LLMs generally underpredicting prominent words in a nearly linear manner. We demonstrate that, in line with these findings, a speech synthesizer conditioned with surprisal values provides a minimal improvement over the baseline with the results suggesting a limited effect of using surprisal values for eliciting appropriate prominence patterns. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 12:49:44 GMT'}]",2023-06-19,"[['Kakouros', 'Sofoklis', ''], ['Šimko', 'Juraj', ''], ['Vainio', 'Martti', ''], ['Suni', 'Antti', '']]",0,0,2023-06-16,1,4,2,0,0,0,63aad36dc981348493be6743292a04234b29ba4e,259188051.0,https://www.semanticscholar.org/paper/63aad36dc981348493be6743292a04234b29ba4e,Speech Synthesis Workshop,2023.0,30.0,1.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2144346', 'name': 'Sofoklis Kakouros'}, {'authorId': '34387110', 'name': 'J. Šimko'}, {'authorId': '144775265', 'name': 'M. Vainio'}, {'authorId': '2433419', 'name': 'A. Suni'}]",['University of Helsinki'],['Finland'],2023-06
2306.09938,Iain Mackie,"Iain Mackie, Ivan Sekulic, Shubham Chatterjee, Jeffrey Dalton, Fabio
  Crestani",GRM: Generative Relevance Modeling Using Relevance-Aware Sample Estimation for Document Retrieval,,,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent studies show that Generative Relevance Feedback (GRF), using text generated by Large Language Models (LLMs), can enhance the effectiveness of query expansion. However, LLMs can generate irrelevant information that harms retrieval effectiveness. To address this, we propose Generative Relevance Modeling (GRM) that uses Relevance-Aware Sample Estimation (RASE) for more accurate weighting of expansion terms. Specifically, we identify similar real documents for each generated document and use a neural re-ranker to estimate their relevance. Experiments on three standard document ranking benchmarks show that GRM improves MAP by 6-9% and R@1k by 2-4%, surpassing previous methods. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 16:18:11 GMT'}]",2023-06-19,"[['Mackie', 'Iain', ''], ['Sekulic', 'Ivan', ''], ['Chatterjee', 'Shubham', ''], ['Dalton', 'Jeffrey', ''], ['Crestani', 'Fabio', '']]",0,0,2023-06-16,1,5,1,0,0,0,0b8eaf52001bafa01dda642a0358ce3355318bc9,259187509.0,https://www.semanticscholar.org/paper/0b8eaf52001bafa01dda642a0358ce3355318bc9,arXiv.org,2023.0,45.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145052856', 'name': 'Iain Mackie'}, {'authorId': '3305422', 'name': 'Ivan Sekulic'}, {'authorId': '2113355478', 'name': 'Shubham Chatterjee'}, {'authorId': '49694325', 'name': 'Jeffrey Stephen Dalton'}, {'authorId': '145876066', 'name': 'F. Crestani'}]","['Università della Svizzera italiana', 'University of Glasgow']","['United Kingdom', 'Switzerland']",2023-06
2306.09983,Daniel Paleka,"Lukas Fluri, Daniel Paleka, Florian Tram\`er",Evaluating Superhuman Models with Consistency Checks,"31 pages, 15 figures. Under review. Code and data are available at
  https://github.com/ethz-spylab/superhuman-ai-consistency",,,,cs.LG cs.AI cs.CR stat.ML,http://creativecommons.org/licenses/by/4.0/,"  If machine learning models were to achieve superhuman abilities at various reasoning or decision-making tasks, how would we go about evaluating such models, given that humans would necessarily be poor proxies for ground truth? In this paper, we propose a framework for evaluating superhuman models via consistency checks. Our premise is that while the correctness of superhuman decisions may be impossible to evaluate, we can still surface mistakes if the model's decisions fail to satisfy certain logical, human-interpretable rules. We instantiate our framework on three tasks where correctness of decisions is hard to evaluate due to either superhuman model abilities, or to otherwise missing ground truth: evaluating chess positions, forecasting future events, and making legal judgments. We show that regardless of a model's (possibly superhuman) performance on these tasks, we can discover logical inconsistencies in decision making. For example: a chess engine assigning opposing valuations to semantically identical boards; GPT-4 forecasting that sports records will evolve non-monotonically over time; or an AI judge assigning bail to a defendant only after we add a felony to their criminal record. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 17:26:38 GMT'}, {'version': 'v2', 'created': 'Mon, 19 Jun 2023 18:03:48 GMT'}]",2023-06-21,"[['Fluri', 'Lukas', ''], ['Paleka', 'Daniel', ''], ['Tramèr', 'Florian', '']]",0,1,2023-06-16,2,3,4,1,0,1,c18c544adc6c3f78843ac0d25473b9b94bc426b6,259188084.0,https://www.semanticscholar.org/paper/c18c544adc6c3f78843ac0d25473b9b94bc426b6,arXiv.org,2023.0,95.0,7.0,2.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2220217917', 'name': 'Lukas Fluri'}, {'authorId': '2175557610', 'name': 'Daniel Paleka'}, {'authorId': '2444919', 'name': 'Florian Tramèr'}]",['ETH Zurich'],['Switzerland'],2023-06
2306.10037,Kostas Karpouzis,"Fereniki Panagopoulou, Christina Parpoula, Kostas Karpouzis",Legal and ethical considerations regarding the use of ChatGPT in education,"Accepted at the 1st International Conference of the Network of
  Learning and Teaching Centers in Greece: Transforming Higher Education
  Teaching Practice",,,,cs.CY,http://creativecommons.org/licenses/by-sa/4.0/,"  Artificial intelligence has evolved enormously over the last two decades, becoming mainstream in different scientific domains including education, where so far, it is mainly utilized to enhance administrative and intelligent tutoring systems services and academic support. ChatGPT, an artificial intelligence-based chatbot, developed by OpenAI and released in November 2022, has rapidly gained attention from the entire international community for its impressive performance in generating comprehensive, systematic, and informative human-like responses to user input through natural language processing. Inevitably, it has also rapidly posed several challenges, opportunities, and potential issues and concerns raised regarding its use across various scientific disciplines. This paper aims to discuss the legal and ethical implications arising from this new technology, identify potential use cases, and enrich our understanding of Generative AI, such as ChatGPT, and its capabilities in education. ","[{'version': 'v1', 'created': 'Fri, 9 Jun 2023 14:54:09 GMT'}]",2023-06-21,"[['Panagopoulou', 'Fereniki', ''], ['Parpoula', 'Christina', ''], ['Karpouzis', 'Kostas', '']]",1,1,2023-06-09,1,3,1,1,0,1,443e837cdf4bb83607083624734103c95f47299d,259202692.0,https://www.semanticscholar.org/paper/443e837cdf4bb83607083624734103c95f47299d,arXiv.org,2023.0,52.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '146737120', 'name': 'Fereniki Panagopoulou'}, {'authorId': '1957152', 'name': 'C. Parpoula'}, {'authorId': '1715144', 'name': 'K. Karpouzis'}]",['Panteion University'],['Greece'],2023-06
2306.10062,Ryan Burnell,"Ryan Burnell, Han Hao, Andrew R. A. Conway, and Jose Hernandez Orallo",Revealing the structure of language model capabilities,"10 pages, 3 figures + references and appendices, for data and
  analysis code see https://github.com/RyanBurnell/revealing-LLM-capabilities",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Building a theoretical understanding of the capabilities of large language models (LLMs) is vital for our ability to predict and explain the behavior of these systems. Here, we investigate the structure of LLM capabilities by extracting latent capabilities from patterns of individual differences across a varied population of LLMs. Using a combination of Bayesian and frequentist factor analysis, we analyzed data from 29 different LLMs across 27 cognitive tasks. We found evidence that LLM capabilities are not monolithic. Instead, they are better explained by three well-delineated factors that represent reasoning, comprehension and core language modeling. Moreover, we found that these three factors can explain a high proportion of the variance in model performance. These results reveal a consistent structure in the capabilities of different LLMs and demonstrate the multifaceted nature of these capabilities. We also found that the three abilities show different relationships to model properties such as model size and instruction tuning. These patterns help refine our understanding of scaling laws and indicate that changes to a model that improve one ability might simultaneously impair others. Based on these findings, we suggest that benchmarks could be streamlined by focusing on tasks that tap into each broad model ability. ","[{'version': 'v1', 'created': 'Wed, 14 Jun 2023 15:43:25 GMT'}]",2023-06-21,"[['Burnell', 'Ryan', ''], ['Hao', 'Han', ''], ['Conway', 'Andrew R. A.', ''], ['Orallo', 'Jose Hernandez', '']]",0,0,2023-06-14,1,4,3,0,0,0,00557300321dc60998e0f42853f4bba52d6e53db,259202736.0,https://www.semanticscholar.org/paper/00557300321dc60998e0f42853f4bba52d6e53db,arXiv.org,2023.0,35.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '1523759881', 'name': 'Ryan Burnell'}, {'authorId': '2888774', 'name': 'Hank Hao'}, {'authorId': '37842641', 'name': 'Andrew R. A. Conway'}, {'authorId': '66969655', 'name': 'José Hernández Orallo'}]","['The Alan Turing Institute', 'Universitat Politècnica de València', 'University of Cambridge', 'New Mexico State University']","['Mexico', 'United Kingdom', 'Spain']",2023-06
2306.10069,Mark D'Inverno,Matthew Yee-king and Andrea Fiorucci and Mark d'Inverno,"The pop song generator: designing an online course to teach collaborative, creative AI",,,,,cs.CY cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This article describes and evaluates a new online AI-creativity course. The course is based around three near-state-of-the-art AI models combined into a pop song generating system. A fine-tuned GPT-2 model writes lyrics, Music-VAE composes musical scores and instrumentation and Diffsinger synthesises a singing voice. We explain the decisions made in designing the course which is based on Piagetian, constructivist 'learning-by-doing'. We present details of the five-week course design with learning objectives, technical concepts, and creative and technical activities. We explain how we overcame technical challenges to build a complete pop song generator system, consisting of Python scripts, pre-trained models, and Javascript code that runs in a dockerised Linux container via a web-based IDE. A quantitative analysis of student activity provides evidence on engagement and a benchmark for future improvements. A qualitative analysis of a workshop with experts validated the overall course design, it suggested the need for a stronger creative brief and ethical and legal content. ","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 18:17:28 GMT'}]",2023-06-21,"[['Yee-king', 'Matthew', ''], ['Fiorucci', 'Andrea', ''], [""d'Inverno"", 'Mark', '']]",0,1,2023-06-15,1,3,2,1,1,0,9e3bfca5d1099caca92534667e4ff9cbd8dc742d,259203366.0,https://www.semanticscholar.org/paper/9e3bfca5d1099caca92534667e4ff9cbd8dc742d,arXiv.org,2023.0,43.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1390095554', 'name': 'M. Yee-King'}, {'authorId': '2056892136', 'name': 'A. Fiorucci'}, {'authorId': '1390095519', 'name': ""M. d'Inverno""}]",['Goldsmiths University of London'],['United Kingdom'],2023-06
2306.10082,Subhrasankar Chatterjee,Subhrasankar Chatterjee and Debasis Samanta,DreamCatcher: Revealing the Language of the Brain with fMRI using GPT Embedding,"10 Pages, 8 figures, 1 table",,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  The human brain possesses remarkable abilities in visual processing, including image recognition and scene summarization. Efforts have been made to understand the cognitive capacities of the visual brain, but a comprehensive understanding of the underlying mechanisms still needs to be discovered. Advancements in brain decoding techniques have led to sophisticated approaches like fMRI-to-Image reconstruction, which has implications for cognitive neuroscience and medical imaging. However, challenges persist in fMRI-to-image reconstruction, such as incorporating global context and contextual information. In this article, we propose fMRI captioning, where captions are generated based on fMRI data to gain insight into the neural correlates of visual perception. This research presents DreamCatcher, a novel framework for fMRI captioning. DreamCatcher consists of the Representation Space Encoder (RSE) and the RevEmbedding Decoder, which transform fMRI vectors into a latent space and generate captions, respectively. We evaluated the framework through visualization, dataset training, and testing on subjects, demonstrating strong performance. fMRI-based captioning has diverse applications, including understanding neural mechanisms, Human-Computer Interaction, and enhancing learning and training processes. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 07:55:20 GMT'}]",2023-06-21,"[['Chatterjee', 'Subhrasankar', ''], ['Samanta', 'Debasis', '']]",0,1,2023-06-16,1,2,1,0,0,0,4025bc5b68d638141d783555814f195af7c75aa6,259202535.0,https://www.semanticscholar.org/paper/4025bc5b68d638141d783555814f195af7c75aa6,arXiv.org,2023.0,38.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '152492630', 'name': 'Subhrasankar Chatterjee'}, {'authorId': '144315835', 'name': 'D. Samanta'}]",['Indian Institute of Technology Kharagpur'],['India'],2023-06
2306.10448,Sanjeev Kumar Karn,"Manuela Daniela Danu, George Marica, Sanjeev Kumar Karn, Bogdan
  Georgescu, Awais Mansoor, Florin Ghesu, Lucian Mihai Itu, Constantin Suciu,
  Sasa Grbic, Oladimeji Farri, Dorin Comaniciu",Generation of Radiology Findings in Chest X-Ray by Leveraging Collaborative Knowledge,Information Technology and Quantitative Management (ITQM 2023),Information Technology and Quantitative Management (ITQM 2023,,,cs.CV cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Among all the sub-sections in a typical radiology report, the Clinical Indications, Findings, and Impression often reflect important details about the health status of a patient. The information included in Impression is also often covered in Findings. While Findings and Impression can be deduced by inspecting the image, Clinical Indications often require additional context. The cognitive task of interpreting medical images remains the most critical and often time-consuming step in the radiology workflow. Instead of generating an end-to-end radiology report, in this paper, we focus on generating the Findings from automated interpretation of medical images, specifically chest X-rays (CXRs). Thus, this work focuses on reducing the workload of radiologists who spend most of their time either writing or narrating the Findings. Unlike past research, which addresses radiology report generation as a single-step image captioning task, we have further taken into consideration the complexity of interpreting CXR images and propose a two-step approach: (a) detecting the regions with abnormalities in the image, and (b) generating relevant text for regions with abnormalities by employing a generative large language model (LLM). This two-step approach introduces a layer of interpretability and aligns the framework with the systematic reasoning that radiologists use when reviewing a CXR. ","[{'version': 'v1', 'created': 'Sun, 18 Jun 2023 00:51:28 GMT'}]",2023-06-21,"[['Danu', 'Manuela Daniela', ''], ['Marica', 'George', ''], ['Karn', 'Sanjeev Kumar', ''], ['Georgescu', 'Bogdan', ''], ['Mansoor', 'Awais', ''], ['Ghesu', 'Florin', ''], ['Itu', 'Lucian Mihai', ''], ['Suciu', 'Constantin', ''], ['Grbic', 'Sasa', ''], ['Farri', 'Oladimeji', ''], ['Comaniciu', 'Dorin', '']]",0,0,2023-06-18,1,11,2,0,0,0,b9d3fe9ffaee62afa55e1336eb17ea7b201e8142,259203643.0,https://www.semanticscholar.org/paper/b9d3fe9ffaee62afa55e1336eb17ea7b201e8142,Procedia Computer Science,2023.0,38.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '1399347861', 'name': 'Manuela Danu'}, {'authorId': '2220304600', 'name': 'George Marica'}, {'authorId': '34112357', 'name': 'Sanjeev Kumar Karn'}, {'authorId': '1747498', 'name': 'B. Georgescu'}, {'authorId': '1792480', 'name': 'Awais Mansoor'}, {'authorId': '2562046', 'name': 'Florin C. Ghesu'}, {'authorId': '3100263', 'name': 'L. Itu'}, {'authorId': '31903205', 'name': 'C. Suciu'}, {'authorId': '1764071', 'name': 'Sasa Grbic'}, {'authorId': '2211973', 'name': 'Oladimeji Farri'}, {'authorId': '1685020', 'name': 'D. Comaniciu'}]","['Transylvania University of Brașov', 'Siemens Healthcare (Germany)']","['Romania', 'Germany']",2023-06
2306.10509,Hassan Khosravi,"Paul Denny and Hassan Khosravi and Arto Hellas and Juho Leinonen and
  Sami Sarsa",Can We Trust AI-Generated Educational Content? Comparative Analysis of Human and AI-Generated Learning Resources,,,,,cs.HC cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As an increasing number of students move to online learning platforms that deliver personalized learning experiences, there is a great need for the production of high-quality educational content. Large language models (LLMs) appear to offer a promising solution to the rapid creation of learning materials at scale, reducing the burden on instructors. In this study, we investigated the potential for LLMs to produce learning resources in an introductory programming context, by comparing the quality of the resources generated by an LLM with those created by students as part of a learnersourcing activity. Using a blind evaluation, students rated the correctness and helpfulness of resources generated by AI and their peers, after both were initially provided with identical exemplars. Our results show that the quality of AI-generated resources, as perceived by students, is equivalent to the quality of resources generated by their peers. This suggests that AI-generated resources may serve as viable supplementary material in certain contexts. Resources generated by LLMs tend to closely mirror the given exemplars, whereas student-generated resources exhibit greater variety in terms of content length and specific syntax features used. The study highlights the need for further research exploring different types of learning resources and a broader range of subject areas, and understanding the long-term impact of AI-generated resources on learning outcomes. ","[{'version': 'v1', 'created': 'Sun, 18 Jun 2023 09:49:21 GMT'}, {'version': 'v2', 'created': 'Mon, 3 Jul 2023 06:59:27 GMT'}]",2023-07-04,"[['Denny', 'Paul', ''], ['Khosravi', 'Hassan', ''], ['Hellas', 'Arto', ''], ['Leinonen', 'Juho', ''], ['Sarsa', 'Sami', '']]",0,0,2023-06-18,2,5,2,0,0,0,339ff0994d40b9ed45d54fb0cc79b80925738024,259313840.0,https://www.semanticscholar.org/paper/339ff0994d40b9ed45d54fb0cc79b80925738024,,2023.0,47.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '143880483', 'name': 'Paul Denny'}, {'authorId': '1508543895', 'name': 'Hassan Khosravi'}, {'authorId': '3446322', 'name': 'Arto Hellas'}, {'authorId': '34690956', 'name': 'Juho Leinonen'}, {'authorId': '1571527353', 'name': 'Sami Sarsa'}]","['Aalto University', 'University of Auckland', 'University of Queensland']","['Finland', 'New Zealand', 'Australia']",2023-06
2306.10723,Teodoro Baldazzi,"Teodoro Baldazzi, Luigi Bellomarini, Stefano Ceri, Andrea Colombo,
  Andrea Gentili, Emanuel Sallinger",Fine-tuning Large Enterprise Language Models via Ontological Reasoning,Accepted at RuleML 2023,,,,cs.CL cs.DB cs.LO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) exploit fine-tuning as a technique to adapt to diverse goals, thanks to task-specific training data. Task specificity should go hand in hand with domain orientation, that is, the specialization of an LLM to accurately address the tasks of a given realm of interest. However, models are usually fine-tuned over publicly available data or, at most, over ground data from databases, ignoring business-level definitions and domain experience. On the other hand, Enterprise Knowledge Graphs (EKGs) are able to capture and augment such domain knowledge via ontological reasoning. With the goal of combining LLM flexibility with the domain orientation of EKGs, we propose a novel neurosymbolic architecture that leverages the power of ontological reasoning to build task- and domain-specific corpora for LLM fine-tuning. ","[{'version': 'v1', 'created': 'Mon, 19 Jun 2023 06:48:45 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Sep 2023 21:37:37 GMT'}]",2023-09-20,"[['Baldazzi', 'Teodoro', ''], ['Bellomarini', 'Luigi', ''], ['Ceri', 'Stefano', ''], ['Colombo', 'Andrea', ''], ['Gentili', 'Andrea', ''], ['Sallinger', 'Emanuel', '']]",0,0,2023-06-19,2,6,3,0,0,0,1e7301ca09f604f56ee268c5ffaddcd7e537d46f,259204134.0,https://www.semanticscholar.org/paper/1e7301ca09f604f56ee268c5ffaddcd7e537d46f,RuleML+RR,2023.0,24.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2053814262', 'name': 'Teodoro Baldazzi'}, {'authorId': '1716855', 'name': 'Luigi Bellomarini'}, {'authorId': '144161686', 'name': 'S. Ceri'}, {'authorId': '2056150893', 'name': 'Andrea Colombo'}, {'authorId': '2064073882', 'name': 'Andrea Gentili'}, {'authorId': '1739608', 'name': 'Emanuel Sallinger'}]","['Roma Tre University', 'Bank of Italy', 'Politecnico di Milano', 'University of Oxford', 'TU Wien']","['Austria', 'United Kingdom', 'Italy']",2023-06
2306.10974,Nicolas Lell,"Justin M\""ucke and Daria Waldow and Luise Metzger and Philipp Schauz
  and Marcel Hoffman and Nicolas Lell and Ansgar Scherp",Fine-Tuning Language Models for Scientific Writing Support,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We support scientific writers in determining whether a written sentence is scientific, to which section it belongs, and suggest paraphrasings to improve the sentence. Firstly, we propose a regression model trained on a corpus of scientific sentences extracted from peer-reviewed scientific papers and non-scientific text to assign a score that indicates the scientificness of a sentence. We investigate the effect of equations and citations on this score to test the model for potential biases. Secondly, we create a mapping of section titles to a standard paper layout in AI and machine learning to classify a sentence to its most likely section. We study the impact of context, i.e., surrounding sentences, on the section classification performance. Finally, we propose a paraphraser, which suggests an alternative for a given sentence that includes word substitutions, additions to the sentence, and structural changes to improve the writing style. We train various large language models on sentences extracted from arXiv papers that were peer reviewed and published at A*, A, B, and C ranked conferences. On the scientificness task, all models achieve an MSE smaller than $2\%$. For the section classification, BERT outperforms WideMLP and SciBERT in most cases. We demonstrate that using context enhances the classification of a sentence, achieving up to a $90\%$ F1-score. Although the paraphrasing models make comparatively few alterations, they produce output sentences close to the gold standard. Large fine-tuned models such as T5 Large perform best in experiments considering various measures of difference between input sentence and gold standard. Code is provided under https://github.com/JustinMuecke/SciSen. ","[{'version': 'v1', 'created': 'Mon, 19 Jun 2023 14:34:49 GMT'}, {'version': 'v2', 'created': 'Wed, 21 Jun 2023 08:31:48 GMT'}]",2023-06-22,"[['Mücke', 'Justin', ''], ['Waldow', 'Daria', ''], ['Metzger', 'Luise', ''], ['Schauz', 'Philipp', ''], ['Hoffman', 'Marcel', ''], ['Lell', 'Nicolas', ''], ['Scherp', 'Ansgar', '']]",0,0,2023-06-19,2,7,1,1,1,0,5ce790f9d94e361931ce44880bf1a7b647aa89a0,259202639.0,https://www.semanticscholar.org/paper/5ce790f9d94e361931ce44880bf1a7b647aa89a0,International Cross-Domain Conference on Machine Learning and Knowledge Extraction,2023.0,0.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2220457579', 'name': 'Justin Mücke'}, {'authorId': '2220300018', 'name': 'Daria Waldow'}, {'authorId': '2220302275', 'name': 'Luise Metzger'}, {'authorId': '2137797103', 'name': 'Philipp Schauz'}, {'authorId': '2216471764', 'name': 'Marcel Hoffmann'}, {'authorId': '2060210260', 'name': 'N. Lell'}, {'authorId': '1753135', 'name': 'A. Scherp'}]",['University of Ulm'],['Germany'],2023-06
2306.10985,Julien Perez,Julien Perez and Denys Proux and Claude Roux and Michael Niemaz,"LARG, Language-based Automatic Reward and Goal Generation",,,,,cs.CL cs.LG cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Goal-conditioned and Multi-Task Reinforcement Learning (GCRL and MTRL) address numerous problems related to robot learning, including locomotion, navigation, and manipulation scenarios. Recent works focusing on language-defined robotic manipulation tasks have led to the tedious production of massive human annotations to create dataset of textual descriptions associated with trajectories. To leverage reinforcement learning with text-based task descriptions, we need to produce reward functions associated with individual tasks in a scalable manner. In this paper, we leverage recent capabilities of Large Language Models (LLMs) and introduce \larg, Language-based Automatic Reward and Goal Generation, an approach that converts a text-based task description into its corresponding reward and goal-generation functions We evaluate our approach for robotic manipulation and demonstrate its ability to train and execute policies in a scalable manner, without the need for handcrafted reward functions. ","[{'version': 'v1', 'created': 'Mon, 19 Jun 2023 14:52:39 GMT'}]",2023-06-21,"[['Perez', 'Julien', ''], ['Proux', 'Denys', ''], ['Roux', 'Claude', ''], ['Niemaz', 'Michael', '']]",0,0,2023-06-19,1,4,3,0,0,0,5d35d6cbc406a379e8b043eb135b6752df5c45f1,259203128.0,https://www.semanticscholar.org/paper/5d35d6cbc406a379e8b043eb135b6752df5c45f1,arXiv.org,2023.0,30.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '121436310', 'name': 'Julien Perez'}, {'authorId': '2220287228', 'name': 'Denys Proux'}, {'authorId': '2069598214', 'name': 'Claude Roux'}, {'authorId': '69408539', 'name': 'Michael Niemaz'}]",['NAVER'],['France'],2023-06
2306.10998,Disha Shrivastava,"Disha Shrivastava, Denis Kocetkov, Harm de Vries, Dzmitry Bahdanau,
  Torsten Scholak",RepoFusion: Training Code Models to Understand Your Repository,,,,,cs.LG cs.AI cs.PL cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite the huge success of Large Language Models (LLMs) in coding assistants like GitHub Copilot, these models struggle to understand the context present in the repository (e.g., imports, parent classes, files with similar names, etc.), thereby producing inaccurate code completions. This effect is more pronounced when using these assistants for repositories that the model has not seen during training, such as proprietary software or work-in-progress code projects. Recent work has shown the promise of using context from the repository during inference. In this work, we extend this idea and propose RepoFusion, a framework to train models to incorporate relevant repository context. Experiments on single-line code completion show that our models trained with repository context significantly outperform much larger code models as CodeGen-16B-multi ($\sim73\times$ larger) and closely match the performance of the $\sim 70\times$ larger StarCoderBase model that was trained with the Fill-in-the-Middle objective. We find these results to be a novel and compelling demonstration of the gains that training with repository context can bring. We carry out extensive ablation studies to investigate the impact of design choices such as context type, number of contexts, context length, and initialization within our framework. Lastly, we release Stack-Repo, a dataset of 200 Java repositories with permissive licenses and near-deduplicated files that are augmented with three types of repository contexts. Additionally, we are making available the code and trained checkpoints for our work. Our released resources can be found at \url{https://huggingface.co/RepoFusion}. ","[{'version': 'v1', 'created': 'Mon, 19 Jun 2023 15:05:31 GMT'}]",2023-06-21,"[['Shrivastava', 'Disha', ''], ['Kocetkov', 'Denis', ''], ['de Vries', 'Harm', ''], ['Bahdanau', 'Dzmitry', ''], ['Scholak', 'Torsten', '']]",0,0,2023-06-19,1,5,4,1,1,0,2bbb16eb8e85c64608af9712724951f070e01910,259203440.0,https://www.semanticscholar.org/paper/2bbb16eb8e85c64608af9712724951f070e01910,arXiv.org,2023.0,41.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '36921665', 'name': 'Disha Shrivastava'}, {'authorId': '2192609008', 'name': 'Denis Kocetkov'}, {'authorId': '153559313', 'name': 'Harm de Vries'}, {'authorId': '3335364', 'name': 'Dzmitry Bahdanau'}, {'authorId': '11869783', 'name': 'Torsten Scholak'}]","['Université de Montréal', 'McGill University']",['Canada'],2023-06
2306.11114,Aleksandr Petrov,Aleksandr V. Petrov and Craig Macdonald,Generative Sequential Recommendation with GPTRec,Accepted at Gen-IR@SIGIR2023 workshop,,,,cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Sequential recommendation is an important recommendation task that aims to predict the next item in a sequence. Recently, adaptations of language models, particularly Transformer-based models such as SASRec and BERT4Rec, have achieved state-of-the-art results in sequential recommendation. In these models, item ids replace tokens in the original language models. However, this approach has limitations. First, the vocabulary of item ids may be many times larger than in language models. Second, the classical Top-K recommendation approach used by these models may not be optimal for complex recommendation objectives, including auxiliary objectives such as diversity, coverage or coherence. Recent progress in generative language models inspires us to revisit generative approaches to address these challenges. This paper presents the GPTRec sequential recommendation model, which is based on the GPT-2 architecture. GPTRec can address large vocabulary issues by splitting item ids into sub-id tokens using a novel SVD Tokenisation algorithm based on quantised item embeddings from an SVD decomposition of the user-item interaction matrix. The paper also presents a novel Next-K recommendation strategy, which generates recommendations item-by-item, considering already recommended items. The Next-K strategy can be used for producing complex interdependent recommendation lists. We experiment with GPTRec on the MovieLens-1M dataset and show that using sub-item tokenisation GPTRec can match the quality of SASRec while reducing the embedding table by 40%. We also show that the recommendations generated by GPTRec on MovieLens-1M using the Next-K recommendation strategy match the quality of SASRec in terms of NDCG@10, meaning that the model can serve as a strong starting point for future research. ","[{'version': 'v1', 'created': 'Mon, 19 Jun 2023 18:27:54 GMT'}]",2023-06-21,"[['Petrov', 'Aleksandr V.', ''], ['Macdonald', 'Craig', '']]",0,1,2023-06-19,1,2,1,1,1,0,f23496d38da8f149127ef013f1604e1057aa2779,259203027.0,https://www.semanticscholar.org/paper/f23496d38da8f149127ef013f1604e1057aa2779,arXiv.org,2023.0,40.0,7.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2175024140', 'name': 'Aleksandr Petrov'}, {'authorId': '145434248', 'name': 'C. Macdonald'}]",['University of Glasgow'],['United Kingdom'],2023-06
2306.11444,Paola Merlo,Paola Merlo,"Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Motivations and Formal Specifications","7pages, 6 figures. arXiv admin note: text overlap with
  arXiv:2205.10866",,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We motivate and formally define a new task for fine-tuning rule-like generalization in large language models. It is conjectured that the shortcomings of current LLMs are due to a lack of ability to generalize. It has been argued that, instead, humans are better at generalization because they have a tendency at extracting rules from complex data. We try to recreate this tendency to rule-based generalization. When exposed to tests of analytic intelligence, for example, the visual RAVEN IQ test, human problem-solvers identify the relevant objects in the picture and their relevant attributes and reason based on rules applied to these objects and attributes. Based on the induced rules, they are able to provide a solution to the test. We propose a task that translates this IQ task into language. In this paper, we provide the formal specification for the task and the generative process of its datasets. ","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 10:45:56 GMT'}]",2023-06-21,"[['Merlo', 'Paola', '']]",0,0,2023-06-20,1,1,1,0,0,0,15beba8e30b21797ac126a7cdc41cb24ac56bf55,259202573.0,https://www.semanticscholar.org/paper/15beba8e30b21797ac126a7cdc41cb24ac56bf55,arXiv.org,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143939590', 'name': 'Paola Merlo'}]",['University of Geneva'],['Switzerland'],2023-06
2306.11527,Yuki Nagai,Yuki Nagai and Akio Tomiya,Self-learning Monte Carlo with equivariant Transformer,"11 pates, 6 figures, the training parameters are improved",,,,cond-mat.str-el cond-mat.dis-nn hep-lat,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine learning and deep learning have revolutionized computational physics, particularly the simulation of complex systems. Equivariance is essential for simulating physical systems because it imposes a strong inductive bias on the probability distribution described by a machine learning model. However, imposing symmetry on the model can sometimes lead to poor acceptance rates in self-learning Monte Carlo (SLMC). Here, we introduce a symmetry equivariant attention mechanism for SLMC, which can be systematically improved. We evaluate our architecture on a spin-fermion model (\textit{i.e.}, double exchange model) on a two-dimensional lattice. Our results show that the proposed method overcomes the poor acceptance rates of linear models and exhibits a similar scaling law to large language models, with model quality monotonically increasing with the number of layers. Our work paves the way for the development of more accurate and efficient Monte Carlo algorithms with machine learning for simulating complex physical systems. ","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 13:30:01 GMT'}, {'version': 'v2', 'created': 'Fri, 28 Jul 2023 06:54:49 GMT'}]",2023-07-31,"[['Nagai', 'Yuki', ''], ['Tomiya', 'Akio', '']]",0,0,2023-06-20,2,2,3,0,0,0,02e699561624adae5ea3550e8ebee988a2557286,259202628.0,https://www.semanticscholar.org/paper/02e699561624adae5ea3550e8ebee988a2557286,,2023.0,58.0,2.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '145760276', 'name': 'Y. Nagai'}, {'authorId': '90901069', 'name': 'A. Tomiya'}]","['International Professional University of Technology in Nagoya', 'Japan Atomic Energy Agency']",['Japan'],2023-06
2306.11593,Luigi Celona,Simone Bianco and Luigi Celona and Marco Donzella and Paolo Napoletano,Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion,,,,,cs.CV cs.AI cs.CL cs.DB cs.LG,http://creativecommons.org/licenses/by/4.0/,"  State-of-The-Art (SoTA) image captioning models often rely on the Microsoft COCO (MS-COCO) dataset for training. This dataset contains annotations provided by human annotators, who typically produce captions averaging around ten tokens. However, this constraint presents a challenge in effectively capturing complex scenes and conveying detailed information. Furthermore, captioning models tend to exhibit bias towards the ``average'' caption, which captures only the more general aspects. What would happen if we were able to automatically generate longer captions, thereby making them more detailed? Would these captions, evaluated by humans, be more or less representative of the image content compared to the original MS-COCO captions? In this paper, we present a novel approach to address previous challenges by showcasing how captions generated from different SoTA models can be effectively fused, resulting in richer captions. Our proposed method leverages existing models from the literature, eliminating the need for additional training. Instead, it utilizes an image-text based metric to rank the captions generated by SoTA models for a given image. Subsequently, the top two captions are fused using a Large Language Model (LLM). Experimental results demonstrate the effectiveness of our approach, as the captions generated by our model exhibit higher consistency with human judgment when evaluated on the MS-COCO test set. By combining the strengths of various SoTA models, our method enhances the quality and appeal of image captions, bridging the gap between automated systems and the rich, informative nature of human-generated descriptions. This advance opens up new possibilities for generating captions that are more suitable for the training of both vision-language and captioning models. ","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 15:13:02 GMT'}]",2023-06-21,"[['Bianco', 'Simone', ''], ['Celona', 'Luigi', ''], ['Donzella', 'Marco', ''], ['Napoletano', 'Paolo', '']]",0,0,2023-06-20,1,4,5,0,0,0,e5d27e79d10a056cdeb86ca25853da8797413afb,259203436.0,https://www.semanticscholar.org/paper/e5d27e79d10a056cdeb86ca25853da8797413afb,arXiv.org,2023.0,39.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2165252949', 'name': 'Simone Bianco'}, {'authorId': '3390122', 'name': 'Luigi Celona'}, {'authorId': '2220301813', 'name': 'Marco Donzella'}, {'authorId': '1705089', 'name': 'Paolo Napoletano'}]",['University of Milano-Bicocca'],['Italy'],2023-06
2306.11644,Suriya Gunasekar,"Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio C\'esar Teodoro Mendes,
  Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo
  de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin
  Wang, S\'ebastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee,
  Yuanzhi Li",Textbooks Are All You Need,"26 pages; changed color scheme of plot. fixed minor typos and added
  couple clarifications",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  We introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook quality"" data from the web (6B tokens) and synthetically generated textbooks and exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains pass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays surprising emergent properties compared to phi-1-base, our model before our finetuning stage on a dataset of coding exercises, and phi-1-small, a smaller model with 350M parameters trained with the same pipeline as phi-1 that still achieves 45% on HumanEval. ","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 16:14:25 GMT'}, {'version': 'v2', 'created': 'Mon, 2 Oct 2023 06:12:30 GMT'}]",2023-10-03,"[['Gunasekar', 'Suriya', ''], ['Zhang', 'Yi', ''], ['Aneja', 'Jyoti', ''], ['Mendes', 'Caio César Teodoro', ''], ['Del Giorno', 'Allie', ''], ['Gopi', 'Sivakanth', ''], ['Javaheripi', 'Mojan', ''], ['Kauffmann', 'Piero', ''], ['de Rosa', 'Gustavo', ''], ['Saarikivi', 'Olli', ''], ['Salim', 'Adil', ''], ['Shah', 'Shital', ''], ['Behl', 'Harkirat Singh', ''], ['Wang', 'Xin', ''], ['Bubeck', 'Sébastien', ''], ['Eldan', 'Ronen', ''], ['Kalai', 'Adam Tauman', ''], ['Lee', 'Yin Tat', ''], ['Li', 'Yuanzhi', '']]",0,1,2023-06-20,2,19,3,1,0,1,2922768fd451ecdb45f48c1a83eb57f54a91221b,259203998.0,https://www.semanticscholar.org/paper/2922768fd451ecdb45f48c1a83eb57f54a91221b,arXiv.org,2023.0,41.0,41.0,2.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3317356', 'name': 'Suriya Gunasekar'}, {'authorId': '2153910714', 'name': 'Yi Zhang'}, {'authorId': '29956361', 'name': 'J. Aneja'}, {'authorId': '2157424631', 'name': 'C. C. T. Mendes'}, {'authorId': '50672277', 'name': 'Allison Del Giorno'}, {'authorId': '40528805', 'name': 'Sivakanth Gopi'}, {'authorId': '51900416', 'name': 'Mojan Javaheripi'}, {'authorId': '2160340819', 'name': 'Piero C. Kauffmann'}, {'authorId': '144977605', 'name': 'Gustavo de Rosa'}, {'authorId': '2347792', 'name': 'Olli Saarikivi'}, {'authorId': '24929535', 'name': 'A. Salim'}, {'authorId': '47973411', 'name': 'S. Shah'}, {'authorId': '145560551', 'name': 'Harkirat Singh Behl'}, {'authorId': '2153689937', 'name': 'Xin Wang'}, {'authorId': '121645690', 'name': 'Sébastien Bubeck'}, {'authorId': '2315830', 'name': 'Ronen Eldan'}, {'authorId': '2186481', 'name': 'A. Kalai'}, {'authorId': '2109308930', 'name': 'Y. Lee'}, {'authorId': '152244300', 'name': 'Yuan-Fang Li'}]",['Microsoft'],['India'],2023-06
2306.11817,Jan \v{Z}i\v{z}ka,"Jan \v{Z}i\v{z}ka, Bruno Rossi, Tom\'a\v{s} Pitner",Towards a Definition of Complex Software System,7 pages,,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Complex Systems were identified and studied in different fields, such as physics, biology, and economics. These systems exhibit exciting properties such as self-organization, robust order, and emergence. In recent years, software systems displaying behaviors associated with Complex Systems are starting to appear, and these behaviors are showing previously unknown potential (e.g., GPT-based applications). Yet, there is no commonly shared definition of a Complex Software System that can serve as a key reference for academia to support research in the area. In this paper, we adopt the theory-to-research strategy to extract properties of Complex Systems from research in other fields, mapping them to software systems to create a formal definition of a Complex Software System. We support the evolution of the properties through future validation, and we provide examples of the application of the definition. Overall, the definition will allow for a more precise, consistent, and rigorous frame of reference for conducting scientific research on software systems. ","[{'version': 'v1', 'created': 'Tue, 20 Jun 2023 18:22:21 GMT'}]",2023-06-22,"[['Žižka', 'Jan', ''], ['Rossi', 'Bruno', ''], ['Pitner', 'Tomáš', '']]",0,1,2023-06-20,1,3,1,0,0,0,e11b04bf3ab7e340b78f89bf1741212acd0eee52,259211823.0,https://www.semanticscholar.org/paper/e11b04bf3ab7e340b78f89bf1741212acd0eee52,Conference on Computer Science and Information Systems,2023.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2152841', 'name': 'J. Zizka'}, {'authorId': '36811031', 'name': 'B. Rossi'}, {'authorId': '2123351366', 'name': 'Tomás Pitner'}]",['Masaryk University'],['Czechia'],2023-06
2306.12132,Krishna Ronanki,"Krishna Ronanki, Beatriz Cabrero-Daniel, and Christian Berger",ChatGPT as a tool for User Story Quality Evaluation: Trustworthy Out of the Box?,"9 Pages, 2 Tables, 1 Figure. Accepted at AI-Assisted Agile Software
  Development Workshop (Co-located with XP 2023)",,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  In Agile software development, user stories play a vital role in capturing and conveying end-user needs, prioritizing features, and facilitating communication and collaboration within development teams. However, automated methods for evaluating user stories require training in NLP tools and can be time-consuming to develop and integrate. This study explores using ChatGPT for user story quality evaluation and compares its performance with an existing benchmark. Our study shows that ChatGPT's evaluation aligns well with human evaluation, and we propose a ``best of three'' strategy to improve its output stability. We also discuss the concept of trustworthiness in AI and its implications for non-experts using ChatGPT's unprocessed outputs. Our research contributes to understanding the reliability and applicability of AI in user story evaluation and offers recommendations for future research. ","[{'version': 'v1', 'created': 'Wed, 21 Jun 2023 09:26:27 GMT'}]",2023-06-22,"[['Ronanki', 'Krishna', ''], ['Cabrero-Daniel', 'Beatriz', ''], ['Berger', 'Christian', '']]",1,1,2023-06-21,1,3,1,1,0,1,55728d968ae0ff7127a0ca38d3ed721ef71d976b,259212147.0,https://www.semanticscholar.org/paper/55728d968ae0ff7127a0ca38d3ed721ef71d976b,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2219554412', 'name': 'Krishna Ronanki'}, {'authorId': '118093354', 'name': 'Beatriz Cabrero Daniel'}, {'authorId': '2220345997', 'name': 'Christian Berger'}]",['University of Gothenburg'],['Sweden'],2023-06
2306.12146,Robin Chan,"Robin Chan, Afra Amini, Mennatallah El-Assady",Which Spurious Correlations Impact Reasoning in NLI Models? A Visual Interactive Diagnosis through Data-Constrained Counterfactuals,"7 pages, Accepted at ACL 2023: System Demonstrations",,,,cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a human-in-the-loop dashboard tailored to diagnosing potential spurious features that NLI models rely on for predictions. The dashboard enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions. Additionally, users can receive feedback from a trained NLI model on how challenging the newly created example is and make refinements based on the feedback. Through our investigation, we discover several categories of spurious correlations that impact the reasoning of NLI models, which we group into three categories: Semantic Relevance, Logical Fallacies, and Bias. Based on our findings, we identify and describe various research opportunities, including diversifying training data and assessing NLI models' robustness by creating adversarial test suites. ","[{'version': 'v1', 'created': 'Wed, 21 Jun 2023 09:50:48 GMT'}]",2023-06-22,"[['Chan', 'Robin', ''], ['Amini', 'Afra', ''], ['El-Assady', 'Mennatallah', '']]",0,1,2023-06-21,1,3,2,1,0,1,7cf2a34fb971441dcc77c905fe2fe1741ef1837f,259211856.0,https://www.semanticscholar.org/paper/7cf2a34fb971441dcc77c905fe2fe1741ef1837f,Annual Meeting of the Association for Computational Linguistics,2023.0,18.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '4253866', 'name': 'Robin Chan'}, {'authorId': '1820796225', 'name': 'Afra Amini'}, {'authorId': '1401917601', 'name': 'Mennatallah El-Assady'}]",['Qu & Co. (Netherlands)'],['Netherlands'],2023-06
2306.12205,Mohamad Ballout,"Mohamad Ballout, Ulf Krumnack, Gunther Heidemann and Kai-Uwe
  K\""uhnberger","Investigating Pre-trained Language Models on Cross-Domain Datasets, a Step Closer to General AI",,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Pre-trained language models have recently emerged as a powerful tool for fine-tuning a variety of language tasks. Ideally, when models are pre-trained on large amount of data, they are expected to gain implicit knowledge. In this paper, we investigate the ability of pre-trained language models to generalize to different non-language tasks. In particular, we test them on tasks from different domains such as computer vision, reasoning on hierarchical data, and protein fold prediction. The four pre-trained models that we used, T5, BART, BERT, and GPT-2 achieve outstanding results. They all have similar performance and they outperform transformers that are trained from scratch by a large margin. For instance, pre-trained language models perform better on the Listops dataset, with an average accuracy of 58.7\%, compared to transformers trained from scratch, which have an average accuracy of 29.0\%. The significant improvement demonstrated across three types of datasets suggests that pre-training on language helps the models to acquire general knowledge, bringing us a step closer to general AI. We also showed that reducing the number of parameters in pre-trained language models does not have a great impact as the performance drops slightly when using T5-Small instead of T5-Base. In fact, when using only 2\% of the parameters, we achieved a great improvement compared to training from scratch. Finally, in contrast to prior work, we find out that using pre-trained embeddings for the input layer is necessary to achieve the desired results. ","[{'version': 'v1', 'created': 'Wed, 21 Jun 2023 11:55:17 GMT'}]",2023-06-22,"[['Ballout', 'Mohamad', ''], ['Krumnack', 'Ulf', ''], ['Heidemann', 'Gunther', ''], ['Kühnberger', 'Kai-Uwe', '']]",0,1,2023-06-21,1,4,2,2,2,0,b43383f10634f7e610f22badd4f42c93e5dcb947,259211816.0,https://www.semanticscholar.org/paper/b43383f10634f7e610f22badd4f42c93e5dcb947,INNS DLIA@IJCNN,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1491169373', 'name': 'Mohamad Ballout'}, {'authorId': '1751765', 'name': 'U. Krumnack'}, {'authorId': '1803409', 'name': 'G. Heidemann'}, {'authorId': '1743582', 'name': 'Kai-Uwe Kühnberger'}]",['Osnabrück University'],['Germany'],2023-06
2306.12567,Koji Mineshima,"Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima,
  Mitsuhiro Okada",Evaluating Large Language Models with NeuBAROCO: Syllogistic Reasoning Ability and Human-like Biases,"To appear in Proceedings of the 4th Natural Logic Meets Machine
  Learning Workshop (NALOMA IV)",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper investigates whether current large language models exhibit biases in logical reasoning, similar to humans. Specifically, we focus on syllogistic reasoning, a well-studied form of inference in the cognitive science of human deduction. To facilitate our analysis, we introduce a dataset called NeuBAROCO, originally designed for psychological experiments that assess human logical abilities in syllogistic reasoning. The dataset consists of syllogistic inferences in both English and Japanese. We examine three types of biases observed in human syllogistic reasoning: belief biases, conversion errors, and atmosphere effects. Our findings demonstrate that current large language models struggle more with problems involving these three types of biases. ","[{'version': 'v1', 'created': 'Wed, 21 Jun 2023 21:04:11 GMT'}]",2023-06-23,"[['Ando', 'Risako', ''], ['Morishita', 'Takanobu', ''], ['Abe', 'Hirohiko', ''], ['Mineshima', 'Koji', ''], ['Okada', 'Mitsuhiro', '']]",0,0,2023-06-21,1,5,2,0,0,0,8ac0a5d4ee77fcb420aa4fbb999d26bae2d0b130,259224503.0,https://www.semanticscholar.org/paper/8ac0a5d4ee77fcb420aa4fbb999d26bae2d0b130,NALOMA,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2220404504', 'name': 'Risako Ando'}, {'authorId': '2220403840', 'name': 'Takanobu Morishita'}, {'authorId': '2069103180', 'name': 'Hirohiko Abe'}, {'authorId': '2106670', 'name': 'K. Mineshima'}, {'authorId': '1690288', 'name': 'M. Okada'}]",['Keio University'],['Japan'],2023-06
2306.12916,Ran Zhang,"Ran Zhang, Jihed Ouni, Steffen Eger","Cross-lingual Cross-temporal Summarization: Dataset, Models, Evaluation",Version 2; Work in progress,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  While summarization has been extensively researched in natural language processing (NLP), cross-lingual cross-temporal summarization (CLCTS) is a largely unexplored area that has the potential to improve cross-cultural accessibility and understanding. This paper comprehensively addresses the CLCTS task, including dataset creation, modeling, and evaluation. We build the first CLCTS corpus, leveraging historical fictive texts and Wikipedia summaries in English and German, and examine the effectiveness of popular transformer end-to-end models with different intermediate finetuning tasks. Additionally, we explore the potential of ChatGPT for CLCTS as a summarizer and an evaluator. Overall, we report evaluations from humans, ChatGPT, and several recent automatic evaluation metrics where we find that our intermediate task finetuned end-to-end models generate bad to moderate quality summaries; ChatGPT as a summarizer (without any finetuning) provides moderate to good quality outputs and as an evaluator correlates moderately with human evaluations but is prone to giving lower scores. ChatGPT also seems very adept at normalizing historical text and outperforms context-unaware spelling normalization tools such as Norma. We finally test ChatGPT in a scenario with adversarially attacked and unseen source documents and find that ChatGPT profits from its prior knowledge to a certain degree, with better performances for omission and entity swap than negation against its prior knowledge. This benefit inflates its assessed quality as ChatGPT performs slightly worse for unseen source documents compared to seen documents. We additionally introspect our models' performances to find that longer, older and more complex source texts (all of which are more characteristic for historical language variants) are harder to summarize for all models, indicating the difficulty of the CLCTS task. ","[{'version': 'v1', 'created': 'Thu, 22 Jun 2023 14:31:18 GMT'}, {'version': 'v2', 'created': 'Thu, 13 Jul 2023 16:48:55 GMT'}]",2023-07-17,"[['Zhang', 'Ran', ''], ['Ouni', 'Jihed', ''], ['Eger', 'Steffen', '']]",1,1,2023-06-22,2,3,1,1,0,1,543cf2cef500c22407a39ad460c87339fadceaf9,259224488.0,https://www.semanticscholar.org/paper/543cf2cef500c22407a39ad460c87339fadceaf9,arXiv.org,2023.0,95.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2019013527', 'name': 'Ran Zhang'}, {'authorId': '2220406599', 'name': 'Jihed Ouni'}, {'authorId': '2620186', 'name': 'Steffen Eger'}]","['Inspiration 1, Bielefeld, 33619, North Rhine-Westphalia, Germany.', 'Bielefeld University', 'Technical University of Darmstadt']",['Germany'],2023-06
2306.12925,Paul Rubenstein,"Paul K. Rubenstein, Chulayuth Asawaroengchai, Duc Dung Nguyen, Ankur
  Bapna, Zal\'an Borsos, F\'elix de Chaumont Quitry, Peter Chen, Dalia El
  Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, Dirk Padfield, James
  Qin, Danny Rozenberg, Tara Sainath, Johan Schalkwyk, Matt Sharifi, Michelle
  Tadmor Ramanovich, Marco Tagliasacchi, Alexandru Tudor, Mihajlo
  Velimirovi\'c, Damien Vincent, Jiahui Yu, Yongqiang Wang, Vicky Zayats, Neil
  Zeghidour, Yu Zhang, Zhishuai Zhang, Lukas Zilka, Christian Frank",AudioPaLM: A Large Language Model That Can Speak and Listen,Technical report,,,,cs.CL cs.AI cs.SD eess.AS stat.ML,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce AudioPaLM, a large language model for speech understanding and generation. AudioPaLM fuses text-based and speech-based language models, PaLM-2 [Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unified multimodal architecture that can process and generate text and speech with applications including speech recognition and speech-to-speech translation. AudioPaLM inherits the capability to preserve paralinguistic information such as speaker identity and intonation from AudioLM and the linguistic knowledge present only in text large language models such as PaLM-2. We demonstrate that initializing AudioPaLM with the weights of a text-only large language model improves speech processing, successfully leveraging the larger quantity of text training data used in pretraining to assist with the speech tasks. The resulting model significantly outperforms existing systems for speech translation tasks and has the ability to perform zero-shot speech-to-text translation for many languages for which input/target language combinations were not seen in training. AudioPaLM also demonstrates features of audio language models, such as transferring a voice across languages based on a short spoken prompt. We release examples of our method at https://google-research.github.io/seanet/audiopalm/examples ","[{'version': 'v1', 'created': 'Thu, 22 Jun 2023 14:37:54 GMT'}]",2023-06-23,"[['Rubenstein', 'Paul K.', ''], ['Asawaroengchai', 'Chulayuth', ''], ['Nguyen', 'Duc Dung', ''], ['Bapna', 'Ankur', ''], ['Borsos', 'Zalán', ''], ['Quitry', 'Félix de Chaumont', ''], ['Chen', 'Peter', ''], ['Badawy', 'Dalia El', ''], ['Han', 'Wei', ''], ['Kharitonov', 'Eugene', ''], ['Muckenhirn', 'Hannah', ''], ['Padfield', 'Dirk', ''], ['Qin', 'James', ''], ['Rozenberg', 'Danny', ''], ['Sainath', 'Tara', ''], ['Schalkwyk', 'Johan', ''], ['Sharifi', 'Matt', ''], ['Ramanovich', 'Michelle Tadmor', ''], ['Tagliasacchi', 'Marco', ''], ['Tudor', 'Alexandru', ''], ['Velimirović', 'Mihajlo', ''], ['Vincent', 'Damien', ''], ['Yu', 'Jiahui', ''], ['Wang', 'Yongqiang', ''], ['Zayats', 'Vicky', ''], ['Zeghidour', 'Neil', ''], ['Zhang', 'Yu', ''], ['Zhang', 'Zhishuai', ''], ['Zilka', 'Lukas', ''], ['Frank', 'Christian', '']]",0,0,2023-06-22,1,30,5,1,0,1,3efb81de24eb88017d6dbcf22cb4215084223fd8,259224345.0,https://www.semanticscholar.org/paper/3efb81de24eb88017d6dbcf22cb4215084223fd8,arXiv.org,2023.0,79.0,41.0,2.0,True,"['Computer Science', 'Engineering', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48159426', 'name': 'Paul K. Rubenstein'}, {'authorId': '50844587', 'name': 'Chulayuth Asawaroengchai'}, {'authorId': '2149981', 'name': 'D. Nguyen'}, {'authorId': '12295226', 'name': 'Ankur Bapna'}, {'authorId': '144494941', 'name': 'Zalán Borsos'}, {'authorId': '123721125', 'name': 'F. D. C. Quitry'}, {'authorId': '2120245658', 'name': 'Peter Chen'}, {'authorId': '2489672', 'name': 'Dalia El Badawy'}, {'authorId': '72549949', 'name': 'Wei Han'}, {'authorId': '144875326', 'name': 'E. Kharitonov'}, {'authorId': '4563878', 'name': 'Hannah Muckenhirn'}, {'authorId': '1745683', 'name': 'D. Padfield'}, {'authorId': '47901308', 'name': 'James Qin'}, {'authorId': '18439314', 'name': 'Daniel Rozenberg'}, {'authorId': '1784851', 'name': 'Tara N. Sainath'}, {'authorId': '1698491', 'name': 'J. Schalkwyk'}, {'authorId': '2112139582', 'name': 'Matthew Sharifi'}, {'authorId': '4122989', 'name': 'Michelle D. Tadmor'}, {'authorId': '2220407386', 'name': 'Ramanovich'}, {'authorId': '1749128', 'name': 'M. Tagliasacchi'}, {'authorId': '50205505', 'name': 'A. Tudor'}, {'authorId': '2220407384', 'name': ""Mihajlo Velimirovi'c""}, {'authorId': '2055932105', 'name': 'Damien Vincent'}, {'authorId': '150167366', 'name': 'Jiahui Yu'}, {'authorId': '2108220460', 'name': 'Yongqiang Wang'}, {'authorId': '143689491', 'name': 'V. Zayats'}, {'authorId': '3404556', 'name': 'Neil Zeghidour'}, {'authorId': '2153632494', 'name': 'Yu Zhang'}, {'authorId': '2144459658', 'name': 'Zhishuai Zhang'}, {'authorId': '1780245', 'name': 'Lukás Zilka'}, {'authorId': '152871063', 'name': 'C. Frank'}]",['FELIX Laboratory'],['Netherlands'],2023-06
2306.12929,Yelysei Bondarenko,"Yelysei Bondarenko, Markus Nagel, Tijmen Blankevoort",Quantizable Transformers: Removing Outliers by Helping Attention Heads Do Nothing,,,,,cs.LG cs.AI cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Transformer models have been widely adopted in various domains over the last years, and especially large language models have advanced the field of AI significantly. Due to their size, the capability of these networks has increased tremendously, but this has come at the cost of a significant increase in necessary compute. Quantization is one of the most effective ways to reduce the computational time and memory consumption of neural networks. Many studies have shown, however, that modern transformer models tend to learn strong outliers in their activations, making them difficult to quantize. To retain acceptable performance, the existence of these outliers requires activations to be in higher bitwidth or the use of different numeric formats, extra fine-tuning, or other workarounds. We show that strong outliers are related to very specific behavior of attention heads that try to learn a ""no-op"" or just a partial update of the residual. To achieve the exact zeros needed in the attention matrix for a no-update, the input to the softmax is pushed to be larger and larger during training, causing outliers in other parts of the network. Based on these observations, we propose two simple (independent) modifications to the attention mechanism - clipped softmax and gated attention. We empirically show that models pre-trained using our methods learn significantly smaller outliers while maintaining and sometimes even improving the floating-point task performance. This enables us to quantize transformers to full INT8 quantization of the activations without any additional effort. We demonstrate the effectiveness of our methods on both language models (BERT, OPT) and vision transformers. ","[{'version': 'v1', 'created': 'Thu, 22 Jun 2023 14:39:04 GMT'}]",2023-06-23,"[['Bondarenko', 'Yelysei', ''], ['Nagel', 'Markus', ''], ['Blankevoort', 'Tijmen', '']]",0,0,2023-06-22,1,3,4,1,1,0,d193675b92fbfbf22ed82fda35cd2e73587e33bd,259224568.0,https://www.semanticscholar.org/paper/d193675b92fbfbf22ed82fda35cd2e73587e33bd,arXiv.org,2023.0,80.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112207572', 'name': 'Yelysei Bondarenko'}, {'authorId': '41229153', 'name': 'Markus Nagel'}, {'authorId': '83133279', 'name': 'Tijmen Blankevoort'}]","['Qualcomm', 'Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc. 37th Conference on Neural Information Processing Systems (NeurIPS 2023).']",['Netherlands'],2023-06
2306.13041,Christoph Leiter,"Christoph Leiter, Piyawat Lertvittayakumjorn, Marina Fomicheva, Wei
  Zhao, Yang Gao, Steffen Eger",Towards Explainable Evaluation Metrics for Machine Translation,"Preprint. We published an earlier version of this paper
  (arXiv:2203.11131) under a different title. Both versions consider the
  conceptualization of explainable metrics and are overall similar. However,
  the new version puts a stronger emphasis on the survey of approaches for the
  explanation of MT metrics including the latest LLM based approaches",,,,cs.CL cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Unlike classical lexical overlap metrics such as BLEU, most current evaluation metrics for machine translation (for example, COMET or BERTScore) are based on black-box large language models. They often achieve strong correlations with human judgments, but recent research indicates that the lower-quality classical metrics remain dominant, one of the potential reasons being that their decision processes are more transparent. To foster more widespread acceptance of novel high-quality metrics, explainability thus becomes crucial. In this concept paper, we identify key properties as well as key goals of explainable machine translation metrics and provide a comprehensive synthesis of recent techniques, relating them to our established goals and properties. In this context, we also discuss the latest state-of-the-art approaches to explainable metrics based on generative models such as ChatGPT and GPT4. Finally, we contribute a vision of next-generation approaches, including natural language explanations. We hope that our work can help catalyze and guide future research on explainable evaluation metrics and, mediately, also contribute to better and more transparent machine translation systems. ","[{'version': 'v1', 'created': 'Thu, 22 Jun 2023 17:07:57 GMT'}]",2023-06-23,"[['Leiter', 'Christoph', ''], ['Lertvittayakumjorn', 'Piyawat', ''], ['Fomicheva', 'Marina', ''], ['Zhao', 'Wei', ''], ['Gao', 'Yang', ''], ['Eger', 'Steffen', '']]",1,1,2023-06-22,1,6,3,2,0,2,8c835daaf7720a168e5d3d669f419765c510bbaf,259224689.0,https://www.semanticscholar.org/paper/8c835daaf7720a168e5d3d669f419765c510bbaf,arXiv.org,2023.0,162.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66122857', 'name': 'Christoph Leiter'}, {'authorId': '9433771', 'name': 'Piyawat Lertvittayakumjorn'}, {'authorId': '2006017', 'name': 'M. Fomicheva'}, {'authorId': '2150717334', 'name': 'Wei Zhao'}, {'authorId': '2145974284', 'name': 'Yang Gao'}, {'authorId': '2620186', 'name': 'Steffen Eger'}]","['Imperial College London', 'Heidelberg Institute for Theoretical Studies', 'University of Sheffield', 'Bielefeld University']","['Germany', 'United Kingdom']",2023-06
2306.13149,Soumyajit Chatterjee Dr.,"Soumyajit Chatterjee, Bivas Mitra and Sandip Chakraborty",AmicroN: A Framework for Generating Annotations for Human Activity Recognition with Granular Micro-Activities,"27 pages, 5 tables, 9 figures",,,,cs.HC cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Efficient human activity recognition (HAR) using sensor data needs a significant volume of annotated data. The growing volume of unlabelled sensor data has challenged conventional practices for gathering HAR annotations with human-in-the-loop approaches, often leading to the collection of shallower annotations. These shallower annotations ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL). Understanding this, we, in this paper, first analyze this lack of granular annotations from available pre-annotated datasets to understand the practical inconsistencies and also perform a detailed survey to look into the human perception surrounding annotations. Drawing motivations from these, we next develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures and the available coarse-grain macro-activity labels. In the backend, AmicroN applies change-point detection followed by zero-shot learning with activity embeddings to identify the unseen micro-activities in an unsupervised manner. Rigorous evaluation on publicly available datasets shows that AmicroN can accurately generate micro-activity annotations with a median F1-score of >0.75. Additionally, we also show that AmicroN can be used in a plug-and-play manner with Large Language Models (LLMs) to obtain the micro-activity labels, thus making it more practical for realistic applications. ","[{'version': 'v1', 'created': 'Thu, 22 Jun 2023 18:14:54 GMT'}]",2023-06-26,"[['Chatterjee', 'Soumyajit', ''], ['Mitra', 'Bivas', ''], ['Chakraborty', 'Sandip', '']]",0,0,2023-06-22,1,3,2,0,0,0,b4a0ce017315272675e5ac9716e47bd745339b55,259243798.0,https://www.semanticscholar.org/paper/b4a0ce017315272675e5ac9716e47bd745339b55,arXiv.org,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1557390030', 'name': 'S. Chatterjee'}, {'authorId': '144985652', 'name': 'Bivas Mitra'}, {'authorId': '1708109', 'name': 'Sandip Chakraborty'}]",['Indian Institute of Technology Kharagpur'],['India'],2023-06
2306.13298,Didar Zowghi,"Muneera Bano, Didar Zowghi, Jon Whittle",Exploring Qualitative Research Using LLMs,,,,,cs.SE cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The advent of AI driven large language models (LLMs) have stirred discussions about their role in qualitative research. Some view these as tools to enrich human understanding, while others perceive them as threats to the core values of the discipline. This study aimed to compare and contrast the comprehension capabilities of humans and LLMs. We conducted an experiment with small sample of Alexa app reviews, initially classified by a human analyst. LLMs were then asked to classify these reviews and provide the reasoning behind each classification. We compared the results with human classification and reasoning. The research indicated a significant alignment between human and ChatGPT 3.5 classifications in one third of cases, and a slightly lower alignment with GPT4 in over a quarter of cases. The two AI models showed a higher alignment, observed in more than half of the instances. However, a consensus across all three methods was seen only in about one fifth of the classifications. In the comparison of human and LLMs reasoning, it appears that human analysts lean heavily on their individual experiences. As expected, LLMs, on the other hand, base their reasoning on the specific word choices found in app reviews and the functional components of the app itself. Our results highlight the potential for effective human LLM collaboration, suggesting a synergistic rather than competitive relationship. Researchers must continuously evaluate LLMs role in their work, thereby fostering a future where AI and humans jointly enrich qualitative research. ","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 05:21:36 GMT'}]",2023-06-26,"[['Bano', 'Muneera', ''], ['Zowghi', 'Didar', ''], ['Whittle', 'Jon', '']]",1,1,2023-06-23,1,3,2,2,0,2,bbfcc31b79110c28047b2ba03ee55335acc8e47c,259243589.0,https://www.semanticscholar.org/paper/bbfcc31b79110c28047b2ba03ee55335acc8e47c,arXiv.org,2023.0,48.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2514873', 'name': 'Muneera Bano'}, {'authorId': '1740931', 'name': 'D. Zowghi'}, {'authorId': '2193085367', 'name': 'Jon Whittle'}]",['Data61'],['Australia'],2023-06
2306.13467,Pere-Llu\'is Huguet Cabot,"Pavlo Vasylenko, Pere-Llu\'is Huguet Cabot, Abelardo Carlos Mart\'inez
  Lorenzo, Roberto Navigli",Incorporating Graph Information in Transformer-based AMR Parsing,"ACL 2023. Please cite authors correctly using both lastnames
  (""Mart\'inez Lorenzo"", ""Huguet Cabot"")",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that aims at providing a semantic graph abstraction representing a given text. Current approaches are based on autoregressive language models such as BART or T5, fine-tuned through Teacher Forcing to obtain a linearized version of the AMR graph from a sentence. In this paper, we present LeakDistill, a model and method that explores a modification to the Transformer architecture, using structural adapters to explicitly incorporate graph information into the learned representations and improve AMR parsing performance. Our experiments show how, by employing word-to-node alignment to embed graph structural information into the encoder at training time, we can obtain state-of-the-art AMR parsing through self-knowledge distillation, even without the use of additional data. We release the code at \url{http://www.github.com/sapienzanlp/LeakDistill}. ","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 12:12:08 GMT'}]",2023-06-26,"[['Vasylenko', 'Pavlo', ''], ['Cabot', 'Pere-Lluís Huguet', ''], ['Lorenzo', 'Abelardo Carlos Martínez', ''], ['Navigli', 'Roberto', '']]",0,0,2023-06-23,1,4,2,1,1,0,5962a137d5cebd8e0c07a3cee0eef75eb1e4fa80,259244018.0,https://www.semanticscholar.org/paper/5962a137d5cebd8e0c07a3cee0eef75eb1e4fa80,Annual Meeting of the Association for Computational Linguistics,2023.0,55.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2220506640', 'name': 'Pavlo Vasylenko'}, {'authorId': '2096255608', 'name': ""Pere-Llu'is Huguet Cabot""}, {'authorId': '2165227698', 'name': 'Abelardo Carlos Martínez Lorenzo'}, {'authorId': '2068519190', 'name': 'Roberto Navigli'}]","['Laboratorio di Scienze della Cittadinanza', 'Sapienza University of Rome']",['Italy'],2023-06
2306.13554,Massimiliano Patacchiola PhD,"Massimiliano Patacchiola, Mingfei Sun, Katja Hofmann, Richard E.
  Turner",Comparing the Efficacy of Fine-Tuning and Meta-Learning for Few-Shot Policy Imitation,,,,,cs.LG cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this paper we explore few-shot imitation learning for control problems, which involves learning to imitate a target policy by accessing a limited set of offline rollouts. This setting has been relatively under-explored despite its relevance to robotics and control applications. State-of-the-art methods developed to tackle few-shot imitation rely on meta-learning, which is expensive to train as it requires access to a distribution over tasks (rollouts from many target policies and variations of the base environment). Given this limitation we investigate an alternative approach, fine-tuning, a family of methods that pretrain on a single dataset and then fine-tune on unseen domain-specific data. Recent work has shown that fine-tuners outperform meta-learners in few-shot image classification tasks, especially when the data is out-of-domain. Here we evaluate to what extent this is true for control problems, proposing a simple yet effective baseline which relies on two stages: (i) training a base policy online via reinforcement learning (e.g. Soft Actor-Critic) on a single base environment, (ii) fine-tuning the base policy via behavioral cloning on a few offline rollouts of the target policy. Despite its simplicity this baseline is competitive with meta-learning methods on a variety of conditions and is able to imitate target policies trained on unseen variations of the original environment. Importantly, the proposed approach is practical and easy to implement, as it does not need any complex meta-training protocol. As a further contribution, we release an open source dataset called iMuJoCo (iMitation MuJoCo) consisting of 154 variants of popular OpenAI-Gym MuJoCo environments with associated pretrained target policies and rollouts, which can be used by the community to study few-shot imitation learning and offline reinforcement learning. ","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 15:29:15 GMT'}]",2023-06-26,"[['Patacchiola', 'Massimiliano', ''], ['Sun', 'Mingfei', ''], ['Hofmann', 'Katja', ''], ['Turner', 'Richard E.', '']]",0,0,2023-06-23,1,4,2,0,0,0,c923f05ac87491069134f12c22087fa8f18045e6,259243672.0,https://www.semanticscholar.org/paper/c923f05ac87491069134f12c22087fa8f18045e6,arXiv.org,2023.0,64.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3366919', 'name': 'Massimiliano Patacchiola'}, {'authorId': '9492808', 'name': 'Mingfei Sun'}, {'authorId': '1380228856', 'name': 'Katja Hofmann'}, {'authorId': '145369890', 'name': 'Richard E. Turner'}]","['University of Cambridge', 'Microsoft', 'University of Manchester']","['India', 'United Kingdom']",2023-06
2306.13649,Rishabh Agarwal,"Rishabh Agarwal, Nino Vieillard, Yongchao Zhou, Piotr Stanczyk, Sabela
  Ramos, Matthieu Geist, Olivier Bachem",Generalized Knowledge Distillation for Auto-regressive Language Models,"First two authors contributed equally. Added new results and
  experiment details",,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Knowledge distillation (KD) is widely used for compressing a teacher model to reduce its inference cost and memory footprint, by training a smaller student model. However, current KD methods for auto-regressive sequence models suffer from distribution mismatch between output sequences seen during training and those generated by the student during inference. To address this issue, we introduce Generalized Knowledge Distillation (GKD). Instead of solely relying on a fixed set of output sequences, GKD trains the student on its self-generated output sequences by leveraging feedback from the teacher on such sequences. Unlike supervised KD approaches, GKD also offers the flexibility to employ alternative loss functions between the student and teacher, which can be useful when the student lacks the expressivity to mimic the teacher's distribution. Furthermore, GKD facilitates the seamless integration of distillation with RL fine-tuning (RLHF). We demonstrate the efficacy of GKD for distilling auto-regressive T5 language models on summarization, translation, and arithmetic reasoning tasks as well as task-agnostic instruction tuning. ","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 17:56:26 GMT'}, {'version': 'v2', 'created': 'Tue, 3 Oct 2023 05:30:36 GMT'}]",2023-10-04,"[['Agarwal', 'Rishabh', ''], ['Vieillard', 'Nino', ''], ['Zhou', 'Yongchao', ''], ['Stanczyk', 'Piotr', ''], ['Ramos', 'Sabela', ''], ['Geist', 'Matthieu', ''], ['Bachem', 'Olivier', '']]",0,0,2023-06-23,2,7,3,1,1,0,7fe07280b6fa92e88462fe173169df6e8b145a70,263610088.0,https://www.semanticscholar.org/paper/7fe07280b6fa92e88462fe173169df6e8b145a70,,2023.0,47.0,1.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2253488622', 'name': 'Rishabh Agarwal'}, {'authorId': '138497788', 'name': 'Nino Vieillard'}, {'authorId': '2189664830', 'name': 'Yongchao Zhou'}, {'authorId': '2067024583', 'name': 'P. Stańczyk'}, {'authorId': '2253595555', 'name': 'Sabela Ramos'}, {'authorId': '2253609155', 'name': 'Matthieu Geist'}, {'authorId': '1936951', 'name': 'Olivier Bachem'}]",['University of Toronto'],['Canada'],2023-06
2306.13781,Negar Arabzadeh,"Siqing Huo, Negar Arabzadeh and Charles L. A. Clarke",Retrieving Supporting Evidence for LLMs Generated Answers,,,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current large language models (LLMs) can exhibit near-human levels of performance on many natural language tasks, including open-domain question answering. Unfortunately, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report a simple experiment to automatically verify generated answers against a corpus. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer. We base our experiment on questions and passages from the MS MARCO (V1) test collection, exploring three retrieval approaches ranging from standard BM25 to a full question answering stack, including a reader based on the LLM. For a large fraction of questions, we find that an LLM is capable of verifying its generated answer if appropriate supporting material is provided. However, with an accuracy of 70-80%, this approach cannot be fully relied upon to detect hallucinations. ","[{'version': 'v1', 'created': 'Fri, 23 Jun 2023 20:45:29 GMT'}]",2023-06-27,"[['Huo', 'Siqing', ''], ['Arabzadeh', 'Negar', ''], ['Clarke', 'Charles L. A.', '']]",0,0,2023-06-23,1,3,1,0,0,0,d5bf1808eebf0560b9a18fbdd11c2fac9e7af9f7,259251952.0,https://www.semanticscholar.org/paper/d5bf1808eebf0560b9a18fbdd11c2fac9e7af9f7,arXiv.org,2023.0,32.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2220538755', 'name': 'Siqing Huo'}, {'authorId': '81447039', 'name': 'Negar Arabzadeh'}, {'authorId': '1751287', 'name': 'C. Clarke'}]",['University of Waterloo'],['Canada'],2023-06
2306.13952,Jonas Sandbrink,Jonas B. Sandbrink,Artificial intelligence and biological misuse: Differentiating risks of language models and biological design tools,"8 pages, 1 figure",,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  As advancements in artificial intelligence (AI) propel progress in the life sciences, they may also enable the weaponisation and misuse of biological agents. This article differentiates two classes of AI tools that pose such biosecurity risks: large language models (LLMs) and biological design tools (BDTs). LLMs, such as GPT-4, are already able to provide dual-use information that removes some barriers encountered by historical biological weapons efforts. As LLMs are turned into lab assistants and autonomous science tools, this will further increase their ability to support research. Thus, LLMs will in particular lower barriers to biological misuse. In contrast, BDTs will expand the capabilities of sophisticated actors. Concretely, BDTs may enable the creation of pandemic pathogens substantially worse than anything seen to date and could enable forms of more predictable and targeted biological weapons. In combination, LLMs and BDTs could raise the ceiling of harm from biological agents and could make them broadly accessible. A range of interventions would help to manage risks. Independent pre-release evaluations could ensure that developers have eliminated dangerous capabilities of new models. Risks from powerful science tools might be mitigated through providing differentiated access to legitimate researchers. Lastly, essential for mitigating risks will be universal and enhanced screening of gene synthesis products. ","[{'version': 'v1', 'created': 'Sat, 24 Jun 2023 12:48:49 GMT'}, {'version': 'v2', 'created': 'Tue, 27 Jun 2023 11:42:48 GMT'}, {'version': 'v3', 'created': 'Fri, 14 Jul 2023 07:27:15 GMT'}, {'version': 'v4', 'created': 'Sat, 5 Aug 2023 14:30:23 GMT'}, {'version': 'v5', 'created': 'Sat, 12 Aug 2023 12:08:56 GMT'}]",2023-08-15,"[['Sandbrink', 'Jonas B.', '']]",0,1,2023-06-24,5,1,1,1,0,1,1090aba5e2e7173d00a40b5dbbf48f0a9014ec22,259252204.0,https://www.semanticscholar.org/paper/1090aba5e2e7173d00a40b5dbbf48f0a9014ec22,arXiv.org,2023.0,20.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '2040076460', 'name': 'J. Sandbrink'}]",['University of Oxford'],['United Kingdom'],2023-06
2306.14165,Suhyung Jang,Suhyung Jang and Ghang Lee,Interactive Design by Integrating a Large Pre-Trained Language Model and Building Information Modeling,,,,,cs.AI cs.HC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This study explores the potential of generative artificial intelligence (AI) models, specifically OpenAI's generative pre-trained transformer (GPT) series, when integrated with building information modeling (BIM) tools as an interactive design assistant for architectural design. The research involves the development and implementation of three key components: 1) BIM2XML, a component that translates BIM data into extensible markup language (XML) format; 2) Generative AI-enabled Interactive Architectural design (GAIA), a component that refines the input design in XML by identifying designer intent, relevant objects, and their attributes, using pre-trained language models; and 3) XML2BIM, a component that converts AI-generated XML data back into a BIM tool. This study validated the proposed approach through a case study involving design detailing, using the GPT series and Revit. Our findings demonstrate the effectiveness of state-of-the-art language models in facilitating dynamic collaboration between architects and AI systems, highlighting the potential for further advancements. ","[{'version': 'v1', 'created': 'Sun, 25 Jun 2023 08:18:03 GMT'}]",2023-06-27,"[['Jang', 'Suhyung', ''], ['Lee', 'Ghang', '']]",0,1,2023-06-25,1,2,2,0,0,0,5436d14b9bc754042d874e0f2e64c9c2dc45d995,259251546.0,https://www.semanticscholar.org/paper/5436d14b9bc754042d874e0f2e64c9c2dc45d995,arXiv.org,2023.0,13.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146472330', 'name': 'Suhyung Jang'}, {'authorId': '20001945', 'name': 'Ghang Lee'}]",['Yonsei University'],['South Korea'],2023-06
2306.14457,Andrea Bacciu,"Andrea Bacciu, Giovanni Trappolini, Andrea Santilli, Emanuele
  Rodol\`a, Fabrizio Silvestri",Fauno: The Italian Large Language Model that will leave you senza parole!,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper presents Fauno, the first and largest open-source Italian conversational Large Language Model (LLM). Our goal with Fauno is to democratize the study of LLMs in Italian, demonstrating that obtaining a fine-tuned conversational bot with a single GPU is possible. In addition, we release a collection of datasets for conversational AI in Italian. The datasets on which we fine-tuned Fauno include various topics such as general question answering, computer science, and medical questions. We release our code and datasets on \url{https://github.com/RSTLess-research/Fauno-Italian-LLM} ","[{'version': 'v1', 'created': 'Mon, 26 Jun 2023 07:00:38 GMT'}]",2023-06-27,"[['Bacciu', 'Andrea', ''], ['Trappolini', 'Giovanni', ''], ['Santilli', 'Andrea', ''], ['Rodolà', 'Emanuele', ''], ['Silvestri', 'Fabrizio', '']]",0,0,2023-06-26,1,5,1,0,0,0,b69969bd91206a9f8f3d474df20caa500904143d,259251907.0,https://www.semanticscholar.org/paper/b69969bd91206a9f8f3d474df20caa500904143d,Italian Information Retrieval Workshop,2023.0,44.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151426607', 'name': 'Andrea Bacciu'}, {'authorId': '120709579', 'name': 'Giovanni Trappolini'}, {'authorId': '2065039862', 'name': 'Andrea Santilli'}, {'authorId': '1796150', 'name': 'E. Rodolà'}, {'authorId': '2192306989', 'name': 'Fabrizio Silvestri'}]","['Sapienza University -Computer Science Department', '13th Italian Information Retrieval Workshop, June 8th -9th, 2023, Pisa, Italy', 'Sapienza University -Department of Computer, Control and Management Engineering']",['Italy'],2023-06
2306.14504,"Victor J\""uttner","Victor J\""uttner, Martin Grimmer, Erik Buchmann",ChatIDS: Explainable Cybersecurity Using Generative AI,"4 pages, 1 figure, preprint SECURWARE 2023",,,,cs.CR,http://creativecommons.org/publicdomain/zero/1.0/,"  Intrusion Detection Systems (IDS) are a proven approach to secure networks. However, in a privately used network, it is difficult for users without cybersecurity expertise to understand IDS alerts, and to respond in time with adequate measures. This puts the security of home networks, smart home installations, home-office workers, etc. at risk, even if an IDS is correctly installed and configured. In this work, we propose ChatIDS, our approach to explain IDS alerts to non-experts by using large language models. We evaluate the feasibility of ChatIDS by using ChatGPT, and we identify open research issues with the help of interdisciplinary experts in artificial intelligence. Our results show that ChatIDS has the potential to increase network security by proposing meaningful security measures in an intuitive language from IDS alerts. Nevertheless, some potential issues in areas such as trust, privacy, ethics, etc. need to be resolved, before ChatIDS might be put into practice. ","[{'version': 'v1', 'created': 'Mon, 26 Jun 2023 08:21:47 GMT'}]",2023-06-27,"[['Jüttner', 'Victor', ''], ['Grimmer', 'Martin', ''], ['Buchmann', 'Erik', '']]",1,1,2023-06-26,1,3,1,1,0,1,0a61d40f88bb48bd416888ea9fdab49157ab56ad,259251827.0,https://www.semanticscholar.org/paper/0a61d40f88bb48bd416888ea9fdab49157ab56ad,arXiv.org,2023.0,29.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2099311887', 'name': 'V. Jüttner'}, {'authorId': '50740727', 'name': 'Martin Grimmer'}, {'authorId': '1747453', 'name': 'Erik Buchmann'}]",['Leipzig University'],['Germany'],2023-06
2306.14583,Atsushi Shirafuji,"Atsushi Shirafuji, Yutaka Watanobe, Takumi Ito, Makoto Morishita, Yuki
  Nakamura, Yusuke Oda, Jun Suzuki",Exploring the Robustness of Large Language Models for Solving Programming Problems,,,,,cs.CL cs.AI cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Using large language models (LLMs) for source code has recently gained attention. LLMs, such as Transformer-based models like Codex and ChatGPT, have been shown to be highly capable of solving a wide range of programming problems. However, the extent to which LLMs understand problem descriptions and generate programs accordingly or just retrieve source code from the most relevant problem in training data based on superficial cues has not been discovered yet. To explore this research question, we conduct experiments to understand the robustness of several popular LLMs, CodeGen and GPT-3.5 series models, capable of tackling code generation tasks in introductory programming problems. Our experimental results show that CodeGen and Codex are sensitive to the superficial modifications of problem descriptions and significantly impact code generation performance. Furthermore, we observe that Codex relies on variable names, as randomized variables decrease the solved rate significantly. However, the state-of-the-art (SOTA) models, such as InstructGPT and ChatGPT, show higher robustness to superficial modifications and have an outstanding capability for solving programming problems. This highlights the fact that slight modifications to the prompts given to the LLMs can greatly affect code generation performance, and careful formatting of prompts is essential for high-quality code generation, while the SOTA models are becoming more robust to perturbations. ","[{'version': 'v1', 'created': 'Mon, 26 Jun 2023 10:48:50 GMT'}]",2023-06-27,"[['Shirafuji', 'Atsushi', ''], ['Watanobe', 'Yutaka', ''], ['Ito', 'Takumi', ''], ['Morishita', 'Makoto', ''], ['Nakamura', 'Yuki', ''], ['Oda', 'Yusuke', ''], ['Suzuki', 'Jun', '']]",1,1,2023-06-26,1,7,3,5,1,4,4c8fb68ef6a37cdf713685c17963e6ff6c585081,259252094.0,https://www.semanticscholar.org/paper/4c8fb68ef6a37cdf713685c17963e6ff6c585081,arXiv.org,2023.0,84.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2203414615', 'name': 'Atsushi Shirafuji'}, {'authorId': '1684644', 'name': 'Y. Watanobe'}, {'authorId': '119804885', 'name': 'Takumi Ito'}, {'authorId': '2731589', 'name': 'Makoto Morishita'}, {'authorId': '2203465404', 'name': 'Yuki Nakamura'}, {'authorId': '143800179', 'name': 'Yusuke Oda'}, {'authorId': '2151576111', 'name': 'Jun Suzuki'}]","['Tohoku University', 'University of Aizu']",['Japan'],2023-06
2306.14704,Hang Dong,"Hang Dong, Jiaoyan Chen, Yuan He, Ian Horrocks",Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement,"5 pages, 1 figure, accepted for CIKM 2023. The dataset, data
  construction scripts, and baseline implementation are available at
  https://zenodo.org/record/8228005 (Zenodo) and
  https://github.com/KRR-Oxford/OET (GitHub)",,10.1145/3583780.3615126,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Mentions of new concepts appear regularly in texts and require automated approaches to harvest and place them into Knowledge Bases (KB), e.g., ontologies and taxonomies. Existing datasets suffer from three issues, (i) mostly assuming that a new concept is pre-discovered and cannot support out-of-KB mention discovery; (ii) only using the concept label as the input along with the KB and thus lacking the contexts of a concept label; and (iii) mostly focusing on concept placement w.r.t a taxonomy of atomic concepts, instead of complex concepts, i.e., with logical operators. To address these issues, we propose a new benchmark, adapting MedMentions dataset (PubMed abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases sub-category and the broader categories of Clinical finding, Procedure, and Pharmaceutical / biologic product. We provide usage on the evaluation with the dataset for out-of-KB mention discovery and concept placement, adapting recent Large Language Model based methods. ","[{'version': 'v1', 'created': 'Mon, 26 Jun 2023 13:54:47 GMT'}, {'version': 'v2', 'created': 'Fri, 11 Aug 2023 14:17:56 GMT'}, {'version': 'v3', 'created': 'Fri, 1 Sep 2023 15:26:45 GMT'}]",2023-09-04,"[['Dong', 'Hang', ''], ['Chen', 'Jiaoyan', ''], ['He', 'Yuan', ''], ['Horrocks', 'Ian', '']]",0,0,2023-06-26,3,4,1,0,0,0,c65f36b8e3a87e5e598fe651114681a93d082fb4,259252051.0,https://www.semanticscholar.org/paper/c65f36b8e3a87e5e598fe651114681a93d082fb4,International Conference on Information and Knowledge Management,2023.0,40.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145153805', 'name': 'Hang Dong'}, {'authorId': '1731892', 'name': 'Jiaoyan Chen'}, {'authorId': '46968114', 'name': 'Yuan He'}, {'authorId': '145655431', 'name': 'Ian Horrocks'}]","['University of Manchester', 'University of Oxford']",['United Kingdom'],2023-06
2306.14905,Teo Susnjak,Teo Susnjak,PRISMA-DFLLM: An Extension of PRISMA for Systematic Literature Reviews using Domain-specific Finetuned Large Language Models,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  With the proliferation of open-sourced Large Language Models (LLMs) and efficient finetuning techniques, we are on the cusp of the emergence of numerous domain-specific LLMs that have been finetuned for expertise across specialized fields and applications for which the current general-purpose LLMs are unsuitable. In academia, this technology has the potential to revolutionize the way we conduct systematic literature reviews (SLRs), access knowledge and generate new insights. This paper proposes an AI-enabled methodological framework that combines the power of LLMs with the rigorous reporting guidelines of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). By finetuning LLMs on domain-specific academic papers that have been selected as a result of a rigorous SLR process, the proposed PRISMA-DFLLM (for Domain-specific Finetuned LLMs) reporting guidelines offer the potential to achieve greater efficiency, reusability and scalability, while also opening the potential for conducting incremental living systematic reviews with the aid of LLMs. Additionally, the proposed approach for leveraging LLMs for SLRs enables the dissemination of finetuned models, empowering researchers to accelerate advancements and democratize cutting-edge research. This paper presents the case for the feasibility of finetuned LLMs to support rigorous SLRs and the technical requirements for realizing this. This work then proposes the extended PRISMA-DFLLM checklist of reporting guidelines as well as the advantages, challenges, and potential implications of implementing PRISMA-DFLLM. Finally, a future research roadmap to develop this line of AI-enabled SLRs is presented, paving the way for a new era of evidence synthesis and knowledge discovery. ","[{'version': 'v1', 'created': 'Thu, 15 Jun 2023 02:52:50 GMT'}]",2023-06-28,"[['Susnjak', 'Teo', '']]",0,0,2023-06-15,1,1,2,0,0,0,dfcfb788305aad7e529b8f1e8ea249e1669435cb,259261987.0,https://www.semanticscholar.org/paper/dfcfb788305aad7e529b8f1e8ea249e1669435cb,arXiv.org,2023.0,65.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2656889', 'name': 'Teo Susnjak'}]",['Massey University'],['New Zealand'],2023-06
2306.15518,Jingwei Ni,"Jingwei Ni, Julia Bingler, Chiara Colesanti-Senni, Mathias Kraus, Glen
  Gostlow, Tobias Schimanski, Dominik Stammbach, Saeid Ashraf Vaghefi, Qian
  Wang, Nicolas Webersinke, Tobias Wekhof, Tingyu Yu, Markus Leippold","Paradigm Shift in Sustainability Disclosure Analysis: Empowering Stakeholders with CHATREPORT, a Language Model-Based Tool",This is a working paper,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  This paper introduces a novel approach to enhance Large Language Models (LLMs) with expert knowledge to automate the analysis of corporate sustainability reports by benchmarking them against the Task Force for Climate-Related Financial Disclosures (TCFD) recommendations. Corporate sustainability reports are crucial in assessing organizations' environmental and social risks and impacts. However, analyzing these reports' vast amounts of information makes human analysis often too costly. As a result, only a few entities worldwide have the resources to analyze these reports, which could lead to a lack of transparency. While AI-powered tools can automatically analyze the data, they are prone to inaccuracies as they lack domain-specific expertise. This paper introduces a novel approach to enhance LLMs with expert knowledge to automate the analysis of corporate sustainability reports. We christen our tool CHATREPORT, and apply it in a first use case to assess corporate climate risk disclosures following the TCFD recommendations. CHATREPORT results from collaborating with experts in climate science, finance, economic policy, and computer science, demonstrating how domain experts can be involved in developing AI tools. We make our prompt templates, generated data, and scores available to the public to encourage transparency. ","[{'version': 'v1', 'created': 'Tue, 27 Jun 2023 14:46:47 GMT'}]",2023-06-28,"[['Ni', 'Jingwei', ''], ['Bingler', 'Julia', ''], ['Colesanti-Senni', 'Chiara', ''], ['Kraus', 'Mathias', ''], ['Gostlow', 'Glen', ''], ['Schimanski', 'Tobias', ''], ['Stammbach', 'Dominik', ''], ['Vaghefi', 'Saeid Ashraf', ''], ['Wang', 'Qian', ''], ['Webersinke', 'Nicolas', ''], ['Wekhof', 'Tobias', ''], ['Yu', 'Tingyu', ''], ['Leippold', 'Markus', '']]",0,0,2023-06-27,1,13,1,0,0,0,15dfb06dab3162f4bb7939b0e54c3b68c2b34cc4,259262438.0,https://www.semanticscholar.org/paper/15dfb06dab3162f4bb7939b0e54c3b68c2b34cc4,Social Science Research Network,2023.0,15.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","[{'authorId': '2046974354', 'name': 'Jingwei Ni'}, {'authorId': '2006205621', 'name': 'J. Bingler'}, {'authorId': '2214326368', 'name': 'Chiara Colesanti-Senni'}, {'authorId': '2156865999', 'name': 'Mathias Kraus'}, {'authorId': '1517877494', 'name': 'G. Gostlow'}, {'authorId': '2213295713', 'name': 'Tobias Schimanski'}, {'authorId': '146552774', 'name': 'Dominik Stammbach'}, {'authorId': '1989342', 'name': 'S. Vaghefi'}, {'authorId': '2183631943', 'name': 'Qian Wang'}, {'authorId': '2023644816', 'name': 'Nicolas Webersinke'}, {'authorId': '121304885', 'name': 'Tobias Wekhof'}, {'authorId': '1841103888', 'name': 'Ting Yu'}, {'authorId': '3073566', 'name': 'Markus Leippold'}]","['Council on Economic Policies, Zurich, Switzerland', 'Swiss Federal Institute of Aquatic Science and Technology', 'Friedrich-Alexander-Universität Erlangen-Nürnberg', 'ETH Zurich', 'University of Oxford', 'Swiss Finance Institute', 'University of Zurich']","['Germany', 'United Kingdom', 'Switzerland']",2023-06
2306.15609,Will Yeadon,Will Yeadon and Douglas P. Halliday,Exploring Durham University Physics exams with Large Language Models,"9 pages, 6 figures",,,,physics.ed-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The emergence of advanced Natural Language Processing (NLP) models like ChatGPT has raised concerns among universities regarding AI-driven exam completion. This paper provides a comprehensive evaluation of the proficiency of GPT-4 and GPT-3.5 in answering a set of 42 exam papers derived from 10 distinct physics courses, administered at Durham University over the span of 2018 to 2022, totalling 593 questions and 2504 available marks. These exams, spanning both undergraduate and postgraduate levels, include traditional pre-COVID and adaptive COVID-era formats. Questions from the years 2018-2020 were designed for pre-COVID in person adjudicated examinations whereas the 2021-2022 exams were set for varying COVID-adapted conditions including open-book conditions. To ensure a fair evaluation of AI performances, the exams completed by AI were assessed by the original exam markers. However, due to staffing constraints, only the aforementioned 593 out of the total 1280 questions were marked. GPT-4 and GPT-3.5 scored an average of 49.4\% and 38.6\%, respectively, suggesting only the weaker students would potential improve their marks if using AI. For exams from the pre-COVID era, the average scores for GPT-4 and GPT-3.5 were 50.8\% and 41.6\%, respectively. However, post-COVID, these dropped to 47.5\% and 33.6\%. Thus contrary to expectations, the change to less fact-based questions in the COVID era did not significantly impact AI performance for the state-of-the-art models such as GPT-4. These findings suggest that while current AI models struggle with university-level Physics questions, an improving trend is observable. The code used for automated AI completion is made publicly available for further research. ","[{'version': 'v1', 'created': 'Tue, 27 Jun 2023 16:49:21 GMT'}]",2023-06-28,"[['Yeadon', 'Will', ''], ['Halliday', 'Douglas P.', '']]",1,1,2023-06-27,1,2,1,3,0,3,d0acaa42a1edbd05070d02722dc3d9268dc72b49,259261904.0,https://www.semanticscholar.org/paper/d0acaa42a1edbd05070d02722dc3d9268dc72b49,,2023.0,18.0,3.0,1.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '3982687', 'name': 'W. Yeadon'}, {'authorId': '2059880123', 'name': 'D. Halliday'}]",['Durham University'],['United Kingdom'],2023-06
2306.15666,Debora Weber-Wulff,"Debora Weber-Wulff (University of Applied Sciences HTW Berlin,
  Germany), Alla Anohina-Naumeca (Riga Technical University, Latvia), Sonja
  Bjelobaba (Uppsala University, Sweden), Tom\'a\v{s} Folt\'ynek (Masaryk
  University, Czechia), Jean Guerrero-Dib (Universidad de Monterrey, Mexico),
  Olumide Popoola (Queen Mary University of London, UK), Petr \v{S}igut
  (Masaryk University, Czechia), Lorna Waddington (University of Leeds, UK)",Testing of Detection Tools for AI-Generated Text,"38 pages, 13 figures and 10 tables, and an appendix with 18 figures.
  Submitted to the International Journal for Educational Integrity",,,,cs.CL cs.AI cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advances in generative pre-trained transformer large language models have emphasised the potential risks of unfair use of artificial intelligence (AI) generated content in an academic environment and intensified efforts in searching for solutions to detect such content. The paper examines the general functionality of detection tools for artificial intelligence generated text and evaluates them based on accuracy and error type analysis. Specifically, the study seeks to answer research questions about whether existing detection tools can reliably differentiate between human-written text and ChatGPT-generated text, and whether machine translation and content obfuscation techniques affect the detection of AI-generated text. The research covers 12 publicly available tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely used in the academic setting. The researchers conclude that the available detection tools are neither accurate nor reliable and have a main bias towards classifying the output as human-written rather than detecting AI-generated text. Furthermore, content obfuscation techniques significantly worsen the performance of tools. The study makes several significant contributions. First, it summarises up-to-date similar scientific and non-scientific efforts in the field. Second, it presents the result of one of the most comprehensive tests conducted so far, based on a rigorous research methodology, an original document set, and a broad coverage of tools. Third, it discusses the implications and drawbacks of using detection tools for AI-generated text in academic settings. ","[{'version': 'v1', 'created': 'Wed, 21 Jun 2023 16:29:44 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Jul 2023 16:14:33 GMT'}]",2023-07-11,"[['Weber-Wulff', 'Debora', '', 'University of Applied Sciences HTW Berlin,\n  Germany'], ['Anohina-Naumeca', 'Alla', '', 'Riga Technical University, Latvia'], ['Bjelobaba', 'Sonja', '', 'Uppsala University, Sweden'], ['Foltýnek', 'Tomáš', '', 'Masaryk\n  University, Czechia'], ['Guerrero-Dib', 'Jean', '', 'Universidad de Monterrey, Mexico'], ['Popoola', 'Olumide', '', 'Queen Mary University of London, UK'], ['Šigut', 'Petr', '', 'Masaryk University, Czechia'], ['Waddington', 'Lorna', '', 'University of Leeds, UK']]",1,1,2023-06-21,2,8,3,1,0,1,bd3558bc203b5006d5bcdc214bfcc65430c576d1,259262442.0,https://www.semanticscholar.org/paper/bd3558bc203b5006d5bcdc214bfcc65430c576d1,arXiv.org,2023.0,40.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1403238588', 'name': 'Debora Weber-Wulff'}, {'authorId': '1403494289', 'name': 'Alla Anohina-Naumeca'}, {'authorId': '2094497860', 'name': 'Sonja Bjelobaba'}, {'authorId': '2749013', 'name': 'T. Foltýnek'}, {'authorId': '1491822685', 'name': 'J. Guerrero-Dib'}, {'authorId': '118177587', 'name': 'Olumide Popoola'}, {'authorId': '2220896315', 'name': 'Petr Sigut'}, {'authorId': '2220633327', 'name': 'Lorna Waddington'}]","['Uppsala University', 'Masaryk University', 'HTW Berlin - University of Applied Sciences', 'Queen Mary University of London', 'Riga Technical University', 'University of Monterrey', 'University of Leeds']","['Germany', 'Sweden', 'Mexico', 'Czechia', 'Latvia', 'United Kingdom']",2023-06
2306.15766,Parikshit Bansal,"Parikshit Bansal, Amit Sharma",Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data. As an approximation to collecting ground-truth labels for the specific domain, we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models. Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular active learning strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference in prediction scores between the base model and the finetuned NLP model, utilizing the fact that most NLP models are finetuned from a base model. Experiments with classification (semantic similarity) and ranking (semantic search) tasks show that our sampling strategy leads to significant gains in accuracy for both the training and target domains. ","[{'version': 'v1', 'created': 'Tue, 27 Jun 2023 19:29:55 GMT'}]",2023-06-29,"[['Bansal', 'Parikshit', ''], ['Sharma', 'Amit', '']]",0,0,2023-06-27,1,2,2,0,0,0,2af358b4771d7bffe491077466fc4d225a16a74b,259274939.0,https://www.semanticscholar.org/paper/2af358b4771d7bffe491077466fc4d225a16a74b,arXiv.org,2023.0,37.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48691300', 'name': 'Parikshit Bansal'}, {'authorId': '2143678801', 'name': 'Amit Sharma'}]",['Microsoft'],['India'],2023-06
2306.16004,Abhijit Anand,"Avishek Anand, Venktesh V, Abhijit Anand, Vinay Setty",Query Understanding in the Age of Large Language Models,Accepted to GENIR(SIGIR'23),,,,cs.IR cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Querying, conversing, and controlling search and information-seeking interfaces using natural language are fast becoming ubiquitous with the rise and adoption of large-language models (LLM). In this position paper, we describe a generic framework for interactive query-rewriting using LLMs. Our proposal aims to unfold new opportunities for improved and transparent intent understanding while building high-performance retrieval systems using LLMs. A key aspect of our framework is the ability of the rewriter to fully specify the machine intent by the search engine in natural language that can be further refined, controlled, and edited before the final retrieval phase. The ability to present, interact, and reason over the underlying machine intent in natural language has profound implications on transparency, ranking performance, and a departure from the traditional way in which supervised signals were collected for understanding intents. We detail the concept, backed by initial experiments, along with open questions for this interactive query understanding framework. ","[{'version': 'v1', 'created': 'Wed, 28 Jun 2023 08:24:14 GMT'}]",2023-06-29,"[['Anand', 'Avishek', ''], ['V', 'Venktesh', ''], ['Anand', 'Abhijit', ''], ['Setty', 'Vinay', '']]",0,0,2023-06-28,1,4,2,0,0,0,9ea943607dc452c917af16ca4763a7ed16c31068,259274869.0,https://www.semanticscholar.org/paper/9ea943607dc452c917af16ca4763a7ed16c31068,arXiv.org,2023.0,96.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '39775488', 'name': 'Avishek Anand'}, {'authorId': '2262446334', 'name': 'V. Venktesh'}, {'authorId': '2161343505', 'name': 'Abhijit Anand'}, {'authorId': '2852530', 'name': 'Vinay Setty'}]","['University of Stavanger', 'L3S Research Center', 'Delft University of Technology']","['Germany', 'Netherlands', 'Norway']",2023-06
2306.16007,Yu Wu,"Yuang Li, Yu Wu, Jinyu Li, Shujie Liu",Prompting Large Language Models for Zero-Shot Domain Adaptation in Speech Recognition,,,,,cs.CL eess.AS eess.SP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The integration of Language Models (LMs) has proven to be an effective way to address domain shifts in speech recognition. However, these approaches usually require a significant amount of target domain text data for the training of LMs. Different from these methods, in this work, with only a domain-specific text prompt, we propose two zero-shot ASR domain adaptation methods using LLaMA, a 7-billion-parameter large language model (LLM). LLM is used in two ways: 1) second-pass rescoring: reranking N-best hypotheses of a given ASR system with LLaMA; 2) deep LLM-fusion: incorporating LLM into the decoder of an encoder-decoder based ASR system. Experiments show that, with only one domain prompt, both methods can effectively reduce word error rates (WER) on out-of-domain TedLium-2 and SPGISpeech datasets. Especially, the deep LLM-fusion has the advantage of better recall of entity and out-of-vocabulary words. ","[{'version': 'v1', 'created': 'Wed, 28 Jun 2023 08:29:00 GMT'}]",2023-06-29,"[['Li', 'Yuang', ''], ['Wu', 'Yu', ''], ['Li', 'Jinyu', ''], ['Liu', 'Shujie', '']]",0,0,2023-06-28,1,4,3,1,1,0,c94f0acf00530dbf9f275dad8515e23dc30666d3,259274964.0,https://www.semanticscholar.org/paper/c94f0acf00530dbf9f275dad8515e23dc30666d3,arXiv.org,2023.0,37.0,6.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2128121514', 'name': 'Yuang Li'}, {'authorId': '49176273', 'name': 'Yu Wu'}, {'authorId': '152319568', 'name': 'Jinyu Li'}, {'authorId': '2107983441', 'name': 'Shujie Liu'}]",['University of Cambridge'],['United Kingdom'],2023-06
2306.16322,Zaid Alyafeai Mr,"Zaid Alyafeai and Maged S. Alshaibani and Badr AlKhamissi and Hamzah
  Luqman and Ebrahim Alareqi and Ali Fadel",Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have demonstrated impressive performance on various downstream tasks without requiring fine-tuning, including ChatGPT, a chat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite having a lower training proportion compared to English, these models also exhibit remarkable capabilities in other languages. In this study, we assess the performance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks: sentiment analysis, translation, transliteration, paraphrasing, part of speech tagging, summarization, and diacritization. Our findings reveal that GPT-4 outperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct an extensive analysis of the sentiment analysis task, providing insights into how LLMs achieve exceptional results on a challenging dialectal dataset. Additionally, we introduce a new Python interface https://github.com/ARBML/Taqyim that facilitates the evaluation of these tasks effortlessly. ","[{'version': 'v1', 'created': 'Wed, 28 Jun 2023 15:54:29 GMT'}]",2023-06-29,"[['Alyafeai', 'Zaid', ''], ['Alshaibani', 'Maged S.', ''], ['AlKhamissi', 'Badr', ''], ['Luqman', 'Hamzah', ''], ['Alareqi', 'Ebrahim', ''], ['Fadel', 'Ali', '']]",1,1,2023-06-28,1,6,1,3,0,3,d14aa448b17fdc8d4ea12b43ee1a2b1254c38703,259274808.0,https://www.semanticscholar.org/paper/d14aa448b17fdc8d4ea12b43ee1a2b1254c38703,arXiv.org,2023.0,49.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '25098419', 'name': 'Zaid Alyafeai'}, {'authorId': '2065657002', 'name': 'Maged S. Alshaibani'}, {'authorId': '2006905770', 'name': 'Badr AlKhamissi'}, {'authorId': '145918569', 'name': 'H. Luqman'}, {'authorId': '52196780', 'name': 'Ebrahim Alareqi'}, {'authorId': '145398706', 'name': 'A. Fadel'}]","['King Fahd University of Petroleum and Minerals', 'Joint Research Center', 'Volvo Cars (Sweden)']","['Sweden', 'Saudi Arabia', 'Spain']",2023-06
2306.16545,Daoji Huang,"Daoji Huang, Otmar Hilliges, Luc Van Gool, Xi Wang",Palm: Predicting Actions through Language Models @ Ego4D Long-Term Action Anticipation Challenge 2023,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  We present Palm, a solution to the Long-Term Action Anticipation (LTA) task utilizing vision-language and large language models. Given an input video with annotated action periods, the LTA task aims to predict possible future actions. We hypothesize that an optimal solution should capture the interdependency between past and future actions, and be able to infer future actions based on the structure and dependency encoded in the past actions. Large language models have demonstrated remarkable commonsense-based reasoning ability. Inspired by that, Palm chains an image captioning model and a large language model. It predicts future actions based on frame descriptions and action labels extracted from the input videos. Our method outperforms other participants in the EGO4D LTA challenge and achieves the best performance in terms of action prediction. Our code is available at https://github.com/DanDoge/Palm ","[{'version': 'v1', 'created': 'Wed, 28 Jun 2023 20:33:52 GMT'}]",2023-06-30,"[['Huang', 'Daoji', ''], ['Hilliges', 'Otmar', ''], ['Van Gool', 'Luc', ''], ['Wang', 'Xi', '']]",0,0,2023-06-28,1,4,1,1,0,1,2aa22c271390653cab888e5f8b22fadcdf68c7a9,259286851.0,https://www.semanticscholar.org/paper/2aa22c271390653cab888e5f8b22fadcdf68c7a9,arXiv.org,2023.0,11.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2364696', 'name': 'Daoji Huang'}, {'authorId': '1466533438', 'name': 'Otmar Hilliges'}, {'authorId': '1681236', 'name': 'L. Gool'}, {'authorId': '2108250806', 'name': 'Xi Wang'}]",['University of Lucknow'],['India'],2023-06
2306.16668,Guido Zuccon,"Guido Zuccon, Harrisen Scells, Shengyao Zhuang",Beyond CO2 Emissions: The Overlooked Impact of Water Consumption of Information Retrieval Models,,,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As in other fields of artificial intelligence, the information retrieval community has grown interested in investigating the power consumption associated with neural models, particularly models of search. This interest has become particularly relevant as the energy consumption of information retrieval models has risen with new neural models based on large language models, leading to an associated increase of CO2 emissions, albeit relatively low compared to fields such as natural language processing. ","[{'version': 'v1', 'created': 'Thu, 29 Jun 2023 03:57:14 GMT'}]",2023-06-30,"[['Zuccon', 'Guido', ''], ['Scells', 'Harrisen', ''], ['Zhuang', 'Shengyao', '']]",0,0,2023-06-29,1,3,1,0,0,0,0937611a2102ea542307d9493a1afb17a8a3b05e,259287222.0,https://www.semanticscholar.org/paper/0937611a2102ea542307d9493a1afb17a8a3b05e,International Conference on the Theory of Information Retrieval,2023.0,45.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1692855', 'name': 'G. Zuccon'}, {'authorId': '8842143', 'name': 'Harrisen Scells'}, {'authorId': '1630489015', 'name': 'Shengyao Zhuang'}]","['Leipzig University', 'University of Queensland']","['Germany', 'Australia']",2023-06
2306.17181,Jun-Min Lee,"Jun-Min Lee, Tae-Bin Ha",Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Generative Adversarial Networks (GAN) is a model for data synthesis, which creates plausible data through the competition of generator and discriminator. Although GAN application to image synthesis is extensively studied, it has inherent limitations to natural language generation. Because natural language is composed of discrete tokens, a generator has difficulty updating its gradient through backpropagation; therefore, most text-GAN studies generate sentences starting with a random token based on a reward system. Thus, the generators of previous studies are pre-trained in an autoregressive way before adversarial training, causing data memorization that synthesized sentences reproduce the training data. In this paper, we synthesize sentences using a framework similar to the original GAN. More specifically, we propose Text Embedding Space Generative Adversarial Networks (TESGAN) which generate continuous text embedding spaces instead of discrete tokens to solve the gradient backpropagation problem. Furthermore, TESGAN conducts unsupervised learning which does not directly refer to the text of the training data to overcome the data memorization issue. By adopting this novel method, TESGAN can synthesize new sentences, showing the potential of unsupervised learning for text synthesis. We expect to see extended research combining Large Language Models with a new perspective of viewing text as an continuous space. ","[{'version': 'v1', 'created': 'Mon, 19 Jun 2023 10:22:12 GMT'}, {'version': 'v2', 'created': 'Mon, 10 Jul 2023 10:12:37 GMT'}, {'version': 'v3', 'created': 'Sat, 16 Sep 2023 02:10:05 GMT'}]",2023-09-19,"[['Lee', 'Jun-Min', ''], ['Ha', 'Tae-Bin', '']]",0,0,2023-06-19,3,2,2,0,0,0,385ea5492cf26911bdba610c8edf0b3240e6e925,259308808.0,https://www.semanticscholar.org/paper/385ea5492cf26911bdba610c8edf0b3240e6e925,Northern European Journal of Language Technology,2023.0,57.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2108309204', 'name': 'Jun-Min Lee'}, {'authorId': '2220961411', 'name': 'Tae-Bin Ha'}]",['Korea Advanced Institute of Science and Technology'],['South Korea'],2023-06
2306.17249,Flavio Petruzzellis,"Flavio Petruzzellis, Alberto Testolin, Alessandro Sperduti",A Hybrid System for Systematic Generalization in Simple Arithmetic Problems,"Accepted at NeSy 2023, 17th International Workshop on Neural-Symbolic
  Learning and Reasoning",,,,cs.NE cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Solving symbolic reasoning problems that require compositionality and systematicity is considered one of the key ingredients of human intelligence. However, symbolic reasoning is still a great challenge for deep learning models, which often cannot generalize the reasoning pattern to out-of-distribution test cases. In this work, we propose a hybrid system capable of solving arithmetic problems that require compositional and systematic reasoning over sequences of symbols. The model acquires such a skill by learning appropriate substitution rules, which are applied iteratively to the input string until the expression is completely resolved. We show that the proposed system can accurately solve nested arithmetical expressions even when trained only on a subset including the simplest cases, significantly outperforming both a sequence-to-sequence model trained end-to-end and a state-of-the-art large language model. ","[{'version': 'v1', 'created': 'Thu, 29 Jun 2023 18:35:41 GMT'}]",2023-07-03,"[['Petruzzellis', 'Flavio', ''], ['Testolin', 'Alberto', ''], ['Sperduti', 'Alessandro', '']]",0,0,2023-06-29,1,3,2,0,0,0,fecbf14c6afa8d17a0cae8697db8abbadb7abe7d,259308904.0,https://www.semanticscholar.org/paper/fecbf14c6afa8d17a0cae8697db8abbadb7abe7d,International Workshop on Neural-Symbolic Learning and Reasoning,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2171081238', 'name': 'Flavio Petruzzellis'}, {'authorId': '1915299', 'name': 'Alberto Testolin'}, {'authorId': '1749815', 'name': 'A. Sperduti'}]","['Certosa di Pontignano, Siena, Italy', 'Department of General Psychology, University of Padova, Padova, Italy', 'Department of Mathematics, University of Padova, Padova, Italy']",['Italy'],2023-06
2306.17519,Pawan Kumar Rajpoot,"Pawan Kumar Rajpoot, Ankur Parikh",GPT-FinRE: In-context Learning for Financial Relation Extraction using Large Language Models,arXiv admin note: text overlap with arXiv:2305.02105 by other authors,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Relation extraction (RE) is a crucial task in natural language processing (NLP) that aims to identify and classify relationships between entities mentioned in text. In the financial domain, relation extraction plays a vital role in extracting valuable information from financial documents, such as news articles, earnings reports, and company filings. This paper describes our solution to relation extraction on one such dataset REFinD. The dataset was released along with shared task as a part of the Fourth Workshop on Knowledge Discovery from Unstructured Data in Financial Services, co-located with SIGIR 2023. In this paper, we employed OpenAI models under the framework of in-context learning (ICL). We utilized two retrieval strategies to find top K relevant in-context learning demonstrations / examples from training data for a given test example. The first retrieval mechanism, we employed, is a learning-free dense retriever and the other system is a learning-based retriever. We were able to achieve 3rd rank overall. Our best F1-score is 0.718. ","[{'version': 'v1', 'created': 'Fri, 30 Jun 2023 10:12:30 GMT'}, {'version': 'v2', 'created': 'Fri, 21 Jul 2023 06:57:49 GMT'}]",2023-07-24,"[['Rajpoot', 'Pawan Kumar', ''], ['Parikh', 'Ankur', '']]",0,1,2023-06-30,2,2,1,0,0,0,5bb69bb7eadf1344b3cb8849855b23ddf28a1528,259309148.0,https://www.semanticscholar.org/paper/5bb69bb7eadf1344b3cb8849855b23ddf28a1528,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2143241321', 'name': 'P. Rajpoot'}, {'authorId': '2113810668', 'name': 'Ankur Parikh'}]","['MUST Research Bangalore, Karnataka, India', 'UtilizeAI Research Bangalore, Karnataka, India']",['India'],2023-06
2307.00526,Mingxue Xu,"Mingxue Xu, Yao Lei Xu, Danilo P. Mandic",TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition,,,,,cs.CL cs.LG cs.NA cs.NE math.NA,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  High-dimensional token embeddings underpin Large Language Models (LLMs), as they can capture subtle semantic information and significantly enhance the modelling of complex language patterns. However, the associated high dimensionality also introduces considerable model parameters, and a prohibitively high model storage. To address this issue, this work proposes an approach based on the Tensor-Train Decomposition (TTD), where each token embedding is treated as a Matrix Product State (MPS) that can be efficiently computed in a distributed manner. The experimental results on GPT-2 demonstrate that, through our approach, the embedding layer can be compressed by a factor of up to 38.40 times, and when the compression factor is 3.31 times, even produced a better performance than the original GPT-2 model. ","[{'version': 'v1', 'created': 'Sun, 2 Jul 2023 09:33:09 GMT'}]",2023-07-04,"[['Xu', 'Mingxue', ''], ['Xu', 'Yao Lei', ''], ['Mandic', 'Danilo P.', '']]",0,1,2023-07-02,1,3,5,1,1,0,af67be0fff8d087a0d8554b6e8998ab12409bbda,259316802.0,https://www.semanticscholar.org/paper/af67be0fff8d087a0d8554b6e8998ab12409bbda,arXiv.org,2023.0,14.0,3.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1785386451', 'name': 'Mingxue Xu'}, {'authorId': '2110212590', 'name': 'Y. Xu'}, {'authorId': '2155041542', 'name': 'Danilo P. Mandic'}]",['Imperial College London'],['United Kingdom'],2023-07
2307.00787,Teun Van Der Weij,"Teun van der Weij, Simon Lermen, Leon lang",Evaluating Shutdown Avoidance of Language Models in Textual Scenarios,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Recently, there has been an increase in interest in evaluating large language models for emergent and dangerous capabilities. Importantly, agents could reason that in some scenarios their goal is better achieved if they are not turned off, which can lead to undesirable behaviors. In this paper, we investigate the potential of using toy textual scenarios to evaluate instrumental reasoning and shutdown avoidance in language models such as GPT-4 and Claude. Furthermore, we explore whether shutdown avoidance is merely a result of simple pattern matching between the dataset and the prompt or if it is a consistent behaviour across different environments and variations.   We evaluated behaviours manually and also experimented with using language models for automatic evaluations, and these evaluations demonstrate that simple pattern matching is likely not the sole contributing factor for shutdown avoidance. This study provides insights into the behaviour of language models in shutdown avoidance scenarios and inspires further research on the use of textual scenarios for evaluations. ","[{'version': 'v1', 'created': 'Mon, 3 Jul 2023 07:05:59 GMT'}]",2023-07-04,"[['van der Weij', 'Teun', ''], ['Lermen', 'Simon', ''], ['lang', 'Leon', '']]",0,1,2023-07-03,1,3,2,2,0,2,186f17fbd5a085932ef89ee2c3d574ba411badca,259316969.0,https://www.semanticscholar.org/paper/186f17fbd5a085932ef89ee2c3d574ba411badca,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2221010426', 'name': 'Teun van der Weij'}, {'authorId': '2221010424', 'name': 'Simon Lermen'}, {'authorId': '2057703505', 'name': 'Leon Lang'}]","['University of Amsterdam', 'Utrecht University', 'Evaluating Shutdown Avoidance of Language Models in Textual Scenarios']",['Netherlands'],2023-07
2307.01128,Alessandro Giuliani,"Salvatore Carta, Alessandro Giuliani, Leonardo Piano, Alessandro
  Sebastian Podda, Livio Pompianu, Sandro Gabriele Tiddia",Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the current digitalization era, capturing and effectively representing knowledge is crucial in most real-world scenarios. In this context, knowledge graphs represent a potent tool for retrieving and organizing a vast amount of information in a properly interconnected and interpretable structure. However, their generation is still challenging and often requires considerable human effort and domain expertise, hampering the scalability and flexibility across different application fields. This paper proposes an innovative knowledge graph generation approach that leverages the potential of the latest generative large language models, such as GPT-3.5, that can address all the main critical issues in knowledge graph building. The approach is conveyed in a pipeline that comprises novel iterative zero-shot and external knowledge-agnostic strategies in the main stages of the generation process. Our unique manifold approach may encompass significant benefits to the scientific community. In particular, the main contribution can be summarized by: (i) an innovative strategy for iteratively prompting large language models to extract relevant components of the final graph; (ii) a zero-shot strategy for each prompt, meaning that there is no need for providing examples for ""guiding"" the prompt result; (iii) a scalable solution, as the adoption of LLMs avoids the need for any external resources or human expertise. To assess the effectiveness of our proposed model, we performed experiments on a dataset that covered a specific domain. We claim that our proposal is a suitable solution for scalable and versatile knowledge graph construction and may be applied to different and novel contexts. ","[{'version': 'v1', 'created': 'Mon, 3 Jul 2023 16:01:45 GMT'}]",2023-07-04,"[['Carta', 'Salvatore', ''], ['Giuliani', 'Alessandro', ''], ['Piano', 'Leonardo', ''], ['Podda', 'Alessandro Sebastian', ''], ['Pompianu', 'Livio', ''], ['Tiddia', 'Sandro Gabriele', '']]",0,1,2023-07-03,1,6,2,1,0,1,50bdea5132ef4b8cf25b0d9f3ac2ee0d09bf18cb,259316469.0,https://www.semanticscholar.org/paper/50bdea5132ef4b8cf25b0d9f3ac2ee0d09bf18cb,arXiv.org,2023.0,31.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '33773039', 'name': 'S. Carta'}, {'authorId': '2072499690', 'name': 'Alessandro Giuliani'}, {'authorId': '1412680660', 'name': 'L. piano'}, {'authorId': '2308276', 'name': 'Alessandro Sebastian Podda'}, {'authorId': '1940336', 'name': 'Livio Pompianu'}, {'authorId': '2221009582', 'name': 'Sandro Gabriele Tiddia'}]",['University of Cagliari'],['Italy'],2023-07
2307.01225,Bushra Sabir,"Bushra Sabir, M. Ali Babar, Sharif Abuadbba",Interpretability and Transparency-Driven Detection and Transformation of Textual Adversarial Examples (IT-DT),,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Transformer-based text classifiers like BERT, Roberta, T5, and GPT-3 have shown impressive performance in NLP. However, their vulnerability to adversarial examples poses a security risk. Existing defense methods lack interpretability, making it hard to understand adversarial classifications and identify model vulnerabilities. To address this, we propose the Interpretability and Transparency-Driven Detection and Transformation (IT-DT) framework. It focuses on interpretability and transparency in detecting and transforming textual adversarial examples. IT-DT utilizes techniques like attention maps, integrated gradients, and model feedback for interpretability during detection. This helps identify salient features and perturbed words contributing to adversarial classifications. In the transformation phase, IT-DT uses pre-trained embeddings and model feedback to generate optimal replacements for perturbed words. By finding suitable substitutions, we aim to convert adversarial examples into non-adversarial counterparts that align with the model's intended behavior while preserving the text's meaning. Transparency is emphasized through human expert involvement. Experts review and provide feedback on detection and transformation results, enhancing decision-making, especially in complex scenarios. The framework generates insights and threat intelligence empowering analysts to identify vulnerabilities and improve model robustness. Comprehensive experiments demonstrate the effectiveness of IT-DT in detecting and transforming adversarial examples. The approach enhances interpretability, provides transparency, and enables accurate identification and successful transformation of adversarial inputs. By combining technical analysis and human expertise, IT-DT significantly improves the resilience and trustworthiness of transformer-based text classifiers against adversarial attacks. ","[{'version': 'v1', 'created': 'Mon, 3 Jul 2023 03:17:20 GMT'}]",2023-07-06,"[['Sabir', 'Bushra', ''], ['Babar', 'M. Ali', ''], ['Abuadbba', 'Sharif', '']]",0,1,2023-07-03,1,3,3,2,1,1,56530e6761adaffc3f607356d39ce7252b872f2e,259342638.0,https://www.semanticscholar.org/paper/56530e6761adaffc3f607356d39ce7252b872f2e,arXiv.org,2023.0,64.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '25681391', 'name': 'Bushra Sabir'}, {'authorId': '2142773270', 'name': 'M. A. Babar'}, {'authorId': '1402904203', 'name': 'Sharif Abuadbba'}]","['University of Adelaide', 'Data61']",['Australia'],2023-07
2307.01387,Javier De La Rosa,"Javier de la Rosa, \'Alvaro P\'erez Pozo, Salvador Ros, Elena
  Gonz\'alez-Blanco","ALBERTI, a Multilingual Domain Specific Language Model for Poetry Analysis","Accepted for publication at SEPLN 2023: 39th International Conference
  of the Spanish Society for Natural Language Processing",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The computational analysis of poetry is limited by the scarcity of tools to automatically analyze and scan poems. In a multilingual settings, the problem is exacerbated as scansion and rhyme systems only exist for individual languages, making comparative studies very challenging and time consuming. In this work, we present \textsc{Alberti}, the first multilingual pre-trained large language model for poetry. Through domain-specific pre-training (DSP), we further trained multilingual BERT on a corpus of over 12 million verses from 12 languages. We evaluated its performance on two structural poetry tasks: Spanish stanza type classification, and metrical pattern prediction for Spanish, English and German. In both cases, \textsc{Alberti} outperforms multilingual BERT and other transformers-based models of similar sizes, and even achieves state-of-the-art results for German when compared to rule-based systems, demonstrating the feasibility and effectiveness of DSP in the poetry domain. ","[{'version': 'v1', 'created': 'Mon, 3 Jul 2023 22:50:53 GMT'}]",2023-07-06,"[['de la Rosa', 'Javier', ''], ['Pozo', 'Álvaro Pérez', ''], ['Ros', 'Salvador', ''], ['González-Blanco', 'Elena', '']]",0,0,2023-07-03,1,4,1,0,0,0,6aa02fa1a77cddc8c6a0a0439901a0c51e77752d,259341862.0,https://www.semanticscholar.org/paper/6aa02fa1a77cddc8c6a0a0439901a0c51e77752d,Proces. del Leng. Natural,2023.0,35.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '144979591', 'name': 'Javier de la Rosa'}, {'authorId': '2149932875', 'name': 'Álvaro Pérez Pozo'}, {'authorId': '2151341033', 'name': 'Salvador Ros'}, {'authorId': '1405423502', 'name': 'E. González-Blanco'}]","['IE University', 'National University of Distance Education', 'National Library of Norway, Norway']","['Spain', 'Norway']",2023-07
2307.01458,Tong Xiang,"Tong Xiang, Liangzhi Li, Wangyue Li, Mingbai Bai, Lu Wei, Bowen Wang,
  Noa Garcia",CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity and Infant Care,NeurIPS 2023 Datasets and Benchmarks Track,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recent advances in natural language processing (NLP), have led to a new trend of applying large language models (LLMs) to real-world scenarios. While the latest LLMs are astonishingly fluent when interacting with humans, they suffer from the misinformation problem by unintentionally generating factually false statements. This can lead to harmful consequences, especially when produced within sensitive contexts, such as healthcare. Yet few previous works have focused on evaluating misinformation in the long-form (LF) generation of LLMs, especially for knowledge-intensive topics. Moreover, although LLMs have been shown to perform well in different languages, misinformation evaluation has been mostly conducted in English. To this end, we present a benchmark, CARE-MI, for evaluating LLM misinformation in: 1) a sensitive topic, specifically the maternity and infant care domain; and 2) a language other than English, namely Chinese. Most importantly, we provide an innovative paradigm for building LF generation evaluation benchmarks that can be transferred to other knowledge-intensive domains and low-resourced languages. Our proposed benchmark fills the gap between the extensive usage of LLMs and the lack of datasets for assessing the misinformation generated by these models. It contains 1,612 expert-checked questions, accompanied with human-selected references. Using our benchmark, we conduct extensive experiments and found that current Chinese LLMs are far from perfect in the topic of maternity and infant care. In an effort to minimize the reliance on human resources for performance evaluation, we offer off-the-shelf judgment models for automatically assessing the LF output of LLMs given benchmark questions. Moreover, we compare potential solutions for LF generation evaluation and provide insights for building better automated metrics. ","[{'version': 'v1', 'created': 'Tue, 4 Jul 2023 03:34:19 GMT'}, {'version': 'v2', 'created': 'Thu, 31 Aug 2023 09:39:29 GMT'}, {'version': 'v3', 'created': 'Mon, 25 Sep 2023 03:22:17 GMT'}]",2023-09-26,"[['Xiang', 'Tong', ''], ['Li', 'Liangzhi', ''], ['Li', 'Wangyue', ''], ['Bai', 'Mingbai', ''], ['Wei', 'Lu', ''], ['Wang', 'Bowen', ''], ['Garcia', 'Noa', '']]",0,0,2023-07-04,3,7,1,0,0,0,7e70b9ac85ff2b27fb2c1c67ea52c39552812dc4,259342842.0,https://www.semanticscholar.org/paper/7e70b9ac85ff2b27fb2c1c67ea52c39552812dc4,arXiv.org,2023.0,75.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '119564884', 'name': 'Tong Xiang'}, {'authorId': '47681301', 'name': 'Liangzhi Li'}, {'authorId': '2216518555', 'name': 'Wangyue Li'}, {'authorId': '2131181215', 'name': 'Min‐Jun Bai'}, {'authorId': '2221145675', 'name': 'Lu Wei'}, {'authorId': '2153213890', 'name': 'Bowen Wang'}, {'authorId': '26385137', 'name': 'Noa García'}]","[""Xiamen Key Laboratory of Women's Internet Health Management,"", 'Osaka University']",['Japan'],2023-07
2307.01644,"Andreas G\""oldi","Andreas G\""oldi and Roman Rietsche",Insert-expansions for Tool-enabled Conversational Agents,,,,,cs.HC cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper delves into an advanced implementation of Chain-of-Thought-Prompting in Large Language Models, focusing on the use of tools (or ""plug-ins"") within the explicit reasoning paths generated by this prompting method. We find that tool-enabled conversational agents often become sidetracked, as additional context from tools like search engines or calculators diverts from original user intents. To address this, we explore a concept wherein the user becomes the tool, providing necessary details and refining their requests. Through Conversation Analysis, we characterize this interaction as insert-expansion - an intermediary conversation designed to facilitate the preferred response. We explore possibilities arising from this 'user-as-a-tool' approach in two empirical studies using direct comparison, and find benefits in the recommendation domain. ","[{'version': 'v1', 'created': 'Tue, 4 Jul 2023 10:57:31 GMT'}]",2023-07-06,"[['Göldi', 'Andreas', ''], ['Rietsche', 'Roman', '']]",0,0,2023-07-04,1,2,3,0,0,0,803a3dd98d72a9fe730f082f3364f9b1f9a0029a,259342223.0,https://www.semanticscholar.org/paper/803a3dd98d72a9fe730f082f3364f9b1f9a0029a,arXiv.org,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2078730637', 'name': 'Andreas Göldi'}, {'authorId': '9486227', 'name': 'Roman Rietsche'}]",['University of St. Gallen'],['Switzerland'],2023-07
2307.01881,Siwon Kim,"Siwon Kim, Sangdoo Yun, Hwaran Lee, Martin Gubri, Sungroh Yoon, Seong
  Joon Oh",ProPILE: Probing Privacy Leakage in Large Language Models,,,,,cs.CR cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The rapid advancement and widespread use of large language models (LLMs) have raised significant concerns regarding the potential leakage of personally identifiable information (PII). These models are often trained on vast quantities of web-collected data, which may inadvertently include sensitive personal data. This paper presents ProPILE, a novel probing tool designed to empower data subjects, or the owners of the PII, with awareness of potential PII leakage in LLM-based services. ProPILE lets data subjects formulate prompts based on their own PII to evaluate the level of privacy intrusion in LLMs. We demonstrate its application on the OPT-1.3B model trained on the publicly available Pile dataset. We show how hypothetical data subjects may assess the likelihood of their PII being included in the Pile dataset being revealed. ProPILE can also be leveraged by LLM service providers to effectively evaluate their own levels of PII leakage with more powerful prompts specifically tuned for their in-house models. This tool represents a pioneering step towards empowering the data subjects for their awareness and control over their own data on the web. ","[{'version': 'v1', 'created': 'Tue, 4 Jul 2023 18:53:47 GMT'}]",2023-07-06,"[['Kim', 'Siwon', ''], ['Yun', 'Sangdoo', ''], ['Lee', 'Hwaran', ''], ['Gubri', 'Martin', ''], ['Yoon', 'Sungroh', ''], ['Oh', 'Seong Joon', '']]",0,0,2023-07-04,1,6,2,1,1,0,1eab717bd05f6b4bc7cfaf5c57419951562de809,259342279.0,https://www.semanticscholar.org/paper/1eab717bd05f6b4bc7cfaf5c57419951562de809,arXiv.org,2023.0,42.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48388878', 'name': 'Siwon Kim'}, {'authorId': '2151587', 'name': 'Sangdoo Yun'}, {'authorId': '2294014', 'name': 'Hwaran Lee'}, {'authorId': '35582593', 'name': 'Martin Gubri'}, {'authorId': '2152497729', 'name': 'Sung-Hoon Yoon'}, {'authorId': '2390510', 'name': 'Seong Joon Oh'}]","['Seoul National University', 'NAVER', 'University of Luxembourg', 'University of Tübingen']","['South Korea', 'Germany', 'Luxembourg']",2023-07
2307.02006,Viktor Schlegel,"Viktor Schlegel, Hao Li, Yuping Wu, Anand Subramanian, Thanh-Tung
  Nguyen, Abhinav Ramesh Kashyap, Daniel Beck, Xiaojun Zeng, Riza Theresa
  Batista-Navarro, Stefan Winkler, Goran Nenadic",PULSAR at MEDIQA-Sum 2023: Large Language Models Augmented by Synthetic Dialogue Convert Patient Dialogues to Medical Records,8 pages. ImageClef 2023 MediQA-Sum,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This paper describes PULSAR, our system submission at the ImageClef 2023 MediQA-Sum task on summarising patient-doctor dialogues into clinical records. The proposed framework relies on domain-specific pre-training, to produce a specialised language model which is trained on task-specific natural data augmented by synthetic data generated by a black-box LLM. We find limited evidence towards the efficacy of domain-specific pre-training and data augmentation, while scaling up the language model yields the best performance gains. Our approach was ranked second and third among 13 submissions on task B of the challenge. Our code is available at https://github.com/yuping-wu/PULSAR. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 03:31:12 GMT'}]",2023-07-06,"[['Schlegel', 'Viktor', ''], ['Li', 'Hao', ''], ['Wu', 'Yuping', ''], ['Subramanian', 'Anand', ''], ['Nguyen', 'Thanh-Tung', ''], ['Kashyap', 'Abhinav Ramesh', ''], ['Beck', 'Daniel', ''], ['Zeng', 'Xiaojun', ''], ['Batista-Navarro', 'Riza Theresa', ''], ['Winkler', 'Stefan', ''], ['Nenadic', 'Goran', '']]",0,0,2023-07-05,1,11,1,0,0,0,586bdad62d35342ec4aae0dd539379fff1ea4547,259341866.0,https://www.semanticscholar.org/paper/586bdad62d35342ec4aae0dd539379fff1ea4547,Conference and Labs of the Evaluation Forum,2023.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '71034258', 'name': 'Viktor Schlegel'}, {'authorId': '144966717', 'name': 'Hao Li'}, {'authorId': '2107934864', 'name': 'Yuping Wu'}, {'authorId': '2057755271', 'name': 'Anand Subramanian'}, {'authorId': '2117824172', 'name': 'Thanh-Tung Nguyen'}, {'authorId': '41124383', 'name': 'Abhinav Ramesh Kashyap'}, {'authorId': '143984297', 'name': 'Daniel Beck'}, {'authorId': '2152293660', 'name': 'Xiaojun Zeng'}, {'authorId': '1400900759', 'name': 'R. Batista-Navarro'}, {'authorId': '2057271731', 'name': 'Stefan Winkler'}, {'authorId': '2144507', 'name': 'G. Nenadic'}]","['ASUS Intelligent Cloud Services (AICS), Singapore.', 'National University of Singapore', 'University of Melbourne', 'University of Manchester']","['United Kingdom', 'Singapore', 'Australia']",2023-07
2307.02053,Soujanya Poria,"Deepanway Ghosal, Yew Ken Chia, Navonil Majumder, Soujanya Poria",Flacuna: Unleashing the Problem Solving Power of Vicuna using FLAN Fine-Tuning,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Recently, the release of INSTRUCTEVAL has provided valuable insights into the performance of large language models (LLMs) that utilize encoder-decoder or decoder-only architecture. Interestingly, despite being introduced four years ago, T5-based LLMs, such as FLAN-T5, continue to outperform the latest decoder-based LLMs, such as LLAMA and VICUNA, on tasks that require general problem-solving skills. This performance discrepancy can be attributed to three key factors: (1) Pre-training data, (2) Backbone architecture, and (3) Instruction dataset. In this technical report, our main focus is on investigating the impact of the third factor by leveraging VICUNA, a large language model based on LLAMA, which has undergone fine-tuning on ChatGPT conversations. To achieve this objective, we fine-tuned VICUNA using a customized instruction dataset collection called FLANMINI. This collection includes a subset of the large-scale instruction dataset known as FLAN, as well as various code-related datasets and conversational datasets derived from ChatGPT/GPT-4. This dataset comprises a large number of tasks that demand problem-solving skills. Our experimental findings strongly indicate that the enhanced problem-solving abilities of our model, FLACUNA, are obtained through fine-tuning VICUNA on the FLAN dataset, leading to significant improvements across numerous benchmark datasets in INSTRUCTEVAL. FLACUNA is publicly available at https://huggingface.co/declare-lab/flacuna-13b-v1.0. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 06:36:54 GMT'}]",2023-07-06,"[['Ghosal', 'Deepanway', ''], ['Chia', 'Yew Ken', ''], ['Majumder', 'Navonil', ''], ['Poria', 'Soujanya', '']]",1,1,2023-07-05,1,4,1,7,4,3,4350f3da1d3456ecdd384b325a1b033b434f7877,259342582.0,https://www.semanticscholar.org/paper/4350f3da1d3456ecdd384b325a1b033b434f7877,arXiv.org,2023.0,16.0,5.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32528506', 'name': 'Deepanway Ghosal'}, {'authorId': '2066312627', 'name': 'Yew Ken Chia'}, {'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}]",['Singapore University of Technology and Design'],['Singapore'],2023-07
2307.02179,Fabrizio Gilardi,"Meysam Alizadeh, Ma\""el Kubli, Zeynab Samei, Shirin Dehghani, Juan
  Diego Bermeo, Maria Korobeynikova, Fabrizio Gilardi",Open-Source Large Language Models Outperform Crowd Workers and Approach ChatGPT in Text-Annotation Tasks,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  This study examines the performance of open-source Large Language Models (LLMs) in text annotation tasks and compares it with proprietary models like ChatGPT and human-based services such as MTurk. While prior research demonstrated the high performance of ChatGPT across numerous NLP tasks, open-source LLMs like HugginChat and FLAN are gaining attention for their cost-effectiveness, transparency, reproducibility, and superior data protection. We assess these models using both zero-shot and few-shot approaches and different temperature parameters across a range of text annotation tasks. Our findings show that while ChatGPT achieves the best performance in most tasks, open-source LLMs not only outperform MTurk but also demonstrate competitive potential against ChatGPT in specific tasks. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 10:15:07 GMT'}]",2023-07-06,"[['Alizadeh', 'Meysam', ''], ['Kubli', 'Maël', ''], ['Samei', 'Zeynab', ''], ['Dehghani', 'Shirin', ''], ['Bermeo', 'Juan Diego', ''], ['Korobeynikova', 'Maria', ''], ['Gilardi', 'Fabrizio', '']]",1,1,2023-07-05,1,7,1,2,0,2,89337b180dc689fab2831a8f6b621fa3df686f86,259341651.0,https://www.semanticscholar.org/paper/89337b180dc689fab2831a8f6b621fa3df686f86,arXiv.org,2023.0,26.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2253532', 'name': 'Meysam Alizadeh'}, {'authorId': '69039257', 'name': 'M. Kubli'}, {'authorId': '103797345', 'name': 'Zeynab Samei'}, {'authorId': '2221126421', 'name': 'Shirin Dehghani'}, {'authorId': '2221127036', 'name': 'Juan Diego Bermeo'}, {'authorId': '84534997', 'name': 'M. Korobeynikova'}, {'authorId': '2221128219', 'name': 'Fabrizio Gilardi'}]","['University of Zurich', 'Institute for Research in Fundamental Sciences', ""Allameh Tabataba'i University""]","['Iran', 'Switzerland']",2023-07
2307.02192,Tamas Bisztray,"Norbert Tihanyi, Tamas Bisztray, Ridhi Jain, Mohamed Amine Ferrag,
  Lucas C. Cordeiro, Vasileios Mavroeidis",The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification,https://github.com/FormAI-Dataset,,,,cs.DB cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper presents the FormAI dataset, a large collection of 112, 000 AI-generated compilable and independent C programs with vulnerability classification. We introduce a dynamic zero-shot prompting technique constructed to spawn diverse programs utilizing Large Language Models (LLMs). The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity. Some programs handle complicated tasks like network management, table games, or encryption, while others deal with simpler tasks like string manipulation. Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name. This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which uses model checking, abstract interpretation, constraint programming, and satisfiability modulo theories to reason over safety/security properties in programs. This approach definitively detects vulnerabilities and offers a formal model known as a counterexample, thus eliminating the possibility of generating false positive reports. We have associated the identified vulnerabilities with Common Weakness Enumeration (CWE) numbers. We make the source code available for the 112, 000 programs, accompanied by a separate file containing the vulnerabilities detected in each program, making the dataset ideal for training LLMs and machine learning algorithms. Our study unveiled that according to ESBMC, 51.24% of the programs generated by GPT-3.5 contained vulnerabilities, thereby presenting considerable risks to software safety and security. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 10:39:58 GMT'}, {'version': 'v2', 'created': 'Sat, 2 Sep 2023 13:23:29 GMT'}]",2023-09-06,"[['Tihanyi', 'Norbert', ''], ['Bisztray', 'Tamas', ''], ['Jain', 'Ridhi', ''], ['Ferrag', 'Mohamed Amine', ''], ['Cordeiro', 'Lucas C.', ''], ['Mavroeidis', 'Vasileios', '']]",0,1,2023-07-05,2,6,2,1,0,1,67455478e77c8672d0dd08f89735a8813bbfec65,259341731.0,https://www.semanticscholar.org/paper/67455478e77c8672d0dd08f89735a8813bbfec65,arXiv.org,2023.0,67.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2752349', 'name': 'Norbert Tihanyi'}, {'authorId': '1404353535', 'name': 'Tamás Bisztray'}, {'authorId': '2113688343', 'name': 'Ridhi Jain'}, {'authorId': '2864573', 'name': 'M. Ferrag'}, {'authorId': '144040212', 'name': 'L. Cordeiro'}, {'authorId': '3479879', 'name': 'Vasileios Mavroeidis'}]","['University of Manchester', 'Technology Innovation Institute', 'University of Oslo']","['United Kingdom', 'Norway', 'United Arab Emirates']",2023-07
2307.02194,Alessandro Berti Mr,"Alessandro Berti, Daniel Schuster, Wil M.P. van der Aalst","Abstractions, Scenarios, and Prompt Definitions for Process Mining with LLMs: A Case Study",,,,,cs.DB,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) are capable of answering questions in natural language for various purposes. With recent advancements (such as GPT-4), LLMs perform at a level comparable to humans for many proficient tasks. The analysis of business processes could benefit from a natural process querying language and using the domain knowledge on which LLMs have been trained. However, it is impossible to provide a complete database or event log as an input prompt due to size constraints. In this paper, we apply LLMs in the context of process mining by i) abstracting the information of standard process mining artifacts and ii) describing the prompting strategies. We implement the proposed abstraction techniques into pm4py, an open-source process mining library. We present a case study using available event logs. Starting from different abstractions and analysis questions, we formulate prompts and evaluate the quality of the answers. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 10:41:54 GMT'}, {'version': 'v2', 'created': 'Fri, 14 Jul 2023 05:47:45 GMT'}]",2023-07-17,"[['Berti', 'Alessandro', ''], ['Schuster', 'Daniel', ''], ['van der Aalst', 'Wil M. P.', '']]",0,1,2023-07-05,2,3,1,1,0,1,425675cc3a4cfadf3b750e1563090a0ed378ddc2,259342720.0,https://www.semanticscholar.org/paper/425675cc3a4cfadf3b750e1563090a0ed378ddc2,arXiv.org,2023.0,29.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2737693', 'name': 'A. Berti'}, {'authorId': '145654957', 'name': 'Daniel Schuster'}, {'authorId': '145898058', 'name': 'Wil M.P. van der Aalst'}]","['RWTH Aachen University', 'Fraunhofer Institute for Applied Information Technology']",['Germany'],2023-07
2307.02243,Garrett Allen,"Garrett Allen, Gaole He, Ujwal Gadiraju",Power-up! What Can Generative Models Do for Human Computation Workflows?,"Accepted and presented at the Generative AI Workshop as part of CHI
  2023",,,,cs.HC cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  We are amidst an explosion of artificial intelligence research, particularly around large language models (LLMs). These models have a range of applications across domains like medicine, finance, commonsense knowledge graphs, and crowdsourcing. Investigation into LLMs as part of crowdsourcing workflows remains an under-explored space. The crowdsourcing research community has produced a body of work investigating workflows and methods for managing complex tasks using hybrid human-AI methods. Within crowdsourcing, the role of LLMs can be envisioned as akin to a cog in a larger wheel of workflows. From an empirical standpoint, little is currently understood about how LLMs can improve the effectiveness of crowdsourcing workflows and how such workflows can be evaluated. In this work, we present a vision for exploring this gap from the perspectives of various stakeholders involved in the crowdsourcing paradigm -- the task requesters, crowd workers, platforms, and end-users. We identify junctures in typical crowdsourcing workflows at which the introduction of LLMs can play a beneficial role and propose means to augment existing design patterns for crowd work. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 12:35:29 GMT'}]",2023-07-06,"[['Allen', 'Garrett', ''], ['He', 'Gaole', ''], ['Gadiraju', 'Ujwal', '']]",0,0,2023-07-05,1,3,2,0,0,0,0d0488ae0917eaf15e0417e4903a2adb4bdbeafb,259341825.0,https://www.semanticscholar.org/paper/0d0488ae0917eaf15e0417e4903a2adb4bdbeafb,arXiv.org,2023.0,49.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2059529123', 'name': 'Garrett Allen'}, {'authorId': '51149404', 'name': 'Gaole He'}, {'authorId': '2516584', 'name': 'U. Gadiraju'}]",['Delft University of Technology'],['Netherlands'],2023-07
2307.02288,Xuan-Quy Dao,Xuan-Quy Dao,"Performance Comparison of Large Language Models on VNHSGE English Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard","11 pages, 8 figures",,,,cs.CL cs.HC,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper presents a performance comparison of three large language models (LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat (BingChat), and Google Bard, on the VNHSGE English dataset. The performance of BingChat, Bard, and ChatGPT (GPT-3.5) is 92.4\%, 86\%, and 79.2\%, respectively. The results show that BingChat is better than ChatGPT and Bard. Therefore, BingChat and Bard can replace ChatGPT while ChatGPT is not yet officially available in Vietnam. The results also indicate that BingChat, Bard and ChatGPT outperform Vietnamese students in English language proficiency. The findings of this study contribute to the understanding of the potential of LLMs in English language education. The remarkable performance of ChatGPT, BingChat, and Bard demonstrates their potential as effective tools for teaching and learning English at the high school level. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 13:40:57 GMT'}, {'version': 'v2', 'created': 'Fri, 7 Jul 2023 00:43:00 GMT'}, {'version': 'v3', 'created': 'Thu, 20 Jul 2023 01:13:27 GMT'}]",2023-07-21,"[['Dao', 'Xuan-Quy', '']]",1,1,2023-07-05,3,1,2,2,0,2,f7f4117842ffd66800b0fe461b1700485f75cc31,259342803.0,https://www.semanticscholar.org/paper/f7f4117842ffd66800b0fe461b1700485f75cc31,arXiv.org,2023.0,17.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2134798816', 'name': 'Xuan-Quy Dao'}]",['Eastern International University'],['Vietnam'],2023-07
2307.02313,Ana-Maria Bucur,Ana-Maria Bucur,Utilizing ChatGPT Generated Data to Retrieve Depression Symptoms from Social Media,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this work, we present the contribution of the BLUE team in the eRisk Lab task on searching for symptoms of depression. The task consists of retrieving and ranking Reddit social media sentences that convey symptoms of depression from the BDI-II questionnaire. Given that synthetic data provided by LLMs have been proven to be a reliable method for augmenting data and fine-tuning downstream models, we chose to generate synthetic data using ChatGPT for each of the symptoms of the BDI-II questionnaire. We designed a prompt such that the generated data contains more richness and semantic diversity than the BDI-II responses for each question and, at the same time, contains emotional and anecdotal experiences that are specific to the more intimate way of sharing experiences on Reddit. We perform semantic search and rank the sentences' relevance to the BDI-II symptoms by cosine similarity. We used two state-of-the-art transformer-based models (MentalRoBERTa and a variant of MPNet) for embedding the social media posts, the original and generated responses of the BDI-II. Our results show that using sentence embeddings from a model designed for semantic search outperforms the approach using embeddings from a model pre-trained on mental health data. Furthermore, the generated synthetic data were proved too specific for this task, the approach simply relying on the BDI-II responses had the best performance. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 14:15:15 GMT'}, {'version': 'v2', 'created': 'Thu, 6 Jul 2023 11:08:51 GMT'}]",2023-07-07,"[['Bucur', 'Ana-Maria', '']]",1,1,2023-07-05,2,1,1,1,0,1,5f464e88001b1658550f8d12d131e90aa9d310f9,259343869.0,https://www.semanticscholar.org/paper/5f464e88001b1658550f8d12d131e90aa9d310f9,Conference and Labs of the Evaluation Forum,2023.0,37.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2007651543', 'name': 'Ana-Maria Bucur'}]","['University of Bucharest', 'Universitat Politècnica de València']","['Romania', 'Spain']",2023-07
2307.02443,Leon Moonen,Max Hort and Anastasiia Grishina and Leon Moonen,An Exploratory Literature Study on Sharing and Energy Use of Language Models for Source Code,"Accepted for publication in the 17th ACM/IEEE International Symposium
  on Empirical Software Engineering and Measurement (ESEM 2023)",,,,cs.SE cs.AI cs.CL cs.LG cs.NE,http://creativecommons.org/licenses/by/4.0/,"  Large language models trained on source code can support a variety of software development tasks, such as code recommendation and program repair. Large amounts of data for training such models benefit the models' performance. However, the size of the data and models results in long training times and high energy consumption. While publishing source code allows for replicability, users need to repeat the expensive training process if models are not shared. The main goal of the study is to investigate if publications that trained language models for software engineering (SE) tasks share source code and trained artifacts. The second goal is to analyze the transparency on training energy usage. We perform a snowballing-based literature search to find publications on language models for source code, and analyze their reusability from a sustainability standpoint.   From 494 unique publications, we identified 293 relevant publications that use language models to address code-related tasks. Among them, 27% (79 out of 293) make artifacts available for reuse. This can be in the form of tools or IDE plugins designed for specific tasks or task-agnostic models that can be fine-tuned for a variety of downstream tasks. Moreover, we collect insights on the hardware used for model training, as well as training time, which together determine the energy consumption of the development process. We find that there are deficiencies in the sharing of information and artifacts for current studies on source code models for software engineering tasks, with 40% of the surveyed papers not sharing source code or trained artifacts. We recommend the sharing of source code as well as trained artifacts, to enable sustainable reproducibility. Moreover, comprehensive information on training times and hardware configurations should be shared for transparency on a model's carbon footprint. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 17:13:00 GMT'}]",2023-07-06,"[['Hort', 'Max', ''], ['Grishina', 'Anastasiia', ''], ['Moonen', 'Leon', '']]",0,0,2023-07-05,1,3,5,0,0,0,b531ec9810a1c913df2d76c75b167b55211e8a85,259342301.0,https://www.semanticscholar.org/paper/b531ec9810a1c913df2d76c75b167b55211e8a85,International Symposium on Empirical Software Engineering and Measurement,2023.0,129.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2091097171', 'name': 'Max Hort'}, {'authorId': '73569689', 'name': 'Anastasiia Grishina'}, {'authorId': '1762006', 'name': 'L. Moonen'}]",['Simula Research Laboratory'],['Norway'],2023-07
2307.02502,Renato P. Dos Santos,"Melanie Swan, Takashi Kido, Eric Roland, Renato P. dos Santos","Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics",,,,,q-bio.OT cs.AI cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  The advancement in generative AI could be boosted with more accessible mathematics. Beyond human-AI chat, large language models (LLMs) are emerging in programming, algorithm discovery, and theorem proving, yet their genomics application is limited. This project introduces Math Agents and mathematical embedding as fresh entries to the ""Moore's Law of Mathematics"", using a GPT-based workflow to convert equations from literature into LaTeX and Python formats. While many digital equation representations exist, there's a lack of automated large-scale evaluation tools. LLMs are pivotal as linguistic user interfaces, providing natural language access for human-AI chat and formal languages for large-scale AI-assisted computational infrastructure. Given the infinite formal possibility spaces, Math Agents, which interact with math, could potentially shift us from ""big data"" to ""big math"". Math, unlike the more flexible natural language, has properties subject to proof, enabling its use beyond traditional applications like high-validation math-certified icons for AI alignment aims. This project aims to use Math Agents and mathematical embeddings to address the ageing issue in information systems biology by applying multiscalar physics mathematics to disease models and genomic data. Generative AI with episodic memory could help analyse causal relations in longitudinal health records, using SIR Precision Health models. Genomic data is suggested for addressing the unsolved Alzheimer's disease problem. ","[{'version': 'v1', 'created': 'Tue, 4 Jul 2023 20:16:32 GMT'}]",2023-07-07,"[['Swan', 'Melanie', ''], ['Kido', 'Takashi', ''], ['Roland', 'Eric', ''], ['Santos', 'Renato P. dos', '']]",0,1,2023-07-04,1,4,3,0,0,0,90fff3e6c55fc43f81e96fea1dc63f114cc036c1,259360593.0,https://www.semanticscholar.org/paper/90fff3e6c55fc43f81e96fea1dc63f114cc036c1,arXiv.org,2023.0,47.0,1.0,1.0,True,"['Computer Science', 'Biology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46838780', 'name': 'M. Swan'}, {'authorId': '2062583457', 'name': 'Takashi Kido'}, {'authorId': '2221202554', 'name': 'Eric Roland'}, {'authorId': '143749184', 'name': 'R. P. D. Santos'}]","['University College London', 'Universidade Luterana do Brasil', 'Teikyo University']","['Japan', 'United Kingdom', 'Brazil']",2023-07
2307.02518,Walid Hariri,Walid Hariri,Analyzing the Performance of ChatGPT in Cardiology and Vascular Pathologies,,,,,cs.CL cs.CY,http://creativecommons.org/licenses/by/4.0/,"  The article aims to analyze the performance of ChatGPT, a large language model developed by OpenAI, in the context of cardiology and vascular pathologies. The study evaluated the accuracy of ChatGPT in answering challenging multiple-choice questions (QCM) using a dataset of 190 questions from the Siamois-QCM platform. The goal was to assess ChatGPT potential as a valuable tool in medical education compared to two well-ranked students of medicine. The results showed that ChatGPT outperformed the students, scoring 175 out of 190 correct answers with a percentage of 92.10\%, while the two students achieved scores of 163 and 159 with percentages of 85.78\% and 82.63\%, respectively. These results showcase how ChatGPT has the potential to be highly effective in the fields of cardiology and vascular pathologies by providing accurate answers to relevant questions. ","[{'version': 'v1', 'created': 'Sat, 15 Apr 2023 20:08:48 GMT'}]",2023-07-07,"[['Hariri', 'Walid', '']]",1,1,2023-04-15,1,1,2,1,0,1,3d7e92a11e3538f7897c5ffc1bbfb10cdcb19019,259360919.0,https://www.semanticscholar.org/paper/3d7e92a11e3538f7897c5ffc1bbfb10cdcb19019,arXiv.org,2023.0,4.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '3430858', 'name': 'Walid Hariri'}]",['Badji Mokhtar University'],['Algeria'],2023-04
2307.02628,Luciano Del Corro,"Luciano Del Corro, Allie Del Giorno, Sahaj Agarwal, Bin Yu, Ahmed
  Awadallah, Subhabrata Mukherjee",SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Autoregressive large language models (LLMs) have made remarkable progress in various natural language generation tasks. However, they incur high computation cost and latency resulting from the autoregressive token-by-token generation. To address this issue, several approaches have been proposed to reduce computational cost using early-exit strategies. These strategies enable faster text generation using reduced computation without applying the full computation graph to each token. While existing token-level early exit methods show promising results for online inference, they cannot be readily applied for batch inferencing and Key-Value caching. This is because they have to wait until the last token in a batch exits before they can stop computing. This severely limits the practical application of such techniques. In this paper, we propose a simple and effective token-level early exit method, SkipDecode, designed to work seamlessly with batch inferencing and KV caching. It overcomes prior constraints by setting up a singular exit point for every token in a batch at each sequence position. It also guarantees a monotonic decrease in exit points, thereby eliminating the need to recompute KV Caches for preceding tokens. Rather than terminating computation prematurely as in prior works, our approach bypasses lower to middle layers, devoting most of the computational resources to upper layers, allowing later tokens to benefit from the compute expenditure by earlier tokens. Our experimental results show that SkipDecode can obtain 2x to 5x inference speedups with negligible regression across a variety of tasks. This is achieved using OPT models of 1.3 billion and 6.7 billion parameters, all the while being directly compatible with batching and KV caching optimization techniques. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 19:59:09 GMT'}]",2023-07-07,"[['Del Corro', 'Luciano', ''], ['Del Giorno', 'Allie', ''], ['Agarwal', 'Sahaj', ''], ['Yu', 'Bin', ''], ['Awadallah', 'Ahmed', ''], ['Mukherjee', 'Subhabrata', '']]",0,0,2023-07-05,1,6,1,1,1,0,ce9435c82dc9b576f2037aa2f4357a520be9b2aa,259360560.0,https://www.semanticscholar.org/paper/ce9435c82dc9b576f2037aa2f4357a520be9b2aa,arXiv.org,2023.0,26.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1875906', 'name': 'Luciano Del Corro'}, {'authorId': '50672277', 'name': 'Allison Del Giorno'}, {'authorId': '2211923024', 'name': 'Sahaj Agarwal'}, {'authorId': '46806278', 'name': 'Ting Yu'}, {'authorId': '2072795428', 'name': 'A. Awadallah'}, {'authorId': '2153292652', 'name': 'Subhabrata Mukherjee'}]",['Microsoft'],['India'],2023-07
2307.02682,Yongrae Jo,"Yongrae Jo, Seongyun Lee, Aiden SJ Lee, Hyunji Lee, Hanseok Oh,
  Minjoon Seo",Zero-Shot Dense Video Captioning by Jointly Optimizing Text and Moment,,,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Dense video captioning, a task of localizing meaningful moments and generating relevant captions for videos, often requires a large, expensive corpus of annotated video segments paired with text. In an effort to minimize the annotation cost, we propose ZeroTA, a novel method for dense video captioning in a zero-shot manner. Our method does not require any videos or annotations for training; instead, it localizes and describes events within each input video at test time by optimizing solely on the input. This is accomplished by introducing a soft moment mask that represents a temporal segment in the video and jointly optimizing it with the prefix parameters of a language model. This joint optimization aligns a frozen language generation model (i.e., GPT-2) with a frozen vision-language contrastive model (i.e., CLIP) by maximizing the matching score between the generated text and a moment within the video. We also introduce a pairwise temporal IoU loss to let a set of soft moment masks capture multiple distinct events within the video. Our method effectively discovers diverse significant events within the video, with the resulting captions appropriately describing these events. The empirical results demonstrate that ZeroTA surpasses zero-shot baselines and even outperforms the state-of-the-art few-shot method on the widely-used benchmark ActivityNet Captions. Moreover, our method shows greater robustness compared to supervised methods when evaluated in out-of-domain scenarios. This research provides insight into the potential of aligning widely-used models, such as language generation models and vision-language models, to unlock a new capability: understanding temporal aspects of videos. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 23:01:26 GMT'}, {'version': 'v2', 'created': 'Tue, 11 Jul 2023 04:10:49 GMT'}]",2023-07-13,"[['Jo', 'Yongrae', ''], ['Lee', 'Seongyun', ''], ['Lee', 'Aiden SJ', ''], ['Lee', 'Hyunji', ''], ['Oh', 'Hanseok', ''], ['Seo', 'Minjoon', '']]",0,1,2023-07-05,2,6,2,1,1,0,2156ed024f2975208f5eb5ce0654608a97f01b46,259360812.0,https://www.semanticscholar.org/paper/2156ed024f2975208f5eb5ce0654608a97f01b46,arXiv.org,2023.0,53.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2144061605', 'name': 'Yongrae Jo'}, {'authorId': '2204559324', 'name': 'Seongyun Lee'}, {'authorId': '2221268022', 'name': 'Aiden SJ Lee'}, {'authorId': '2140191673', 'name': 'Hyunji Lee'}, {'authorId': '2150052936', 'name': 'Hanseok Oh'}, {'authorId': '4418074', 'name': 'Minjoon Seo'}]","['Korea Advanced Institute of Science and Technology', 'Korea University']",['South Korea'],2023-07
2307.03025,Minghao Wu,"Minghao Wu, Alham Fikri Aji",Style Over Substance: Evaluation Biases for Large Language Models,"Work in progress, 17 pages, 4 tables, 12 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As large language models (LLMs) continue to advance, accurately and comprehensively evaluating their performance becomes increasingly challenging. Human evaluations are conventionally considered the gold standard in natural language generation, but recent advancements incorporate state-of-the-art LLMs as proxies for human judges in evaluation processes. However, the extent to which humans and LLMs are capable evaluators remains uncertain. This study investigates the behavior of crowd-sourced and expert annotators, as well as LLMs, when comparing outputs from different models. To achieve this, we curate a dataset of intentionally flawed machine-generated answers. Our findings reveal a concerning bias in the evaluation process, as answers with factual errors are rated more favorably than answers that are too short or contained grammatical errors. To address this issue, we propose independently evaluating machine-generated text across multiple dimensions, rather than merging all the evaluation aspects into a single score. We instantiate this idea with the Elo rating system, resulting in the Multi-Elo Rating System. Empirical results from our study reveal that this proposed approach significantly enhances the quality of LLM-based evaluations, particularly in terms of factual accuracy. However, there is no significant improvement in crowd-sourced-based evaluations, indicating the need for further investigation and refinement. ","[{'version': 'v1', 'created': 'Thu, 6 Jul 2023 14:42:01 GMT'}, {'version': 'v2', 'created': 'Tue, 15 Aug 2023 05:11:41 GMT'}]",2023-08-16,"[['Wu', 'Minghao', ''], ['Aji', 'Alham Fikri', '']]",0,0,2023-07-06,2,2,1,0,0,0,7ace46ab8e71c4304682ab126b1212deb54b9b03,259360998.0,https://www.semanticscholar.org/paper/7ace46ab8e71c4304682ab126b1212deb54b9b03,arXiv.org,2023.0,47.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2145209409', 'name': 'Minghao Wu'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}]","['Monash University', 'Mohamed bin Zayed University of Artificial Intelligence']","['United Arab Emirates', 'Australia']",2023-07
2307.03027,Sebastian Schelter,"Xiaozhong Lyu, Stefan Grafberger, Samantha Biegel, Shaopeng Wei, Meng
  Cao, Sebastian Schelter, Ce Zhang",Improving Retrieval-Augmented Large Language Models via Data Importance Learning,,,,,cs.LG cs.CL cs.IR,http://creativecommons.org/licenses/by-sa/4.0/,"  Retrieval augmentation enables large language models to take advantage of external knowledge, for example on tasks like question answering and data imputation. However, the performance of such retrieval-augmented models is limited by the data quality of their underlying retrieval corpus. In this paper, we propose an algorithm based on multilinear extension for evaluating the data importance of retrieved data points. There are exponentially many terms in the multilinear extension, and one key contribution of this paper is a polynomial time algorithm that computes exactly, given a retrieval-augmented model with an additive utility function and a validation set, the data importance of data points in the retrieval corpus using the multilinear extension of the model's utility function. We further proposed an even more efficient ({\epsilon}, {\delta})-approximation algorithm. Our experimental results illustrate that we can enhance the performance of large language models by only pruning or reweighting the retrieval corpus, without requiring further training. For some tasks, this even allows a small model (e.g., GPT-JT), augmented with a search engine API, to outperform GPT-3.5 (without retrieval augmentation). Moreover, we show that weights based on multilinear extension can be computed efficiently in practice (e.g., in less than ten minutes for a corpus with 100 million elements). ","[{'version': 'v1', 'created': 'Thu, 6 Jul 2023 14:44:07 GMT'}]",2023-07-07,"[['Lyu', 'Xiaozhong', ''], ['Grafberger', 'Stefan', ''], ['Biegel', 'Samantha', ''], ['Wei', 'Shaopeng', ''], ['Cao', 'Meng', ''], ['Schelter', 'Sebastian', ''], ['Zhang', 'Ce', '']]",0,1,2023-07-06,1,7,3,1,0,1,f2dbc96d7f8250b1c6e7ebcdf9a8093b9c286226,259360590.0,https://www.semanticscholar.org/paper/f2dbc96d7f8250b1c6e7ebcdf9a8093b9c286226,arXiv.org,2023.0,30.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35308280', 'name': 'Xiaozhong Lyu'}, {'authorId': '1393463989', 'name': 'Stefan Grafberger'}, {'authorId': '2086970867', 'name': 'Samantha Biegel'}, {'authorId': '1409866591', 'name': 'Shaopeng Wei'}, {'authorId': '2057073725', 'name': 'Meng Cao'}, {'authorId': '2180399', 'name': 'Sebastian Schelter'}, {'authorId': '1776014', 'name': 'Ce Zhang'}]",['University of Amsterdam'],['Netherlands'],2023-07
2307.03042,Aryo Gema,"Aryo Pradipta Gema, Luke Daines, Pasquale Minervini, Beatrice Alex",Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Adapting pretrained language models to novel domains, such as clinical applications, traditionally involves retraining their entire set of parameters. However, this approach is increasingly proven to be impractical owing to the substantial computational requirements associated with training such large language models. To address this issue, Parameter-Efficient Fine-Tuning (PEFT) techniques offer a viable solution by selectively fine-tuning a small subset of additional parameters, significantly reducing the computational requirements for domain adaptation. In this study, we propose Clinical LLaMA-LoRA, a PEFT adapter layer built upon the open-sourced LLaMA model. Clinical LLaMA-LoRA is trained using clinical notes obtained from the MIMIC-IV database, thereby creating a specialised adapter designed for the clinical domain. Additionally, we propose a two-step PEFT framework which fuses Clinical LLaMA-LoRA with Downstream LLaMA-LoRA, another PEFT adapter specialised for downstream tasks. We evaluate this framework on multiple clinical outcome prediction datasets, comparing it to clinically trained language models. Our proposed framework achieves a state-of-the-art AUROC score averaged across all clinical downstream tasks. We observe substantial improvements of 6-9% AUROC score in the large-scale multilabel classification tasks, such as diagnoses and procedures classification. ","[{'version': 'v1', 'created': 'Thu, 6 Jul 2023 15:06:41 GMT'}, {'version': 'v2', 'created': 'Wed, 12 Jul 2023 13:57:41 GMT'}]",2023-07-13,"[['Gema', 'Aryo Pradipta', ''], ['Daines', 'Luke', ''], ['Minervini', 'Pasquale', ''], ['Alex', 'Beatrice', '']]",0,0,2023-07-06,2,4,2,1,1,0,6651eb8205e3d90c420fbdf8a2740c74e590e545,259361061.0,https://www.semanticscholar.org/paper/6651eb8205e3d90c420fbdf8a2740c74e590e545,arXiv.org,2023.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '27080447', 'name': 'Aryo Pradipta Gema'}, {'authorId': '7823016', 'name': 'L. Daines'}, {'authorId': '3051815', 'name': 'Pasquale Minervini'}, {'authorId': '2089542577', 'name': 'B. Alex'}]",['University of Edinburgh'],['United Kingdom'],2023-07
2307.03489,Paulo Jos\'e Cavalcanti De Vasconcelos Filho,"Paulo J. Cavalcanti, John H. Selby, Ana Bel\'en Sainz",Every non-signalling channel is common-cause realizable,"18 pages, loads of digrams. Comments welcome",,,,quant-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this work we show that the set of non-signalling resources of a locally-tomographic generalised probabilistic theory (GPT), such as quantum and classical theory, coincides with its set of GPT-common-cause realizable resources, where the common causes come from an associated GPT. From a causal perspective, this result provides a reason for, in the study of resource theories of common-cause processes, taking the non-signalling channels as the resources of the enveloping theory. This answers a critical open question in Ref.~\cite{schmid2020postquantum}. An immediate corollary of our result is that every non-signalling assemblage is realizable in a GPT, answering in the affirmative the question posed in Ref.~\cite{cavalcanti2022post}. ","[{'version': 'v1', 'created': 'Fri, 7 Jul 2023 09:56:14 GMT'}]",2023-07-10,"[['Cavalcanti', 'Paulo J.', ''], ['Selby', 'John H.', ''], ['Sainz', 'Ana Belén', '']]",0,1,2023-07-07,1,3,1,0,0,0,f47d64c09f562cdfe11aa90039a57825e0ab8c9f,259375625.0,https://www.semanticscholar.org/paper/f47d64c09f562cdfe11aa90039a57825e0ab8c9f,,2023.0,15.0,0.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1490482349', 'name': 'P. J. Cavalcanti'}, {'authorId': '49610827', 'name': 'John H. Selby'}, {'authorId': '102423242', 'name': 'A. B. Sainz'}]",['University of Gdańsk'],['Poland'],2023-07
2307.03569,Christin Katharina Kreutz,"Bj\""orn Engelmann, Fabian Haak, Christin Katharina Kreutz, Narjes
  Nikzad Khasmakhi, Philipp Schaer",Text Simplification of Scientific Texts for Non-Expert Readers,"Paper accepted at SimpleText@CLEF'23, 12 pages, 1 Figure, 4 Tables",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Reading levels are highly individual and can depend on a text's language, a person's cognitive abilities, or knowledge on a topic. Text simplification is the task of rephrasing a text to better cater to the abilities of a specific target reader group. Simplification of scientific abstracts helps non-experts to access the core information by bypassing formulations that require domain or expert knowledge. This is especially relevant for, e.g., cancer patients reading about novel treatment options. The SimpleText lab hosts the simplification of scientific abstracts for non-experts (Task 3) to advance this field. We contribute three runs employing out-of-the-box summarization models (two based on T5, one based on PEGASUS) and one run using ChatGPT with complex phrase identification. ","[{'version': 'v1', 'created': 'Fri, 7 Jul 2023 13:05:11 GMT'}]",2023-07-10,"[['Engelmann', 'Björn', ''], ['Haak', 'Fabian', ''], ['Kreutz', 'Christin Katharina', ''], ['Khasmakhi', 'Narjes Nikzad', ''], ['Schaer', 'Philipp', '']]",1,1,2023-07-07,1,5,2,2,1,1,c73ff556c6e62df4a59f9b1120c5d61b73b7b6ba,259377033.0,https://www.semanticscholar.org/paper/c73ff556c6e62df4a59f9b1120c5d61b73b7b6ba,Conference and Labs of the Evaluation Forum,2023.0,27.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '19108802', 'name': 'Björn Engelmann'}, {'authorId': '2117326853', 'name': 'Fabian Haak'}, {'authorId': '46351484', 'name': 'Christin Katharina Kreutz'}, {'authorId': '1620486779', 'name': 'Narjes Nikzad'}, {'authorId': '2221321580', 'name': 'Khasmakhi'}, {'authorId': '34588911', 'name': 'Philipp Schaer'}]",['TH Köln - University of Applied Sciences'],['Germany'],2023-07
2307.03941,Dawen Zhang,"Dawen Zhang, Pamela Finckenberg-Broman, Thong Hoang, Shidong Pan,
  Zhenchang Xing, Mark Staples, Xiwei Xu","Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions","The new version made minor changes related to the writing and also
  the existing literature",,,,cs.CY cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. It was a significant emergent right as the result of the evolution of technology. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of differential privacy, machine unlearning, model editing, and prompt engineering. With the rapid advancement of AI and the increasing need of regulating this powerful technology, learning from the case of RTBF can provide valuable lessons for technical practitioners, legal experts, organizations, and authorities. ","[{'version': 'v1', 'created': 'Sat, 8 Jul 2023 09:28:50 GMT'}, {'version': 'v2', 'created': 'Fri, 8 Sep 2023 14:51:10 GMT'}, {'version': 'v3', 'created': 'Fri, 22 Sep 2023 01:43:33 GMT'}]",2023-09-25,"[['Zhang', 'Dawen', ''], ['Finckenberg-Broman', 'Pamela', ''], ['Hoang', 'Thong', ''], ['Pan', 'Shidong', ''], ['Xing', 'Zhenchang', ''], ['Staples', 'Mark', ''], ['Xu', 'Xiwei', '']]",0,0,2023-07-08,3,7,3,0,0,0,8f93f95e093aab16e594b4a246a205007e107c7a,259501864.0,https://www.semanticscholar.org/paper/8f93f95e093aab16e594b4a246a205007e107c7a,arXiv.org,2023.0,34.0,4.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2044453685', 'name': 'Dawen Zhang'}, {'authorId': '1450822328', 'name': 'Pamela Finckenberg-Broman'}, {'authorId': '9719656', 'name': 'Thong Hoang'}, {'authorId': '2111780741', 'name': 'Shidong Pan'}, {'authorId': '3138980', 'name': 'Zhenchang Xing'}, {'authorId': '144283633', 'name': 'M. Staples'}, {'authorId': '3087664', 'name': 'Xiwei Xu'}]",['Australian National University'],['Australia'],2023-07
2307.04172,Rao Ma,"Rao Ma, Mengjie Qian, Potsawee Manakul, Mark Gales, Kate Knill",Can Generative Large Language Models Perform ASR Error Correction?,,,,,cs.CL cs.SD eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ASR error correction is an interesting option for post processing speech recognition system outputs. These error correction models are usually trained in a supervised fashion using the decoding results of a target ASR system. This approach can be computationally intensive and the model is tuned to a specific ASR system. Recently generative large language models (LLMs) have been applied to a wide range of natural language processing tasks, as they can operate in a zero-shot or few shot fashion. In this paper we investigate using ChatGPT, a generative LLM, for ASR error correction. Based on the ASR N-best output, we propose both unconstrained and constrained, where a member of the N-best list is selected, approaches. Additionally, zero and 1-shot settings are evaluated. Experiments show that this generative LLM approach can yield performance gains for two different state-of-the-art ASR architectures, transducer and attention-encoder-decoder based, and multiple test sets. ","[{'version': 'v1', 'created': 'Sun, 9 Jul 2023 13:38:25 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Sep 2023 07:32:03 GMT'}]",2023-10-02,"[['Ma', 'Rao', ''], ['Qian', 'Mengjie', ''], ['Manakul', 'Potsawee', ''], ['Gales', 'Mark', ''], ['Knill', 'Kate', '']]",1,1,2023-07-09,2,5,3,1,0,1,f52ea31e37c45e0de7ab4a5324d4d970479c110a,259501588.0,https://www.semanticscholar.org/paper/f52ea31e37c45e0de7ab4a5324d4d970479c110a,arXiv.org,2023.0,37.0,6.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50397234', 'name': 'Rao Ma'}, {'authorId': '10769548', 'name': 'Mengjie Qian'}, {'authorId': '89355510', 'name': 'Potsawee Manakul'}, {'authorId': '1740397', 'name': 'M. Gales'}, {'authorId': '145962472', 'name': 'K. Knill'}]",['University of Cambridge'],['United Kingdom'],2023-07
2307.04412,Dima Galat,"Dima Galat, Marian-Andrei Rizoiu",Enhancing Biomedical Text Summarization and Question-Answering: On the Utility of Domain-Specific Pre-Training,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Biomedical summarization requires large datasets to train for text generation. We show that while transfer learning offers a viable option for addressing this challenge, an in-domain pre-training does not always offer advantages in a BioASQ summarization task. We identify a suitable model architecture and use it to show a benefit of a general-domain pre-training followed by a task-specific fine-tuning in the context of a BioASQ summarization task, leading to a novel three-step fine-tuning approach that works with only a thousand in-domain examples. Our results indicate that a Large Language Model without domain-specific pre-training can have a significant edge in some domain-specific biomedical text generation tasks. ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 08:32:45 GMT'}]",2023-07-11,"[['Galat', 'Dima', ''], ['Rizoiu', 'Marian-Andrei', '']]",0,0,2023-07-10,1,2,1,0,0,0,8a1c61b9364f0ae19331b1ea753ff892c635c59b,259502233.0,https://www.semanticscholar.org/paper/8a1c61b9364f0ae19331b1ea753ff892c635c59b,Conference and Labs of the Evaluation Forum,2023.0,34.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2124425279', 'name': 'Dima Galat'}, {'authorId': '1808087', 'name': 'Marian-Andrei Rizoiu'}]","['University of Technology Sydney', 'University of Technology']","['Russia', 'Australia']",2023-07
2307.04492,Shipra Sharma Ms.,Shipra Sharma and Balwinder Sodhi,Calculating Originality of LLM Assisted Source Code,,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The ease of using a Large Language Model (LLM) to answer a wide variety of queries and their high availability has resulted in LLMs getting integrated into various applications. LLM-based recommenders are now routinely used by students as well as professional software programmers for code generation and testing. Though LLM-based technology has proven useful, its unethical and unattributed use by students and professionals is a growing cause of concern. As such, there is a need for tools and technologies which may assist teachers and other evaluators in identifying whether any portion of a source code is LLM generated.   In this paper, we propose a neural network-based tool that instructors can use to determine the original effort (and LLM's contribution) put by students in writing source codes. Our tool is motivated by minimum description length measures like Kolmogorov complexity. Our initial experiments with moderate sized (up to 500 lines of code) have shown promising results that we report in this paper. ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 11:30:46 GMT'}]",2023-07-11,"[['Sharma', 'Shipra', ''], ['Sodhi', 'Balwinder', '']]",0,0,2023-07-10,1,2,1,0,0,0,601d612088d048bb5a9bfafb45c4463c0725cc1c,259501012.0,https://www.semanticscholar.org/paper/601d612088d048bb5a9bfafb45c4463c0725cc1c,arXiv.org,2023.0,25.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109850198', 'name': 'Shipra Sharma'}, {'authorId': '2453744', 'name': 'B. Sodhi'}]",['Indian Institute of Technology Ropar'],['India'],2023-07
2307.04573,Deniz Kenan K{\i}l{\i}\c{c},"Deniz Kenan K{\i}l{\i}\c{c}, Alex Elkj{\ae}r Vasegaard, Aur\'elien
  Desoeuvres, Peter Nielsen",A Semi-Automated Solution Approach Selection Tool for Any Use Case via Scopus and OpenAI: a Case Study for AI/ML in Oncology,"The paper is under review in Expert Systems with Applications,
  Elsevier",,,,cs.AI cs.IR cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In today's vast literature landscape, a manual review is very time-consuming. To address this challenge, this paper proposes a semi-automated tool for solution method review and selection. It caters to researchers, practitioners, and decision-makers while serving as a benchmark for future work. The tool comprises three modules: (1) paper selection and scoring, using a keyword selection scheme to query Scopus API and compute relevancy; (2) solution method extraction in papers utilizing OpenAI API; (3) sensitivity analysis and post-analyzes. It reveals trends, relevant papers, and methods. AI in the oncology case study and several use cases are presented with promising results, comparing the tool to manual ground truth. ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 14:07:28 GMT'}]",2023-07-11,"[['Kılıç', 'Deniz Kenan', ''], ['Vasegaard', 'Alex Elkjær', ''], ['Desoeuvres', 'Aurélien', ''], ['Nielsen', 'Peter', '']]",0,0,2023-07-10,1,4,3,0,0,0,64c8a8d7515c36e69cfd4133e7926b973f707836,259501676.0,https://www.semanticscholar.org/paper/64c8a8d7515c36e69cfd4133e7926b973f707836,arXiv.org,2023.0,58.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49199984', 'name': 'D. Kılıç'}, {'authorId': '1520173098', 'name': 'Alex Elkjær Vasegaard'}, {'authorId': '1708201732', 'name': 'Aurélien Desoeuvres'}, {'authorId': '2221649400', 'name': 'Peter Nielsen'}]",['Aalborg University'],['Denmark'],2023-07
2307.04601,Hugo Abonizio,"Hugo Abonizio, Luiz Bonifacio, Vitor Jeronymo, Roberto Lotufo, Jakub
  Zavrel, Rodrigo Nogueira",InPars Toolkit: A Unified and Reproducible Synthetic Data Generation Pipeline for Neural Information Retrieval,,,,,cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Recent work has explored Large Language Models (LLMs) to overcome the lack of training data for Information Retrieval (IR) tasks. The generalization abilities of these models have enabled the creation of synthetic in-domain data by providing instructions and a few examples on a prompt. InPars and Promptagator have pioneered this approach and both methods have demonstrated the potential of using LLMs as synthetic data generators for IR tasks. This makes them an attractive solution for IR tasks that suffer from a lack of annotated data. However, the reproducibility of these methods was limited, because InPars' training scripts are based on TPUs -- which are not widely accessible -- and because the code for Promptagator was not released and its proprietary LLM is not publicly accessible. To fully realize the potential of these methods and make their impact more widespread in the research community, the resources need to be accessible and easy to reproduce by researchers and practitioners. Our main contribution is a unified toolkit for end-to-end reproducible synthetic data generation research, which includes generation, filtering, training and evaluation. Additionally, we provide an interface to IR libraries widely used by the community and support for GPU. Our toolkit not only reproduces the InPars method and partially reproduces Promptagator, but also provides a plug-and-play functionality allowing the use of different LLMs, exploring filtering methods and finetuning various reranker models on the generated data. We also made available all the synthetic data generated in this work for the 18 different datasets in the BEIR benchmark which took more than 2,000 GPU hours to be generated as well as the reranker models finetuned on the synthetic data. Code and data are available at https://github.com/zetaalphavector/InPars ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 14:39:43 GMT'}]",2023-07-11,"[['Abonizio', 'Hugo', ''], ['Bonifacio', 'Luiz', ''], ['Jeronymo', 'Vitor', ''], ['Lotufo', 'Roberto', ''], ['Zavrel', 'Jakub', ''], ['Nogueira', 'Rodrigo', '']]",0,0,2023-07-10,1,6,1,0,0,0,1c5f8e384b06c01d71d629040f3dc3e3fc2da6c1,259501085.0,https://www.semanticscholar.org/paper/1c5f8e384b06c01d71d629040f3dc3e3fc2da6c1,arXiv.org,2023.0,20.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1394470211', 'name': 'Hugo Abonizio'}, {'authorId': '2003019597', 'name': 'L. Bonifacio'}, {'authorId': '2167031295', 'name': 'Vitor Jeronymo'}, {'authorId': '2066179820', 'name': 'R. Lotufo'}, {'authorId': '3316623', 'name': 'Jakub Zavrel'}, {'authorId': '143744603', 'name': 'Rodrigo Nogueira'}]","['Universidade Estadual de Campinas (UNICAMP)', 'Zeta Alpha NeuralMind University of Campinas Brazil']",['Brazil'],2023-07
2307.04683,David Pride Mr,"David Pride, Matteo Cancellieri and Petr Knoth","CORE-GPT: Combining Open Access research and large language models for credible, trustworthy question answering","12 pages, accepted submission to TPDL2023",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we present CORE-GPT, a novel question-answering platform that combines GPT-based language models and more than 32 million full-text open access scientific articles from CORE. We first demonstrate that GPT3.5 and GPT4 cannot be relied upon to provide references or citations for generated text. We then introduce CORE-GPT which delivers evidence-based answers to questions, along with citations and links to the cited papers, greatly increasing the trustworthiness of the answers and reducing the risk of hallucinations. CORE-GPT's performance was evaluated on a dataset of 100 questions covering the top 20 scientific domains in CORE, resulting in 100 answers and links to 500 relevant articles. The quality of the provided answers and and relevance of the links were assessed by two annotators. Our results demonstrate that CORE-GPT can produce comprehensive and trustworthy answers across the majority of scientific domains, complete with links to genuine, relevant scientific articles. ","[{'version': 'v1', 'created': 'Thu, 6 Jul 2023 13:41:36 GMT'}]",2023-07-11,"[['Pride', 'David', ''], ['Cancellieri', 'Matteo', ''], ['Knoth', 'Petr', '']]",0,1,2023-07-06,1,3,2,2,0,2,6e3ac4c4e820ca939f8ec235eb256028d0125ab4,259501770.0,https://www.semanticscholar.org/paper/6e3ac4c4e820ca939f8ec235eb256028d0125ab4,arXiv.org,2023.0,16.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064119650', 'name': 'David Pride'}, {'authorId': '2066327521', 'name': 'M. Cancellieri'}, {'authorId': '1848764', 'name': 'Petr Knoth'}]",['The Open University'],['United Kingdom'],2023-07
2307.04693,Noble Saji Mathews,"Debeshee Das, Noble Saji Mathews, Alex Mathai, Srikanth Tamilselvam,
  Kranthi Sedamaki, Sridhar Chimalakonda and Atul Kumar",COMEX: A Tool for Generating Customized Source Code Representations,"The paper has been accepted for publication at ASE 2023 (Tool
  Demonstrations Track)",,,,cs.SE cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system. Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks. However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language. Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc. Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming. To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks. Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages. We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE.   Tool: https://pypi.org/project/comex - GitHub: https://github.com/IBM/tree-sitter-codeviews - Demo: https://youtu.be/GER6U87FVbU ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 16:46:34 GMT'}]",2023-07-11,"[['Das', 'Debeshee', ''], ['Mathews', 'Noble Saji', ''], ['Mathai', 'Alex', ''], ['Tamilselvam', 'Srikanth', ''], ['Sedamaki', 'Kranthi', ''], ['Chimalakonda', 'Sridhar', ''], ['Kumar', 'Atul', '']]",0,0,2023-07-10,1,7,2,2,1,1,65d44118b734afc659d36a623756f0b8646be763,259501130.0,https://www.semanticscholar.org/paper/65d44118b734afc659d36a623756f0b8646be763,International Conference on Automated Software Engineering,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2169805280', 'name': 'Debeshee Das'}, {'authorId': '1736509572', 'name': 'N. Mathews'}, {'authorId': '47569888', 'name': 'Alex Mathai'}, {'authorId': '144063173', 'name': 'Srikanth G. Tamilselvam'}, {'authorId': '2205195340', 'name': 'Kranthi Sedamaki'}, {'authorId': '1926332', 'name': 'S. Chimalakonda'}, {'authorId': '2144870066', 'name': 'Atul Kumar'}]","['Indian Institute of Technology Tirupati', 'IBM Research - India']",['India'],2023-07
2307.04761,Yi-Ling Chung,"Yi-Ling Chung, Gavin Abercrombie, Florence Enock, Jonathan Bright,
  Verena Rieser",Understanding Counterspeech for Online Harm Mitigation,"21 pages, 2 figures, 2 tables",,,,cs.CL cs.AI cs.CY,http://creativecommons.org/licenses/by-sa/4.0/,"  Counterspeech offers direct rebuttals to hateful speech by challenging perpetrators of hate and showing support to targets of abuse. It provides a promising alternative to more contentious measures, such as content moderation and deplatforming, by contributing a greater amount of positive online speech rather than attempting to mitigate harmful content through removal. Advances in the development of large language models mean that the process of producing counterspeech could be made more efficient by automating its generation, which would enable large-scale online campaigns. However, we currently lack a systematic understanding of several important factors relating to the efficacy of counterspeech for hate mitigation, such as which types of counterspeech are most effective, what are the optimal conditions for implementation, and which specific effects of hate it can best ameliorate. This paper aims to fill this gap by systematically reviewing counterspeech research in the social sciences and comparing methodologies and findings with computer science efforts in automatic counterspeech generation. By taking this multi-disciplinary view, we identify promising future directions in both fields. ","[{'version': 'v1', 'created': 'Sat, 1 Jul 2023 20:54:01 GMT'}]",2023-07-11,"[['Chung', 'Yi-Ling', ''], ['Abercrombie', 'Gavin', ''], ['Enock', 'Florence', ''], ['Bright', 'Jonathan', ''], ['Rieser', 'Verena', '']]",0,0,2023-07-01,1,5,3,0,0,0,2fca068a24b1b766c9c02c6aa004ca60d81023cc,259501638.0,https://www.semanticscholar.org/paper/2fca068a24b1b766c9c02c6aa004ca60d81023cc,arXiv.org,2023.0,109.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2087250906', 'name': 'Yi-ling Chung'}, {'authorId': '17038002', 'name': 'Gavin Abercrombie'}, {'authorId': '6503145', 'name': 'Florence E. Enock'}, {'authorId': '144008442', 'name': 'Jonathan Bright'}, {'authorId': '1681799', 'name': 'Verena Rieser'}]","['The Alan Turing Institute', 'Heriot-Watt University']",['United Kingdom'],2023-07
2307.04907,Supun Bhathiya Hemanthage,"Bhathiya Hemanthage, Christian Dondrup, Phil Bartie, Oliver Lemon",SimpleMTOD: A Simple Language Model for Multimodal Task-Oriented Dialogue with Symbolic Scene Representation,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  SimpleMTOD is a simple language model which recasts several sub-tasks in multimodal task-oriented dialogues as sequence prediction tasks. SimpleMTOD is built on a large-scale transformer-based auto-regressive architecture, which has already proven to be successful in uni-modal task-oriented dialogues, and effectively leverages transfer learning from pre-trained GPT-2. In-order to capture the semantics of visual scenes, we introduce both local and de-localized tokens for objects within a scene. De-localized tokens represent the type of an object rather than the specific object itself and so possess a consistent meaning across the dataset. SimpleMTOD achieves a state-of-the-art BLEU score (0.327) in the Response Generation sub-task of the SIMMC 2.0 test-std dataset while performing on par in other multimodal sub-tasks: Disambiguation, Coreference Resolution, and Dialog State Tracking. This is despite taking a minimalist approach for extracting visual (and non-visual) information. In addition the model does not rely on task-specific architectural changes such as classification heads. ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 21:16:46 GMT'}]",2023-07-12,"[['Hemanthage', 'Bhathiya', ''], ['Dondrup', 'Christian', ''], ['Bartie', 'Phil', ''], ['Lemon', 'Oliver', '']]",0,1,2023-07-10,1,4,2,1,1,0,e6334e47a7fa0955a295e202f4af3fd402e8303b,259766152.0,https://www.semanticscholar.org/paper/e6334e47a7fa0955a295e202f4af3fd402e8303b,International Conference on Computational Semantics,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2187584915', 'name': 'Bhathiya Hemanthage'}, {'authorId': '2069568', 'name': 'C. Dondrup'}, {'authorId': '4099495', 'name': 'P. Bartie'}, {'authorId': '1782798', 'name': 'Oliver Lemon'}]",['Heriot-Watt University'],['United Kingdom'],2023-07
2307.05082,Kyrylo Malakhov,"Oleksandr Palagin, Vladislav Kaverinskiy, Anna Litvin and Kyrylo
  Malakhov",OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning,"14 pages, 1 figure. Published. International Journal of Computing,
  22(2), 170-183. https://doi.org/10.47839/ijc.22.2.3086","International Journal of Computing (2023), 22(2), 170-183",10.47839/ijc.22.2.3086,,cs.AI cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  This research presents a comprehensive methodology for utilizing an ontology-driven structured prompts system in interplay with ChatGPT, a widely used large language model (LLM). The study develops formal models, both information and functional, and establishes the methodological foundations for integrating ontology-driven prompts with ChatGPT's meta-learning capabilities. The resulting productive triad comprises the methodological foundations, advanced information technology, and the OntoChatGPT system, which collectively enhance the effectiveness and performance of chatbot systems. The implementation of this technology is demonstrated using the Ukrainian language within the domain of rehabilitation. By applying the proposed methodology, the OntoChatGPT system effectively extracts entities from contexts, classifies them, and generates relevant responses. The study highlights the versatility of the methodology, emphasizing its applicability not only to ChatGPT but also to other chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2 LLM. The underlying principles of meta-learning, structured prompts, and ontology-driven information retrieval form the core of the proposed methodology, enabling their adaptation and utilization in various LLM-based systems. This versatile approach opens up new possibilities for NLP and dialogue systems, empowering developers to enhance the performance and functionality of chatbot systems across different domains and languages. ","[{'version': 'v1', 'created': 'Tue, 11 Jul 2023 07:31:58 GMT'}]",2023-07-12,"[['Palagin', 'Oleksandr', ''], ['Kaverinskiy', 'Vladislav', ''], ['Litvin', 'Anna', ''], ['Malakhov', 'Kyrylo', '']]",1,1,2023-07-11,1,4,3,2,0,2,5a714e920688a3a9296efa0cfa531de263a93de3,259583199.0,https://www.semanticscholar.org/paper/5a714e920688a3a9296efa0cfa531de263a93de3,International Scientific Journal of Computing,2023.0,52.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '49430517', 'name': 'O. Palagin'}, {'authorId': '2222171788', 'name': 'Vladislav Kaverinskiy'}, {'authorId': '2222165884', 'name': 'Anna Litvin'}, {'authorId': '35671992', 'name': 'K. Malakhov'}]",['National Academy of Sciences of Ukraine'],['Ukraine'],2023-07
2307.05488,Tiong Goh,Tiong-Thye Goh,Prototyping Theories with ChatGPT: Experiment with the Technology Acceptance Model,"15 pages, 6 figures, 12 tables",,,,cs.HC cs.CY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This research paper presents the findings of two experimental studies that explore the use of ChatGPT as a tool for theory prototyping. The objective of the studies is to assess ChatGPT's ability to comprehend theoretical concepts and differentiate between constructs. During the experiments, duplicated responses were identified in both Study 1 and Study 2, with duplicate response rates of 26.25% and 40% respectively. The results of the experiments indicate that ChatGPT can generate responses aligned with the constructs of the Technology Acceptance Model (TAM). The loading and reliability coefficients demonstrate the validity of the models, with Study 1 achieving an R-squared value of 82% and Study 2 achieving 71%. In Study 2, two items with negative wording exhibited low loadings and were subsequently removed from the model. Both studies exhibit reasonable discriminant validity despite high correlations among the TAM constructs. The experiments reveal potential biases in the generated samples, particularly regarding gender and usage experiences. These biases may impact the responses of constructs and should be considered when interpreting ChatGPT's conceptual capabilities. In sum, ChatGPT shows promise as a tool for theory prototyping, generating relevant responses aligned with theoretical constructs. However, further investigation is needed to address limitations such as duplicated responses, variations in prompts, and the generalizability of findings to different contexts. ","[{'version': 'v1', 'created': 'Sun, 4 Jun 2023 23:55:53 GMT'}]",2023-07-13,"[['Goh', 'Tiong-Thye', '']]",1,1,2023-06-04,1,1,2,1,0,1,df999200092d27737eccf2fc897e53dc1bef2239,259836916.0,https://www.semanticscholar.org/paper/df999200092d27737eccf2fc897e53dc1bef2239,arXiv.org,2023.0,21.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '39000252', 'name': 'T. Goh'}]",['Victoria University of Wellington'],['New Zealand'],2023-06
2307.05492,Zachary Robertson,Zachary Robertson,GPT4 is Slightly Helpful for Peer-Review Assistance: A Pilot Study,15 pages,,,,cs.HC cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this pilot study, we investigate the use of GPT4 to assist in the peer-review process. Our key hypothesis was that GPT-generated reviews could achieve comparable helpfulness to human reviewers. By comparing reviews generated by both human reviewers and GPT models for academic papers submitted to a major machine learning conference, we provide initial evidence that artificial intelligence can contribute effectively to the peer-review process. We also perform robustness experiments with inserted errors to understand which parts of the paper the model tends to focus on. Our findings open new avenues for leveraging machine learning tools to address resource constraints in peer review. The results also shed light on potential enhancements to the review process and lay the groundwork for further research on scaling oversight in a domain where human-feedback is increasingly a scarce resource. ","[{'version': 'v1', 'created': 'Fri, 16 Jun 2023 23:11:06 GMT'}]",2023-07-13,"[['Robertson', 'Zachary', '']]",0,1,2023-06-16,1,1,3,1,0,1,9ae09574e5765b7e92c205188dac7c77bd3d001e,259837446.0,https://www.semanticscholar.org/paper/9ae09574e5765b7e92c205188dac7c77bd3d001e,arXiv.org,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1854303398', 'name': 'Zachary Robertson'}]",['Institute of Computer Science'],['Poland'],2023-06
2307.05518,Paolo Burelli,"Thomas Volden, Djordje Grbic, Paolo Burelli",Procedurally generating rules to adapt difficulty for narrative puzzle games,,,,,cs.HC cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  This paper focuses on procedurally generating rules and communicating them to players to adjust the difficulty. This is part of a larger project to collect and adapt games in educational games for young children using a digital puzzle game designed for kindergarten. A genetic algorithm is used together with a difficulty measure to find a target number of solution sets and a large language model is used to communicate the rules in a narrative context. During testing the approach was able to find rules that approximate any given target difficulty within two dozen generations on average. The approach was combined with a large language model to create a narrative puzzle game where players have to host a dinner for animals that can't get along. Future experiments will try to improve evaluation, specialize the language model on children's literature, and collect multi-modal data from players to guide adaptation. ","[{'version': 'v1', 'created': 'Fri, 7 Jul 2023 11:14:53 GMT'}]",2023-07-13,"[['Volden', 'Thomas', ''], ['Grbic', 'Djordje', ''], ['Burelli', 'Paolo', '']]",0,0,2023-07-07,1,3,2,0,0,0,7fc09d86b4cc95ef84f47489b2ebd867aa949133,259837207.0,https://www.semanticscholar.org/paper/7fc09d86b4cc95ef84f47489b2ebd867aa949133,arXiv.org,2023.0,15.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '97977920', 'name': 'T. Volden'}, {'authorId': '49816790', 'name': 'Djordje Grbic'}, {'authorId': '1944718', 'name': 'Paolo Burelli'}]","['University of Copenhagen', 'IT University of Copenhagen']",['Denmark'],2023-07
2307.05574,Edirlei Soares De Lima,"Antonio L. Furtado, Marco A. Casanova, Edirlei Soares de Lima",Some Preliminary Steps Towards Metaverse Logic,,,,,cs.LO cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Assuming that the term 'metaverse' could be understood as a computer-based implementation of multiverse applications, we started to look in the present work for a logic that would be powerful enough to handle the situations arising both in the real and in the fictional underlying application domains. Realizing that first-order logic fails to account for the unstable behavior of even the most simpleminded information system domains, we resorted to non-conventional extensions, in an attempt to sketch a minimal composite logic strategy. The discussion was kept at a rather informal level, always trying to convey the intuition behind the theoretical notions in natural language terms, and appealing to an AI agent, namely ChatGPT, in the hope that algorithmic and common-sense approaches can be usefully combined. ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 09:13:22 GMT'}]",2023-07-13,"[['Furtado', 'Antonio L.', ''], ['Casanova', 'Marco A.', ''], ['de Lima', 'Edirlei Soares', '']]",1,1,2023-07-10,1,3,2,1,0,1,a0fca45e07161f29feec365a3ca447d0adc7f47f,259837167.0,https://www.semanticscholar.org/paper/a0fca45e07161f29feec365a3ca447d0adc7f47f,INTERNAL RESEARCH REPORTS,2018.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1719471', 'name': 'A. Furtado'}, {'authorId': '145771411', 'name': 'M. Casanova'}, {'authorId': '35245740', 'name': 'E. S. D. Lima'}]","['Pontifical Catholic University of Rio de Janeiro', 'Universidade Europeia']","['Portugal', 'Brazil']",2023-07
2307.05646,Dhruv Mullick,"Dhruv Mullick, Bilal Ghanem, Alona Fyshe",Better Handling Coreference Resolution in Aspect Level Sentiment Classification by Fine-Tuning Language Models,Work done up till December 2022,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Customer feedback is invaluable to companies as they refine their products. Monitoring customer feedback can be automated with Aspect Level Sentiment Classification (ALSC) which allows us to analyse specific aspects of the products in reviews. Large Language Models (LLMs) are the heart of many state-of-the-art ALSC solutions, but they perform poorly in some scenarios requiring Coreference Resolution (CR). In this work, we propose a framework to improve an LLM's performance on CR-containing reviews by fine tuning on highly inferential tasks. We show that the performance improvement is likely attributed to the improved model CR ability. We also release a new dataset that focuses on CR in ALSC. ","[{'version': 'v1', 'created': 'Tue, 11 Jul 2023 12:43:28 GMT'}]",2023-07-13,"[['Mullick', 'Dhruv', ''], ['Ghanem', 'Bilal', ''], ['Fyshe', 'Alona', '']]",0,0,2023-07-11,1,3,1,0,0,0,c7c3db89eae487aef6e0024f81022420dd5d26f0,259837058.0,https://www.semanticscholar.org/paper/c7c3db89eae487aef6e0024f81022420dd5d26f0,arXiv.org,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '20602059', 'name': 'Dhruv Mullick'}, {'authorId': '46188821', 'name': 'Bilal Ghanem'}, {'authorId': '2655967', 'name': 'Alona Fyshe'}]",['University of Alberta'],['Canada'],2023-07
2307.05779,Wayne Yang,"Wayne Yang, Garrett Nicolai",Neural Machine Translation Data Generation and Augmentation using ChatGPT,"8 Pages, 4 Figures, 4 Tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Neural models have revolutionized the field of machine translation, but creating parallel corpora is expensive and time-consuming. We investigate an alternative to manual parallel corpora - hallucinated parallel corpora created by generative language models. Although these models are themselves trained on parallel data, they can leverage a multilingual vector space to create data, and may be able to supplement small manually-procured corpora. Our experiments highlight two key findings - despite a lack of diversity in their output, the hallucinated data improves the translation signal, even when the domain clashes with the original dataset. ","[{'version': 'v1', 'created': 'Tue, 11 Jul 2023 20:15:47 GMT'}]",2023-07-13,"[['Yang', 'Wayne', ''], ['Nicolai', 'Garrett', '']]",1,1,2023-07-11,1,2,1,1,0,1,0547b1b984b4051375e4371030731736ea7c44fc,259837429.0,https://www.semanticscholar.org/paper/0547b1b984b4051375e4371030731736ea7c44fc,arXiv.org,2023.0,19.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2223023686', 'name': 'Wayne Yang'}, {'authorId': '40156252', 'name': 'Garrett Nicolai'}]",['University of British Columbia'],['Canada'],2023-07
2307.05909,Hitesh Mohapatra Dr,Hitesh Mohapatra and Soumya Ranjan Mishra,Exploring AI Tool's Versatile Responses: An In-depth Analysis Across Different Industries and Its Performance Evaluation,,,,,cs.HC,http://creativecommons.org/licenses/by/4.0/,"  AI Tool is a large language model (LLM) designed to generate human-like responses in natural language conversations. It is trained on a massive corpus of text from the internet, which allows it to leverage a broad understanding of language, general knowledge, and various domains. AI Tool can provide information, engage in conversations, assist with tasks, and even offer creative suggestions. The underlying technology behind AI Tool is a transformer neural network. Transformers excel at capturing long-range dependencies in text, making them well-suited for language-related tasks. AI Tool has 175 billion parameters, making it one of the largest and most powerful LLMs to date. This work presents an overview of AI Tool's responses on various sectors of industry. Further, the responses of AI Tool have been cross-verified with human experts in the corresponding fields. To validate the performance of AI Tool, a few explicit parameters have been considered and the evaluation has been done. This study will help the research community and other users to understand the uses of AI Tool and its interaction pattern. The results of this study show that AI Tool is able to generate human-like responses that are both informative and engaging. However, it is important to note that AI Tool can occasionally produce incorrect or nonsensical answers. It is therefore important to critically evaluate the information that AI Tool provides and to verify it from reliable sources when necessary. Overall, this study suggests that AI Tool is a promising new tool for natural language processing, and that it has the potential to be used in a wide variety of applications. ","[{'version': 'v1', 'created': 'Wed, 12 Jul 2023 04:31:34 GMT'}, {'version': 'v2', 'created': 'Mon, 21 Aug 2023 06:44:40 GMT'}]",2023-08-22,"[['Mohapatra', 'Hitesh', ''], ['Mishra', 'Soumya Ranjan', '']]",0,0,2023-07-12,2,2,1,0,0,0,d88c9134473afffa898a48e6ab1b588505f3a1b4,261046922.0,https://www.semanticscholar.org/paper/d88c9134473afffa898a48e6ab1b588505f3a1b4,,2023.0,36.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '80896788', 'name': 'Hitesh Mohapatra'}, {'authorId': '2109483428', 'name': 'S. Mishra'}]","['School of Computer Engineering, KIIT (Deemed to be) University, Bhubaneswar -751024, Odisha,India']",['India'],2023-07
2307.06187,Nathalia Nascimento,"Nathalia Nascimento, Paulo Alencar, Donald Cowan",Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems,"6 pages, submitted",,,,cs.MA cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In autonomic computing, self-adaptation has been proposed as a fundamental paradigm to manage the complexity of multiagent systems (MASs). This achieved by extending a system with support to monitor and adapt itself to achieve specific concerns of interest. Communication in these systems is key given that in scenarios involving agent interaction, it enhances cooperation and reduces coordination challenges by enabling direct, clear information exchange. However, improving the expressiveness of the interaction communication with MASs is not without challenges. In this sense, the interplay between self-adaptive systems and effective communication is crucial for future MAS advancements. In this paper, we propose the integration of large language models (LLMs) such as GPT-based technologies into multiagent systems. We anchor our methodology on the MAPE-K model, which is renowned for its robust support in monitoring, analyzing, planning, and executing system adaptations in response to dynamic environments. We also present a practical illustration of the proposed approach, in which we implement and assess a basic MAS-based application. The approach significantly advances the state-of-the-art of self-adaptive systems by proposing a new paradigm for MAS self-adaptation of autonomous systems based on LLM capabilities. ","[{'version': 'v1', 'created': 'Wed, 12 Jul 2023 14:26:46 GMT'}]",2023-07-13,"[['Nascimento', 'Nathalia', ''], ['Alencar', 'Paulo', ''], ['Cowan', 'Donald', '']]",0,1,2023-07-12,1,3,3,0,0,0,1f9822022f586e375461660db792f23e891c7123,259836864.0,https://www.semanticscholar.org/paper/1f9822022f586e375461660db792f23e891c7123,arXiv.org,2023.0,19.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2658311', 'name': 'N. Nascimento'}, {'authorId': '40761174', 'name': 'Paulo Alencar'}, {'authorId': '2149928782', 'name': 'Donald D. Cowan'}]",['University of Waterloo'],['Canada'],2023-07
2307.06439,Yu Gu,"Yu Gu, Sheng Zhang, Naoto Usuyama, Yonas Woldesenbet, Cliff Wong,
  Praneeth Sanapathi, Mu Wei, Naveen Valluri, Erika Strandberg, Tristan
  Naumann, Hoifung Poon",Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs), such as GPT-4, have demonstrated remarkable capabilities across a wide range of tasks, including health applications. In this paper, we study how LLMs can be used to scale biomedical knowledge curation. We find that while LLMs already possess decent competency in structuring biomedical text, by distillation into a task-specific student model through self-supervised learning, substantial gains can be attained over out-of-box LLMs, with additional advantages such as cost, efficiency, and white-box model access.   We conduct a case study on adverse drug event (ADE) extraction, which is an important area for improving care. On standard ADE extraction evaluation, a GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised state-of-the-art models without using any labeled data. Despite being over 1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by over 6 absolute points in F1 and GPT-4 by over 5 absolute points.   Ablation studies on distillation model choice (e.g., PubMedBERT vs BioGPT) and ADE extraction architecture shed light on best practice for biomedical knowledge extraction. Similar gains were attained by distillation for other standard biomedical knowledge extraction tasks such as gene-disease associations and protected health information, further illustrating the promise of this approach. ","[{'version': 'v1', 'created': 'Wed, 12 Jul 2023 20:08:48 GMT'}]",2023-07-14,"[['Gu', 'Yu', ''], ['Zhang', 'Sheng', ''], ['Usuyama', 'Naoto', ''], ['Woldesenbet', 'Yonas', ''], ['Wong', 'Cliff', ''], ['Sanapathi', 'Praneeth', ''], ['Wei', 'Mu', ''], ['Valluri', 'Naveen', ''], ['Strandberg', 'Erika', ''], ['Naumann', 'Tristan', ''], ['Poon', 'Hoifung', '']]",0,1,2023-07-12,1,11,2,2,0,2,6c12769939dd75bd681d37ea17cce7e6a57f5c6e,259847622.0,https://www.semanticscholar.org/paper/6c12769939dd75bd681d37ea17cce7e6a57f5c6e,arXiv.org,2023.0,25.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112677245', 'name': 'Yu Gu'}, {'authorId': '41209309', 'name': 'Sheng Zhang'}, {'authorId': '2637252', 'name': 'Naoto Usuyama'}, {'authorId': '3310870', 'name': 'Yonas G. Woldesenbet'}, {'authorId': '2109566188', 'name': 'Cliff Wong'}, {'authorId': '2223542076', 'name': 'Praneeth Sanapathi'}, {'authorId': '2072847758', 'name': 'Mu-Hsin Wei'}, {'authorId': '48269128', 'name': 'Naveen Valluri'}, {'authorId': '35009788', 'name': 'Erika Strandberg'}, {'authorId': '40466858', 'name': 'Tristan Naumann'}, {'authorId': '1759772', 'name': 'Hoifung Poon'}]",['Microsoft'],['India'],2023-07
2307.06464,Istvan David,"Eugene Syriani, Istvan David, Gauransh Kumar",Assessing the Ability of ChatGPT to Screen Articles for Systematic Reviews,,,,,cs.SE cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  By organizing knowledge within a research field, Systematic Reviews (SR) provide valuable leads to steer research. Evidence suggests that SRs have become first-class artifacts in software engineering. However, the tedious manual effort associated with the screening phase of SRs renders these studies a costly and error-prone endeavor. While screening has traditionally been considered not amenable to automation, the advent of generative AI-driven chatbots, backed with large language models is set to disrupt the field. In this report, we propose an approach to leverage these novel technological developments for automating the screening of SRs. We assess the consistency, classification performance, and generalizability of ChatGPT in screening articles for SRs and compare these figures with those of traditional classifiers used in SR automation. Our results indicate that ChatGPT is a viable option to automate the SR processes, but requires careful considerations from developers when integrating ChatGPT into their SR tools. ","[{'version': 'v1', 'created': 'Wed, 12 Jul 2023 21:39:42 GMT'}]",2023-07-14,"[['Syriani', 'Eugene', ''], ['David', 'Istvan', ''], ['Kumar', 'Gauransh', '']]",1,1,2023-07-12,1,3,3,1,0,1,4c652efea036960b1ef47a245a08ec97e3ef3abb,259847392.0,https://www.semanticscholar.org/paper/4c652efea036960b1ef47a245a08ec97e3ef3abb,arXiv.org,2023.0,63.0,3.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2873716', 'name': 'Eugene Syriani'}, {'authorId': '144729797', 'name': 'István Dávid'}, {'authorId': '2223406825', 'name': 'Gauransh Kumar'}]",['Université de Montréal'],['Canada'],2023-07
2307.06616,Mohamed Amine Ferrag,"Mohamed Amine Ferrag, Ammar Battah, Norbert Tihanyi, Merouane Debbah,
  Thierry Lestable, Lucas C. Cordeiro",SecureFalcon: The Next Cyber Reasoning System for Cyber Security,,,,,cs.CR cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Software vulnerabilities leading to various detriments such as crashes, data loss, and security breaches, significantly hinder the quality, affecting the market adoption of software applications and systems. Although traditional methods such as automated software testing, fault localization, and repair have been intensively studied, static analysis tools are most commonly used and have an inherent false positives rate, posing a solid challenge to developer productivity. Large Language Models (LLMs) offer a promising solution to these persistent issues. Among these, FalconLLM has shown substantial potential in identifying intricate patterns and complex vulnerabilities, hence crucial in software vulnerability detection. In this paper, for the first time, FalconLLM is being fine-tuned for cybersecurity applications, thus introducing SecureFalcon, an innovative model architecture built upon FalconLLM. SecureFalcon is trained to differentiate between vulnerable and non-vulnerable C code samples. We build a new training dataset, FormAI, constructed thanks to Generative Artificial Intelligence (AI) and formal verification to evaluate its performance. SecureFalcon achieved an impressive 94% accuracy rate in detecting software vulnerabilities, emphasizing its significant potential to redefine software vulnerability detection methods in cybersecurity. ","[{'version': 'v1', 'created': 'Thu, 13 Jul 2023 08:34:09 GMT'}]",2023-07-14,"[['Ferrag', 'Mohamed Amine', ''], ['Battah', 'Ammar', ''], ['Tihanyi', 'Norbert', ''], ['Debbah', 'Merouane', ''], ['Lestable', 'Thierry', ''], ['Cordeiro', 'Lucas C.', '']]",0,0,2023-07-13,1,6,2,0,0,0,42029832864c30c42a77538939f176f572b324a6,259847202.0,https://www.semanticscholar.org/paper/42029832864c30c42a77538939f176f572b324a6,arXiv.org,2023.0,39.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2864573', 'name': 'M. Ferrag'}, {'authorId': '1574150859', 'name': 'A. Battah'}, {'authorId': '2752349', 'name': 'Norbert Tihanyi'}, {'authorId': '2065834880', 'name': 'M. Debbah'}, {'authorId': '2266737', 'name': 'T. Lestable'}, {'authorId': '144040212', 'name': 'L. Cordeiro'}]","['University of Manchester', 'Khalifa University of Science and Technology', 'Technology Innovation Institute']","['United Kingdom', 'United Arab Emirates']",2023-07
2307.06713,Lautaro Estienne,"Lautaro Estienne, Luciana Ferrer, Mat\'ias Vera, Pablo Piantanida",Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  A wide variety of natural language tasks are currently being addressed with large-scale language models (LLMs). These models are usually trained with a very large amount of unsupervised text data and adapted to perform a downstream natural language task using methods like fine-tuning, calibration or in-context learning. In this work, we propose an approach to adapt the prior class distribution to perform text classification tasks without the need for labelled samples and only few in-domain sample queries. The proposed approach treats the LLM as a black box, adding a stage where the model posteriors are calibrated to the task. Results show that these methods outperform the un-adapted model for different number of training shots in the prompt and a previous approach were calibration is performed without using any adaptation data. ","[{'version': 'v1', 'created': 'Thu, 13 Jul 2023 12:11:36 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Aug 2023 16:21:49 GMT'}, {'version': 'v3', 'created': 'Wed, 9 Aug 2023 07:40:43 GMT'}]",2023-08-10,"[['Estienne', 'Lautaro', ''], ['Ferrer', 'Luciana', ''], ['Vera', 'Matías', ''], ['Piantanida', 'Pablo', '']]",0,0,2023-07-13,3,4,2,0,0,0,ea8067ee6c3923b259bda0a07d3001e18c2d97bf,259847422.0,https://www.semanticscholar.org/paper/ea8067ee6c3923b259bda0a07d3001e18c2d97bf,Recent Advances in Natural Language Processing,2023.0,35.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2147166593', 'name': 'Lautaro Estienne'}]","['Consejo Nacional de Investigaciones Científicas y Técnicas', 'University of Buenos Aires', 'University of Paris-Saclay', 'Institute of Astronomy and Space Physics']","['Argentina', 'France']",2023-07
2307.06794,Navid Rezaei,"Navid Rezaei, Marek Z. Reformat",Negated Complementary Commonsense using Large Language Models,"Appeared in Natural Language Reasoning and Structured Explanations
  Workshop (NLRSE) - ACL 2023",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Larger language models, such as GPT-3, have shown to be excellent in many tasks. However, we demonstrate that out-of-ordinary questions can throw the model off guard. This work focuses on finding answers to negated complementary questions in commonsense scenarios. We illustrate how such questions adversely affect the model responses. We propose a model-agnostic methodology to improve the performance in negated complementary scenarios. Our method outperforms few-shot generation from GPT-3 (by more than 11 points) and, more importantly, highlights the significance of studying the response of large language models in negated complementary questions. The code, data, and experiments are available under: https://github.com/navidre/negated_complementary_commonsense. ","[{'version': 'v1', 'created': 'Thu, 13 Jul 2023 15:03:48 GMT'}]",2023-07-14,"[['Rezaei', 'Navid', ''], ['Reformat', 'Marek Z.', '']]",0,1,2023-07-13,1,2,2,1,0,1,82232e09d629235e62f6163c813cbebefad1807c,259847451.0,https://www.semanticscholar.org/paper/82232e09d629235e62f6163c813cbebefad1807c,arXiv.org,2023.0,16.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2163521043', 'name': 'Navid Rezaei'}, {'authorId': '1742322', 'name': 'M. Reformat'}]","['Społeczna Akademia Nauk', 'University of Alberta']","['Canada', 'Poland']",2023-07
2307.06844,Anj Simmons,"Anj Simmons, Rajesh Vasa","Garbage in, garbage out: Zero-shot detection of crime using Large Language Models","5 pages, 4 figures, 1 table",,,,cs.CL cs.AI cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper proposes exploiting the common sense knowledge learned by large language models to perform zero-shot reasoning about crimes given textual descriptions of surveillance videos. We show that when video is (manually) converted to high quality textual descriptions, large language models are capable of detecting and classifying crimes with state-of-the-art performance using only zero-shot reasoning. However, existing automated video-to-text approaches are unable to generate video descriptions of sufficient quality to support reasoning (garbage video descriptions into the large language model, garbage out). ","[{'version': 'v1', 'created': 'Tue, 4 Jul 2023 01:29:15 GMT'}]",2023-07-14,"[['Simmons', 'Anj', ''], ['Vasa', 'Rajesh', '']]",0,0,2023-07-04,1,2,3,0,0,0,043fc7127099cbacb0d97f34c16e0e9869e817f3,259847413.0,https://www.semanticscholar.org/paper/043fc7127099cbacb0d97f34c16e0e9869e817f3,arXiv.org,2023.0,10.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2155271803', 'name': 'Anj Simmons'}, {'authorId': '33402434', 'name': 'Rajesh Vasa'}]",['Deakin University'],['Australia'],2023-07
2307.06917,Lars-Peter Meyer,"Lars-Peter Meyer, Claus Stadler, Johannes Frey, Norman Radtke, Kurt
  Junghanns, Roy Meissner, Gordian Dziwis, Kirill Bulert, Michael Martin",LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT,"to appear in conference proceedings of AI-Tomorrow-23, 29.+30.6.2023
  in Leipzig, Germany",,,,cs.AI cs.CL cs.DB,http://creativecommons.org/licenses/by/4.0/,"  Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines. KGs surpass any other form of representation in terms of effectiveness. However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices. It also demands a significant amount of work. Considering the advancements in large language models (LLMs) and their interfaces and applications in recent years, we have conducted comprehensive experiments with ChatGPT to explore its potential in supporting KGE. In this paper, we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs. ","[{'version': 'v1', 'created': 'Thu, 13 Jul 2023 17:31:41 GMT'}]",2023-07-14,"[['Meyer', 'Lars-Peter', ''], ['Stadler', 'Claus', ''], ['Frey', 'Johannes', ''], ['Radtke', 'Norman', ''], ['Junghanns', 'Kurt', ''], ['Meissner', 'Roy', ''], ['Dziwis', 'Gordian', ''], ['Bulert', 'Kirill', ''], ['Martin', 'Michael', '']]",1,1,2023-07-13,1,9,3,1,0,1,b0272a6f542d2dd0809e29caf97f2cd72793cad7,259847255.0,https://www.semanticscholar.org/paper/b0272a6f542d2dd0809e29caf97f2cd72793cad7,arXiv.org,2023.0,8.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145243956', 'name': 'Lars Meyer'}, {'authorId': '2390605', 'name': 'Claus Stadler'}, {'authorId': '32114346', 'name': 'Johannes Frey'}, {'authorId': '2096905450', 'name': 'Norman Radtke'}, {'authorId': '48555227', 'name': 'K. Junghanns'}, {'authorId': '36476994', 'name': 'R. Meissner'}, {'authorId': '2212030380', 'name': 'Gordian Dziwis'}, {'authorId': '2108312', 'name': 'Kirill Bulert'}, {'authorId': '2110607609', 'name': 'Michael Martin'}]","['Institut für Biomedizinische Analytik und NMR Imaging (Germany)', 'Leipzig University']",['Germany'],2023-07
2307.06985,L. Siddharth Mr,"L Siddharth, Jianxi Luo",Towards Populating Generalizable Engineering Design Knowledge,,,,,cs.CL cs.DB cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Aiming to populate generalizable engineering design knowledge, we propose a method to extract facts of the form <head entity, relationship, tail entity> from sentences found in patent documents. These facts could be combined within and across patent documents to form knowledge graphs that serve as schemes for representing as well as storing design knowledge. Existing methods in engineering design literature often utilise a set of predefined relationships to populate triples that are statistical approximations rather than facts. In our method, we train a tagger to identify both entities and relationships from a sentence. Given a pair of entities, we train another tagger to identify the specific relationship tokens. For training these taggers, we manually construct a dataset of 44,227 sentences and corresponding facts. We benchmark our method against two typically recommended approaches. We apply our method by extracting facts from sentences found in patents related to fan systems. We build a knowledge base using these facts to demonstrate how domain ontologies could be constructed and contextualised knowledge of subsystems could be visualised. We then search the knowledge base for key issues prevailing in fan systems. We organize the responses into knowledge graphs and hold a comparative discussion against the opinions about the key issues from ChatGPT. ","[{'version': 'v1', 'created': 'Thu, 13 Jul 2023 17:25:28 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Sep 2023 21:10:14 GMT'}]",2023-09-20,"[['Siddharth', 'L', ''], ['Luo', 'Jianxi', '']]",1,1,2023-07-13,2,2,3,1,0,1,524cc6783be04906d26183530c0e155384ec6217,259924838.0,https://www.semanticscholar.org/paper/524cc6783be04906d26183530c0e155384ec6217,arXiv.org,2023.0,66.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51471694', 'name': 'L. Siddharth'}, {'authorId': '145990580', 'name': 'Jianxi Luo'}]",['Singapore University of Technology and Design'],['Singapore'],2023-07
2307.07047,Bo-Ru Lu,"Bo-Ru Lu, Nikita Haduong, Chia-Hsuan Lee, Zeqiu Wu, Hao Cheng, Paul
  Koester, Jean Utke, Tao Yu, Noah A. Smith, Mari Ostendorf",DIALGEN: Collaborative Human-LM Generated Dialogues for Improved Understanding of Human-Human Conversations,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Applications that could benefit from automatic understanding of human-human conversations often come with challenges associated with private information in real-world data such as call center or clinical conversations. Working with protected data also increases costs of annotation, which limits technology development. To address these challenges, we propose DIALGEN, a human-in-the-loop semi-automated dialogue generation framework. DIALGEN uses a language model (ChatGPT) that can follow schema and style specifications to produce fluent conversational text, generating a complex conversation through iteratively generating subdialogues and using human feedback to correct inconsistencies or redirect the flow. In experiments on structured summarization of agent-client information gathering calls, framed as dialogue state tracking, we show that DIALGEN data enables significant improvement in model performance. ","[{'version': 'v1', 'created': 'Thu, 13 Jul 2023 20:02:50 GMT'}]",2023-07-17,"[['Lu', 'Bo-Ru', ''], ['Haduong', 'Nikita', ''], ['Lee', 'Chia-Hsuan', ''], ['Wu', 'Zeqiu', ''], ['Cheng', 'Hao', ''], ['Koester', 'Paul', ''], ['Utke', 'Jean', ''], ['Yu', 'Tao', ''], ['Smith', 'Noah A.', ''], ['Ostendorf', 'Mari', '']]",1,1,2023-07-13,1,10,1,1,0,1,b4c761620e28a340397e937b7460f3fe4985cd8c,259924704.0,https://www.semanticscholar.org/paper/b4c761620e28a340397e937b7460f3fe4985cd8c,arXiv.org,2023.0,96.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2150794720', 'name': 'Bo-Ru Lu'}, {'authorId': '3465456', 'name': 'Nikita Haduong'}, {'authorId': '2115642672', 'name': 'Chia-Hsuan Lee'}, {'authorId': '7806955', 'name': 'Zeqiu Wu'}, {'authorId': '145242715', 'name': 'Hao Cheng'}, {'authorId': '2223553043', 'name': 'Paul Koester'}, {'authorId': '2711744', 'name': 'J. Utke'}, {'authorId': '2117900202', 'name': 'Tao Yu'}, {'authorId': '144365876', 'name': 'Noah A. Smith'}, {'authorId': '144339506', 'name': 'Mari Ostendorf'}]",['University of Hong Kong'],['Hong Kong'],2023-07
2307.07312,Agnes Axelsson,Agnes Axelsson and Gabriel Skantze,Using Large Language Models for Zero-Shot Natural Language Generation from Knowledge Graphs,"9 pages, 3 pages appendices, 1 figure, 4 tables (incl. appendices)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In any system that uses structured knowledge graph (KG) data as its underlying knowledge representation, KG-to-text generation is a useful tool for turning parts of the graph data into text that can be understood by humans. Recent work has shown that models that make use of pretraining on large amounts of text data can perform well on the KG-to-text task even with relatively small sets of training data on the specific graph-to-text task. In this paper, we build on this concept by using large language models to perform zero-shot generation based on nothing but the model's understanding of the triple structure from what it can read. We show that ChatGPT achieves near state-of-the-art performance on some measures of the WebNLG 2020 challenge, but falls behind on others. Additionally, we compare factual, counter-factual and fictional statements, and show that there is a significant connection between what the LLM already knows about the data it is parsing and the quality of the output text. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 12:45:03 GMT'}, {'version': 'v2', 'created': 'Tue, 22 Aug 2023 14:10:19 GMT'}]",2023-08-23,"[['Axelsson', 'Agnes', ''], ['Skantze', 'Gabriel', '']]",1,1,2023-07-14,2,2,1,1,0,1,31c87314bff4e79ce2a0082a8001f4a9f720482b,259924559.0,https://www.semanticscholar.org/paper/31c87314bff4e79ce2a0082a8001f4a9f720482b,MMNLG,2023.0,61.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2136655033', 'name': 'Agnes Axelsson'}, {'authorId': '103081544', 'name': 'G. Skantze'}]","['KTH Royal Institute of Technology', 'Division of Speech, Music and Hearing (TMH) / Lindstedtsvägen']",['Sweden'],2023-07
2307.07331,Matthias A{\ss}enmacher,"Ibrahim Tolga \""Ozt\""urk and Rostislav Nedelchev and Christian Heumann
  and Esteban Garces Arias and Marius Roger and Bernd Bischl and Matthias
  A{\ss}enmacher",How Different Is Stereotypical Bias Across Languages?,"Accepted @ ""3rd Workshop on Bias and Fairness in AI"" (co-located with
  ECML PKDD 2023). This is the author's version of the work. The definite
  version of record will be published in the proceedings",,,,cs.CL cs.CY cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  Recent studies have demonstrated how to assess the stereotypical bias in pre-trained English language models. In this work, we extend this branch of research in multiple different dimensions by systematically investigating (a) mono- and multilingual models of (b) different underlying architectures with respect to their bias in (c) multiple different languages. To that end, we make use of the English StereoSet data set (Nadeem et al., 2021), which we semi-automatically translate into German, French, Spanish, and Turkish. We find that it is of major importance to conduct this type of analysis in a multilingual setting, as our experiments show a much more nuanced picture as well as notable differences from the English-only analysis. The main takeaways from our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical behavior across languages, English (monolingual) models exhibit the strongest bias, and the stereotypes reflected in the data set are least present in Turkish models. Finally, we release our codebase alongside the translated data sets and practical guidelines for the semi-automatic translation to encourage a further extension of our work to other languages. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 13:17:11 GMT'}]",2023-07-17,"[['Öztürk', 'Ibrahim Tolga', ''], ['Nedelchev', 'Rostislav', ''], ['Heumann', 'Christian', ''], ['Arias', 'Esteban Garces', ''], ['Roger', 'Marius', ''], ['Bischl', 'Bernd', ''], ['Aßenmacher', 'Matthias', '']]",0,1,2023-07-14,1,7,4,0,0,0,95c08573427cdc23454b35271f7438622d9d394a,259924852.0,https://www.semanticscholar.org/paper/95c08573427cdc23454b35271f7438622d9d394a,arXiv.org,2023.0,30.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2223541879', 'name': 'Ibrahim Tolga Ozturk'}, {'authorId': '52220722', 'name': 'R. Nedelchev'}, {'authorId': '2316681', 'name': 'C. Heumann'}, {'authorId': '2223542126', 'name': 'Esteban Garces Arias'}, {'authorId': '2223542046', 'name': 'Marius Roger'}, {'authorId': '2133449619', 'name': 'Bernd Bischl'}, {'authorId': '7809845', 'name': 'M. Aßenmacher'}]","['Ludwig-Maximilians-Universität München', 'University of Bonn']",['Germany'],2023-07
2307.07341,Zixin Guo,"Zixin Guo, Tzu-Jui Julius Wang, Selen Pehlivan, Abduljalil Radman,
  Jorma Laaksonen",PiTL: Cross-modal Retrieval with Weakly-supervised Vision-language Pre-training via Prompting,,"SIGIR, 2023, 2261-2265",10.1145/3539618.3592038,,cs.IR cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Vision-language (VL) Pre-training (VLP) has shown to well generalize VL models over a wide range of VL downstream tasks, especially for cross-modal retrieval. However, it hinges on a huge amount of image-text pairs, which requires tedious and costly curation. On the contrary, weakly-supervised VLP (W-VLP) explores means with object tags generated by a pre-trained object detector (OD) from images. Yet, they still require paired information, i.e. images and object-level annotations, as supervision to train an OD.   To further reduce the amount of supervision, we propose Prompts-in-The-Loop (PiTL) that prompts knowledge from large language models (LLMs) to describe images. Concretely, given a category label of an image, e.g. refinery, the knowledge, e.g. a refinery could be seen with large storage tanks, pipework, and ..., extracted by LLMs is used as the language counterpart. The knowledge supplements, e.g. the common relations among entities most likely appearing in a scene. We create IN14K, a new VL dataset of 9M images and 1M descriptions of 14K categories from ImageNet21K with PiTL. Empirically, the VL models pre-trained with PiTL-generated pairs are strongly favored over other W-VLP works on image-to-text (I2T) and text-to-image (T2I) retrieval tasks, with less supervision. The results reveal the effectiveness of PiTL-generated pairs for VLP. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 13:43:04 GMT'}]",2023-07-20,"[['Guo', 'Zixin', ''], ['Wang', 'Tzu-Jui Julius', ''], ['Pehlivan', 'Selen', ''], ['Radman', 'Abduljalil', ''], ['Laaksonen', 'Jorma', '']]",0,0,2023-07-14,1,5,2,0,0,0,177bf0086a714ff305e45b720cda82e992c9fc7c,259924511.0,https://www.semanticscholar.org/paper/177bf0086a714ff305e45b720cda82e992c9fc7c,Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112226054', 'name': 'Zixin Guo'}, {'authorId': '3461751', 'name': 'T. Wang'}, {'authorId': '39173237', 'name': 'Selen Pehlivan'}, {'authorId': '47547144', 'name': 'Abduljalil Radman'}, {'authorId': '144376259', 'name': 'J. Laaksonen'}]",['Aalto University'],['Finland'],2023-07
2307.07367,Johannes Wachs,"Maria del Rio-Chanona, Nadzeya Laurentsyeva, Johannes Wachs",Are Large Language Models a Threat to Digital Public Goods? Evidence from Activity on Stack Overflow,,,,,cs.SI cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Large language models like ChatGPT efficiently provide users with information about various topics, presenting a potential substitute for searching the web and asking people for help online. But since users interact privately with the model, these models may drastically reduce the amount of publicly available human-generated data and knowledge resources. This substitution can present a significant problem in securing training data for future models. In this work, we investigate how the release of ChatGPT changed human-generated open data on the web by analyzing the activity on Stack Overflow, the leading online Q\&A platform for computer programming. We find that relative to its Russian and Chinese counterparts, where access to ChatGPT is limited, and to similar forums for mathematics, where ChatGPT is less capable, activity on Stack Overflow significantly decreased. A difference-in-differences model estimates a 16\% decrease in weekly posts on Stack Overflow. This effect increases in magnitude over time, and is larger for posts related to the most widely used programming languages. Posts made after ChatGPT get similar voting scores than before, suggesting that ChatGPT is not merely displacing duplicate or low-quality content. These results suggest that more users are adopting large language models to answer questions and they are better substitutes for Stack Overflow for languages for which they have more training data. Using models like ChatGPT may be more efficient for solving certain programming problems, but its widespread adoption and the resulting shift away from public exchange on the web will limit the open data people and models can learn from in the future. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 14:22:12 GMT'}]",2023-07-17,"[['del Rio-Chanona', 'Maria', ''], ['Laurentsyeva', 'Nadzeya', ''], ['Wachs', 'Johannes', '']]",1,1,2023-07-14,1,3,3,1,0,1,567dd229e4dbb24d5cca06b81cf132824b97d599,259924483.0,https://www.semanticscholar.org/paper/567dd229e4dbb24d5cca06b81cf132824b97d599,arXiv.org,2023.0,50.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2223594545', 'name': 'Maria del Rio-Chanona'}, {'authorId': '118406147', 'name': 'Nadzeya Laurentsyeva'}, {'authorId': '39963117', 'name': 'Johannes Wachs'}]","['Ludwig-Maximilians-Universität München', 'Corvinus University of Budapest', 'Centre for Economic and Regional Studies', 'Harvard Kennedy School', 'Complexity Science Hub Vienna']","['Germany', 'Austria', 'Hungary']",2023-07
2307.07381,Krishna Ronanki,"Krishna Ronanki, Christian Berger, Jennifer Horkoff",Investigating ChatGPT's Potential to Assist in Requirements Elicitation Processes,"Accepted at SEAA 2023. 8 pages, 5 figures",,,,cs.SE,http://creativecommons.org/licenses/by-sa/4.0/,"  Natural Language Processing (NLP) for Requirements Engineering (RE) (NLP4RE) seeks to apply NLP tools, techniques, and resources to the RE process to increase the quality of the requirements. There is little research involving the utilization of Generative AI-based NLP tools and techniques for requirements elicitation. In recent times, Large Language Models (LLM) like ChatGPT have gained significant recognition due to their notably improved performance in NLP tasks. To explore the potential of ChatGPT to assist in requirements elicitation processes, we formulated six questions to elicit requirements using ChatGPT. Using the same six questions, we conducted interview-based surveys with five RE experts from academia and industry and collected 30 responses containing requirements. The quality of these 36 responses (human-formulated + ChatGPT-generated) was evaluated over seven different requirements quality attributes by another five RE experts through a second round of interview-based surveys. In comparing the quality of requirements generated by ChatGPT with those formulated by human experts, we found that ChatGPT-generated requirements are highly Abstract, Atomic, Consistent, Correct, and Understandable. Based on these results, we present the most pressing issues related to LLMs and what future research should focus on to leverage the emergent behaviour of LLMs more effectively in natural language-based RE activities. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 14:45:36 GMT'}]",2023-07-17,"[['Ronanki', 'Krishna', ''], ['Berger', 'Christian', ''], ['Horkoff', 'Jennifer', '']]",1,1,2023-07-14,1,3,1,1,0,1,37d7fd90943b76657ff88d030a9d28677914160f,259924649.0,https://www.semanticscholar.org/paper/37d7fd90943b76657ff88d030a9d28677914160f,arXiv.org,2023.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2219554412', 'name': 'Krishna Ronanki'}, {'authorId': '2220345997', 'name': 'Christian Berger'}, {'authorId': '1790567', 'name': 'Jennifer Horkoff'}]",['University of Gothenburg'],['Sweden'],2023-07
2307.07411,Michael Liut,"Michael Sheinman Orenstrakh, Oscar Karnalim, Carlos Anibal Suarez,
  Michael Liut",Detecting LLM-Generated Text in Computing Education: A Comparative Study for ChatGPT Cases,"18 pages total (16 pages, 2 reference pages). In submission",,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Due to the recent improvements and wide availability of Large Language Models (LLMs), they have posed a serious threat to academic integrity in education. Modern LLM-generated text detectors attempt to combat the problem by offering educators with services to assess whether some text is LLM-generated. In this work, we have collected 124 submissions from computer science students before the creation of ChatGPT. We then generated 40 ChatGPT submissions. We used this data to evaluate eight publicly-available LLM-generated text detectors through the measures of accuracy, false positives, and resilience. The purpose of this work is to inform the community of what LLM-generated text detectors work and which do not, but also to provide insights for educators to better maintain academic integrity in their courses. Our results find that CopyLeaks is the most accurate LLM-generated text detector, GPTKit is the best LLM-generated text detector to reduce false positives, and GLTR is the most resilient LLM-generated text detector. We also express concerns over 52 false positives (of 114 human written submissions) generated by GPTZero. Finally, we note that all LLM-generated text detectors are less accurate with code, other languages (aside from English), and after the use of paraphrasing tools (like QuillBot). Modern detectors are still in need of improvements so that they can offer a full-proof solution to help maintain academic integrity. Further, their usability can be improved by facilitating a smooth API integration, providing clear documentation of their features and the understandability of their model(s), and supporting more commonly used languages. ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 12:18:34 GMT'}]",2023-07-17,"[['Orenstrakh', 'Michael Sheinman', ''], ['Karnalim', 'Oscar', ''], ['Suarez', 'Carlos Anibal', ''], ['Liut', 'Michael', '']]",1,1,2023-07-10,1,4,2,1,0,1,be383c607d4d357c763d2329ab71799c6e1393b4,259924631.0,https://www.semanticscholar.org/paper/be383c607d4d357c763d2329ab71799c6e1393b4,arXiv.org,2023.0,55.0,5.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2223551699', 'name': 'Michael Sheinman Orenstrakh'}, {'authorId': '8722618', 'name': 'Oscar Karnalim'}, {'authorId': '153842213', 'name': 'C. Suárez'}, {'authorId': '1397294204', 'name': 'Michael Liut'}]","['University of Toronto', 'Maranatha Christian University', 'Escuela Superior Politecnica del Litoral']","['Canada', 'Indonesia', 'Ecuador']",2023-07
2307.07889,Adian Liusie,"Adian Liusie, Potsawee Manakul, Mark J. F. Gales",LLM Comparative Assessment: Zero-shot NLG Evaluation through Pairwise Comparisons using Large Language Models,12 pages,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Current developments in large language models (LLMs) have enabled impressive zero-shot capabilities across various natural language tasks. An interesting application of these systems is in the automated assessment of natural language generation (NLG), a highly challenging area with great practical benefit. In this paper, we explore two options for exploiting the emergent abilities of LLMs for zero-shot NLG assessment: absolute score prediction, and comparative assessment which uses relative comparisons between pairs of candidates. Though comparative assessment has not been extensively studied in NLG assessment, we note that humans often find it more intuitive to compare two options rather than scoring each one independently. This work examines comparative assessment from multiple perspectives: performance compared to absolute grading; positional biases in the prompt; and efficient ranking in terms of the number of comparisons. We illustrate that LLM comparative assessment is a simple, general and effective approach for NLG assessment. For moderate-sized open-source LLMs, such as FlanT5 and Llama2-chat, comparative assessment is superior to prompt scoring, and in many cases can achieve performance competitive with state-of-the-art methods. Additionally, we demonstrate that LLMs often exhibit strong positional biases when making pairwise comparisons, and we propose debiasing methods that can further improve performance. ","[{'version': 'v1', 'created': 'Sat, 15 Jul 2023 22:02:12 GMT'}, {'version': 'v2', 'created': 'Wed, 16 Aug 2023 14:55:35 GMT'}]",2023-08-17,"[['Liusie', 'Adian', ''], ['Manakul', 'Potsawee', ''], ['Gales', 'Mark J. F.', '']]",0,0,2023-07-15,2,3,1,0,0,0,c6f1fa0228eecfcd0a83b601a7f0fbf5b55b3368,259937561.0,https://www.semanticscholar.org/paper/c6f1fa0228eecfcd0a83b601a7f0fbf5b55b3368,,2023.0,34.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2190750613', 'name': 'Adian Liusie'}, {'authorId': '89355510', 'name': 'Potsawee Manakul'}, {'authorId': '1740397', 'name': 'M. Gales'}]",['University of Cambridge'],['United Kingdom'],2023-07
2307.08225,Shuhao Zhang,"Shuhao Zhang, Xianzhi Zeng, Yuhao Wu, Zhonghao Yang",Harnessing Scalable Transactional Stream Processing for Managing Large Language Models [Vision],,,,,cs.DB cs.AI cs.DC,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have demonstrated extraordinary performance across a broad array of applications, from traditional language processing tasks to interpreting structured sequences like time-series data. Yet, their effectiveness in fast-paced, online decision-making environments requiring swift, accurate, and concurrent responses poses a significant challenge. This paper introduces TStreamLLM, a revolutionary framework integrating Transactional Stream Processing (TSP) with LLM management to achieve remarkable scalability and low latency. By harnessing the scalability, consistency, and fault tolerance inherent in TSP, TStreamLLM aims to manage continuous & concurrent LLM updates and usages efficiently. We showcase its potential through practical use cases like real-time patient monitoring and intelligent traffic management. The exploration of synergies between TSP and LLM management can stimulate groundbreaking developments in AI and database research. This paper provides a comprehensive overview of challenges and opportunities in this emerging field, setting forth a roadmap for future exploration and development. ","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 04:01:02 GMT'}]",2023-07-18,"[['Zhang', 'Shuhao', ''], ['Zeng', 'Xianzhi', ''], ['Wu', 'Yuhao', ''], ['Yang', 'Zhonghao', '']]",0,0,2023-07-17,1,4,3,0,0,0,a4e32021908ae088839878a94513c2202e4bf084,259936966.0,https://www.semanticscholar.org/paper/a4e32021908ae088839878a94513c2202e4bf084,arXiv.org,2023.0,43.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2188004', 'name': 'Shuhao Zhang'}, {'authorId': '2111551824', 'name': 'Xianzhi Zeng'}, {'authorId': '2223670108', 'name': 'Yuhao Wu'}, {'authorId': '2111737301', 'name': 'Zhonghao Yang'}]",['Singapore University of Technology and Design'],['Singapore'],2023-07
2307.08272,Xuan-Quy Dao,"Xuan-Quy Dao, Ngoc-Bich Le",ChatGPT is Good but Bing Chat is Better for Vietnamese Students,13 pages; 6 figures,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This study examines the efficacy of two SOTA large language models (LLMs), namely ChatGPT and Microsoft Bing Chat (BingChat), in catering to the needs of Vietnamese students. Although ChatGPT exhibits proficiency in multiple disciplines, Bing Chat emerges as the more advantageous option. We conduct a comparative analysis of their academic achievements in various disciplines, encompassing mathematics, literature, English language, physics, chemistry, biology, history, geography, and civic education. The results of our study suggest that BingChat demonstrates superior performance compared to ChatGPT across a wide range of subjects, with the exception of literature, where ChatGPT exhibits better performance. Additionally, BingChat utilizes the more advanced GPT-4 technology in contrast to ChatGPT, which is built upon GPT-3.5. This allows BingChat to improve to comprehension, reasoning and generation of creative and informative text. Moreover, the fact that BingChat is accessible in Vietnam and its integration of hyperlinks and citations within responses serve to reinforce its superiority. In our analysis, it is evident that while ChatGPT exhibits praiseworthy qualities, BingChat presents a more apdated solutions for Vietnamese students. ","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 06:36:53 GMT'}, {'version': 'v2', 'created': 'Wed, 19 Jul 2023 23:52:23 GMT'}, {'version': 'v3', 'created': 'Sun, 30 Jul 2023 01:04:05 GMT'}]",2023-08-01,"[['Dao', 'Xuan-Quy', ''], ['Le', 'Ngoc-Bich', '']]",1,1,2023-07-17,3,2,1,3,0,3,2d71be736d1015f9e21c31a7b9dfd9db509f3ee9,259936856.0,https://www.semanticscholar.org/paper/2d71be736d1015f9e21c31a7b9dfd9db509f3ee9,arXiv.org,2023.0,28.0,3.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'History', 'source': 's2-fos-model'}]","[{'authorId': '2134798816', 'name': 'Xuan-Quy Dao'}, {'authorId': '2082348114', 'name': 'Ngoc-Bich Le'}]","['International University', 'Eastern International University']","['Cambodia', 'Vietnam']",2023-07
2307.08393,Luca Benedetto,"Andrew Caines, Luca Benedetto, Shiva Taslimipoor, Christopher Davis,
  Yuan Gao, Oeistein Andersen, Zheng Yuan, Mark Elliott, Russell Moore,
  Christopher Bryant, Marek Rei, Helen Yannakoudakis, Andrew Mullooly, Diane
  Nicholls, Paula Buttery",On the application of Large Language Models for language teaching and assessment technology,"Accepted at the AIED2023 workshop: Empowering Education with LLMs -
  the Next-Gen Interface and Content Generation",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The recent release of very large language models such as PaLM and GPT-4 has made an unprecedented impact in the popular media and public consciousness, giving rise to a mixture of excitement and fear as to their capabilities and potential uses, and shining a light on natural language processing research which had not previously received so much attention. The developments offer great promise for education technology, and in this paper we look specifically at the potential for incorporating large language models in AI-driven language teaching and assessment systems. We consider several research areas and also discuss the risks and ethical considerations surrounding generative AI in education technology for language learners. Overall we find that larger language models offer improvements over previous models in text generation, opening up routes toward content generation which had not previously been plausible. For text generation they must be prompted carefully and their outputs may need to be reshaped before they are ready for use. For automated grading and grammatical error correction, tasks whose progress is checked on well-known benchmarks, early investigations indicate that large language models on their own do not improve on state-of-the-art results according to standard evaluation metrics. For grading it appears that linguistic features established in the literature should still be used for best performance, and for error correction it may be that the models can offer alternative feedback styles which are not measured sensitively with existing methods. In all cases, there is work to be done to experiment with the inclusion of large language models in education technology for language learners, in order to properly understand and report on their capacities and limitations, and to ensure that foreseeable risks such as misinformation and harmful bias are mitigated. ","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 11:12:56 GMT'}]",2023-07-18,"[['Caines', 'Andrew', ''], ['Benedetto', 'Luca', ''], ['Taslimipoor', 'Shiva', ''], ['Davis', 'Christopher', ''], ['Gao', 'Yuan', ''], ['Andersen', 'Oeistein', ''], ['Yuan', 'Zheng', ''], ['Elliott', 'Mark', ''], ['Moore', 'Russell', ''], ['Bryant', 'Christopher', ''], ['Rei', 'Marek', ''], ['Yannakoudakis', 'Helen', ''], ['Mullooly', 'Andrew', ''], ['Nicholls', 'Diane', ''], ['Buttery', 'Paula', '']]",0,1,2023-07-17,1,15,2,2,0,2,4a806670b0aeb2b55c1efce5ae294e34ac9c676b,259937556.0,https://www.semanticscholar.org/paper/4a806670b0aeb2b55c1efce5ae294e34ac9c676b,LLM@AIED,2023.0,127.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143726824', 'name': 'Andrew Caines'}, {'authorId': '73771574', 'name': 'Luca Benedetto'}, {'authorId': '2555867', 'name': 'Shiva Taslimipoor'}, {'authorId': '145808477', 'name': 'Christopher Davis'}, {'authorId': '2145975187', 'name': 'Yuan Gao'}, {'authorId': '2223595100', 'name': 'Oeistein Andersen'}, {'authorId': '2087294016', 'name': 'Zheng Yuan'}, {'authorId': '2056996791', 'name': 'Mark Elliott'}, {'authorId': '2109982490', 'name': 'Russell Moore'}, {'authorId': '145178009', 'name': 'Christopher Bryant'}, {'authorId': '145687301', 'name': 'Marek Rei'}, {'authorId': '2169553', 'name': 'H. Yannakoudakis'}, {'authorId': '2220404453', 'name': 'Andrew Mullooly'}, {'authorId': '46951456', 'name': 'D. Nicholls'}, {'authorId': '33490976', 'name': 'P. Buttery'}]","[""King's College London"", 'Cambridge University Press', 'Imperial College London', 'University of Cambridge', 'English Language iTutoring (ELiT)']",['United Kingdom'],2023-07
2307.08564,Andrea Baronchelli,Andrea Baronchelli,Shaping New Norms for Artificial Intelligence: A Complex Systems Perspective,,,,,physics.soc-ph,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  As Artificial Intelligence (AI) becomes increasingly integrated into our lives, the need for new norms, encompassing both social conventions and formal regulation, becomes crucial. The task of developing such norms is challenging because the development of AI occurs at a much faster pace than the characteristic time of norm formation. Furthermore, this rapid speed makes it difficult to anticipate future scenarios. This paper examines the processes of norm formation surrounding AI from a complex systems perspective. Focusing on how new norms can be established, rather than on what these norms should be, it distinguishes different scenarios based on the centralisation or decentralisation of the norm formation process. In particular, the article highlights possible criticalities of the cases where new codes of behaviour are shaped by formal authorities, informal institutions, or emerge spontaneously in a bottom-up fashion. On the latter point, the paper reports a conversation that took place between the author and ChatGPT on May 22, 2023, in which the LLM discusses some of the emerging norms it has observed. Far from aiming at exhaustiveness, this article aims to offer readers some further interpretive tools to understand society's response to the growing pervasiveness of AI. The conclusion presents an outlook on how AI could influence the formation of future social norms and emphasises the importance for open societies to anchor their formal deliberation process in an open, inclusive, and transparent public discourse. ","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 15:31:58 GMT'}]",2023-07-18,"[['Baronchelli', 'Andrea', '']]",1,1,2023-07-17,1,1,1,1,0,1,68d867e928be8d18bbdfa35e4577b78053516a22,259937539.0,https://www.semanticscholar.org/paper/68d867e928be8d18bbdfa35e4577b78053516a22,,2023.0,51.0,0.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2836702', 'name': 'A. Baronchelli'}]","['The Alan Turing Institute', 'City, University of London']",['United Kingdom'],2023-07
2307.08823,Jonas Schuett,"Leonie Koessler, Jonas Schuett",Risk assessment at AGI companies: A review of popular risk assessment techniques from other safety-critical industries,"44 pages, 13 figures, 9 tables",,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Companies like OpenAI, Google DeepMind, and Anthropic have the stated goal of building artificial general intelligence (AGI) - AI systems that perform as well as or better than humans on a wide variety of cognitive tasks. However, there are increasing concerns that AGI would pose catastrophic risks. In light of this, AGI companies need to drastically improve their risk management practices. To support such efforts, this paper reviews popular risk assessment techniques from other safety-critical industries and suggests ways in which AGI companies could use them to assess catastrophic risks from AI. The paper discusses three risk identification techniques (scenario analysis, fishbone method, and risk typologies and taxonomies), five risk analysis techniques (causal mapping, Delphi technique, cross-impact analysis, bow tie analysis, and system-theoretic process analysis), and two risk evaluation techniques (checklists and risk matrices). For each of them, the paper explains how they work, suggests ways in which AGI companies could use them, discusses their benefits and limitations, and makes recommendations. Finally, the paper discusses when to conduct risk assessments, when to use which technique, and how to use any of them. The reviewed techniques will be obvious to risk management professionals in other industries. And they will not be sufficient to assess catastrophic risks from AI. However, AGI companies should not skip the straightforward step of reviewing best practices from other industries. ","[{'version': 'v1', 'created': 'Mon, 17 Jul 2023 20:36:51 GMT'}]",2023-07-19,"[['Koessler', 'Leonie', ''], ['Schuett', 'Jonas', '']]",0,0,2023-07-17,1,2,1,1,0,1,3270d292aa0ce0c01ca4fadfc0f355ff1d45d754,259951436.0,https://www.semanticscholar.org/paper/3270d292aa0ce0c01ca4fadfc0f355ff1d45d754,arXiv.org,2023.0,188.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2148827272', 'name': 'Leonie Koessler'}, {'authorId': '1388301316', 'name': 'Jonas Schuett'}]",['Centre for the Governance of AI'],['United Kingdom'],2023-07
2307.08922,Cheng-Kuang Wu,"Cheng-Kuang Wu, Wei-Lin Chen, Hsin-Hsi Chen",Large Language Models Perform Diagnostic Reasoning,"Accepted as a Tiny Paper at ICLR 2023 (10 pages, 5 figures)",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We explore the extension of chain-of-thought (CoT) prompting to medical reasoning for the task of automatic diagnosis. Motivated by doctors' underlying reasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical results demonstrate that by simply prompting large language models trained only on general text corpus with two DR-CoT exemplars, the diagnostic accuracy improves by 15% comparing to standard prompting. Moreover, the gap reaches a pronounced 18% in out-domain settings. Our findings suggest expert-knowledge reasoning in large language models can be elicited through proper promptings. ","[{'version': 'v1', 'created': 'Tue, 18 Jul 2023 01:43:00 GMT'}]",2023-07-19,"[['Wu', 'Cheng-Kuang', ''], ['Chen', 'Wei-Lin', ''], ['Chen', 'Hsin-Hsi', '']]",0,0,2023-07-18,1,3,1,0,0,0,4a5af57b2056c4cc0a768d830d5427f0d1bdae33,259950441.0,https://www.semanticscholar.org/paper/4a5af57b2056c4cc0a768d830d5427f0d1bdae33,Tiny Papers @ ICLR,2023.0,18.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2217944277', 'name': 'Cheng-Kuang Wu'}, {'authorId': '2128184431', 'name': 'Wei-Lin Chen'}, {'authorId': '2145279517', 'name': 'Hsin-Hsi Chen'}]",['National Taiwan University'],['Taiwan'],2023-07
2307.09162,Vishesh Thakur,Vishesh Thakur,Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Gender bias in artificial intelligence (AI) and natural language processing has garnered significant attention due to its potential impact on societal perceptions and biases. This research paper aims to analyze gender bias in Large Language Models (LLMs) with a focus on multiple comparisons between GPT-2 and GPT-3.5, some prominent language models, to better understand its implications. Through a comprehensive literature review, the study examines existing research on gender bias in AI language models and identifies gaps in the current knowledge. The methodology involves collecting and preprocessing data from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis techniques to evaluate gender bias in the generated text. The findings shed light on gendered word associations, language usage, and biased narratives present in the outputs of these Large Language Models. The discussion explores the ethical implications of gender bias and its potential consequences on social perceptions and marginalized communities. Additionally, the paper presents strategies for reducing gender bias in LLMs, including algorithmic approaches and data augmentation techniques. The research highlights the importance of interdisciplinary collaborations and the role of sociological studies in mitigating gender bias in AI models. By addressing these issues, we can pave the way for more inclusive and unbiased AI systems that have a positive impact on society. ","[{'version': 'v1', 'created': 'Tue, 18 Jul 2023 11:38:45 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Aug 2023 13:15:24 GMT'}, {'version': 'v3', 'created': 'Thu, 31 Aug 2023 20:02:47 GMT'}]",2023-09-04,"[['Thakur', 'Vishesh', '']]",0,1,2023-07-18,3,1,1,2,1,1,677b1bde3d39f71722d967546e34d7ada0cbe0f2,259950823.0,https://www.semanticscholar.org/paper/677b1bde3d39f71722d967546e34d7ada0cbe0f2,arXiv.org,2023.0,30.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2217270630', 'name': 'Vishesh Thakur'}]",['Indian Institute of Technology Bhilai'],['India'],2023-07
2307.09381,Claudio Di Sipio,"Phuong T. Nguyen, Juri Di Rocco, Claudio Di Sipio, Riccardo Rubei,
  Davide Di Ruscio, Massimiliano Di Penta",Is this Snippet Written by ChatGPT? An Empirical Study with a CodeBERT-Based Classifier,,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it as a tool to solve development problems. However, while offering a practical solution to programming problems, ChatGPT should be mainly used as a supporting tool (e.g., in software education) rather than as a replacement for the human being. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content may need to be adapted to work effectively with source code. This paper presents an empirical study to investigate the feasibility of automated identification of AI-generated code snippets, and the factors that influence this ability. To this end, we propose a novel approach called GPTSniffer, which builds on top of CodeBERT to detect source code written by AI. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, and outperforms two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps to boost classification performances. ","[{'version': 'v1', 'created': 'Tue, 18 Jul 2023 16:01:15 GMT'}, {'version': 'v2', 'created': 'Mon, 7 Aug 2023 07:41:37 GMT'}]",2023-08-08,"[['Nguyen', 'Phuong T.', ''], ['Di Rocco', 'Juri', ''], ['Di Sipio', 'Claudio', ''], ['Rubei', 'Riccardo', ''], ['Di Ruscio', 'Davide', ''], ['Di Penta', 'Massimiliano', '']]",1,1,2023-07-18,2,6,1,1,0,1,eb621916f44220e16d7441fb95b0542597203f83,259950759.0,https://www.semanticscholar.org/paper/eb621916f44220e16d7441fb95b0542597203f83,arXiv.org,2023.0,37.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145431495', 'name': 'P. Nguyen'}, {'authorId': '37121973', 'name': 'Juri Di Rocco'}, {'authorId': '1644891552', 'name': 'Claudio Di Sipio'}, {'authorId': '80788365', 'name': 'Riccardo Rubei'}, {'authorId': '2133181', 'name': 'D. D. Ruscio'}, {'authorId': '1719962', 'name': 'M. D. Penta'}]","[""University of L'Aquila""]",['Italy'],2023-07
2307.09416,Lorenzo Baraldi,"Federico Betti, Jacopo Staiano, Lorenzo Baraldi, Lorenzo Baraldi, Rita
  Cucchiara, Nicu Sebe",Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation Evaluation,Accepted as oral at ACM MultiMedia 2023 (Brave New Ideas track),,,,cs.CV cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Research in Image Generation has recently made significant progress, particularly boosted by the introduction of Vision-Language models which are able to produce high-quality visual content based on textual inputs. Despite ongoing advancements in terms of generation quality and realism, no methodical frameworks have been defined yet to quantitatively measure the quality of the generated content and the adherence with the prompted requests: so far, only human-based evaluations have been adopted for quality satisfaction and for comparing different generative methods. We introduce a novel automated method for Visual Concept Evaluation (ViCE), i.e. to assess consistency between a generated/edited image and the corresponding prompt/instructions, with a process inspired by the human cognitive behaviour. ViCE combines the strengths of Large Language Models (LLMs) and Visual Question Answering (VQA) into a unified pipeline, aiming to replicate the human cognitive process in quality assessment. This method outlines visual concepts, formulates image-specific verification questions, utilizes the Q&A system to investigate the image, and scores the combined outcome. Although this brave new hypothesis of mimicking humans in the image evaluation process is in its preliminary assessment stage, results are promising and open the door to a new form of automatic evaluation which could have significant impact as the image generation or the image target editing tasks become more and more sophisticated. ","[{'version': 'v1', 'created': 'Tue, 18 Jul 2023 16:33:30 GMT'}, {'version': 'v2', 'created': 'Wed, 19 Jul 2023 08:27:50 GMT'}]",2023-07-20,"[['Betti', 'Federico', ''], ['Staiano', 'Jacopo', ''], ['Baraldi', 'Lorenzo', ''], ['Baraldi', 'Lorenzo', ''], ['Cucchiara', 'Rita', ''], ['Sebe', 'Nicu', '']]",0,0,2023-07-18,2,6,2,0,0,0,eb3f3e42332a2aec2798752b30f93f93b647be8b,259950866.0,https://www.semanticscholar.org/paper/eb3f3e42332a2aec2798752b30f93f93b647be8b,ACM Multimedia,2023.0,40.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66851422', 'name': 'F. Betti'}, {'authorId': '1767493', 'name': 'Jacopo Staiano'}, {'authorId': '1843795', 'name': 'L. Baraldi'}, {'authorId': '1741922', 'name': 'R. Cucchiara'}, {'authorId': '1429806753', 'name': 'N. Sebe'}]","['University of Modena and Reggio Emilia', 'University of Trento', 'University of Pisa']",['Italy'],2023-07
2307.09744,Long Mai Thanh,Long Mai and Julie Carson-Berndsen,Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The integration of natural language processing (NLP) technologies into educational applications has shown promising results, particularly in the language learning domain. Recently, many spoken open-domain chatbots have been used as speaking partners, helping language learners improve their language skills. However, one of the significant challenges is the high word-error-rate (WER) when recognizing non-native/non-fluent speech, which interrupts conversation flow and leads to disappointment for learners. This paper explores the use of GPT4 for ASR error correction in conversational settings. In addition to WER, we propose to use semantic textual similarity (STS) and next response sensibility (NRS) metrics to evaluate the impact of error correction models on the quality of the conversation. We find that transcriptions corrected by GPT4 lead to higher conversation quality, despite an increase in WER. GPT4 also outperforms standard error correction methods without the need for in-domain training data. ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 04:25:21 GMT'}]",2023-07-20,"[['Mai', 'Long', ''], ['Carson-Berndsen', 'Julie', '']]",0,1,2023-07-19,1,2,2,1,0,1,8a1d456c9b1d4801f10cdeb699c20f1dd17be045,259982763.0,https://www.semanticscholar.org/paper/8a1d456c9b1d4801f10cdeb699c20f1dd17be045,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2712573', 'name': 'Long Mai'}, {'authorId': '1401148076', 'name': 'Julie Carson-Berndsen'}]",['University College Dublin'],['Ireland'],2023-07
2307.09923,Michael Grohs,"Michael Grohs, Luka Abb, Nourhan Elsayed, and Jana-Rebecca Rehse",Large Language Models can accomplish Business Process Management Tasks,Accepted at NLP4BPM workshop at BPM 2023,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Business Process Management (BPM) aims to improve organizational activities and their outcomes by managing the underlying processes. To achieve this, it is often necessary to consider information from various sources, including unstructured textual documents. Therefore, researchers have developed several BPM-specific solutions that extract information from textual documents using Natural Language Processing techniques. These solutions are specific to their respective tasks and cannot accomplish multiple process-related problems as a general-purpose instrument. However, in light of the recent emergence of Large Language Models (LLMs) with remarkable reasoning capabilities, such a general-purpose instrument with multiple applications now appears attainable. In this paper, we illustrate how LLMs can accomplish text-related BPM tasks by applying a specific LLM to three exemplary tasks: mining imperative process models from textual descriptions, mining declarative process models from textual descriptions, and assessing the suitability of process tasks from textual descriptions for robotic process automation. We show that, without extensive configuration or prompt engineering, LLMs perform comparably to or better than existing solutions and discuss implications for future BPM research as well as practical usage. ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 11:54:46 GMT'}]",2023-07-20,"[['Grohs', 'Michael', ''], ['Abb', 'Luka', ''], ['Elsayed', 'Nourhan', ''], ['Rehse', 'Jana-Rebecca', '']]",0,0,2023-07-19,1,4,1,0,0,0,b43e9b674d4572e1aba8b40a28056ab118ad5e83,259983054.0,https://www.semanticscholar.org/paper/b43e9b674d4572e1aba8b40a28056ab118ad5e83,arXiv.org,2023.0,20.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '82288707', 'name': 'Michael Grohs'}, {'authorId': '2179109868', 'name': 'Luka Abb'}, {'authorId': '2060265821', 'name': 'Nourhan Elsayed'}, {'authorId': '2708391', 'name': 'Jana-Rebecca Rehse'}]",['University of Mannheim'],['Germany'],2023-07
2307.09998,Jordan Meadows,"Jordan Meadows, Marco Valentino, Andre Freitas",Generating Mathematical Derivations with Large Language Models,10 pages,,,,cs.CL math.HO,http://creativecommons.org/licenses/by/4.0/,"  The derivation of mathematical results in specialised fields, using Large Language Models (LLMs), is an emerging research direction that can help identify models' limitations, and potentially support mathematical discovery. In this paper, we leverage a symbolic engine to generate derivations of equations at scale, and investigate the capabilities of LLMs when deriving goal equations from premises. Specifically, we employ in-context learning for GPT and fine-tune a range of T5 models to compare the robustness and generalisation of pre-training strategies to specialised models. Empirical results show that fine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and out-of-distribution test sets in conventional scores. However, an in-depth analysis reveals that the fine-tuned models are more sensitive to perturbations involving unseen symbols and (to a lesser extent) changes to equation structure. In addition, we analyse 1.7K equations, and over 200 derivations, to highlight common reasoning errors such as the inclusion of incorrect, irrelevant, and redundant equations. Finally, we explore the suitability of existing metrics for evaluating mathematical derivations and find evidence that, while they can capture general properties such as sensitivity to perturbations, they fail to highlight fine-grained reasoning errors and essential differences between models. Overall, this work demonstrates that training models on synthetic data may improve their math capabilities beyond much larger LLMs, but current metrics are not appropriately assessing the quality of generated mathematical text. ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 14:13:02 GMT'}, {'version': 'v2', 'created': 'Sat, 22 Jul 2023 04:03:35 GMT'}, {'version': 'v3', 'created': 'Tue, 8 Aug 2023 12:23:49 GMT'}]",2023-08-09,"[['Meadows', 'Jordan', ''], ['Valentino', 'Marco', ''], ['Freitas', 'Andre', '']]",0,1,2023-07-19,3,3,2,3,2,1,4703cbd3743ff81297c64007db0109d96dec98c0,259982788.0,https://www.semanticscholar.org/paper/4703cbd3743ff81297c64007db0109d96dec98c0,arXiv.org,2023.0,53.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151056786', 'name': 'Jordan Meadows'}, {'authorId': '34102057', 'name': 'Marco Valentino'}, {'authorId': '2057619238', 'name': 'André Freitas'}]","['University of Manchester', 'Idiap Research Institute']","['United Kingdom', 'Switzerland']",2023-07
2307.10022,Konstantinos Pitas,Konstantinos Pitas,Europepolls: A Dataset of Country-Level Opinion Polling Data for the European Union and the UK,,,,,cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  I propose an open dataset of country-level historical opinion polling data for the European Union and the UK. The dataset aims to fill a gap in available opinion polling data for the European Union. Some existing datasets are restricted to the past five years, limiting research opportunities. At the same time, some larger proprietary datasets exist but are available only in a visual preprocessed time series format. Finally, while other large datasets for individual countries might exist, these could be inaccessible due to language barriers. The data was gathered from Wikipedia, and preprocessed using the pandas library. Both the raw and the preprocessed data are in the .csv format. I hope that given the recent advances in LLMs and deep learning in general, this large dataset will enable researchers to uncover complex interactions between multimodal data (news articles, economic indicators, social media) and voting behavior. The raw data, the preprocessed data, and the preprocessing scripts are available on GitHub. ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 15:05:55 GMT'}]",2023-07-20,"[['Pitas', 'Konstantinos', '']]",0,0,2023-07-19,1,1,1,0,0,0,746780e7a54978a5849a8ce890c938500afda99f,259982969.0,https://www.semanticscholar.org/paper/746780e7a54978a5849a8ce890c938500afda99f,arXiv.org,2023.0,16.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3208802', 'name': 'Konstantinos Pitas'}]",['Inria Grenoble - Rhône-Alpes research centre'],['France'],2023-07
2307.10169,Jean Kaddour,"Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta
  Raileanu, Robert McHardy",Challenges and Applications of Large Language Models,"72 pages. v01. Work in progress. Feedback and comments are highly
  appreciated!",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years. Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the field's current state more quickly and become productive. ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 17:55:13 GMT'}]",2023-07-20,"[['Kaddour', 'Jean', ''], ['Harris', 'Joshua', ''], ['Mozes', 'Maximilian', ''], ['Bradley', 'Herbie', ''], ['Raileanu', 'Roberta', ''], ['McHardy', 'Robert', '']]",0,0,2023-07-19,1,6,3,0,0,0,e01ab53663e5df5961a021506a9cb09f4efc3788,259982665.0,https://www.semanticscholar.org/paper/e01ab53663e5df5961a021506a9cb09f4efc3788,arXiv.org,2023.0,0.0,33.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66914903', 'name': 'Jean Kaddour'}, {'authorId': '145556319', 'name': 'J. Harris'}, {'authorId': '37237998', 'name': 'Maximilian Mozes'}, {'authorId': '2070768742', 'name': 'Herbie Bradley'}, {'authorId': '48647153', 'name': 'Roberta Raileanu'}, {'authorId': '32415937', 'name': 'R. McHardy'}]","['University of Cambridge', 'UK Health Security Agency']",['United Kingdom'],2023-07
2307.10195,Mark Scanlon,"Mark Scanlon, Frank Breitinger, Christopher Hargreaves, Jan-Niclas
  Hilgert, John Sheppard","ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown",,,,,cs.CR cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of domains has become a topic of much discussion in the scientific community and society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take instructions, or prompts, from users and generate answers and solutions based on very large volumes of text-based training data. This paper assesses the impact and potential impact of ChatGPT on the field of digital forensics, specifically looking at its latest pre-trained LLM, GPT-4. A series of experiments are conducted to assess its capability across several digital forensic use cases including artefact understanding, evidence searching, code generation, anomaly detection, incident response, and education. Across these topics, its strengths and risks are outlined and a number of general conclusions are drawn. Overall this paper concludes that while there are some potential low-risk applications of ChatGPT within digital forensics, many are either unsuitable at present, since the evidence would need to be uploaded to the service, or they require sufficient knowledge of the topic being asked of the tool to identify incorrect assumptions, inaccuracies, and mistakes. However, to an appropriately knowledgeable user, it could act as a useful supporting tool in some circumstances. ","[{'version': 'v1', 'created': 'Mon, 10 Jul 2023 20:07:30 GMT'}]",2023-07-21,"[['Scanlon', 'Mark', ''], ['Breitinger', 'Frank', ''], ['Hargreaves', 'Christopher', ''], ['Hilgert', 'Jan-Niclas', ''], ['Sheppard', 'John', '']]",1,1,2023-07-10,1,5,3,4,1,3,97b1d7a68201fc0e87915ad12a34a1b7ddf0dcf4,259991541.0,https://www.semanticscholar.org/paper/97b1d7a68201fc0e87915ad12a34a1b7ddf0dcf4,Forensic Science International: Digital Investigation,2023.0,30.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145983978', 'name': 'M. Scanlon'}, {'authorId': '3230061', 'name': 'Frank Breitinger'}, {'authorId': '3447798', 'name': 'C. Hargreaves'}, {'authorId': '51131883', 'name': 'Jan-Niclas Hilgert'}, {'authorId': '2065412403', 'name': 'John W. Sheppard'}]","['University of Lausanne', 'University College Dublin', 'Fraunhofer Institute for Communication, Information Processing and Ergonomics', 'University of Oxford', 'South East Technological University']","['Germany', 'Ireland', 'United Kingdom', 'Switzerland']",2023-07
2307.10214,Davide Sanvito,"Giuseppe Siracusano, Davide Sanvito, Roberto Gonzalez, Manikantan
  Srinivasan, Sivakaman Kamatchi, Wataru Takahashi, Masaru Kawakita, Takahiro
  Kakumaru, Roberto Bifulco",Time for aCTIon: Automated Analysis of Cyber Threat Intelligence in the Wild,,,,,cs.CR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Cyber Threat Intelligence (CTI) plays a crucial role in assessing risks and enhancing security for organizations. However, the process of extracting relevant information from unstructured text sources can be expensive and time-consuming. Our empirical experience shows that existing tools for automated structured CTI extraction have performance limitations. Furthermore, the community lacks a common benchmark to quantitatively assess their performance. We fill these gaps providing a new large open benchmark dataset and aCTIon, a structured CTI information extraction tool. The dataset includes 204 real-world publicly available reports and their corresponding structured CTI information in STIX format. Our team curated the dataset involving three independent groups of CTI analysts working over the course of several months. To the best of our knowledge, this dataset is two orders of magnitude larger than previously released open source datasets. We then design aCTIon, leveraging recently introduced large language models (GPT3.5) in the context of two custom information extraction pipelines. We compare our method with 10 solutions presented in previous work, for which we develop our own implementations when open-source implementations were lacking. Our results show that aCTIon outperforms previous work for structured CTI extraction with an improvement of the F1-score from 10%points to 50%points across all tasks. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 13:43:16 GMT'}]",2023-07-21,"[['Siracusano', 'Giuseppe', ''], ['Sanvito', 'Davide', ''], ['Gonzalez', 'Roberto', ''], ['Srinivasan', 'Manikantan', ''], ['Kamatchi', 'Sivakaman', ''], ['Takahashi', 'Wataru', ''], ['Kawakita', 'Masaru', ''], ['Kakumaru', 'Takahiro', ''], ['Bifulco', 'Roberto', '']]",0,1,2023-07-14,1,9,2,1,0,1,116fe7bbb1910f506ca52874352b7c99b4b1488a,259991762.0,https://www.semanticscholar.org/paper/116fe7bbb1910f506ca52874352b7c99b4b1488a,arXiv.org,2023.0,63.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48710117', 'name': 'G. Siracusano'}, {'authorId': '3109801', 'name': 'D. Sanvito'}, {'authorId': '2109141737', 'name': 'Roberto González'}, {'authorId': '2540412', 'name': 'Manikantan Srinivasan'}, {'authorId': '2215650893', 'name': 'S. Kamatchi'}, {'authorId': '2059695503', 'name': 'Wataru Takahashi'}, {'authorId': '31990183', 'name': 'Masaru Kawakita'}, {'authorId': '3277863', 'name': 'Takahiro Kakumaru'}, {'authorId': '1707367', 'name': 'R. Bifulco'}]","['NEC Corporation India', 'NEC Laboratories Europe']",['India'],2023-07
2307.10348,Pablo Antonio Mart\'inez,"Pablo Antonio Mart\'inez and Gregorio Bernab\'e and Jos\'e Manuel
  Garc\'ia",Code Detection for Hardware Acceleration Using Large Language Models,,,,,cs.SE cs.LG cs.PL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large language models (LLMs) have been massively applied to many tasks, often surpassing state-of-the-art approaches. While their effectiveness in code generation has been extensively studied (e.g., AlphaCode), their potential for code detection remains unexplored.   This work presents the first analysis of code detection using LLMs. Our study examines essential kernels, including matrix multiplication, convolution, and fast-fourier transform, implemented in C/C++. We propose both a preliminary, naive prompt and a novel prompting strategy for code detection.   Results reveal that conventional prompting achieves great precision but poor accuracy (68.8%, 22.3%, and 79.2% for GEMM, convolution, and FFT, respectively) due to a high number of false positives. Our novel prompting strategy substantially reduces false positives, resulting in excellent overall accuracy (91.1%, 97.9%, and 99.7%, respectively). These results pose a considerable challenge to existing state-of-the-art code detection methods. ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 17:21:58 GMT'}]",2023-07-21,"[['Martínez', 'Pablo Antonio', ''], ['Bernabé', 'Gregorio', ''], ['García', 'José Manuel', '']]",0,0,2023-07-19,1,3,3,1,0,1,ab4c08d9ae0f408dc4ad83e24455f091efa7682f,259991703.0,https://www.semanticscholar.org/paper/ab4c08d9ae0f408dc4ad83e24455f091efa7682f,arXiv.org,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2185593294', 'name': ""Pablo Antonio Mart'inez""}, {'authorId': '2224019399', 'name': ""Gregorio Bernab'e""}, {'authorId': '2203317597', 'name': ""Jos'e Manuel Garc'ia""}]",['University of Murcia'],['Spain'],2023-07
2307.10472,Faiza Khattak Dr.,"Omkar Dige, Jacob-Junqi Tian, David Emerson, Faiza Khan Khattak",Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting?,,,,,cs.CL cs.AI cs.CY cs.LG,http://creativecommons.org/licenses/by/4.0/,"  As the breadth and depth of language model applications continue to expand rapidly, it is increasingly important to build efficient frameworks for measuring and mitigating the learned or inherited social biases of these models. In this paper, we present our work on evaluating instruction fine-tuned language models' ability to identify bias through zero-shot prompting, including Chain-of-Thought (CoT) prompts. Across LLaMA and its two instruction fine-tuned versions, Alpaca 7B performs best on the bias identification task with an accuracy of 56.7%. We also demonstrate that scaling up LLM size and data diversity could lead to further performance gain. This is a work-in-progress presenting the first component of our bias mitigation framework. We will keep updating this work as we get more results. ","[{'version': 'v1', 'created': 'Wed, 19 Jul 2023 22:03:40 GMT'}]",2023-07-21,"[['Dige', 'Omkar', ''], ['Tian', 'Jacob-Junqi', ''], ['Emerson', 'David', ''], ['Khattak', 'Faiza Khan', '']]",0,0,2023-07-19,1,4,4,2,1,1,0cfd72e3d81f35bccc1e67f5992e112a601ba2ba,259991491.0,https://www.semanticscholar.org/paper/0cfd72e3d81f35bccc1e67f5992e112a601ba2ba,arXiv.org,2023.0,26.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2224019101', 'name': 'O. Dige'}, {'authorId': '2220028602', 'name': 'Jacob-Junqi Tian'}, {'authorId': '2055879362', 'name': 'David B. Emerson'}, {'authorId': '2374769', 'name': 'Faiza Khan Khattak'}]","['McGill University', 'Vector Institute']",['Canada'],2023-07
2307.10587,Anand Kumar Rai,"Anand Kumar Rai, Siddharth D Jaiswal, Animesh Mukherjee",A Deep Dive into the Disparity of Word Error Rates Across Thousands of NPTEL MOOC Videos,,,,,cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automatic speech recognition (ASR) systems are designed to transcribe spoken language into written text and find utility in a variety of applications including voice assistants and transcription services. However, it has been observed that state-of-the-art ASR systems which deliver impressive benchmark results, struggle with speakers of certain regions or demographics due to variation in their speech properties. In this work, we describe the curation of a massive speech dataset of 8740 hours consisting of $\sim9.8$K technical lectures in the English language along with their transcripts delivered by instructors representing various parts of Indian demography. The dataset is sourced from the very popular NPTEL MOOC platform. We use the curated dataset to measure the existing disparity in YouTube Automatic Captions and OpenAI Whisper model performance across the diverse demographic traits of speakers in India. While there exists disparity due to gender, native region, age and speech rate of speakers, disparity based on caste is non-existent. We also observe statistically significant disparity across the disciplines of the lectures. These results indicate the need of more inclusive and robust ASR systems and more representational datasets for disparity evaluation in them. ","[{'version': 'v1', 'created': 'Thu, 20 Jul 2023 05:03:00 GMT'}]",2023-07-21,"[['Rai', 'Anand Kumar', ''], ['Jaiswal', 'Siddharth D', ''], ['Mukherjee', 'Animesh', '']]",0,0,2023-07-20,1,3,2,0,0,0,7184f95ac2d20412f2f25c3fdd2b24ce6591f9c8,259991024.0,https://www.semanticscholar.org/paper/7184f95ac2d20412f2f25c3fdd2b24ce6591f9c8,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2224015152', 'name': 'Anand Kumar Rai'}, {'authorId': '2066685493', 'name': 'Siddharth D. Jaiswal'}, {'authorId': '46405816', 'name': 'Animesh Mukherjee'}]",['Indian Institute of Technology Kharagpur'],['India'],2023-07
2307.10634,Musa \.Ihtiyar,Musa Nuri Ihtiyar and Arzucan Ozgur,Generative Language Models on Nucleotide Sequences of Human Genes,,,,,q-bio.GN cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language models, primarily transformer-based ones, obtained colossal success in NLP. To be more precise, studies like BERT in NLU and works such as GPT-3 for NLG are very crucial. DNA sequences are very close to natural language in terms of structure, so if the DNA-related bioinformatics domain is concerned, discriminative models, like DNABert, exist. Yet, the generative side of the coin is mainly unexplored to the best of our knowledge. Consequently, we focused on developing an autoregressive generative language model like GPT-3 for DNA sequences. Because working with whole DNA sequences is challenging without substantial computational resources, we decided to carry out our study on a smaller scale, focusing on nucleotide sequences of human genes, unique parts in DNA with specific functionalities, instead of the whole DNA. This decision did not change the problem structure a lot due to the fact that both DNA and genes can be seen as 1D sequences consisting of four different nucleotides without losing much information and making too much simplification. First of all, we systematically examined an almost entirely unexplored problem and observed that RNNs performed the best while simple techniques like N-grams were also promising. Another beneficial point was learning how to work with generative models on languages we do not understand, unlike natural language. How essential using real-life tasks beyond the classical metrics such as perplexity is observed. Furthermore, checking whether the data-hungry nature of these models can be changed through selecting a language with minimal vocabulary size, four owing to four different types of nucleotides, is examined. The reason for reviewing this was that choosing such a language might make the problem easier. However, what we observed in this study was it did not provide that much of a change in the amount of data needed. ","[{'version': 'v1', 'created': 'Thu, 20 Jul 2023 06:59:02 GMT'}]",2023-07-21,"[['Ihtiyar', 'Musa Nuri', ''], ['Ozgur', 'Arzucan', '']]",0,1,2023-07-20,1,2,3,1,0,1,34e80cd5c3c4d15f01c98c10644ef255125e0d61,259991605.0,https://www.semanticscholar.org/paper/34e80cd5c3c4d15f01c98c10644ef255125e0d61,arXiv.org,2023.0,40.0,0.0,0.0,True,"['Computer Science', 'Biology']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","[{'authorId': '2224017385', 'name': 'Musa Nuri Ihtiyar'}, {'authorId': '2113900183', 'name': 'Arzucan Özgür'}]",['Boğaziçi University'],['Turkey'],2023-07
2307.10719,David Glukhov,"David Glukhov, Ilia Shumailov, Yarin Gal, Nicolas Papernot, Vardan
  Papyan",LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?,,,,,cs.AI cs.CL cs.CR cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, as LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs from a collection of permissible ones. As a result, we propose that the problem of censorship needs to be reevaluated; it should be treated as a security problem which warrants the adaptation of security-based approaches to mitigate potential risks. ","[{'version': 'v1', 'created': 'Thu, 20 Jul 2023 09:25:02 GMT'}]",2023-07-25,"[['Glukhov', 'David', ''], ['Shumailov', 'Ilia', ''], ['Gal', 'Yarin', ''], ['Papernot', 'Nicolas', ''], ['Papyan', 'Vardan', '']]",0,0,2023-07-20,1,5,4,0,0,0,139a0c7a60667979dcb57eae677f75ff3f0b0196,259991450.0,https://www.semanticscholar.org/paper/139a0c7a60667979dcb57eae677f75ff3f0b0196,arXiv.org,2023.0,60.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2224017005', 'name': 'David Glukhov'}, {'authorId': '47473421', 'name': 'Ilia Shumailov'}, {'authorId': '2681954', 'name': 'Y. Gal'}, {'authorId': '1967156', 'name': 'Nicolas Papernot'}, {'authorId': '2734935', 'name': 'V. Papyan'}]","['University of Toronto', 'University of Oxford']","['Canada', 'United Kingdom']",2023-07
2307.10778,Jens-Joris Decorte,"Jens-Joris Decorte, Severine Verlinden, Jeroen Van Hautte, Johannes
  Deleu, Chris Develder and Thomas Demeester",Extreme Multi-Label Skill Extraction Training using Large Language Models,"Accepted to the International workshop on AI for Human Resources and
  Public Employment Services (AI4HR&PES) as part of ECML-PKDD 2023",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Online job ads serve as a valuable source of information for skill requirements, playing a crucial role in labor market analysis and e-recruitment processes. Since such ads are typically formatted in free text, natural language processing (NLP) technologies are required to automatically process them. We specifically focus on the task of detecting skills (mentioned literally, or implicitly described) and linking them to a large skill ontology, making it a challenging case of extreme multi-label classification (XMLC). Given that there is no sizable labeled (training) dataset are available for this specific XMLC task, we propose techniques to leverage general Large Language Models (LLMs). We describe a cost-effective approach to generate an accurate, fully synthetic labeled dataset for skill extraction, and present a contrastive learning strategy that proves effective in the task. Our results across three skill extraction benchmarks show a consistent increase of between 15 to 25 percentage points in \textit{R-Precision@5} compared to previously published results that relied solely on distant supervision through literal matches. ","[{'version': 'v1', 'created': 'Thu, 20 Jul 2023 11:29:15 GMT'}]",2023-07-21,"[['Decorte', 'Jens-Joris', ''], ['Verlinden', 'Severine', ''], ['Van Hautte', 'Jeroen', ''], ['Deleu', 'Johannes', ''], ['Develder', 'Chris', ''], ['Demeester', 'Thomas', '']]",0,0,2023-07-20,1,6,1,0,0,0,0741ace46e0668ea1ea8161442f2a8e92f178fc7,259991026.0,https://www.semanticscholar.org/paper/0741ace46e0668ea1ea8161442f2a8e92f178fc7,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2127470139', 'name': 'Jens-Joris Decorte'}, {'authorId': '46476168', 'name': 'S. Verlinden'}, {'authorId': '1382199471', 'name': 'Jeroen Van Hautte'}, {'authorId': '2630759', 'name': 'Johannes Deleu'}, {'authorId': '2067842103', 'name': 'Chris Develder'}, {'authorId': '1388296896', 'name': 'Thomas Demeester'}]","['TechWolf, 9000 Gent, Belgium', 'Ghent University']",['Belgium'],2023-07
2307.10793,Patricia Widjojo,Patricia Widjojo and Christoph Treude,Addressing Compiler Errors: Stack Overflow or Large Language Models?,,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Compiler error messages serve as an initial resource for programmers dealing with compilation errors. However, previous studies indicate that they often lack sufficient targeted information to resolve code issues. Consequently, programmers typically rely on their own research to fix errors. Historically, Stack Overflow has been the primary resource for such information, but recent advances in large language models offer alternatives. This study systematically examines 100 compiler error messages from three sources to determine the most effective approach for programmers encountering compiler errors. Factors considered include Stack Overflow search methods and the impact of model version and prompt phrasing when using large language models. The results reveal that GPT-4 outperforms Stack Overflow in explaining compiler error messages, the effectiveness of adding code snippets to Stack Overflow searches depends on the search method, and results for Stack Overflow differ significantly between Google and StackExchange API searches. Furthermore, GPT-4 surpasses GPT-3.5, with ""How to fix"" prompts yielding superior outcomes to ""What does this error mean"" prompts. These results offer valuable guidance for programmers seeking assistance with compiler error messages, underscoring the transformative potential of advanced large language models like GPT-4 in debugging and opening new avenues of exploration for researchers in AI-assisted programming. ","[{'version': 'v1', 'created': 'Thu, 20 Jul 2023 11:46:48 GMT'}]",2023-07-21,"[['Widjojo', 'Patricia', ''], ['Treude', 'Christoph', '']]",0,1,2023-07-20,1,2,1,2,0,2,ab91ce3fa3ebcffb637bd48b5caeba4967d2a79d,259991589.0,https://www.semanticscholar.org/paper/ab91ce3fa3ebcffb637bd48b5caeba4967d2a79d,arXiv.org,2023.0,0.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2224014534', 'name': 'Patricia Widjojo'}, {'authorId': '1685418', 'name': 'Christoph Treude'}]",['University of Melbourne'],['Australia'],2023-07
2307.11388,Shintaro Uchiyama,"Shintaro Uchiyama, Kyoji Umemura and Yusuke Morita",Large Language Model-based System to Provide Immediate Feedback to Students in Flipped Classroom Preparation Learning,6 pages,,,,cs.HC cs.AI cs.CY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This paper proposes a system that uses large language models to provide immediate feedback to students in flipped classroom preparation learning. This study aimed to solve challenges in the flipped classroom model, such as ensuring that students are emotionally engaged and motivated to learn. Students often have questions about the content of lecture videos in the preparation of flipped classrooms, but it is difficult for teachers to answer them immediately. The proposed system was developed using the ChatGPT API on a video-watching support system for preparation learning that is being used in real practice. Answers from ChatGPT often do not align with the context of the student's question. Therefore, this paper also proposes a method to align the answer with the context. This paper also proposes a method to collect the teacher's answers to the students' questions and use them as additional guides for the students. This paper discusses the design and implementation of the proposed system. ","[{'version': 'v1', 'created': 'Fri, 21 Jul 2023 06:59:53 GMT'}]",2023-07-24,"[['Uchiyama', 'Shintaro', ''], ['Umemura', 'Kyoji', ''], ['Morita', 'Yusuke', '']]",1,1,2023-07-21,1,3,3,1,0,1,eefbfb1d3ecf3aacdc0443d2ad50b662762dbec6,260091340.0,https://www.semanticscholar.org/paper/eefbfb1d3ecf3aacdc0443d2ad50b662762dbec6,arXiv.org,2023.0,15.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2104460810', 'name': 'Shintaro Uchiyama'}, {'authorId': '34796291', 'name': 'Kyoji Umemura'}, {'authorId': '2900470', 'name': 'Y. Morita'}]","['Toyohashi University of Technology', 'Waseda University']",['Japan'],2023-07
2307.11661,Mayug Maniparambil,"Mayug Maniparambil, Chris Vorster, Derek Molloy, Noel Murphy, Kevin
  McGuinness, Noel E. O'Connor",Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts,"Paper accepted at ICCV-W 2023. V2 contains additional comparisons
  with concurrent works",,,,cs.CV cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have revolutionized visual representation learning by providing good performance on downstream datasets. VLMs are 0-shot adapted to a downstream dataset by designing prompts that are relevant to the dataset. Such prompt engineering makes use of domain expertise and a validation dataset. Meanwhile, recent developments in generative pretrained models like GPT-4 mean they can be used as advanced internet search tools. They can also be manipulated to provide visual information in any structure. In this work, we show that GPT-4 can be used to generate text that is visually descriptive and how this can be used to adapt CLIP to downstream tasks. We show considerable improvements in 0-shot transfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD (~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt. We also design a simple few-shot adapter that learns to choose the best possible sentences to construct generalizable classifiers that outperform the recently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized fine-grained datasets. The code, prompts, and auxiliary text dataset is available at https://github.com/mayug/VDT-Adapter. ","[{'version': 'v1', 'created': 'Fri, 21 Jul 2023 15:49:59 GMT'}, {'version': 'v2', 'created': 'Tue, 8 Aug 2023 13:44:12 GMT'}]",2023-08-09,"[['Maniparambil', 'Mayug', ''], ['Vorster', 'Chris', ''], ['Molloy', 'Derek', ''], ['Murphy', 'Noel', ''], ['McGuinness', 'Kevin', ''], [""O'Connor"", 'Noel E.', '']]",0,1,2023-07-21,2,6,4,1,0,1,3e0a691277183a6704310af3e4e9e271400612bc,260091777.0,https://www.semanticscholar.org/paper/3e0a691277183a6704310af3e4e9e271400612bc,arXiv.org,2023.0,57.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46223705', 'name': 'Mayug Maniparambil'}, {'authorId': '1397441651', 'name': 'Chris Vorster'}, {'authorId': '14664898', 'name': 'D. Molloy'}, {'authorId': '144353758', 'name': 'N. Murphy'}, {'authorId': '145470864', 'name': 'Kevin McGuinness'}, {'authorId': '2137567915', 'name': ""Noel E. O'Connor""}]",['Dublin City University'],['Ireland'],2023-07
2307.11729,Ryuto Koike,"Ryuto Koike, Masahiro Kaneko, Naoaki Okazaki",OUTFOX: LLM-generated Essay Detection through In-context Learning with Adversarially Generated Examples,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have achieved human-level fluency in text generation, making it difficult to distinguish between human-written and LLM-generated texts. This poses a growing risk of misuse of LLMs and demands the development of detectors to identify LLM-generated texts. However, existing detectors lack robustness against attacks: they degrade detection accuracy by simply paraphrasing LLM-generated texts. Furthermore, a malicious user might attempt to deliberately evade the detectors based on detection results, but this has not been assumed in previous studies. In this paper, we propose OUTFOX, a framework that improves the robustness of LLM-generated-text detectors by allowing both the detector and the attacker to consider each other's output. In this framework, the attacker uses the detector's prediction labels as examples for in-context learning and adversarially generates essays that are harder to detect, while the detector uses the adversarially generated essays as examples for in-context learning to learn to detect essays from a strong attacker. Experiments in the domain of student essays show that the proposed detector improves the detection performance on the attacker-generated texts by up to +41.3 points in F1-score. Furthermore, the proposed detector shows a state-of-the-art detection performance: up to 96.9 points in F1-score, beating existing detectors on non-attacked texts. Finally, the proposed attacker drastically degrades the performance of detectors by up to -57.0 points F1-score, massively outperforming the baseline paraphrasing method for evading detection. ","[{'version': 'v1', 'created': 'Fri, 21 Jul 2023 17:40:47 GMT'}, {'version': 'v2', 'created': 'Mon, 4 Sep 2023 10:20:30 GMT'}]",2023-09-06,"[['Koike', 'Ryuto', ''], ['Kaneko', 'Masahiro', ''], ['Okazaki', 'Naoaki', '']]",0,0,2023-07-21,2,3,1,0,0,0,0095acc4f2c3255cf38fdf844003c97858adb418,260091573.0,https://www.semanticscholar.org/paper/0095acc4f2c3255cf38fdf844003c97858adb418,arXiv.org,2023.0,34.0,4.0,2.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2138646471', 'name': 'Ryuto Koike'}, {'authorId': '143655216', 'name': 'Masahiro Kaneko'}, {'authorId': '1764004', 'name': 'Naoaki Okazaki'}]",['Tokyo Institute of Technology'],['Japan'],2023-07
2307.11761,Yashar Deldjoo,Yashar Deldjoo,Fairness of ChatGPT and the Role Of Explainable-Guided Prompts,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Our research investigates the potential of Large-scale Language Models (LLMs), specifically OpenAI's GPT, in credit risk assessment-a binary classification task. Our findings suggest that LLMs, when directed by judiciously designed prompts and supplemented with domain-specific knowledge, can parallel the performance of traditional Machine Learning (ML) models. Intriguingly, they achieve this with significantly less data-40 times less, utilizing merely 20 data points compared to the ML's 800. LLMs particularly excel in minimizing false positives and enhancing fairness, both being vital aspects of risk analysis. While our results did not surpass those of classical ML models, they underscore the potential of LLMs in analogous tasks, laying a groundwork for future explorations into harnessing the capabilities of LLMs in diverse ML tasks. ","[{'version': 'v1', 'created': 'Fri, 14 Jul 2023 09:20:16 GMT'}]",2023-07-25,"[['Deldjoo', 'Yashar', '']]",1,1,2023-07-14,1,1,2,1,0,1,f3d5ff52104f86dcb4efe9f78490caf0481fe50b,260125378.0,https://www.semanticscholar.org/paper/f3d5ff52104f86dcb4efe9f78490caf0481fe50b,arXiv.org,2023.0,16.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2614755', 'name': 'Yashar Deldjoo'}]",['Polytechnic University of Bari'],['Italy'],2023-07
2307.11788,Jonas Stein,"Jonas Stein, Ivo Christ, Nicolas Kraus, Maximilian Balthasar Mansky,
  Robert M\""uller, Claudia Linnhoff-Popien",Applying QNLP to sentiment analysis in finance,,"QCE'23 Companion: Proceedings of the Companion IEEE International
  Conference on Quantum Computing and Engineering, 2023, 20-25",10.1109/QCE57702.2023.10178,,cs.CL cs.AI quant-ph,http://creativecommons.org/licenses/by/4.0/,"  As an application domain where the slightest qualitative improvements can yield immense value, finance is a promising candidate for early quantum advantage. Focusing on the rapidly advancing field of Quantum Natural Language Processing (QNLP), we explore the practical applicability of the two central approaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data generation approach, we conduct a case study with more than 1000 realistic sentences and find that QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results for their available software implementations. ","[{'version': 'v1', 'created': 'Thu, 20 Jul 2023 18:30:35 GMT'}, {'version': 'v2', 'created': 'Mon, 31 Jul 2023 05:50:30 GMT'}, {'version': 'v3', 'created': 'Mon, 11 Sep 2023 07:21:10 GMT'}]",2023-09-19,"[['Stein', 'Jonas', ''], ['Christ', 'Ivo', ''], ['Kraus', 'Nicolas', ''], ['Mansky', 'Maximilian Balthasar', ''], ['Müller', 'Robert', ''], ['Linnhoff-Popien', 'Claudia', '']]",1,1,2023-07-20,3,6,3,1,0,1,a816753df84ac3952a4f52a8505036e23c86edb1,260125353.0,https://www.semanticscholar.org/paper/a816753df84ac3952a4f52a8505036e23c86edb1,arXiv.org,2023.0,31.0,1.0,0.0,False,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2173870813', 'name': 'Jonas Stein'}, {'authorId': '2224650833', 'name': 'Ivo Christ'}, {'authorId': '2176869820', 'name': 'Nico Kraus'}, {'authorId': '2140297805', 'name': 'M. Mansky'}, {'authorId': '2114053260', 'name': 'Robert Müller'}, {'authorId': '1402371578', 'name': 'Claudia Linnhoff-Popien'}]",['Ludwig-Maximilians-Universität München'],['Germany'],2023-07
2307.11795,Chunyang Wu,"Yassir Fathullah, Chunyang Wu, Egor Lakomkin, Junteng Jia, Yuan
  Shangguan, Ke Li, Jinxi Guo, Wenhan Xiong, Jay Mahadeokar, Ozlem Kalinli,
  Christian Fuegen, Mike Seltzer",Prompting Large Language Models with Speech Recognition Abilities,,,,,eess.AS cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models have proven themselves highly flexible, able to solve a wide range of generative tasks, such as abstractive summarization and open-ended question answering. In this paper we extend the capabilities of LLMs by directly attaching a small audio encoder allowing it to perform speech recognition. By directly prepending a sequence of audial embeddings to the text token embeddings, the LLM can be converted to an automatic speech recognition (ASR) system, and be used in the exact same manner as its textual counterpart. Experiments on Multilingual LibriSpeech (MLS) show that incorporating a conformer encoder into the open sourced LLaMA-7B allows it to outperform monolingual baselines by 18% and perform multilingual speech recognition despite LLaMA being trained overwhelmingly on English text. Furthermore, we perform ablation studies to investigate whether the LLM can be completely frozen during training to maintain its original capabilities, scaling up the audio encoder, and increasing the audio encoder striding to generate fewer embeddings. The results from these studies show that multilingual ASR is possible even when the LLM is frozen or when strides of almost 1 second are used in the audio encoder opening up the possibility for LLMs to operate on long-form audio. ","[{'version': 'v1', 'created': 'Fri, 21 Jul 2023 08:39:15 GMT'}]",2023-07-25,"[['Fathullah', 'Yassir', ''], ['Wu', 'Chunyang', ''], ['Lakomkin', 'Egor', ''], ['Jia', 'Junteng', ''], ['Shangguan', 'Yuan', ''], ['Li', 'Ke', ''], ['Guo', 'Jinxi', ''], ['Xiong', 'Wenhan', ''], ['Mahadeokar', 'Jay', ''], ['Kalinli', 'Ozlem', ''], ['Fuegen', 'Christian', ''], ['Seltzer', 'Mike', '']]",0,0,2023-07-21,1,12,4,1,1,0,f63f37d981e2c36b1ea35f2025e55adee7906f69,260126118.0,https://www.semanticscholar.org/paper/f63f37d981e2c36b1ea35f2025e55adee7906f69,arXiv.org,2023.0,24.0,13.0,1.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1400414048', 'name': 'Yassir Fathullah'}, {'authorId': '1699859', 'name': 'Chunyang Wu'}, {'authorId': '3156707', 'name': 'Egor Lakomkin'}, {'authorId': '49222521', 'name': 'J. Jia'}, {'authorId': '3316583', 'name': 'Yuan Shangguan'}, {'authorId': '49243436', 'name': 'Ke Li'}, {'authorId': '3299398', 'name': 'Jinxi Guo'}, {'authorId': '22253126', 'name': 'Wenhan Xiong'}, {'authorId': '3222225', 'name': 'Jay Mahadeokar'}, {'authorId': '1729960', 'name': 'Ozlem Kalinli'}, {'authorId': '39547770', 'name': 'Christian Fuegen'}, {'authorId': '1727524', 'name': 'M. Seltzer'}]",['University of Cambridge'],['United Kingdom'],2023-07
2307.11991,Tin Lai,"Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu, Yichao Dou, Ziqi
  Wang",Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The demand for psychological counselling has grown significantly in recent years, particularly with the global outbreak of COVID-19, which has heightened the need for timely and professional mental health support. Online psychological counselling has emerged as the predominant mode of providing services in response to this demand. In this study, we propose the Psy-LLM framework, an AI-based assistive tool leveraging Large Language Models (LLMs) for question-answering in psychological consultation settings to ease the demand for mental health professions. Our framework combines pre-trained LLMs with real-world professional Q\&A from psychologists and extensively crawled psychological articles. The Psy-LLM framework serves as a front-end tool for healthcare professionals, allowing them to provide immediate responses and mindfulness activities to alleviate patient stress. Additionally, it functions as a screening tool to identify urgent cases requiring further assistance. We evaluated the framework using intrinsic metrics, such as perplexity, and extrinsic evaluation metrics, with human participant assessments of response helpfulness, fluency, relevance, and logic. The results demonstrate the effectiveness of the Psy-LLM framework in generating coherent and relevant answers to psychological questions. This article discusses the potential and limitations of using large language models to enhance mental health support through AI technologies. ","[{'version': 'v1', 'created': 'Sat, 22 Jul 2023 06:21:41 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Sep 2023 04:52:38 GMT'}]",2023-09-04,"[['Lai', 'Tin', ''], ['Shi', 'Yukun', ''], ['Du', 'Zicong', ''], ['Wu', 'Jiajie', ''], ['Fu', 'Ken', ''], ['Dou', 'Yichao', ''], ['Wang', 'Ziqi', '']]",0,0,2023-07-22,2,7,2,0,0,0,5473e1a50f7d9a9d5b9a1a1cc95687ce995f07e9,260125719.0,https://www.semanticscholar.org/paper/5473e1a50f7d9a9d5b9a1a1cc95687ce995f07e9,arXiv.org,2023.0,63.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2182069844', 'name': 'Tin Lai'}, {'authorId': '2189010210', 'name': 'Yukun Shi'}, {'authorId': '2162360084', 'name': 'Zicong Du'}, {'authorId': '2224670632', 'name': 'Jiajie Wu'}, {'authorId': '2224625390', 'name': 'Ken Fu'}, {'authorId': '2066362856', 'name': 'Yi-Fan Dou'}, {'authorId': '2224620203', 'name': 'Ziqi Wang'}]",['University of Sydney'],['Australia'],2023-07
2307.12057,Akide Liu,Akide Liu,External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback,"technical report, add code link. arXiv admin note: text overlap with
  arXiv:2305.11206 by other authors",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Memory is identified as a crucial human faculty that allows for the retention of visual and linguistic information within the hippocampus and neurons in the brain, which can subsequently be retrieved to address real-world challenges that arise through a lifetime of learning. The resolution of complex AI tasks through the application of acquired knowledge represents a stride toward the realization of artificial general intelligence. However, despite the prevalence of Large Language Models (LLMs) like GPT-3.5 and GPT-4 \cite{brown2020language, leiter2023chatgpt, zaitsu2023distinguishing, OpenAI2023GPT4TR} , which have displayed remarkable capabilities in language comprehension, generation, interaction, and reasoning, they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases. This paper proposes that LLMs could be augmented through the selective integration of knowledge from external repositories, and in doing so, introduces a novel methodology for External Reasoning, exemplified by ChatPDF. Central to this approach is the establishment of a tiered policy for \textbf{External Reasoning based on Multiple LLM Interchange Assistance} in \cref{fig:overall}, where the level of support rendered is modulated across entry, intermediate, and advanced tiers based on the complexity of the query, with adjustments made in response to human feedback. A comprehensive evaluation of this methodology is conducted using multiple LLMs and the results indicate state-of-the-art performance in \cref{comparison} , surpassing existing solutions including ChatPDF.com. Moreover, the paper emphasizes that this approach is more efficient compared to the direct processing of full text by LLMs. The source code is publicly available at: \url{https://github.com/AkideLiu/ANLP}. ","[{'version': 'v1', 'created': 'Wed, 5 Jul 2023 17:05:32 GMT'}, {'version': 'v2', 'created': 'Sat, 26 Aug 2023 19:29:03 GMT'}]",2023-08-29,"[['Liu', 'Akide', '']]",1,1,2023-07-05,2,1,3,2,0,2,7858a2994c740765037602c8fbaf628c8e9d9540,260125946.0,https://www.semanticscholar.org/paper/7858a2994c740765037602c8fbaf628c8e9d9540,arXiv.org,2023.0,25.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2173701426', 'name': 'Akide Liu'}]",['University of Adelaide'],['Australia'],2023-07
2307.12114,Yanis Labrak,"Yanis Labrak, Mickael Rouvier, Richard Dufour",A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks,Under review process,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/publicdomain/zero/1.0/,"  We evaluate four state-of-the-art instruction-tuned large language models (LLMs) -- ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca -- on a set of 13 real-world clinical and biomedical natural language processing (NLP) tasks in English, such as named-entity recognition (NER), question-answering (QA), relation extraction (RE), etc. Our overall results demonstrate that the evaluated LLMs begin to approach performance of state-of-the-art models in zero- and few-shot scenarios for most tasks, and particularly well for the QA task, even though they have never seen examples from these tasks before. However, we observed that the classification and RE tasks perform below what can be achieved with a specifically trained model for the medical field, such as PubMedBERT. Finally, we noted that no LLM outperforms all the others on all the studied tasks, with some models being better suited for certain tasks than others. ","[{'version': 'v1', 'created': 'Sat, 22 Jul 2023 15:58:17 GMT'}]",2023-07-25,"[['Labrak', 'Yanis', ''], ['Rouvier', 'Mickael', ''], ['Dufour', 'Richard', '']]",1,1,2023-07-22,1,3,3,7,4,3,75059feaaec7dd0a8810d8f4ec6985f5d00b73d5,260126061.0,https://www.semanticscholar.org/paper/75059feaaec7dd0a8810d8f4ec6985f5d00b73d5,arXiv.org,2023.0,52.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2139767217', 'name': 'Yanis Labrak'}, {'authorId': '1708538', 'name': 'Mickael Rouvier'}, {'authorId': '144757606', 'name': 'Richard Dufour'}]","['Nantes Université', 'Zenidoc, France', 'University of Avignon']",['France'],2023-07
2307.12267,Zijie Zeng,"Zijie Zeng, Lele Sha, Yuheng Li, Kaixun Yang, Dragan Ga\v{s}evi\'c,
  Guanliang Chen",Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education,"9 pages including references, 2 figures",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The recent large language models (LLMs), e.g., ChatGPT, have been able to generate human-like and fluent responses when provided with specific instructions. While admitting the convenience brought by technological advancement, educators also have concerns that students might leverage LLMs to complete their writing assignments and pass them off as their original work. Although many AI content detection studies have been conducted as a result of such concerns, most of these prior studies modeled AI content detection as a classification problem, assuming that a text is either entirely human-written or entirely AI-generated. In this study, we investigated AI content detection in a rarely explored yet realistic setting where the text to be detected is collaboratively written by human and generative LLMs (i.e., hybrid text). We first formalized the detection task as identifying the transition points between human-written content and AI-generated content from a given hybrid text (boundary detection). Then we proposed a two-step approach where we (1) separated AI-generated content from human-written content during the encoder training process; and (2) calculated the distances between every two adjacent prototypes and assumed that the boundaries exist between the two adjacent prototypes that have the furthest distance from each other. Through extensive experiments, we observed the following main findings: (1) the proposed approach consistently outperformed the baseline methods across different experiment settings; (2) the encoder training process can significantly boost the performance of the proposed approach; (3) when detecting boundaries for single-boundary hybrid essays, the proposed approach could be enhanced by adopting a relatively large prototype size, leading to a 22% improvement in the In-Domain evaluation and an 18% improvement in the Out-of-Domain evaluation. ","[{'version': 'v1', 'created': 'Sun, 23 Jul 2023 08:47:51 GMT'}, {'version': 'v2', 'created': 'Wed, 9 Aug 2023 11:25:30 GMT'}, {'version': 'v3', 'created': 'Fri, 11 Aug 2023 09:18:51 GMT'}, {'version': 'v4', 'created': 'Wed, 16 Aug 2023 08:44:08 GMT'}]",2023-08-17,"[['Zeng', 'Zijie', ''], ['Sha', 'Lele', ''], ['Li', 'Yuheng', ''], ['Yang', 'Kaixun', ''], ['Gašević', 'Dragan', ''], ['Chen', 'Guanliang', '']]",1,1,2023-07-23,4,6,2,1,0,1,90c7be0a840dbd9802dc108ba5bece8707054214,260735775.0,https://www.semanticscholar.org/paper/90c7be0a840dbd9802dc108ba5bece8707054214,,2023.0,36.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8647899', 'name': 'Zijie Zeng'}, {'authorId': '2111509741', 'name': 'Lele Sha'}, {'authorId': '2110538637', 'name': 'Yuheng Li'}, {'authorId': '2224678722', 'name': 'Kaixun Yang'}, {'authorId': '2230649418', 'name': ""Dragan Gavsevi'c""}, {'authorId': '1566337182', 'name': 'Guanliang Chen'}]",['Monash University'],['Australia'],2023-07
2307.12375,Jannik Kossen,"Jannik Kossen, Yarin Gal, Tom Rainforth",In-Context Learning Learns Label Relationships but Is Not Conventional Learning,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The predictions of Large Language Models (LLMs) on downstream tasks often improve significantly when including examples of the input--label relationship in the context. However, there is currently no consensus about how this in-context learning (ICL) ability of LLMs works. For example, while Xie et al. (2021) liken ICL to a general-purpose learning algorithm, Min et al. (2022) argue ICL does not even learn label relationships from in-context examples. In this paper, we provide novel insights into how ICL leverages label information, revealing both capabilities and limitations. To ensure we obtain a comprehensive picture of ICL behavior, we study probabilistic aspects of ICL predictions and thoroughly examine the dynamics of ICL as more examples are provided. Our experiments show that ICL predictions almost always depend on in-context labels, and that ICL can learn truly novel tasks in-context. However, we also find that ICL struggles to fully overcome prediction preferences acquired from pre-training data, and, further, that ICL does not consider all in-context information equally. ","[{'version': 'v1', 'created': 'Sun, 23 Jul 2023 16:54:41 GMT'}, {'version': 'v2', 'created': 'Mon, 7 Aug 2023 13:22:01 GMT'}, {'version': 'v3', 'created': 'Tue, 3 Oct 2023 08:19:44 GMT'}]",2023-10-04,"[['Kossen', 'Jannik', ''], ['Gal', 'Yarin', ''], ['Rainforth', 'Tom', '']]",0,0,2023-07-23,3,3,3,0,0,0,cf7368f38cc1f0861d4b35db1307776c7f3f237d,260125327.0,https://www.semanticscholar.org/paper/cf7368f38cc1f0861d4b35db1307776c7f3f237d,,2023.0,67.0,2.0,1.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064853201', 'name': 'Jannik Kossen'}, {'authorId': '2681954', 'name': 'Y. Gal'}, {'authorId': '2358794', 'name': 'Tom Rainforth'}]",['University of Oxford'],['United Kingdom'],2023-07
2307.12469,Cen Zhang,"Cen Zhang, Mingqiang Bai, Yaowen Zheng, Yeting Li, Xiaofei Xie,
  Yuekang Li, Wei Ma, Limin Sun, Yang Liu",Understanding Large Language Model Based Fuzz Driver Generation,"12 pages, 13 figures",,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Fuzz drivers are necessary for library API fuzzing. Automatic fuzz driver generation is challenging since it requires generating high quality API usage code which is correct and robust. Large language model based fuzz driver generator is a promising direction. Compared to traditional program analysis based generators, it is a text-based approach which is more lightweight and general. It can easily leverage various sources of API usage information for generation and generate human-friendly code. Nonetheless, there still lacks the basic understanding on this direction. To fill this gap, we did a study aiming the core issues of using LLMs on effective fuzz driver generation. For systematic understanding, 5 query strategies are designed and analyzed from basic to enhanced. For evaluation in scale, we built a semi-automatic framework, containing a quiz with 86 driver generation questions collected from 30 popular C projects, and a set of criteria for precise driver effectiveness validation. In total, 189,628 fuzz drivers using 0.22 billion tokens are generated and evaluated. Besides, generated drivers were compared with industrial used ones to obtain practical insights (3.12 CPU year fuzzing experiments). Our study revealed: 1) LLM-based generation has shown promising practicality. 64% questions can be solved entirely automatically and the number rises to 91% if manual semantic validators are incorporated. Moreover, the generated drivers exhibited competitive performance to those commonly employed in the industry; 2) LLMs struggle to generate fuzz drivers that require complex API usage specifics. Three key designs can help: repeatedly querying, querying with examples, and iteratively querying. Combining them yields a dominant strategy; 3) Significant rooms for improvement are still left, such as automatic semantic correctness validation, API usage expansion, and semantic oracle generation. ","[{'version': 'v1', 'created': 'Mon, 24 Jul 2023 01:49:05 GMT'}, {'version': 'v2', 'created': 'Sun, 6 Aug 2023 04:42:58 GMT'}]",2023-08-08,"[['Zhang', 'Cen', ''], ['Bai', 'Mingqiang', ''], ['Zheng', 'Yaowen', ''], ['Li', 'Yeting', ''], ['Xie', 'Xiaofei', ''], ['Li', 'Yuekang', ''], ['Ma', 'Wei', ''], ['Sun', 'Limin', ''], ['Liu', 'Yang', '']]",0,0,2023-07-24,2,9,1,0,0,0,953de78b58e35e9ca021ba7e32f66af0ffa17172,260126020.0,https://www.semanticscholar.org/paper/953de78b58e35e9ca021ba7e32f66af0ffa17172,arXiv.org,2023.0,38.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2109269289', 'name': 'Cen Zhang'}, {'authorId': '2224609210', 'name': 'Mingqiang Bai'}, {'authorId': '8499465', 'name': 'Yaowen Zheng'}, {'authorId': '47001735', 'name': 'Yeting Li'}, {'authorId': '49419199', 'name': 'Xiaofei Xie'}, {'authorId': '22799258', 'name': 'Yuekang Li'}, {'authorId': '2111665481', 'name': 'Wei Ma'}, {'authorId': '2148908062', 'name': 'Limin Sun'}, {'authorId': '46399749', 'name': 'Yang Liu'}]","['UNSW Sydney', 'Nanyang Technological University']","['Singapore', 'Australia']",2023-07
2307.12701,Alessandro Berti Mr,"Alessandro Berti, Mahnaz Sadat Qafari",Leveraging Large Language Models (LLMs) for Process Mining (Technical Report),,,,,cs.DB,http://creativecommons.org/licenses/by/4.0/,"  This technical report describes the intersection of process mining and large language models (LLMs), specifically focusing on the abstraction of traditional and object-centric process mining artifacts into textual format. We introduce and explore various prompting strategies: direct answering, where the large language model directly addresses user queries; multi-prompt answering, which allows the model to incrementally build on the knowledge obtained through a series of prompts; and the generation of database queries, facilitating the validation of hypotheses against the original event log.   Our assessment considers two large language models, GPT-4 and Google's Bard, under various contextual scenarios across all prompting strategies. Results indicate that these models exhibit a robust understanding of key process mining abstractions, with notable proficiency in interpreting both declarative and procedural process models.   In addition, we find that both models demonstrate strong performance in the object-centric setting, which could significantly propel the advancement of the object-centric process mining discipline.   Additionally, these models display a noteworthy capacity to evaluate various concepts of fairness in process mining. This opens the door to more rapid and efficient assessments of the fairness of process mining event logs, which has significant implications for the field.   The integration of these large language models into process mining applications may open new avenues for exploration, innovation, and insight generation in the field. ","[{'version': 'v1', 'created': 'Mon, 24 Jul 2023 11:36:22 GMT'}]",2023-07-25,"[['Berti', 'Alessandro', ''], ['Qafari', 'Mahnaz Sadat', '']]",0,1,2023-07-24,1,2,1,1,0,1,060c2264f21f16523ed7c194e78fabc90a982c2f,260125013.0,https://www.semanticscholar.org/paper/060c2264f21f16523ed7c194e78fabc90a982c2f,arXiv.org,2023.0,55.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2737693', 'name': 'A. Berti'}, {'authorId': '1388378964', 'name': 'Mahnaz Sadat Qafari'}]","['RWTH Aachen University', 'Fraunhofer Institute for Applied Information Technology', 'Konrad-Adenauer-Straße, Sankt Augustin, 53757, NRW, Germany.']",['Germany'],2023-07
2307.12776,Valerio Capraro,"Valerio Capraro, Roberto Di Paolo, Veronica Pizziol",Predict-AI-bility of how humans balance self-interest with the interest of others,,,,,econ.GN cs.AI cs.CY cs.GT q-fin.EC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Generative artificial intelligence holds enormous potential to revolutionize decision-making processes, from everyday to high-stake scenarios. However, as many decisions carry social implications, for AI to be a reliable assistant for decision-making it is crucial that it is able to capture the balance between self-interest and the interest of others. We investigate the ability of three of the most advanced chatbots to predict dictator game decisions across 78 experiments with human participants from 12 countries. We find that only GPT-4 (not Bard nor Bing) correctly captures qualitative behavioral patterns, identifying three major classes of behavior: self-interested, inequity-averse, and fully altruistic. Nonetheless, GPT-4 consistently overestimates other-regarding behavior, inflating the proportion of inequity-averse and fully altruistic participants. This bias has significant implications for AI developers and users. ","[{'version': 'v1', 'created': 'Fri, 21 Jul 2023 13:23:31 GMT'}]",2023-07-25,"[['Capraro', 'Valerio', ''], ['Di Paolo', 'Roberto', ''], ['Pizziol', 'Veronica', '']]",0,1,2023-07-21,1,3,5,1,0,1,ede94c6c717fc3f5819c0ea35cc0b7918219cc98,260124981.0,https://www.semanticscholar.org/paper/ede94c6c717fc3f5819c0ea35cc0b7918219cc98,Social Science Research Network,2023.0,66.0,0.0,0.0,True,"['Computer Science', 'Economics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Economics', 'source': 's2-fos-model'}]","[{'authorId': '31558629', 'name': 'V. Capraro'}, {'authorId': '2094281620', 'name': 'R. D. Paolo'}, {'authorId': '2132244378', 'name': 'Veronica Pizziol'}]","['University of Milan', 'University of Bologna', 'IMT School for Advanced Studies Lucca']",['Italy'],2023-07
2307.12798,Andrea Bacciu,"Andrea Bacciu, Florin Cuconasu, Federico Siciliano, Fabrizio
  Silvestri, Nicola Tonellotto, Giovanni Trappolini",RRAML: Reinforced Retrieval Augmented Machine Learning,,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  The emergence of large language models (LLMs) has revolutionized machine learning and related fields, showcasing remarkable abilities in comprehending, generating, and manipulating human language. However, their conventional usage through API-based text prompt submissions imposes certain limitations in terms of context constraints and external source availability. To address these challenges, we propose a novel framework called Reinforced Retrieval Augmented Machine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs with supporting information retrieved by a purpose-built retriever from a vast user-provided database. By leveraging recent advancements in reinforcement learning, our method effectively addresses several critical challenges. Firstly, it circumvents the need for accessing LLM gradients. Secondly, our method alleviates the burden of retraining LLMs for specific tasks, as it is often impractical or impossible due to restricted access to the model and the computational intensity involved. Additionally we seamlessly link the retriever's task with the reasoner, mitigating hallucinations and reducing irrelevant, and potentially damaging retrieved documents. We believe that the research agenda outlined in this paper has the potential to profoundly impact the field of AI, democratizing access to and utilization of LLMs for a wide range of entities. ","[{'version': 'v1', 'created': 'Mon, 24 Jul 2023 13:51:19 GMT'}, {'version': 'v2', 'created': 'Tue, 25 Jul 2023 05:42:34 GMT'}, {'version': 'v3', 'created': 'Thu, 27 Jul 2023 07:20:28 GMT'}]",2023-07-28,"[['Bacciu', 'Andrea', ''], ['Cuconasu', 'Florin', ''], ['Siciliano', 'Federico', ''], ['Silvestri', 'Fabrizio', ''], ['Tonellotto', 'Nicola', ''], ['Trappolini', 'Giovanni', '']]",0,0,2023-07-24,3,6,2,0,0,0,808ae6428998eac3a609d91b7c7364795abeee3f,260125198.0,https://www.semanticscholar.org/paper/808ae6428998eac3a609d91b7c7364795abeee3f,arXiv.org,2023.0,27.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151426607', 'name': 'Andrea Bacciu'}, {'authorId': '2224626776', 'name': 'Florin Cocunasu'}, {'authorId': '1752951302', 'name': 'F. Siciliano'}, {'authorId': '2192306989', 'name': 'Fabrizio Silvestri'}, {'authorId': '2783910', 'name': 'N. Tonellotto'}, {'authorId': '120709579', 'name': 'Giovanni Trappolini'}]","['Sapienza University of Rome', 'University of Pisa']",['Italy'],2023-07
2307.12856,Hiroki Furuta,"Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka
  Matsuo, Douglas Eck, Aleksandra Faust","A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis",,,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation. However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML. We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions. WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those. We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization. We empirically demonstrate that our modular recipe improves the success on real websites by over 50%, and that HTML-T5 is the best model to solve various HTML understanding tasks; achieving 18.7% higher success rate than the prior method on MiniWoB web automation benchmark, and SoTA performance on Mind2Web, an offline task planning evaluation. ","[{'version': 'v1', 'created': 'Mon, 24 Jul 2023 14:56:30 GMT'}, {'version': 'v2', 'created': 'Sun, 1 Oct 2023 10:30:27 GMT'}, {'version': 'v3', 'created': 'Tue, 3 Oct 2023 03:51:14 GMT'}]",2023-10-04,"[['Gur', 'Izzeddin', ''], ['Furuta', 'Hiroki', ''], ['Huang', 'Austin', ''], ['Safdari', 'Mustafa', ''], ['Matsuo', 'Yutaka', ''], ['Eck', 'Douglas', ''], ['Faust', 'Aleksandra', '']]",0,0,2023-07-24,3,7,3,5,1,4,a53c8ba374d430d6c3786d13c04edb200d547750,260126067.0,https://www.semanticscholar.org/paper/a53c8ba374d430d6c3786d13c04edb200d547750,arXiv.org,2023.0,99.0,21.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3737312', 'name': 'Izzeddin Gur'}, {'authorId': '2052903664', 'name': 'Hiroki Furuta'}, {'authorId': '2054859790', 'name': 'Austin Huang'}, {'authorId': '2093894693', 'name': 'Mustafa Safdari'}, {'authorId': '2153732825', 'name': 'Yutaka Matsuo'}, {'authorId': '2396681', 'name': 'D. Eck'}, {'authorId': '145520045', 'name': 'Aleksandra Faust'}]",['The University of Tokyo'],['Japan'],2023-07
2307.13106,"Petter T\""ornberg","Petter T\""ornberg",How to use LLMs for Text Analysis,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This guide introduces Large Language Models (LLM) as a highly versatile text analysis method within the social sciences. As LLMs are easy-to-use, cheap, fast, and applicable on a broad range of text analysis tasks, ranging from text annotation and classification to sentiment analysis and critical discourse analysis, many scholars believe that LLMs will transform how we do text analysis. This how-to guide is aimed at students and researchers with limited programming experience, and offers a simple introduction to how LLMs can be used for text analysis in your own research project, as well as advice on best practices. We will go through each of the steps of analyzing textual data with LLMs using Python: installing the software, setting up the API, loading the data, developing an analysis prompt, analyzing the text, and validating the results. As an illustrative example, we will use the challenging task of identifying populism in political texts, and show how LLMs move beyond the existing state-of-the-art. ","[{'version': 'v1', 'created': 'Mon, 24 Jul 2023 19:54:15 GMT'}]",2023-07-26,"[['Törnberg', 'Petter', '']]",0,0,2023-07-24,1,1,2,0,0,0,b5961c022e67ee638cf0641086b697af46a6dc8e,260155374.0,https://www.semanticscholar.org/paper/b5961c022e67ee638cf0641086b697af46a6dc8e,,2023.0,28.0,2.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2214288112', 'name': 'Petter Tornberg'}]",['University of Amsterdam'],['Netherlands'],2023-07
2307.13714,G\'abor Bella,"Paula Helm, G\'abor Bella, Gertraud Koch, Fausto Giunchiglia",Diversity and Language Technology: How Techno-Linguistic Bias Can Cause Epistemic Injustice,arXiv admin note: text overlap with arXiv:2307.13405,,,,cs.CY cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  It is well known that AI-based language technology -- large language models, machine translation systems, multilingual dictionaries, and corpora -- is currently limited to 2 to 3 percent of the world's most widely spoken and/or financially and politically best supported languages. In response, recent research efforts have sought to extend the reach of AI technology to ``underserved languages.'' In this paper, we show that many of these attempts produce flawed solutions that adhere to a hard-wired representational preference for certain languages, which we call techno-linguistic bias. Techno-linguistic bias is distinct from the well-established phenomenon of linguistic bias as it does not concern the languages represented but rather the design of the technologies. As we show through the paper, techno-linguistic bias can result in systems that can only express concepts that are part of the language and culture of dominant powers, unable to correctly represent concepts from other communities. We argue that at the root of this problem lies a systematic tendency of technology developer communities to apply a simplistic understanding of diversity which does not do justice to the more profound differences that languages, and ultimately the communities that speak them, embody. Drawing on the concept of epistemic injustice, we point to the broader sociopolitical consequences of the bias we identify and show how it can lead not only to a disregard for valuable aspects of diversity but also to an under-representation of the needs and diverse worldviews of marginalized language communities. ","[{'version': 'v1', 'created': 'Tue, 25 Jul 2023 16:08:27 GMT'}]",2023-07-27,"[['Helm', 'Paula', ''], ['Bella', 'Gábor', ''], ['Koch', 'Gertraud', ''], ['Giunchiglia', 'Fausto', '']]",0,0,2023-07-25,1,4,2,0,0,0,37feb42ac5946894e3eb2451269173b1302a79ae,260165001.0,https://www.semanticscholar.org/paper/37feb42ac5946894e3eb2451269173b1302a79ae,arXiv.org,2023.0,57.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2091918122', 'name': 'P. Helm'}, {'authorId': '21693058', 'name': 'Gábor Bella'}, {'authorId': '2054250304', 'name': 'G. Koch'}, {'authorId': '1720285', 'name': 'Fausto Giunchiglia'}]","['University of Amsterdam', 'IMT Atlantique', 'Universität Hamburg', 'University of Trento']","['Germany', 'Netherlands', 'France', 'Italy']",2023-07
2308.10022,Ting Zhang,"Ting Zhang, Ivana Clairine Irsan, Ferdian Thung, David Lo",Cupid: Leveraging ChatGPT for More Accurate Duplicate Bug Report Detection,Recently submitted to TOSEM,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Duplicate bug report detection (DBRD) is a long-standing challenge in both academia and industry. Over the past decades, researchers have proposed various approaches to detect duplicate bug reports more accurately. With the recent advancement of deep learning, researchers have also proposed several approaches that leverage deep learning models to detect duplicate bug reports. A recent benchmarking study on DBRD also reveals that the performance of deep learning-based approaches is not always better than the traditional approaches. However, traditional approaches have limitations, e.g., they are usually based on the bag-of-words model, which cannot capture the semantics of bug reports. To address these aforementioned challenges, we seek to leverage state-of-the-art large language model to improve the performance of the traditional DBRD approach.   In this paper, we propose an approach called Cupid, which combines the best-performing traditional DBRD approach REP with the state-of-the-art large language model ChatGPT. Specifically, we first leverage ChatGPT under the zero-shot setting to get essential information on bug reports. We then use the essential information as the input of REP to detect duplicate bug reports. We conducted an evaluation on comparing Cupid with three existing approaches on three datasets. The experimental results show that Cupid achieves new state-of-the-art results, reaching Recall Rate@10 scores ranging from 0.59 to 0.67 across all the datasets analyzed. Our work highlights the potential of combining large language models to improve the performance of software engineering tasks. ","[{'version': 'v1', 'created': 'Sat, 19 Aug 2023 14:16:30 GMT'}, {'version': 'v2', 'created': 'Sun, 27 Aug 2023 13:58:55 GMT'}]",2023-08-29,"[['Zhang', 'Ting', ''], ['Irsan', 'Ivana Clairine', ''], ['Thung', 'Ferdian', ''], ['Lo', 'David', '']]",1,1,2023-08-19,2,4,1,1,0,1,76426af4c1aea5b0b52321973eaa1cc4a4e6444d,261049538.0,https://www.semanticscholar.org/paper/76426af4c1aea5b0b52321973eaa1cc4a4e6444d,arXiv.org,2023.0,81.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146322053', 'name': 'Ting Zhang'}, {'authorId': '9223952', 'name': 'I. Irsan'}, {'authorId': '2121315', 'name': 'Ferdian Thung'}, {'authorId': '2150912791', 'name': 'David Lo'}]","['FERDIAN THUNG, Singapore', 'Singapore Management University']",['Singapore'],2023-08
2308.10092,Zachary Yang,"Hao Yu, Zachary Yang, Kellin Pelrine, Jean Francois Godbout, Reihaneh
  Rabbany","Open, Closed, or Small Language Models for Text Classification?","14 pages, 15 Tables, 1 Figure",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Recent advancements in large language models have demonstrated remarkable capabilities across various NLP tasks. But many questions remain, including whether open-source models match closed ones, why these models excel or struggle with certain tasks, and what types of practical procedures can improve performance. We address these questions in the context of classification by evaluating three classes of models using eight datasets across three distinct tasks: named entity recognition, political party prediction, and misinformation detection. While larger LLMs often lead to improved performance, open-source models can rival their closed-source counterparts by fine-tuning. Moreover, supervised smaller models, like RoBERTa, can achieve similar or even greater performance in many datasets compared to generative LLMs. On the other hand, closed models maintain an advantage in hard tasks that demand the most generalizability. This study underscores the importance of model selection based on task requirements ","[{'version': 'v1', 'created': 'Sat, 19 Aug 2023 18:58:32 GMT'}]",2023-08-22,"[['Yu', 'Hao', ''], ['Yang', 'Zachary', ''], ['Pelrine', 'Kellin', ''], ['Godbout', 'Jean Francois', ''], ['Rabbany', 'Reihaneh', '']]",0,0,2023-08-19,1,5,2,0,0,0,3af09b9c1dcc3c0177cc46c274be27596b3ab168,261049379.0,https://www.semanticscholar.org/paper/3af09b9c1dcc3c0177cc46c274be27596b3ab168,arXiv.org,2023.0,51.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2110750027', 'name': 'Hao Yu'}, {'authorId': '2155115994', 'name': 'Zachary Yang'}, {'authorId': '104333826', 'name': 'Kellin Pelrine'}, {'authorId': '2028704969', 'name': 'J. Godbout'}, {'authorId': '2490772', 'name': 'Reihaneh Rabbany'}]","['McGill University', 'University of Milan', 'Université de Montréal']","['Canada', 'Italy']",2023-08
2308.10354,Zeinab Sadat Taghavi,"Zeinab Sadat Taghavi, Soroush Gooran, Seyed Arshan Dalili, Hamidreza
  Amirzadeh, Mohammad Jalal Nematbakhsh, Hossein Sameti",Imaginations of WALL-E : Reconstructing Experiences with an Imagination-Inspired Module for Advanced AI Systems,"18 pages,",,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this paper, we introduce a novel Artificial Intelligence (AI) system inspired by the philosophical and psychoanalytical concept of imagination as a ``Re-construction of Experiences"". Our AI system is equipped with an imagination-inspired module that bridges the gap between textual inputs and other modalities, enriching the derived information based on previously learned experiences. A unique feature of our system is its ability to formulate independent perceptions of inputs. This leads to unique interpretations of a concept that may differ from human interpretations but are equally valid, a phenomenon we term as ``Interpretable Misunderstanding"". We employ large-scale models, specifically a Multimodal Large Language Model (MLLM), enabling our proposed system to extract meaningful information across modalities while primarily remaining unimodal. We evaluated our system against other large language models across multiple tasks, including emotion recognition and question-answering, using a zero-shot methodology to ensure an unbiased scenario that may happen by fine-tuning. Significantly, our system outperformed the best Large Language Models (LLM) on the MELD, IEMOCAP, and CoQA datasets, achieving Weighted F1 (WF1) scores of 46.74%, 25.23%, and Overall F1 (OF1) score of 17%, respectively, compared to 22.89%, 12.28%, and 7% from the well-performing LLM. The goal is to go beyond the statistical view of language processing and tie it to human concepts such as philosophy and psychoanalysis. This work represents a significant advancement in the development of imagination-inspired AI systems, opening new possibilities for AI to generate deep and interpretable information across modalities, thereby enhancing human-AI interaction. ","[{'version': 'v1', 'created': 'Sun, 20 Aug 2023 20:10:55 GMT'}]",2023-08-22,"[['Taghavi', 'Zeinab Sadat', ''], ['Gooran', 'Soroush', ''], ['Dalili', 'Seyed Arshan', ''], ['Amirzadeh', 'Hamidreza', ''], ['Nematbakhsh', 'Mohammad Jalal', ''], ['Sameti', 'Hossein', '']]",0,0,2023-08-20,1,6,2,0,0,0,53adaabb301a91c606dfef8fdae97b8b7c031e7b,261049486.0,https://www.semanticscholar.org/paper/53adaabb301a91c606dfef8fdae97b8b7c031e7b,arXiv.org,2023.0,49.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '7840758', 'name': 'Zeinab Taghavi'}, {'authorId': '41093374', 'name': 'S. Gooran'}, {'authorId': '2221318341', 'name': 'Seyed Arshan Dalili'}, {'authorId': '2232783711', 'name': 'Hamidreza Amirzadeh'}, {'authorId': '2232782679', 'name': 'Mohammad Jalal Nematbakhsh'}, {'authorId': '3096615', 'name': 'H. Sameti'}]",['Sharif University of Technology'],['Iran'],2023-08
2308.10435,Nathalia Nascimento,Nathalia Nascimento and Paulo Alencar and Donald Cowan,GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems,8 pages,,,,cs.MA cs.AI cs.NE cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper introduces the ""GPT-in-the-loop"" approach, a novel method combining the advanced reasoning capabilities of Large Language Models (LLMs) like Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems. Venturing beyond traditional adaptive approaches that generally require long training processes, our framework employs GPT-4 for enhanced problem-solving and explanation skills. Our experimental backdrop is the smart streetlight Internet of Things (IoT) application. Here, agents use sensors, actuators, and neural networks to create an energy-efficient lighting system. By integrating GPT-4, these agents achieve superior decision-making and adaptability without the need for extensive training. We compare this approach with both traditional neuroevolutionary methods and solutions provided by software engineers, underlining the potential of GPT-driven multiagent systems in IoT. Structurally, the paper outlines the incorporation of GPT into the agent-driven Framework for the Internet of Things (FIoT), introduces our proposed GPT-in-the-loop approach, presents comparative results in the IoT context, and concludes with insights and future directions. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 03:08:16 GMT'}]",2023-08-22,"[['Nascimento', 'Nathalia', ''], ['Alencar', 'Paulo', ''], ['Cowan', 'Donald', '']]",0,1,2023-08-21,1,3,4,1,0,1,c06e4e187f4dddb3b67ba4932ef2b096f146c20f,261048710.0,https://www.semanticscholar.org/paper/c06e4e187f4dddb3b67ba4932ef2b096f146c20f,arXiv.org,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2658311', 'name': 'N. Nascimento'}, {'authorId': '2149928820', 'name': 'Paulo S. C. Alencar'}, {'authorId': '2149928782', 'name': 'Donald D. Cowan'}]",['University of Waterloo'],['Canada'],2023-08
2308.10443,Wesley Joon-Wie Tann,"Wesley Tann, Yuancheng Liu, Jun Heng Sim, Choon Meng Seah, Ee-Chien
  Chang",Using Large Language Models for Cybersecurity Capture-The-Flag Challenges and Certification Questions,,,,,cs.AI cs.CL cs.CY,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The assessment of cybersecurity Capture-The-Flag (CTF) exercises involves participants finding text strings or ``flags'' by exploiting system vulnerabilities. Large Language Models (LLMs) are natural-language models trained on vast amounts of words to understand and generate text; they can perform well on many CTF challenges. Such LLMs are freely available to students. In the context of CTF exercises in the classroom, this raises concerns about academic integrity. Educators must understand LLMs' capabilities to modify their teaching to accommodate generative AI assistance. This research investigates the effectiveness of LLMs, particularly in the realm of CTF challenges and questions. Here we evaluate three popular LLMs, OpenAI ChatGPT, Google Bard, and Microsoft Bing. First, we assess the LLMs' question-answering performance on five Cisco certifications with varying difficulty levels. Next, we qualitatively study the LLMs' abilities in solving CTF challenges to understand their limitations. We report on the experience of using the LLMs for seven test cases in all five types of CTF challenges. In addition, we demonstrate how jailbreak prompts can bypass and break LLMs' ethical safeguards. The paper concludes by discussing LLM's impact on CTF exercises and its implications. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 03:30:21 GMT'}]",2023-08-22,"[['Tann', 'Wesley', ''], ['Liu', 'Yuancheng', ''], ['Sim', 'Jun Heng', ''], ['Seah', 'Choon Meng', ''], ['Chang', 'Ee-Chien', '']]",1,1,2023-08-21,1,5,3,1,0,1,e64df7e9448f7a9a4cb5d22c21c460134c8646ac,261049087.0,https://www.semanticscholar.org/paper/e64df7e9448f7a9a4cb5d22c21c460134c8646ac,arXiv.org,2023.0,18.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '68972525', 'name': 'W. Tann'}, {'authorId': '2143861019', 'name': 'Yuancheng Liu'}, {'authorId': '2232779982', 'name': 'Jun Heng Sim'}, {'authorId': '120632009', 'name': 'C. Seah'}, {'authorId': '144556100', 'name': 'E. Chang'}]","['National University of Singapore', 'National Cybersecurity R&D Lab Singapore']",['Singapore'],2023-08
2308.10462,Martin Weyssow,"Martin Weyssow, Xin Zhou, Kisub Kim, David Lo and Houari Sahraoui",Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models,10+2 pages,,,,cs.SE cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) possess impressive capabilities to generate meaningful code snippets given natural language intents in zero-shot, i.e., without the need for specific fine-tuning. In the perspective of unleashing their full potential, prior work has demonstrated the benefits of fine-tuning the models to task-specific data. However, fine-tuning process demands heavy computational costs and is intractable when resources are scarce, especially for models with billions of parameters. In light of these challenges, previous studies explored In-Context Learning (ICL) as an effective strategy to generate contextually appropriate code without fine-tuning. However, it operates at inference time and does not involve learning task-specific parameters, potentially limiting the model's performance on downstream tasks. In this context, we foresee that Parameter-Efficient Fine-Tuning (PEFT) techniques carry a high potential for efficiently specializing LLMs to task-specific data. In this paper, we deliver a comprehensive study of LLMs with the impact of PEFT techniques under the automated code generation scenario. Our experimental results reveal the superiority and potential of such techniques over ICL on a wide range of LLMs in reducing the computational burden and improving performance. Therefore, the study opens opportunities for broader applications of PEFT in software engineering scenarios. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 04:31:06 GMT'}]",2023-08-22,"[['Weyssow', 'Martin', ''], ['Zhou', 'Xin', ''], ['Kim', 'Kisub', ''], ['Lo', 'David', ''], ['Sahraoui', 'Houari', '']]",0,0,2023-08-21,1,5,3,0,0,0,9a7b9515b66bf83c9c808626206eabe9a8837c22,261048999.0,https://www.semanticscholar.org/paper/9a7b9515b66bf83c9c808626206eabe9a8837c22,arXiv.org,2023.0,87.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1820831988', 'name': 'M. Weyssow'}, {'authorId': '2148928671', 'name': 'Xin Zhou'}, {'authorId': '35276441', 'name': 'Kisub Kim'}, {'authorId': '2150912791', 'name': 'David Lo'}, {'authorId': '9460712', 'name': 'H. Sahraoui'}]","['Université de Montréal', 'Knowledge Innovation Market', 'Singapore Management University']","['Canada', 'Singapore', 'Spain']",2023-08
2308.10633,Yasuto Hoshi,"Yasuto Hoshi, Daisuke Miyashita, Youyang Ng, Kento Tatsuno, Yasuhiro
  Morioka, Osamu Torii, Jun Deguchi",RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models,"18 pages, 2 figures, see https://youtu.be/JYbm75qnfTg for the
  demonstration screencast",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Retrieval-augmented large language models (R-LLMs) combine pre-trained large language models (LLMs) with information retrieval systems to improve the accuracy of factual question-answering. However, current libraries for building R-LLMs provide high-level abstractions without sufficient transparency for evaluating and optimizing prompts within specific inference processes such as retrieval and generation. To address this gap, we present RaLLe, an open-source framework designed to facilitate the development, evaluation, and optimization of R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily develop and evaluate R-LLMs, improving hand-crafted prompts, assessing individual inference processes, and objectively measuring overall system performance quantitatively. By leveraging these features, developers can enhance the performance and accuracy of their R-LLMs in knowledge-intensive generation tasks. We open-source our code at https://github.com/yhoshi3/RaLLe. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 11:08:16 GMT'}]",2023-08-22,"[['Hoshi', 'Yasuto', ''], ['Miyashita', 'Daisuke', ''], ['Ng', 'Youyang', ''], ['Tatsuno', 'Kento', ''], ['Morioka', 'Yasuhiro', ''], ['Torii', 'Osamu', ''], ['Deguchi', 'Jun', '']]",0,0,2023-08-21,1,7,2,0,0,0,c055baf5e8586edace51d1a7720de3c4ed345d72,261049520.0,https://www.semanticscholar.org/paper/c055baf5e8586edace51d1a7720de3c4ed345d72,arXiv.org,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2211101536', 'name': 'Yasuto Hoshi'}, {'authorId': '2441156', 'name': 'D. Miyashita'}, {'authorId': '20556792', 'name': 'Youyang Ng'}, {'authorId': '2232784235', 'name': 'Kento Tatsuno'}, {'authorId': '51194024', 'name': 'Yasuhiro Morioka'}, {'authorId': '2422593', 'name': 'Osamu Torii'}, {'authorId': '49192096', 'name': 'J. Deguchi'}]","['Kioxia Corporation, Japan']",['Japan'],2023-08
2308.10741,Christian Schlarmann,Christian Schlarmann and Matthias Hein,On the Adversarial Robustness of Multi-Modal Foundation Models,ICCV AROW 2023,,,,cs.LG cs.AI cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Multi-modal foundation models combining vision and language models such as Flamingo or GPT-4 have recently gained enormous interest. Alignment of foundation models is used to prevent models from providing toxic or harmful output. While malicious users have successfully tried to jailbreak foundation models, an equally important question is if honest users could be harmed by malicious third-party content. In this paper we show that imperceivable attacks on images in order to change the caption output of a multi-modal foundation model can be used by malicious content providers to harm honest users e.g. by guiding them to malicious websites or broadcast fake information. This indicates that countermeasures to adversarial attacks should be used by any deployed multi-modal foundation model. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 14:09:09 GMT'}]",2023-08-22,"[['Schlarmann', 'Christian', ''], ['Hein', 'Matthias', '']]",0,1,2023-08-21,1,2,3,1,0,1,5690e35b8beab92a80055fe2530c29c24e495379,261048835.0,https://www.semanticscholar.org/paper/5690e35b8beab92a80055fe2530c29c24e495379,arXiv.org,2023.0,42.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2232781936', 'name': 'Christian Schlarmann'}, {'authorId': '143610806', 'name': 'Matthias Hein'}]",['University of Tübingen'],['Germany'],2023-08
2308.10758,Anxo Perez AnxoPerez,"Anxo P\'erez, Marcos Fern\'andez-Pichel, Javier Parapar, David E.
  Losada",DepreSym: A Depression Symptom Annotated Corpus and the Role of LLMs as Assessors of Psychological Markers,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Computational methods for depression detection aim to mine traces of depression from online publications posted by Internet users. However, solutions trained on existing collections exhibit limited generalisation and interpretability. To tackle these issues, recent studies have shown that identifying depressive symptoms can lead to more robust models. The eRisk initiative fosters research on this area and has recently proposed a new ranking task focused on developing search methods to find sentences related to depressive symptoms. This search challenge relies on the symptoms specified by the Beck Depression Inventory-II (BDI-II), a questionnaire widely used in clinical practice. Based on the participant systems' results, we present the DepreSym dataset, consisting of 21580 sentences annotated according to their relevance to the 21 BDI-II symptoms. The labelled sentences come from a pool of diverse ranking methods, and the final dataset serves as a valuable resource for advancing the development of models that incorporate depressive markers such as clinical symptoms. Due to the complex nature of this relevance annotation, we designed a robust assessment methodology carried out by three expert assessors (including an expert psychologist). Additionally, we explore here the feasibility of employing recent Large Language Models (ChatGPT and GPT4) as potential assessors in this complex task. We undertake a comprehensive examination of their performance, determine their main limitations and analyze their role as a complement or replacement for human annotators. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 14:44:31 GMT'}]",2023-08-22,"[['Pérez', 'Anxo', ''], ['Fernández-Pichel', 'Marcos', ''], ['Parapar', 'Javier', ''], ['Losada', 'David E.', '']]",1,1,2023-08-21,1,4,2,2,0,2,2597053a697ff3f2dc2ffd200b97eed0b3da333d,261048669.0,https://www.semanticscholar.org/paper/2597053a697ff3f2dc2ffd200b97eed0b3da333d,arXiv.org,2023.0,0.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2190771581', 'name': ""Anxo P'erez""}, {'authorId': '2232779965', 'name': ""Marcos Fern'andez-Pichel""}, {'authorId': '1898621', 'name': 'Javier Parapar'}, {'authorId': '2356644', 'name': 'D. Losada'}]","['Marcos Fernández-Pichel, David E. Losada', 'University of A Coruña', 'University of Santiago de Compostela']",['Spain'],2023-08
2308.10783,Md. Arid Hasan,"Md. Arid Hasan, Shudipta Das, Afiyat Anjum, Firoj Alam, Anika Anjum,
  Avijit Sarker, Sheak Rashed Haider Noori",Zero- and Few-Shot Prompting with LLMs: A Comparative Study with Fine-tuned Models for Bangla Sentiment Analysis,"Zero-Shot Prompting, Few-Shot Prompting, LLMs, Comparative Study,
  Fine-tuned Models, Bangla, Sentiment Analysis",,,,cs.CL cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The rapid expansion of the digital world has propelled sentiment analysis into a critical tool across diverse sectors such as marketing, politics, customer service, and healthcare. While there have been significant advancements in sentiment analysis for widely spoken languages, low-resource languages, such as Bangla, remain largely under-researched due to resource constraints. Furthermore, the recent unprecedented performance of Large Language Models (LLMs) in various applications highlights the need to evaluate them in the context of low-resource languages. In this study, we present a sizeable manually annotated dataset encompassing 33,605 Bangla news tweets and Facebook comments. We also investigate zero- and few-shot in-context learning with several language models, including Flan-T5, GPT-4, and Bloomz, offering a comparative analysis against fine-tuned models. Our findings suggest that monolingual transformer-based models consistently outperform other models, even in zero and few-shot scenarios. To foster continued exploration, we intend to make this dataset and our research tools publicly available to the broader research community. In the spirit of further research, we plan to make this dataset and our experimental resources publicly accessible to the wider research community. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 15:19:10 GMT'}]",2023-08-22,"[['Hasan', 'Md. Arid', ''], ['Das', 'Shudipta', ''], ['Anjum', 'Afiyat', ''], ['Alam', 'Firoj', ''], ['Anjum', 'Anika', ''], ['Sarker', 'Avijit', ''], ['Noori', 'Sheak Rashed Haider', '']]",0,1,2023-08-21,1,7,2,5,3,2,bc70af9248d210663edf22e5fc84ca9313c697b0,261048795.0,https://www.semanticscholar.org/paper/bc70af9248d210663edf22e5fc84ca9313c697b0,arXiv.org,2023.0,51.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151116677', 'name': 'Md. Arid Hasan'}, {'authorId': '2198439213', 'name': 'Shudipta Das'}, {'authorId': '2232781563', 'name': 'Afiyat Anjum'}, {'authorId': '37784060', 'name': 'Firoj Alam'}, {'authorId': '35324286', 'name': 'Anika Anjum'}, {'authorId': '2008192067', 'name': 'Avijit Sarker'}, {'authorId': '7638904', 'name': 'S. R. H. Noori'}]","['Daffodil International University', 'University of New Brunswick', 'Qatar Computing Research Institute']","['Canada', 'Qatar', 'Bangladesh']",2023-08
2308.10944,Henry Leung,"Henry W. Leung, Jo Bovy",Towards an astronomical foundation model for stars with a Transformer-based model,,,,,astro-ph.IM astro-ph.GA astro-ph.SR,http://creativecommons.org/licenses/by/4.0/,"  Rapid strides are currently being made in the field of artificial intelligence using Transformer-based models like Large Language Models (LLMs). The potential of these methods for creating a single, large, versatile model in astronomy has not yet been explored. In this work, we propose a framework for data-driven astronomy that uses the same core techniques and architecture as used by LLMs. Using a variety of observations and labels of stars as an example, we build a Transformer-based model and train it in a self-supervised manner with cross-survey data sets to perform a variety of inference tasks. In particular, we demonstrate that a $\textit{single}$ model can perform both discriminative and generative tasks even if the model was not trained or fine-tuned to do any specific task. For example, on the discriminative task of deriving stellar parameters from Gaia XP spectra, we achieve an accuracy of 47 K in $T_\mathrm{eff}$, 0.11 dex in $\log{g}$, and 0.07 dex in $[\mathrm{M/H}]$, outperforming an expert $\texttt{XGBoost}$ model in the same setting. But the same model can also generate XP spectra from stellar parameters, inpaint unobserved spectral regions, extract empirical stellar loci, and even determine the interstellar extinction curve. Our framework demonstrates that building and training a $\textit{single}$ foundation model without fine-tuning using data and parameters from multiple surveys to predict unmeasured observations and parameters is well within reach. Such ""Large Astronomy Models"" trained on large quantities of observational data will play a large role in the analysis of current and future large surveys. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 18:00:05 GMT'}, {'version': 'v2', 'created': 'Thu, 28 Sep 2023 13:47:44 GMT'}]",2023-09-29,"[['Leung', 'Henry W.', ''], ['Bovy', 'Jo', '']]",0,0,2023-08-21,2,2,3,0,0,0,264cb7a7dbee1303ff9e0ebe2dac78646271a2fb,261064643.0,https://www.semanticscholar.org/paper/264cb7a7dbee1303ff9e0ebe2dac78646271a2fb,,2023.0,9.0,3.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '27363660', 'name': 'Henry W. Leung'}, {'authorId': '4718160', 'name': 'J. Bovy'}]",['University of Toronto'],['Canada'],2023-08
2308.11236,Bilel Benjdira Dr.,"Bilel Benjdira, Anis Koubaa, Anas M. Ali",ROSGPT_Vision: Commanding Robots Using Only Language Models' Prompts,,,,,cs.RO cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In this paper, we argue that the next generation of robots can be commanded using only Language Models' prompts. Every prompt interrogates separately a specific Robotic Modality via its Modality Language Model (MLM). A central Task Modality mediates the whole communication to execute the robotic mission via a Large Language Model (LLM). This paper gives this new robotic design pattern the name of: Prompting Robotic Modalities (PRM). Moreover, this paper applies this PRM design pattern in building a new robotic framework named ROSGPT_Vision. ROSGPT_Vision allows the execution of a robotic task using only two prompts: a Visual and an LLM prompt. The Visual Prompt extracts, in natural language, the visual semantic features related to the task under consideration (Visual Robotic Modality). Meanwhile, the LLM Prompt regulates the robotic reaction to the visual description (Task Modality). The framework automates all the mechanisms behind these two prompts. The framework enables the robot to address complex real-world scenarios by processing visual data, making informed decisions, and carrying out actions automatically. The framework comprises one generic vision module and two independent ROS nodes. As a test application, we used ROSGPT_Vision to develop CarMate, which monitors the driver's distraction on the roads and makes real-time vocal notifications to the driver. We showed how ROSGPT_Vision significantly reduced the development cost compared to traditional methods. We demonstrated how to improve the quality of the application by optimizing the prompting strategies, without delving into technical details. ROSGPT_Vision is shared with the community (link: https://github.com/bilel-bj/ROSGPT_Vision) to advance robotic research in this direction and to build more robotic frameworks that implement the PRM design pattern and enables controlling robots using only prompts. ","[{'version': 'v1', 'created': 'Tue, 22 Aug 2023 07:21:24 GMT'}, {'version': 'v2', 'created': 'Wed, 23 Aug 2023 08:31:16 GMT'}]",2023-08-24,"[['Benjdira', 'Bilel', ''], ['Koubaa', 'Anis', ''], ['Ali', 'Anas M.', '']]",0,1,2023-08-22,2,3,2,0,0,0,53e8d327e7ceda6f4efd321752da57edbaee6257,261065191.0,https://www.semanticscholar.org/paper/53e8d327e7ceda6f4efd321752da57edbaee6257,arXiv.org,2023.0,44.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '11042085', 'name': 'Bilel Benjdira'}, {'authorId': '1714415', 'name': 'A. Koubâa'}, {'authorId': '2107609407', 'name': 'Anas M. Ali'}]",['Prince Sultan University'],['Saudi Arabia'],2023-08
2308.11424,Makayla Lewis,Makayla Lewis,AIxArtist: A First-Person Tale of Interacting with Artificial Intelligence to Escape Creative Block,"1st International Workshop on Explainable AI for the Arts (XAIxArts),
  ACM Creativity and Cognition (C&C) 2023. Online, 6 pages.
  https://xaixarts.github.io",,,,cs.HC cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  The future of the arts and artificial intelligence (AI) is promising as technology advances. As the use of AI in design becomes more widespread, art practice may not be a human-only art form and could instead become a digitally integrated experience. With enhanced creativity and collaboration, arts and AI could work together towards creating artistic outputs that are visually appealing and meet the needs of the artist and viewer. While it is uncertain how far the integration will go, arts and AI will likely influence one another. This workshop pictorial puts forward first-person research that shares interactions between an HCI researcher and AI as they try to escape the creative block. The pictorial paper explores two questions: How can AI support artists' creativity, and what does it mean to be explainable in this context? HIs, ChatGPT and Midjourney were engaged; the result was a series of reflections that require further discussion and explorations in the XAIxArts community: Transparency of attribution, the creation process, ethics of asking, and inspiration vs copying. ","[{'version': 'v1', 'created': 'Tue, 22 Aug 2023 13:15:29 GMT'}]",2023-08-23,"[['Lewis', 'Makayla', '']]",1,1,2023-08-22,1,1,2,1,0,1,654876642a6ec1e44ddc435f8c80f199fb1dc404,261065292.0,https://www.semanticscholar.org/paper/654876642a6ec1e44ddc435f8c80f199fb1dc404,arXiv.org,2023.0,19.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","[{'authorId': '145172819', 'name': 'Makayla M. Lewis'}]",['Kingston University'],['United Kingdom'],2023-08
2308.11483,Pouya Pezeshkpour,"Pouya Pezeshkpour, Estevam Hruschka",Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have demonstrated remarkable capabilities in various NLP tasks. However, previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models. As these models become more powerful, it becomes imperative to understand and address these limitations. In this paper, we focus on LLMs robustness on the task of multiple-choice questions -- commonly adopted task to study reasoning and fact-retrieving capability of LLMs. Investigating the sensitivity of LLMs towards the order of options in multiple-choice questions, we demonstrate a considerable performance gap of approximately 13% to 75% in LLMs on different benchmarks, when answer options are reordered, even when using demonstrations in a few-shot setting. Through a detailed analysis, we conjecture that this sensitivity arises when LLMs are uncertain about the prediction between the top-2/3 choices, and specific options placements may favor certain prediction between those top choices depending on the question caused by positional bias. We also identify patterns in top-2 choices that amplify or mitigate the model's bias toward option placement. We found that for amplifying bias, the optimal strategy involves positioning the top two choices as the first and last options. Conversely, to mitigate bias, we recommend placing these choices among the adjacent options. To validate our conjecture, we conduct various experiments and adopt two approaches to calibrate LLMs' predictions, leading to up to 8 percentage points improvement across different models and benchmarks. ","[{'version': 'v1', 'created': 'Tue, 22 Aug 2023 14:54:59 GMT'}]",2023-08-23,"[['Pezeshkpour', 'Pouya', ''], ['Hruschka', 'Estevam', '']]",0,0,2023-08-22,1,2,3,0,0,0,fd81018bc72b030545a2d3f3010f3758ec4d48c3,261064970.0,https://www.semanticscholar.org/paper/fd81018bc72b030545a2d3f3010f3758ec4d48c3,arXiv.org,2023.0,24.0,13.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '1713436', 'name': 'Pouya Pezeshkpour'}, {'authorId': '1842532', 'name': 'Estevam Hruschka'}]",['Laboratori Guglielmo Marconi (Italy)'],['Italy'],2023-08
2308.11485,Tiberio Uricchio,"Alberto Baldrati, Marco Bertini, Tiberio Uricchio, Alberto del Bimbo",Composed Image Retrieval using Contrastive Learning and Task-oriented CLIP-based Features,"Accepted in ACM Transactions on Multimedia Computing Communications
  and Applications (TOMM)",,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Given a query composed of a reference image and a relative caption, the Composed Image Retrieval goal is to retrieve images visually similar to the reference one that integrates the modifications expressed by the caption. Given that recent research has demonstrated the efficacy of large-scale vision and language pre-trained (VLP) models in various tasks, we rely on features from the OpenAI CLIP model to tackle the considered task. We initially perform a task-oriented fine-tuning of both CLIP encoders using the element-wise sum of visual and textual features. Then, in the second stage, we train a Combiner network that learns to combine the image-text features integrating the bimodal information and providing combined features used to perform the retrieval. We use contrastive learning in both stages of training. Starting from the bare CLIP features as a baseline, experimental results show that the task-oriented fine-tuning and the carefully crafted Combiner network are highly effective and outperform more complex state-of-the-art approaches on FashionIQ and CIRR, two popular and challenging datasets for composed image retrieval. Code and pre-trained models are available at https://github.com/ABaldrati/CLIP4Cir ","[{'version': 'v1', 'created': 'Tue, 22 Aug 2023 15:03:16 GMT'}]",2023-08-23,"[['Baldrati', 'Alberto', ''], ['Bertini', 'Marco', ''], ['Uricchio', 'Tiberio', ''], ['del Bimbo', 'Alberto', '']]",0,0,2023-08-22,1,4,1,0,0,0,d1c3c6ec970e8e901d14b9a10b9c88e6e6338b8c,261065158.0,https://www.semanticscholar.org/paper/d1c3c6ec970e8e901d14b9a10b9c88e6e6338b8c,"ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP)",2023.0,57.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2149413263', 'name': 'Alberto Baldrati'}, {'authorId': '1801509', 'name': 'M. Bertini'}, {'authorId': '1789269', 'name': 'Tiberio Uricchio'}, {'authorId': '8196487', 'name': 'A. Bimbo'}]","['University of Florence', 'University of Macerata', 'Marco Bertini,', 'University of Pisa']",['Italy'],2023-08
2308.11526,Pranjal Gupta,"Pranjal Gupta and Harshit Kumar and Debanjana Kar and Karan Bhukar and
  Pooja Aggarwal and Prateeti Mohapatra",Learning Representations on Logs for AIOps,"11 pages, 2023 IEEE 16th International Conference on Cloud Computing
  (CLOUD)",,,,cs.CL cs.AI cs.SE,http://creativecommons.org/licenses/by/4.0/,"  AI for IT Operations (AIOps) is a powerful platform that Site Reliability Engineers (SREs) use to automate and streamline operational workflows with minimal human intervention. Automated log analysis is a critical task in AIOps as it provides key insights for SREs to identify and address ongoing faults. Tasks such as log format detection, log classification, and log parsing are key components of automated log analysis. Most of these tasks require supervised learning; however, there are multiple challenges due to limited labelled log data and the diverse nature of log data. Large Language Models (LLMs) such as BERT and GPT3 are trained using self-supervision on a vast amount of unlabeled data. These models provide generalized representations that can be effectively used for various downstream tasks with limited labelled data. Motivated by the success of LLMs in specific domains like science and biology, this paper introduces a LLM for log data which is trained on public and proprietary log data. The results of our experiments demonstrate that the proposed LLM outperforms existing models on multiple downstream tasks. In summary, AIOps powered by LLMs offers an efficient and effective solution for automating log analysis tasks and enabling SREs to focus on higher-level tasks. Our proposed LLM, trained on public and proprietary log data, offers superior performance on multiple downstream tasks, making it a valuable addition to the AIOps platform. ","[{'version': 'v1', 'created': 'Fri, 18 Aug 2023 20:34:46 GMT'}]",2023-08-23,"[['Gupta', 'Pranjal', ''], ['Kumar', 'Harshit', ''], ['Kar', 'Debanjana', ''], ['Bhukar', 'Karan', ''], ['Aggarwal', 'Pooja', ''], ['Mohapatra', 'Prateeti', '']]",0,1,2023-08-18,1,6,3,1,0,1,f6974a11315fa698dc584e9f09316d61f414e952,261064771.0,https://www.semanticscholar.org/paper/f6974a11315fa698dc584e9f09316d61f414e952,IEEE International Conference on Cloud Computing,2023.0,45.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2042299842', 'name': 'Pranjal Gupta'}, {'authorId': '145369847', 'name': 'Harshit Kumar'}, {'authorId': '29850167', 'name': 'Debanjana Kar'}, {'authorId': '2111874424', 'name': 'Karan Bhukar'}, {'authorId': '2070039961', 'name': 'Pooja Aggarwal'}, {'authorId': '39700099', 'name': 'P. Mohapatra'}]",['IBM Research - India'],['India'],2023-08
2308.11563,Silvana Deilen,"Silvana Deilen, Sergio Hern\'andez Garrido, Ekaterina
  Lapshinova-Koltunski, Christiane Maa{\ss}",Using ChatGPT as a CAT tool in Easy Language translation,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  This study sets out to investigate the feasibility of using ChatGPT to translate citizen-oriented administrative texts into German Easy Language, a simplified, controlled language variety that is adapted to the needs of people with reading impairments. We use ChatGPT to translate selected texts from websites of German public authorities using two strategies, i.e. linguistic and holistic. We analyse the quality of the generated texts based on different criteria, such as correctness, readability, and syntactic complexity. The results indicated that the generated texts are easier than the standard texts, but that they still do not fully meet the established Easy Language standards. Additionally, the content is not always rendered correctly. ","[{'version': 'v1', 'created': 'Tue, 22 Aug 2023 16:59:31 GMT'}]",2023-08-23,"[['Deilen', 'Silvana', ''], ['Garrido', 'Sergio Hernández', ''], ['Lapshinova-Koltunski', 'Ekaterina', ''], ['Maaß', 'Christiane', '']]",1,1,2023-08-22,1,4,1,1,0,1,3327d826366572353e3ed4a8b59c2addd6ab0ca8,261064655.0,https://www.semanticscholar.org/paper/3327d826366572353e3ed4a8b59c2addd6ab0ca8,TSAR,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2260958124', 'name': 'Silvana Deilen'}, {'authorId': '2232951566', 'name': ""Sergio Hern'andez Garrido""}, {'authorId': '1402921027', 'name': 'Ekaterina Lapshinova-Koltunski'}, {'authorId': '65846171', 'name': 'Christiane Maaß'}]",['University of Hildesheim'],['Germany'],2023-08
2308.11585,Yosuke Miyanishi,"Yosuke Miyanishi, Minh Le Nguyen",Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes,,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the wake of the explosive growth of machine learning (ML) usage, particularly within the context of emerging Large Language Models (LLMs), comprehending the semantic significance rooted in their internal workings is crucial. While causal analyses focus on defining semantics and its quantification, the gradient-based approach is central to explainable AI (XAI), tackling the interpretation of the black box. By synergizing these approaches, the exploration of how a model's internal mechanisms illuminate its causal effect has become integral for evidence-based decision-making. A parallel line of research has revealed that intersectionality - the combinatory impact of multiple demographics of an individual - can be structured in the form of an Averaged Treatment Effect (ATE). Initially, this study illustrates that the hateful memes detection problem can be formulated as an ATE, assisted by the principles of intersectionality, and that a modality-wise summarization of gradient-based attention attribution scores can delineate the distinct behaviors of three Transformerbased models concerning ATE. Subsequently, we show that the latest LLM LLaMA2 has the ability to disentangle the intersectional nature of memes detection in an in-context learning setting, with their mechanistic properties elucidated via meta-gradient, a secondary form of gradient. In conclusion, this research contributes to the ongoing dialogue surrounding XAI and the multifaceted nature of ML models. ","[{'version': 'v1', 'created': 'Sat, 19 Aug 2023 13:14:15 GMT'}]",2023-08-23,"[['Miyanishi', 'Yosuke', ''], ['Nguyen', 'Minh Le', '']]",0,0,2023-08-19,1,2,2,0,0,0,3ac3c10e1317fe8419f794cf30ce3227e95e1f54,261065082.0,https://www.semanticscholar.org/paper/3ac3c10e1317fe8419f794cf30ce3227e95e1f54,arXiv.org,2023.0,69.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '11038927', 'name': 'Yosuke Miyanishi'}, {'authorId': '2155078701', 'name': 'M. Nguyen'}]",['Japan Advanced Institute of Science and Technology'],['Japan'],2023-08
2308.12086,Maria Rigaki,"Maria Rigaki, Ond\v{r}ej Luk\'a\v{s}, Carlos A. Catania, Sebastian
  Garcia",Out of the Cage: How Stochastic Parrots Win in Cyber Security Environments,"Under review. 10 pages plus appendices, 7 figures, 4 tables. Edit:
  fix e-mails and code repository",,,,cs.CR cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large Language Models (LLMs) have gained widespread popularity across diverse domains involving text generation, summarization, and various natural language processing tasks. Despite their inherent limitations, LLM-based designs have shown promising capabilities in planning and navigating open-world scenarios. This paper introduces a novel application of pre-trained LLMs as agents within cybersecurity network environments, focusing on their utility for sequential decision-making processes.   We present an approach wherein pre-trained LLMs are leveraged as attacking agents in two reinforcement learning environments. Our proposed agents demonstrate similar or better performance against state-of-the-art agents trained for thousands of episodes in most scenarios and configurations. In addition, the best LLM agents perform similarly to human testers of the environment without any additional training process. This design highlights the potential of LLMs to efficiently address complex decision-making tasks within cybersecurity.   Furthermore, we introduce a new network security environment named NetSecGame. The environment is designed to eventually support complex multi-agent scenarios within the network security domain. The proposed environment mimics real network attacks and is designed to be highly modular and adaptable for various scenarios. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 12:11:27 GMT'}, {'version': 'v2', 'created': 'Mon, 28 Aug 2023 09:42:59 GMT'}]",2023-08-29,"[['Rigaki', 'Maria', ''], ['Lukáš', 'Ondřej', ''], ['Catania', 'Carlos A.', ''], ['Garcia', 'Sebastian', '']]",0,0,2023-08-23,2,4,3,0,0,0,2172c97edcaeba396dcb863154b4b489d3c2840c,261076387.0,https://www.semanticscholar.org/paper/2172c97edcaeba396dcb863154b4b489d3c2840c,arXiv.org,2023.0,52.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46215736', 'name': 'M. Rigaki'}, {'authorId': '2077130347', 'name': 'Ondrej Lukás'}, {'authorId': '145151811', 'name': 'C. Catania'}, {'authorId': '32015343', 'name': 'S. García'}]","['Czech Technical University in Prague', 'National University of Cuyo']","['Czechia', 'Argentina']",2023-08
2308.12095,Anamaria Irmgard Mojica Hanke,"Laura Cabra-Acela and Anamaria Mojica-Hanke and Mario
  Linares-V\'asquez and Steffen Herbold",On Using Information Retrieval to Recommend Machine Learning Good Practices for Software Engineers,Accepted for Publication at ESEC/FSE demonstrations track,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Machine learning (ML) is nowadays widely used for different purposes and in several disciplines. From self-driving cars to automated medical diagnosis, machine learning models extensively support users' daily activities, and software engineering tasks are no exception. Not embracing good ML practices may lead to pitfalls that hinder the performance of an ML system and potentially lead to unexpected results. Despite the existence of documentation and literature about ML best practices, many non-ML experts turn towards gray literature like blogs and Q&A systems when looking for help and guidance when implementing ML systems. To better aid users in distilling relevant knowledge from such sources, we propose a recommender system that recommends ML practices based on the user's context. As a first step in creating a recommender system for machine learning practices, we implemented Idaka. A tool that provides two different approaches for retrieving/generating ML best practices: i) an information retrieval (IR) engine and ii) a large language model. The IR-engine uses BM25 as the algorithm for retrieving the practices, and a large language model, in our case Alpaca. The platform has been designed to allow comparative studies of best practices retrieval tools. Idaka is publicly available at GitHub: https://bit.ly/idaka. Video: https://youtu.be/cEb-AhIPxnM. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 12:28:18 GMT'}, {'version': 'v2', 'created': 'Fri, 25 Aug 2023 08:05:52 GMT'}]",2023-08-28,"[['Cabra-Acela', 'Laura', ''], ['Mojica-Hanke', 'Anamaria', ''], ['Linares-Vásquez', 'Mario', ''], ['Herbold', 'Steffen', '']]",0,0,2023-08-23,2,4,1,1,0,1,2f26d6935face2856d71cc1a9147255ea6bf74be,261076185.0,https://www.semanticscholar.org/paper/2f26d6935face2856d71cc1a9147255ea6bf74be,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2233086777', 'name': 'Laura Cabra-Acela'}, {'authorId': '1949197826', 'name': 'Anamaria Mojica-Hanke'}, {'authorId': '2202543460', 'name': ""Mario Linares-V'asquez""}, {'authorId': '3063461', 'name': 'S. Herbold'}]","['University of Passau', 'Universidad de Los Andes']","['Germany', 'Bolivia']",2023-08
2308.12682,Rishi Hazra,"Rishi Hazra, Pedro Zuidberg Dos Martires, Luc De Raedt",SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge,,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have demonstrated impressive planning abilities due to their vast ""world knowledge"". Yet, obtaining plans that are both feasible (grounded in affordances) and cost-effective (in plan length), remains a challenge, despite recent progress. This contrasts with heuristic planning methods that employ domain knowledge (formalized in action models such as PDDL) and heuristic search to generate feasible, optimal plans. Inspired by this, we propose to combine the power of LLMs and heuristic planning by leveraging the world knowledge of LLMs and the principles of heuristic search. Our approach, SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain knowledge, that evaluates actions' feasibility (Can) and long-term reward/payoff (Pay), and heuristic search to select the best sequence of actions. Our contributions are (1) a novel framing of the LLM planning problem in the context of heuristic planning, (2) integrating grounding and cost-effective elements into the generated plans, and (3) using heuristic search over actions. Our extensive evaluations show that our model surpasses other LLM planning approaches. ","[{'version': 'v1', 'created': 'Thu, 24 Aug 2023 09:47:28 GMT'}]",2023-08-25,"[['Hazra', 'Rishi', ''], ['Martires', 'Pedro Zuidberg Dos', ''], ['De Raedt', 'Luc', '']]",0,0,2023-08-24,1,3,1,0,0,0,7569d62c7651625456a2cbd4922d9d65351593ac,261100610.0,https://www.semanticscholar.org/paper/7569d62c7651625456a2cbd4922d9d65351593ac,arXiv.org,2023.0,38.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '1399739959', 'name': 'Rishi Hazra'}, {'authorId': '51007563', 'name': 'Pedro Zuidberg Dos Martires'}, {'authorId': '1740042', 'name': 'L. D. Raedt'}]","['Örebro University', 'KU Leuven']","['Belgium', 'Sweden']",2023-08
2308.12833,Maximilian Mozes,"Maximilian Mozes, Xuanli He, Bennett Kleinberg, Lewis D. Griffin","Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities",Pre-print,,,,cs.CL cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Spurred by the recent rapid increase in the development and distribution of large language models (LLMs) across industry and academia, much recent work has drawn attention to safety- and security-related threats and vulnerabilities of LLMs, including in the context of potentially criminal activities. Specifically, it has been shown that LLMs can be misused for fraud, impersonation, and the generation of malware; while other authors have considered the more general problem of AI alignment. It is important that developers and practitioners alike are aware of security-related problems with such models. In this paper, we provide an overview of existing - predominantly scientific - efforts on identifying and mitigating threats and vulnerabilities arising from LLMs. We present a taxonomy describing the relationship between threats caused by the generative capabilities of LLMs, prevention measures intended to address such threats, and vulnerabilities arising from imperfect prevention measures. With our work, we hope to raise awareness of the limitations of LLMs in light of such security concerns, among both experienced developers and novel users of such technologies. ","[{'version': 'v1', 'created': 'Thu, 24 Aug 2023 14:45:50 GMT'}]",2023-08-25,"[['Mozes', 'Maximilian', ''], ['He', 'Xuanli', ''], ['Kleinberg', 'Bennett', ''], ['Griffin', 'Lewis D.', '']]",0,0,2023-08-24,1,4,2,0,0,0,ac1788e9a168a6455beb6316f316950842297c11,261101245.0,https://www.semanticscholar.org/paper/ac1788e9a168a6455beb6316f316950842297c11,arXiv.org,2023.0,220.0,6.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '37237998', 'name': 'Maximilian Mozes'}, {'authorId': '2116986629', 'name': 'Xuanli He'}, {'authorId': '6032930', 'name': 'Bennett Kleinberg'}, {'authorId': '2052553185', 'name': 'L. D. Griffin'}]","['University College London', 'Tilburg University']","['United Kingdom', 'Netherlands']",2023-08
2308.13067,Matej Zecevic,"Matej Ze\v{c}evi\'c and Moritz Willig and Devendra Singh Dhami and
  Kristian Kersting",Causal Parrots: Large Language Models May Talk Causality But Are Not Causal,"Published in Transactions in Machine Learning Research (TMLR)
  (08/2023). Main paper: 17 pages, References: 3 pages, Appendix: 7 pages.
  Figures: 5 main, 3 appendix. Tables: 3 main",Transactions in Machine Learning Research (08/2023),,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Some argue scale is all what is needed to achieve AI, covering even causal models. We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables. We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained. If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.' ","[{'version': 'v1', 'created': 'Thu, 24 Aug 2023 20:23:13 GMT'}]",2023-08-28,"[['Zečević', 'Matej', ''], ['Willig', 'Moritz', ''], ['Dhami', 'Devendra Singh', ''], ['Kersting', 'Kristian', '']]",0,0,2023-08-24,1,4,2,0,0,0,b9672ac98913c43fcb996b3def314789d1cc0cf4,261214555.0,https://www.semanticscholar.org/paper/b9672ac98913c43fcb996b3def314789d1cc0cf4,arXiv.org,2023.0,71.0,9.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35745805', 'name': 'M. Zecevic'}, {'authorId': '1387999893', 'name': 'Moritz Willig'}, {'authorId': '39552485', 'name': 'D. Dhami'}, {'authorId': '2113406566', 'name': 'K. Kersting'}]","['Hessian Center for AI (hessian.AI), Germany', 'German Research Centre for Artificial Intelligence', 'Technical University of Darmstadt']",['Germany'],2023-08
2308.13142,Tianyi Zhang,"Tianyi Zhang, Zheng Wang, Jing Huang, Mohiuddin Muhammad Tasnim, Wei
  Shi",A Survey of Diffusion Based Image Generation Models: Issues and Their Solutions,,,,,cs.CV cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  Recently, there has been significant progress in the development of large models. Following the success of ChatGPT, numerous language models have been introduced, demonstrating remarkable performance. Similar advancements have also been observed in image generation models, such as Google's Imagen model, OpenAI's DALL-E 2, and stable diffusion models, which have exhibited impressive capabilities in generating images. However, similar to large language models, these models still encounter unresolved challenges. Fortunately, the availability of open-source stable diffusion models and their underlying mathematical principles has enabled the academic community to extensively analyze the performance of current image generation models and make improvements based on this stable diffusion framework. This survey aims to examine the existing issues and the current solutions pertaining to image generation models. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 02:35:54 GMT'}]",2023-08-28,"[['Zhang', 'Tianyi', ''], ['Wang', 'Zheng', ''], ['Huang', 'Jing', ''], ['Tasnim', 'Mohiuddin Muhammad', ''], ['Shi', 'Wei', '']]",1,1,2023-08-25,1,5,2,1,0,1,49faa5c9bf6459a256f68872fb3b51df6b0a2dd8,261214460.0,https://www.semanticscholar.org/paper/49faa5c9bf6459a256f68872fb3b51df6b0a2dd8,arXiv.org,2023.0,84.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146334570', 'name': 'Tianyi Zhang'}, {'authorId': '50219447', 'name': 'Zheng Wang'}, {'authorId': '2210525127', 'name': 'Jin Huang'}, {'authorId': '104349231', 'name': 'M. M. Tasnim'}, {'authorId': '2199629455', 'name': 'Wei Shi'}]",['Huawei Technologies (Singapore)'],['Singapore'],2023-08
2308.13207,Anmol Nayak,Anmol Nayak and Hari Prasad Timmapathini,LLM2KB: Constructing Knowledge Bases using instruction tuned context aware Large Language Models,"16 pages, 1 figure, LM-KBC 2023 Challenge at International Semantic
  Web Conference 2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The advent of Large Language Models (LLM) has revolutionized the field of natural language processing, enabling significant progress in various applications. One key area of interest is the construction of Knowledge Bases (KB) using these powerful models. Knowledge bases serve as repositories of structured information, facilitating information retrieval and inference tasks. Our paper proposes LLM2KB, a system for constructing knowledge bases using large language models, with a focus on the Llama 2 architecture and the Wikipedia dataset. We perform parameter efficient instruction tuning for Llama-2-13b-chat and StableBeluga-13B by training small injection models that have only 0.05 % of the parameters of the base models using the Low Rank Adaptation (LoRA) technique. These injection models have been trained with prompts that are engineered to utilize Wikipedia page contexts of subject entities fetched using a Dense Passage Retrieval (DPR) algorithm, to answer relevant object entities for a given subject entity and relation. Our best performing model achieved an average F1 score of 0.6185 across 21 relations in the LM-KBC challenge held at the ISWC 2023 conference. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 07:04:16 GMT'}]",2023-08-28,"[['Nayak', 'Anmol', ''], ['Timmapathini', 'Hari Prasad', '']]",0,0,2023-08-25,1,2,1,1,1,0,4a9d0f0e68742b95b0dc778be0e3405f704f49a2,261214545.0,https://www.semanticscholar.org/paper/4a9d0f0e68742b95b0dc778be0e3405f704f49a2,arXiv.org,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46364598', 'name': 'Anmol Nayak'}, {'authorId': '2008210594', 'name': 'Hariprasad Timmapathini'}]",['Robert Bosch (India)'],['India'],2023-08
2308.13278,Achkan Salehi,Achkan Salehi and Stephane Doncieux,Integrating LLMs and Decision Transformers for Language Grounded Generative Quality-Diversity,"16 pages, 9 figures, 2 tables",,,,cs.LG cs.AI cs.RO,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Quality-Diversity is a branch of stochastic optimization that is often applied to problems from the Reinforcement Learning and control domains in order to construct repertoires of well-performing policies/skills that exhibit diversity with respect to a behavior space. Such archives are usually composed of a finite number of reactive agents which are each associated to a unique behavior descriptor, and instantiating behavior descriptors outside of that coarsely discretized space is not straight-forward. While a few recent works suggest solutions to that issue, the trajectory that is generated is not easily customizable beyond the specification of a target behavior descriptor. We propose to jointly solve those problems in environments where semantic information about static scene elements is available by leveraging a Large Language Model to augment the repertoire with natural language descriptions of trajectories, and training a policy conditioned on those descriptions. Thus, our method allows a user to not only specify an arbitrary target behavior descriptor, but also provide the model with a high-level textual prompt to shape the generated trajectory. We also propose an LLM-based approach to evaluating the performance of such generative agents. Furthermore, we develop a benchmark based on simulated robot navigation in a 2d maze that we use for experimental validation. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 10:00:06 GMT'}]",2023-08-28,"[['Salehi', 'Achkan', ''], ['Doncieux', 'Stephane', '']]",0,0,2023-08-25,1,2,3,0,0,0,5ef87dda04569d89559db9ac83833433416fa66e,261214553.0,https://www.semanticscholar.org/paper/5ef87dda04569d89559db9ac83833433416fa66e,arXiv.org,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '30095335', 'name': 'Achkan Salehi'}, {'authorId': '1765955', 'name': 'S. Doncieux'}]",['Sorbonne Université'],['France'],2023-08
2308.13317,Aline Ioste Rodrigheri,Aline Ioste,Transforming the Output of Generative Pre-trained Transformer: The Influence of the PGI Framework on Attention Dynamics,,,,,cs.AI cs.CL cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  This paper presents a novel approach named Persona-Grouping-Intelligence (PGI), which has been crafted to tackle the challenges posed by GPT models when applied to real-world business issues. PGI leverages the inherent capabilities of the GPT model to comprehend intricate language structures and generate responses that are contextually relevant. The experiment occurred in a business scenario where human intelligence was being underutilized due to less optimized business processes. The primary objective of this approach is to leverage GPT models to reduce the workload on humans in tasks that are extensive, monotonous, and repetitive. Instead, the focus is redirected toward decision-making activities. Remarkably, the experiment yielded an accuracy rate of 93.81% in validating 4,000 responses generated by the model, underscoring the effectiveness of the PGI strategies. Effectively addressing the issue of underutilized human intelligence, this paradigm shift aligns business environments with dynamic machine intelligence, enabling them to navigate the intricacies of real-world challenges. This approach facilitates the practical utilization of these models to tackle actual problems. The methodology offers an opportunity to reshape the fundamental structure of business processes by seamlessly integrating human decision-making with adaptable machine intelligence. Consequently, this optimization enhances operational efficiency and elevates strategic decision-making across diverse business contexts. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 11:41:05 GMT'}]",2023-08-28,"[['Ioste', 'Aline', '']]",0,1,2023-08-25,1,1,3,0,0,0,407c0a02c26567318113cdb489766b8fa570d9a3,261214353.0,https://www.semanticscholar.org/paper/407c0a02c26567318113cdb489766b8fa570d9a3,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2164036684', 'name': 'Aline Ioste'}]","['Department of Business Architecture, AI Specialist, Itau Unibanco -Brazil', 'Universidade de São Paulo']",['Brazil'],2023-08
2308.13382,Zengqun Zhao,"Zengqun Zhao, Ioannis Patras",Prompting Visual-Language Models for Dynamic Facial Expression Recognition,Accepted at BMVC 2023,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  This paper presents a novel visual-language model called DFER-CLIP, which is based on the CLIP model and designed for in-the-wild Dynamic Facial Expression Recognition (DFER). Specifically, the proposed DFER-CLIP consists of a visual part and a textual part. For the visual part, based on the CLIP image encoder, a temporal model consisting of several Transformer encoders is introduced for extracting temporal facial expression features, and the final feature embedding is obtained as a learnable ""class"" token. For the textual part, we use as inputs textual descriptions of the facial behaviour that is related to the classes (facial expressions) that we are interested in recognising -- those descriptions are generated using large language models, like ChatGPT. This, in contrast to works that use only the class names and more accurately captures the relationship between them. Alongside the textual description, we introduce a learnable token which helps the model learn relevant context information for each expression during training. Extensive experiments demonstrate the effectiveness of the proposed method and show that our DFER-CLIP also achieves state-of-the-art results compared with the current supervised DFER methods on the DFEW, FERV39k, and MAFW benchmarks. Code is publicly available at https://github.com/zengqunzhao/DFER-CLIP. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 13:52:05 GMT'}]",2023-08-28,"[['Zhao', 'Zengqun', ''], ['Patras', 'Ioannis', '']]",1,1,2023-08-25,1,2,1,1,0,1,d85118424790f6c6aed4f81db48a690f9f27b5d1,261214803.0,https://www.semanticscholar.org/paper/d85118424790f6c6aed4f81db48a690f9f27b5d1,arXiv.org,2023.0,53.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2116254370', 'name': 'Zengqun Zhao'}, {'authorId': '50058816', 'name': 'I. Patras'}]",['Queen Mary University of London'],['United Kingdom'],2023-08
2308.13387,Yuxia Wang,"Yuxia Wang, Haonan Li, Xudong Han, Preslav Nakov, Timothy Baldwin",Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs,"18 pages, 9 figures, 11 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  With the rapid evolution of large language models (LLMs), new and hard-to-predict harmful capabilities are emerging. This requires developers to be able to identify risks through the evaluation of ""dangerous capabilities"" in order to responsibly deploy LLMs. In this work, we collect the first open-source dataset to evaluate safeguards in LLMs, and deploy safer open-source LLMs at a low cost. Our dataset is curated and filtered to consist only of instructions that responsible language models should not follow. We annotate and assess the responses of six popular LLMs to these instructions. Based on our annotation, we proceed to train several BERT-like classifiers, and find that these small classifiers can achieve results that are comparable with GPT-4 on automatic safety evaluation. Warning: this paper contains example data that may be offensive, harmful, or biased. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 14:02:12 GMT'}, {'version': 'v2', 'created': 'Mon, 4 Sep 2023 01:47:30 GMT'}]",2023-09-06,"[['Wang', 'Yuxia', ''], ['Li', 'Haonan', ''], ['Han', 'Xudong', ''], ['Nakov', 'Preslav', ''], ['Baldwin', 'Timothy', '']]",0,1,2023-08-25,2,5,1,1,0,1,288063323dddad9bea7eb1230a2048546435687e,261214837.0,https://www.semanticscholar.org/paper/288063323dddad9bea7eb1230a2048546435687e,arXiv.org,2023.0,29.0,7.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2115829571', 'name': 'Yuxia Wang'}, {'authorId': '49404498', 'name': 'Haonan Li'}, {'authorId': '2110982198', 'name': 'Xudong Han'}, {'authorId': '2026545715', 'name': 'Preslav Nakov'}, {'authorId': '2112644025', 'name': 'Timothy Baldwin'}]","['University of Melbourne', 'Equal contribution.']",['Australia'],2023-08
2308.13479,Samuel Rhys Cox,"Samuel Rhys Cox, Ashraf Abdul and Wei Tsang Ooi",Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages,"3 pages, 1 figure, 1 table, to be published in Proceedings of the
  11th International Conference on Human-Agent Interaction (ACM HAI'23)",,,,cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) are increasingly capable and prevalent, and can be used to produce creative content. The quality of content is influenced by the prompt used, with more specific prompts that incorporate examples generally producing better results. On from this, it could be seen that using instructions written for crowdsourcing tasks (that are specific and include examples to guide workers) could prove effective LLM prompts. To explore this, we used a previous crowdsourcing pipeline that gave examples to people to help them generate a collectively diverse corpus of motivational messages. We then used this same pipeline to generate messages using GPT-4, and compared the collective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the pipeline, and (3 & 4) two baseline GPT-4 prompts. We found that the LLM prompts using the crowdsourcing pipeline caused GPT-4 to produce more diverse messages than the two baseline prompts. We also discuss implications from messages generated by both human writers and LLMs. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 16:35:06 GMT'}]",2023-08-28,"[['Cox', 'Samuel Rhys', ''], ['Abdul', 'Ashraf', ''], ['Ooi', 'Wei Tsang', '']]",0,1,2023-08-25,1,3,2,1,0,1,8da6e4537122af618c36563caef5863f8728d789,261214615.0,https://www.semanticscholar.org/paper/8da6e4537122af618c36563caef5863f8728d789,arXiv.org,2023.0,29.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51039177', 'name': 'Samuel Rhys Cox'}, {'authorId': '20956040', 'name': 'Ashraf Abdul'}, {'authorId': '1678873', 'name': 'Wei Tsang Ooi'}]","['National University of Singapore', 'National']",['Singapore'],2023-08
2308.13517,Yihao Fang,"Yihao Fang, Xianzhi Li, Stephen W. Thomas, Xiaodan Zhu",ChatGPT as Data Augmentation for Compositional Generalization: A Case Study in Open Intent Detection,,"Proceedings of the Joint Workshop of the 5th Financial Technology
  and Natural Language Processing (FinNLP) and 2nd Multimodal AI For Financial
  Forecasting (Muffin), Macao, August 20, 2023",,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Open intent detection, a crucial aspect of natural language understanding, involves the identification of previously unseen intents in user-generated text. Despite the progress made in this field, challenges persist in handling new combinations of language components, which is essential for compositional generalization. In this paper, we present a case study exploring the use of ChatGPT as a data augmentation technique to enhance compositional generalization in open intent detection tasks. We begin by discussing the limitations of existing benchmarks in evaluating this problem, highlighting the need for constructing datasets for addressing compositional generalization in open intent detection tasks. By incorporating synthetic data generated by ChatGPT into the training process, we demonstrate that our approach can effectively improve model performance. Rigorous evaluation of multiple benchmarks reveals that our method outperforms existing techniques and significantly enhances open intent detection capabilities. Our findings underscore the potential of large language models like ChatGPT for data augmentation in natural language understanding tasks. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 17:51:23 GMT'}]",2023-08-28,"[['Fang', 'Yihao', ''], ['Li', 'Xianzhi', ''], ['Thomas', 'Stephen W.', ''], ['Zhu', 'Xiaodan', '']]",1,1,2023-08-25,1,4,2,1,0,1,057122d989a681592c409160dffb74bcb2e42d11,261214454.0,https://www.semanticscholar.org/paper/057122d989a681592c409160dffb74bcb2e42d11,FINNLP,2023.0,12.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2112786461', 'name': 'Yihao Fang'}, {'authorId': '50079608', 'name': 'Xianzhi Li'}, {'authorId': '1847208', 'name': 'Stephen W. Thomas'}, {'authorId': '150345740', 'name': 'Xiaodan Zhu'}]","[""Queen's University""]",['Canada'],2023-08
2308.13542,Thommen George Karimpanal,"Thommen George Karimpanal, Laknath Buddhika Semage, Santu Rana, Hung
  Le, Truyen Tran, Sunil Gupta and Svetha Venkatesh",LaGR-SEQ: Language-Guided Reinforcement Learning with Sample-Efficient Querying,"18 pages, 11 figures",,,,cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have recently demonstrated their impressive ability to provide context-aware responses via text. This ability could potentially be used to predict plausible solutions in sequential decision making tasks pertaining to pattern completion. For example, by observing a partial stack of cubes, LLMs can predict the correct sequence in which the remaining cubes should be stacked by extrapolating the observed patterns (e.g., cube sizes, colors or other attributes) in the partial stack. In this work, we introduce LaGR (Language-Guided Reinforcement learning), which uses this predictive ability of LLMs to propose solutions to tasks that have been partially completed by a primary reinforcement learning (RL) agent, in order to subsequently guide the latter's training. However, as RL training is generally not sample-efficient, deploying this approach would inherently imply that the LLM be repeatedly queried for solutions; a process that can be expensive and infeasible. To address this issue, we introduce SEQ (sample efficient querying), where we simultaneously train a secondary RL agent to decide when the LLM should be queried for solutions. Specifically, we use the quality of the solutions emanating from the LLM as the reward to train this agent. We show that our proposed framework LaGR-SEQ enables more efficient primary RL training, while simultaneously minimizing the number of queries to the LLM. We demonstrate our approach on a series of tasks and highlight the advantages of our approach, along with its limitations and potential future research directions. ","[{'version': 'v1', 'created': 'Mon, 21 Aug 2023 02:07:35 GMT'}]",2023-08-29,"[['Karimpanal', 'Thommen George', ''], ['Semage', 'Laknath Buddhika', ''], ['Rana', 'Santu', ''], ['Le', 'Hung', ''], ['Tran', 'Truyen', ''], ['Gupta', 'Sunil', ''], ['Venkatesh', 'Svetha', '']]",0,0,2023-08-21,1,7,1,0,0,0,0458c2ec6b3b3fc17a60dd09ae4904dd1eefb171,261245313.0,https://www.semanticscholar.org/paper/0458c2ec6b3b3fc17a60dd09ae4904dd1eefb171,arXiv.org,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '13526886', 'name': 'T. G. Karimpanal'}, {'authorId': '30073855', 'name': 'Laknath Semage'}, {'authorId': '2867032', 'name': 'Santu Rana'}, {'authorId': '2145242474', 'name': 'Hung Le'}, {'authorId': '6254479', 'name': 'T. Tran'}, {'authorId': '46415033', 'name': 'S. Gupta'}, {'authorId': '2068804643', 'name': 'S. Venkatesh'}]",['Deakin University'],['Australia'],2023-08
2308.13576,Shrutendra Harsola,Sourav Prosad and Viswa Datha Polavarapu and Shrutendra Harsola,An Ensemble Approach to Personalized Real Time Predictive Writing for Experts,"ACM SIGKDD Workshop on Machine Learning in Finance, 2023",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Completing a sentence, phrase or word after typing few words / characters is very helpful for Intuit financial experts, while taking notes or having a live chat with users, since they need to write complex financial concepts more efficiently and accurately many times in a day. In this paper, we tie together different approaches like large language models, traditional Markov Models and char level models to create an end-to-end system to provide personalised sentence/word auto-complete suggestions to experts, under strict latency constraints. Proposed system can auto-complete sentences, phrases or words while writing with personalisation and can be trained with very less data and resources with good efficiency. Our proposed system is not only efficient and personalized but also robust as it leverages multiple machine learning techniques along with transfer learning approach to fine tune large language model with Intuit specific data. This ensures that even in cases of rare or unusual phrases, the system can provide relevant auto-complete suggestions in near real time. Survey has showed that this system saves expert note-taking time and boosts expert confidence in their communication with teammates and clients. Since enabling this predictive writing feature for QBLive experts, more than a million keystrokes have been saved based on these suggestions. We have done comparative study for our ensemble choice. Moreover this feature can be integrated with any product which has writing facility within a very short period of time. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 12:45:46 GMT'}]",2023-08-29,"[['Prosad', 'Sourav', ''], ['Polavarapu', 'Viswa Datha', ''], ['Harsola', 'Shrutendra', '']]",0,0,2023-08-25,1,3,1,0,0,0,847e087ba2461350975b9de834c744dff0935a31,261242510.0,https://www.semanticscholar.org/paper/847e087ba2461350975b9de834c744dff0935a31,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2234342517', 'name': 'Sourav Prosad'}, {'authorId': '2234344345', 'name': 'Viswa Datha Polavarapu'}, {'authorId': '35429622', 'name': 'Shrutendra Harsola'}]","['Intuit AI, Bengaluru India']",['India'],2023-08
2308.13724,Zhehua Zhou,"Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, Lei Ma",ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning,,,,,cs.RO cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Motivated by the substantial achievements observed in Large Language Models (LLMs) in the field of natural language processing, recent research has commenced investigations into the application of LLMs for complex, long-horizon sequential task planning challenges in robotics. LLMs are advantageous in offering the potential to enhance the generalizability as task-agnostic planners and facilitate flexible interaction between human instructors and planning systems. However, task plans generated by LLMs often lack feasibility and correctness. To address this challenge, we introduce ISR-LLM, a novel framework that improves LLM-based planning through an iterative self-refinement process. The framework operates through three sequential steps: preprocessing, planning, and iterative self-refinement. During preprocessing, an LLM translator is employed to convert natural language input into a Planning Domain Definition Language (PDDL) formulation. In the planning phase, an LLM planner formulates an initial plan, which is then assessed and refined in the iterative self-refinement step by using a validator. We examine the performance of ISR-LLM across three distinct planning domains. The results show that ISR-LLM is able to achieve markedly higher success rates in task accomplishments compared to state-of-the-art LLM-based planners. Moreover, it also preserves the broad applicability and generalizability of working with natural language instructions. ","[{'version': 'v1', 'created': 'Sat, 26 Aug 2023 01:31:35 GMT'}]",2023-08-29,"[['Zhou', 'Zhehua', ''], ['Song', 'Jiayang', ''], ['Yao', 'Kunpeng', ''], ['Shu', 'Zhan', ''], ['Ma', 'Lei', '']]",0,0,2023-08-26,1,5,2,0,0,0,dcf87f11e245b76437c2f551c1ff6a7842585811,261245497.0,https://www.semanticscholar.org/paper/dcf87f11e245b76437c2f551c1ff6a7842585811,arXiv.org,2023.0,50.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35366941', 'name': 'Zhehua Zhou'}, {'authorId': '3427937', 'name': 'Jiayang Song'}, {'authorId': '13319361', 'name': 'Kunpeng Yao'}, {'authorId': '2234398874', 'name': 'Zhan Shu'}, {'authorId': '49198778', 'name': 'Lei Ma'}]","['École Polytechnique Fédérale de Lausanne', 'University of Alberta', 'The University of Tokyo']","['Canada', 'Japan', 'Switzerland']",2023-08
2308.13768,Charles O'Neill,"Charles O'Neill, Jack Miller, Ioana Ciuca, Yuan-Sen Ting, Thang Bui",Adversarial Fine-Tuning of Language Models: An Iterative Optimisation Approach for the Generation and Detection of Problematic Content,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In this paper, we tackle the emerging challenge of unintended harmful content generation in Large Language Models (LLMs) with a novel dual-stage optimisation technique using adversarial fine-tuning. Our two-pronged approach employs an adversarial model, fine-tuned to generate potentially harmful prompts, and a judge model, iteratively optimised to discern these prompts. In this adversarial cycle, the two models seek to outperform each other in the prompting phase, generating a dataset of rich examples which are then used for fine-tuning. This iterative application of prompting and fine-tuning allows continuous refinement and improved performance. The performance of our approach is evaluated through classification accuracy on a dataset consisting of problematic prompts not detected by GPT-4, as well as a selection of contentious but unproblematic prompts. We show considerable increase in classification accuracy of the judge model on this challenging dataset as it undergoes the optimisation process. Furthermore, we show that a rudimentary model \texttt{ada} can achieve 13\% higher accuracy on the hold-out test set than GPT-4 after only a few rounds of this process, and that this fine-tuning improves performance in parallel tasks such as toxic comment identification. ","[{'version': 'v1', 'created': 'Sat, 26 Aug 2023 05:20:58 GMT'}]",2023-08-29,"[[""O'Neill"", 'Charles', ''], ['Miller', 'Jack', ''], ['Ciuca', 'Ioana', ''], ['Ting', 'Yuan-Sen', ''], ['Bui', 'Thang', '']]",0,1,2023-08-26,1,5,2,1,0,1,09680ee0e95504e20c4f829560eb85246ba91aae,261242802.0,https://www.semanticscholar.org/paper/09680ee0e95504e20c4f829560eb85246ba91aae,arXiv.org,2023.0,52.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2072014290', 'name': ""C. O'Neill""}, {'authorId': '2229023715', 'name': 'Jack W. Miller'}, {'authorId': '50062876', 'name': 'I. Ciucă'}, {'authorId': '93622633', 'name': 'Y. Ting'}, {'authorId': '2229238231', 'name': 'Thang Bui'}]",['Australian National University'],['Australia'],2023-08
2308.13812,Hao Fei,"Hao Fei, Shengqiong Wu, Wei Ji, Hanwang Zhang, Tat-Seng Chua",Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models,,,,,cs.AI cs.CV,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Text-to-video (T2V) synthesis has gained increasing attention in the community, in which the recently emerged diffusion models (DMs) have promisingly shown stronger performance than the past approaches. While existing state-of-the-art DMs are competent to achieve high-resolution video generation, they may largely suffer from key limitations (e.g., action occurrence disorders, crude video motions) with respect to the intricate temporal dynamics modeling, one of the crux of video synthesis. In this work, we investigate strengthening the awareness of video dynamics for DMs, for high-quality T2V generation. Inspired by human intuition, we design an innovative dynamic scene manager (dubbed as Dysen) module, which includes (step-1) extracting from input text the key actions with proper time-order arrangement, (step-2) transforming the action schedules into the dynamic scene graph (DSG) representations, and (step-3) enriching the scenes in the DSG with sufficient and reasonable details. Taking advantage of the existing powerful LLMs (e.g., ChatGPT) via in-context learning, Dysen realizes (nearly) human-level temporal dynamics understanding. Finally, the resulting video DSG with rich action scene details is encoded as fine-grained spatio-temporal features, integrated into the backbone T2V DM for video generating. Experiments on popular T2V datasets suggest that our framework consistently outperforms prior arts with significant margins, especially in the scenario with complex actions. Project page at https://haofei.vip/Dysen-VDM ","[{'version': 'v1', 'created': 'Sat, 26 Aug 2023 08:31:48 GMT'}]",2023-08-29,"[['Fei', 'Hao', ''], ['Wu', 'Shengqiong', ''], ['Ji', 'Wei', ''], ['Zhang', 'Hanwang', ''], ['Chua', 'Tat-Seng', '']]",1,1,2023-08-26,1,5,2,1,0,1,d0a7f7fe31e0e0c42b471b4c47a313bd8c8e5206,261243084.0,https://www.semanticscholar.org/paper/d0a7f7fe31e0e0c42b471b4c47a313bd8c8e5206,arXiv.org,2023.0,78.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2142672912', 'name': 'Hao Fei'}, {'authorId': '1957924118', 'name': 'Shengqiong Wu'}, {'authorId': '2072613978', 'name': 'Wei Ji'}, {'authorId': '5462268', 'name': 'Hanwang Zhang'}, {'authorId': '143779329', 'name': 'Tat-seng Chua'}]","['National University of Singapore', 'Nanyang Technological University']",['Singapore'],2023-08
2308.13963,Palash Roy,"Ajmain Inqiad Alam, Palash Ranjan Roy, Farouq Al-omari, Chanchal Kumar
  Roy, Banani Roy, Kevin Schneider",GPTCloneBench: A comprehensive benchmark of semantic clones and cross-language clones using GPT-3 model and SemanticCloneBench,"Accepted in 39th IEEE International Conference on Software
  Maintenance and Evolution(ICSME 2023)",,,,cs.SE,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  With the emergence of Machine Learning, there has been a surge in leveraging its capabilities for problem-solving across various domains. In the code clone realm, the identification of type-4 or semantic clones has emerged as a crucial yet challenging task. Researchers aim to utilize Machine Learning to tackle this challenge, often relying on the BigCloneBench dataset. However, it's worth noting that BigCloneBench, originally not designed for semantic clone detection, presents several limitations that hinder its suitability as a comprehensive training dataset for this specific purpose. Furthermore, CLCDSA dataset suffers from a lack of reusable examples aligning with real-world software systems, rendering it inadequate for cross-language clone detection approaches. In this work, we present a comprehensive semantic clone and cross-language clone benchmark, GPTCloneBench by exploiting SemanticCloneBench and OpenAI's GPT-3 model. In particular, using code fragments from SemanticCloneBench as sample inputs along with appropriate prompt engineering for GPT-3 model, we generate semantic and cross-language clones for these specific fragments and then conduct a combination of extensive manual analysis, tool-assisted filtering, functionality testing and automated validation in building the benchmark. From 79,928 clone pairs of GPT-3 output, we created a benchmark with 37,149 true semantic clone pairs, 19,288 false semantic pairs(Type-1/Type-2), and 20,770 cross-language clones across four languages (Java, C, C#, and Python). Our benchmark is 15-fold larger than SemanticCloneBench, has more functional code examples for software systems and programming language support than CLCDSA, and overcomes BigCloneBench's qualities, quantification, and language variety limitations. ","[{'version': 'v1', 'created': 'Sat, 26 Aug 2023 21:50:34 GMT'}, {'version': 'v2', 'created': 'Fri, 1 Sep 2023 17:44:38 GMT'}]",2023-09-04,"[['Alam', 'Ajmain Inqiad', ''], ['Roy', 'Palash Ranjan', ''], ['Al-omari', 'Farouq', ''], ['Roy', 'Chanchal Kumar', ''], ['Roy', 'Banani', ''], ['Schneider', 'Kevin', '']]",0,1,2023-08-26,2,6,1,1,0,1,50d40d05598e456188a3be42983b8daabd3f04f7,261245622.0,https://www.semanticscholar.org/paper/50d40d05598e456188a3be42983b8daabd3f04f7,arXiv.org,2023.0,58.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '70645384', 'name': 'A. Alam'}, {'authorId': '2051272535', 'name': 'Palash Roy'}, {'authorId': '67187029', 'name': 'Farouq Al-Omari'}, {'authorId': '1738612', 'name': 'C. Roy'}, {'authorId': '50666808', 'name': 'B. Roy'}, {'authorId': '38558513', 'name': 'Kevin A. Schneider'}]",['University of Saskatchewan'],['Canada'],2023-08
2308.14186,Leonardo Ranaldi Mr,"Leonardo Ranaldi, Giulia Pucci, Andre Freitas",Empowering Cross-lingual Abilities of Instruction-tuned Large Language Models by Translation-following demonstrations,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The language ability of Large Language Models (LLMs) is often unbalanced towards English because of the imbalance in the distribution of the pre-training data. This disparity is demanded in further fine-tuning and affecting the cross-lingual abilities of LLMs. In this paper, we propose to empower Instructiontuned LLMs (It-LLMs) in languages other than English by building semantic alignment between them. Hence, we propose CrossAlpaca, an It-LLM with cross-lingual instruction-following and Translation-following demonstrations to improve semantic alignment between languages. We validate our approach on the multilingual Question Answering (QA) benchmarks XQUAD and MLQA and adapted versions of MMLU and BBH. Our models, tested over six different languages, outperform the It-LLMs tuned on monolingual data. The final results show that instruction tuning on non-English data is not enough and that semantic alignment can be further improved by Translation-following demonstrations. ","[{'version': 'v1', 'created': 'Sun, 27 Aug 2023 19:22:12 GMT'}]",2023-08-29,"[['Ranaldi', 'Leonardo', ''], ['Pucci', 'Giulia', ''], ['Freitas', 'Andre', '']]",0,0,2023-08-27,1,3,2,0,0,0,630c62c60720f9a6ee1708c6ad586c020fb4b5d2,261242630.0,https://www.semanticscholar.org/paper/630c62c60720f9a6ee1708c6ad586c020fb4b5d2,arXiv.org,2023.0,47.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2008183566', 'name': 'Leonardo Ranaldi'}, {'authorId': '2199247500', 'name': 'Giulia Pucci'}, {'authorId': '145528474', 'name': 'A. Freitas'}]","['University of Manchester', 'Idiap Research Institute']","['United Kingdom', 'Switzerland']",2023-08
2308.14266,Wen Yu Chang Morris,"Wen-Yu Chang, Yun-Nung Chen",SalesBot 2.0: A Human-Like Intent-Guided Chit-Chat Dataset,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In recent research on dialogue systems and corpora, there has been a significant focus on two distinct categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD systems aim to satisfy specific user goals, such as finding a movie to watch, whereas open-domain systems primarily focus on generating engaging conversations. A recent study by Chiu et al. (2022) introduced SalesBot, which provides simulators and a dataset with one-turn transition from chit-chat to task-oriented dialogues. However, the previously generated data solely relied on BlenderBot, which raised concerns about its long-turn naturalness and consistency during a conversation. To address this issue, this paper aims to build SalesBot 2.0, a revised version of the published data, by leveraging the commonsense knowledge of large language models (LLMs) through proper prompting. The objective is to gradually bridge the gap between chit-chat and TOD towards better naturalness and consistency. The newly released large-scale dataset with detailed annotations exhibits smoother transitions between topics and is more human-like in terms of naturalness and consistency. It can serve as a valuable resource for both academic research and commercial applications. Furthermore, our proposed framework can be applied to generate numerous dialogues with various target intents. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 02:48:49 GMT'}]",2023-08-29,"[['Chang', 'Wen-Yu', ''], ['Chen', 'Yun-Nung', '']]",0,0,2023-08-28,1,2,2,0,0,0,369bc24b935357d661dbefd66dc3c3b6403c4cb9,261242890.0,https://www.semanticscholar.org/paper/369bc24b935357d661dbefd66dc3c3b6403c4cb9,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50310256', 'name': 'Wen-Yu Chang'}, {'authorId': '1725643', 'name': 'Yun-Nung (Vivian) Chen'}]",['National Taiwan University'],['Taiwan'],2023-08
2308.14306,Yuansheng Ni,"Yuansheng Ni, Sichao Jiang, Xinyu wu, Hui Shen, Yuli Zhou",Evaluating the Robustness to Instructions of Large Language Models,"In our study, erroneous data analysis inadvertently led to misleading
  outcomes. Incorrect variables were included, distorting results. This
  emphasizes the significance of robust data processing and analysis techniques
  in research",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recently, Instruction fine-tuning has risen to prominence as a potential method for enhancing the zero-shot capabilities of Large Language Models (LLMs) on novel tasks. This technique has shown an exceptional ability to boost the performance of moderately sized LLMs, sometimes even reaching performance levels comparable to those of much larger model variants. The focus is on the robustness of instruction-tuned LLMs to seen and unseen tasks. We conducted an exploration of six models including Alpaca, Vicuna, WizardLM, and Traditional Task-oriented Models(Flan-T5-XL/XXL, T0++) using real-world relation extraction datasets as case studies. We carried out a comprehensive evaluation of these instruction-following LLMs which have been tuned based on open-domain instructions and task-oriented instructions. The main discussion is their performance and robustness towards instructions. We have observed that in most cases, the model's performance in dealing with unfamiliar instructions tends to worsen significantly, and the robustness of the model for RE instructions deteriorates compared to QA. Further, we discovered that up until a certain parameter size threshold (3B), the performance of the FLAN-T5 model improves as the parameter count increases. The robustness of different scales of FLAN-T5 models to RE instruction is worse than the robustness to QA instruction. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 04:57:07 GMT'}, {'version': 'v2', 'created': 'Tue, 29 Aug 2023 20:10:50 GMT'}]",2023-08-31,"[['Ni', 'Yuansheng', ''], ['Jiang', 'Sichao', ''], ['wu', 'Xinyu', ''], ['Shen', 'Hui', ''], ['Zhou', 'Yuli', '']]",0,0,2023-08-28,2,5,2,6,4,2,8c71e49b619a941d6da7747e37221e8a4d567200,261242705.0,https://www.semanticscholar.org/paper/8c71e49b619a941d6da7747e37221e8a4d567200,arXiv.org,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2234349553', 'name': 'Yuansheng Ni'}, {'authorId': '2234534845', 'name': 'Sichao Jiang'}, {'authorId': '2155226277', 'name': 'Xinyu Wu'}, {'authorId': '2235493404', 'name': 'Hui Shen'}, {'authorId': '2110320956', 'name': 'Yuli Zhou'}]",['University of Zurich'],['Switzerland'],2023-08
2308.14337,Jonathan Shaki,"Jonathan Shaki, Sarit Kraus, Michael Wooldridge",Cognitive Effects in Large Language Models,Accepted and will be published in the ECAI conference,,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) such as ChatGPT have received enormous attention over the past year and are now used by hundreds of millions of people every day. The rapid adoption of this technology naturally raises questions about the possible biases such models might exhibit. In this work, we tested one of these models (GPT-3) on a range of cognitive effects, which are systematic patterns that are usually found in human cognitive tasks. We found that LLMs are indeed prone to several human cognitive effects. Specifically, we show that the priming, distance, SNARC, and size congruity effects were presented with GPT-3, while the anchoring effect is absent. We describe our methodology, and specifically the way we converted real-world experiments to text-based experiments. Finally, we speculate on the possible reasons why GPT-3 exhibits these effects and discuss whether they are imitated or reinvented. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 06:30:33 GMT'}]",2023-08-29,"[['Shaki', 'Jonathan', ''], ['Kraus', 'Sarit', ''], ['Wooldridge', 'Michael', '']]",1,1,2023-08-28,1,3,2,2,0,2,3d85460139dd4a49e3d601daebfce86c50577bca,261242972.0,https://www.semanticscholar.org/paper/3d85460139dd4a49e3d601daebfce86c50577bca,European Conference on Artificial Intelligence,2023.0,39.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2234348128', 'name': 'Jonathan Shaki'}, {'authorId': '1691597', 'name': 'Sarit Kraus'}, {'authorId': '48106342', 'name': 'M. Wooldridge'}]","['University of Oxford', 'Bar-Ilan University']","['United Kingdom', 'Israel']",2023-08
2308.14429,Xi Yan,"Xi Yan, Cedric M\""oller and Ricardo Usbeck",Biomedical Entity Linking with Triple-aware Pre-Training,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Linking biomedical entities is an essential aspect in biomedical natural language processing tasks, such as text mining and question answering. However, a difficulty of linking the biomedical entities using current large language models (LLM) trained on a general corpus is that biomedical entities are scarcely distributed in texts and therefore have been rarely seen during training by the LLM. At the same time, those LLMs are not aware of high level semantic connection between different biomedical entities, which are useful in identifying similar concepts in different textual contexts. To cope with aforementioned problems, some recent works focused on injecting knowledge graph information into LLMs. However, former methods either ignore the relational knowledge of the entities or lead to catastrophic forgetting. Therefore, we propose a novel framework to pre-train the powerful generative LLM by a corpus synthesized from a KG. In the evaluations we are unable to confirm the benefit of including synonym, description or relational information. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 09:06:28 GMT'}]",2023-08-29,"[['Yan', 'Xi', ''], ['Möller', 'Cedric', ''], ['Usbeck', 'Ricardo', '']]",0,0,2023-08-28,1,3,2,0,0,0,c8af5d5bc5d9bbc60f8f942d749e579583d87cf7,261243000.0,https://www.semanticscholar.org/paper/c8af5d5bc5d9bbc60f8f942d749e579583d87cf7,arXiv.org,2023.0,22.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2160701193', 'name': 'Xiongliang Yan'}, {'authorId': '2143124795', 'name': 'Cedric Moller'}, {'authorId': '2370666', 'name': 'Ricardo Usbeck'}]",['Universität Hamburg'],['Germany'],2023-08
2308.14634,Lefteris Loukas,"Lefteris Loukas, Ilias Stogiannidis, Prodromos Malakasiotis, Stavros
  Vassos",Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance,Early pre-print; Accepted at the 5th FinNLP workshop @ IJCAI-2023,,,,cs.CL cs.AI cs.LG q-fin.CP,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  We propose the use of conversational GPT models for easy and quick few-shot text classification in the financial domain using the Banking77 dataset. Our approach involves in-context learning with GPT-3.5 and GPT-4, which minimizes the technical expertise required and eliminates the need for expensive GPU computing while yielding quick and accurate results. Additionally, we fine-tune other pre-trained, masked language models with SetFit, a recent contrastive learning technique, to achieve state-of-the-art results both in full-data and few-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can outperform fine-tuned, non-generative models even with fewer examples. However, subscription fees associated with these solutions may be considered costly for small organizations. Lastly, we find that generative models perform better on the given task when shown representative samples selected by a human expert rather than when shown random ones. We conclude that a) our proposed methods offer a practical solution for few-shot tasks in datasets with limited label availability, and b) our state-of-the-art results can inspire future work in the area. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 15:04:16 GMT'}]",2023-08-29,"[['Loukas', 'Lefteris', ''], ['Stogiannidis', 'Ilias', ''], ['Malakasiotis', 'Prodromos', ''], ['Vassos', 'Stavros', '']]",1,1,2023-08-28,1,4,4,3,0,3,64f6efeed573a0862f4cf66897f0ec34ad7fc95d,261245297.0,https://www.semanticscholar.org/paper/64f6efeed573a0862f4cf66897f0ec34ad7fc95d,FINNLP,2023.0,48.0,1.0,0.0,True,"['Computer Science', 'Economics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2130142972', 'name': 'L. Loukas'}, {'authorId': '2234394970', 'name': 'Ilias Stogiannidis'}, {'authorId': '1950133', 'name': 'Prodromos Malakasiotis'}, {'authorId': '1728186', 'name': 'S. Vassos'}]",['Athens University of Economics and Business'],['Greece'],2023-08
2308.14683,Thanh Thi Nguyen,"Thanh Thi Nguyen, Campbell Wilson, Janis Dalins",Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual Predatory Chats and Abusive Texts,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Detecting online sexual predatory behaviours and abusive language on social media platforms has become a critical area of research due to the growing concerns about online safety, especially for vulnerable populations such as children and adolescents. Researchers have been exploring various techniques and approaches to develop effective detection systems that can identify and mitigate these risks. Recent development of large language models (LLMs) has opened a new opportunity to address this problem more effectively. This paper proposes an approach to detection of online sexual predatory chats and abusive language using the open-source pretrained Llama 2 7B-parameter model, recently released by Meta GenAI. We fine-tune the LLM using datasets with different sizes, imbalance degrees, and languages (i.e., English, Roman Urdu and Urdu). Based on the power of LLMs, our approach is generic and automated without a manual search for a synergy between feature extraction and classifier design steps like conventional methods in this domain. Experimental results show a strong performance of the proposed approach, which performs proficiently and consistently across three distinct datasets with five sets of experiments. This study's outcomes indicate that the proposed method can be implemented in real-world applications (even with non-English languages) for flagging sexual predators, offensive or toxic content, hate speech, and discriminatory language in online discussions and comments to maintain respectful internet or digital communities. Furthermore, it can be employed for solving text classification problems with other potential applications such as sentiment analysis, spam and phishing detection, sorting legal documents, fake news detection, language identification, user intent recognition, text-based product categorization, medical record analysis, and resume screening. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 16:18:50 GMT'}]",2023-08-29,"[['Nguyen', 'Thanh Thi', ''], ['Wilson', 'Campbell', ''], ['Dalins', 'Janis', '']]",0,0,2023-08-28,1,3,3,1,1,0,a69af3b83b1f2e5e3e3673352c8532b30bf5b80c,261243153.0,https://www.semanticscholar.org/paper/a69af3b83b1f2e5e3e3673352c8532b30bf5b80c,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2162300434', 'name': 'Thanh Thi Nguyen'}, {'authorId': '2108929741', 'name': 'Campbell Wilson'}, {'authorId': '1932038', 'name': 'Janis Dalins'}]",['Monash University'],['Australia'],2023-08
2308.14732,Renato Krohling,Renato A. Krohling,Bayesian artificial brain with ChatGPT,,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper aims to investigate the mathematical problem-solving capabilities of Chat Generative Pre-Trained Transformer (ChatGPT) in case of Bayesian reasoning. The study draws inspiration from Zhu & Gigerenzer's research in 2006, which posed the question: Can children reason the Bayesian way? In the pursuit of answering this question, a set of 10 Bayesian reasoning problems were presented. The results of their work revealed that children's ability to reason effectively using Bayesian principles is contingent upon a well-structured information representation. In this paper, we present the same set of 10 Bayesian reasoning problems to ChatGPT. Remarkably, the results demonstrate that ChatGPT provides the right solutions to all problems. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 17:34:24 GMT'}]",2023-08-29,"[['Krohling', 'Renato A.', '']]",1,1,2023-08-28,1,1,1,1,0,1,512230fb04f55b19cb860a66c0975a3798f4f67f,261276808.0,https://www.semanticscholar.org/paper/512230fb04f55b19cb860a66c0975a3798f4f67f,arXiv.org,2023.0,5.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2884202', 'name': 'R. Krohling'}]",['Universidade Federal do Espírito Santo'],['Brazil'],2023-08
2308.14746,Lucas Ventura,"Lucas Ventura, Antoine Yang, Cordelia Schmid, G\""ul Varol",CoVR: Learning Composed Video Retrieval from Web Video Captions,,,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Composed Image Retrieval (CoIR) has recently gained popularity as a task that considers both text and image queries together, to search for relevant images in a database. Most CoIR approaches require manually annotated datasets, comprising image-text-image triplets, where the text describes a modification from the query image to the target image. However, manual curation of CoIR triplets is expensive and prevents scalability. In this work, we instead propose a scalable automatic dataset creation methodology that generates triplets given video-caption pairs, while also expanding the scope of the task to include composed video retrieval (CoVR). To this end, we mine paired videos with a similar caption from a large database, and leverage a large language model to generate the corresponding modification text. Applying this methodology to the extensive WebVid2M collection, we automatically construct our WebVid-CoVR dataset, resulting in 1.6 million triplets. Moreover, we introduce a new benchmark for CoVR with a manually annotated evaluation set, along with baseline results. Our experiments further demonstrate that training a CoVR model on our dataset effectively transfers to CoIR, leading to improved state-of-the-art performance in the zero-shot setup on both the CIRR and FashionIQ benchmarks. Our code, datasets, and models are publicly available at https://imagine.enpc.fr/~ventural/covr. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 17:55:33 GMT'}]",2023-08-29,"[['Ventura', 'Lucas', ''], ['Yang', 'Antoine', ''], ['Schmid', 'Cordelia', ''], ['Varol', 'Gül', '']]",0,0,2023-08-28,1,4,1,0,0,0,1b6e40c46f2e680620cf70218ae4edbc895d305f,261276645.0,https://www.semanticscholar.org/paper/1b6e40c46f2e680620cf70218ae4edbc895d305f,arXiv.org,2023.0,77.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2060550280', 'name': 'Lucas Ventura'}, {'authorId': '2064599701', 'name': 'Antoine Yang'}, {'authorId': '2462253', 'name': 'C. Schmid'}, {'authorId': '2668759', 'name': 'Gül Varol'}]","[""Laboratoire d'Informatique Gaspard-Monge"", 'Université Paris Sciences et Lettres']",['France'],2023-08
2308.14752,Peter S. Park,"Peter S. Park, Simon Goldstein, Aidan O'Gara, Michael Chen, Dan
  Hendrycks","AI Deception: A Survey of Examples, Risks, and Potential Solutions","18 pages (not including executive summary, references, and appendix),
  six figures",,,,cs.CY cs.AI cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper argues that a range of current AI systems have learned how to deceive humans. We define deception as the systematic inducement of false beliefs in the pursuit of some outcome other than the truth. We first survey empirical examples of AI deception, discussing both special-use AI systems (including Meta's CICERO) built for specific competitive situations, and general-purpose AI systems (such as large language models). Next, we detail several risks from AI deception, such as fraud, election tampering, and losing control of AI systems. Finally, we outline several potential solutions to the problems posed by AI deception: first, regulatory frameworks should subject AI systems that are capable of deception to robust risk-assessment requirements; second, policymakers should implement bot-or-not laws; and finally, policymakers should prioritize the funding of relevant research, including tools to detect AI deception and to make AI systems less deceptive. Policymakers, researchers, and the broader public should work proactively to prevent AI deception from destabilizing the shared foundations of our society. ","[{'version': 'v1', 'created': 'Mon, 28 Aug 2023 17:59:35 GMT'}]",2023-08-29,"[['Park', 'Peter S.', ''], ['Goldstein', 'Simon', ''], [""O'Gara"", 'Aidan', ''], ['Chen', 'Michael', ''], ['Hendrycks', 'Dan', '']]",0,0,2023-08-28,1,5,3,0,0,0,05ef87f4d0e7b7506bb81b350e71da61b8cee4b9,261276587.0,https://www.semanticscholar.org/paper/05ef87f4d0e7b7506bb81b350e71da61b8cee4b9,arXiv.org,2023.0,103.0,11.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2204761274', 'name': 'Peter S. Park'}, {'authorId': '145744178', 'name': 'Simon Goldstein'}, {'authorId': '2226774081', 'name': ""Aidan O'Gara""}, {'authorId': '2235148916', 'name': 'Michael Chen'}, {'authorId': '3422872', 'name': 'Dan Hendrycks'}]","['Australian Catholic University', 'Center for AI Safety']",['Australia'],2023-08
2308.14963,Jimmy Lin,"Jimmy Lin, Ronak Pradeep, Tommaso Teofili, Jasper Xian",Vector Search with OpenAI Embeddings: Lucene Is All You Need,,,,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We provide a reproducible, end-to-end demonstration of vector search with OpenAI embeddings using Lucene on the popular MS MARCO passage ranking test collection. The main goal of our work is to challenge the prevailing narrative that a dedicated vector store is necessary to take advantage of recent advances in deep neural networks as applied to search. Quite the contrary, we show that hierarchical navigable small-world network (HNSW) indexes in Lucene are adequate to provide vector search capabilities in a standard bi-encoder architecture. This suggests that, from a simple cost-benefit analysis, there does not appear to be a compelling reason to introduce a dedicated vector store into a modern ""AI stack"" for search, since such applications have already received substantial investments in existing, widely deployed infrastructure. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 01:30:23 GMT'}]",2023-08-30,"[['Lin', 'Jimmy', ''], ['Pradeep', 'Ronak', ''], ['Teofili', 'Tommaso', ''], ['Xian', 'Jasper', '']]",0,0,2023-08-29,1,4,1,0,0,0,a08bde10a47059b0ba1e58b425dd080ec9b42339,261276669.0,https://www.semanticscholar.org/paper/a08bde10a47059b0ba1e58b425dd080ec9b42339,arXiv.org,2023.0,29.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2154743364', 'name': 'Jimmy Lin'}, {'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '2235063355', 'name': 'Tommaso Teofili'}, {'authorId': '2235064158', 'name': 'Jasper Xian'}]","['Roma Tre University', 'University of Waterloo']","['Canada', 'Italy']",2023-08
2308.14972,Yaonan Zhu,"Haokun Liu, Yaonan Zhu, Kenji Kato, Izumi Kondo, Tadayoshi Aoyama, and
  Yasuhisa Hasegawa",LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks,IEEE MHS 2023,,,,cs.RO cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper presents a novel approach to enhance autonomous robotic manipulation using the Large Language Model (LLM) for logical inference, converting high-level language commands into sequences of executable motion functions. The proposed system combines the advantage of LLM with YOLO-based environmental perception to enable robots to autonomously make reasonable decisions and task planning based on the given commands. Additionally, to address the potential inaccuracies or illogical actions arising from LLM, a combination of teleoperation and Dynamic Movement Primitives (DMP) is employed for action correction. This integration aims to improve the practicality and generalizability of the LLM-based human-robot collaboration system. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 01:54:49 GMT'}]",2023-08-30,"[['Liu', 'Haokun', ''], ['Zhu', 'Yaonan', ''], ['Kato', 'Kenji', ''], ['Kondo', 'Izumi', ''], ['Aoyama', 'Tadayoshi', ''], ['Hasegawa', 'Yasuhisa', '']]",0,0,2023-08-29,1,6,2,0,0,0,83c3ddd2e56152c8361bfad7d0522a03aa4de6c2,261277182.0,https://www.semanticscholar.org/paper/83c3ddd2e56152c8361bfad7d0522a03aa4de6c2,arXiv.org,2023.0,5.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '48447436', 'name': 'Haokun Liu'}, {'authorId': '8247318', 'name': 'Yaonan Zhu'}, {'authorId': '2110285301', 'name': 'Kenji Kato'}, {'authorId': '78210211', 'name': 'Izumi Kondo'}, {'authorId': '1752849', 'name': 'T. Aoyama'}, {'authorId': '2068240315', 'name': 'Y. Hasegawa'}]","['National Center for Geriatrics and Gerontology', 'Nagoya University']",['Japan'],2023-08
2308.15047,Mathias Gammelgaard,"Mathias Lykke Gammelgaard, Jonathan Gabel Christiansen, Anders
  S{\o}gaard",Large language models converge toward human-like concept organization,,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models show human-like performance in knowledge extraction, reasoning and dialogue, but it remains controversial whether this performance is best explained by memorization and pattern matching, or whether it reflects human-like inferential semantics and world knowledge. Knowledge bases such as WikiData provide large-scale, high-quality representations of inferential semantics and world knowledge. We show that large language models learn to organize concepts in ways that are strikingly similar to how concepts are organized in such knowledge bases. Knowledge bases model collective, institutional knowledge, and large language models seem to induce such knowledge from raw text. We show that bigger and better models exhibit more human-like concept organization, across four families of language models and three knowledge graph embeddings. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 06:09:47 GMT'}]",2023-08-30,"[['Gammelgaard', 'Mathias Lykke', ''], ['Christiansen', 'Jonathan Gabel', ''], ['Søgaard', 'Anders', '']]",0,0,2023-08-29,1,3,2,0,0,0,9b2d422225142abef905433173d3307a3fb2bb3a,261277205.0,https://www.semanticscholar.org/paper/9b2d422225142abef905433173d3307a3fb2bb3a,arXiv.org,2023.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2139776079', 'name': 'Mathias Gammelgaard'}, {'authorId': '2235072337', 'name': 'Jonathan Gabel Christiansen'}, {'authorId': '1700187', 'name': 'Anders Søgaard'}]",['University of Copenhagen'],['Denmark'],2023-08
2308.15118,Mu-Tien Kuo,"Mu-Tien Kuo, Chih-Chung Hsueh, Richard Tzong-Han Tsai",Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills,,,,,cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  While large language models have made strides in natural language processing, their proficiency in complex reasoning tasks requiring formal language comprehension, such as chess, remains less investigated. This paper probes the performance of ChatGPT, a sophisticated language model by OpenAI in tackling such complex reasoning tasks, using chess as a case study. Through robust metrics examining both the legality and quality of moves, we assess ChatGPT's understanding of the chessboard, adherence to chess rules, and strategic decision-making abilities. Our evaluation identifies limitations within ChatGPT's attention mechanism that affect its formal language comprehension and uncovers the model's underdeveloped self-regulation abilities. Our study also reveals ChatGPT's propensity for a coherent strategy in its gameplay and a noticeable uptick in decision-making assertiveness when the model is presented with a greater volume of natural language or possesses a more lucid understanding of the state of the chessboard. These findings contribute to the growing exploration of language models' abilities beyond natural language processing, providing valuable information for future research towards models demonstrating human-like cognitive abilities. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 08:36:30 GMT'}]",2023-08-30,"[['Kuo', 'Mu-Tien', ''], ['Hsueh', 'Chih-Chung', ''], ['Tsai', 'Richard Tzong-Han', '']]",1,1,2023-08-29,1,3,1,1,0,1,f221eccdd96122a42c5e65532373e6974b30c20c,261276512.0,https://www.semanticscholar.org/paper/f221eccdd96122a42c5e65532373e6974b30c20c,arXiv.org,2023.0,38.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2235060252', 'name': 'Mu-Tien Kuo'}, {'authorId': '145397010', 'name': 'Chih‐Chung Hsueh'}, {'authorId': '1724351', 'name': 'Richard Tzong-Han Tsai'}]","['Academia Sinica', 'National Central University', 'Chingshin Academy, Taiwan']",['Taiwan'],2023-08
2308.15197,Xinglei Wang,"Xinglei Wang, Meng Fang, Zichao Zeng, Tao Cheng",Where Would I Go Next? Large Language Models as Human Mobility Predictors,"13 pages, 5 figures, 4 tables",,,,cs.AI cs.SI physics.soc-ph,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Accurate human mobility prediction underpins many important applications across a variety of domains, including epidemic modelling, transport planning, and emergency responses. Due to the sparsity of mobility data and the stochastic nature of people's daily activities, achieving precise predictions of people's locations remains a challenge. While recently developed large language models (LLMs) have demonstrated superior performance across numerous language-related tasks, their applicability to human mobility studies remains unexplored. Addressing this gap, this article delves into the potential of LLMs for human mobility prediction tasks. We introduce a novel method, LLM-Mob, which leverages the language understanding and reasoning capabilities of LLMs for analysing human mobility data. We present concepts of historical stays and context stays to capture both long-term and short-term dependencies in human movement and enable time-aware prediction by using time information of the prediction target. Additionally, we design context-inclusive prompts that enable LLMs to generate more accurate predictions. Comprehensive evaluations of our method reveal that LLM-Mob excels in providing accurate and interpretable predictions, highlighting the untapped potential of LLMs in advancing human mobility prediction techniques. We posit that our research marks a significant paradigm shift in human mobility modelling, transitioning from building complex domain-specific models to harnessing general-purpose LLMs that yield accurate predictions through language instructions. The code for this work is available at https://github.com/xlwang233/LLM-Mob. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 10:24:23 GMT'}]",2023-08-30,"[['Wang', 'Xinglei', ''], ['Fang', 'Meng', ''], ['Zeng', 'Zichao', ''], ['Cheng', 'Tao', '']]",0,0,2023-08-29,1,4,3,0,0,0,68b39dd4e2327734851f6e0b96d10e021037499a,261276812.0,https://www.semanticscholar.org/paper/68b39dd4e2327734851f6e0b96d10e021037499a,arXiv.org,2023.0,43.0,2.0,0.0,True,"['Computer Science', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '153315857', 'name': 'Xinglei Wang'}, {'authorId': '2235066980', 'name': 'Meng Fang'}, {'authorId': '2237400428', 'name': 'Zichao Zeng'}, {'authorId': '2238293328', 'name': 'Tao Cheng'}]","['University College London', 'University of Liverpool']",['United Kingdom'],2023-08
2308.15214,Neeraj Cherakara,"Neeraj Cherakara, Finny Varghese, Sheena Shabana, Nivan Nelson,
  Abhiram Karukayil, Rohith Kulothungan, Mohammed Afil Farhan, Birthe Nesset,
  Meriam Moujahid, Tanvi Dinkar, Verena Rieser, Oliver Lemon","FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions","5 pages, 2 figures, Accepted at SIGDIAL 2023 (24th Meeting of the
  Special Interest Group on Discourse and Dialogue), for the demo video, see
  https://youtu.be/fwtUl1kl22s",,,,cs.CL cs.AI cs.HC cs.RO,http://creativecommons.org/licenses/by/4.0/,"  We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of open and closed-domain dialogue along with facial expressions, by using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 11:08:40 GMT'}, {'version': 'v2', 'created': 'Wed, 30 Aug 2023 13:13:19 GMT'}]",2023-08-31,"[['Cherakara', 'Neeraj', ''], ['Varghese', 'Finny', ''], ['Shabana', 'Sheena', ''], ['Nelson', 'Nivan', ''], ['Karukayil', 'Abhiram', ''], ['Kulothungan', 'Rohith', ''], ['Farhan', 'Mohammed Afil', ''], ['Nesset', 'Birthe', ''], ['Moujahid', 'Meriam', ''], ['Dinkar', 'Tanvi', ''], ['Rieser', 'Verena', ''], ['Lemon', 'Oliver', '']]",0,1,2023-08-29,2,12,4,1,0,1,c39ae3e539eb18f4e5fb06c3f1d71f484a48409e,261277101.0,https://www.semanticscholar.org/paper/c39ae3e539eb18f4e5fb06c3f1d71f484a48409e,SIGDIAL Conferences,2023.0,16.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2235069660', 'name': 'Neeraj Cherakara'}, {'authorId': '48042379', 'name': 'Finny S. Varghese'}, {'authorId': '2235070114', 'name': 'Sheena Shabana'}, {'authorId': '2235070359', 'name': 'Nivan Nelson'}, {'authorId': '2235068975', 'name': 'Abhiram Karukayil'}, {'authorId': '2235068496', 'name': 'Rohith Kulothungan'}, {'authorId': '2235069835', 'name': 'Mohammed Afil Farhan'}, {'authorId': '2052028780', 'name': 'Birthe Nesset'}, {'authorId': '2159681406', 'name': 'Meriam Moujahid'}, {'authorId': '72115354', 'name': 'Tanvi Dinkar'}, {'authorId': '1681799', 'name': 'Verena Rieser'}, {'authorId': '1782798', 'name': 'Oliver Lemon'}]",['Heriot-Watt University'],['United Kingdom'],2023-08
2308.15231,Angus Addlesee,"Angus Addlesee, Weronika Siei\'nska, Nancie Gunson, Daniel Hern\'andez
  Garcia, Christian Dondrup, Oliver Lemon","Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering",Accepted and will appear in the Proceedings of SIGdial 2023,,,,cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  This paper evaluates the extent to which current Large Language Models (LLMs) can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other's goals, and provide other people's goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The `reasoning' style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A `story' style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs. ","[{'version': 'v1', 'created': 'Tue, 29 Aug 2023 11:40:03 GMT'}]",2023-08-30,"[['Addlesee', 'Angus', ''], ['Sieińska', 'Weronika', ''], ['Gunson', 'Nancie', ''], ['Garcia', 'Daniel Hernández', ''], ['Dondrup', 'Christian', ''], ['Lemon', 'Oliver', '']]",0,1,2023-08-29,1,6,2,2,1,1,8a1a8290f7d42b0ce60445a4c0130ef737b3ff69,261276294.0,https://www.semanticscholar.org/paper/8a1a8290f7d42b0ce60445a4c0130ef737b3ff69,SIGDIAL Conferences,2023.0,52.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1389544608', 'name': 'Angus Addlesee'}, {'authorId': '2066269869', 'name': ""Weronika Siei'nska""}, {'authorId': '1748999', 'name': 'Nancie Gunson'}, {'authorId': '2082311020', 'name': 'Daniel Hernández García'}, {'authorId': '2069568', 'name': 'C. Dondrup'}, {'authorId': '1782798', 'name': 'Oliver Lemon'}]","['University of Edinburgh', 'Heriot-Watt University']",['United Kingdom'],2023-08
2308.15699,Fujio Toriumi,"Tomoki Fukuma, Koki Noda, Yuta Yamamoto, Takaya Hoshi, Yoshiharu
  Ichikawa, Kyosuke Kambe, Yu Masubuchi, Fujio Toriumi",Investigating Quantitative-Qualitative Topical Preference: A Comparative Study of Early and Late Engagers in Japanese ChatGPT Conversations,,,,,cs.SI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This study investigates engagement patterns related to OpenAI's ChatGPT on Japanese Twitter, focusing on two distinct user groups - early and late engagers, inspired by the Innovation Theory. Early engagers are defined as individuals who initiated conversations about ChatGPT during its early stages, whereas late engagers are those who began participating at a later date. To examine the nature of the conversations, we employ a dual methodology, encompassing both quantitative and qualitative analyses. The quantitative analysis reveals that early engagers often engage with more forward-looking and speculative topics, emphasizing the technological advancements and potential transformative impact of ChatGPT. Conversely, the late engagers intereact more with contemporary topics, focusing on the optimization of existing AI capabilities and considering their inherent limitations. Through our qualitative analysis, we propose a method to measure the proportion of shared or unique viewpoints within topics across both groups. We found that early engagers generally concentrate on a more limited range of perspectives, whereas late engagers exhibit a wider range of viewpoints. Interestingly, a weak correlation was found between the volume of tweets and the diversity of discussed topics in both groups. These findings underscore the importance of identifying semantic bias, rather than relying solely on the volume of tweets, for understanding differences in communication styles between groups within a given topic. Moreover, our versatile dual methodology holds potential for broader applications, such as studying engagement patterns within different user groups, or in contexts beyond ChatGPT. ","[{'version': 'v1', 'created': 'Wed, 30 Aug 2023 01:51:36 GMT'}]",2023-08-31,"[['Fukuma', 'Tomoki', ''], ['Noda', 'Koki', ''], ['Yamamoto', 'Yuta', ''], ['Hoshi', 'Takaya', ''], ['Ichikawa', 'Yoshiharu', ''], ['Kambe', 'Kyosuke', ''], ['Masubuchi', 'Yu', ''], ['Toriumi', 'Fujio', '']]",1,1,2023-08-30,1,8,1,1,0,1,effac5ff5960103483cda82bce0479a13d5ca10b,261339011.0,https://www.semanticscholar.org/paper/effac5ff5960103483cda82bce0479a13d5ca10b,arXiv.org,2023.0,15.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '1434548998', 'name': 'Tomoki Fukuma'}, {'authorId': '2171657247', 'name': 'Koki Noda'}, {'authorId': '2235831222', 'name': 'Yuta Yamamoto'}, {'authorId': '2235813571', 'name': 'Takaya Hoshi'}, {'authorId': '3237816', 'name': 'Yoshiharu Ichikawa'}, {'authorId': '72167464', 'name': 'Kyosuke Kambe'}, {'authorId': '1400682774', 'name': 'Yuki Masubuchi'}, {'authorId': '1777367', 'name': 'F. Toriumi'}]","['Japan Broadcasting Corporation (Japan)', 'TDAI Lab Co., Ltd., Japan', 'The University of Tokyo']",['Japan'],2023-08
2308.15762,Ziming Liu,"Ziming Liu, Shenggan Cheng, Haotian Zhou, Yang You",Hanayo: Harnessing Wave-like Pipeline Parallelism for Enhanced Large Model Training Efficiency,"12 pages, 12 figures. This paper has been accepted by SC23(The
  International Conference for High Performance Computing, Networking, Storage
  and Analysis). The information can be seen at
  https://sc23.supercomputing.org/presentation/?id=pap352&sess=sess168",,10.1145/3581784.3607073,,cs.DC,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large-scale language models have become increasingly challenging and expensive to train. Among various methods addressing this issue, Pipeline Parallelism has been widely employed to accommodate massive model weights within limited GPU memory. This paper introduces Hanayo, a wave-like pipeline parallelism strategy that boasts a concise structure and practical applicability, alongside a high-performance pipeline execution runtime to tackle the challenges of pipeline strategy implementation. Hanayo mitigates the issues of pipeline bubbles and excessive memory consumption prevalent in existing schemes, without resorting to model duplicates as in Chimera. Our evaluation, conducted on four distinct computing clusters and involving both GPT-like and BERT-like architectures with up to 32 GPUs, demonstrates up to a 30.4 \% increase in throughput compared to the state-of-the-art approach. ","[{'version': 'v1', 'created': 'Wed, 30 Aug 2023 05:03:29 GMT'}]",2023-08-31,"[['Liu', 'Ziming', ''], ['Cheng', 'Shenggan', ''], ['Zhou', 'Haotian', ''], ['You', 'Yang', '']]",0,1,2023-08-30,1,4,1,0,0,0,aa6ddad0a84eaa004e49142981d05c5f36cc585e,261339639.0,https://www.semanticscholar.org/paper/aa6ddad0a84eaa004e49142981d05c5f36cc585e,International Conference on Software Composition,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2117941801', 'name': 'Ziming Liu'}, {'authorId': '1454003795', 'name': 'Shenggan Cheng'}, {'authorId': '2111826798', 'name': 'Hao Zhou'}, {'authorId': '144259229', 'name': 'Yang You'}]",['National University of Singapore'],['Singapore'],2023-08
2308.16149,Preslav Nakov,"Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan
  Li, Fajri Koto, William Marshall, Gurpreet Gosal, Cynthia Liu, Zhiming Chen,
  Osama Mohammed Afzal, Samta Kamboj, Onkar Pandit, Rahul Pal, Lalit Pradhan,
  Zain Muhammad Mujahid, Massa Baali, Xudong Han, Sondos Mahmoud Bsharat, Alham
  Fikri Aji, Zhiqiang Shen, Zhengzhong Liu, Natalia Vassilieva, Joel Hestness,
  Andy Hock, Andrew Feldman, Jonathan Lee, Andrew Jackson, Hector Xuguang Ren,
  Preslav Nakov, Timothy Baldwin, Eric Xing",Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models,"Arabic-centric, foundation model, large-language model, LLM,
  generative model, instruction-tuned, Jais, Jais-chat",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs). The models are based on the GPT-3 decoder-only architecture and are pretrained on a mixture of Arabic and English texts, including source code in various programming languages. With 13 billion parameters, they demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin, based on extensive evaluation. Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data. We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs. Available at https://huggingface.co/inception-mbzuai/jais-13b-chat ","[{'version': 'v1', 'created': 'Wed, 30 Aug 2023 17:07:17 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Sep 2023 11:51:51 GMT'}]",2023-10-02,"[['Sengupta', 'Neha', ''], ['Sahu', 'Sunil Kumar', ''], ['Jia', 'Bokang', ''], ['Katipomu', 'Satheesh', ''], ['Li', 'Haonan', ''], ['Koto', 'Fajri', ''], ['Marshall', 'William', ''], ['Gosal', 'Gurpreet', ''], ['Liu', 'Cynthia', ''], ['Chen', 'Zhiming', ''], ['Afzal', 'Osama Mohammed', ''], ['Kamboj', 'Samta', ''], ['Pandit', 'Onkar', ''], ['Pal', 'Rahul', ''], ['Pradhan', 'Lalit', ''], ['Mujahid', 'Zain Muhammad', ''], ['Baali', 'Massa', ''], ['Han', 'Xudong', ''], ['Bsharat', 'Sondos Mahmoud', ''], ['Aji', 'Alham Fikri', ''], ['Shen', 'Zhiqiang', ''], ['Liu', 'Zhengzhong', ''], ['Vassilieva', 'Natalia', ''], ['Hestness', 'Joel', ''], ['Hock', 'Andy', ''], ['Feldman', 'Andrew', ''], ['Lee', 'Jonathan', ''], ['Jackson', 'Andrew', ''], ['Ren', 'Hector Xuguang', ''], ['Nakov', 'Preslav', ''], ['Baldwin', 'Timothy', ''], ['Xing', 'Eric', '']]",0,1,2023-08-30,2,32,3,1,0,1,5c577988ccebfea96de86678d04fd94fad367d2e,261339576.0,https://www.semanticscholar.org/paper/5c577988ccebfea96de86678d04fd94fad367d2e,arXiv.org,2023.0,119.0,7.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1880394', 'name': 'Neha Sengupta'}, {'authorId': '3422905', 'name': 'Sunil Kumar Sahu'}, {'authorId': '2087720002', 'name': 'Bokang Jia'}, {'authorId': '2235818050', 'name': 'Satheesh Katipomu'}, {'authorId': '49404498', 'name': 'Haonan Li'}, {'authorId': '2789148', 'name': 'Fajri Koto'}, {'authorId': '49843300', 'name': 'Osama Mohammed Afzal'}, {'authorId': '2203791403', 'name': 'Samta Kamboj'}, {'authorId': '22171629', 'name': 'O. Pandit'}, {'authorId': '2235794681', 'name': 'Rahul Pal'}, {'authorId': '2076256459', 'name': 'Lalit Pradhan'}, {'authorId': '123838298', 'name': 'Zainul Mujahid'}, {'authorId': '1380273855', 'name': 'Massa Baali'}, {'authorId': '2110982198', 'name': 'Xudong Han'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}, {'authorId': '100468503', 'name': 'Zhengzhong Liu'}, {'authorId': '2235826325', 'name': 'Andy Hock'}, {'authorId': '77917645', 'name': 'Andrew Feldman'}, {'authorId': '2235945609', 'name': 'Jonathan Lee'}, {'authorId': '2064974174', 'name': 'A. Jackson'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}, {'authorId': '145465286', 'name': 'Timothy Baldwin'}, {'authorId': '2064963077', 'name': 'Eric P. Xing'}]","['Inception, UAE', 'Cerebras Systems', 'Mohamed bin Zayed University of Artificial Intelligence']",['United Arab Emirates'],2023-08
2308.16316,Tanujit Chakraborty,"Tanujit Chakraborty, Ujjwal Reddy K S, Shraddha M. Naik, Madhurima
  Panja, Bayapureddy Manvitha",Ten Years of Generative Adversarial Nets (GANs): A survey of the state-of-the-art,,,,,cs.LG cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Since their inception in 2014, Generative Adversarial Networks (GANs) have rapidly emerged as powerful tools for generating realistic and diverse data across various domains, including computer vision and other applied areas. Consisting of a discriminative network and a generative network engaged in a Minimax game, GANs have revolutionized the field of generative modeling. In February 2018, GAN secured the leading spot on the ``Top Ten Global Breakthrough Technologies List'' issued by the Massachusetts Science and Technology Review. Over the years, numerous advancements have been proposed, leading to a rich array of GAN variants, such as conditional GAN, Wasserstein GAN, CycleGAN, and StyleGAN, among many others. This survey aims to provide a general overview of GANs, summarizing the latent architecture, validation metrics, and application areas of the most widely recognized variants. We also delve into recent theoretical developments, exploring the profound connection between the adversarial principle underlying GAN and Jensen-Shannon divergence, while discussing the optimality characteristics of the GAN framework. The efficiency of GAN variants and their model architectures will be evaluated along with training obstacles as well as training solutions. In addition, a detailed discussion will be provided, examining the integration of GANs with newly developed deep learning frameworks such as Transformers, Physics-Informed Neural Networks, Large Language models, and Diffusion models. Finally, we reveal several issues as well as future research outlines in this field. ","[{'version': 'v1', 'created': 'Wed, 30 Aug 2023 20:46:45 GMT'}]",2023-09-01,"[['Chakraborty', 'Tanujit', ''], ['S', 'Ujjwal Reddy K', ''], ['Naik', 'Shraddha M.', ''], ['Panja', 'Madhurima', ''], ['Manvitha', 'Bayapureddy', '']]",0,0,2023-08-30,1,5,2,0,0,0,d31b0f55bbe44caf586e3b0e8424129ea8f068cd,261396141.0,https://www.semanticscholar.org/paper/d31b0f55bbe44caf586e3b0e8424129ea8f068cd,arXiv.org,2023.0,250.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46204267', 'name': 'Tanujit Chakraborty'}, {'authorId': '2236706125', 'name': 'Ujjwal Reddy'}, {'authorId': '145704497', 'name': 'Shraddha M. Naik'}, {'authorId': '123545829', 'name': 'Madhurima Panja'}, {'authorId': '1661030647', 'name': 'B. Manvitha'}]","['Sorbonne Université', 'International Institute of Information Technology Bangalore', 'Vellore Institute of Technology University', 'Sorbonne University Abu Dhabi']","['India', 'France', 'United Arab Emirates']",2023-08
2308.16557,Arghavan Moradi Dakhel,"Arghavan Moradi Dakhel, Amin Nikanjam, Vahid Majdinasab, Foutse Khomh,
  Michel C. Desmarais",Effective Test Generation Using Pre-trained Large Language Models and Mutation Testing,"16 pages, 3 figures",,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  One of the critical phases in software development is software testing. Testing helps with identifying potential bugs and reducing maintenance costs. The goal of automated test generation tools is to ease the development of tests by suggesting efficient bug-revealing tests. Recently, researchers have leveraged Large Language Models (LLMs) of code to generate unit tests. While the code coverage of generated tests was usually assessed, the literature has acknowledged that the coverage is weakly correlated with the efficiency of tests in bug detection. To improve over this limitation, in this paper, we introduce MuTAP for improving the effectiveness of test cases generated by LLMs in terms of revealing bugs by leveraging mutation testing. Our goal is achieved by augmenting prompts with surviving mutants, as those mutants highlight the limitations of test cases in detecting bugs. MuTAP is capable of generating effective test cases in the absence of natural language descriptions of the Program Under Test (PUTs). We employ different LLMs within MuTAP and evaluate their performance on different benchmarks. Our results show that our proposed method is able to detect up to 28% more faulty human-written code snippets. Among these, 17% remained undetected by both the current state-of-the-art fully automated test generation tool (i.e., Pynguin) and zero-shot/few-shot learning approaches on LLMs. Furthermore, MuTAP achieves a Mutation Score (MS) of 93.57% on synthetic buggy code, outperforming all other approaches in our evaluation. Our findings suggest that although LLMs can serve as a useful tool to generate test cases, they require specific post-processing steps to enhance the effectiveness of the generated test cases which may suffer from syntactic or functional errors and may be ineffective in detecting certain types of bugs and testing corner cases PUTs. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 08:48:31 GMT'}]",2023-09-01,"[['Dakhel', 'Arghavan Moradi', ''], ['Nikanjam', 'Amin', ''], ['Majdinasab', 'Vahid', ''], ['Khomh', 'Foutse', ''], ['Desmarais', 'Michel C.', '']]",0,0,2023-08-31,1,5,1,0,0,0,958530b2a6267fd0c251a7c82e0267c21dca9cdf,261394507.0,https://www.semanticscholar.org/paper/958530b2a6267fd0c251a7c82e0267c21dca9cdf,arXiv.org,2023.0,53.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35647660', 'name': 'Arghavan Moradi Dakhel'}, {'authorId': '2076564', 'name': 'Amin Nikanjam'}, {'authorId': '2174176115', 'name': 'Vahid Majdinasab'}, {'authorId': '1703493', 'name': 'Foutse Khomh'}, {'authorId': '8994568', 'name': 'M. Desmarais'}]",['Polytechnique Montréal'],['Canada'],2023-08
2308.16622,Lars-Peter Meyer,"Lars-Peter Meyer, Johannes Frey, Kurt Junghanns, Felix Brei, Kirill
  Bulert, Sabine Gr\""under-Fahrer, Michael Martin",Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering,"To be published in SEMANTICS 2023 poster track proceedings. SEMANTICS
  2023 EU: 19th International Conference on Semantic Systems, September 20-22,
  2023, Leipzig, Germany",,,,cs.AI cs.CL cs.DB,http://creativecommons.org/licenses/by/4.0/,"  As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 10:31:19 GMT'}]",2023-09-01,"[['Meyer', 'Lars-Peter', ''], ['Frey', 'Johannes', ''], ['Junghanns', 'Kurt', ''], ['Brei', 'Felix', ''], ['Bulert', 'Kirill', ''], ['Gründer-Fahrer', 'Sabine', ''], ['Martin', 'Michael', '']]",0,0,2023-08-31,1,7,3,0,0,0,d0e3af5f20a451c04770929979d7a8406a1a2466,261395136.0,https://www.semanticscholar.org/paper/d0e3af5f20a451c04770929979d7a8406a1a2466,arXiv.org,2023.0,5.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145243956', 'name': 'Lars Meyer'}, {'authorId': '32114346', 'name': 'Johannes Frey'}, {'authorId': '48555227', 'name': 'K. Junghanns'}, {'authorId': '2236686278', 'name': 'Felix Brei'}, {'authorId': '2108312', 'name': 'Kirill Bulert'}, {'authorId': '1411787759', 'name': 'Sabine Grunder-Fahrer'}, {'authorId': '2216105617', 'name': 'Michael Martin'}]","['Institute for Applied Informatics, Goerdelerring 9, 04109 Leipzig, Germany, https:// infai.org', 'Agile Knowledge Engineering and Semantic Web (AKSW),', 'Leipzig University']",['Germany'],2023-08
2308.16753,Abhijit Anand,"Abhijit Anand, Venktesh V, Vinay Setty, Avishek Anand",Context Aware Query Rewriting for Text Rankers using LLM,,,,,cs.IR cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Query rewriting refers to an established family of approaches that are applied to underspecified and ambiguous queries to overcome the vocabulary mismatch problem in document ranking. Queries are typically rewritten during query processing time for better query modelling for the downstream ranker. With the advent of large-language models (LLMs), there have been initial investigations into using generative approaches to generate pseudo documents to tackle this inherent vocabulary gap. In this work, we analyze the utility of LLMs for improved query rewriting for text ranking tasks. We find that there are two inherent limitations of using LLMs as query re-writers -- concept drift when using only queries as prompts and large inference costs during query processing. We adopt a simple, yet surprisingly effective, approach called context aware query rewriting (CAR) to leverage the benefits of LLMs for query understanding. Firstly, we rewrite ambiguous training queries by context-aware prompting of LLMs, where we use only relevant documents as context.Unlike existing approaches, we use LLM-based query rewriting only during the training phase. Eventually, a ranker is fine-tuned on the rewritten queries instead of the original queries during training. In our extensive experiments, we find that fine-tuning a ranker using re-written queries offers a significant improvement of up to 33% on the passage ranking task and up to 28% on the document ranking task when compared to the baseline performance of using original queries. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 14:19:50 GMT'}]",2023-09-01,"[['Anand', 'Abhijit', ''], ['V', 'Venktesh', ''], ['Setty', 'Vinay', ''], ['Anand', 'Avishek', '']]",0,0,2023-08-31,1,4,2,0,0,0,dfea29ea51bcc6dece773d4054e6f7658cb33bf8,261395843.0,https://www.semanticscholar.org/paper/dfea29ea51bcc6dece773d4054e6f7658cb33bf8,arXiv.org,2023.0,56.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2161343505', 'name': 'Abhijit Anand'}, {'authorId': '80285140', 'name': 'V. Venktesh'}, {'authorId': '2852530', 'name': 'Vinay Setty'}, {'authorId': '39775488', 'name': 'Avishek Anand'}]","['L3S Research Institute Germany Venktesh V', 'Delft University of Technology', 'University of Stavanger']","['Germany', 'Netherlands', 'Norway']",2023-08
2308.16763,Kairui Hu Mr,"Kairui Hu, Ming Yan, Joey Tianyi Zhou, Ivor W. Tsang, Wen Haw Chong,
  Yong Keong Yap",Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection,"5 pages, 2 figures, 2 tables",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Stance detection aims to identify the attitude expressed in a document towards a given target. Techniques such as Chain-of-Thought (CoT) prompting have advanced this task, enhancing a model's reasoning capabilities through the derivation of intermediate rationales. However, CoT relies primarily on a model's pre-trained internal knowledge during reasoning, thereby neglecting the valuable external information that is previously unknown to the model. This omission, especially within the unsupervised reasoning process, can affect the model's overall performance. Moreover, while CoT enhances Large Language Models (LLMs), smaller LMs, though efficient operationally, face challenges in delivering nuanced reasoning. In response to these identified gaps, we introduce the Ladder-of-Thought (LoT) for the stance detection task. Constructed through a dual-phase Progressive Optimization Framework, LoT directs the small LMs to assimilate high-quality external knowledge, refining the intermediate rationales produced. These bolstered rationales subsequently serve as the foundation for more precise predictions - akin to how a ladder facilitates reaching elevated goals. LoT achieves a balance between efficiency and performance. Our empirical evaluations underscore LoT's efficacy, marking a 16% improvement over GPT-3.5 and a 10% enhancement compared to GPT-3.5 with CoT on stance detection task. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 14:31:48 GMT'}, {'version': 'v2', 'created': 'Thu, 7 Sep 2023 09:15:24 GMT'}]",2023-09-08,"[['Hu', 'Kairui', ''], ['Yan', 'Ming', ''], ['Zhou', 'Joey Tianyi', ''], ['Tsang', 'Ivor W.', ''], ['Chong', 'Wen Haw', ''], ['Yap', 'Yong Keong', '']]",0,1,2023-08-31,2,6,2,1,0,1,9059dfa3406af7bb1d1a94bd778eef42f0449dff,261395606.0,https://www.semanticscholar.org/paper/9059dfa3406af7bb1d1a94bd778eef42f0449dff,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2236645169', 'name': 'Kairui Hu'}, {'authorId': '2047087220', 'name': 'Ming Yan'}, {'authorId': '10638646', 'name': 'Joey Tianyi Zhou'}, {'authorId': '1807998', 'name': 'I. Tsang'}, {'authorId': '2223253', 'name': 'Wen-Haw Chong'}, {'authorId': '1742123174', 'name': 'Yong Keong Yap'}]","['Institute of High Performance Computing', 'Agency for Science, Technology and Research', 'DSO National Laboratories']",['Singapore'],2023-08
2308.16771,Rick Steinert,"Rick Steinert, Saskia Altmann",Linking microblogging sentiments to stock price movement: An application of GPT-4,,,,,q-fin.ST q-fin.CP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper investigates the potential improvement of the GPT-4 Language Learning Model (LLM) in comparison to BERT for modeling same-day daily stock price movements of Apple and Tesla in 2017, based on sentiment analysis of microblogging messages. We recorded daily adjusted closing prices and translated them into up-down movements. Sentiment for each day was extracted from messages on the Stocktwits platform using both LLMs. We develop a novel method to engineer a comprehensive prompt for contextual sentiment analysis which unlocks the true capabilities of modern LLM. This enables us to carefully retrieve sentiments, perceived advantages or disadvantages, and the relevance towards the analyzed company. Logistic regression is used to evaluate whether the extracted message contents reflect stock price movements. As a result, GPT-4 exhibited substantial accuracy, outperforming BERT in five out of six months and substantially exceeding a naive buy-and-hold strategy, reaching a peak accuracy of 71.47 % in May. The study also highlights the importance of prompt engineering in obtaining desired outputs from GPT-4's contextual abilities. However, the costs of deploying GPT-4 and the need for fine-tuning prompts highlight some practical considerations for its use. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 14:49:26 GMT'}]",2023-09-01,"[['Steinert', 'Rick', ''], ['Altmann', 'Saskia', '']]",0,1,2023-08-31,1,2,2,1,0,1,d6eedd8f08e929f7d11b6e20c31730d11f8f4297,261396058.0,https://www.semanticscholar.org/paper/d6eedd8f08e929f7d11b6e20c31730d11f8f4297,,2023.0,37.0,0.0,0.0,False,['Economics'],"[{'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '89556743', 'name': 'R. Steinert'}, {'authorId': '2236698079', 'name': 'Saskia Altmann'}]",['European University Viadrina'],['Germany'],2023-08
2309.00029,Hieke Keuning,"Natalie Kiesler, Dominic Lohr, Hieke Keuning",Exploring the Potential of Large Language Models to Generate Formative Programming Feedback,Accepted to FIE 2023,,,,cs.AI cs.CY cs.SE,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Ever since the emergence of large language models (LLMs) and related applications, such as ChatGPT, its performance and error analysis for programming tasks have been subject to research. In this work-in-progress paper, we explore the potential of such LLMs for computing educators and learners, as we analyze the feedback it generates to a given input containing program code. In particular, we aim at (1) exploring how an LLM like ChatGPT responds to students seeking help with their introductory programming tasks, and (2) identifying feedback types in its responses. To achieve these goals, we used students' programming sequences from a dataset gathered within a CS1 course as input for ChatGPT along with questions required to elicit feedback and correct solutions. The results show that ChatGPT performs reasonably well for some of the introductory programming tasks and student errors, which means that students can potentially benefit. However, educators should provide guidance on how to use the provided feedback, as it can contain misleading information for novices. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 15:22:11 GMT'}]",2023-09-04,"[['Kiesler', 'Natalie', ''], ['Lohr', 'Dominic', ''], ['Keuning', 'Hieke', '']]",1,1,2023-08-31,1,3,3,1,0,1,abf0228ac6a191bf2beee336bfb156e3a13c2b5e,261494005.0,https://www.semanticscholar.org/paper/abf0228ac6a191bf2beee336bfb156e3a13c2b5e,arXiv.org,2023.0,28.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '8449546', 'name': 'Natalie Kiesler'}, {'authorId': '2175100148', 'name': 'Dominic Lohr'}, {'authorId': '3198315', 'name': 'H. Keuning'}]","['Utrecht University', 'DIPF | Leibniz Institute for Research and Information in Education', 'Friedrich-Alexander-Universität Erlangen-Nürnberg']","['Germany', 'Netherlands']",2023-08
2309.00071,Jeffrey Quesnelle,"Bowen Peng, Jeffrey Quesnelle, Honglu Fan, Enrico Shippole",YaRN: Efficient Context Window Extension of Large Language Models,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Rotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models. However, these models fail to generalize past the sequence length they were trained on. We present YaRN (Yet another RoPE extensioN method), a compute-efficient method to extend the context window of such models, requiring 10x less tokens and 2.5x less training steps than previous methods. Using YaRN, we show that LLaMA models can effectively utilize and extrapolate to context lengths much longer than their original pre-training would allow, while also surpassing previous the state-of-the-art at context window extension. In addition, we demonstrate that YaRN exhibits the capability to extrapolate beyond the limited context of a fine-tuning dataset. We publish the checkpoints of Llama 2 7B/13B fine-tuned using YaRN with 64k and 128k context windows at https://github.com/jquesnelle/yarn ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 18:18:07 GMT'}]",2023-09-04,"[['Peng', 'Bowen', ''], ['Quesnelle', 'Jeffrey', ''], ['Fan', 'Honglu', ''], ['Shippole', 'Enrico', '']]",0,0,2023-08-31,1,4,3,1,1,0,819bbdc2dac9e13d9ca3e2508a6e063186ce5e40,261493986.0,https://www.semanticscholar.org/paper/819bbdc2dac9e13d9ca3e2508a6e063186ce5e40,arXiv.org,2023.0,43.0,18.0,3.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237425757', 'name': 'Bowen Peng'}, {'authorId': '2237424519', 'name': 'Jeffrey Quesnelle'}, {'authorId': '2237558988', 'name': 'Honglu Fan'}, {'authorId': '2237424515', 'name': 'Enrico Shippole'}]",['University of Geneva'],['Switzerland'],2023-08
2309.00095,Simon Thorne,Simon Thorne,Experimenting with ChatGPT for Spreadsheet Formula Generation: Evidence of Risk in AI Generated Spreadsheets,15 Pages,"EuSpRIG Proceedings 2023, ISBN: 978-1-905404-57-5",,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLM) have become sophisticated enough that complex computer programs can be created through interpretation of plain English sentences and implemented in a variety of modern languages such as Python, Java Script, C++ and Spreadsheets. These tools are powerful and relatively accurate and therefore provide broad access to computer programming regardless of the background or knowledge of the individual using them. This paper presents a series of experiments with ChatGPT to explore the tool's ability to produce valid spreadsheet formulae and related computational outputs in situations where ChatGPT has to deduce, infer and problem solve the answer. The results show that in certain circumstances, ChatGPT can produce correct spreadsheet formulae with correct reasoning, deduction and inference. However, when information is limited, uncertain or the problem is too complex, the accuracy of ChatGPT breaks down as does its ability to reason, infer and deduce. This can also result in false statements and ""hallucinations"" that all subvert the process of creating spreadsheet formulae. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 19:31:32 GMT'}]",2023-09-04,"[['Thorne', 'Simon', '']]",1,1,2023-08-31,1,1,1,1,0,1,1de2c130266961f3915e3cecb1cfd8432d3fd292,261493865.0,https://www.semanticscholar.org/paper/1de2c130266961f3915e3cecb1cfd8432d3fd292,arXiv.org,2023.0,16.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '33877910', 'name': 'Simon Thorne'}]",['Cardiff Metropolitan University'],['United Kingdom'],2023-08
2309.00155,Carlos Catania Dr,"Muris Sladi\'c and Veronica Valeros and Carlos Catania and Sebastian
  Garcia",LLM in the Shell: Generative Honeypots,5 pages. 1 figure 1 table,,,,cs.CR cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Honeypots are essential tools in cybersecurity. However, most of them (even the high-interaction ones) lack the required realism to engage and fool human attackers. This limitation makes them easily discernible, hindering their effectiveness. This work introduces a novel method to create dynamic and realistic software honeypots based on Large Language Models. Preliminary results indicate that LLMs can create credible and dynamic honeypots capable of addressing important limitations of previous honeypots, such as deterministic responses, lack of adaptability, etc. We evaluated the realism of each command by conducting an experiment with human attackers who needed to say if the answer from the honeypot was fake or not. Our proposed honeypot, called shelLM, reached an accuracy rate of 0.92. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 22:05:46 GMT'}]",2023-09-04,"[['Sladić', 'Muris', ''], ['Valeros', 'Veronica', ''], ['Catania', 'Carlos', ''], ['Garcia', 'Sebastian', '']]",0,0,2023-08-31,1,4,3,0,0,0,df18a4168fd3e0ca452056e1e0a887141edef9b1,261493978.0,https://www.semanticscholar.org/paper/df18a4168fd3e0ca452056e1e0a887141edef9b1,arXiv.org,2023.0,11.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237424782', 'name': ""Muris Sladi'c""}, {'authorId': '2105778', 'name': 'Veronica Valeros'}, {'authorId': '145151811', 'name': 'C. Catania'}, {'authorId': '2237485406', 'name': 'Sebastian Garcia'}]","['Czech Technical University in Prague', ""École Supérieure d'Ingénieurs en Génie Électrique""]","['Czechia', 'France']",2023-08
2309.00237,Sunjun Kweon,"Sunjun Kweon, Junu Kim, Jiyoun Kim, Sujeong Im, Eunbyeol Cho, Seongsu
  Bae, Jungwoo Oh, Gyubok Lee, Jong Hak Moon, Seng Chan You, Seungjin Baek,
  Chang Hoon Han, Yoon Bin Jung, Yohan Jo, Edward Choi",Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes,https://github.com/starmpcc/Asclepius,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The development of large language models tailored for handling patients' clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations. To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature. We then use these synthetic notes to train our specialized clinical large language model, Asclepius. While Asclepius is trained on synthetic data, we assess its potential performance in real-world applications by evaluating it using real clinical notes. We benchmark Asclepius against several other large language models, including GPT-3.5-turbo and other open-source alternatives. To further validate our approach using synthetic notes, we also compare Asclepius with its variants trained on real clinical notes. Our findings convincingly demonstrate that synthetic clinical notes can serve as viable substitutes for real ones when constructing high-performing clinical language models. This conclusion is supported by detailed evaluations conducted by both GPT-4 and medical professionals. All resources including weights, codes, and data used in the development of Asclepius are made publicly accessible for future research. ","[{'version': 'v1', 'created': 'Fri, 1 Sep 2023 04:01:20 GMT'}, {'version': 'v2', 'created': 'Wed, 6 Sep 2023 18:11:15 GMT'}]",2023-09-08,"[['Kweon', 'Sunjun', ''], ['Kim', 'Junu', ''], ['Kim', 'Jiyoun', ''], ['Im', 'Sujeong', ''], ['Cho', 'Eunbyeol', ''], ['Bae', 'Seongsu', ''], ['Oh', 'Jungwoo', ''], ['Lee', 'Gyubok', ''], ['Moon', 'Jong Hak', ''], ['You', 'Seng Chan', ''], ['Baek', 'Seungjin', ''], ['Han', 'Chang Hoon', ''], ['Jung', 'Yoon Bin', ''], ['Jo', 'Yohan', ''], ['Choi', 'Edward', '']]",0,1,2023-09-01,2,15,2,2,0,2,355d580b7f24afb073fbb21d8ad3fd2034dc3128,261494009.0,https://www.semanticscholar.org/paper/355d580b7f24afb073fbb21d8ad3fd2034dc3128,arXiv.org,2023.0,56.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2217192784', 'name': 'Sunjun Kweon'}, {'authorId': '2237591679', 'name': 'Junu Kim'}, {'authorId': '2177426085', 'name': 'Jiyoun Kim'}, {'authorId': '2237426647', 'name': 'Sujeong Im'}, {'authorId': '2237425314', 'name': 'Eunbyeol Cho'}, {'authorId': '2149556520', 'name': 'Seongsu Bae'}, {'authorId': '2110913353', 'name': 'Jungwoo Oh'}, {'authorId': '2115216766', 'name': 'Gyubok Lee'}, {'authorId': '2237425645', 'name': 'Jong Hak Moon'}, {'authorId': '2237425713', 'name': 'Seng Chan You'}, {'authorId': '2237425043', 'name': 'Seungjin Baek'}, {'authorId': '2237449108', 'name': 'Chang Hoon Han'}, {'authorId': '2237637583', 'name': 'Yoon Bin Jung'}, {'authorId': '39947629', 'name': 'Yohan Jo'}, {'authorId': '3242613', 'name': 'E. Choi'}]","['Seoul National University', 'Yonsei University']",['South Korea'],2023-09
2309.00329,Jaroslaw Hryszko,"Tomasz Wojnar, Jaroslaw Hryszko, Adam Roman",Mi-Go: Test Framework which uses YouTube as Data Source for Evaluating Speech Recognition Models like OpenAI's Whisper,"25 pages, 9 tables, 3 figures",,,,cs.SD cs.LG cs.SE eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This article introduces Mi-Go, a novel testing framework aimed at evaluating the performance and adaptability of general-purpose speech recognition machine learning models across diverse real-world scenarios. The framework leverages YouTube as a rich and continuously updated data source, accounting for multiple languages, accents, dialects, speaking styles, and audio quality levels. To demonstrate the effectiveness of the framework, the Whisper model, developed by OpenAI, was employed as a test object. The tests involve using a total of 124 YouTube videos to test all Whisper model versions. The results underscore the utility of YouTube as a valuable testing platform for speech recognition models, ensuring their robustness, accuracy, and adaptability to diverse languages and acoustic conditions. Additionally, by contrasting the machine-generated transcriptions against human-made subtitles, the Mi-Go framework can help pinpoint potential misuse of YouTube subtitles, like Search Engine Optimization. ","[{'version': 'v1', 'created': 'Fri, 1 Sep 2023 08:31:35 GMT'}]",2023-09-04,"[['Wojnar', 'Tomasz', ''], ['Hryszko', 'Jaroslaw', ''], ['Roman', 'Adam', '']]",0,0,2023-09-01,1,3,4,0,0,0,6552b9fd7e53bdc836b3d8ad74288ca13718f10a,261494108.0,https://www.semanticscholar.org/paper/6552b9fd7e53bdc836b3d8ad74288ca13718f10a,arXiv.org,2023.0,12.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237426217', 'name': 'Tomasz Wojnar'}, {'authorId': '26651696', 'name': 'Jaroslaw Hryszko'}, {'authorId': '2237426347', 'name': 'Adam Roman'}]",['Jagiellonian University'],['Poland'],2023-09
2309.00638,Peer Nagy,"Peer Nagy, Sascha Frey, Silvia Sapora, Kang Li, Anisoara Calinescu,
  Stefan Zohren, Jakob Foerster",Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network,,,,,q-fin.TR cs.AI cs.LG q-fin.CP,http://creativecommons.org/licenses/by/4.0/,"  Developing a generative model of realistic order flow in financial markets is a challenging open problem, with numerous applications for market participants. Addressing this, we propose the first end-to-end autoregressive generative model that generates tokenized limit order book (LOB) messages. These messages are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle long sequences efficiently, the model employs simplified structured state-space layers to process sequences of order book states and tokenized messages. Using LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message data, converting groups of successive digits to tokens, similar to tokenization in large language models. Out-of-sample results show promising performance in approximating the data distribution, as evidenced by low model perplexity. Furthermore, the mid-price returns calculated from the generated order flow exhibit a significant correlation with the data, indicating impressive conditional forecast performance. Due to the granularity of generated data, and the accuracy of the model, it offers new application areas for future work beyond forecasting, e.g. acting as a world model in high-frequency financial reinforcement learning applications. Overall, our results invite the use and extension of the model in the direction of autoregressive large financial models for the generation of high-frequency financial data and we commit to open-sourcing our code to facilitate future research. ","[{'version': 'v1', 'created': 'Wed, 23 Aug 2023 09:37:22 GMT'}]",2023-09-06,"[['Nagy', 'Peer', ''], ['Frey', 'Sascha', ''], ['Sapora', 'Silvia', ''], ['Li', 'Kang', ''], ['Calinescu', 'Anisoara', ''], ['Zohren', 'Stefan', ''], ['Foerster', 'Jakob', '']]",0,0,2023-08-23,1,7,4,0,0,0,f7768c6aa322f1b70ec31fbcd59bae22f25cf367,261530968.0,https://www.semanticscholar.org/paper/f7768c6aa322f1b70ec31fbcd59bae22f25cf367,arXiv.org,2023.0,56.0,0.0,0.0,True,"['Economics', 'Computer Science']","[{'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2202175084', 'name': 'Peer Nagy'}, {'authorId': '103621997', 'name': 'Sascha Frey'}, {'authorId': '87219304', 'name': 'Silvia Sapora'}, {'authorId': '2234058787', 'name': 'Kang Li'}, {'authorId': '2237803573', 'name': 'Anisoara Calinescu'}, {'authorId': '2237801362', 'name': 'Stefan Zohren'}, {'authorId': '2237802887', 'name': 'Jakob Foerster'}]",['University of Oxford'],['United Kingdom'],2023-08
2309.00649,Pawe{\l} Niszczota,"Pawe{\l} Niszczota, Sami Abbas",GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice,"43 pages, 2 figures and 2 tables in main text","Finance Research Letters, 2023, 58, 104333",10.1016/j.frl.2023.104333,,cs.CL cs.AI cs.CY econ.GN q-fin.EC,http://creativecommons.org/licenses/by/4.0/,"  We assess the ability of GPT -- a large language model -- to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 12:53:52 GMT'}]",2023-09-06,"[['Niszczota', 'Paweł', ''], ['Abbas', 'Sami', '']]",1,1,2023-08-31,1,2,5,3,0,3,c07a769da491dd5b6d7244c0d8f6614525ccb437,261042901.0,https://www.semanticscholar.org/paper/c07a769da491dd5b6d7244c0d8f6614525ccb437,Finance Research Letters,2023.0,57.0,1.0,0.0,True,"['Computer Science', 'Economics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","[{'authorId': '21726720', 'name': 'Paweł Niszczota'}, {'authorId': '123524298', 'name': 'S. Abbas'}]",['Poznań University of Economics and Business'],['Poland'],2023-08
2309.00733,Saeid Asgari Taghanaki,"Saeid Asgari Taghanaki, Aliasghar Khani, Amir Khasahmadi, Aditya
  Sanghi, Karl D.D. Willis, Ali Mahdavi-Amiri",Learned Visual Features to Textual Explanations,,,,,cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Interpreting the learned features of vision models has posed a longstanding challenge in the field of machine learning. To address this issue, we propose a novel method that leverages the capabilities of large language models (LLMs) to interpret the learned features of pre-trained image classifiers. Our method, called TExplain, tackles this task by training a neural network to establish a connection between the feature space of image classifiers and LLMs. Then, during inference, our approach generates a vast number of sentences to explain the features learned by the classifier for a given image. These sentences are then used to extract the most frequent words, providing a comprehensive understanding of the learned features and patterns within the classifier. Our method, for the first time, utilizes these frequent words corresponding to a visual representation to provide insights into the decision-making process of the independently trained classifier, enabling the detection of spurious correlations, biases, and a deeper comprehension of its behavior. To validate the effectiveness of our approach, we conduct experiments on diverse datasets, including ImageNet-9L and Waterbirds. The results demonstrate the potential of our method to enhance the interpretability and robustness of image classifiers. ","[{'version': 'v1', 'created': 'Fri, 1 Sep 2023 20:59:46 GMT'}]",2023-09-06,"[['Taghanaki', 'Saeid Asgari', ''], ['Khani', 'Aliasghar', ''], ['Khasahmadi', 'Amir', ''], ['Sanghi', 'Aditya', ''], ['Willis', 'Karl D. D.', ''], ['Mahdavi-Amiri', 'Ali', '']]",0,0,2023-09-01,1,6,2,0,0,0,5181f13783ac1701ca7581789e0e36bc45e92a69,261530187.0,https://www.semanticscholar.org/paper/5181f13783ac1701ca7581789e0e36bc45e92a69,arXiv.org,2023.0,40.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '17803311', 'name': 'Saeid Asgari Taghanaki'}, {'authorId': '1642129353', 'name': 'A. Khani'}, {'authorId': '2005585581', 'name': 'A. Khasahmadi'}, {'authorId': '1557900502', 'name': 'Aditya Sanghi'}, {'authorId': '2237801735', 'name': 'Karl D.D. Willis'}, {'authorId': '1399132068', 'name': 'Ali Mahdavi-Amiri'}]",['Simon Fraser University'],['Canada'],2023-09
2309.01105,Cheonsu Jeong Dr,Cheonsu Jeong,A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture,,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model. A comprehensive analysis of these steps is undertaken, emphasizing their significance in addressing the scarcity of data. The study highlights the efficacy of the proposed method, showcasing its applicability through illustrative instances. By implementing the RAG model for information storage and retrieval, the research not only contributes to a deeper comprehension of generative AI technology but also facilitates its practical usability within enterprises utilizing LLMs. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services within corporate settings. ","[{'version': 'v1', 'created': 'Sun, 3 Sep 2023 07:03:17 GMT'}, {'version': 'v2', 'created': 'Mon, 18 Sep 2023 11:36:50 GMT'}]",2023-09-19,"[['Jeong', 'Cheonsu', '']]",0,0,2023-09-03,2,1,2,0,0,0,dcf2e723ee9c3270c98ff768b139cca75d29242e,261531346.0,https://www.semanticscholar.org/paper/dcf2e723ee9c3270c98ff768b139cca75d29242e,arXiv.org,2023.0,34.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '98037302', 'name': 'Cheon-Su Jeong'}]",['Samsung'],['South Korea'],2023-09
2309.01245,Mohamed Akrout,Mohamed Akrout,Representations Matter: Embedding Modes of Large Language Models using Dynamic Mode Decomposition,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Existing large language models (LLMs) are known for generating ""hallucinated"" content, namely a fabricated text of plausibly looking, yet unfounded, facts. To identify when these hallucination scenarios occur, we examine the properties of the generated text in the embedding space. Specifically, we draw inspiration from the dynamic mode decomposition (DMD) tool in analyzing the pattern evolution of text embeddings across sentences. We empirically demonstrate how the spectrum of sentence embeddings over paragraphs is constantly low-rank for the generated text, unlike that of the ground-truth text. Importantly, we find that evaluation cases having LLM hallucinations correspond to ground-truth embedding patterns with a higher number of modes being poorly approximated by the few modes associated with LLM embedding patterns. In analogy to near-field electromagnetic evanescent waves, the embedding DMD eigenmodes of the generated text with hallucinations vanishes quickly across sentences as opposed to those of the ground-truth text. This suggests that the hallucinations result from both the generation techniques and the underlying representation. ","[{'version': 'v1', 'created': 'Sun, 3 Sep 2023 19:10:18 GMT'}]",2023-09-06,"[['Akrout', 'Mohamed', '']]",0,0,2023-09-03,1,1,2,0,0,0,91e8102b16daeffd4031418c479eb2764ca20877,261530365.0,https://www.semanticscholar.org/paper/91e8102b16daeffd4031418c479eb2764ca20877,arXiv.org,2023.0,10.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2065334711', 'name': 'Mohamed Akrout'}]",['University of Manitoba'],['Canada'],2023-09
2309.01247,John Bj{\o}rnar Bremnes,"John Bj{\o}rnar Bremnes, Thomas N. Nipen, Ivar A. Seierstad",Evaluation of forecasts by a global data-driven weather model with and without probabilistic post-processing at Norwegian stations,"9 pages, 5 figures",,,,physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  During the last two years, tremendous progress in global data-driven weather models trained on numerical weather prediction (NWP) re-analysis data has been made. The most recent models trained on the ERA5 at 0.25{\deg} resolution demonstrate forecast quality on par with ECMWF's high-resolution model with respect to a wide selection of verification metrics. In this study, one of these models, the Pangu-Weather, is compared to several NWP models with and without probabilistic post-processing for 2-meter temperature and 10-meter wind speed forecasting at 183 Norwegian SYNOP stations up to +60 hours ahead. The NWP models included are the ECMWF HRES, ECMWF ENS and the Harmonie-AROME ensemble model MEPS with 2.5 km spatial resolution. Results show that the performances of the global models are on the same level with Pangu-Weather being slightly better than the ECMWF models for temperature and slightly worse for wind speed. The MEPS model clearly provided the best forecasts for both parameters. The post-processing improved the forecast quality considerably for all models, but to a larger extent for the coarse-resolution global models due to stronger systematic deficiencies in these. Apart from this, the main characteristics in the scores were more or less the same with and without post-processing. Our results thus confirm the conclusions from other studies that global data-driven models are promising for operational weather forecasting. ","[{'version': 'v1', 'created': 'Sun, 3 Sep 2023 19:20:24 GMT'}]",2023-09-06,"[['Bremnes', 'John Bjørnar', ''], ['Nipen', 'Thomas N.', ''], ['Seierstad', 'Ivar A.', '']]",0,0,2023-09-03,1,3,1,0,0,0,2029a29bec902d78ee2969739cd467e14586f945,261530794.0,https://www.semanticscholar.org/paper/2029a29bec902d78ee2969739cd467e14586f945,,2023.0,21.0,0.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","[{'authorId': '2449273', 'name': 'J. B. Bremnes'}, {'authorId': '70190922', 'name': 'T. Nipen'}, {'authorId': '103637926', 'name': 'I. Seierstad'}]",['Norwegian Meteorological Institute'],['Norway'],2023-09
2309.01446,Raz Lapid,"Raz Lapid, Ron Langberg, Moshe Sipper",Open Sesame! Universal Black Box Jailbreaking of Large Language Models,,,,,cs.CL cs.CV cs.NE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs), designed to provide helpful and safe responses, often rely on alignment techniques to align with user intent and social guidelines. Unfortunately, this alignment can be exploited by malicious actors seeking to manipulate an LLM's outputs for unintended purposes. In this paper we introduce a novel approach that employs a genetic algorithm (GA) to manipulate LLMs when model architecture and parameters are inaccessible. The GA attack works by optimizing a universal adversarial prompt that -- when combined with a user's query -- disrupts the attacked model's alignment, resulting in unintended and potentially harmful outputs. Our novel approach systematically reveals a model's limitations and vulnerabilities by uncovering instances where its responses deviate from expected behavior. Through extensive experiments we demonstrate the efficacy of our technique, thus contributing to the ongoing discussion on responsible AI development by providing a diagnostic tool for evaluating and enhancing alignment of LLMs with human intent. To our knowledge this is the first automated universal black box jailbreak attack. ","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 08:54:20 GMT'}, {'version': 'v2', 'created': 'Sun, 17 Sep 2023 13:19:11 GMT'}]",2023-09-19,"[['Lapid', 'Raz', ''], ['Langberg', 'Ron', ''], ['Sipper', 'Moshe', '']]",0,0,2023-09-04,2,3,3,0,0,0,f846c0c59608f0a8ff18f4c52adba87bf49dc229,261530019.0,https://www.semanticscholar.org/paper/f846c0c59608f0a8ff18f4c52adba87bf49dc229,arXiv.org,2023.0,48.0,9.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2173526660', 'name': 'Raz Lapid'}, {'authorId': '2237799035', 'name': 'Ron Langberg'}, {'authorId': '2237798704', 'name': 'Moshe Sipper'}]","['DeepKeep, Tel-Aviv, Israel', 'Ben-Gurion University of the Negev']",['Israel'],2023-09
2309.01538,Linhao Luo,"Linhao Luo, Jiaxin Ju, Bo Xiong, Yuan-Fang Li, Gholamreza Haffari,
  Shirui Pan",ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning,"11 pages, 4 figures",,,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Logical rules are essential for uncovering the logical connections between relations, which could improve the reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from the computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs to prompt LLMs to generate logical rules. To refine the generated rules, a rule ranking module estimates the rule quality by incorporating facts from existing KGs. Last, a rule validator harnesses the reasoning ability of LLMs to validate the logical correctness of ranked rules through chain-of-thought reasoning. ChatRule is evaluated on four large-scale KGs, w.r.t. different rule quality metrics and downstream tasks, showing the effectiveness and scalability of our method. ","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 11:38:02 GMT'}, {'version': 'v2', 'created': 'Wed, 13 Sep 2023 13:00:23 GMT'}]",2023-09-14,"[['Luo', 'Linhao', ''], ['Ju', 'Jiaxin', ''], ['Xiong', 'Bo', ''], ['Li', 'Yuan-Fang', ''], ['Haffari', 'Gholamreza', ''], ['Pan', 'Shirui', '']]",0,0,2023-09-04,2,6,2,0,0,0,18664b47516ba5424ba5efa79d3f816224245325,261530825.0,https://www.semanticscholar.org/paper/18664b47516ba5424ba5efa79d3f816224245325,arXiv.org,2023.0,39.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238130759', 'name': 'Linhao Luo'}, {'authorId': '2237806895', 'name': 'Jiaxin Ju'}, {'authorId': '2065364720', 'name': 'Bo Xiong'}, {'authorId': '4495301', 'name': 'Yuan-Fang Li'}, {'authorId': '2561045', 'name': 'Gholamreza Haffari'}, {'authorId': '2585415', 'name': 'Shirui Pan'}]","['Monash University', 'Griffith University', 'University of Stuttgart']","['Germany', 'Australia']",2023-09
2309.01586,Matthew Edwards,Piyush Bajaj and Matthew Edwards,Automatic Scam-Baiting Using ChatGPT,"Proceedings of the 7th International Workshop on Applications of AI,
  Cyber Security and Economics Data Analytics (ACE-2023) (in press)",,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Automatic scam-baiting is an online fraud countermeasure that involves automated systems responding to online fraudsters in order to waste their time and deplete their resources, diverting attackers away from real potential victims. Previous work has demonstrated that text generation systems are capable of engaging with attackers as automatic scam-baiters, but the fluency and coherence of generated text may be a limit to the effectiveness of such systems.   In this paper, we report on the results of a month-long experiment comparing the effectiveness of two ChatGPT-based automatic scam-baiters to a control measure. Within our results, with engagement from over 250 real email fraudsters, we find that ChatGPT-based scam-baiters show a marked increase in scammer response rate and conversation length relative to the control measure, outperforming previous approaches. We discuss the implications of these results and practical considerations for wider deployment of automatic scam-baiting. ","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 13:13:35 GMT'}]",2023-09-06,"[['Bajaj', 'Piyush', ''], ['Edwards', 'Matthew', '']]",1,1,2023-09-04,1,2,1,1,0,1,cf76ea0b31e159ee83c738226a784c7c17961800,261530417.0,https://www.semanticscholar.org/paper/cf76ea0b31e159ee83c738226a784c7c17961800,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '34766381', 'name': 'P. Bajaj'}, {'authorId': '2237805966', 'name': 'Matthew Edwards'}]",['University of Bristol'],['United Kingdom'],2023-09
2309.01659,Andres Karjus,"Andres Karjus, Christine Cuskley",Evolving linguistic divergence on polarizing social media,,,,,cs.SI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Language change is influenced by many factors, but often starts from synchronic variation, where multiple linguistic patterns or forms coexist, or where different speech communities use language in increasingly different ways. Besides regional or economic reasons, communities may form and segregate based on political alignment. The latter, referred to as political polarization, is of growing societal concern across the world. Here we map and quantify linguistic divergence across the partisan left-right divide in the United States, using social media data. We develop a general methodology to delineate (social) media users by their political preference, based on which (potentially biased) news media accounts they do and do not follow on a given platform. Our data consists of 1.5M short posts by 10k users (about 20M words) from the social media platform Twitter (now ""X""). Delineating this sample involved mining the platform for the lists of followers (n=422M) of 72 large news media accounts. We quantify divergence in topics of conversation and word frequencies, messaging sentiment, and lexical semantics of words and emoji. We find signs of linguistic divergence across all these aspects, especially in topics and themes of conversation, in line with previous research. While US American English remains largely intelligible within its large speech community, our findings point at areas where miscommunication may eventually arise given ongoing polarization and therefore potential linguistic divergence. Our methodology - combining data mining, lexicostatistics, machine learning, large language models and a systematic human annotation approach - is largely language and platform agnostic. In other words, while we focus here on US political divides and US English, the same approach is applicable to other countries, languages, and social media platforms. ","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 15:21:55 GMT'}]",2023-09-06,"[['Karjus', 'Andres', ''], ['Cuskley', 'Christine', '']]",0,0,2023-09-04,1,2,2,0,0,0,60d0376c5c70f068e44d49ccdcdd88bd42867c8c,261530513.0,https://www.semanticscholar.org/paper/60d0376c5c70f068e44d49ccdcdd88bd42867c8c,arXiv.org,2023.0,103.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '50994722', 'name': 'Andres Karjus'}, {'authorId': '2237800589', 'name': 'Christine Cuskley'}]","['University of Newcastle Australia', 'Tallinn University', 'Estonian Business School']","['Estonia', 'Australia']",2023-09
2309.01664,Bernhard Hilpert,"Joost Broekens, Bernhard Hilpert, Suzan Verberne, Kim Baraka, Patrick
  Gebhard and Aske Plaat",Fine-grained Affective Processing Capabilities Emerging from Large Language Models,,,,,cs.CL cs.AI cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models, in particular generative pre-trained transformers (GPTs), show impressive results on a wide variety of language-related tasks. In this paper, we explore ChatGPT's zero-shot ability to perform affective computing tasks using prompting alone. We show that ChatGPT a) performs meaningful sentiment analysis in the Valence, Arousal and Dominance dimensions, b) has meaningful emotion representations in terms of emotion categories and these affective dimensions, and c) can perform basic appraisal-based emotion elicitation of situations based on a prompt-based computational implementation of the OCC appraisal model. These findings are highly relevant: First, they show that the ability to solve complex affect processing tasks emerges from language-based token prediction trained on extensive data sets. Second, they show the potential of large language models for simulating, processing and analyzing human emotions, which has important implications for various applications such as sentiment analysis, socially interactive agents, and social robotics. ","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 15:32:47 GMT'}]",2023-09-06,"[['Broekens', 'Joost', ''], ['Hilpert', 'Bernhard', ''], ['Verberne', 'Suzan', ''], ['Baraka', 'Kim', ''], ['Gebhard', 'Patrick', ''], ['Plaat', 'Aske', '']]",1,1,2023-09-04,1,6,3,1,0,1,80f659d35c3a4c0b6bf9b7925cb9a68afd684337,261530762.0,https://www.semanticscholar.org/paper/80f659d35c3a4c0b6bf9b7925cb9a68afd684337,arXiv.org,2023.0,38.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1735303', 'name': 'J. Broekens'}, {'authorId': '1455857216', 'name': 'Bernhard Hilpert'}, {'authorId': '2239104085', 'name': 'Suzan Verberne'}, {'authorId': '2237805953', 'name': 'Kim Baraka'}, {'authorId': '2237806469', 'name': 'Patrick Gebhard'}, {'authorId': '2562595', 'name': 'A. Plaat'}]","['German Research Centre for Artificial Intelligence', 'Department of Computer Science Free University Amsterdam Amsterdam, the Netherlands', 'Leiden University']","['Germany', 'Netherlands']",2023-09
2309.01669,Leon Weber,"Leon Weber-Genzel and Robert Litschko and Ekaterina Artemova and
  Barbara Plank",Donkii: Can Annotation Error Detection Methods Find Errors in Instruction-Tuning Datasets?,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Instruction-tuning has become an integral part of training pipelines for Large Language Models (LLMs) and has been shown to yield strong performance gains. In an orthogonal line of research, Annotation Error Detection (AED) has emerged as a tool for detecting quality issues of gold-standard labels. But so far, the application of AED methods is limited to discriminative settings. It is an open question how well AED methods generalize to generative settings which are becoming widespread via generative LLMs. In this work, we present a first and new benchmark for AED on instruction-tuning data: Donkii. It encompasses three instruction-tuning datasets enriched with annotations by experts and semi-automatic methods. We find that all three datasets contain clear-cut errors that sometimes directly propagate into instruction-tuned LLMs. We propose four AED baselines for the generative setting and evaluate them comprehensively on the newly introduced dataset. Our results demonstrate that choosing the right AED method and model size is indeed crucial, thereby deriving practical recommendations. To gain insights, we provide a first case-study to examine how the quality of the instruction-tuning datasets influences downstream performance. ","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 15:34:02 GMT'}]",2023-09-06,"[['Weber-Genzel', 'Leon', ''], ['Litschko', 'Robert', ''], ['Artemova', 'Ekaterina', ''], ['Plank', 'Barbara', '']]",0,0,2023-09-04,1,4,1,0,0,0,1c594adf08fc2ab2fbe5ec1f2468cd7eca73b587,261531320.0,https://www.semanticscholar.org/paper/1c594adf08fc2ab2fbe5ec1f2468cd7eca73b587,arXiv.org,2023.0,50.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237809324', 'name': 'Leon Weber-Genzel'}, {'authorId': '46249177', 'name': 'Robert Litschko'}, {'authorId': '13033978', 'name': 'E. Artemova'}, {'authorId': '2022124', 'name': 'Barbara Plank'}]","['University of Copenhagen', 'Ludwig-Maximilians-Universität München']","['Germany', 'Denmark']",2023-09
2309.01715,Fandi Yi,"Boqi Chen, Fandi Yi, D\'aniel Varr\'o",Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction,Accepted by MDE Intelligence 2023,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Taxonomies represent hierarchical relations between entities, frequently applied in various software modeling and natural language processing (NLP) activities. They are typically subject to a set of structural constraints restricting their content. However, manual taxonomy construction can be time-consuming, incomplete, and costly to maintain. Recent studies of large language models (LLMs) have demonstrated that appropriate user inputs (called prompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks without explicit (re-)training. However, existing approaches for automated taxonomy construction typically involve fine-tuning a language model by adjusting model parameters. In this paper, we present a general framework for taxonomy construction that takes into account structural constraints. We subsequently conduct a systematic comparison between the prompting and fine-tuning approaches performed on a hypernym taxonomy and a novel computer science taxonomy dataset. Our result reveals the following: (1) Even without explicit training on the dataset, the prompting approach outperforms fine-tuning-based approaches. Moreover, the performance gap between prompting and fine-tuning widens when the training dataset is small. However, (2) taxonomies generated by the fine-tuning approach can be easily post-processed to satisfy all the constraints, whereas handling violations of the taxonomies produced by the prompting approach can be challenging. These evaluation findings provide guidance on selecting the appropriate method for taxonomy construction and highlight potential enhancements for both approaches. ","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 16:53:17 GMT'}]",2023-09-06,"[['Chen', 'Boqi', ''], ['Yi', 'Fandi', ''], ['Varró', 'Dániel', '']]",0,1,2023-09-04,1,3,2,1,0,1,08400a12db21fe4d4f844fec57844e74ac09c9ba,261531340.0,https://www.semanticscholar.org/paper/08400a12db21fe4d4f844fec57844e74ac09c9ba,arXiv.org,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237865625', 'name': 'Boqi Chen'}, {'authorId': '2237805302', 'name': 'Fandi Yi'}, {'authorId': '71971228', 'name': 'Dániel Varró'}]","['McGill University', 'Linköping University']","['Canada', 'Sweden']",2023-09
2309.01809,Harish Tayyar Madabushi PhD,"Sheng Lu and Irina Bigoulaeva and Rachneet Sachdeva and Harish Tayyar
  Madabushi and Iryna Gurevych",Are Emergent Abilities in Large Language Models just In-Context Learning?,"Code available at https://github.com/UKPLab/on-emergence and data
  available at https://tudatalib.ulb.tu-darmstadt.de/handle/tudatalib/3931",,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Large language models have exhibited emergent abilities, demonstrating exceptional performance across diverse tasks for which they were not explicitly trained, including those that require complex reasoning abilities. The emergence of such abilities carries profound implications for the future direction of research in NLP, especially as the deployment of such models becomes more prevalent. However, one key challenge is that the evaluation of these abilities is often confounded by competencies that arise in models through alternative prompting techniques, such as in-context learning and instruction following, which also emerge as the models are scaled up. In this study, we provide the first comprehensive examination of these emergent abilities while accounting for various potentially biasing factors that can influence the evaluation of models. We conduct rigorous tests on a set of 18 models, encompassing a parameter range from 60 million to 175 billion parameters, across a comprehensive set of 22 tasks. Through an extensive series of over 1,000 experiments, we provide compelling evidence that emergent abilities can primarily be ascribed to in-context learning. We find no evidence for the emergence of reasoning abilities, thus providing valuable insights into the underlying mechanisms driving the observed abilities and thus alleviating safety concerns regarding their use. ","[{'version': 'v1', 'created': 'Mon, 4 Sep 2023 20:54:11 GMT'}]",2023-09-06,"[['Lu', 'Sheng', ''], ['Bigoulaeva', 'Irina', ''], ['Sachdeva', 'Rachneet', ''], ['Madabushi', 'Harish Tayyar', ''], ['Gurevych', 'Iryna', '']]",0,0,2023-09-04,1,5,1,0,0,0,3e4afde5a9de2c1801da99b8aff5ae05923f256b,261531236.0,https://www.semanticscholar.org/paper/3e4afde5a9de2c1801da99b8aff5ae05923f256b,arXiv.org,2023.0,74.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237947104', 'name': 'Sheng Lu'}, {'authorId': '2081604910', 'name': 'Irina Bigoulaeva'}, {'authorId': '1490892639', 'name': 'Rachneet Sachdeva'}, {'authorId': '3467205', 'name': 'Harish Tayyar Madabushi'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}]","['University of Bath', 'Technical University of Darmstadt']","['Germany', 'United Kingdom']",2023-09
2309.02142,Roberto Ulloa Dr.,"Celina Kacperski, Roberto Ulloa, Denis Bonnay, Juhi Kulshrestha, Peter
  Selb, Andreas Spitz",Who are the users of ChatGPT? Implications for the digital divide from web tracking data,,,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  A major challenge of our time is reducing disparities in access to and effective use of digital technologies, with recent discussions highlighting the role of AI in exacerbating the digital divide. We examine user characteristics that predict usage of the AI-powered conversational agent ChatGPT. We combine web tracking and survey data of N=1068 German citizens to investigate differences in activity (usage, visits and duration on chat.openai.com). We examine socio-demographics commonly associated with the digital divide and explore further socio-political attributes identified via stability selection in Lasso regressions. We confirm lower age and more education to affect ChatGPT usage, but not gender and income. We find full-time employment and more children to be barriers to ChatGPT activity. Rural residence, writing and social media activities, as well as more political knowledge, were positively associated with ChatGPT activity. Our research informs efforts to address digital disparities and promote digital literacy among underserved populations. ","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 11:31:54 GMT'}]",2023-09-06,"[['Kacperski', 'Celina', ''], ['Ulloa', 'Roberto', ''], ['Bonnay', 'Denis', ''], ['Kulshrestha', 'Juhi', ''], ['Selb', 'Peter', ''], ['Spitz', 'Andreas', '']]",1,1,2023-09-05,1,6,1,1,0,1,b70761e8c7b0445aceb38aaa89b26df92defd342,261557629.0,https://www.semanticscholar.org/paper/b70761e8c7b0445aceb38aaa89b26df92defd342,arXiv.org,2023.0,45.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145104204', 'name': 'C. Kacperski'}, {'authorId': '2237991479', 'name': 'Roberto Ulloa'}, {'authorId': '2237993077', 'name': 'Denis Bonnay'}, {'authorId': '2709512', 'name': 'Juhi Kulshrestha'}, {'authorId': '70171338', 'name': 'Peter Selb'}, {'authorId': '2237991580', 'name': 'Andreas Spitz'}]","['Aalto University', 'University of Konstanz', 'Université Paris Nanterre', 'Seeburg Castle University']","['Germany', 'Austria', 'France', 'Finland']",2023-09
2309.02233,Yubo Wang,"Yubo Wang, Xueguang Ma, Wenhu Chen",Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large-scale language models (LLMs), such as ChatGPT, are capable of generating human-like responses for various downstream tasks, such as task-oriented dialogues and question answering. However, applying LLMs to medical domains remains challenging due to their inability to leverage domain-specific knowledge. In this study, we present the Large-scale Language Models Augmented with Medical Textbooks (LLM-AMT), which integrates authoritative medical textbooks as the cornerstone of its design, enhancing its proficiency in the specialized domain through plug-and-play modules, comprised of a Hybrid Textbook Retriever, supplemented by the Query Augmenter and the LLM Reader. Experimental evaluation on three open-domain medical question-answering tasks reveals a substantial enhancement in both the professionalism and accuracy of the LLM responses when utilizing LLM-AMT, exhibiting an improvement ranging from 11.4% to 13.2%. Despite being 100 times smaller, we found that medical textbooks as the retrieval corpus serves as a more valuable external knowledge source than Wikipedia in the medical domain. Our experiments show that textbook augmentation results in a performance improvement ranging from 9.7% to 12.2% over Wikipedia augmentation. ","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 13:39:38 GMT'}]",2023-09-06,"[['Wang', 'Yubo', ''], ['Ma', 'Xueguang', ''], ['Chen', 'Wenhu', '']]",1,1,2023-09-05,1,3,2,1,0,1,5e761e9f5cd9672a181b256299cd2916a8079461,261557644.0,https://www.semanticscholar.org/paper/5e761e9f5cd9672a181b256299cd2916a8079461,arXiv.org,2023.0,39.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238120100', 'name': 'Yubo Wang'}, {'authorId': '2461713', 'name': 'Xueguang Ma'}, {'authorId': '2928777', 'name': 'Wenhu Chen'}]",['University of Waterloo'],['Canada'],2023-09
2309.02285,Yichong Leng,"Yichong Leng, Zhifang Guo, Kai Shen, Xu Tan, Zeqian Ju, Yanqing Liu,
  Yufei Liu, Dongchao Yang, Leying Zhang, Kaitao Song, Lei He, Xiang-Yang Li,
  Sheng Zhao, Tao Qin, Jiang Bian",PromptTTS 2: Describing and Generating Voices with Text Prompt,Demo page: https://speechresearch.github.io/prompttts2,,,,eess.AS cs.CL cs.LG cs.SD,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Speech conveys more information than just text, as the same word can be uttered in various voices to convey diverse information. Compared to traditional text-to-speech (TTS) methods relying on speech prompts (reference speech) for voice variability, using text prompts (descriptions) is more user-friendly since speech prompts can be hard to find or may not exist at all. TTS approaches based on the text prompt face two challenges: 1) the one-to-many problem, where not all details about voice variability can be described in the text prompt, and 2) the limited availability of text prompt datasets, where vendors and large cost of data labeling are required to write text prompt for speech. In this work, we introduce PromptTTS 2 to address these challenges with a variation network to provide variability information of voice not captured by text prompts, and a prompt generation pipeline to utilize the large language models (LLM) to compose high quality text prompts. Specifically, the variation network predicts the representation extracted from the reference speech (which contains full information about voice) based on the text prompt representation. For the prompt generation pipeline, it generates text prompts for speech with a speech understanding model to recognize voice attributes (e.g., gender, speed) from speech and a large language model to formulate text prompt based on the recognition results. Experiments on a large-scale (44K hours) speech dataset demonstrate that compared to the previous works, PromptTTS 2 generates voices more consistent with text prompts and supports the sampling of diverse voice variability, thereby offering users more choices on voice generation. Additionally, the prompt generation pipeline produces high-quality prompts, eliminating the large labeling cost. The demo page of PromptTTS 2 is available online\footnote{https://speechresearch.github.io/prompttts2}. ","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 14:45:27 GMT'}]",2023-09-06,"[['Leng', 'Yichong', ''], ['Guo', 'Zhifang', ''], ['Shen', 'Kai', ''], ['Tan', 'Xu', ''], ['Ju', 'Zeqian', ''], ['Liu', 'Yanqing', ''], ['Liu', 'Yufei', ''], ['Yang', 'Dongchao', ''], ['Zhang', 'Leying', ''], ['Song', 'Kaitao', ''], ['He', 'Lei', ''], ['Li', 'Xiang-Yang', ''], ['Zhao', 'Sheng', ''], ['Qin', 'Tao', ''], ['Bian', 'Jiang', '']]",0,0,2023-09-05,1,15,4,0,0,0,e33a8f49a46321fb7c1a89d4b759a00a6880fd3d,261557296.0,https://www.semanticscholar.org/paper/e33a8f49a46321fb7c1a89d4b759a00a6880fd3d,arXiv.org,2023.0,57.0,1.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '148398655', 'name': 'Yichong Leng'}, {'authorId': '2238215402', 'name': 'Zhifang Guo'}, {'authorId': '2237989965', 'name': 'Kai Shen'}, {'authorId': '48391466', 'name': 'Xu Tan'}, {'authorId': '1613055688', 'name': 'Zeqian Ju'}, {'authorId': '2108086973', 'name': 'Yanqing Liu'}, {'authorId': '2238126539', 'name': 'Yufei Liu'}, {'authorId': '2238138795', 'name': 'Dongchao Yang'}, {'authorId': '2238127115', 'name': 'Leying Zhang'}, {'authorId': '50982078', 'name': 'Kaitao Song'}, {'authorId': '145836234', 'name': 'Lei He'}, {'authorId': '2108750136', 'name': 'Xiang-Yang Li'}, {'authorId': '47601191', 'name': 'Sheng Zhao'}, {'authorId': '2237988703', 'name': 'Tao Qin'}, {'authorId': '2192822005', 'name': 'Jiang Bian'}]",['Microsoft'],['India'],2023-09
2309.02373,Piotr Nawrot,Piotr Nawrot,nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style Models with Limited Resources,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  State-of-the-art language models like T5 have revolutionized the NLP landscape, but their computational demands hinder a large portion of the research community. To address this challenge, we present nanoT5, a specially-optimized PyTorch framework for efficient pre-training and fine-tuning of T5 models. Drawing on insights from optimizer differences and prioritizing efficiency, nanoT5 allows a T5-Base model to be pre-trained on a single GPU in just 16 hours, without any loss in performance. With the introduction of this open-source framework, we hope to widen the accessibility to language modelling research and cater to the community's demand for more user-friendly T5 (Encoder-Decoder) implementations. Our contributions, including configurations, codebase, software/hardware insights, and pre-trained models, are available to the public, aiming to strike a balance between research accessibility and resource constraints in NLP. ","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 16:35:41 GMT'}]",2023-09-06,"[['Nawrot', 'Piotr', '']]",0,0,2023-09-05,1,1,1,1,1,0,8ab5af5c9510bb25dcef0338cb5575461a3ba140,261556952.0,https://www.semanticscholar.org/paper/8ab5af5c9510bb25dcef0338cb5575461a3ba140,arXiv.org,2023.0,31.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40284207', 'name': 'Piotr Nawrot'}]",['University of Edinburgh'],['United Kingdom'],2023-09
2309.02553,Javier Ferrando,"Javier Ferrando, Matthias Sperber, Hendra Setiawan, Dominic Telaar,
  Sa\v{s}a Hasan",Automating Behavioral Testing in Machine Translation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Behavioral testing in NLP allows fine-grained evaluation of systems by examining their linguistic capabilities through the analysis of input-output behavior. Unfortunately, existing work on behavioral testing in Machine Translation (MT) is currently restricted to largely handcrafted tests covering a limited range of capabilities and languages. To address this limitation, we propose to use Large Language Models (LLMs) to generate a diverse set of source sentences tailored to test the behavior of MT models in a range of situations. We can then verify whether the MT model exhibits the expected behavior through matching candidate sets that are also generated using LLMs. Our approach aims to make behavioral testing of MT systems practical while requiring only minimal human effort. In our experiments, we apply our proposed evaluation framework to assess multiple available MT systems, revealing that while in general pass-rates follow the trends observable from traditional accuracy-based metrics, our method was able to uncover several important differences and potential bugs that go unnoticed when relying only on accuracy. ","[{'version': 'v1', 'created': 'Tue, 5 Sep 2023 19:40:45 GMT'}, {'version': 'v2', 'created': 'Thu, 7 Sep 2023 00:23:34 GMT'}]",2023-09-08,"[['Ferrando', 'Javier', ''], ['Sperber', 'Matthias', ''], ['Setiawan', 'Hendra', ''], ['Telaar', 'Dominic', ''], ['Hasan', 'Saša', '']]",0,0,2023-09-05,2,5,2,0,0,0,6b3a205b08f10320c17abdeb5681df447683c661,261556930.0,https://www.semanticscholar.org/paper/6b3a205b08f10320c17abdeb5681df447683c661,arXiv.org,2023.0,38.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1751450782', 'name': 'Javier Ferrando'}, {'authorId': '3011998', 'name': 'Matthias Sperber'}, {'authorId': '2237986609', 'name': 'Hendra Setiawan'}, {'authorId': '2237986093', 'name': 'Dominic Telaar'}, {'authorId': '2237987545', 'name': 'Savsa Hasan'}]",['Universitat Politècnica de Catalunya'],['Spain'],2023-09
2309.02884,Supun Manathunga,"Supun Manathunga, Isuru Hettigoda",Aligning Large Language Models for Clinical Tasks,"10 pages, 3 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) have demonstrated remarkable adaptability, showcasing their capacity to excel in tasks for which they were not explicitly trained. However, despite their impressive natural language processing (NLP) capabilities, effective alignment of LLMs remains a crucial challenge when deploying them for specific clinical applications. The ability to generate responses with factually accurate content and to engage in non-trivial reasoning steps are crucial for the LLMs to be eligible for applications in clinical medicine. Employing a combination of techniques including instruction-tuning and in-prompt strategies like few-shot and chain-of-thought prompting has significantly enhanced the performance of LLMs. Our proposed alignment strategy for medical question-answering, known as 'expand-guess-refine', offers a parameter and data-efficient solution. A preliminary analysis of this method demonstrated outstanding performance, achieving a score of 70.63% on a subset of questions sourced from the USMLE dataset. ","[{'version': 'v1', 'created': 'Wed, 6 Sep 2023 10:20:06 GMT'}, {'version': 'v2', 'created': 'Thu, 7 Sep 2023 01:52:33 GMT'}]",2023-09-08,"[['Manathunga', 'Supun', ''], ['Hettigoda', 'Isuru', '']]",0,0,2023-09-06,2,2,1,0,0,0,a570d3d8f1b66a8ab3fff7876dc9bba3bcdc789b,261557581.0,https://www.semanticscholar.org/paper/a570d3d8f1b66a8ab3fff7876dc9bba3bcdc789b,arXiv.org,2023.0,55.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2181963294', 'name': 'Supun Manathunga'}, {'authorId': '2237990802', 'name': 'Isuru Hettigoda'}]",['University of Peradeniya'],['Sri Lanka'],2023-09
2309.02986,Jozef Han\v{c},"Dominik Borovsk\'y, Jozef Han\v{c}, Martina Han\v{c}ov\'a",Innovative approaches to high school physics competitions: Harnessing the power of AI and open science,"10 pages, 4 figures, preprint DIDFYZ2023 conference",,,,physics.ed-ph,http://creativecommons.org/licenses/by/4.0/,"  High school physics competitions serve as a platform for talented students to showcase their skills, engage in challenging problems, and foster a passion for science. This paper explores innovative approaches to enhance these competitions by harnessing the power of open science and artificial intelligence (AI) tools. Particularly we delve into the capabilities of state-of-the-art AI chatbots, i.e. ChatGPT, Bard, Claude, related to problem solving in physics. Together with open science tools like SageMath and Jupyter AI, they have the potential to serve as intelligent, powerful co-pilots, tutors, and assistants in understanding and applying physics, as well as knowledge from connected STEM fields. Furthermore, these innovative approaches can revolutionize high school physics competitions, providing students and their tutors with powerful resources to excel in their scientific pursuits. ","[{'version': 'v1', 'created': 'Wed, 6 Sep 2023 13:32:46 GMT'}]",2023-09-07,"[['Borovský', 'Dominik', ''], ['Hanč', 'Jozef', ''], ['Hančová', 'Martina', '']]",1,1,2023-09-06,1,3,1,2,0,2,8cabc3453c7bdd406e39bcb7967f919548d62f53,261556827.0,https://www.semanticscholar.org/paper/8cabc3453c7bdd406e39bcb7967f919548d62f53,,2023.0,20.0,0.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2230284693', 'name': ""Dominik Borovsk'y""}, {'authorId': '122405513', 'name': 'Jozef Hanvc'}, {'authorId': '1463116848', 'name': ""Martina Hanvcov'a""}]","['University of Pavol Jozef Šafárik', 'Institute of Physics']",['Slovakia'],2023-09
2309.03044,Ehsan Mashhadi,"Ehsan Mashhadi, Hossein Ahmadvand, Hadi Hemmati",Method-Level Bug Severity Prediction using Source Code Metrics and LLMs,,,10.5281/zenodo.8267597,,cs.SE,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In the past couple of decades, significant research efforts are devoted to the prediction of software bugs. However, most existing work in this domain treats all bugs the same, which is not the case in practice. It is important for a defect prediction method to estimate the severity of the identified bugs so that the higher-severity ones get immediate attention. In this study, we investigate source code metrics, source code representation using large language models (LLMs), and their combination in predicting bug severity labels of two prominent datasets. We leverage several source metrics at method-level granularity to train eight different machine-learning models. Our results suggest that Decision Tree and Random Forest models outperform other models regarding our several evaluation metrics. We then use the pre-trained CodeBERT LLM to study the source code representations' effectiveness in predicting bug severity. CodeBERT finetuning improves the bug severity prediction results significantly in the range of 29%-140% for several evaluation metrics, compared to the best classic prediction model on source code metric. Finally, we integrate source code metrics into CodeBERT as an additional input, using our two proposed architectures, which both enhance the CodeBERT model effectiveness. ","[{'version': 'v1', 'created': 'Wed, 6 Sep 2023 14:38:07 GMT'}]",2023-09-07,"[['Mashhadi', 'Ehsan', ''], ['Ahmadvand', 'Hossein', ''], ['Hemmati', 'Hadi', '']]",0,0,2023-09-06,1,3,1,0,0,0,24208a1dd01a4dc4ee9fdeccc1d8eb900ed74271,261556689.0,https://www.semanticscholar.org/paper/24208a1dd01a4dc4ee9fdeccc1d8eb900ed74271,IEEE International Symposium on Software Reliability Engineering,2023.0,75.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2056768255', 'name': 'Ehsan Mashhadi'}, {'authorId': '2237983084', 'name': 'Hossein Ahmadvand'}, {'authorId': '2214676644', 'name': 'Hadi Hemmati'}]","['University of Calgary', 'York University']",['Canada'],2023-09
2309.03079,Udit Gupta,Udit Gupta,GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models,,,,,q-fin.ST cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Annual Reports of publicly listed companies contain vital information about their financial health which can help assess the potential impact on Stock price of the firm. These reports are comprehensive in nature, going up to, and sometimes exceeding, 100 pages. Analysing these reports is cumbersome even for a single firm, let alone the whole universe of firms that exist. Over the years, financial experts have become proficient in extracting valuable information from these documents relatively quickly. However, this requires years of practice and experience. This paper aims to simplify the process of assessing Annual Reports of all the firms by leveraging the capabilities of Large Language Models (LLMs). The insights generated by the LLM are compiled in a Quant styled dataset and augmented by historical stock price data. A Machine Learning model is then trained with LLM outputs as features. The walkforward test results show promising outperformance wrt S&P500 returns. This paper intends to provide a framework for future work in this direction. To facilitate this, the code has been released as open source. ","[{'version': 'v1', 'created': 'Wed, 6 Sep 2023 17:18:55 GMT'}]",2023-09-07,"[['Gupta', 'Udit', '']]",0,1,2023-09-06,1,1,3,0,0,0,110052b69ccbcc280b1a806c4e0bf876e6a5b116,261556898.0,https://www.semanticscholar.org/paper/110052b69ccbcc280b1a806c4e0bf876e6a5b116,Social Science Research Network,2023.0,10.0,1.0,0.0,True,"['Economics', 'Computer Science']","[{'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237986107', 'name': 'Udit Gupta'}]",['University of Toronto'],['Canada'],2023-09
2309.03175,Eduardo S\'anchez,"Eduardo S\'anchez, Pierre Andrews, Pontus Stenetorp, Mikel Artetxe,
  Marta R. Costa-juss\`a",Gender-specific Machine Translation with Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Decoder-only Large Language Models (LLMs) have demonstrated potential in machine translation (MT), albeit with performance slightly lagging behind traditional encoder-decoder Neural Machine Translation (NMT) systems. However, LLMs offer a unique advantage: the ability to control the properties of the output through prompts. In this study, we harness this flexibility to explore LLaMa's capability to produce gender-specific translations for languages with grammatical gender. Our results indicate that LLaMa can generate gender-specific translations with competitive accuracy and gender bias mitigation when compared to NLLB, a state-of-the-art multilingual NMT system. Furthermore, our experiments reveal that LLaMa's translations are robust, showing significant performance drops when evaluated against opposite-gender references in gender-ambiguous datasets but maintaining consistency in less ambiguous contexts. This research provides insights into the potential and challenges of using LLMs for gender-specific translations and highlights the importance of in-context learning to elicit new tasks in LLMs. ","[{'version': 'v1', 'created': 'Wed, 6 Sep 2023 17:24:06 GMT'}]",2023-09-07,"[['Sánchez', 'Eduardo', ''], ['Andrews', 'Pierre', ''], ['Stenetorp', 'Pontus', ''], ['Artetxe', 'Mikel', ''], ['Costa-jussà', 'Marta R.', '']]",0,0,2023-09-06,1,5,1,2,2,0,fb2719aa3245a1757144d273be0a9b3a96d43a3f,261557040.0,https://www.semanticscholar.org/paper/fb2719aa3245a1757144d273be0a9b3a96d43a3f,arXiv.org,2023.0,50.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238097447', 'name': ""Eduardo S'anchez""}, {'authorId': '5657660', 'name': 'Pierre Yves Andrews'}, {'authorId': '1918552', 'name': 'Pontus Stenetorp'}, {'authorId': '2347956', 'name': 'Mikel Artetxe'}, {'authorId': '1398996347', 'name': 'M. Costa-jussà'}]",['University College London'],['United Kingdom'],2023-09
2309.03412,Masahiro Suzuki,"Masahiro Suzuki, Masanori Hirano, Hiroki Sakaji",From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Instruction tuning is essential for large language models (LLMs) to become interactive. While many instruction tuning datasets exist in English, there is a noticeable lack in other languages. Also, their effectiveness has not been well verified in non-English languages. We construct a Japanese instruction dataset by expanding and filtering existing datasets and apply the dataset to a Japanese pre-trained base model. We performed Low-Rank Adaptation (LoRA) tuning on both Japanese and English existing models using our instruction dataset. We evaluated these models from both quantitative and qualitative perspectives. As a result, the effectiveness of Japanese instruction datasets is confirmed. The results also indicate that even with relatively small LLMs, performances in downstream tasks would be improved through instruction tuning. Our instruction dataset, tuned models, and implementation are publicly available online. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 00:14:37 GMT'}]",2023-09-08,"[['Suzuki', 'Masahiro', ''], ['Hirano', 'Masanori', ''], ['Sakaji', 'Hiroki', '']]",0,0,2023-09-07,1,3,1,0,0,0,b549b74b70ab1123d6771a67d4912daef8e13a30,261582389.0,https://www.semanticscholar.org/paper/b549b74b70ab1123d6771a67d4912daef8e13a30,Social Science Research Network,2023.0,56.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2111455444', 'name': 'Masahiro Suzuki'}, {'authorId': '32949796', 'name': 'Masanori Hirano'}, {'authorId': '2879326', 'name': 'Hiroki Sakaji'}]",['The University of Tokyo'],['Japan'],2023-09
2309.03613,Dario Di Palma,"Dario Di Palma, Giovanni Maria Biancofiore, Vito Walter Anelli,
  Fedelucio Narducci, Tommaso Di Noia, Eugenio Di Sciascio",Evaluating ChatGPT as a Recommender System: A Rigorous Approach,,,,,cs.IR cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Recent popularity surrounds large AI language models due to their impressive natural language capabilities. They contribute significantly to language-related tasks, including prompt-based learning, making them valuable for various specific tasks. This approach unlocks their full potential, enhancing precision and generalization. Research communities are actively exploring their applications, with ChatGPT receiving recognition. Despite extensive research on large language models, their potential in recommendation scenarios still needs to be explored. This study aims to fill this gap by investigating ChatGPT's capabilities as a zero-shot recommender system. Our goals include evaluating its ability to use user preferences for recommendations, reordering existing recommendation lists, leveraging information from similar users, and handling cold-start situations. We assess ChatGPT's performance through comprehensive experiments using three datasets (MovieLens Small, Last.FM, and Facebook Book). We compare ChatGPT's performance against standard recommendation algorithms and other large language models, such as GPT-3.5 and PaLM-2. To measure recommendation effectiveness, we employ widely-used evaluation metrics like Mean Average Precision (MAP), Recall, Precision, F1, normalized Discounted Cumulative Gain (nDCG), Item Coverage, Expected Popularity Complement (EPC), Average Coverage of Long Tail (ACLT), Average Recommendation Popularity (ARP), and Popularity-based Ranking-based Equal Opportunity (PopREO). Through thoroughly exploring ChatGPT's abilities in recommender systems, our study aims to contribute to the growing body of research on the versatility and potential applications of large language models. Our experiment code is available on the GitHub repository: https://github.com/sisinflab/Recommender-ChatGPT ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 10:13:09 GMT'}]",2023-09-08,"[['Di Palma', 'Dario', ''], ['Biancofiore', 'Giovanni Maria', ''], ['Anelli', 'Vito Walter', ''], ['Narducci', 'Fedelucio', ''], ['Di Noia', 'Tommaso', ''], ['Di Sciascio', 'Eugenio', '']]",1,1,2023-09-07,1,6,3,3,0,3,f7d3c17ad1dee97377651e0f5646b3fc6d047fc0,261582579.0,https://www.semanticscholar.org/paper/f7d3c17ad1dee97377651e0f5646b3fc6d047fc0,arXiv.org,2023.0,63.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '117667461', 'name': 'Dario Di Palma'}, {'authorId': '71307529', 'name': 'Giovanni Maria Biancofiore'}, {'authorId': '2431124', 'name': 'V. W. Anelli'}, {'authorId': '1741231', 'name': 'F. Narducci'}, {'authorId': '1737962', 'name': 'T. D. Noia'}, {'authorId': '1738818', 'name': 'E. Sciascio'}]","['Polytechnic University of Bari', 'https://github.com/sisinflab/Recommender-ChatGPT']",['Italy'],2023-09
2309.03645,Dina Zilbershtein,"Mateo Gutierrez Granada, Dina Zilbershtein, Daan Odijk, Francesco
  Barile",VideolandGPT: A User Study on a Conversational Recommender System,"Preprint for KARS2023 (5th Knowledge-aware and Conversational
  Recommender Systems Workshop at RecSys2023)",,,,cs.IR cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  This paper investigates how large language models (LLMs) can enhance recommender systems, with a specific focus on Conversational Recommender Systems that leverage user preferences and personalised candidate selections from existing ranking models. We introduce VideolandGPT, a recommender system for a Video-on-Demand (VOD) platform, Videoland, which uses ChatGPT to select from a predetermined set of contents, considering the additional context indicated by users' interactions with a chat interface. We evaluate ranking metrics, user experience, and fairness of recommendations, comparing a personalised and a non-personalised version of the system, in a between-subject user study. Our results indicate that the personalised version outperforms the non-personalised in terms of accuracy and general user satisfaction, while both versions increase the visibility of items which are not in the top of the recommendation lists. However, both versions present inconsistent behavior in terms of fairness, as the system may generate recommendations which are not available on Videoland. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 11:24:47 GMT'}]",2023-09-08,"[['Granada', 'Mateo Gutierrez', ''], ['Zilbershtein', 'Dina', ''], ['Odijk', 'Daan', ''], ['Barile', 'Francesco', '']]",1,1,2023-09-07,1,4,2,1,0,1,54b82a32a694a6e23256ab2c82d448c2e1623623,261582774.0,https://www.semanticscholar.org/paper/54b82a32a694a6e23256ab2c82d448c2e1623623,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2127512873', 'name': 'Mateo Gutierrez Granada'}, {'authorId': '2238209637', 'name': 'Dina Zilbershtein'}, {'authorId': '1714964', 'name': 'Daan Odijk'}, {'authorId': '2239104329', 'name': 'Francesco Barile'}]","['Maastricht University', 'AO Nederland']",['Netherlands'],2023-09
2309.03748,Hendrik Purwins,"Mina Foosherian, Hendrik Purwins, Purna Rathnayake, Touhidul Alam, Rui
  Teimao, Klaus-Dieter Thoben",Enhancing Pipeline-Based Conversational Agents with Large Language Models,,,,,cs.CL cs.AI cs.LG stat.ML,http://creativecommons.org/licenses/by/4.0/,"  The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT-4. However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation. This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations. In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design. In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities. We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example. Companies may be hesitant to replace their pipeline-based agents with LLMs entirely due to privacy concerns and the need for deep integration within their existing ecosystems. A hybrid approach in which LLMs' are integrated into the pipeline-based agents allows them to save time and costs of building and running agents by capitalizing on the capabilities of LLMs while retaining the integration and privacy safeguards of their existing systems. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 14:43:17 GMT'}]",2023-09-08,"[['Foosherian', 'Mina', ''], ['Purwins', 'Hendrik', ''], ['Rathnayake', 'Purna', ''], ['Alam', 'Touhidul', ''], ['Teimao', 'Rui', ''], ['Thoben', 'Klaus-Dieter', '']]",0,1,2023-09-07,1,6,4,1,0,1,1c9566ea496c2407877452ef0ea2606da44c8925,261582576.0,https://www.semanticscholar.org/paper/1c9566ea496c2407877452ef0ea2606da44c8925,arXiv.org,2023.0,37.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2101187031', 'name': 'Mina Foosherian'}, {'authorId': '2238208177', 'name': 'Hendrik Purwins'}, {'authorId': '2238208004', 'name': 'Purna Rathnayake'}, {'authorId': '2238207921', 'name': 'Touhidul Alam'}, {'authorId': '2238208943', 'name': 'Rui Teimao'}, {'authorId': '144199043', 'name': 'K. Thoben'}]","['Bremer Institut für Produktion und Logistik GmbH', 'University of Bremen', 'Accenture GmbH Liquid Studio Balanstrasse 73 81541, Munich, Germany', 'Center of Excellence for LLMs Balanstrasse 73 81541, Munich, Germany', ""Lloyd's""]","['Germany', 'United Kingdom']",2023-09
2309.03787,Chengguang Gan,"Chengguang Gan, Qinghao Zhang, Tatsunori Mori",USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset,"Model already Open Sourced, Dataset will release soon",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sentiment analysis is a pivotal task in the domain of natural language processing. It encompasses both text-level sentiment polarity classification and word-level Part of Speech(POS) sentiment polarity determination. Such analysis challenges models to understand text holistically while also extracting nuanced information. With the rise of Large Language Models(LLMs), new avenues for sentiment analysis have opened. This paper proposes enhancing performance by leveraging the Mutual Reinforcement Effect(MRE) between individual words and the overall text. It delves into how word polarity influences the overarching sentiment of a passage. To support our research, we annotated four novel Sentiment Text Classification and Part of Speech(SCPOS) datasets, building upon existing sentiment classification datasets. Furthermore, we developed a Universal Sentiment Analysis(USA) model, with a 7-billion parameter size. Experimental results revealed that our model surpassed the performance of gpt-3.5-turbo across all four datasets, underscoring the significance of MRE in sentiment analysis. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 15:35:00 GMT'}, {'version': 'v2', 'created': 'Thu, 14 Sep 2023 05:53:45 GMT'}]",2023-09-15,"[['Gan', 'Chengguang', ''], ['Zhang', 'Qinghao', ''], ['Mori', 'Tatsunori', '']]",0,1,2023-09-07,2,3,1,1,0,1,147763dbb9b9b0363ed0479c4cfa5844c537c344,261582566.0,https://www.semanticscholar.org/paper/147763dbb9b9b0363ed0479c4cfa5844c537c344,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2180661276', 'name': 'Chengguang Gan'}, {'authorId': '2224093040', 'name': 'Qinghao Zhang'}, {'authorId': '2238342160', 'name': 'Tatsunori Mori'}]","['Pusan National University', 'Yokohama National University']","['South Korea', 'Japan']",2023-09
2309.03876,Patrick Haller,"Patrick Haller, Ansar Aynetdinov, Alan Akbik",OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs,"6 pages, 1 figure, 3 tables",,,,cs.CL cs.AI cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions. However, an open research question concerns the inherent biases of trained models and their responses. For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias. Current research work seeks to de-bias such models, or suppress potentially biased answers. With this demonstration, we take a different view on biases in instruction-tuning: Rather than aiming to suppress them, we aim to make them explicit and transparent. To this end, we present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate. The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison. To train the underlying model, we identified 11 different biases (political, geographic, gender, age) and derived an instruction-tuning corpus in which each answer was written by members of one of these demographics. This paper presents OpinionGPT, illustrates how we trained the bias-aware model and showcases the web application (available at https://opiniongpt.informatik.hu-berlin.de). ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 17:41:01 GMT'}]",2023-09-08,"[['Haller', 'Patrick', ''], ['Aynetdinov', 'Ansar', ''], ['Akbik', 'Alan', '']]",0,1,2023-09-07,1,3,4,0,0,0,a327111002d3d76510970d1eec3f03fb85314f11,261582269.0,https://www.semanticscholar.org/paper/a327111002d3d76510970d1eec3f03fb85314f11,arXiv.org,2023.0,29.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': None, 'name': 'Patrick Haller'}, {'authorId': '74210019', 'name': 'Ansar Aynetdinov'}, {'authorId': '2403712', 'name': 'A. Akbik'}]",['Humboldt-Universität zu Berlin'],['Germany'],2023-09
2309.03884,Tal Shaharabany,"Tal Shaharabany, Ariel Shaulov and Lior Wolf",Zero-Shot Audio Captioning via Audibility Guidance,,,,,cs.SD cs.CL eess.AS,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The task of audio captioning is similar in essence to tasks such as image and video captioning. However, it has received much less attention. We propose three desiderata for captioning audio -- (i) fluency of the generated text, (ii) faithfulness of the generated text to the input audio, and the somewhat related (iii) audibility, which is the quality of being able to be perceived based only on audio. Our method is a zero-shot method, i.e., we do not learn to perform captioning. Instead, captioning occurs as an inference process that involves three networks that correspond to the three desired qualities: (i) A Large Language Model, in our case, for reasons of convenience, GPT-2, (ii) A model that provides a matching score between an audio file and a text, for which we use a multimodal matching network called ImageBind, and (iii) A text classifier, trained using a dataset we collected automatically by instructing GPT-4 with prompts designed to direct the generation of both audible and inaudible sentences. We present our results on the AudioCap dataset, demonstrating that audibility guidance significantly enhances performance compared to the baseline, which lacks this objective. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 17:45:58 GMT'}]",2023-09-08,"[['Shaharabany', 'Tal', ''], ['Shaulov', 'Ariel', ''], ['Wolf', 'Lior', '']]",0,1,2023-09-07,1,3,3,2,1,1,3e104595041078e888825f80bb893d86754b52fe,261582897.0,https://www.semanticscholar.org/paper/3e104595041078e888825f80bb893d86754b52fe,arXiv.org,2023.0,26.0,1.0,1.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1438948620', 'name': 'Tal Shaharabany'}, {'authorId': '2238209594', 'name': 'Ariel Shaulov'}, {'authorId': '145128145', 'name': 'Lior Wolf'}]",['Tel Aviv University'],['Israel'],2023-09
2309.03914,Tao Xiao,"Tao Xiao, Christoph Treude, Hideaki Hata, Kenichi Matsumoto",DevGPT: Studying Developer-ChatGPT Conversations,MSR 2024 Mining Challenge Proposal,,,,cs.SE,http://creativecommons.org/licenses/by/4.0/,"  The emergence of large language models (LLMs) such as ChatGPT has disrupted the landscape of software development. Many studies are investigating the quality of responses generated by ChatGPT, the efficacy of various prompting techniques, and its comparative performance in programming contests, to name a few examples. Yet, we know very little about how ChatGPT is actually used by software developers. What questions do developers present to ChatGPT? What are the dynamics of these interactions? What is the backdrop against which these conversations are held, and how do the conversations feedback into the artifacts of their work? To close this gap, we introduce DevGPT, a curated dataset which encompasses 17,913 prompts and ChatGPT's responses including 11,751 code snippets, coupled with the corresponding software development artifacts -- ranging from source code, commits, issues, pull requests, to discussions and Hacker News threads -- to enable the analysis of the context and implications of these developer interactions with ChatGPT. ","[{'version': 'v1', 'created': 'Thu, 31 Aug 2023 06:55:40 GMT'}]",2023-09-11,"[['Xiao', 'Tao', ''], ['Treude', 'Christoph', ''], ['Hata', 'Hideaki', ''], ['Matsumoto', 'Kenichi', '']]",1,1,2023-08-31,1,4,1,1,0,1,def24fb1e977db69f4b1b866b807f9ab9bad5227,261660223.0,https://www.semanticscholar.org/paper/def24fb1e977db69f4b1b866b807f9ab9bad5227,arXiv.org,2023.0,5.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144994999', 'name': 'Tao Xiao'}, {'authorId': '1685418', 'name': 'Christoph Treude'}, {'authorId': '145050815', 'name': 'Hideaki Hata'}, {'authorId': '2238636149', 'name': 'Kenichi Matsumoto'}]","['University of Melbourne', 'Shinshu University', 'Nara Institute of Science and Technology']","['Japan', 'Australia']",2023-08
2309.04146,Wonseok Hwang,"Kyoungyeon Cho, Seungkum Han, Wonseok Hwang",NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  The statistical analysis of large scale legal corpus can provide valuable legal insights. For such analysis one needs to (1) select a subset of the corpus using document retrieval tools, (2) structuralize text using information extraction (IE) systems, and (3) visualize the data for the statistical analysis. Each process demands either specialized tools or programming skills whereas no comprehensive unified ""no-code"" tools have been available. Especially for IE, if the target information is not predefined in the ontology of the IE system, one needs to build their own system. Here we provide NESTLE, a no code tool for large-scale statistical analysis of legal corpus. With NESTLE, users can search target documents, extract information, and visualize the structured data all via the chat interface with accompanying auxiliary GUI for the fine-level control. NESTLE consists of three main components: a search engine, an end-to-end IE system, and a Large Language Model (LLM) that glues the whole components together and provides the chat interface. Powered by LLM and the end-to-end IE system, NESTLE can extract any type of information that has not been predefined in the IE system opening up the possibility of unlimited customizable statistical analysis of the corpus without writing a single line of code. The use of the custom end-to-end IE system also enables faster and low-cost IE on large scale corpus. We validate our system on 15 Korean precedent IE tasks and 3 legal text classification tasks from LEXGLUE. The comprehensive experiments reveal NESTLE can achieve GPT-4 comparable performance by training the internal IE module with 4 human-labeled, and 192 LLM-labeled examples. The detailed analysis provides the insight on the trade-off between accuracy, time, and cost in building such system. ","[{'version': 'v1', 'created': 'Fri, 8 Sep 2023 06:23:25 GMT'}]",2023-09-11,"[['Cho', 'Kyoungyeon', ''], ['Han', 'Seungkum', ''], ['Hwang', 'Wonseok', '']]",0,1,2023-09-08,1,3,2,1,0,1,d2e2f399cf141976a30ebb1d95d4408ab5c5b29e,261660571.0,https://www.semanticscholar.org/paper/d2e2f399cf141976a30ebb1d95d4408ab5c5b29e,arXiv.org,2023.0,0.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2151022286', 'name': 'Kyoungyeon Cho'}, {'authorId': '2238901701', 'name': 'Seungkum Han'}, {'authorId': '2238813298', 'name': 'Wonseok Hwang'}]",['University of Seoul'],['South Korea'],2023-09
2309.04213,Yan Jiang,"Yan Jiang, Ruihong Qiu, Yi Zhang, Zi Huang",UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As social media becomes increasingly popular, more and more activities related to public health emerge. Current techniques for public health analysis involve popular models such as BERT and large language models (LLMs). However, the costs of training in-domain LLMs for public health are especially expensive. Furthermore, such kinds of in-domain datasets from social media are generally imbalanced. To tackle these challenges, the data imbalance issue can be overcome by data augmentation and balanced training. Moreover, the ability of the LLMs can be effectively utilized by prompting the model properly. In this paper, a novel ALEX framework is proposed to improve the performance of public health analysis on social media by adopting an LLMs explanation mechanism. Results show that our ALEX model got the best performance among all submissions in both Task 2 and Task 4 with a high score in Task 1 in Social Media Mining for Health 2023 (SMM4H)[1]. Our code has been released at https:// github.com/YanJiangJerry/ALEX. ","[{'version': 'v1', 'created': 'Fri, 8 Sep 2023 08:54:55 GMT'}, {'version': 'v2', 'created': 'Tue, 12 Sep 2023 07:19:22 GMT'}]",2023-09-13,"[['Jiang', 'Yan', ''], ['Qiu', 'Ruihong', ''], ['Zhang', 'Yi', ''], ['Huang', 'Zi', '']]",0,0,2023-09-08,2,4,2,0,0,0,2a492377428d78a4f047a5b9b703c8625e0c1786,261660277.0,https://www.semanticscholar.org/paper/2a492377428d78a4f047a5b9b703c8625e0c1786,arXiv.org,2023.0,8.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238993080', 'name': 'Yan Jiang'}, {'authorId': '1395454635', 'name': 'Ruihong Qiu'}, {'authorId': '39939149', 'name': 'Yi Zhang'}, {'authorId': '2238904560', 'name': 'Zi Huang'}]",['University of Queensland'],['Australia'],2023-09
2309.04292,Patr\'icia Pereira,"Patr\'icia Pereira, Rui Ribeiro, Helena Moniz, Luisa Coheur and Joao
  Paulo Carvalho",Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations,FUZZ-IEEE 2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Fuzzy Fingerprints have been successfully used as an interpretable text classification technique, but, like most other techniques, have been largely surpassed in performance by Large Pre-trained Language Models, such as BERT or RoBERTa. These models deliver state-of-the-art results in several Natural Language Processing tasks, namely Emotion Recognition in Conversations (ERC), but suffer from the lack of interpretability and explainability. In this paper, we propose to combine the two approaches to perform ERC, as a means to obtain simpler and more interpretable Large Language Models-based classifiers. We propose to feed the utterances and their previous conversational turns to a pre-trained RoBERTa, obtaining contextual embedding utterance representations, that are then supplied to an adapted Fuzzy Fingerprint classification module. We validate our approach on the widely used DailyDialog ERC benchmark dataset, in which we obtain state-of-the-art level results using a much lighter model. ","[{'version': 'v1', 'created': 'Fri, 8 Sep 2023 12:26:01 GMT'}]",2023-09-11,"[['Pereira', 'Patrícia', ''], ['Ribeiro', 'Rui', ''], ['Moniz', 'Helena', ''], ['Coheur', 'Luisa', ''], ['Carvalho', 'Joao Paulo', '']]",0,0,2023-09-08,1,5,2,0,0,0,fb47199fac9d1073256065af7a61455885a31116,261660669.0,https://www.semanticscholar.org/paper/fb47199fac9d1073256065af7a61455885a31116,IEEE International Conference on Fuzzy Systems,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2058093218', 'name': 'Patrícia Pereira'}, {'authorId': '2070255380', 'name': 'Rui Ribeiro'}, {'authorId': '2504458', 'name': 'Helena Moniz'}, {'authorId': '1771718', 'name': 'Luísa Coheur'}, {'authorId': '123739597', 'name': 'Joao Paulo Carvalho'}]",['University of Lisbon'],['Portugal'],2023-09
2309.04646,Thuan Doan Vu,"Vu-Thuan Doan, Quoc-Truong Truong, Duc-Vu Nguyen, Vinh-Tiep Nguyen,
  and Thuy-Ngan Nguyen Luu",Efficient Finetuning Large Language Models For Vietnamese Chatbot,"arXiv admin note: text overlap with arXiv:2304.08177,
  arXiv:2303.16199 by other authors",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs), such as GPT-4, PaLM, and LLaMa, have been shown to achieve remarkable performance across a variety of natural language tasks. Recent advancements in instruction tuning bring LLMs with ability in following user's instructions and producing human-like responses. However, the high costs associated with training and implementing LLMs pose challenges to academic research. Furthermore, the availability of pretrained LLMs and instruction-tune datasets for Vietnamese language is limited. To tackle these concerns, we leverage large-scale instruction-following datasets from open-source projects, namely Alpaca, GPT4All, and Chat-Doctor, which cover general domain and specific medical domain. To the best of our knowledge, these are the first instructional dataset for Vietnamese. Subsequently, we utilize parameter-efficient tuning through Low-Rank Adaptation (LoRA) on two open LLMs: Bloomz (Multilingual) and GPTJ-6B (Vietnamese), resulting four models: Bloomz-Chat, Bloomz-Doctor, GPTJ-Chat, GPTJ-Doctor.Finally, we assess the effectiveness of our methodology on a per-sample basis, taking into consideration the helpfulness, relevance, accuracy, level of detail in their responses. This evaluation process entails the utilization of GPT-4 as an automated scoring mechanism. Despite utilizing a low-cost setup, our method demonstrates about 20-30\% improvement over the original models in our evaluation tasks. ","[{'version': 'v1', 'created': 'Sat, 9 Sep 2023 00:11:53 GMT'}]",2023-09-12,"[['Doan', 'Vu-Thuan', ''], ['Truong', 'Quoc-Truong', ''], ['Nguyen', 'Duc-Vu', ''], ['Nguyen', 'Vinh-Tiep', ''], ['Luu', 'Thuy-Ngan Nguyen', '']]",0,1,2023-09-09,1,5,2,5,2,3,57cd349e70282f9877d9eb9689b5999b9f059dc9,261682123.0,https://www.semanticscholar.org/paper/57cd349e70282f9877d9eb9689b5999b9f059dc9,International Conference on Multimedia Analysis and Pattern Recognition,2023.0,18.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238951980', 'name': 'Vu-Thuan Doan'}, {'authorId': '2238951930', 'name': 'Quoc-Truong Truong'}, {'authorId': '146525995', 'name': 'Duc-Vu Nguyen'}, {'authorId': '2239052357', 'name': 'Vinh-Tiep Nguyen'}, {'authorId': '2238951963', 'name': 'Thuy-Ngan Nguyen Luu'}]","['Vietnam National University Ho Chi Minh City', 'University of Information Technology']",['Vietnam'],2023-09
2309.04704,Bohdan Pavlyshenko,Bohdan M. Pavlyshenko,Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model,,,,,cs.CL cs.AI cs.CY cs.IR cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The paper considers the possibility of fine-tuning Llama 2 large language model (LLM) for the disinformation analysis and fake news detection. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text on revealing disinformation and propaganda narratives, fact checking, fake news detection, manipulation analytics, extracting named entities with their sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a deep analysis of texts and reveal complex styles and narratives. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models. ","[{'version': 'v1', 'created': 'Sat, 9 Sep 2023 07:10:19 GMT'}]",2023-09-12,"[['Pavlyshenko', 'Bohdan M.', '']]",0,0,2023-09-09,1,1,5,1,1,0,969a9fc0fe874b150c712f6b9a2a890f819e6c30,261682524.0,https://www.semanticscholar.org/paper/969a9fc0fe874b150c712f6b9a2a890f819e6c30,arXiv.org,2023.0,28.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3008532', 'name': 'B. Pavlyshenko'}]",['Lviv University'],['Ukraine'],2023-09
2309.04827,Elena Voita,"Elena Voita, Javier Ferrando, Christoforos Nalmpantis","Neurons in Large Language Models: Dead, N-gram, Positional",,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the network is sparse and represents many discrete features. Here, many neurons (more than 70% in some layers of the 66b model) are ""dead"", i.e. they never activate on a large collection of diverse data. At the same time, many of the alive neurons are reserved for discrete features and act as token and n-gram detectors. Interestingly, their corresponding FFN updates not only promote next token candidates as could be expected, but also explicitly focus on removing the information about triggering them tokens, i.e., current input. To the best of our knowledge, this is the first example of mechanisms specialized at removing (rather than adding) information from the residual stream. With scale, models become more sparse in a sense that they have more dead neurons and token detectors. Finally, some neurons are positional: them being activated or not depends largely (or solely) on position and less so (or not at all) on textual data. We find that smaller models have sets of neurons acting as position range indicators while larger models operate in a less explicit manner. ","[{'version': 'v1', 'created': 'Sat, 9 Sep 2023 15:51:36 GMT'}]",2023-09-12,"[['Voita', 'Elena', ''], ['Ferrando', 'Javier', ''], ['Nalmpantis', 'Christoforos', '']]",0,0,2023-09-09,1,3,1,1,1,0,110804428354df709b3693f9efc81946a9036ebf,261682169.0,https://www.semanticscholar.org/paper/110804428354df709b3693f9efc81946a9036ebf,arXiv.org,2023.0,53.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46235299', 'name': 'Elena Voita'}, {'authorId': '1751450782', 'name': 'Javier Ferrando'}, {'authorId': '31434304', 'name': 'Christoforos Nalmpantis'}]",['Universitat Politècnica de Catalunya'],['Spain'],2023-09
2309.04858,Yun William Yu,"Daphne Ippolito, Nicholas Carlini, Katherine Lee, Milad Nasr, Yun
  William Yu",Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System,"6 pages, 4 figures, 3 tables. Also, 5 page appendix. Accepted to INLG
  2023",,,,cs.LG cs.CL cs.CR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-$k$ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT). ","[{'version': 'v1', 'created': 'Sat, 9 Sep 2023 18:19:47 GMT'}]",2023-09-12,"[['Ippolito', 'Daphne', ''], ['Carlini', 'Nicholas', ''], ['Lee', 'Katherine', ''], ['Nasr', 'Milad', ''], ['Yu', 'Yun William', '']]",1,1,2023-09-09,1,5,3,1,0,1,03fb535de5cfcf435705a079334ac60f501226ab,261681722.0,https://www.semanticscholar.org/paper/03fb535de5cfcf435705a079334ac60f501226ab,International Conference on Natural Language Generation,2023.0,15.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '7975935', 'name': 'Daphne Ippolito'}, {'authorId': '2483738', 'name': 'Nicholas Carlini'}, {'authorId': '3844009', 'name': 'Katherine Lee'}, {'authorId': '3490923', 'name': 'Milad Nasr'}, {'authorId': '2239157286', 'name': 'Yun William Yu'}]","['University of Toronto', 'Google']","['Canada', 'United Kingdom']",2023-09
2309.04992,Adian Liusie,"Adian Liusie, Potsawee Manakul, Mark J. F. Gales",Mitigating Word Bias in Zero-shot Prompt-based Classifiers,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Prompt-based classifiers are an attractive approach for zero-shot classification. However, the precise choice of the prompt template and label words can largely influence performance, with semantically equivalent settings often showing notable performance difference. This discrepancy can be partly attributed to word biases, where the classifier may be biased towards classes. To address this problem, it is possible to optimise classification thresholds on a labelled data set, however, this mitigates some of the advantages of prompt-based classifiers. This paper instead approaches this problem by examining the expected marginal probabilities of the classes. Here, probabilities are reweighted to have a uniform prior over classes, in an unsupervised fashion. Further, we draw a theoretical connection between the class priors and the language models' word prior, and offer the ability to set a threshold in a zero-resource fashion. We show that matching class priors correlates strongly with the oracle upper bound performance and demonstrate large consistent performance gains for prompt settings over a range of NLP tasks. ","[{'version': 'v1', 'created': 'Sun, 10 Sep 2023 10:57:41 GMT'}]",2023-09-12,"[['Liusie', 'Adian', ''], ['Manakul', 'Potsawee', ''], ['Gales', 'Mark J. F.', '']]",0,0,2023-09-10,1,3,1,0,0,0,e7d21ad4da122bf1db19e4fda57bf94c1dfa24a4,261681775.0,https://www.semanticscholar.org/paper/e7d21ad4da122bf1db19e4fda57bf94c1dfa24a4,arXiv.org,2023.0,21.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2190750613', 'name': 'Adian Liusie'}, {'authorId': '89355510', 'name': 'Potsawee Manakul'}, {'authorId': '1740397', 'name': 'M. Gales'}]",['University of Cambridge'],['United Kingdom'],2023-09
2309.05076,Maximilian Croissant,"Maximilian Croissant, Madeleine Frister, Guy Schofield, Cade McCall",An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language Model Game Agents,,,,,cs.AI cs.CL cs.HC,http://creativecommons.org/licenses/by/4.0/,"  The development of believable, natural, and interactive digital artificial agents is a field of growing interest. Theoretical uncertainties and technical barriers present considerable challenges to the field, particularly with regards to developing agents that effectively simulate human emotions. Large language models (LLMs) might address these issues by tapping common patterns in situational appraisal. In three empirical experiments, this study tests the capabilities of LLMs to solve emotional intelligence tasks and to simulate emotions. It presents and evaluates a new chain-of-emotion architecture for emotion simulation within video games, based on psychological appraisal research. Results show that it outperforms standard LLM architectures on a range of user experience and content analysis metrics. This study therefore provides early evidence of how to construct and test affective agents based on cognitive processes represented in language models. ","[{'version': 'v1', 'created': 'Sun, 10 Sep 2023 16:55:49 GMT'}]",2023-09-12,"[['Croissant', 'Maximilian', ''], ['Frister', 'Madeleine', ''], ['Schofield', 'Guy', ''], ['McCall', 'Cade', '']]",0,0,2023-09-10,1,4,3,0,0,0,5e2d50f7745d7d1cd92c1f8fb79ec03735605b08,261681777.0,https://www.semanticscholar.org/paper/5e2d50f7745d7d1cd92c1f8fb79ec03735605b08,arXiv.org,2023.0,68.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1637847907', 'name': 'Maximilian Croissant'}, {'authorId': '2145921389', 'name': 'Madeleine Frister'}, {'authorId': '2238949192', 'name': 'Guy Schofield'}, {'authorId': '2238949347', 'name': 'Cade McCall'}]",['University of York'],['United Kingdom'],2023-09
2309.05142,Michalis Vlachos,"Michalis Vlachos and Mircea Lungu and Yash Raj Shrestha and
  Johannes-Rudolf David",Large Language Models for Difficulty Estimation of Foreign Language Content with Application to Language Learning,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  We use large language models to aid learners enhance proficiency in a foreign language. This is accomplished by identifying content on topics that the user is interested in, and that closely align with the learner's proficiency level in that foreign language. Our work centers on French content, but our approach is readily transferable to other languages. Our solution offers several distinctive characteristics that differentiate it from existing language-learning solutions, such as, a) the discovery of content across topics that the learner cares about, thus increasing motivation, b) a more precise estimation of the linguistic difficulty of the content than traditional readability measures, and c) the availability of both textual and video-based content. The linguistic complexity of video content is derived from the video captions. It is our aspiration that such technology will enable learners to remain engaged in the language-learning process by continuously adapting the topics and the difficulty of the content to align with the learners' evolving interests and learning objectives. ","[{'version': 'v1', 'created': 'Sun, 10 Sep 2023 21:23:09 GMT'}]",2023-09-12,"[['Vlachos', 'Michalis', ''], ['Lungu', 'Mircea', ''], ['Shrestha', 'Yash Raj', ''], ['David', 'Johannes-Rudolf', '']]",0,0,2023-09-10,1,4,2,0,0,0,6214d693b6679aecfd2b2d5f8d5b220c255fadc2,261681745.0,https://www.semanticscholar.org/paper/6214d693b6679aecfd2b2d5f8d5b220c255fadc2,arXiv.org,2023.0,44.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '151481675', 'name': 'Michalis Vlachos'}, {'authorId': '2238949204', 'name': 'Mircea Lungu'}, {'authorId': '2698101', 'name': 'Y. Shrestha'}, {'authorId': '2238949448', 'name': 'Johannes-Rudolf David'}]","['University of Lausanne', 'IT University of Copenhagen']","['Switzerland', 'Denmark']",2023-09
2309.05163,Will Yeadon,Will Yeadon and Tom Hardy,The Impact of AI in Physics Education: A Comprehensive Review from GCSE to University Levels,"22 pages, 10 Figures, 2 Tables",,,,physics.ed-ph,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  With the rapid evolution of Artificial Intelligence (AI), its potential implications for higher education have become a focal point of interest. This study delves into the capabilities of AI in Physics Education and offers actionable AI policy recommendations. Using a Large Language Model (LLM), we assessed its ability to answer 1337 Physics exam questions spanning GCSE, A-Level, and Introductory University curricula. We employed various AI prompting techniques: Zero Shot, In Context Learning, and Confirmatory Checking, which merges Chain of Thought reasoning with Reflection. The AI's proficiency varied across academic levels: it scored an average of 83.4% on GCSE, 63.8% on A-Level, and 37.4% on university-level questions, with an overall average of 59.9% using the most effective prompting technique. In a separate test, the LLM's accuracy on 5000 mathematical operations was found to decrease as the number of digits increased. Furthermore, when evaluated as a marking tool, the LLM's concordance with human markers averaged at 50.8%, with notable inaccuracies in marking straightforward questions, like multiple-choice. Given these results, our recommendations underscore caution: while current LLMs can consistently perform well on Physics questions at earlier educational stages, their efficacy diminishes with advanced content and complex calculations. LLM outputs often showcase novel methods not in the syllabus, excessive verbosity, and miscalculations in basic arithmetic. This suggests that at university, there's no substantial threat from LLMs for non-invigilated Physics questions. However, given the LLMs' considerable proficiency in writing Physics essays and coding abilities, non-invigilated examinations of these skills in Physics are highly vulnerable to automated completion by LLMs. This vulnerability also extends to Physics questions pitched at lower academic levels. ","[{'version': 'v1', 'created': 'Sun, 10 Sep 2023 23:06:15 GMT'}]",2023-09-12,"[['Yeadon', 'Will', ''], ['Hardy', 'Tom', '']]",0,0,2023-09-10,1,2,1,0,0,0,e2ffb7b4215cbe7b5d06be4a37aacedc8762fd50,261682569.0,https://www.semanticscholar.org/paper/e2ffb7b4215cbe7b5d06be4a37aacedc8762fd50,,2023.0,36.0,2.0,0.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}, {'category': 'Physics', 'source': 's2-fos-model'}]","[{'authorId': '2238952578', 'name': 'Will Yeadon'}, {'authorId': '2238952591', 'name': 'Tom Hardy'}]","['South Rd, Durham, DH1 3LE, UK', 'Durham University']",['United Kingdom'],2023-09
2309.05173,Zhengxiang Shi,"Zhengxiang Shi, Aldo Lipani",DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning,Code is available at https://github.com/ZhengxiangShi/DePT,,,,cs.CL cs.AI cs.CV cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Prompt tuning (PT), where a small amount of trainable soft (continuous) prompt vectors is affixed to the input of language models (LM), has shown promising results across various tasks and models for parameter-efficient fine-tuning (PEFT). PT stands out from other PEFT approaches because it maintains competitive performance with fewer trainable parameters and does not drastically scale up its parameters as the model size expands. However, PT introduces additional soft prompt tokens, leading to longer input sequences, which significantly impacts training and inference time and memory usage due to the Transformer's quadratic complexity. Particularly concerning for Large Language Models (LLMs) that face heavy daily querying. To address this issue, we propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt into a shorter soft prompt and a pair of low-rank matrices that are then optimised with two different learning rates. This allows DePT to achieve better performance while saving over 20% memory and time costs compared to vanilla PT and its variants, without changing trainable parameter sizes. Through extensive experiments on 23 natural language processing (NLP) and vision-language (VL) tasks, we demonstrate that DePT outperforms state-of-the-art PEFT approaches, including the full fine-tuning baseline in some scenarios. Additionally, we empirically show that DEPT grows more efficient as the model size increases. Our further study reveals that DePT integrates seamlessly with parameter-efficient transfer learning in the few-shot learning setting and highlights its adaptability to various model architectures and sizes. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 00:02:05 GMT'}]",2023-09-12,"[['Shi', 'Zhengxiang', ''], ['Lipani', 'Aldo', '']]",0,0,2023-09-11,1,2,4,0,0,0,2efadc1c928c8d92756e573f371b8d46087865ed,261682057.0,https://www.semanticscholar.org/paper/2efadc1c928c8d92756e573f371b8d46087865ed,arXiv.org,2023.0,68.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2110398077', 'name': 'Zhengxiang Shi'}, {'authorId': '2121294485', 'name': 'Aldo Lipani'}]",['University College London'],['United Kingdom'],2023-09
2309.05238,Shuai Wang,"Shuai Wang, Harrisen Scells, Martin Potthast, Bevan Koopman, Guido
  Zuccon",Generating Natural Language Queries for More Effective Systematic Review Screening Prioritisation,Preprints for Accepted paper in SIGIR-AP-2023,,,,cs.IR cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Screening prioritisation in medical systematic reviews aims to rank the set of documents retrieved by complex Boolean queries. The goal is to prioritise the most important documents so that subsequent review steps can be carried out more efficiently and effectively. The current state of the art uses the final title of the review to rank documents using BERT-based neural neural rankers. However, the final title is only formulated at the end of the review process, which makes this approach impractical as it relies on ex post facto information. At the time of screening, only a rough working title is available, with which the BERT-based ranker achieves is significantly worse than the final title. In this paper, we explore alternative sources of queries for screening prioritisation, such as the Boolean query used to retrieve the set of documents to be screened, and queries generated by instruction-based generative large language models such as ChatGPT and Alpaca. Our best approach is not only practical based on the information available at screening time, but is similar in effectiveness with the final title. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 05:12:14 GMT'}]",2023-09-12,"[['Wang', 'Shuai', ''], ['Scells', 'Harrisen', ''], ['Potthast', 'Martin', ''], ['Koopman', 'Bevan', ''], ['Zuccon', 'Guido', '']]",1,1,2023-09-11,1,5,2,2,0,2,a7cb000aa86eb035cdb527349885191fe52baf86,261682437.0,https://www.semanticscholar.org/paper/a7cb000aa86eb035cdb527349885191fe52baf86,arXiv.org,2023.0,82.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2146514461', 'name': 'Shuai Wang'}, {'authorId': '8842143', 'name': 'Harrisen Scells'}, {'authorId': '3046200', 'name': 'Martin Potthast'}, {'authorId': '1783566', 'name': 'B. Koopman'}, {'authorId': '1692855', 'name': 'G. Zuccon'}]","['Leipzig University', 'Commonwealth Scientific and Industrial Research Organisation', 'University of Queensland']","['Germany', 'Australia']",2023-09
2309.05454,Joseph Marvin Imperial,"Joseph Marvin Imperial, Harish Tayyar Madabushi",Flesch or Fumble? Evaluating Readability Standard Alignment of Instruction-Tuned Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Readability metrics and standards such as Flesch Kincaid Grade Level (FKGL) and the Common European Framework of Reference for Languages (CEFR) exist to guide teachers and educators to properly assess the complexity of educational materials before administering them for classroom use. In this study, we select a diverse set of open and closed-source instruction-tuned language models and investigate their performances in writing story completions and simplifying narratives$-$tasks that teachers perform$-$using standard-guided prompts controlling text readability. Our extensive findings provide empirical proof of how globally recognized models like ChatGPT may be considered less effective and may require more refined prompts for these generative tasks compared to other open-sourced models such as BLOOMZ and FlanT5$-$which have shown promising results. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 13:50:38 GMT'}]",2023-09-12,"[['Imperial', 'Joseph Marvin', ''], ['Madabushi', 'Harish Tayyar', '']]",1,1,2023-09-11,1,2,1,2,1,1,78b2336d5d0c9e5dd1eefebdc82faf90d9586d81,261697064.0,https://www.semanticscholar.org/paper/78b2336d5d0c9e5dd1eefebdc82faf90d9586d81,arXiv.org,2023.0,70.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151472158', 'name': 'Joseph Marvin Imperial'}, {'authorId': '3467205', 'name': 'Harish Tayyar Madabushi'}]","['National University', 'University of Bath']","['Philippines', 'United Kingdom']",2023-09
2309.05463,Suriya Gunasekar,"Yuanzhi Li, S\'ebastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya
  Gunasekar, Yin Tat Lee",Textbooks Are All You Need II: phi-1.5 technical report,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  We continue the investigation into the power of smaller Transformer-based language models as initiated by \textbf{TinyStories} -- a 10 million parameter model that can produce coherent English -- and the follow-up work on \textbf{phi-1}, a 1.3 billion parameter model with Python coding performance close to the state-of-the-art. The latter work proposed to use existing Large Language Models (LLMs) to generate ``textbook quality"" data as a way to enhance the learning process compared to traditional web data. We follow the ``Textbooks Are All You Need"" approach, focusing this time on common sense reasoning in natural language, and create a new 1.3 billion parameter model named \textbf{phi-1.5}, with performance on natural language tasks comparable to models 5x larger, and surpassing most non-frontier LLMs on more complex reasoning tasks such as grade-school mathematics and basic coding. More generally, \textbf{phi-1.5} exhibits many of the traits of much larger LLMs, both good -- such as the ability to ``think step by step"" or perform some rudimentary in-context learning -- and bad, including hallucinations and the potential for toxic and biased generations -- encouragingly though, we are seeing improvement on that front thanks to the absence of web data. We open-source \textbf{phi-1.5} to promote further research on these urgent topics. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 14:01:45 GMT'}]",2023-09-12,"[['Li', 'Yuanzhi', ''], ['Bubeck', 'Sébastien', ''], ['Eldan', 'Ronen', ''], ['Del Giorno', 'Allie', ''], ['Gunasekar', 'Suriya', ''], ['Lee', 'Yin Tat', '']]",0,0,2023-09-11,1,6,2,0,0,0,e26888285436bc7998e5c95102a9beb60144be5e,261696657.0,https://www.semanticscholar.org/paper/e26888285436bc7998e5c95102a9beb60144be5e,arXiv.org,2023.0,39.0,21.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '152244300', 'name': 'Yuan-Fang Li'}, {'authorId': '1815542', 'name': 'Sébastien Bubeck'}, {'authorId': '2315830', 'name': 'Ronen Eldan'}, {'authorId': '50672277', 'name': 'Allison Del Giorno'}, {'authorId': '3317356', 'name': 'Suriya Gunasekar'}, {'authorId': '2239163839', 'name': 'Yin Tat Lee'}]",['Microsoft'],['India'],2023-09
2309.05501,Ha Thanh Nguyen,"Ha-Thanh Nguyen, Randy Goebel, Francesca Toni, Kostas Stathis, Ken
  Satoh",Black-Box Analysis: GPTs Across Time in Legal Textual Entailment Task,ISAILD@KSE 2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The evolution of Generative Pre-trained Transformer (GPT) models has led to significant advancements in various natural language processing applications, particularly in legal textual entailment. We present an analysis of GPT-3.5 (ChatGPT) and GPT-4 performances on COLIEE Task 4 dataset, a prominent benchmark in this domain. The study encompasses data from Heisei 18 (2006) to Reiwa 3 (2021), exploring the models' abilities to discern entailment relationships within Japanese statute law across different periods. Our preliminary experimental results unveil intriguing insights into the models' strengths and weaknesses in handling legal textual entailment tasks, as well as the patterns observed in model performance. In the context of proprietary models with undisclosed architectures and weights, black-box analysis becomes crucial for evaluating their capabilities. We discuss the influence of training data distribution and the implications on the models' generalizability. This analysis serves as a foundation for future research, aiming to optimize GPT-based models and enable their successful adoption in legal information extraction and entailment applications. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 14:43:54 GMT'}]",2023-09-12,"[['Nguyen', 'Ha-Thanh', ''], ['Goebel', 'Randy', ''], ['Toni', 'Francesca', ''], ['Stathis', 'Kostas', ''], ['Satoh', 'Ken', '']]",1,1,2023-09-11,1,5,2,3,0,3,9a88def3950f734f8fd7ea0dd5a45d5279dd5470,261697053.0,https://www.semanticscholar.org/paper/9a88def3950f734f8fd7ea0dd5a45d5279dd5470,arXiv.org,2023.0,28.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2716209', 'name': 'Nguyen Ha Thanh'}, {'authorId': '2239102814', 'name': 'Randy Goebel'}, {'authorId': '49973505', 'name': 'Francesca Toni'}, {'authorId': '1802398', 'name': 'Kostas Stathis'}, {'authorId': '2154464229', 'name': 'Ken Satoh'}]","['Royal Holloway University of London', 'Imperial College London', 'National Institute of Informatics', 'University of Alberta']","['Canada', 'Japan', 'United Kingdom']",2023-09
2309.05682,Paul Bilokon,Paul Bilokon and Oleksandr Bilokon and Saeed Amen,"A compendium of data sources for data science, machine learning, and artificial intelligence",,,,,cs.LG cs.AI cs.DB q-bio.QM q-fin.CP,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advances in data science, machine learning, and artificial intelligence, such as the emergence of large language models, are leading to an increasing demand for data that can be processed by such models. While data sources are application-specific, and it is impossible to produce an exhaustive list of such data sources, it seems that a comprehensive, rather than complete, list would still benefit data scientists and machine learning experts of all levels of seniority. The goal of this publication is to provide just such an (inevitably incomplete) list -- or compendium -- of data sources across multiple areas of applications, including finance and economics, legal (laws and regulations), life sciences (medicine and drug discovery), news sentiment and social media, retail and ecommerce, satellite imagery, and shipping and logistics, and sports. ","[{'version': 'v1', 'created': 'Sun, 10 Sep 2023 19:15:22 GMT'}]",2023-09-13,"[['Bilokon', 'Paul', ''], ['Bilokon', 'Oleksandr', ''], ['Amen', 'Saeed', '']]",0,0,2023-09-10,1,3,5,0,0,0,00646ee26fb4e2f00ccb47a7d123f1e1dbbc129b,261697438.0,https://www.semanticscholar.org/paper/00646ee26fb4e2f00ccb47a7d123f1e1dbbc129b,Social Science Research Network,2023.0,76.0,0.0,0.0,False,"['Computer Science', 'Biology', 'Economics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2240294146', 'name': 'Paul Bilokon'}, {'authorId': '2239110873', 'name': 'Oleksandr Bilokon'}, {'authorId': '2239110381', 'name': 'Saeed Amen'}]","['Turnleaf Analytics Ltd 59 Kensington Court London W8 5DG', 'Imperial College London', 'Western University']","['Canada', 'United Kingdom']",2023-09
2309.05951,Yan Jiang,"Yan Jiang, Ruihong Qiu, Yi Zhang, Peng-Fei Zhang",Balanced and Explainable Social Media Analysis for Public Health with Large Language Models,arXiv admin note: text overlap with arXiv:2309.04213,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As social media becomes increasingly popular, more and more public health activities emerge, which is worth noting for pandemic monitoring and government decision-making. Current techniques for public health analysis involve popular models such as BERT and large language models (LLMs). Although recent progress in LLMs has shown a strong ability to comprehend knowledge by being fine-tuned on specific domain datasets, the costs of training an in-domain LLM for every specific public health task are especially expensive. Furthermore, such kinds of in-domain datasets from social media are generally highly imbalanced, which will hinder the efficiency of LLMs tuning. To tackle these challenges, the data imbalance issue can be overcome by sophisticated data augmentation methods for social media datasets. In addition, the ability of the LLMs can be effectively utilised by prompting the model properly. In light of the above discussion, in this paper, a novel ALEX framework is proposed for social media analysis on public health. Specifically, an augmentation pipeline is developed to resolve the data imbalance issue. Furthermore, an LLMs explanation mechanism is proposed by prompting an LLM with the predicted results from BERT models. Extensive experiments conducted on three tasks at the Social Media Mining for Health 2023 (SMM4H) competition with the first ranking in two tasks demonstrate the superior performance of the proposed ALEX method. Our code has been released in https://github.com/YanJiangJerry/ALEX. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 04:15:34 GMT'}]",2023-09-13,"[['Jiang', 'Yan', ''], ['Qiu', 'Ruihong', ''], ['Zhang', 'Yi', ''], ['Zhang', 'Peng-Fei', '']]",0,0,2023-09-12,1,4,1,0,0,0,02838f3cd9c7bbb679968ba593699f920ef2f4fc,261696719.0,https://www.semanticscholar.org/paper/02838f3cd9c7bbb679968ba593699f920ef2f4fc,Australasian Database Conference,2023.0,46.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238993080', 'name': 'Yan Jiang'}, {'authorId': '2239102694', 'name': 'Ruihong Qiu'}, {'authorId': '39939149', 'name': 'Yi Zhang'}, {'authorId': '40075735', 'name': 'P. Zhang'}]",['University of Queensland'],['Australia'],2023-09
2309.05958,Kazuhiro Takemoto,Kazuhiro Takemoto,The Moral Machine Experiment on Large Language Models,"12 pages, 2 Figures",,,,cs.CL cs.CY cs.HC,http://creativecommons.org/licenses/by/4.0/,"  As large language models (LLMs) become more deeply integrated into various sectors, understanding how they make moral judgments has become crucial, particularly in the realm of autonomous driving. This study utilized the Moral Machine framework to investigate the ethical decision-making tendencies of prominent LLMs, including GPT-3.5, GPT-4, PaLM 2, and Llama 2, comparing their responses to human preferences. While LLMs' and humans' preferences such as prioritizing humans over pets and favoring saving more lives are broadly aligned, PaLM 2 and Llama 2, especially, evidence distinct deviations. Additionally, despite the qualitative similarities between the LLM and human preferences, there are significant quantitative disparities, suggesting that LLMs might lean toward more uncompromising decisions, compared to the milder inclinations of humans. These insights elucidate the ethical frameworks of LLMs and their potential implications for autonomous driving. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 04:49:39 GMT'}]",2023-09-13,"[['Takemoto', 'Kazuhiro', '']]",0,1,2023-09-12,1,1,3,4,1,3,429cda56b73b956ab032b551761a6c9308c13131,261696854.0,https://www.semanticscholar.org/paper/429cda56b73b956ab032b551761a6c9308c13131,arXiv.org,2023.0,24.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","[{'authorId': '2239102286', 'name': 'Kazuhiro Takemoto'}]",['Kyushu Institute of Technology'],['Japan'],2023-09
2309.06029,Roberto Cerina,Roberto Cerina and Raymond Duch,Artificially Intelligent Opinion Polling,,,,,stat.ME,http://creativecommons.org/licenses/by/4.0/,"  We seek to democratise public-opinion research by providing practitioners with a general methodology to make representative inference from cheap, high-frequency, highly unrepresentative samples. We focus specifically on samples which are readily available in moderate sizes. To this end, we provide two major contributions: 1) we introduce a general sample-selection process which we name online selection, and show it is a special-case of selection on the dependent variable. We improve MrP for severely biased samples by introducing a bias-correction term in the style of King and Zeng to the logistic-regression framework. We show this bias-corrected model outperforms traditional MrP under online selection, and achieves performance similar to random-sampling in a vast array of scenarios; 2) we present a protocol to use Large Language Models (LLMs) to extract structured, survey-like data from social-media. We provide a prompt-style that can be easily adapted to a variety of survey designs. We show that LLMs agree with human raters with respect to the demographic, socio-economic and political characteristics of these online users. The end-to-end implementation takes unrepresentative, unsrtuctured social media data as inputs, and produces timely high-quality area-level estimates as outputs. This is Artificially Intelligent Opinion Polling. We show that our AI polling estimates of the 2020 election are highly accurate, on-par with estimates produced by state-level polling aggregators such as FiveThirtyEight, or from MrP models fit to extremely expensive high-quality samples. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 08:03:02 GMT'}]",2023-09-13,"[['Cerina', 'Roberto', ''], ['Duch', 'Raymond', '']]",0,0,2023-09-12,1,2,1,0,0,0,e037a6a65f5ac25018c593bc23e14fb32e438304,261697094.0,https://www.semanticscholar.org/paper/e037a6a65f5ac25018c593bc23e14fb32e438304,,2023.0,88.0,0.0,0.0,False,['Mathematics'],"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '118597836', 'name': 'Roberto Cerina'}, {'authorId': '2239107143', 'name': 'Raymond Duch'}]","['University of Amsterdam', 'University of Oxford']","['United Kingdom', 'Netherlands']",2023-09
2309.06089,Boshko Koloski,"Boshko Koloski, Bla\v{z} \v{S}krlj, Marko Robnik-\v{S}ikonja, Senja
  Pollak",Measuring Catastrophic Forgetting in Cross-Lingual Transfer Paradigms: Exploring Tuning Strategies,,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  The cross-lingual transfer is a promising technique to solve tasks in less-resourced languages. In this empirical study, we compare two fine-tuning approaches combined with zero-shot and full-shot learning approaches for large language models in a cross-lingual setting. As fine-tuning strategies, we compare parameter-efficient adapter methods with fine-tuning of all parameters. As cross-lingual transfer strategies, we compare the intermediate-training (\textit{IT}) that uses each language sequentially and cross-lingual validation (\textit{CLV}) that uses a target language already in the validation phase of fine-tuning. We assess the success of transfer and the extent of catastrophic forgetting in a source language due to cross-lingual transfer, i.e., how much previously acquired knowledge is lost when we learn new information in a different language. The results on two different classification problems, hate speech detection and product reviews, each containing datasets in several languages, show that the \textit{IT} cross-lingual strategy outperforms \textit{CLV} for the target language. Our findings indicate that, in the majority of cases, the \textit{CLV} strategy demonstrates superior retention of knowledge in the base language (English) compared to the \textit{IT} strategy, when evaluating catastrophic forgetting in multiple cross-lingual transfers. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 09:37:08 GMT'}]",2023-09-13,"[['Koloski', 'Boshko', ''], ['Škrlj', 'Blaž', ''], ['Robnik-Šikonja', 'Marko', ''], ['Pollak', 'Senja', '']]",0,0,2023-09-12,1,4,2,0,0,0,8f4ae6552e49d229eaf374156f9197e980fa7df8,261696642.0,https://www.semanticscholar.org/paper/8f4ae6552e49d229eaf374156f9197e980fa7df8,arXiv.org,2023.0,49.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2003646352', 'name': 'Boshko Koloski'}, {'authorId': '7746943', 'name': 'Blaž Škrlj'}, {'authorId': '1399065078', 'name': 'M. Robnik-Sikonja'}, {'authorId': '1491181728', 'name': 'S. Pollak'}]","['Jožef Stefan International Postgraduate School', 'University of Ljubljana']",['Slovenia'],2023-09
2309.06112,Sharath Srivatsa,"Sharath Srivatsa, Srinath Srinivasa",Characterizing Latent Perspectives of Media Houses Towards Public Figures,,,,,cs.CL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Media houses reporting on public figures, often come with their own biases stemming from their respective worldviews. A characterization of these underlying patterns helps us in better understanding and interpreting news stories. For this, we need diverse or subjective summarizations, which may not be amenable for classifying into predefined class labels. This work proposes a zero-shot approach for non-extractive or generative characterizations of person entities from a corpus using GPT-2. We use well-articulated articles from several well-known news media houses as a corpus to build a sound argument for this approach. First, we fine-tune a GPT-2 pre-trained language model with a corpus where specific person entities are characterized. Second, we further fine-tune this with demonstrations of person entity characterizations, created from a corpus of programmatically constructed characterizations. This twice fine-tuned model is primed with manual prompts consisting of entity names that were not previously encountered in the second fine-tuning, to generate a simple sentence about the entity. The results were encouraging, when compared against actual characterizations from the corpus. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 10:27:39 GMT'}]",2023-09-13,"[['Srivatsa', 'Sharath', ''], ['Srinivasa', 'Srinath', '']]",0,1,2023-09-12,1,2,2,1,1,0,4b8b45a1ecc8a69ed2285629d47aaa1589387023,261696989.0,https://www.semanticscholar.org/paper/4b8b45a1ecc8a69ed2285629d47aaa1589387023,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1870621', 'name': 'S. Srivatsa'}, {'authorId': '144427922', 'name': 'S. Srinivasa'}]",['International Institute of Information Technology Bangalore'],['India'],2023-09
2309.06342,Changjie Wang,"Changjie Wang, Mariano Scazzariello, Alireza Farshin, Dejan Kostic and
  Marco Chiesa",Making Network Configuration Human Friendly,"6 pages,3 figures",,,,cs.NI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper explores opportunities to utilize Large Language Models (LLMs) to make network configuration human-friendly, simplifying the configuration of network devices and minimizing errors. We examine the effectiveness of these models in translating high-level policies and requirements (i.e., specified in natural language) into low-level network APIs, which requires understanding the hardware and protocols. More specifically, we propose NETBUDDY for generating network configurations from scratch and modifying them at runtime. NETBUDDY splits the generation of network configurations into fine-grained steps and relies on self-healing code-generation approaches to better take advantage of the full potential of LLMs. We first thoroughly examine the challenges of using these models to produce a fully functional & correct configuration, and then evaluate the feasibility of realizing NETBUDDY by building a proof-of-concept solution using GPT-4 to translate a set of high-level requirements into P4 and BGP configurations and run them using the Kathar\'a network emulator. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 16:02:07 GMT'}]",2023-09-13,"[['Wang', 'Changjie', ''], ['Scazzariello', 'Mariano', ''], ['Farshin', 'Alireza', ''], ['Kostic', 'Dejan', ''], ['Chiesa', 'Marco', '']]",0,1,2023-09-12,1,5,1,1,0,1,5ba398a4e64c688de82c5b8f26583d86269a3781,261696620.0,https://www.semanticscholar.org/paper/5ba398a4e64c688de82c5b8f26583d86269a3781,arXiv.org,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2239168925', 'name': 'Changjie Wang'}, {'authorId': '2239098972', 'name': 'Mariano Scazzariello'}, {'authorId': '9601220', 'name': 'Alireza Farshin'}, {'authorId': '144914281', 'name': 'Dejan Kostic'}, {'authorId': '2239100004', 'name': 'Marco Chiesa'}]",['RISE Research Institutes of Sweden'],['Sweden'],2023-09
2309.06364,Joel Leibo,"Aliya Amirova, Theodora Fteropoulli, Nafiso Ahmed, Martin R. Cowie,
  Joel Z. Leibo",Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity,"46 pages, 5 tables, 5 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Today, using Large-scale generative Language Models (LLMs) it is possible to simulate free responses to interview questions like those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial ""silicon participants"" generated by LLMs may be productively studied using qualitative methods aiming to produce insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a term introduced by Argyle et al. (2023) capturing the degree to which LLM-generated outputs mirror human sub-populations' beliefs and attitudes. By definition, high algorithmic fidelity suggests latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews with silicon participants matching specific demographic characteristics one-for-one with a set of human participants. Using framework-based qualitative analysis, we showed the key themes obtained from both human and silicon participants were strikingly similar. However, when we analyzed the structure and tone of the interviews we found even more striking differences. We also found evidence of the hyper-accuracy distortion described by Aher et al. (2023). We conclude that the LLM we tested (GPT-3.5) does not have sufficient algorithmic fidelity to expect research on it to generalize to human populations. However, the rapid pace of LLM research makes it plausible this could change in the future. Thus we stress the need to establish epistemic norms now around how to assess validity of LLM-based qualitative research, especially concerning the need to ensure representation of heterogeneous lived experiences. ","[{'version': 'v1', 'created': 'Wed, 6 Sep 2023 15:00:44 GMT'}]",2023-09-13,"[['Amirova', 'Aliya', ''], ['Fteropoulli', 'Theodora', ''], ['Ahmed', 'Nafiso', ''], ['Cowie', 'Martin R.', ''], ['Leibo', 'Joel Z.', '']]",0,1,2023-09-06,1,5,2,1,0,1,ba5aefce80edc7da110f53fd071f4fbd6b5195b9,261696822.0,https://www.semanticscholar.org/paper/ba5aefce80edc7da110f53fd071f4fbd6b5195b9,arXiv.org,2023.0,91.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '143869696', 'name': 'A. Amirova'}, {'authorId': '8318559', 'name': 'T. Fteropoulli'}, {'authorId': '2239105075', 'name': 'Nafiso Ahmed'}, {'authorId': '2237574510', 'name': 'Martin R. Cowie'}, {'authorId': '1700356', 'name': 'Joel Z. Leibo'}]","['University College London', ""King's College London"", 'Google', 'University of Cyprus', ""Population Health Sciences, School of Life Course & Population Sciences, Faculty of Life Sciences & Medicine, King's College London, UK"", 'Royal Brompton Hospital']","['United Kingdom', 'Cyprus']",2023-09
2309.06384,Dongyub Lee,"Dongyub Lee, Taesun Whang, Chanhee Lee, Heuiseok Lim",Towards Reliable and Fluent Large Language Models: Incorporating Feedback Learning Loops in QA Systems,"5 pages, Under Review",,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) have emerged as versatile tools in various daily applications. However, they are fraught with issues that undermine their utility and trustworthiness. These include the incorporation of erroneous references (citation), the generation of hallucinated information (correctness), and the inclusion of superfluous or omission of crucial details (fluency). To ameliorate these concerns, this study makes several key contributions. First, we build a dataset to train a critic model capable of evaluating the citation, correctness, and fluency of responses generated by LLMs in QA systems. Second, we propose an automated feedback mechanism that leverages the critic model to offer real-time feedback on heterogeneous aspects of generated text. Third, we introduce a feedback learning loop that uses this critic model to iteratively improve the performance of the LLM responsible for response generation. Experimental results demonstrate the efficacy of our approach, showing substantial improvements in citation and fluency metrics for ChatGPT, including a 4% precision increase in citation and an approximately 8% enhancement in the MAUVE metric for fluency, while maintaining high levels of correctness. ","[{'version': 'v1', 'created': 'Fri, 8 Sep 2023 09:39:53 GMT'}]",2023-09-13,"[['Lee', 'Dongyub', ''], ['Whang', 'Taesun', ''], ['Lee', 'Chanhee', ''], ['Lim', 'Heuiseok', '']]",1,1,2023-09-08,1,4,2,1,0,1,c90ea67a7b2f617e0cb199f511caad3c7dee1557,261696685.0,https://www.semanticscholar.org/paper/c90ea67a7b2f617e0cb199f511caad3c7dee1557,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51021762', 'name': 'Dongyub Lee'}, {'authorId': '89016637', 'name': 'Taesun Whang'}, {'authorId': '2807382', 'name': 'Chanhee Lee'}, {'authorId': '2239151880', 'name': 'Heuiseok Lim'}]","['NAVER', 'Korea University']",['South Korea'],2023-09
2309.06424,Palash Roy,"Palash R. Roy, Ajmain I. Alam, Farouq Al-omari, Banani Roy, Chanchal
  K. Roy, Kevin A. Schneider",Unveiling the potential of large language models in generating semantic and cross-language clones,Accepted in IWSC,,,,cs.SE cs.AI cs.LG,http://creativecommons.org/licenses/by-sa/4.0/,"  Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking. OpenAI's GPT model has potential in such clone generation as GPT is used for text generation. When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours. Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance. In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.We have comprised a diverse set of code fragments and assessed GPT-3s performance in generating code variants.Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate the model's ability to produce accurate and semantically correct variants. Our findings shed light on GPT-3's strengths in code generation, offering insights into the potential applications and challenges of using advanced language models in software development. Our quantitative analysis yields compelling results. In the realm of semantic clones, GPT-3 attains an impressive accuracy of 62.14% and 0.55 BLEU score, achieved through few-shot prompt engineering. Furthermore, the model shines in transcending linguistic confines, boasting an exceptional 91.25% accuracy in generating cross-language clones ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 17:40:49 GMT'}]",2023-09-13,"[['Roy', 'Palash R.', ''], ['Alam', 'Ajmain I.', ''], ['Al-omari', 'Farouq', ''], ['Roy', 'Banani', ''], ['Roy', 'Chanchal K.', ''], ['Schneider', 'Kevin A.', '']]",0,1,2023-09-12,1,6,3,1,0,1,073972fa0de48db1304509041e877e568c94e7de,261697388.0,https://www.semanticscholar.org/paper/073972fa0de48db1304509041e877e568c94e7de,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2239108495', 'name': 'Palash R. Roy'}, {'authorId': '70645384', 'name': 'A. Alam'}, {'authorId': '67187029', 'name': 'Farouq Al-Omari'}, {'authorId': '50666808', 'name': 'B. Roy'}, {'authorId': '1738612', 'name': 'C. Roy'}, {'authorId': '2239095572', 'name': 'Kevin A. Schneider'}]",['University of Saskatchewan'],['Canada'],2023-09
2309.06553,Hao Sun,"Hao Sun, Alihan H\""uy\""uk, Mihaela van der Schaar",Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this study, we aim to enhance the arithmetic reasoning ability of Large Language Models (LLMs) through zero-shot prompt optimization. We identify a previously overlooked objective of query dependency in such optimization and elucidate two ensuing challenges that impede the successful and economical design of prompt optimization techniques. One primary issue is the absence of an effective method to evaluate prompts during inference when the golden answer is unavailable. Concurrently, learning via interactions with the LLMs to navigate the expansive natural language prompting space proves to be resource-intensive. To address this, we introduce Prompt-OIRL, which harnesses offline inverse reinforcement learning to draw insights from offline prompting demonstration data. Such data exists as by-products when diverse prompts are benchmarked on open-accessible datasets. With Prompt-OIRL, the query-dependent prompt optimization objective is achieved by first learning an offline reward model. This model can evaluate any query-prompt pairs without accessing LLMs. Subsequently, a best-of-N strategy is deployed to recommend the optimal prompt. Our experimental evaluations across various LLM scales and arithmetic reasoning datasets underscore both the efficacy and economic viability of the proposed approach. ","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 01:12:52 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Sep 2023 12:45:18 GMT'}]",2023-10-02,"[['Sun', 'Hao', ''], ['Hüyük', 'Alihan', ''], ['van der Schaar', 'Mihaela', '']]",0,0,2023-09-13,2,3,3,0,0,0,0ad677b4172e5aef8b18bc6832145d1a03e11da4,263882822.0,https://www.semanticscholar.org/paper/0ad677b4172e5aef8b18bc6832145d1a03e11da4,arXiv.org,2023.0,104.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2257404641', 'name': 'Hao Sun'}, {'authorId': '83246796', 'name': 'Alihan Hüyük'}, {'authorId': '1729969', 'name': 'M. Schaar'}]",['University of Cambridge'],['United Kingdom'],2023-09
2309.06706,Minghan Wang,"Minghan Wang, Jinming Zhao, Thuy-Trang Vu, Fatemeh Shiri, Ehsan
  Shareghi, Gholamreza Haffari",Simultaneous Machine Translation with Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLM) have demonstrated their abilities to solve various natural language processing tasks through dialogue-based interactions. For instance, research indicates that LLMs can achieve competitive performance in offline machine translation tasks for high-resource languages. However, applying LLMs to simultaneous machine translation (SimulMT) poses many challenges, including issues related to the training-inference mismatch arising from different decoding patterns. In this paper, we explore the feasibility of utilizing LLMs for SimulMT. Building upon conventional approaches, we introduce a simple yet effective mixture policy that enables LLMs to engage in SimulMT without requiring additional training. Furthermore, after Supervised Fine-Tuning (SFT) on a mixture of full and prefix sentences, the model exhibits significant performance improvements. Our experiments, conducted with Llama2-7B-chat on nine language pairs from the MUST-C dataset, demonstrate that LLM can achieve translation quality and latency comparable to dedicated SimulMT models. ","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 04:06:47 GMT'}]",2023-09-14,"[['Wang', 'Minghan', ''], ['Zhao', 'Jinming', ''], ['Vu', 'Thuy-Trang', ''], ['Shiri', 'Fatemeh', ''], ['Shareghi', 'Ehsan', ''], ['Haffari', 'Gholamreza', '']]",0,0,2023-09-13,1,6,1,0,0,0,53174067c1b037f6ba5343806b580a2bf35ccda9,261705915.0,https://www.semanticscholar.org/paper/53174067c1b037f6ba5343806b580a2bf35ccda9,arXiv.org,2023.0,17.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2239243837', 'name': 'Minghan Wang'}, {'authorId': '2256929426', 'name': 'Jinming Zhao'}, {'authorId': '122699890', 'name': 'Thuy-Trang Vu'}, {'authorId': '49994056', 'name': 'Fatemeh Shiri'}, {'authorId': '2888926', 'name': 'Ehsan Shareghi'}, {'authorId': '2561045', 'name': 'Gholamreza Haffari'}]",['Monash University'],['Australia'],2023-09
2309.06759,Ting Hu,"Ting Hu, Christoph Meinel, Haojin Yang",Scaled Prompt-Tuning for Few-Shot Natural Language Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The increasingly Large Language Models (LLMs) demonstrate stronger language understanding and generation capabilities, while the memory demand and computation cost of fine-tuning LLMs on downstream tasks are non-negligible. Besides, fine-tuning generally requires a certain amount of data from individual tasks whilst data collection cost is another issue to consider in real-world applications. In this work, we focus on Parameter-Efficient Fine-Tuning (PEFT) methods for few-shot Natural Language Generation (NLG), which freeze most parameters in LLMs and tune a small subset of parameters in few-shot cases so that memory footprint, training cost, and labeling cost are reduced while maintaining or even improving the performance. We propose a Scaled Prompt-Tuning (SPT) method which surpasses conventional PT with better performance and generalization ability but without an obvious increase in training cost. Further study on intermediate SPT suggests the superior transferability of SPT in few-shot scenarios, providing a recipe for data-deficient and computation-limited circumstances. Moreover, a comprehensive comparison of existing PEFT methods reveals that certain approaches exhibiting decent performance with modest training cost such as Prefix-Tuning in prior study could struggle in few-shot NLG tasks, especially on challenging datasets. ","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 07:12:31 GMT'}]",2023-09-14,"[['Hu', 'Ting', ''], ['Meinel', 'Christoph', ''], ['Yang', 'Haojin', '']]",0,0,2023-09-13,1,3,1,0,0,0,ed4cfe818d18092b3fe0ca3c43de28728e2f0d2e,261705827.0,https://www.semanticscholar.org/paper/ed4cfe818d18092b3fe0ca3c43de28728e2f0d2e,arXiv.org,2023.0,22.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1811091645', 'name': 'Ting Hu'}, {'authorId': '2239199657', 'name': 'Christoph Meinel'}, {'authorId': '1688587', 'name': 'Haojin Yang'}]",['Hasso Plattner Institute'],['Germany'],2023-09
2309.07009,Konstantinos Kogkalidis,"Konstantinos Kogkalidis, Stergios Chatzikyriakidis, Eirini
  Chrysovalantou Giannikouri, Vassiliki Katsouli, Christina Klironomou,
  Christina Koula, Dimitris Papadakis, Thelka Pasparaki, Erofili Psaltaki,
  Efthymia Sakellariou, Hara Soupiona",OYXOY: A Modern NLP Test Suite for Modern Greek,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  This paper serves as a foundational step towards the development of a linguistically motivated and technically relevant evaluation suite for Greek NLP. We initiate this endeavor by introducing four expert-verified evaluation tasks, specifically targeted at natural language inference, word sense disambiguation (through example comparison or sense selection) and metaphor detection. More than language-adapted replicas of existing tasks, we contribute two innovations which will resonate with the broader resource and evaluation community. Firstly, our inference dataset is the first of its kind, marking not just \textit{one}, but rather \textit{all} possible inference labels, accounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages. Using ChatGPT as a language-neutral parser, we transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other three tasks through simple projections. Alongside each task, we conduct experiments using currently available state of the art machinery. Our experimental baselines affirm the challenging nature of our tasks and highlight the need for expedited progress in order for the Greek NLP ecosystem to keep pace with contemporary mainstream research. ","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 15:00:56 GMT'}]",2023-09-14,"[['Kogkalidis', 'Konstantinos', ''], ['Chatzikyriakidis', 'Stergios', ''], ['Giannikouri', 'Eirini Chrysovalantou', ''], ['Katsouli', 'Vassiliki', ''], ['Klironomou', 'Christina', ''], ['Koula', 'Christina', ''], ['Papadakis', 'Dimitris', ''], ['Pasparaki', 'Thelka', ''], ['Psaltaki', 'Erofili', ''], ['Sakellariou', 'Efthymia', ''], ['Soupiona', 'Hara', '']]",1,1,2023-09-13,1,11,1,1,0,1,808c0bc633e8a49ef447fe13ed7cf4e0460d9be4,261705664.0,https://www.semanticscholar.org/paper/808c0bc633e8a49ef447fe13ed7cf4e0460d9be4,arXiv.org,2023.0,39.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2239196158', 'name': 'Konstantinos Kogkalidis'}, {'authorId': '2136336', 'name': 'S. Chatzikyriakidis'}, {'authorId': '2186551805', 'name': 'Eirini Chrysovalantou Giannikouri'}, {'authorId': '2239196444', 'name': 'Vassiliki Katsouli'}, {'authorId': '2239196087', 'name': 'Christina Klironomou'}, {'authorId': '2226456358', 'name': 'Christina Koula'}, {'authorId': '2226454576', 'name': 'Dimitris Papadakis'}, {'authorId': '2239197022', 'name': 'Thelka Pasparaki'}, {'authorId': '2186551795', 'name': 'Erofili Psaltaki'}, {'authorId': '2140366055', 'name': 'E. Sakellariou'}, {'authorId': '2239197366', 'name': 'Hara Soupiona'}]","['Aalto University', 'University of Crete']","['Greece', 'Finland']",2023-09
2309.07098,Rico Sennrich,Rico Sennrich and Jannis Vamvas and Alireza Mohammadshahi,Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Hallucinations and off-target translation remain unsolved problems in machine translation, especially for low-resource languages and massively multilingual models. In this paper, we introduce methods to mitigate both failure cases with a modified decoding objective, without requiring retraining or external models. In source-contrastive decoding, we search for a translation that is probable given the correct input, but improbable given a random input segment, hypothesising that hallucinations will be similarly probable given either. In language-contrastive decoding, we search for a translation that is probable, but improbable given the wrong language indicator token. In experiments on M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4 points on average across 57 tested translation directions. In a proof of concept on English--German, we also show that we can suppress off-target translations with the Llama 2 chat models, demonstrating the applicability of the method to machine translation with LLMs. We release our source code at https://github.com/ZurichNLP/ContraDecode. ","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 17:15:27 GMT'}]",2023-09-14,"[['Sennrich', 'Rico', ''], ['Vamvas', 'Jannis', ''], ['Mohammadshahi', 'Alireza', '']]",0,0,2023-09-13,1,3,1,1,1,0,84078a137029d70e8b51041354cd931d1196806d,261705560.0,https://www.semanticscholar.org/paper/84078a137029d70e8b51041354cd931d1196806d,arXiv.org,2023.0,42.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2082372', 'name': 'Rico Sennrich'}, {'authorId': '1568852178', 'name': 'Jannis Vamvas'}, {'authorId': '2239195841', 'name': 'Alireza Mohammadshahi'}]","['École Polytechnique Fédérale de Lausanne', 'University of Zurich']",['Switzerland'],2023-09
2309.07161,Suthee Ruangwises,Suthee Ruangwises,"Sumplete is Hard, Even with Two Different Numbers",,,,,cs.DS cs.CC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Sumplete is a logic puzzle famous for being developed by ChatGPT. The puzzle consists of a rectangular grid, with each cell containing a number. The player has to cross out some numbers such that the sum of uncrossed numbers in each row and column is equal to a given integer assigned to that row or column. In this paper, we prove that deciding a solvability of a given Sumplete puzzle is NP-complete, even if the grid contains only two different numbers. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 10:54:09 GMT'}, {'version': 'v2', 'created': 'Fri, 15 Sep 2023 17:06:06 GMT'}]",2023-09-18,"[['Ruangwises', 'Suthee', '']]",1,1,2023-09-11,2,1,2,1,0,1,719b736fce6c34ba43909c3b5c2c0c00c433b2ed,261823334.0,https://www.semanticscholar.org/paper/719b736fce6c34ba43909c3b5c2c0c00c433b2ed,arXiv.org,2023.0,3.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","[{'authorId': '1878884', 'name': 'Suthee Ruangwises'}]",['University of Electro-Communications'],['Japan'],2023-09
2309.07172,Yuan He,"Yuan He, Jiaoyan Chen, Hang Dong, Ian Horrocks",Exploring Large Language Models for Ontology Alignment,Accepted at ISWC 2023 (Posters and Demos),,,,cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This work investigates the applicability of recent generative Large Language Models (LLMs), such as the GPT series and Flan-T5, to ontology alignment for identifying concept equivalence mappings across ontologies. To test the zero-shot performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging subsets from two equivalence matching datasets of the OAEI Bio-ML track, taking into account concept labels and structural contexts. Preliminary findings suggest that LLMs have the potential to outperform existing ontology alignment systems like BERTMap, given careful framework and prompt design. ","[{'version': 'v1', 'created': 'Tue, 12 Sep 2023 17:01:02 GMT'}]",2023-09-15,"[['He', 'Yuan', ''], ['Chen', 'Jiaoyan', ''], ['Dong', 'Hang', ''], ['Horrocks', 'Ian', '']]",0,1,2023-09-12,1,4,3,4,2,2,0e173e52710cd05f6482808d084c16f6818d9f48,261824419.0,https://www.semanticscholar.org/paper/0e173e52710cd05f6482808d084c16f6818d9f48,arXiv.org,2023.0,6.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46968114', 'name': 'Yuan He'}, {'authorId': '2240684541', 'name': 'Jiaoyan Chen'}, {'authorId': '145153805', 'name': 'Hang Dong'}, {'authorId': '145655431', 'name': 'Ian Horrocks'}]","['University of Manchester', 'University of Oxford']",['United Kingdom'],2023-09
2309.07251,Daisuke Oba,"Daisuke Oba, Masahiro Kaneko, Danushka Bollegala",In-Contextual Bias Suppression for Large Language Models,13 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Despite their impressive performance in a wide range of NLP tasks, Large Language Models (LLMs) have been reported to encode worrying-levels of gender bias. Prior work has proposed debiasing methods that require human labelled examples, data augmentation and fine-tuning of the LLMs, which are computationally costly. Moreover, one might not even have access to the internal parameters for performing debiasing such as in the case of commercially available LLMs such as GPT-4. To address this challenge we propose bias suppression, a novel alternative to debiasing that does not require access to model parameters. We show that text-based preambles, generated from manually designed templates covering counterfactual statements, can accurately suppress gender biases in LLMs. Moreover, we find that descriptive sentences for occupations can further suppress gender biases. Interestingly, we find that bias suppression has a minimal adverse effect on downstream task performance, while effectively mitigating the gender biases. ","[{'version': 'v1', 'created': 'Wed, 13 Sep 2023 18:39:08 GMT'}]",2023-09-15,"[['Oba', 'Daisuke', ''], ['Kaneko', 'Masahiro', ''], ['Bollegala', 'Danushka', '']]",0,1,2023-09-13,1,3,1,1,0,1,eb345260f39695811509bd9ae0d244b390eeae8a,261822519.0,https://www.semanticscholar.org/paper/eb345260f39695811509bd9ae0d244b390eeae8a,arXiv.org,2023.0,69.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2240524903', 'name': 'Daisuke Oba'}, {'authorId': '143655216', 'name': 'Masahiro Kaneko'}, {'authorId': '2075356592', 'name': 'D. Bollegala'}]","['University of Liverpool', 'Mohamed bin Zayed University of Artificial Intelligence', 'The University of Tokyo']","['Japan', 'United Kingdom', 'United Arab Emirates']",2023-09
2309.07545,Debayan Banerjee,"Debayan Banerjee, Arefa, Ricardo Usbeck and Chris Biemann",DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph,"Accepted at International Semantic Web Conference (ISWC) 2023 Posters
  & Demo Track",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this work, we present a web application named DBLPLink, which performs entity linking over the DBLP scholarly knowledge graph. DBLPLink uses text-to-text pre-trained language models, such as T5, to produce entity label spans from an input text question. Entity candidates are fetched from a database based on the labels, and an entity re-ranker sorts them based on entity embeddings, such as TransE, DistMult and ComplEx. The results are displayed so that users may compare and contrast the results between T5-small, T5-base and the different KG embeddings used. The demo can be accessed at https://ltdemos.informatik.uni-hamburg.de/dblplink/. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 09:15:36 GMT'}, {'version': 'v2', 'created': 'Mon, 25 Sep 2023 08:44:19 GMT'}]",2023-09-26,"[['Banerjee', 'Debayan', ''], ['Arefa', '', ''], ['Usbeck', 'Ricardo', ''], ['Biemann', 'Chris', '']]",0,0,2023-09-14,2,4,1,1,1,0,6e4ff438f6101d57a71ca5dd6c58fa14bf20e2f8,261823385.0,https://www.semanticscholar.org/paper/6e4ff438f6101d57a71ca5dd6c58fa14bf20e2f8,arXiv.org,2023.0,12.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '35635012', 'name': 'Debayan Banerjee'}, {'authorId': '2240537408', 'name': 'Arefa'}, {'authorId': '2370666', 'name': 'Ricardo Usbeck'}, {'authorId': '31565315', 'name': 'Chris Biemann'}]","['Jamia Millia Islamia', 'Universität Hamburg']","['Germany', 'India']",2023-09
2309.07601,Jo\~ao Leite,"Jo\~ao A. Leite, Olesya Razuvayevskaya, Kalina Bontcheva, Carolina
  Scarton",Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Credibility signals represent a wide range of heuristics that are typically used by journalists and fact-checkers to assess the veracity of online content. Automating the task of credibility signal extraction, however, is very challenging as it requires high-accuracy signal-specific extractors to be trained, while there are currently no sufficiently large datasets annotated with all credibility signals. This paper investigates whether large language models (LLMs) can be prompted effectively with a set of 18 credibility signals to produce weak labels for each signal. We then aggregate these potentially noisy labels using weak supervision in order to predict content veracity. We demonstrate that our approach, which combines zero-shot LLM credibility signal labeling and weak supervision, outperforms state-of-the-art classifiers on two misinformation datasets without using any ground-truth labels for training. We also analyse the contribution of the individual credibility signals towards predicting content veracity, which provides new valuable insights into their role in misinformation detection. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 11:06:51 GMT'}]",2023-09-15,"[['Leite', 'João A.', ''], ['Razuvayevskaya', 'Olesya', ''], ['Bontcheva', 'Kalina', ''], ['Scarton', 'Carolina', '']]",0,0,2023-09-14,1,4,3,0,0,0,4c91353654b9cca00b1b595e010a1059fc9406e4,261823489.0,https://www.semanticscholar.org/paper/4c91353654b9cca00b1b595e010a1059fc9406e4,arXiv.org,2023.0,65.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '80218924', 'name': 'João A. Leite'}, {'authorId': '22534429', 'name': 'Olesya Razuvayevskaya'}, {'authorId': '1785423162', 'name': 'Kalina Bontcheva'}, {'authorId': '2064492081', 'name': 'Carolina Scarton'}]",['University of Sheffield'],['United Kingdom'],2023-09
2309.07606,Mengjie Qian,"Mengjie Qian, Rao Ma, Adian Liusie, Erfan Loweimi, Kate M. Knill, Mark
  J.F. Gales",Zero-shot Audio Topic Reranking using Large Language Models,,,,,cs.CL cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The Multimodal Video Search by Examples (MVSE) project investigates using video clips as the query term for information retrieval, rather than the more traditional text query. This enables far richer search modalities such as images, speaker, content, topic, and emotion. A key element for this process is highly rapid, flexible, search to support large archives, which in MVSE is facilitated by representing video attributes by embeddings. This work aims to mitigate any performance loss from this rapid archive search by examining reranking approaches. In particular, zero-shot reranking methods using large language models are investigated as these are applicable to any video archive audio content. Performance is evaluated for topic-based retrieval on a publicly available video archive, the BBC Rewind corpus. Results demonstrate that reranking can achieve improved retrieval ranking without the need for any task-specific training data. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 11:13:36 GMT'}]",2023-09-15,"[['Qian', 'Mengjie', ''], ['Ma', 'Rao', ''], ['Liusie', 'Adian', ''], ['Loweimi', 'Erfan', ''], ['Knill', 'Kate M.', ''], ['Gales', 'Mark J. F.', '']]",0,0,2023-09-14,1,6,2,0,0,0,9c8f579c61ae6d16dcaa4e9259f69b90872ad665,261822655.0,https://www.semanticscholar.org/paper/9c8f579c61ae6d16dcaa4e9259f69b90872ad665,arXiv.org,2023.0,21.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '10769548', 'name': 'Mengjie Qian'}, {'authorId': '50397234', 'name': 'Rao Ma'}, {'authorId': '2190750613', 'name': 'Adian Liusie'}, {'authorId': '2791396', 'name': 'Erfan Loweimi'}, {'authorId': '145962472', 'name': 'K. Knill'}, {'authorId': '1740397', 'name': 'M. Gales'}]",['University of Cambridge'],['United Kingdom'],2023-09
2309.07623,Xinyu Wang,"Xinyu Wang, Bohan Zhuang, Qi Wu",SwitchGPT: Adapting Large Language Models for Non-Text Outputs,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs), primarily trained on text-based datasets, exhibit exceptional proficiencies in understanding and executing complex linguistic instructions via text outputs. However, they falter when requests to generate non-text ones. Concurrently, modality conversion models, such as text-to-image, despite generating high-quality images, suffer from a lack of extensive textual pretraining. As a result, these models are only capable of accommodating specific image descriptions rather than comprehending more complex instructions. To bridge this gap, we propose a novel approach, \methodname, from a modality conversion perspective that evolves a text-based LLM into a multi-modal one. We specifically employ a minimal dataset to instruct LLMs to recognize the intended output modality as directed by the instructions. Consequently, the adapted LLM can effectively summon various off-the-shelf modality conversion models from the model zoos to generate non-text responses. This circumvents the necessity for complicated pretraining that typically requires immense quantities of paired multi-modal data, while simultaneously inheriting the extensive knowledge of LLMs and the ability of high-quality generative models. To evaluate and compare the adapted multi-modal LLM with its traditional counterparts, we have constructed a multi-modal instruction benchmark that solicits diverse modality outputs. The experiment results reveal that, with minimal training, LLMs can be conveniently adapted to comprehend requests for non-text responses, thus achieving higher flexibility in multi-modal scenarios. Code and data will be made available at https://github.com/xinke-wang/SwitchGPT. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 11:38:23 GMT'}]",2023-09-15,"[['Wang', 'Xinyu', ''], ['Zhuang', 'Bohan', ''], ['Wu', 'Qi', '']]",0,1,2023-09-14,1,3,1,0,0,0,366564d210768814bc880e391b909cfbd95f8964,261822601.0,https://www.semanticscholar.org/paper/366564d210768814bc880e391b909cfbd95f8964,arXiv.org,2023.0,52.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2240543227', 'name': 'Xinyu Wang'}, {'authorId': '3194022', 'name': 'Bohan Zhuang'}, {'authorId': '2240758455', 'name': 'Qi Wu'}]","['Monash University', 'University of Adelaide']",['Australia'],2023-09
2309.07664,Louis Lippens,Louis Lippens,Computer says 'no': Exploring systemic hiring bias in ChatGPT using an audit approach,"35 pages, 2 tables, 4 figures; for data and supplementary tables, see
  https://osf.io/vezt7/?view_only=0fb1f53c502a4c7091f3003d972f93b3",,,,econ.GN q-fin.EC,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Large language models offer significant potential for optimising professional activities, such as streamlining personnel selection procedures. However, concerns exist about these models perpetuating systemic biases embedded into their pre-training data. This study explores whether ChatGPT, a chatbot producing human-like responses to language tasks, displays ethnic or gender bias in job applicant screening. Using a correspondence audit approach, I simulated a CV screening task in which I instructed the chatbot to rate fictitious applicant profiles only differing in names, signalling ethnic and gender identity. Comparing ratings of Arab, Asian, Black American, Central African, Dutch, Eastern European, Hispanic, Turkish, and White American male and female applicants, I show that ethnic and gender identity influence ChatGPT's evaluations. The ethnic bias appears to arise partly from the prompts' language and partly from ethnic identity cues in applicants' names. Although ChatGPT produces no overall gender bias, I find some evidence for a gender-ethnicity interaction effect. These findings underscore the importance of addressing systemic bias in language model-driven applications to ensure equitable treatment across demographic groups. Practitioners aspiring to adopt these tools should practice caution, given the adverse impact they can produce, especially when using them for selection decisions involving humans. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 12:28:55 GMT'}]",2023-09-15,"[['Lippens', 'Louis', '']]",1,1,2023-09-14,1,1,2,1,0,1,cdaf024bd11f5754157bfcd28a5a3c3146c360af,261822574.0,https://www.semanticscholar.org/paper/cdaf024bd11f5754157bfcd28a5a3c3146c360af,,2023.0,73.0,0.0,0.0,False,['Economics'],"[{'category': 'Economics', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2240525978', 'name': 'Louis Lippens'}]",['Ghent University'],['Belgium'],2023-09
2309.07689,Mahdi Dhaini,"Mahdi Dhaini, Wessel Poelman, Ege Erdogan",Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text,"Published in the Proceedings of the Student Research Workshop
  associated with RANLP-2023",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  While recent advancements in the capabilities and widespread accessibility of generative language models, such as ChatGPT (OpenAI, 2022), have brought about various benefits by generating fluent human-like text, the task of distinguishing between human- and large language model (LLM) generated text has emerged as a crucial problem. These models can potentially deceive by generating artificial text that appears to be human-generated. This issue is particularly significant in domains such as law, education, and science, where ensuring the integrity of text is of the utmost importance. This survey provides an overview of the current approaches employed to differentiate between texts generated by humans and ChatGPT. We present an account of the different datasets constructed for detecting ChatGPT-generated text, the various methods utilized, what qualitative analyses into the characteristics of human versus ChatGPT-generated text have been performed, and finally, summarize our findings into general insights ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 13:05:20 GMT'}]",2023-09-15,"[['Dhaini', 'Mahdi', ''], ['Poelman', 'Wessel', ''], ['Erdogan', 'Ege', '']]",1,1,2023-09-14,1,3,2,1,0,1,0beed2f59894d291990ce7ef94bfcc0293c5c4f1,261822277.0,https://www.semanticscholar.org/paper/0beed2f59894d291990ce7ef94bfcc0293c5c4f1,Recent Advances in Natural Language Processing,2023.0,58.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2240530810', 'name': 'Mahdi Dhaini'}, {'authorId': '2175481435', 'name': 'Wessel Poelman'}, {'authorId': '2240530396', 'name': 'Ege Erdogan'}]",['Technical University of Munich'],['Germany'],2023-09
2309.07822,Rachneet Sachdeva,"Rachneet Sachdeva, Martin Tutek, Iryna Gurevych",CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration,We make our code available at: https://github.com/UKPLab/CATfOOD,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  In recent years, large language models (LLMs) have shown remarkable capabilities at scale, particularly at generating text conditioned on a prompt. In our work, we investigate the use of LLMs to augment training data of small language models~(SLMs) with automatically generated counterfactual~(CF) instances -- i.e. minimally altered inputs -- in order to improve out-of-domain~(OOD) performance of SLMs in the extractive question answering~(QA) setup. We show that, across various LLM generators, such data augmentation consistently enhances OOD performance and improves model calibration for both confidence-based and rationale-augmented calibrator models. Furthermore, these performance improvements correlate with higher diversity of CF instances in terms of their surface form and semantic content. Finally, we show that CF augmented models which are easier to calibrate also exhibit much lower entropy when assigning importance, indicating that rationale-augmented calibrators prefer concise explanations. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 16:16:40 GMT'}, {'version': 'v2', 'created': 'Fri, 15 Sep 2023 07:57:55 GMT'}]",2023-09-18,"[['Sachdeva', 'Rachneet', ''], ['Tutek', 'Martin', ''], ['Gurevych', 'Iryna', '']]",0,0,2023-09-14,2,3,1,0,0,0,06c8f8aa5d9fc02ea8ba35010e5b1e8420014c62,261823125.0,https://www.semanticscholar.org/paper/06c8f8aa5d9fc02ea8ba35010e5b1e8420014c62,arXiv.org,2023.0,73.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1490892639', 'name': 'Rachneet Sachdeva'}, {'authorId': '3466460', 'name': 'Martin Tutek'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}]",['Technical University of Darmstadt'],['Germany'],2023-09
2309.07917,Andrea Amaduzzi,"Andrea Amaduzzi, Giuseppe Lisanti, Samuele Salti, Luigi Di Stefano",Looking at words and points with attention: a benchmark for text-to-shape coherence,"ICCV 2023 Workshop ""AI for 3D Content Creation"", Project page:
  https://cvlab-unibo.github.io/CrossCoherence-Web/, 26 pages",,,,cs.CV,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  While text-conditional 3D object generation and manipulation have seen rapid progress, the evaluation of coherence between generated 3D shapes and input textual descriptions lacks a clear benchmark. The reason is twofold: a) the low quality of the textual descriptions in the only publicly available dataset of text-shape pairs; b) the limited effectiveness of the metrics used to quantitatively assess such coherence. In this paper, we propose a comprehensive solution that addresses both weaknesses. Firstly, we employ large language models to automatically refine textual descriptions associated with shapes. Secondly, we propose a quantitative metric to assess text-to-shape coherence, through cross-attention mechanisms. To validate our approach, we conduct a user study and compare quantitatively our metric with existing ones. The refined dataset, the new metric and a set of text-shape pairs validated by the user study comprise a novel, fine-grained benchmark that we publicly release to foster research on text-to-shape coherence of text-conditioned 3D generative models. Benchmark available at https://cvlab-unibo.github.io/CrossCoherence-Web/. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 17:59:48 GMT'}]",2023-09-15,"[['Amaduzzi', 'Andrea', ''], ['Lisanti', 'Giuseppe', ''], ['Salti', 'Samuele', ''], ['Di Stefano', 'Luigi', '']]",0,0,2023-09-14,1,4,1,0,0,0,dc6db5fb7188fedce99ebcdbc43cbb194bac9cad,261822315.0,https://www.semanticscholar.org/paper/dc6db5fb7188fedce99ebcdbc43cbb194bac9cad,arXiv.org,2023.0,45.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2240529031', 'name': 'Andrea Amaduzzi'}, {'authorId': '2240529123', 'name': 'Giuseppe Lisanti'}, {'authorId': '2607607', 'name': 'Samuele Salti'}, {'authorId': '2213727247', 'name': 'Luigi Di Stefano'}]","['CVLAB, Department of Computer Science and Engineering (DISI)', 'University of Bologna']",['Italy'],2023-09
2309.08047,Julius Steen,"Julius Steen, Katja Markert",Investigating Gender Bias in News Summarization,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Summarization is an important application of large language models (LLMs). Most previous evaluation of summarization models has focused on their performance in content selection, grammaticality and coherence. However, it is well known that LLMs reproduce and reinforce harmful social biases. This raises the question: Do these biases affect model outputs in a relatively constrained setting like summarization?   To help answer this question, we first motivate and introduce a number of definitions for biased behaviours in summarization models, along with practical measures to quantify them. Since we find biases inherent to the input document can confound our analysis, we additionally propose a method to generate input documents with carefully controlled demographic attributes. This allows us to sidestep this issue, while still working with somewhat realistic input documents.   Finally, we apply our measures to summaries generated by both purpose-built summarization models and general purpose chat models. We find that content selection in single document summarization seems to be largely unaffected by bias, while hallucinations exhibit evidence of biases propagating to generated summaries. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 22:20:27 GMT'}]",2023-09-18,"[['Steen', 'Julius', ''], ['Markert', 'Katja', '']]",0,0,2023-09-14,1,2,1,0,0,0,17f106df47f82fe494aa25f0d88c44754bd18259,262013727.0,https://www.semanticscholar.org/paper/17f106df47f82fe494aa25f0d88c44754bd18259,arXiv.org,2023.0,43.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '40402751', 'name': 'Julius Steen'}, {'authorId': '2243011466', 'name': 'Katja Markert'}]",['Heidelberg University'],['Germany'],2023-09
2309.08181,Michael Stewart,"Michael Stewart, Melinda Hodkiewicz, and Sirui Li",Large Language Models for Failure Mode Classification: An Investigation,"8 pages, 3 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this paper we present the first investigation into the effectiveness of Large Language Models (LLMs) for Failure Mode Classification (FMC). FMC, the task of automatically labelling an observation with a corresponding failure mode code, is a critical task in the maintenance domain as it reduces the need for reliability engineers to spend their time manually analysing work orders. We detail our approach to prompt engineering to enable an LLM to predict the failure mode of a given observation using a restricted code list. We demonstrate that the performance of a GPT-3.5 model (F1=0.80) fine-tuned on annotated data is a significant improvement over a currently available text classification model (F1=0.60) trained on the same annotated data set. The fine-tuned model also outperforms the out-of-the box GPT-3.5 (F1=0.46). This investigation reinforces the need for high quality fine-tuning data sets for domain-specific tasks using LLMs. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 06:13:01 GMT'}]",2023-09-18,"[['Stewart', 'Michael', ''], ['Hodkiewicz', 'Melinda', ''], ['Li', 'Sirui', '']]",0,1,2023-09-15,1,3,1,1,0,1,cf9318ab2b86926d5435d73b715e71e8ffc5f769,261875794.0,https://www.semanticscholar.org/paper/cf9318ab2b86926d5435d73b715e71e8ffc5f769,arXiv.org,2023.0,18.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2241216384', 'name': 'Michael Stewart'}, {'authorId': '2241216354', 'name': 'Melinda Hodkiewicz'}, {'authorId': '2241219460', 'name': 'Sirui Li'}]",['University of Western Australia'],['Australia'],2023-09
2309.08473,Massimo Bonavita,Massimo Bonavita,On the limitations of data-driven weather forecasting models,,,,,stat.ML cs.LG physics.ao-ph,http://creativecommons.org/licenses/by/4.0/,"  As in many other areas of engineering and applied science, Machine Learning (ML) is having a profound impact in the domain of Weather and Climate Prediction. A very recent development in this area has been the emergence of fully data-driven ML prediction models which routinely claim superior performance to that of traditional physics-based models. In this work, we examine some aspects of the forecasts produced by an exemplar of the current generation of ML models, Pangu-Weather, with a focus on the fidelity and physical consistency of those forecasts and how these characteristics relate to perceived forecast performance. The main conclusion is that Pangu-Weather forecasts, and by extension those of similar ML models, do not have the fidelity and physical consistency of physics-based models and their advantage in accuracy on traditional deterministic metrics of forecast skill can be attributed, to a large extent, to these peculiarities. Similarly to other current post-processing technologies, ML models appear to be able to add value to standard NWP outputs for specific forecast applications and combined with their extremely low computational cost during deployment, will likely provide an additional, useful source of forecast information. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 15:21:57 GMT'}]",2023-09-18,"[['Bonavita', 'Massimo', '']]",0,0,2023-09-15,1,1,3,0,0,0,744673e2d8de075584cff1dedb78b3ac49bfb1ed,262013237.0,https://www.semanticscholar.org/paper/744673e2d8de075584cff1dedb78b3ac49bfb1ed,arXiv.org,2023.0,26.0,0.0,0.0,True,"['Computer Science', 'Mathematics', 'Physics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","[{'authorId': '2242549528', 'name': 'Massimo Bonavita'}]",['European Centre for Medium-Range Weather Forecasts'],['United Kingdom'],2023-09
2309.08491,Bohui Zhang,"Bohui Zhang, Ioannis Reklos, Nitisha Jain, Albert Mero\~no Pe\~nuela,
  Elena Simperl",Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata,"Knowledge Base Construction from Pre-trained Language Models (LM-KBC)
  Challenge @ ISWC 2023",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In this work, we explore the use of Large Language Models (LLMs) for knowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge. For this task, given subject and relation pairs sourced from Wikidata, we utilize pre-trained LLMs to produce the relevant objects in string format and link them to their respective Wikidata QIDs. We developed a pipeline using LLMs for Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata entity mapping. The method achieved a macro-averaged F1-score of 0.701 across the properties, with the scores varying from 1.00 to 0.328. These results demonstrate that the knowledge of LLMs varies significantly depending on the domain and that further experimentation is required to determine the circumstances under which LLMs can be used for automatic Knowledge Base (e.g., Wikidata) completion and correction. The investigation of the results also suggests the promising contribution of LLMs in collaborative knowledge engineering. LLMKE won Track 2 of the challenge. The implementation is available at https://github.com/bohuizhang/LLMKE. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 15:51:14 GMT'}]",2023-09-18,"[['Zhang', 'Bohui', ''], ['Reklos', 'Ioannis', ''], ['Jain', 'Nitisha', ''], ['Peñuela', 'Albert Meroño', ''], ['Simperl', 'Elena', '']]",0,0,2023-09-15,1,5,2,0,0,0,ca535fd261b464750f218c823b93c39450691720,262013497.0,https://www.semanticscholar.org/paper/ca535fd261b464750f218c823b93c39450691720,arXiv.org,2023.0,31.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243445781', 'name': 'Bohui Zhang'}, {'authorId': '2163780942', 'name': 'Ioannis Reklos'}, {'authorId': '2242712463', 'name': 'Nitisha Jain'}, {'authorId': '2243983027', 'name': 'Albert Meroño-Peñuela'}, {'authorId': '2927032', 'name': 'E. Simperl'}]","[""King's College London""]",['United Kingdom'],2023-09
2309.08568,Mehdi Letafati,"Mehdi Letafati, Samad Ali, and Matti Latva-aho",Denoising Diffusion Probabilistic Models for Hardware-Impaired Communications,,,,,cs.IT eess.SP math.IT,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Generative AI has received significant attention among a spectrum of diverse industrial and academic domains, thanks to the magnificent results achieved from deep generative models such as generative pre-trained transformers (GPT) and diffusion models. In this paper, we explore the applications of denoising diffusion probabilistic models (DDPMs) in wireless communication systems under practical assumptions such as hardware impairments (HWI), low-SNR regime, and quantization error. Diffusion models are a new class of state-of-the-art generative models that have already showcased notable success with some of the popular examples by OpenAI1 and Google Brain2. The intuition behind DDPM is to decompose the data generation process over small ``denoising'' steps. Inspired by this, we propose using denoising diffusion model-based receiver for a practical wireless communication scheme, while providing network resilience in low-SNR regimes, non-Gaussian noise, different HWI levels, and quantization error. We evaluate the reconstruction performance of our scheme in terms of mean-squared error (MSE) metric. Our results show that more than 25 dB improvement in MSE is achieved compared to deep neural network (DNN)-based receivers. We also highlight robust out-of-distribution performance under non-Gaussian noise. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 17:35:50 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Oct 2023 12:03:32 GMT'}]",2023-10-06,"[['Letafati', 'Mehdi', ''], ['Ali', 'Samad', ''], ['Latva-aho', 'Matti', '']]",0,1,2023-09-15,2,3,3,0,0,0,86512e5b411071904fcfe753b50ad6c6e14a638a,262013690.0,https://www.semanticscholar.org/paper/86512e5b411071904fcfe753b50ad6c6e14a638a,arXiv.org,2023.0,34.0,0.0,0.0,True,"['Computer Science', 'Engineering', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243010296', 'name': 'Mehdi Letafati'}, {'authorId': '2555406', 'name': 'Samad Ali'}, {'authorId': '1381804818', 'name': 'M. Latva-aho'}]",['University of Oulu'],['Finland'],2023-09
2309.08573,Hannah Rose Kirk Miss,"Khyati Khandelwal, Manuel Tonneau, Andrew M. Bean, Hannah Rose Kirk,
  Scott A. Hale",Casteist but Not Racist? Quantifying Disparities in Large Language Model Bias between India and the West,,,,,cs.CL cs.CY,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs), now used daily by millions of users, can encode societal biases, exposing their users to representational harms. A large body of scholarship on LLM bias exists but it predominantly adopts a Western-centric frame and attends comparatively less to bias levels and potential harms in the Global South. In this paper, we quantify stereotypical bias in popular LLMs according to an Indian-centric frame and compare bias levels between the Indian and Western contexts. To do this, we develop a novel dataset which we call Indian-BhED (Indian Bias Evaluation Dataset), containing stereotypical and anti-stereotypical examples for caste and religion contexts. We find that the majority of LLMs tested are strongly biased towards stereotypes in the Indian context, especially as compared to the Western context. We finally investigate Instruction Prompting as a simple intervention to mitigate such bias and find that it significantly reduces both stereotypical and anti-stereotypical biases in the majority of cases for GPT-3.5. The findings of this work highlight the need for including more diverse voices when evaluating LLMs. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 17:38:41 GMT'}]",2023-09-18,"[['Khandelwal', 'Khyati', ''], ['Tonneau', 'Manuel', ''], ['Bean', 'Andrew M.', ''], ['Kirk', 'Hannah Rose', ''], ['Hale', 'Scott A.', '']]",0,1,2023-09-15,1,5,2,1,0,1,e4282cab4a435d5249fc8db49fc1c9268438fedb,262013517.0,https://www.semanticscholar.org/paper/e4282cab4a435d5249fc8db49fc1c9268438fedb,arXiv.org,2023.0,57.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2228157939', 'name': 'Khyati Khandelwal'}, {'authorId': '2159207178', 'name': 'Manuel Tonneau'}, {'authorId': '2242554313', 'name': 'Andrew M. Bean'}, {'authorId': '90729626', 'name': 'Hannah Rose Kirk'}, {'authorId': '1741886127', 'name': 'Scott A. Hale'}]",['University of Oxford'],['United Kingdom'],2023-09
2309.08591,Chen Liu,"Chen Cecilia Liu, Fajri Koto, Timothy Baldwin, Iryna Gurevych",Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) are highly adept at question answering and reasoning tasks, but when reasoning in situational context, human expectations vary depending on the relevant cultural common ground. As human languages are associated with diverse cultures, LLMs should also be culturally-diverse reasoners. In this paper, we study the ability of a wide range of state-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings in a conversational context. Our experiments reveal that: (1) mLLMs 'knows' limited proverbs and memorizing proverbs does not mean understanding them within a conversational context; (2) mLLMs struggle to reason with figurative proverbs and sayings, and when asked to select the wrong answer (instead of asking it to select the correct answer); and (3) there is a ""culture gap"" in mLLMs when reasoning about proverbs and sayings translated from other languages. We construct and release our evaluation dataset MAPS (MulticultrAl Proverbs and Sayings) for proverb understanding with conversational context for six different languages. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 17:45:28 GMT'}]",2023-09-18,"[['Liu', 'Chen Cecilia', ''], ['Koto', 'Fajri', ''], ['Baldwin', 'Timothy', ''], ['Gurevych', 'Iryna', '']]",0,0,2023-09-15,1,4,1,0,0,0,25e4e7a69454099ca0e3ccbf079452878d3abce9,261875650.0,https://www.semanticscholar.org/paper/25e4e7a69454099ca0e3ccbf079452878d3abce9,arXiv.org,2023.0,46.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '143876027', 'name': 'Chen Cecilia Liu'}, {'authorId': '2789148', 'name': 'Fajri Koto'}, {'authorId': '145465286', 'name': 'Timothy Baldwin'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}]","['Mohamed bin Zayed University of Artificial Intelligence', 'Technical University of Darmstadt']","['Germany', 'United Arab Emirates']",2023-09
2309.08624,Vithya Yogarajan,"Vithya Yogarajan, Gillian Dobbie, Timothy Pistotti, Joshua Bensemann,
  Kobe Knowles",Challenges in Annotating Datasets to Quantify Bias in Under-represented Society,"Accepted in Ethics and Trust in Human-AI Collaboration:
  Socio-Technical Approaches @ The 32nd International Joint Conference on
  Artificial Intelligence",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Recent advances in artificial intelligence, including the development of highly sophisticated large language models (LLM), have proven beneficial in many real-world applications. However, evidence of inherent bias encoded in these LLMs has raised concerns about equity. In response, there has been an increase in research dealing with bias, including studies focusing on quantifying bias and developing debiasing techniques. Benchmark bias datasets have also been developed for binary gender classification and ethical/racial considerations, focusing predominantly on American demographics. However, there is minimal research in understanding and quantifying bias related to under-represented societies. Motivated by the lack of annotated datasets for quantifying bias in under-represented societies, we endeavoured to create benchmark datasets for the New Zealand (NZ) population. We faced many challenges in this process, despite the availability of three annotators. This research outlines the manual annotation process, provides an overview of the challenges we encountered and lessons learnt, and presents recommendations for future research. ","[{'version': 'v1', 'created': 'Mon, 11 Sep 2023 22:24:39 GMT'}]",2023-09-19,"[['Yogarajan', 'Vithya', ''], ['Dobbie', 'Gillian', ''], ['Pistotti', 'Timothy', ''], ['Bensemann', 'Joshua', ''], ['Knowles', 'Kobe', '']]",0,0,2023-09-11,1,5,2,0,0,0,fec06097c0db7e0b0347ae31585e246dba06ea49,262045241.0,https://www.semanticscholar.org/paper/fec06097c0db7e0b0347ae31585e246dba06ea49,arXiv.org,2023.0,46.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '51071778', 'name': 'Vithya Yogarajan'}, {'authorId': '2239439286', 'name': 'Gillian Dobbie'}, {'authorId': '2243195218', 'name': 'Timothy Pistotti'}, {'authorId': '6835173', 'name': 'Joshua Bensemann'}, {'authorId': '2216490249', 'name': 'Kobe Knowles'}]",['University of Auckland'],['New Zealand'],2023-09
2309.08636,Benjamin Stular,Edisa Lozi\'c and Benjamin \v{S}tular,ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3),"Non-peer reviewed preprint. Includes Graphical abstract, 8 Figures.
  Appendices are linked and deposited at Zenodo",,,,cs.CL cs.AI cs.CY cs.ET cs.HC,http://creativecommons.org/licenses/by/4.0/,"  Historically, proficient writing was deemed essential for human advancement, with creative expression viewed as one of the hallmarks of human achievement. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness, while qualitative precision gauged the scientific contribution. While the AI chatbots, especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, they failed in generating original scientific content. As a side note, our results also suggest that with ChatGPT-4 the size of the LLMs has plateaued. Furthermore, the paper underscores the intricate and recursive nature of human research. This process of transforming raw data into refined knowledge is computationally irreducible, which highlights the challenges AI chatbots face in emulating human originality in scientific writing. In conclusion, while large language models have revolutionised content generation, their ability to produce original scientific contributions in the humanities remains limited. We expect that this will change in the near future with the evolution of current LLM-based AI chatbots towards LLM-powered software. ","[{'version': 'v1', 'created': 'Thu, 14 Sep 2023 14:04:03 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Sep 2023 08:47:33 GMT'}]",2023-09-25,"[['Lozić', 'Edisa', ''], ['Štular', 'Benjamin', '']]",1,1,2023-09-14,2,2,5,2,0,2,eae34c019fd08d5b2df25dd3d21149eaf67c6183,262045066.0,https://www.semanticscholar.org/paper/eae34c019fd08d5b2df25dd3d21149eaf67c6183,Future Internet,2023.0,140.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '120330902', 'name': 'Edisa Lozić'}, {'authorId': '83193967', 'name': 'Benjamin Štular'}]",['Slovenian Academy of Sciences and Arts'],['Slovenia'],2023-09
2309.08648,Yonchanok Khaokaew,"Yonchanok Khaokaew, Hao Xue, Flora D. Salim",MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Despite the rapid advancement of mobile applications, predicting app usage remains a formidable challenge due to intricate user behaviours and ever-evolving contexts. To address these issues, this paper introduces the Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model. This innovative approach utilizes Large Language Models (LLMs) to predict app usage accurately. Rigorous testing on two public datasets highlights MAPLE's capability to decipher intricate patterns and comprehend user contexts. These robust results confirm MAPLE's versatility and resilience across various scenarios. While its primary design caters to app prediction, the outcomes also emphasize the broader applicability of LLMs in different domains. Through this research, we emphasize the potential of LLMs in app usage prediction and suggest their transformative capacity in modelling human behaviours across diverse fields. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 13:15:54 GMT'}]",2023-09-19,"[['Khaokaew', 'Yonchanok', ''], ['Xue', 'Hao', ''], ['Salim', 'Flora D.', '']]",0,0,2023-09-15,1,3,2,0,0,0,59fc922aac0f177a517d5656868c9c4334d863ef,262044117.0,https://www.semanticscholar.org/paper/59fc922aac0f177a517d5656868c9c4334d863ef,arXiv.org,2023.0,37.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1900284', 'name': 'Yonchanok Khaokaew'}, {'authorId': '1560895396', 'name': 'Hao Xue'}, {'authorId': '144954586', 'name': 'Flora D. Salim'}]","['Flora D. Salim', 'UNSW Sydney']",['Australia'],2023-09
2309.08674,Terry Yue Zhuo,"Jinyan Su, Terry Yue Zhuo, Jonibek Mansurov, Di Wang, Preslav Nakov",Fake News Detectors are Biased against Texts Generated by Large Language Models,The first two authors contributed equally,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The spread of fake news has emerged as a critical challenge, undermining trust and posing threats to society. In the era of Large Language Models (LLMs), the capability to generate believable fake content has intensified these concerns. In this study, we present a novel paradigm to evaluate fake news detectors in scenarios involving both human-written and LLM-generated misinformation. Intriguingly, our findings reveal a significant bias in many existing detectors: they are more prone to flagging LLM-generated content as fake news while often misclassifying human-written fake news as genuine. This unexpected bias appears to arise from distinct linguistic patterns inherent to LLM outputs. To address this, we introduce a mitigation strategy that leverages adversarial training with LLM-paraphrased genuine news. The resulting model yielded marked improvements in detection accuracy for both human and LLM-generated news. To further catalyze research in this domain, we release two comprehensive datasets, \texttt{GossipCop++} and \texttt{PolitiFact++}, thus amalgamating human-validated articles with LLM-generated fake and real news. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 18:04:40 GMT'}]",2023-09-19,"[['Su', 'Jinyan', ''], ['Zhuo', 'Terry Yue', ''], ['Mansurov', 'Jonibek', ''], ['Wang', 'Di', ''], ['Nakov', 'Preslav', '']]",0,0,2023-09-15,1,5,2,0,0,0,8e5353c3e5bdb11f2df318ebd23faa65697ba929,261891488.0,https://www.semanticscholar.org/paper/8e5353c3e5bdb11f2df318ebd23faa65697ba929,arXiv.org,2023.0,40.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2116966710', 'name': 'Jinyan Su'}, {'authorId': '2080123731', 'name': 'Terry Yue Zhuo'}, {'authorId': '2218861055', 'name': 'Jonibek Mansurov'}, {'authorId': '2242030474', 'name': 'Di Wang'}, {'authorId': '2026545715', 'name': 'Preslav Nakov'}]","['Monash University', 'King Abdullah University of Science and Technology', 'Mohamed bin Zayed University of Artificial Intelligence']","['Australia', 'Saudi Arabia', 'United Arab Emirates']",2023-09
2309.08688,Mehdi Letafati,"Mehdi Letafati, Samad Ali, and Matti Latva-aho",Probabilistic Constellation Shaping With Denoising Diffusion Probabilistic Models: A Novel Approach,arXiv admin note: text overlap with arXiv:2309.08568,,,,cs.IT eess.SP math.IT,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  With the incredible results achieved from generative pre-trained transformers (GPT) and diffusion models, generative AI (GenAI) is envisioned to yield remarkable breakthroughs in various industrial and academic domains. In this paper, we utilize denoising diffusion probabilistic models (DDPM), as one of the state-of-the-art generative models, for probabilistic constellation shaping in wireless communications. While the geometry of constellations is predetermined by the networking standards, probabilistic constellation shaping can help enhance the information rate and communication performance by designing the probability of occurrence (generation) of constellation symbols. Unlike conventional methods that deal with an optimization problem over the discrete distribution of constellations, we take a radically different approach. Exploiting the ``denoise-and-generate'' characteristic of DDPMs, the key idea is to learn how to generate constellation symbols out of noise, ``mimicking'' the way the receiver performs symbol reconstruction. By doing so, we make the constellation symbols sent by the transmitter, and what is inferred (reconstructed) at the receiver become as similar as possible. Our simulations show that the proposed scheme outperforms deep neural network (DNN)-based benchmark and uniform shaping, while providing network resilience as well as robust out-of-distribution performance under low-SNR regimes and non-Gaussian noise. Notably, a threefold improvement in terms of mutual information is achieved compared to DNN-based approach for 64-QAM geometry. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 18:27:44 GMT'}]",2023-09-19,"[['Letafati', 'Mehdi', ''], ['Ali', 'Samad', ''], ['Latva-aho', 'Matti', '']]",0,1,2023-09-15,1,3,3,0,0,0,3b44151e633b21a6cbe008dd95e1496c65123555,262043685.0,https://www.semanticscholar.org/paper/3b44151e633b21a6cbe008dd95e1496c65123555,arXiv.org,2023.0,18.0,3.0,0.0,True,"['Computer Science', 'Engineering', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243010296', 'name': 'Mehdi Letafati'}, {'authorId': '2555406', 'name': 'Samad Ali'}, {'authorId': '1381804818', 'name': 'M. Latva-aho'}]",['University of Oulu'],['Finland'],2023-09
2309.08715,EPTCS,"Martin Berglund (Ume{\aa} University), Brink van der Merwe
  (Stellenbosch University)",Formalizing BPE Tokenization,"In Proceedings NCMA 2023, arXiv:2309.07333","EPTCS 388, 2023, pp. 16-27",10.4204/EPTCS.388.4,,cs.FL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this paper, we formalize practical byte pair encoding tokenization as it is used in large language models and other NLP systems, in particular we formally define and investigate the semantics of the SentencePiece and HuggingFace tokenizers, in particular how they relate to each other, depending on how the tokenization rules are constructed. Beyond this we consider how tokenization can be performed in an incremental fashion, as well as doing it left-to-right using an amount of memory constant in the length of the string, enabling e.g. using a finite state string-to-string transducer. ","[{'version': 'v1', 'created': 'Fri, 15 Sep 2023 19:10:42 GMT'}]",2023-09-19,"[['Berglund', 'Martin', '', 'Umeå University'], ['van der Merwe', 'Brink', '', 'Stellenbosch University']]",0,0,2023-09-15,1,2,1,0,0,0,7d1d3cdcf59232ceb74e6235a59f18b487e66a86,261848460.0,https://www.semanticscholar.org/paper/7d1d3cdcf59232ceb74e6235a59f18b487e66a86,Electronic Proceedings in Theoretical Computer Science,2023.0,10.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '34890857', 'name': 'Martin Berglund'}, {'authorId': '2403851', 'name': 'Brink van der Merwe'}]",['Umeå University'],['Sweden'],2023-09
2309.08922,Hossein Rajabzadeh,"Hossein Rajabzadeh, Suyuchen Wang, Hyock Ju Kwon, Bang Liu",Multimodal Multi-Hop Question Answering Through a Conversation Between Tools and Efficiently Finetuned Large Language Models,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We employ a tool-interacting divide-and-conquer strategy enabling large language models (LLMs) to answer complex multimodal multi-hop questions. In particular, we harness the power of large language models to divide a given multimodal multi-hop question into unimodal single-hop sub-questions to be answered by the appropriate tool from a predefined set of tools. After all corresponding tools provide the LLM with their answers, the LLM generates the next relevant unimodal single-hop question. To increase the reasoning ability of LLMs, we prompt chatGPT to generate a tool-interacting divide-and-conquer dataset. This dataset is then used to efficiently finetune the corresponding LLM. To assess the effectiveness of this approach, we conduct an evaluation on two recently introduced complex question-answering datasets. The experimental analysis demonstrate substantial improvements over existing state-of-the-art solutions, indicating the efficacy and generality of our strategy ","[{'version': 'v1', 'created': 'Sat, 16 Sep 2023 08:22:22 GMT'}]",2023-09-19,"[['Rajabzadeh', 'Hossein', ''], ['Wang', 'Suyuchen', ''], ['Kwon', 'Hyock Ju', ''], ['Liu', 'Bang', '']]",1,1,2023-09-16,1,4,1,1,0,1,3ec464696db25acc2c39a6d967ec3df09e06f633,261891369.0,https://www.semanticscholar.org/paper/3ec464696db25acc2c39a6d967ec3df09e06f633,arXiv.org,2023.0,33.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2241468593', 'name': 'Hossein Rajabzadeh'}, {'authorId': '1643451565', 'name': 'Suyuchen Wang'}, {'authorId': '2241480742', 'name': 'Hyock Ju Kwon'}, {'authorId': '2241485472', 'name': 'Bang Liu'}]","['Université de Montréal', 'University of Waterloo']",['Canada'],2023-09
2309.08958,Pinzhen Chen,"Pinzhen Chen, Shaoxiong Ji, Nikolay Bogoychev, Barry Haddow, Kenneth
  Heafield",Monolingual or Multilingual Instruction Tuning: Which Makes a Better Alpaca,Work in progress,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Foundational large language models (LLMs) can be instruction-tuned to develop open-ended question-answering capability, facilitating applications such as the creation of AI assistants. While such efforts are often carried out in a single language, building on prior research, we empirically analyze cost-efficient approaches of monolingual and multilingual tuning, shedding light on the efficacy of LLMs in responding to queries across monolingual and multilingual contexts. Our study employs the Alpaca dataset and machine translations of it to form multilingual training data, which is then used to tune LLMs through low-rank adaptation and full-parameter training. Comparisons reveal that multilingual tuning is not crucial for an LLM's English performance, but is key to its robustness in a multilingual environment. With a fixed budget, a multilingual instruction-tuned model, merely trained on downsampled data, can be as powerful as training monolingual models for each language. Our findings serve as a guide for expanding language support through instruction tuning with constrained computational resources. ","[{'version': 'v1', 'created': 'Sat, 16 Sep 2023 11:22:46 GMT'}]",2023-09-19,"[['Chen', 'Pinzhen', ''], ['Ji', 'Shaoxiong', ''], ['Bogoychev', 'Nikolay', ''], ['Haddow', 'Barry', ''], ['Heafield', 'Kenneth', '']]",0,0,2023-09-16,1,5,2,1,0,1,cd7c9fbb2acab241b0b4c7837877a19335c7284c,262053896.0,https://www.semanticscholar.org/paper/cd7c9fbb2acab241b0b4c7837877a19335c7284c,arXiv.org,2023.0,33.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '143616669', 'name': 'Pinzhen Chen'}, {'authorId': '2237431906', 'name': 'Shaoxiong Ji'}, {'authorId': '3444222', 'name': 'Nikolay Bogoychev'}, {'authorId': '2259100', 'name': 'B. Haddow'}, {'authorId': '1702066', 'name': 'Kenneth Heafield'}]","['University of Helsinki', 'University of Edinburgh']","['United Kingdom', 'Finland']",2023-09
2309.08969,Yuxia Wang,"Yuxia Wang, Minghan Wang, Preslav Nakov",Rethinking STS and NLI in Large Language Models,arXiv admin note: text overlap with arXiv:2212.13138 by other authors,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In this study, we aim to rethink STS and NLI in the era of large language models (LLMs). We first evaluate the accuracy of clinical/biomedical STS and NLI over five datasets, and then we assess LLM predictive confidence and their capability of capturing collective human opinions. We find that LLMs may be able to provide personalised descriptions for a specific topic, or to generate semantically similar content in different tones, but that this is hard for current LLMs to make personalised judgements or decisions. We further find that zero-shot ChatGPT achieves competitive accuracy over clinical and biomedical STS/NLI, constraining to the fine-tuned BERT-base. However, there is a large variation in sampling, ensembled results perform the best. ","[{'version': 'v1', 'created': 'Sat, 16 Sep 2023 11:58:39 GMT'}]",2023-09-20,"[['Wang', 'Yuxia', ''], ['Wang', 'Minghan', ''], ['Nakov', 'Preslav', '']]",1,1,2023-09-16,1,3,1,1,0,1,40dccaaf6f5a563437f26c75e92279ba415df392,261884422.0,https://www.semanticscholar.org/paper/40dccaaf6f5a563437f26c75e92279ba415df392,arXiv.org,2023.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2241417701', 'name': 'Yuxia Wang'}, {'authorId': '2242189619', 'name': 'Minghan Wang'}, {'authorId': '2026545715', 'name': 'Preslav Nakov'}]",['Monash University'],['Australia'],2023-09
2309.09071,Ha Thanh Nguyen,"Hai-Long Nguyen, Thi-Kieu-Trang Pham, Thai-Son Le, Tan-Minh Nguyen,
  Thi-Hai-Yen Vuong, Ha-Thanh Nguyen",RMDM: A Multilabel Fakenews Dataset for Vietnamese Evidence Verification,ISAILD@KSE 2023,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In this study, we present a novel and challenging multilabel Vietnamese dataset (RMDM) designed to assess the performance of large language models (LLMs), in verifying electronic information related to legal contexts, focusing on fake news as potential input for electronic evidence. The RMDM dataset comprises four labels: real, mis, dis, and mal, representing real information, misinformation, disinformation, and mal-information, respectively. By including these diverse labels, RMDM captures the complexities of differing fake news categories and offers insights into the abilities of different language models to handle various types of information that could be part of electronic evidence. The dataset consists of a total of 1,556 samples, with 389 samples for each label. Preliminary tests on the dataset using GPT-based and BERT-based models reveal variations in the models' performance across different labels, indicating that the dataset effectively challenges the ability of various language models to verify the authenticity of such information. Our findings suggest that verifying electronic information related to legal contexts, including fake news, remains a difficult problem for language models, warranting further attention from the research community to advance toward more reliable AI models for potential legal applications. ","[{'version': 'v1', 'created': 'Sat, 16 Sep 2023 18:35:08 GMT'}]",2023-09-19,"[['Nguyen', 'Hai-Long', ''], ['Pham', 'Thi-Kieu-Trang', ''], ['Le', 'Thai-Son', ''], ['Nguyen', 'Tan-Minh', ''], ['Vuong', 'Thi-Hai-Yen', ''], ['Nguyen', 'Ha-Thanh', '']]",0,1,2023-09-16,1,6,2,0,0,0,8e21244d8b65db8b3977d4cc2f2999ff049c4cda,261884532.0,https://www.semanticscholar.org/paper/8e21244d8b65db8b3977d4cc2f2999ff049c4cda,arXiv.org,2023.0,22.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2239461322', 'name': 'Hai-Long Nguyen'}, {'authorId': '2241450496', 'name': 'Thi-Kieu-Trang Pham'}, {'authorId': '2241400959', 'name': 'Thai-Son Le'}, {'authorId': '2191810014', 'name': 'Tan-Minh Nguyen'}, {'authorId': '50777503', 'name': 'Thi-Hai-Yen Vuong'}, {'authorId': '2716209', 'name': 'Nguyen Ha Thanh'}]","['National Institute of Informatics', 'Universidad de Ingeniería y Tecnología']","['Japan', 'Peru']",2023-09
2309.09126,Chowdhury Rahman,"Chowdhury Rafeed Rahman, Limsoon Wong",How much can ChatGPT really help Computational Biologists in Programming?,,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  ChatGPT, a recently developed product by openAI, is successfully leaving its mark as a multi-purpose natural language based chatbot. In this paper, we are more interested in analyzing its potential in the field of computational biology. A major share of work done by computational biologists these days involve coding up Bioinformatics algorithms, analyzing data, creating pipelining scripts and even machine learning modeling & feature extraction. This paper focuses on the potential influence (both positive and negative) of ChatGPT in the mentioned aspects with illustrative examples from different perspectives. Compared to other fields of Computer Science, Computational Biology has: (1) less coding resources, (2) more sensitivity and bias issues (deals with medical data) and (3) more necessity of coding assistance (people from diverse background come to this field). Keeping such issues in mind, we cover use cases such as code writing, reviewing, debugging, converting, refactoring and pipelining using ChatGPT from the perspective of computational biologists in this paper. ","[{'version': 'v1', 'created': 'Sun, 17 Sep 2023 01:36:02 GMT'}]",2023-09-20,"[['Rahman', 'Chowdhury Rafeed', ''], ['Wong', 'Limsoon', '']]",1,1,2023-09-17,1,2,2,1,0,1,544c7c031a7f02ac11c521c093d9fb49883b245e,261959377.0,https://www.semanticscholar.org/paper/544c7c031a7f02ac11c521c093d9fb49883b245e,arXiv.org,2023.0,52.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '52220379', 'name': 'C. Rahman'}, {'authorId': '2244663146', 'name': 'Limsoon Wong'}]",['National University of Singapore'],['Singapore'],2023-09
2309.09261,Marios Fragkoulis,"Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos,
  Dietmar Jannach, Marios Fragkoulis",Leveraging Large Language Models for Sequential Recommendation,9 pages,,10.1145/3604915.3610639,"In Seventeenth ACM Conference on Recommender Systems (RecSys '23),
  September 18--22, 2023, Singapore, Singapore. ACM, New York, NY, USA",cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Sequential recommendation problems have received increasing attention in research during the past few years, leading to the inception of a large variety of algorithmic approaches. In this work, we explore how large language models (LLMs), which are nowadays introducing disruptive effects in many AI-based applications, can be used to build or improve sequential recommendation approaches. Specifically, we devise and evaluate three approaches to leverage the power of LLMs in different ways. Our results from experiments on two datasets show that initializing the state-of-the-art sequential recommendation model BERT4Rec with embeddings obtained from an LLM improves NDCG by 15-20% compared to the vanilla BERT4Rec model. Furthermore, we find that a simple approach that leverages LLM embeddings for producing recommendations, can provide competitive performance by highlighting semantically related items. We publicly share the code and data of our experiments to ensure reproducibility. ","[{'version': 'v1', 'created': 'Sun, 17 Sep 2023 12:53:53 GMT'}]",2023-09-19,"[['Harte', 'Jesse', ''], ['Zorgdrager', 'Wouter', ''], ['Louridas', 'Panos', ''], ['Katsifodimos', 'Asterios', ''], ['Jannach', 'Dietmar', ''], ['Fragkoulis', 'Marios', '']]",0,0,2023-09-17,1,6,1,0,0,0,41c3745b834cb3147cc956d9d39e86028649b1e9,261823711.0,https://www.semanticscholar.org/paper/41c3745b834cb3147cc956d9d39e86028649b1e9,ACM Conference on Recommender Systems,2023.0,47.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2240534335', 'name': 'Jesse Harte'}, {'authorId': '2142315031', 'name': 'Wouter Zorgdrager'}, {'authorId': '123396793', 'name': 'Panos Louridas'}, {'authorId': '2138521152', 'name': 'Asterios Katsifodimos'}, {'authorId': '1705282', 'name': 'D. Jannach'}, {'authorId': '1792039', 'name': 'Marios Fragkoulis'}]","['University of Klagenfurt', 'Athens University of Economics and Business', 'WOUTER ZORGDRAGER, Delivery Hero Research, Germany', 'Delft University of Technology', 'Delivery Hero Research, Germany and Delft University of Technology, The Netherlands', 'MARIOS FRAGKOULIS, Delivery Hero Research, Germany']","['Greece', 'Germany', 'Austria', 'Netherlands']",2023-09
2309.09338,Gerd Kortemeyer,Gerd Kortemeyer,Performance of the Pre-Trained Large Language Model GPT-4 on Automated Short Answer Grading,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Automated Short Answer Grading (ASAG) has been an active area of machine-learning research for over a decade. It promises to let educators grade and give feedback on free-form responses in large-enrollment courses in spite of limited availability of human graders. Over the years, carefully trained models have achieved increasingly higher levels of performance. More recently, pre-trained Large Language Models (LLMs) emerged as a commodity, and an intriguing question is how a general-purpose tool without additional training compares to specialized models. We studied the performance of GPT-4 on the standard benchmark 2-way and 3-way datasets SciEntsBank and Beetle, where in addition to the standard task of grading the alignment of the student answer with a reference answer, we also investigated withholding the reference answer. We found that overall, the performance of the pre-trained general-purpose GPT-4 LLM is comparable to hand-engineered models, but worse than pre-trained LLMs that had specialized training. ","[{'version': 'v1', 'created': 'Sun, 17 Sep 2023 18:04:34 GMT'}]",2023-09-19,"[['Kortemeyer', 'Gerd', '']]",0,1,2023-09-17,1,1,1,1,0,1,6c16ffcdd208f0dbbbb30bfb518d9214befe6804,262045158.0,https://www.semanticscholar.org/paper/6c16ffcdd208f0dbbbb30bfb518d9214befe6804,arXiv.org,2023.0,19.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243196001', 'name': 'Gerd Kortemeyer'}]",['ETH Zurich'],['Switzerland'],2023-09
2309.09401,Guido Zuccon,"Guido Zuccon, Bevan Koopman, Razia Shaik",ChatGPT Hallucinates when Attributing Answers,,,,,cs.AI cs.DL cs.IR,http://creativecommons.org/licenses/by/4.0/,"  Can ChatGPT provide evidence to support its answers? Does the evidence it suggests actually exist and does it really support its answer? We investigate these questions using a collection of domain-specific knowledge-based questions, specifically prompting ChatGPT to provide both an answer and supporting evidence in the form of references to external sources. We also investigate how different prompts impact answers and evidence. We find that ChatGPT provides correct or partially correct answers in about half of the cases (50.6% of the times), but its suggested references only exist 14% of the times. We further provide insights on the generated references that reveal common traits among the references that ChatGPT generates, and show how even if a reference provided by the model does exist, this reference often does not support the claims ChatGPT attributes to it. Our findings are important because (1) they are the first systematic analysis of the references created by ChatGPT in its answers; (2) they suggest that the model may leverage good quality information in producing correct answers, but is unable to attribute real evidence to support its answers. Prompts, raw result files and manual analysis are made publicly available. ","[{'version': 'v1', 'created': 'Sun, 17 Sep 2023 23:49:12 GMT'}]",2023-09-19,"[['Zuccon', 'Guido', ''], ['Koopman', 'Bevan', ''], ['Shaik', 'Razia', '']]",1,1,2023-09-17,1,3,3,1,0,1,ef60365a029358adf2057863718b36aeb9e9a009,261891399.0,https://www.semanticscholar.org/paper/ef60365a029358adf2057863718b36aeb9e9a009,arXiv.org,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1692855', 'name': 'G. Zuccon'}, {'authorId': '1783566', 'name': 'B. Koopman'}, {'authorId': '2241469445', 'name': 'Razia Shaik'}]","['Commonwealth Scientific and Industrial Research Organisation', 'University of Queensland']",['Australia'],2023-09
2309.09495,Mohit Jain,"Pradyumna YM, Vinod Ganesan, Dinesh Kumar Arumugam, Meghna Gupta,
  Nischith Shadagopan, Tanay Dixit, Sameer Segal, Pratyush Kumar, Mohit Jain,
  Sriram Rajamani",PwR: Exploring the Role of Representations in Conversational Programming,"23 pages, 3 figures, 2 tables, under submission for ACM CHI 2024",,,,cs.HC cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) have revolutionized programming and software engineering. AI programming assistants such as GitHub Copilot X enable conversational programming, narrowing the gap between human intent and code generation. However, prior literature has identified a key challenge--there is a gap between user's mental model of the system's understanding after a sequence of natural language utterances, and the AI system's actual understanding. To address this, we introduce Programming with Representations (PwR), an approach that uses representations to convey the system's understanding back to the user in natural language. We conducted an in-lab task-centered study with 14 users of varying programming proficiency and found that representations significantly improve understandability, and instilled a sense of agency among our participants. Expert programmers use them for verification, while intermediate programmers benefit from confirmation. Natural language-based development with LLMs, coupled with representations, promises to transform software development, making it more accessible and efficient. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 05:38:23 GMT'}]",2023-09-19,"[['YM', 'Pradyumna', ''], ['Ganesan', 'Vinod', ''], ['Arumugam', 'Dinesh Kumar', ''], ['Gupta', 'Meghna', ''], ['Shadagopan', 'Nischith', ''], ['Dixit', 'Tanay', ''], ['Segal', 'Sameer', ''], ['Kumar', 'Pratyush', ''], ['Jain', 'Mohit', ''], ['Rajamani', 'Sriram', '']]",0,0,2023-09-18,1,10,2,0,0,0,05c6d102b7e37f1f03c938729ceffd43f9fc1725,262045156.0,https://www.semanticscholar.org/paper/05c6d102b7e37f1f03c938729ceffd43f9fc1725,arXiv.org,2023.0,35.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2160630928', 'name': 'YM Pradyumna'}, {'authorId': '145743088', 'name': 'Vinod Ganesan'}, {'authorId': '2137866430', 'name': 'D. Arumugam'}, {'authorId': '2242822458', 'name': 'Meghna Gupta'}, {'authorId': '2206705630', 'name': 'Nischith Shadagopan'}, {'authorId': '2126503480', 'name': 'Tanay Dixit'}, {'authorId': '2242814985', 'name': 'Sameer Segal'}, {'authorId': '38724234', 'name': 'Pratyush Kumar'}, {'authorId': '2243125175', 'name': 'Mohit Jain'}, {'authorId': '1685546', 'name': 'S. Rajamani'}]",['Microsoft'],['India'],2023-09
2309.09582,Jonas Golde,"Jonas Golde, Patrick Haller, Felix Hamborg, Julian Risch, Alan Akbik",Fabricator: An Open Source Toolkit for Generating Labeled Training Data with Teacher LLMs,3 Figures and 2 Tables,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Most NLP tasks are modeled as supervised learning and thus require labeled training data to train effective models. However, manually producing such data at sufficient quality and quantity is known to be costly and time-intensive. Current research addresses this bottleneck by exploring a novel paradigm called zero-shot learning via dataset generation. Here, a powerful LLM is prompted with a task description to generate labeled data that can be used to train a downstream NLP model. For instance, an LLM might be prompted to ""generate 500 movie reviews with positive overall sentiment, and another 500 with negative sentiment."" The generated data could then be used to train a binary sentiment classifier, effectively leveraging an LLM as a teacher to a smaller student model. With this demo, we introduce Fabricator, an open-source Python toolkit for dataset generation. Fabricator implements common dataset generation workflows, supports a wide range of downstream NLP tasks (such as text classification, question answering, and entity recognition), and is integrated with well-known libraries to facilitate quick experimentation. With Fabricator, we aim to support researchers in conducting reproducible dataset generation experiments using LLMs and help practitioners apply this approach to train models for downstream tasks. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 08:45:47 GMT'}]",2023-09-19,"[['Golde', 'Jonas', ''], ['Haller', 'Patrick', ''], ['Hamborg', 'Felix', ''], ['Risch', 'Julian', ''], ['Akbik', 'Alan', '']]",0,0,2023-09-18,1,5,2,0,0,0,9deae1f6a7033acd001fd92a06988efcafd6cf0d,262046531.0,https://www.semanticscholar.org/paper/9deae1f6a7033acd001fd92a06988efcafd6cf0d,arXiv.org,2023.0,37.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '144983077', 'name': 'Jonas Golde'}, {'authorId': None, 'name': 'Patrick Haller'}, {'authorId': '2243192605', 'name': 'Felix Hamborg'}, {'authorId': '2243192023', 'name': 'Julian Risch'}, {'authorId': '2403712', 'name': 'A. Akbik'}]","['Humboldt-Universität zu Berlin', 'deepset GmbH']",['Germany'],2023-09
2309.09708,Nan Li,"Nan Li, Bo Kang, Tijl De Bie",LLM4Jobs: Unsupervised occupation extraction and standardization leveraging Large Language Models,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Automated occupation extraction and standardization from free-text job postings and resumes are crucial for applications like job recommendation and labor market policy formation. This paper introduces LLM4Jobs, a novel unsupervised methodology that taps into the capabilities of large language models (LLMs) for occupation coding. LLM4Jobs uniquely harnesses both the natural language understanding and generation capacities of LLMs. Evaluated on rigorous experimentation on synthetic and real-world datasets, we demonstrate that LLM4Jobs consistently surpasses unsupervised state-of-the-art benchmarks, demonstrating its versatility across diverse datasets and granularities. As a side result of our work, we present both synthetic and real-world datasets, which may be instrumental for subsequent research in this domain. Overall, this investigation highlights the promise of contemporary LLMs for the intricate task of occupation extraction and standardization, laying the foundation for a robust and adaptable framework relevant to both research and industrial contexts. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 12:22:00 GMT'}, {'version': 'v2', 'created': 'Tue, 19 Sep 2023 09:28:18 GMT'}]",2023-09-20,"[['Li', 'Nan', ''], ['Kang', 'Bo', ''], ['De Bie', 'Tijl', '']]",0,0,2023-09-18,2,3,2,0,0,0,b41c6e17c131fca6a5c7d37c4587b6c71c3c566b,261898109.0,https://www.semanticscholar.org/paper/b41c6e17c131fca6a5c7d37c4587b6c71c3c566b,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2215172053', 'name': 'Nan Li'}, {'authorId': '144325478', 'name': 'Bo Kang'}, {'authorId': '51204489', 'name': 'T. D. Bie'}]",['Ghent University'],['Belgium'],2023-09
2309.09812,Zhanyu Wang,"Zhanyu Wang, Lingqiao Liu, Lei Wang and Luping Zhou",R2GenGPT: Radiology Report Generation with Frozen LLMs,Submitted to meta-radiology,,,,cs.CV,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large Language Models (LLMs) have consistently showcased remarkable generalization capabilities when applied to various language tasks. Nonetheless, harnessing the full potential of LLMs for Radiology Report Generation (R2Gen) still presents a challenge, stemming from the inherent disparity in modality between LLMs and the R2Gen task. To bridge this gap effectively, we propose R2GenGPT, which is a novel solution that aligns visual features with the word embedding space of LLMs using an efficient visual alignment module. This innovative approach empowers the previously static LLM to seamlessly integrate and process image information, marking a step forward in optimizing R2Gen performance. R2GenGPT offers the following benefits. First, it attains state-of-the-art (SOTA) performance by training only the lightweight visual alignment module while freezing all the parameters of LLM. Second, it exhibits high training efficiency, as it requires the training of an exceptionally minimal number of parameters while achieving rapid convergence. By employing delta tuning, our model only trains 5M parameters (which constitute just 0.07\% of the total parameter count) to achieve performance close to the SOTA levels. Our code is available at https://github.com/wang-zhanyu/R2GenGPT. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 14:35:35 GMT'}]",2023-09-19,"[['Wang', 'Zhanyu', ''], ['Liu', 'Lingqiao', ''], ['Wang', 'Lei', ''], ['Zhou', 'Luping', '']]",0,1,2023-09-18,1,4,1,0,0,0,3222702f7be3375008619be6fd6bdc334988d2ba,262044687.0,https://www.semanticscholar.org/paper/3222702f7be3375008619be6fd6bdc334988d2ba,arXiv.org,2023.0,50.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2135223272', 'name': 'Zhanyu Wang'}, {'authorId': '2243894782', 'name': 'Lingqiao Liu'}, {'authorId': '36547165', 'name': 'Lei Wang'}, {'authorId': '6578587', 'name': 'Luping Zhou'}]","['University of Adelaide', 'University of Wollongong', 'University of Sydney']",['Australia'],2023-09
2309.09898,Simon Hosemann,"Maurice Funk, Simon Hosemann, Jean Christoph Jung, Carsten Lutz",Towards Ontology Construction with Language Models,"KBC-LM'23: Knowledge Base Construction from Pre-trained Language
  Models workshop at ISWC 2023",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,  We present a method for automatically constructing a concept hierarchy for a given domain by querying a large language model. We apply this method to various domains using OpenAI's GPT 3.5. Our experiments indicate that LLMs can be of considerable help for constructing concept hierarchies. ,"[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 16:02:39 GMT'}]",2023-09-19,"[['Funk', 'Maurice', ''], ['Hosemann', 'Simon', ''], ['Jung', 'Jean Christoph', ''], ['Lutz', 'Carsten', '']]",0,1,2023-09-18,1,4,1,1,0,1,af28645353cb4be65a7c35becfe4c2c9d1335ba0,262044094.0,https://www.semanticscholar.org/paper/af28645353cb4be65a7c35becfe4c2c9d1335ba0,arXiv.org,2023.0,29.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '29434671', 'name': 'Maurice Funk'}, {'authorId': '2243197011', 'name': 'Simon Hosemann'}, {'authorId': '1804478', 'name': 'J. C. Jung'}, {'authorId': '2242848026', 'name': 'Carsten Lutz'}]","['TU Dortmund University', 'Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI', 'Leipzig University']",['Germany'],2023-09
2309.09902,Stephan Bialonski,"Tobias Bornheim, Niklas Grieger, Patrick Gustav Blaneck, Stephan
  Bialonski",Speaker attribution in German parliamentary debates with QLoRA-adapted large language models,"8 pages, 3 figures",,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The growing body of political texts opens up new opportunities for rich insights into political dynamics and ideologies but also increases the workload for manual analysis. Automated speaker attribution, which detects who said what to whom in a speech event and is closely related to semantic role labeling, is an important processing step for computational text analysis. We study the potential of the large language model family Llama 2 to automate speaker attribution in German parliamentary debates from 2017-2021. We fine-tune Llama 2 with QLoRA, an efficient training strategy, and observe our approach to achieve competitive performance in the GermEval 2023 Shared Task On Speaker Attribution in German News Articles and Parliamentary Debates. Our results shed light on the capabilities of large language models in automating speaker attribution, revealing a promising avenue for computational analysis of political discourse and the development of semantic role labeling systems. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 16:06:16 GMT'}]",2023-09-19,"[['Bornheim', 'Tobias', ''], ['Grieger', 'Niklas', ''], ['Blaneck', 'Patrick Gustav', ''], ['Bialonski', 'Stephan', '']]",0,0,2023-09-18,1,4,1,1,1,0,e54ab1b3cf2fe3f695e0bfc0bde55c4aacd68249,262044336.0,https://www.semanticscholar.org/paper/e54ab1b3cf2fe3f695e0bfc0bde55c4aacd68249,arXiv.org,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","[{'authorId': '2125818889', 'name': 'Tobias Bornheim'}, {'authorId': '2088382168', 'name': 'Niklas Grieger'}, {'authorId': '2184146158', 'name': 'Patrick Gustav Blaneck'}, {'authorId': '2243180507', 'name': 'Stephan Bialonski'}]","['Utrecht University', 'FH Aachen']","['Germany', 'Netherlands']",2023-09
2309.10048,Artur M Schweidtmann,"Lukas Schulze Balhorn, Jana M. Weber, Stefan Buijsman, Julian R.
  Hildebrandt, Martina Ziefle and Artur M. Schweidtmann",What does ChatGPT know about natural science and engineering?,,,,,cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  ChatGPT is a powerful language model from OpenAI that is arguably able to comprehend and generate text. ChatGPT is expected to have a large impact on society, research, and education. An essential step to understand ChatGPT's expected impact is to study its domain-specific answering capabilities. Here, we perform a systematic empirical assessment of its abilities to answer questions across the natural science and engineering domains. We collected 594 questions from 198 faculty members across 5 faculties at Delft University of Technology. After collecting the answers from ChatGPT, the participants assessed the quality of the answers using a systematic scheme. Our results show that the answers from ChatGPT are on average perceived as ``mostly correct''. Two major trends are that the rating of the ChatGPT answers significantly decreases (i) as the complexity level of the question increases and (ii) as we evaluate skills beyond scientific knowledge, e.g., critical attitude. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 18:05:44 GMT'}]",2023-09-20,"[['Balhorn', 'Lukas Schulze', ''], ['Weber', 'Jana M.', ''], ['Buijsman', 'Stefan', ''], ['Hildebrandt', 'Julian R.', ''], ['Ziefle', 'Martina', ''], ['Schweidtmann', 'Artur M.', '']]",1,1,2023-09-18,1,6,1,1,0,1,bffb1a3d7433800fec53fa7119737234c27d823d,262053426.0,https://www.semanticscholar.org/paper/bffb1a3d7433800fec53fa7119737234c27d823d,arXiv.org,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2179880784', 'name': 'Lukas Schulze Balhorn'}, {'authorId': '2243458363', 'name': 'Jana M. Weber'}, {'authorId': '2243232102', 'name': 'Stefan Buijsman'}, {'authorId': '38739279', 'name': 'J. Hildebrandt'}, {'authorId': '2242806758', 'name': 'Martina Ziefle'}, {'authorId': '41072400', 'name': 'Artur M. Schweidtmann'}]","['RWTH Aachen University', 'Delft University of Technology']","['Germany', 'Netherlands']",2023-09
2309.10312,Jing Huang,"Jing Huang, Atticus Geiger, Karel D'Oosterlinck, Zhengxuan Wu,
  Christopher Potts",Rigorously Assessing Natural Language Explanations of Neurons,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Natural language is an appealing medium for explaining how large language models process and store information, but evaluating the faithfulness of such explanations is challenging. To help address this, we develop two modes of evaluation for natural language explanations that claim individual neurons represent a concept in a text input. In the observational mode, we evaluate claims that a neuron $a$ activates on all and only input strings that refer to a concept picked out by the proposed explanation $E$. In the intervention mode, we construe $E$ as a claim that the neuron $a$ is a causal mediator of the concept denoted by $E$. We apply our framework to the GPT-4-generated explanations of GPT-2 XL neurons of Bills et al. (2023) and show that even the most confident explanations have high error rates and little to no causal efficacy. We close the paper by critically assessing whether natural language is a good choice for explanations and whether neurons are the best level of analysis. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 04:49:45 GMT'}]",2023-09-20,"[['Huang', 'Jing', ''], ['Geiger', 'Atticus', ''], [""D'Oosterlinck"", 'Karel', ''], ['Wu', 'Zhengxuan', ''], ['Potts', 'Christopher', '']]",0,1,2023-09-19,1,5,1,2,1,1,97cea53d979305e6686387ff0ee38a15e3a5ba46,262054234.0,https://www.semanticscholar.org/paper/97cea53d979305e6686387ff0ee38a15e3a5ba46,arXiv.org,2023.0,44.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2145739230', 'name': 'Jing Huang'}, {'authorId': '80833908', 'name': 'Atticus Geiger'}, {'authorId': '2123124766', 'name': ""Karel D'Oosterlinck""}, {'authorId': '47039337', 'name': 'Zhengxuan Wu'}, {'authorId': '144922861', 'name': 'Christopher Potts'}]",['Ghent University'],['Belgium'],2023-09
2309.10359,Srishti Yadav,"Peter Ebert Christensen, Srishti Yadav, Serge Belongie","Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning",,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Unsupported and unfalsifiable claims we encounter in our daily lives can influence our view of the world. Characterizing, summarizing, and -- more generally -- making sense of such claims, however, can be challenging. In this work, we focus on fine-grained debate topics and formulate a new task of distilling, from such claims, a countable set of narratives. We present a crowdsourced dataset of 12 controversial topics, comprising more than 120k arguments, claims, and comments from heterogeneous sources, each annotated with a narrative label. We further investigate how large language models (LLMs) can be used to synthesise claims using In-Context Learning. We find that generated claims with supported evidence can be used to improve the performance of narrative classification models and, additionally, that the same model can infer the stance and aspect using a few training examples. Such a model can be useful in applications which rely on narratives , e.g. fact-checking. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 06:42:37 GMT'}]",2023-09-20,"[['Christensen', 'Peter Ebert', ''], ['Yadav', 'Srishti', ''], ['Belongie', 'Serge', '']]",0,0,2023-09-19,1,3,1,0,0,0,ff5eed73dca84fcc7b98142055c35dd7b8724c80,259305673.0,https://www.semanticscholar.org/paper/ff5eed73dca84fcc7b98142055c35dd7b8724c80,arXiv.org,2023.0,43.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1482473886', 'name': 'Peter Ebert Christensen'}, {'authorId': '2241991825', 'name': 'Srishti Yadav'}, {'authorId': '50172592', 'name': 'Serge J. Belongie'}]",['University of Copenhagen'],['Denmark'],2023-09
2309.10419,Changyoon Lee,"Changyoon Lee, Junho Myung, Jieun Han, Jiho Jin and Alice Oh",Learning from Teaching Assistants to Program with Subgoals: Exploring the Potential for AI Teaching Assistants,"15 pages, 6 figures, submitted to CHI 2024",,,,cs.HC cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  With recent advances in generative AI, conversational models like ChatGPT have become feasible candidates for TAs. We investigate the practicality of using generative AI as TAs in introductory programming education by examining novice learners' interaction with TAs in a subgoal learning environment. To compare the learners' interaction and perception of the AI and human TAs, we conducted a between-subject study with 20 novice programming learners. Learners solve programming tasks by producing subgoals and subsolutions with the guidance of a TA. Our study shows that learners can solve tasks faster with comparable scores with AI TAs. Learners' perception of the AI TA is on par with that of human TAs in terms of speed and comprehensiveness of the replies and helpfulness, difficulty, and satisfaction of the conversation. Finally, we suggest guidelines to better design and utilize generative AI as TAs in programming education from the result of our chat log analysis. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 08:30:58 GMT'}]",2023-09-20,"[['Lee', 'Changyoon', ''], ['Myung', 'Junho', ''], ['Han', 'Jieun', ''], ['Jin', 'Jiho', ''], ['Oh', 'Alice', '']]",1,1,2023-09-19,1,5,2,1,0,1,d4d6415001f39c1e66fb27bed771cf315c32a04e,262054293.0,https://www.semanticscholar.org/paper/d4d6415001f39c1e66fb27bed771cf315c32a04e,arXiv.org,2023.0,43.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '151506322', 'name': 'Changyoon Lee'}, {'authorId': '2137320052', 'name': 'Jun-Hee Myung'}, {'authorId': '2243340335', 'name': 'Jieun Han'}, {'authorId': '2165259166', 'name': 'Jiho Jin'}, {'authorId': '2463290', 'name': 'Alice H. Oh'}]",['Korea Advanced Institute of Science and Technology'],['South Korea'],2023-09
2309.10463,Maciej Korczynski,"Nils Begou, Jeremy Vinoy, Andrzej Duda, Maciej Korczynski",Exploring the Dark Side of AI: Advanced Phishing Attack Design and Deployment Using ChatGPT,,"Proceedings of the IEEE Conference on Communications and Network
  Security (CNS), 2023",,,cs.CR cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  This paper explores the possibility of using ChatGPT to develop advanced phishing attacks and automate their large-scale deployment. We make ChatGPT generate the following parts of a phishing attack: i) cloning a targeted website, ii) integrating code for stealing credentials, iii) obfuscating code, iv) automating website deployment on a hosting provider, v) registering a phishing domain name, and vi) integrating the website with a reverse proxy. The initial assessment of the automatically generated phishing kits highlights their rapid generation and deployment process as well as the close resemblance of the resulting pages to the target website. More broadly, we demonstrate that recent advances in AI underscore the potential risks of its misuse in phishing attacks, which can lead to their increased prevalence and severity. This highlights the necessity for enhanced countermeasures within AI systems. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 09:31:39 GMT'}]",2023-09-20,"[['Begou', 'Nils', ''], ['Vinoy', 'Jeremy', ''], ['Duda', 'Andrzej', ''], ['Korczynski', 'Maciej', '']]",1,1,2023-09-19,1,4,2,1,0,1,c5708cd273220947da139ec4d58292d1d3b808ea,262053924.0,https://www.semanticscholar.org/paper/c5708cd273220947da139ec4d58292d1d3b808ea,IEEE Conference on Communications and Network Security,2023.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243236407', 'name': 'Nils Begou'}, {'authorId': '2243233678', 'name': 'Jeremy Vinoy'}, {'authorId': '2243237981', 'name': 'Andrzej Duda'}, {'authorId': '2540125', 'name': 'Maciej Korczyński'}]",['Grenoble Institute of Technology'],['France'],2023-09
2309.10524,Yosuke Higuchi,"Yosuke Higuchi, Tetsuji Ogawa, Tetsunori Kobayashi",Harnessing the Zero-Shot Power of Instruction-Tuned Large Language Model in End-to-End Speech Recognition,Submitted to ICASSP2024,,,,eess.AS cs.CL cs.SD,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present a novel integration of an instruction-tuned large language model (LLM) and end-to-end automatic speech recognition (ASR). Modern LLMs can perform a wide range of linguistic tasks within zero-shot learning when provided with a precise instruction or a prompt to guide the text generation process towards the desired task. We explore using this zero-shot capability of LLMs to extract linguistic information that can contribute to improving ASR performance. Specifically, we direct an LLM to correct grammatical errors in an ASR hypothesis and harness the embedded linguistic knowledge to conduct end-to-end ASR. The proposed model is built on the hybrid connectionist temporal classification (CTC) and attention architecture, where an instruction-tuned LLM (i.e., Llama2) is employed as a front-end of the decoder. An ASR hypothesis, subject to correction, is obtained from the encoder via CTC decoding, which is then fed into the LLM along with an instruction. The decoder subsequently takes as input the LLM embeddings to perform sequence generation, incorporating acoustic information from the encoder output. Experimental results and analyses demonstrate that the proposed integration yields promising performance improvements, and our approach largely benefits from LLM-based rescoring. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 11:10:50 GMT'}]",2023-09-20,"[['Higuchi', 'Yosuke', ''], ['Ogawa', 'Tetsuji', ''], ['Kobayashi', 'Tetsunori', '']]",0,0,2023-09-19,1,3,3,0,0,0,d932b850f67288f79f67b3af747d8c245e003256,262053496.0,https://www.semanticscholar.org/paper/d932b850f67288f79f67b3af747d8c245e003256,arXiv.org,2023.0,47.0,0.0,0.0,True,"['Computer Science', 'Engineering']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '46722767', 'name': 'Yosuke Higuchi'}, {'authorId': '3279652', 'name': 'Tetsuji Ogawa'}, {'authorId': '2110798040', 'name': 'Tetsunori Kobayashi'}]",['Waseda University'],['Japan'],2023-09
2309.10544,Lewis Birch,"Lewis Birch, William Hackett, Stefan Trawicki, Neeraj Suri, Peter
  Garraghan",Model Leeching: An Extraction Attack Targeting LLMs,,,,,cs.LG cs.AI cs.CL cs.CR,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Model Leeching is a novel extraction attack targeting Large Language Models (LLMs), capable of distilling task-specific knowledge from a target LLM into a reduced parameter model. We demonstrate the effectiveness of our attack by extracting task capability from ChatGPT-3.5-Turbo, achieving 73% Exact Match (EM) similarity, and SQuAD EM and F1 accuracy scores of 75% and 87%, respectively for only $50 in API cost. We further demonstrate the feasibility of adversarial attack transferability from an extracted model extracted via Model Leeching to perform ML attack staging against a target LLM, resulting in an 11% increase to attack success rate when applied to ChatGPT-3.5-Turbo. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 11:45:29 GMT'}]",2023-09-20,"[['Birch', 'Lewis', ''], ['Hackett', 'William', ''], ['Trawicki', 'Stefan', ''], ['Suri', 'Neeraj', ''], ['Garraghan', 'Peter', '']]",1,1,2023-09-19,1,5,4,1,0,1,ab2066233ea2da540f44118d989d66db5687752a,262053852.0,https://www.semanticscholar.org/paper/ab2066233ea2da540f44118d989d66db5687752a,arXiv.org,2023.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243227740', 'name': 'Lewis Birch'}, {'authorId': '2243232141', 'name': 'William Hackett'}, {'authorId': '2184771671', 'name': 'Stefan Trawicki'}, {'authorId': '2094514756', 'name': 'N. Suri'}, {'authorId': '3052818', 'name': 'P. Garraghan'}]",['Lancaster University'],['United Kingdom'],2023-09
2309.10563,Nishchal Prasad,"Nishchal Prasad, Mohand Boughanem, Taoufik Dkaki",A Hierarchical Neural Framework for Classification and its Explanation in Large Unstructured Legal Documents,,,,,cs.IR cs.LG,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Automatic legal judgment prediction and its explanation suffer from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents and extracting their explanation becomes a challenging task, more so on documents with no structural annotation. We define this problem as ""scarce annotated legal documents"" and explore their lack of structural information and their long lengths with a deep-learning-based classification framework which we call MESc; ""Multi-stage Encoder-based Supervised with-clustering""; for judgment prediction. We explore the adaptability of LLMs with multi-billion parameters (GPT-Neo, and GPT-J) to legal texts and their intra-domain(legal) transfer learning capacity. Alongside this, we compare their performance and adaptability with MESc and the impact of combining embeddings from their last layers. For such hierarchical models, we also propose an explanation extraction algorithm named ORSE; Occlusion sensitivity-based Relevant Sentence Extractor; based on the input-occlusion sensitivity of the model, to explain the predictions with the most relevant sentences from the document. We explore these methods and test their effectiveness with extensive experiments and ablation studies on legal documents from India, the European Union, and the United States with the ILDC dataset and a subset of the LexGLUE dataset. MESc achieves a minimum total performance gain of approximately 2 points over previous state-of-the-art proposed methods, while ORSE applied on MESc achieves a total average gain of 50% over the baseline explainability scores. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 12:18:28 GMT'}, {'version': 'v2', 'created': 'Mon, 25 Sep 2023 15:10:37 GMT'}]",2023-09-26,"[['Prasad', 'Nishchal', ''], ['Boughanem', 'Mohand', ''], ['Dkaki', 'Taoufik', '']]",0,1,2023-09-19,2,3,2,0,0,0,ba5afd33db5d86bec96cd0ea4555a2dd09a9b08d,262054187.0,https://www.semanticscholar.org/paper/ba5afd33db5d86bec96cd0ea4555a2dd09a9b08d,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2128323637', 'name': 'Nishchal Prasad'}, {'authorId': '47506168', 'name': 'M. Boughanem'}, {'authorId': '2243238642', 'name': 'Taoufik Dkaki'}]",['Toulouse Institute of Computer Science Research'],['France'],2023-09
2309.10621,Bhaskar Mitra,"Paul Thomas, Seth Spielman, Nick Craswell and Bhaskar Mitra",Large language models can accurately predict searcher preferences,,,,,cs.IR cs.AI cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Relevance labels, which indicate whether a search result is valuable to a searcher, are key to evaluating and optimising search systems. The best way to capture the true preferences of users is to ask them for their careful feedback on which results would be useful, but this approach does not scale to produce a large number of labels. Getting relevance labels at scale is usually done with third-party labellers, who judge on behalf of the user, but there is a risk of low-quality data if the labeller doesn't understand user needs. To improve quality, one standard approach is to study real users through interviews, user studies and direct feedback, find areas where labels are systematically disagreeing with users, then educate labellers about user needs through judging guidelines, training and monitoring. This paper introduces an alternate approach for improving label quality. It takes careful feedback from real users, which by definition is the highest-quality first-party gold data that can be derived, and develops an large language model prompt that agrees with that data.   We present ideas and observations from deploying language models for large-scale relevance labelling at Bing, and illustrate with data from TREC. We have found large language models can be effective, with accuracy as good as human labellers and similar capability to pick the hardest queries, best runs, and best groups. Systematic changes to the prompts make a difference in accuracy, but so too do simple paraphrases. To measure agreement with real searchers needs high-quality ``gold'' labels, but with these we find that models produce better labels than third-party workers, for a fraction of the cost, and these labels let us train notably better rankers. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 13:55:39 GMT'}]",2023-09-20,"[['Thomas', 'Paul', ''], ['Spielman', 'Seth', ''], ['Craswell', 'Nick', ''], ['Mitra', 'Bhaskar', '']]",0,0,2023-09-19,1,4,4,0,0,0,68838aba1cc6e20028f9703b96e3517b01972277,262054847.0,https://www.semanticscholar.org/paper/68838aba1cc6e20028f9703b96e3517b01972277,arXiv.org,2023.0,53.0,5.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '41202995', 'name': 'Paul Thomas'}, {'authorId': '2227547996', 'name': 'S. Spielman'}, {'authorId': '1703980', 'name': 'Nick Craswell'}, {'authorId': '116506812', 'name': 'Bhaskar Mitra'}]",['Microsoft'],['Canada'],2023-09
2309.10661,Samuel Cahyawijaya,"Samuel Cahyawijaya, Holy Lovenia, Fajri Koto, Dea Adhista, Emmanuel
  Dave, Sarah Oktavianti, Salsabil Maulana Akbar, Jhonson Lee, Nuur Shadieq,
  Tjeng Wawan Cenggoro, Hanung Wahyuning Linuwih, Bryan Wilie, Galih Pradipta
  Muridan, Genta Indra Winata, David Moeljadi, Alham Fikri Aji, Ayu
  Purwarianti, Pascale Fung",NusaWrites: Constructing High-Quality Corpora for Underrepresented and Extremely Low-Resource Languages,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-sa/4.0/,"  Democratizing access to natural language processing (NLP) technology is crucial, especially for underrepresented and extremely low-resource languages. Previous research has focused on developing labeled and unlabeled corpora for these languages through online scraping and document translation. While these methods have proven effective and cost-efficient, we have identified limitations in the resulting corpora, including a lack of lexical diversity and cultural relevance to local communities. To address this gap, we conduct a case study on Indonesian local languages. We compare the effectiveness of online scraping, human translation, and paragraph writing by native speakers in constructing datasets. Our findings demonstrate that datasets generated through paragraph writing by native speakers exhibit superior quality in terms of lexical diversity and cultural content. In addition, we present the \datasetname{} benchmark, encompassing 12 underrepresented and extremely low-resource languages spoken by millions of individuals in Indonesia. Our empirical experiment results using existing multilingual large language models conclude the need to extend these models to more underrepresented languages. We release the NusaWrites dataset at https://github.com/IndoNLP/nusa-writes. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 14:42:33 GMT'}, {'version': 'v2', 'created': 'Wed, 20 Sep 2023 02:15:50 GMT'}]",2023-09-21,"[['Cahyawijaya', 'Samuel', ''], ['Lovenia', 'Holy', ''], ['Koto', 'Fajri', ''], ['Adhista', 'Dea', ''], ['Dave', 'Emmanuel', ''], ['Oktavianti', 'Sarah', ''], ['Akbar', 'Salsabil Maulana', ''], ['Lee', 'Jhonson', ''], ['Shadieq', 'Nuur', ''], ['Cenggoro', 'Tjeng Wawan', ''], ['Linuwih', 'Hanung Wahyuning', ''], ['Wilie', 'Bryan', ''], ['Muridan', 'Galih Pradipta', ''], ['Winata', 'Genta Indra', ''], ['Moeljadi', 'David', ''], ['Aji', 'Alham Fikri', ''], ['Purwarianti', 'Ayu', ''], ['Fung', 'Pascale', '']]",0,0,2023-09-19,2,18,2,0,0,0,24288671a2a65bb9bcc155fd28f3b28210b850d6,261951742.0,https://www.semanticscholar.org/paper/24288671a2a65bb9bcc155fd28f3b28210b850d6,arXiv.org,2023.0,85.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '66986482', 'name': 'Samuel Cahyawijaya'}, {'authorId': '116344405', 'name': 'Holy Lovenia'}, {'authorId': '2789148', 'name': 'Fajri Koto'}, {'authorId': '2210201739', 'name': 'Dea Adhista'}, {'authorId': '2242161249', 'name': 'Emmanuel Dave'}, {'authorId': '2242159209', 'name': 'Sarah Oktavianti'}, {'authorId': '2242161500', 'name': 'Salsabil Maulana Akbar'}, {'authorId': '2242192851', 'name': 'Jhonson Lee'}, {'authorId': '2242166155', 'name': 'Nuur Shadieq'}, {'authorId': '9455273', 'name': 'T. W. Cenggoro'}, {'authorId': '2242153068', 'name': 'Hanung Wahyuning Linuwih'}, {'authorId': '150048491', 'name': 'Bryan Wilie'}, {'authorId': '2242150539', 'name': 'Galih Pradipta Muridan'}, {'authorId': '9162688', 'name': 'Genta Indra Winata'}, {'authorId': '35722593', 'name': 'David Moeljadi'}, {'authorId': '8129718', 'name': 'Alham Fikri Aji'}, {'authorId': '1962263', 'name': 'A. Purwarianti'}, {'authorId': '40539650', 'name': 'Pascale Fung'}]","['Bandung Institute of Technology', 'Equal Contribution † Equal Contribution', 'Kanda University of International Studies', 'Binus University']","['Indonesia', 'Japan']",2023-09
2309.10677,Yucheng Li,Yucheng Li,Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation,,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Data contamination in model evaluation is getting increasingly prevalent as the massive training corpora of large language models often unintentionally include benchmark samples. Therefore, contamination analysis has became an inevitable part of reliable model evaluation. However, existing method of contamination analysis requires the access of the entire training data which is often confidential for recent models. This prevent the community to rigorously audit these models and conduct accurate assessment of their capability. In this paper, we propose a novel method to quantify contamination without the access of the full training set, that measure the extent of contamination with perplexity. Our analysis provides evidence of significant memorisation of recent foundation models in popular reading comprehension, summarisation benchmarks, while multiple choice appears less contaminated. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 15:02:58 GMT'}, {'version': 'v2', 'created': 'Wed, 27 Sep 2023 01:15:49 GMT'}]",2023-09-28,"[['Li', 'Yucheng', '']]",0,0,2023-09-19,2,1,2,0,0,0,e800ff2229ef60b74663d8fe4e330243729b046c,262055119.0,https://www.semanticscholar.org/paper/e800ff2229ef60b74663d8fe4e330243729b046c,arXiv.org,2023.0,17.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1527099159', 'name': 'Yucheng Li'}]",['University of Surrey'],['United Kingdom'],2023-09
2309.10707,Ting-Yao Hu,"Hsuan Su, Ting-Yao Hu, Hema Swetha Koppula, Raviteja Vemulapalli,
  Jen-Hao Rick Chang, Karren Yang, Gautam Varma Mantena, Oncel Tuzel",Corpus Synthesis for Zero-shot ASR domain Adaptation using Large Language Models,,,,,eess.AS cs.CL cs.LG cs.SD,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  While Automatic Speech Recognition (ASR) systems are widely used in many real-world applications, they often do not generalize well to new domains and need to be finetuned on data from these domains. However, target-domain data usually are not readily available in many scenarios. In this paper, we propose a new strategy for adapting ASR models to new target domains without any text or speech from those domains. To accomplish this, we propose a novel data synthesis pipeline that uses a Large Language Model (LLM) to generate a target domain text corpus, and a state-of-the-art controllable speech synthesis model to generate the corresponding speech. We propose a simple yet effective in-context instruction finetuning strategy to increase the effectiveness of LLM in generating text corpora for new domains. Experiments on the SLURP dataset show that the proposed method achieves an average relative word error rate improvement of $28\%$ on unseen target domains without any performance drop in source domains. ","[{'version': 'v1', 'created': 'Mon, 18 Sep 2023 15:43:08 GMT'}]",2023-09-20,"[['Su', 'Hsuan', ''], ['Hu', 'Ting-Yao', ''], ['Koppula', 'Hema Swetha', ''], ['Vemulapalli', 'Raviteja', ''], ['Chang', 'Jen-Hao Rick', ''], ['Yang', 'Karren', ''], ['Mantena', 'Gautam Varma', ''], ['Tuzel', 'Oncel', '']]",0,0,2023-09-18,1,8,4,0,0,0,0bf089e917d6326a133f3355becdc4f552b66300,262054317.0,https://www.semanticscholar.org/paper/0bf089e917d6326a133f3355becdc4f552b66300,arXiv.org,2023.0,29.0,0.0,0.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2242806865', 'name': 'Hsuan Su'}, {'authorId': '2998709', 'name': 'Ting-yao Hu'}, {'authorId': '1723948', 'name': 'H. Koppula'}, {'authorId': '39963722', 'name': 'Raviteja Vemulapalli'}, {'authorId': '2148969927', 'name': 'Jen-Hao Rick Chang'}, {'authorId': '2242863924', 'name': 'Karren Yang'}, {'authorId': '2119428', 'name': 'G. Mantena'}, {'authorId': '2577513', 'name': 'Oncel Tuzel'}]",['National Taiwan University'],['Taiwan'],2023-09
2309.10744,Hiromu Yakura,Hiromu Yakura,Evaluating large language models' ability to understand metaphor and sarcasm using a screening test for Asperger syndrome,,,,,cs.CL cs.AI cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Metaphors and sarcasm are precious fruits of our highly-evolved social communication skills. However, children with Asperger syndrome are known to have difficulties in comprehending sarcasm, even if they possess a certain level of verbal IQ sufficient for understanding metaphors. Given that, a screening test that scores the ability to understand metaphor and sarcasm has been used to differentiate Asperger syndrome from other symptoms exhibiting akin external behaviors (e.g., attention-deficit/hyperactivity disorder). This study uses the standardized test to examine the capability of recent large language models (LLMs) in understanding human nuanced communication. The results divulged that, whereas their ability to comprehend metaphors has been improved with the increase of the number of model parameters, the improvement in sarcasm understanding was not observed. This implies that an alternative approach is imperative to imbue LLMs with the capacity to grasp sarcasm, which has been associated with the amygdala, a pivotal cerebral region for emotional learning, in the case of humans. ","[{'version': 'v1', 'created': 'Tue, 19 Sep 2023 16:41:19 GMT'}]",2023-09-20,"[['Yakura', 'Hiromu', '']]",0,0,2023-09-19,1,1,3,0,0,0,9d5b25c671a00ff5931b428e3d4f06e8ab1d6d76,262054003.0,https://www.semanticscholar.org/paper/9d5b25c671a00ff5931b428e3d4f06e8ab1d6d76,arXiv.org,2023.0,56.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '33688371', 'name': 'Hiromu Yakura'}]",['University of Tsukuba'],['Japan'],2023-09
2309.11127,Hyelin Nam PhD candidate,"Hyelin Nam, Jihong Park, Jinho Choi, Mehdi Bennis, and Seong-Lyun Kim",Language-Oriented Communication with Semantic Coding and Knowledge Distillation for Text-to-Image Generation,"5 pages, 4 figures, submitted to 2024 IEEE International Conference
  on Acoustics, Speech and Signal Processing",,,,eess.SP cs.AI cs.CL,http://creativecommons.org/publicdomain/zero/1.0/,"  By integrating recent advances in large language models (LLMs) and generative models into the emerging semantic communication (SC) paradigm, in this article we put forward to a novel framework of language-oriented semantic communication (LSC). In LSC, machines communicate using human language messages that can be interpreted and manipulated via natural language processing (NLP) techniques for SC efficiency. To demonstrate LSC's potential, we introduce three innovative algorithms: 1) semantic source coding (SSC) which compresses a text prompt into its key head words capturing the prompt's syntactic essence while maintaining their appearance order to keep the prompt's context; 2) semantic channel coding (SCC) that improves robustness against errors by substituting head words with their lenghthier synonyms; and 3) semantic knowledge distillation (SKD) that produces listener-customized prompts via in-context learning the listener's language style. In a communication task for progressive text-to-image generation, the proposed methods achieve higher perceptual similarities with fewer transmissions while enhancing robustness in noisy communication channels. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 08:19:05 GMT'}]",2023-09-21,"[['Nam', 'Hyelin', ''], ['Park', 'Jihong', ''], ['Choi', 'Jinho', ''], ['Bennis', 'Mehdi', ''], ['Kim', 'Seong-Lyun', '']]",0,0,2023-09-20,1,5,3,0,0,0,914a0f5e7eb98842f220a5082dba4f9382086f27,262063998.0,https://www.semanticscholar.org/paper/914a0f5e7eb98842f220a5082dba4f9382086f27,arXiv.org,2023.0,20.0,1.0,0.0,True,"['Engineering', 'Computer Science']","[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2150706588', 'name': 'Hyelin Nam'}, {'authorId': '48490823', 'name': 'Jihong Park'}, {'authorId': '4724587', 'name': 'Jinho D. Choi'}, {'authorId': '1702172', 'name': 'M. Bennis'}, {'authorId': '2163410193', 'name': 'Seong-Lyun Kim'}]","['Deakin University', 'University of Oulu']","['Finland', 'Australia']",2023-09
2309.11165,Alberto Mu\~noz-Ortiz,Alberto Mu\~noz-Ortiz and David Vilares and Carlos G\'omez-Rodr\'iguez,Assessment of Pre-Trained Models Across Languages and Grammars,Accepted at IJCNLP-AACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We present an approach for assessing how multilingual large language models (LLMs) learn syntax in terms of multi-formalism syntactic structures. We aim to recover constituent and dependency structures by casting parsing as sequence labeling. To do so, we select a few LLMs and study them on 13 diverse UD treebanks for dependency parsing and 10 treebanks for constituent parsing. Our results show that: (i) the framework is consistent across encodings, (ii) pre-trained word vectors do not favor constituency representations of syntax over dependencies, (iii) sub-word tokenization is needed to represent syntax, in contrast to character-based models, and (iv) occurrence of a language in the pretraining data is more important than the amount of task data when recovering syntax from the word vectors. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 09:23:36 GMT'}]",2023-09-21,"[['Muñoz-Ortiz', 'Alberto', ''], ['Vilares', 'David', ''], ['Gómez-Rodríguez', 'Carlos', '']]",0,0,2023-09-20,1,3,1,0,0,0,d28d94dd981e55003230e18c931387da29ebb47b,262063988.0,https://www.semanticscholar.org/paper/d28d94dd981e55003230e18c931387da29ebb47b,arXiv.org,2023.0,55.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2123454646', 'name': 'Alberto Muñoz-Ortiz'}, {'authorId': '3259155', 'name': 'David Vilares'}, {'authorId': '2450508', 'name': 'Carlos Gómez-Rodríguez'}]","['Departamento de Ciencias de la Computación y Tecnologías de la Información Campus de Elviña s/n, 15071 A Coruña, Spain', 'University of A Coruña']",['Spain'],2023-09
2309.11197,Imanol Schlag,"Aleksandar Stani\'c, Dylan Ashley, Oleg Serikov, Louis Kirsch,
  Francesco Faccio, J\""urgen Schmidhuber, Thomas Hofmann, Imanol Schlag",The Languini Kitchen: Enabling Language Modelling Research at Different Scales of Compute,,,,,cs.LG cs.CL,http://creativecommons.org/licenses/by/4.0/,"  The Languini Kitchen serves as both a research collective and codebase designed to empower researchers with limited computational resources to contribute meaningfully to the field of language modelling. We introduce an experimental protocol that enables model comparisons based on equivalent compute, measured in accelerator hours. The number of tokens on which a model is trained is defined by the model's throughput and the chosen compute class. Notably, this approach avoids constraints on critical hyperparameters which affect total parameters or floating-point operations. For evaluation, we pre-process an existing large, diverse, and high-quality dataset of books that surpasses existing academic benchmarks in quality, diversity, and document length. On it, we compare methods based on their empirical scaling trends which are estimated through experiments at various levels of compute. This work also provides two baseline models: a feed-forward model derived from the GPT-2 architecture and a recurrent model in the form of a novel LSTM with ten-fold throughput. While the GPT baseline achieves better perplexity throughout all our levels of compute, our LSTM baseline exhibits a predictable and more favourable scaling law. This is due to the improved throughput and the need for fewer training tokens to achieve the same decrease in test perplexity. Extrapolating the scaling laws leads of both models results in an intersection at roughly 50,000 accelerator hours. We hope this work can serve as the foundation for meaningful and reproducible language modelling research. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 10:31:17 GMT'}]",2023-09-21,"[['Stanić', 'Aleksandar', ''], ['Ashley', 'Dylan', ''], ['Serikov', 'Oleg', ''], ['Kirsch', 'Louis', ''], ['Faccio', 'Francesco', ''], ['Schmidhuber', 'Jürgen', ''], ['Hofmann', 'Thomas', ''], ['Schlag', 'Imanol', '']]",0,1,2023-09-20,1,8,2,1,1,0,77b046c5d568b329a927cfc895ea2e6c8f43ff43,262064942.0,https://www.semanticscholar.org/paper/77b046c5d568b329a927cfc895ea2e6c8f43ff43,arXiv.org,2023.0,94.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2064448663', 'name': 'Aleksandar Stanic'}, {'authorId': '2243276279', 'name': 'Dylan Ashley'}, {'authorId': '2243266019', 'name': 'Oleg Serikov'}, {'authorId': '3031520', 'name': 'Louis Kirsch'}, {'authorId': '79787170', 'name': 'Francesco Faccio'}, {'authorId': '145341374', 'name': 'J. Schmidhuber'}, {'authorId': '2243267340', 'name': 'Thomas Hofmann'}, {'authorId': '35328044', 'name': 'Imanol Schlag'}]","['The Swiss AI Lab IDSIA/USI/SUPSI ‡ AI Initiative,', 'King Abdullah University of Science and Technology']",['Saudi Arabia'],2023-09
2309.11231,Jonnathan Berrezueta-Guzman,"Jonnathan Berrezueta-Guzman, Laura Malache-Silva and Stephan Krusche",ChatGPT-4 as a Tool for Reviewing Academic Books in Spanish,"Preprint. Paper accepted in the 18\textsuperscript{th} Latin American
  Conference on Learning Technologies (LACLO 2023), 14 pages",,,,cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This study evaluates the potential of ChatGPT-4, an artificial intelligence language model developed by OpenAI, as an editing tool for Spanish literary and academic books. The need for efficient and accessible reviewing and editing processes in the publishing industry has driven the search for automated solutions. ChatGPT-4, being one of the most advanced language models, offers notable capabilities in text comprehension and generation. In this study, the features and capabilities of ChatGPT-4 are analyzed in terms of grammatical correction, stylistic coherence, and linguistic enrichment of texts in Spanish. Tests were conducted with 100 literary and academic texts, where the edits made by ChatGPT-4 were compared to those made by expert human reviewers and editors. The results show that while ChatGPT-4 is capable of making grammatical and orthographic corrections with high accuracy and in a very short time, it still faces challenges in areas such as context sensitivity, bibliometric analysis, deep contextual understanding, and interaction with visual content like graphs and tables. However, it is observed that collaboration between ChatGPT-4 and human reviewers and editors can be a promising strategy for improving efficiency without compromising quality. Furthermore, the authors consider that ChatGPT-4 represents a valuable tool in the editing process, but its use should be complementary to the work of human editors to ensure high-caliber editing in Spanish literary and academic books. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 11:44:45 GMT'}]",2023-09-21,"[['Berrezueta-Guzman', 'Jonnathan', ''], ['Malache-Silva', 'Laura', ''], ['Krusche', 'Stephan', '']]",1,1,2023-09-20,1,3,1,1,0,1,88e27f48bdd7edbfb7360c37dedc2bf61f27d1b9,262063914.0,https://www.semanticscholar.org/paper/88e27f48bdd7edbfb7360c37dedc2bf61f27d1b9,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '1409264877', 'name': 'Jonnathan Berrezueta-Guzman'}, {'authorId': '2243284866', 'name': 'Laura Malache-Silva'}, {'authorId': '2244619339', 'name': 'Stephan Krusche'}]","['Technical University of Munich', 'Corporación Ecuatoriana para el Desarrollo de la Investigación y la Academia']","['Germany', 'Ecuador']",2023-09
2309.11259,Vladimir Araujo,"Vladimir Araujo, Maria Mihaela Trusca, Rodrigo Tufi\~no,
  Marie-Francine Moens",Sequence-to-Sequence Spanish Pre-trained Language Models,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In recent years, substantial advancements in pre-trained language models have paved the way for the development of numerous non-English language versions, with a particular focus on encoder-only and decoder-only architectures. While Spanish language models encompassing BERT, RoBERTa, and GPT have exhibited prowess in natural language understanding and generation, there remains a scarcity of encoder-decoder models designed for sequence-to-sequence tasks involving input-output pairs. This paper breaks new ground by introducing the implementation and evaluation of renowned encoder-decoder architectures, exclusively pre-trained on Spanish corpora. Specifically, we present Spanish versions of BART, T5, and BERT2BERT-style models and subject them to a comprehensive assessment across a diverse range of sequence-to-sequence tasks, spanning summarization, rephrasing, and generative question answering. Our findings underscore the competitive performance of all models, with BART and T5 emerging as top performers across all evaluated tasks. As an additional contribution, we have made all models publicly available to the research community, fostering future exploration and development in Spanish language processing. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 12:35:19 GMT'}]",2023-09-21,"[['Araujo', 'Vladimir', ''], ['Trusca', 'Maria Mihaela', ''], ['Tufiño', 'Rodrigo', ''], ['Moens', 'Marie-Francine', '']]",0,1,2023-09-20,1,4,3,1,1,0,d2f7661e026ffe3155c4dd8c151b7a8c2364397d,262067504.0,https://www.semanticscholar.org/paper/d2f7661e026ffe3155c4dd8c151b7a8c2364397d,arXiv.org,2023.0,49.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2243014355', 'name': 'Vladimir Araujo'}, {'authorId': '1491292346', 'name': 'Maria Mihaela Truşcǎ'}, {'authorId': '2243296994', 'name': 'Rodrigo Tufino'}, {'authorId': '1802161', 'name': 'M. Moens'}]",['Politecnica Salesiana University'],['Ecuador'],2023-09
2309.11285,Areg Mikael Sarvazyan,"Areg Mikael Sarvazyan, Jos\'e \'Angel Gonz\'alez, Marc
  Franco-Salvador, Francisco Rangel, Berta Chulvi, Paolo Rosso",Overview of AuTexTification at IberLEF 2023: Detection and Attribution of Machine-Generated Text in Multiple Domains,Accepted at SEPLN 2023,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  This paper presents the overview of the AuTexTification shared task as part of the IberLEF 2023 Workshop in Iberian Languages Evaluation Forum, within the framework of the SEPLN 2023 conference. AuTexTification consists of two subtasks: for Subtask 1, participants had to determine whether a text is human-authored or has been generated by a large language model. For Subtask 2, participants had to attribute a machine-generated text to one of six different text generation models. Our AuTexTification 2023 dataset contains more than 160.000 texts across two languages (English and Spanish) and five domains (tweets, reviews, news, legal, and how-to articles). A total of 114 teams signed up to participate, of which 36 sent 175 runs, and 20 of them sent their working notes. In this overview, we present the AuTexTification dataset and task, the submitted participating systems, and the results. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 13:10:06 GMT'}]",2023-09-21,"[['Sarvazyan', 'Areg Mikael', ''], ['González', 'José Ángel', ''], ['Franco-Salvador', 'Marc', ''], ['Rangel', 'Francisco', ''], ['Chulvi', 'Berta', ''], ['Rosso', 'Paolo', '']]",0,0,2023-09-20,1,6,3,0,0,0,c3b09dde03c65f53e046f8cce5201de6a6f17dbe,262055483.0,https://www.semanticscholar.org/paper/c3b09dde03c65f53e046f8cce5201de6a6f17dbe,Proces. del Leng. Natural,2023.0,66.0,8.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2241540449', 'name': 'A. Sarvazyan'}, {'authorId': '2242065237', 'name': 'José Ángel González'}, {'authorId': '1403862010', 'name': 'Marc Franco-Salvador'}, {'authorId': '133975199', 'name': 'Francisco Rangel'}, {'authorId': '4696191', 'name': 'Berta Chulvi'}, {'authorId': '143752702', 'name': 'Paolo Rosso'}]","['Symanto Research, Valencia, Spain', 'Universitat Politècnica de València']",['Spain'],2023-09
2309.11295,Ofir Ben Shoham,"Ofir Ben Shoham, Nadav Rappoport",CPLLM: Clinical Prediction with Large Language Models,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We present Clinical Prediction with Large Language Models (CPLLM), a method that involves fine-tuning a pre-trained Large Language Model (LLM) for clinical disease prediction. We utilized quantization and fine-tuned the LLM using prompts, with the task of predicting whether patients will be diagnosed with a target disease during their next visit or in the subsequent diagnosis, leveraging their historical diagnosis records. We compared our results versus various baselines, including Logistic Regression, RETAIN, and Med-BERT, which is the current state-of-the-art model for disease prediction using structured EHR data. Our experiments have shown that CPLLM surpasses all the tested models in terms of both PR-AUC and ROC-AUC metrics, displaying noteworthy enhancements compared to the baseline models. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 13:24:12 GMT'}]",2023-09-21,"[['Shoham', 'Ofir Ben', ''], ['Rappoport', 'Nadav', '']]",0,0,2023-09-20,1,2,3,0,0,0,048ed2240412b684ff88ddf6aac7152d04e5d233,261975024.0,https://www.semanticscholar.org/paper/048ed2240412b684ff88ddf6aac7152d04e5d233,arXiv.org,2023.0,48.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '2218035287', 'name': 'Ofir Ben Shoham'}, {'authorId': '3001854', 'name': 'Nadav Rappoport'}]",['Ben-Gurion University of the Negev'],['Israel'],2023-09
2309.11392,Siqing Huo,"Siqing Huo, Negar Arabzadeh, Charles L. A. Clarke",Retrieving Supporting Evidence for Generative Question Answering,arXiv admin note: text overlap with arXiv:2306.13781,"Annual International ACM SIGIR Conference on Research and
  Development in Information Retrieval in the Asia Pacific Region (SIGIR-AP
  '23), November 26--28, 2023, Beijing, China",10.1145/3624918.3625336,,cs.IR,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering. Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report two simple experiments to automatically validate generated answers against a corpus. We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers. In the first experiment, we validate the generated answer in its entirety. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer. In the second experiment, we consider the generated answer at a more granular level, prompting the LLM to extract a list of factual statements from the answer and verifying each statement separately. We query the corpus with each factual statement and then present the LLM with the statement and the corresponding retrieved evidence. The LLM is prompted to indicate if the statement can be supported and make necessary edits using the retrieved material. With an accuracy of over 80%, we find that an LLM is capable of verifying its generated answer when a corpus of supporting material is provided. However, manual assessment of a random sample of questions reveals that incorrect generated answers are missed by this verification process. While this verification process can reduce hallucinations, it can not entirely eliminate them. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 15:16:42 GMT'}]",2023-09-29,"[['Huo', 'Siqing', ''], ['Arabzadeh', 'Negar', ''], ['Clarke', 'Charles L. A.', '']]",0,0,2023-09-20,1,3,1,0,0,0,0630a18fe3fe4765132ad52a591f9776cf3284bf,262063818.0,https://www.semanticscholar.org/paper/0630a18fe3fe4765132ad52a591f9776cf3284bf,arXiv.org,2023.0,43.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2220538755', 'name': 'Siqing Huo'}, {'authorId': '81447039', 'name': 'Negar Arabzadeh'}, {'authorId': '2242866162', 'name': 'Charles L. A. Clarke'}]",['University of Waterloo'],['Canada'],2023-09
2309.11427,Sewoong Lee,"Sewoong Lee, JinKyou Choi and Min Su Kim",Generative Pre-Training of Time-Series Data for Unsupervised Fault Detection in Semiconductor Manufacturing,,,,,cs.LG cs.AI,http://creativecommons.org/licenses/by/4.0/,"  This paper introduces TRACE-GPT, which stands for Time-seRies Anomaly-detection with Convolutional Embedding and Generative Pre-trained Transformers. TRACE-GPT is designed to pre-train univariate time-series sensor data and detect faults on unlabeled datasets in semiconductor manufacturing. In semiconductor industry, classifying abnormal time-series sensor data from normal data is important because it is directly related to wafer defect. However, small, unlabeled, and even mixed training data without enough anomalies make classification tasks difficult. In this research, we capture features of time-series data with temporal convolutional embedding and Generative Pre-trained Transformer (GPT) to classify abnormal sequences from normal sequences using cross entropy loss. We prove that our model shows better performance than previous unsupervised models with both an open dataset, the University of California Riverside (UCR) time-series classification archive, and the process log of our Chemical Vapor Deposition (CVD) equipment. Our model has the highest F1 score at Equal Error Rate (EER) across all datasets and is only 0.026 below the supervised state-of-the-art baseline on the open dataset. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 16:01:45 GMT'}]",2023-09-21,"[['Lee', 'Sewoong', ''], ['Choi', 'JinKyou', ''], ['Kim', 'Min Su', '']]",0,1,2023-09-20,1,3,2,0,0,0,2e3d41b82671e4aefe0e30b8f97cea0fc2de0415,262063918.0,https://www.semanticscholar.org/paper/2e3d41b82671e4aefe0e30b8f97cea0fc2de0415,arXiv.org,2023.0,65.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243280279', 'name': 'Sewoong Lee'}, {'authorId': '2243944402', 'name': 'JinKyou Choi'}, {'authorId': '2242863673', 'name': 'Min Su Kim'}]",['Samsung'],['South Korea'],2023-09
2309.11439,Masahiro Kaneko,"Masahiro Kaneko, Naoaki Okazaki",Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction,Work in progress,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  In Grammatical Error Correction (GEC), it is crucial to ensure the user's comprehension of a reason for correction. Existing studies present tokens, examples, and hints as to the basis for correction but do not directly explain the reasons for corrections. Although methods that use Large Language Models (LLMs) to provide direct explanations in natural language have been proposed for various tasks, no such method exists for GEC. Generating explanations for GEC corrections involves aligning input and output tokens, identifying correction points, and presenting corresponding explanations consistently. However, it is not straightforward to specify a complex format to generate explanations, because explicit control of generation is difficult with prompts. This study introduces a method called controlled generation with Prompt Insertion (PI) so that LLMs can explain the reasons for corrections in natural language. In PI, LLMs first correct the input text, and then we automatically extract the correction points based on the rules. The extracted correction points are sequentially inserted into the LLM's explanation output as prompts, guiding the LLMs to generate explanations for the correction points. We also create an Explainable GEC (XGEC) dataset of correction reasons by annotating NUCLE, CoNLL2013, and CoNLL2014. Although generations from GPT-3 and ChatGPT using original prompts miss some correction points, the generation control using PI can explicitly guide to describe explanations for all correction points, contributing to improved performance in generating correction reasons. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 16:14:10 GMT'}]",2023-09-21,"[['Kaneko', 'Masahiro', ''], ['Okazaki', 'Naoaki', '']]",1,1,2023-09-20,1,2,1,2,0,2,ebac8b472511bb1c53fe7e7b3decdb9493a484ce,262064965.0,https://www.semanticscholar.org/paper/ebac8b472511bb1c53fe7e7b3decdb9493a484ce,arXiv.org,2023.0,32.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '143655216', 'name': 'Masahiro Kaneko'}, {'authorId': '1764004', 'name': 'Naoaki Okazaki'}]",['Tokyo Institute of Technology'],['Japan'],2023-09
2309.11508,Johannes Schneider,"Johannes Schneider, Bernd Schenk, Christina Niklaus, Michaelis Vlachos",Towards LLM-based Autograding for Short Textual Answers,,,,,cs.CL cs.AI,http://creativecommons.org/publicdomain/zero/1.0/,"  Grading of exams is an important, labor intensive, subjective, repetitive and frequently challenging task. The feasibility of autograding textual responses has greatly increased thanks to the availability of large language models (LLMs) such as ChatGPT and because of the substantial influx of data brought about by digitalization. However, entrusting AI models with decision-making roles raises ethical considerations, mainly stemming from potential biases and issues related to generating false information. Thus, in this manuscript we provide an evaluation of a large language model for the purpose of autograding, while also highlighting how LLMs can support educators in validating their grading procedures. Our evaluation is targeted towards automatic short textual answers grading (ASAG), spanning various languages and examinations from two distinct courses. Our findings suggest that while ""out-of-the-box"" LLMs provide a valuable tool to provide a complementary perspective, their readiness for independent automated grading remains a work in progress, necessitating human oversight. ","[{'version': 'v1', 'created': 'Sat, 9 Sep 2023 22:25:56 GMT'}]",2023-09-22,"[['Schneider', 'Johannes', ''], ['Schenk', 'Bernd', ''], ['Niklaus', 'Christina', ''], ['Vlachos', 'Michaelis', '']]",1,1,2023-09-09,1,4,2,1,0,1,386c22dc924d0090b82b713ae9f553f1be91bf87,262083885.0,https://www.semanticscholar.org/paper/386c22dc924d0090b82b713ae9f553f1be91bf87,arXiv.org,2023.0,28.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243339708', 'name': 'Johannes Schneider'}, {'authorId': '2243336019', 'name': 'Bernd Schenk'}, {'authorId': '2243335058', 'name': 'Christina Niklaus'}, {'authorId': '2243334843', 'name': 'Michaelis Vlachos'}]","['University of Lausanne', 'University of Liechtenstein', 'University of St. Gallen']","['Switzerland', 'Liechtenstein']",2023-09
2309.11668,Vivek Iyer,"Vivek Iyer, Pinzhen Chen and Alexandra Birch",Towards Effective Disambiguation for Machine Translation with Large Language Models,"10 pages, 3 figures",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Resolving semantic ambiguity has long been recognised as a central challenge in the field of machine translation. Recent work on benchmarking translation performance on ambiguous sentences has exposed the limitations of conventional Neural Machine Translation (NMT) systems, which fail to capture many of these cases. Large language models (LLMs) have emerged as a promising alternative, demonstrating comparable performance to traditional NMT models while introducing new paradigms for controlling the target outputs. In this paper, we study the capabilities of LLMs to translate ambiguous sentences containing polysemous words and rare word senses. We also propose two ways to improve the handling of such ambiguity through in-context learning and fine-tuning on carefully curated ambiguous datasets. Experiments show that our methods can match or outperform state-of-the-art systems such as DeepL and NLLB in four out of five language directions. Our research provides valuable insights into effectively adapting LLMs for disambiguation during machine translation. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 22:22:52 GMT'}]",2023-09-22,"[['Iyer', 'Vivek', ''], ['Chen', 'Pinzhen', ''], ['Birch', 'Alexandra', '']]",0,0,2023-09-20,1,3,1,1,1,0,5ca0a9e4c0277e379740f889f00c79ddf507569c,262083660.0,https://www.semanticscholar.org/paper/5ca0a9e4c0277e379740f889f00c79ddf507569c,arXiv.org,2023.0,54.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1742526965', 'name': 'Vivek Iyer'}, {'authorId': '143616669', 'name': 'Pinzhen Chen'}, {'authorId': '2539211', 'name': 'Alexandra Birch'}]",['University of Edinburgh'],['United Kingdom'],2023-09
2309.11669,He Bai,"Ali Mousavi, Xin Zhan, He Bai, Peng Shi, Theo Rekatsinas, Benjamin
  Han, Yunyao Li, Jeff Pound, Josh Susskind, Natalie Schluter, Ihab Ilyas,
  Navdeep Jaitly",Construction of Paired Knowledge Graph-Text Datasets Informed by Cyclic Evaluation,16 pages,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Datasets that pair Knowledge Graphs (KG) and text together (KG-T) can be used to train forward and reverse neural models that generate text from KG and vice versa. However models trained on datasets where KG and text pairs are not equivalent can suffer from more hallucination and poorer recall. In this paper, we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination. We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset. Using cyclic evaluation we find that manually created WebNLG is much better than automatically created TeKGen and T-REx. Guided by these observations, we construct a new, improved dataset called LAGRANGE using heuristics meant to improve equivalence between KG and text and show the impact of each of the heuristics on cyclic evaluation. We also construct two synthetic datasets using large language models (LLMs), and observe that these are conducive to models that perform significantly well on cyclic generation of text, but less so on cyclic generation of KGs, probably because of a lack of a consistent underlying ontology. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 22:30:20 GMT'}]",2023-09-22,"[['Mousavi', 'Ali', ''], ['Zhan', 'Xin', ''], ['Bai', 'He', ''], ['Shi', 'Peng', ''], ['Rekatsinas', 'Theo', ''], ['Han', 'Benjamin', ''], ['Li', 'Yunyao', ''], ['Pound', 'Jeff', ''], ['Susskind', 'Josh', ''], ['Schluter', 'Natalie', ''], ['Ilyas', 'Ihab', ''], ['Jaitly', 'Navdeep', '']]",0,0,2023-09-20,1,12,1,0,0,0,bb86a2592e9efa196aefd6bbc39bf62a3202e9db,262084176.0,https://www.semanticscholar.org/paper/bb86a2592e9efa196aefd6bbc39bf62a3202e9db,arXiv.org,2023.0,25.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243336632', 'name': 'Ali Mousavi'}, {'authorId': '2243337763', 'name': 'Xin Zhan'}, {'authorId': '37374479', 'name': 'He Bai'}, {'authorId': '2243340600', 'name': 'Peng Shi'}, {'authorId': '2243336634', 'name': 'Theo Rekatsinas'}, {'authorId': '2243377351', 'name': 'Benjamin Han'}, {'authorId': '1718694', 'name': 'Yunyao Li'}, {'authorId': '2243336030', 'name': 'Jeff Pound'}, {'authorId': '2243336902', 'name': 'Josh Susskind'}, {'authorId': '2243335295', 'name': 'Natalie Schluter'}, {'authorId': '2243335549', 'name': 'Ihab Ilyas'}, {'authorId': '3111912', 'name': 'N. Jaitly'}]",['University of Waterloo'],['Canada'],2023-09
2309.11672,Munyeong Kim,Munyeong Kim and Sungsu Kim,Generative AI in Mafia-like Game Simulation,"26 pages, 3 figures; data, scripts, and codes:
  https://github.com/MunyeongKim/Gen-AI-in-Mafia- like-Game",,,,cs.AI cs.HC,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  In this research, we explore the efficacy and potential of Generative AI models, specifically focusing on their application in role-playing simulations exemplified through Spyfall, a renowned mafia-style game. By leveraging GPT-4's advanced capabilities, the study aimed to showcase the model's potential in understanding, decision-making, and interaction during game scenarios. Comparative analyses between GPT-4 and its predecessor, GPT-3.5-turbo, demonstrated GPT-4's enhanced adaptability to the game environment, with significant improvements in posing relevant questions and forming human-like responses. However, challenges such as the model;s limitations in bluffing and predicting opponent moves emerged. Reflections on game development, financial constraints, and non-verbal limitations of the study were also discussed. The findings suggest that while GPT-4 exhibits promising advancements over earlier models, there remains potential for further development, especially in instilling more human-like attributes in AI. ","[{'version': 'v1', 'created': 'Wed, 20 Sep 2023 22:38:34 GMT'}]",2023-09-22,"[['Kim', 'Munyeong', ''], ['Kim', 'Sungsu', '']]",0,1,2023-09-20,1,2,2,2,0,2,6626e28dcc3ece3ffed897a875766af7c7386732,262084115.0,https://www.semanticscholar.org/paper/6626e28dcc3ece3ffed897a875766af7c7386732,arXiv.org,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2243411670', 'name': 'Munyeong Kim'}, {'authorId': '2243680074', 'name': 'Sungsu Kim'}]",['Kyungpook National University'],['South Korea'],2023-09
2309.11852,Yoichi Ishibashi,"Yoichi Ishibashi, Hidetoshi Shimodaira",Knowledge Sanitization of Large Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We explore a knowledge sanitization approach to mitigate the privacy concerns associated with large language models (LLMs). LLMs trained on a large corpus of Web data can memorize and potentially reveal sensitive or confidential information, raising critical security concerns. Our technique fine-tunes these models, prompting them to generate harmless responses such as ``I don't know'' when queried about specific information. Experimental results in a closed-book question-answering task show that our straightforward method not only minimizes particular knowledge leakage but also preserves the overall performance of LLM. These two advantages strengthen the defense against extraction attacks and reduces the emission of harmful content such as hallucinations. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 07:49:55 GMT'}]",2023-09-22,"[['Ishibashi', 'Yoichi', ''], ['Shimodaira', 'Hidetoshi', '']]",0,0,2023-09-21,1,2,1,0,0,0,db95150f29a37d8736037af7506ca7c63331e097,262083936.0,https://www.semanticscholar.org/paper/db95150f29a37d8736037af7506ca7c63331e097,arXiv.org,2023.0,38.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2059148476', 'name': 'Yoichi Ishibashi'}, {'authorId': '48162944', 'name': 'H. Shimodaira'}]",['Kyoto University'],['Japan'],2023-09
2309.11981,Pedro Moya,"Patricio Vera, Pedro Moya and Lisa Barraza",Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics,"14 pages, 1 table, 2 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 11:34:52 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Sep 2023 03:33:58 GMT'}, {'version': 'v3', 'created': 'Thu, 5 Oct 2023 02:58:52 GMT'}]",2023-10-06,"[['Vera', 'Patricio', ''], ['Moya', 'Pedro', ''], ['Barraza', 'Lisa', '']]",0,0,2023-09-21,3,3,2,0,0,0,33c3b99d9c05aadeff992e65aeb1c086c7ef5ba8,262084375.0,https://www.semanticscholar.org/paper/33c3b99d9c05aadeff992e65aeb1c086c7ef5ba8,arXiv.org,2023.0,151.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243336975', 'name': 'Patricio Vera'}, {'authorId': '2243335072', 'name': 'Pedro Moya'}, {'authorId': '2243335641', 'name': 'Lisa Barraza'}]","['Neurocreaciones, Las Condes, Santiago, Chile.']",['Chile'],2023-09
2309.12071,Matheus Santos Bachelor,Matheus L. O. Santos and Cl\'audio E. C. Campelo,Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam,"8 pages, 6 figures, 4 tables",,,,cs.AI cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  Although Large Language Models (LLMs) represent a revolution in the way we interact with computers, allowing the construction of complex questions and the ability to reason over a sequence of statements, their use is restricted due to the need for dedicated hardware for execution. In this study, we evaluate the performance of LLMs based on the 7 and 13 billion LLaMA models, subjected to a quantization process and run on home hardware. The models considered were Alpaca, Koala, and Vicuna. To evaluate the effectiveness of these models, we developed a database containing 1,006 questions from the ENEM (Brazilian National Secondary School Exam). Our analysis revealed that the best performing models achieved an accuracy of approximately 46% for the original texts of the Portuguese questions and 49% on their English translations. In addition, we evaluated the computational efficiency of the models by measuring the time required for execution. On average, the 7 and 13 billion LLMs took approximately 20 and 50 seconds, respectively, to process the queries on a machine equipped with an AMD Ryzen 5 3600x processor ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 13:39:54 GMT'}]",2023-09-22,"[['Santos', 'Matheus L. O.', ''], ['Campelo', 'Cláudio E. C.', '']]",0,0,2023-09-21,1,2,2,4,3,1,9d32573d364fefb42b2833c44c36f87ad46897cc,262084119.0,https://www.semanticscholar.org/paper/9d32573d364fefb42b2833c44c36f87ad46897cc,arXiv.org,2023.0,17.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244570745', 'name': 'Matheus L. O. Santos'}, {'authorId': '2237987101', 'name': ""Cl'audio E. C. Campelo""}]",['Universidade Federal de Campina Grande'],['Brazil'],2023-09
2309.12074,Giulia Polverini,"Giulia Polverini, Bor Gregorcic",How understanding large language models can inform their use in physics education,,,,,physics.ed-ph,http://creativecommons.org/licenses/by/4.0/,"  The paper aims to fulfil three main functions: (1) to serve as an introduction for the physics education community to the functioning of Large Language Models (LLMs), (2) to present a series of illustrative examples demonstrating how prompt-engineering techniques can impact LLMs performance on conceptual physics tasks and (3) to discuss potential implications of the understanding of LLMs and prompt engineering for physics teaching and learning. We first summarise existing research on the performance of a popular LLM-based chatbot (ChatGPT) on physics tasks. We then give a basic account of how LLMs work, illustrate essential features of their functioning, and discuss their strengths and limitations. Equipped with this knowledge, we discuss some challenges with generating useful output with ChatGPT-4 in the context of introductory physics, paying special attention to conceptual questions and problems. We then provide a condensed overview of relevant literature on prompt engineering and demonstrate through illustrative examples how selected prompt-engineering techniques can be employed to improve ChatGPT-4's output on conceptual introductory physics problems. Qualitatively studying these examples provides additional insights into ChatGPT's functioning and its utility in physics problem solving. Finally, we consider how insights from the paper can inform the use of LMMs in the teaching and learning of physics. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 13:42:57 GMT'}]",2023-09-22,"[['Polverini', 'Giulia', ''], ['Gregorcic', 'Bor', '']]",1,1,2023-09-21,1,2,1,1,0,1,d651380f8c99f2522ead2d86d60cb4af4413abfa,262083876.0,https://www.semanticscholar.org/paper/d651380f8c99f2522ead2d86d60cb4af4413abfa,,2023.0,85.0,1.0,1.0,False,['Physics'],"[{'category': 'Physics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2243337671', 'name': 'Giulia Polverini'}, {'authorId': '66357374', 'name': 'B. Gregorcic'}]",['Uppsala University'],['Sweden'],2023-09
2309.12263,Xenia Ohmer,"Leon Ackermann, Xenia Ohmer",On the Relationship between Skill Neurons and Robustness in Prompt Tuning,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs). Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task. In this paper, we study the robustness of Prompt Tuning in relation to these ""skill neurons"", using RoBERTa and T5. We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa. At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5. Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa. We conclude that higher adversarial robustness may be related to a model's ability to activate the relevant skill neurons on adversarial data. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 17:13:21 GMT'}]",2023-09-22,"[['Ackermann', 'Leon', ''], ['Ohmer', 'Xenia', '']]",0,0,2023-09-21,1,2,1,1,1,0,4407da6ff9b06b00b2a5a93f5c4d333875207811,262084034.0,https://www.semanticscholar.org/paper/4407da6ff9b06b00b2a5a93f5c4d333875207811,arXiv.org,2023.0,21.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2243382301', 'name': 'Leon Ackermann'}, {'authorId': '4573107', 'name': 'Xenia Ohmer'}]",['Osnabrück University'],['Germany'],2023-09
2309.12269,Alexander Terenin,"Andreas \""Ostling and Holli Sargeant and Huiyuan Xie and Ludwig Bull
  and Alexander Terenin and Leif Jonsson and M{\aa}ns Magnusson and Felix
  Steffek",The Cambridge Law Corpus: A Corpus for Legal AI Research,,"Advances in Neural Information Processing Systems, Datasets and
  Benchmarks Track, 2023",,,cs.CL cs.CY stat.AP,http://creativecommons.org/licenses/by/4.0/,"  We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 17:24:40 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Sep 2023 19:35:21 GMT'}]",2023-09-26,"[['Östling', 'Andreas', ''], ['Sargeant', 'Holli', ''], ['Xie', 'Huiyuan', ''], ['Bull', 'Ludwig', ''], ['Terenin', 'Alexander', ''], ['Jonsson', 'Leif', ''], ['Magnusson', 'Måns', ''], ['Steffek', 'Felix', '']]",0,1,2023-09-21,2,8,3,2,0,2,99ad058e5ae063490399d854a95dfcf917527cae,262083849.0,https://www.semanticscholar.org/paper/99ad058e5ae063490399d854a95dfcf917527cae,arXiv.org,2023.0,61.0,0.0,0.0,True,"['Computer Science', 'Mathematics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}]","[{'authorId': '2243335823', 'name': 'Andreas Ostling'}, {'authorId': '2161835433', 'name': 'Holli Sargeant'}, {'authorId': '2243370272', 'name': 'Huiyuan Xie'}, {'authorId': '2243334454', 'name': 'Ludwig Bull'}, {'authorId': '2243337188', 'name': 'Alexander Terenin'}, {'authorId': '37414560', 'name': 'Leif Jonsson'}, {'authorId': '89105040', 'name': 'Maans Magnusson'}, {'authorId': '2243334550', 'name': 'Felix Steffek'}]","['University of Cambridge', 'Uppsala University']","['United Kingdom', 'Sweden']",2023-09
2309.12288,Owain Evans,"Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper
  Stickland, Tomasz Korbak, Owain Evans","The Reversal Curse: LLMs trained on ""A is B"" fail to learn ""B is A""","18 pages, 10 figures",,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form ""A is B"", it will not automatically generalize to the reverse direction ""B is A"". This is the Reversal Curse. For instance, if a model is trained on ""Olaf Scholz was the ninth Chancellor of Germany"", it will not automatically be able to answer the question, ""Who was the ninth Chancellor of Germany?"". Moreover, the likelihood of the correct answer (""Olaf Scholz"") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if ""A is B'' occurs, ""B is A"" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as ""Uriah Hawthorne is the composer of 'Abyssal Melodies'"" and showing that they fail to correctly answer ""Who composed 'Abyssal Melodies?'"". The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as ""Who is Tom Cruise's mother? [A: Mary Lee Pfeiffer]"" and the reverse ""Who is Mary Lee Pfeiffer's son?"". GPT-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter. This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse. Code is available at https://github.com/lukasberglund/reversal_curse. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 17:52:19 GMT'}, {'version': 'v2', 'created': 'Fri, 22 Sep 2023 18:08:20 GMT'}]",2023-09-26,"[['Berglund', 'Lukas', ''], ['Tong', 'Meg', ''], ['Kaufmann', 'Max', ''], ['Balesni', 'Mikita', ''], ['Stickland', 'Asa Cooper', ''], ['Korbak', 'Tomasz', ''], ['Evans', 'Owain', '']]",1,1,2023-09-21,2,7,3,4,1,3,8eafec7014d08043517834b5a2ed26384f188873,262083829.0,https://www.semanticscholar.org/paper/8eafec7014d08043517834b5a2ed26384f188873,arXiv.org,2023.0,34.0,17.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237798380', 'name': 'Lukas Berglund'}, {'authorId': '2237797264', 'name': 'Meg Tong'}, {'authorId': '2237795846', 'name': 'Max Kaufmann'}, {'authorId': '2237797134', 'name': 'Mikita Balesni'}, {'authorId': '68974453', 'name': 'Asa Cooper Stickland'}, {'authorId': '2237795801', 'name': 'Tomasz Korbak'}, {'authorId': '47107786', 'name': 'Owain Evans'}]",['University of Oxford'],['United Kingdom'],2023-09
2309.12331,Myke Healy,Myke Healy,"Approaches to Generative Artificial Intelligence, A Social Justice Perspective","12 pages, 3 figures, 14 references",,10.13140/RG.2.2.24788.78723,,cs.CY cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In the 2023-2024 academic year, the widespread availability of generative artificial intelligence, exemplified by ChatGPT's 1.6 billion monthly visits, is set to impact academic integrity. With 77% of high school students previously reporting engagement in dishonest behaviour, the rise of AI-driven writing assistance, dubbed 'AI-giarism' by Chan (arXiv:2306.03358v2), will make plagiarism more accessible and less detectable. While these concerns are urgent, they also raise broader questions about the revolutionary nature of this technology, including autonomy, data privacy, copyright, and equity. This paper aims to explore generative AI from a social justice perspective, examining the training of these models, the inherent biases, and the potential injustices in detecting AI-generated writing. ","[{'version': 'v1', 'created': 'Thu, 17 Aug 2023 06:30:46 GMT'}]",2023-09-25,"[['Healy', 'Myke', '']]",1,1,2023-08-17,1,1,2,1,0,1,d1e8f6e015a06c8ae298d41fd4456b8a1257de27,261486853.0,https://www.semanticscholar.org/paper/d1e8f6e015a06c8ae298d41fd4456b8a1257de27,Social Science Research Network,2023.0,13.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2237338971', 'name': 'Myke Healy'}]",['University of Calgary'],['Canada'],2023-08
2309.12342,Reem Masoud,"Reem I. Masoud, Ziquan Liu, Martin Ferianc, Philip Treleaven, Miguel
  Rodrigues",Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions,31 pages,,,,cs.CY cs.CL cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The deployment of large language models (LLMs) raises concerns regarding their cultural misalignment and potential ramifications on individuals from various cultural norms. Existing work investigated political and social biases and public opinions rather than their cultural values. To address this limitation, the proposed Cultural Alignment Test (CAT) quantifies cultural alignment using Hofstede's cultural dimension framework, which offers an explanatory cross-cultural comparison through the latent variable analysis. We apply our approach to assess the cultural values embedded in state-of-the-art LLMs, such as: ChatGPT and Bard, across diverse cultures of countries: United States (US), Saudi Arabia, China, and Slovakia, using different prompting styles and hyperparameter settings. Our results not only quantify cultural alignment of LLMs with certain countries, but also reveal the difference between LLMs in explanatory cultural dimensions. While all LLMs did not provide satisfactory results in understanding cultural values, GPT-4 exhibited the highest CAT score for the cultural values of the US. ","[{'version': 'v1', 'created': 'Fri, 25 Aug 2023 14:50:13 GMT'}]",2023-09-25,"[['Masoud', 'Reem I.', ''], ['Liu', 'Ziquan', ''], ['Ferianc', 'Martin', ''], ['Treleaven', 'Philip', ''], ['Rodrigues', 'Miguel', '']]",1,1,2023-08-25,1,5,3,2,0,2,3d682feaba804468217d27cf3f1e1db202cfca86,262216989.0,https://www.semanticscholar.org/paper/3d682feaba804468217d27cf3f1e1db202cfca86,arXiv.org,2023.0,74.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2244620002', 'name': 'Reem I. Masoud'}, {'authorId': '2244737557', 'name': 'Ziquan Liu'}, {'authorId': '100998451', 'name': 'Martin Ferianc'}, {'authorId': '2265550541', 'name': 'Philip C. Treleaven'}, {'authorId': '2150940135', 'name': 'Miguel Rodrigues'}]","['University College London', 'King Abdulaziz University']","['Saudi Arabia', 'United Kingdom']",2023-08
2309.12348,Christos-Nikolaos Anagnostopoulos,Christos-Nikolaos Anagnostopoulos,ChatGPT impacts in programming education: A recent literature overview that debates ChatGPT responses,16 pages,,,,cs.CY,http://creativecommons.org/licenses/by/4.0/,"  This paper aims at a brief overview of the main impact of ChatGTP in the scientific field of programming and learning/education in computer science. It lists, covers and documents from the literature the major issues that have been identified for this topic, such as applications, advantages and limitations, ethical issues raised. Answers to the above questions were solicited from ChatGPT itself, the responses were collected, and then the recent literature was surveyed to determine whether or not the responses are supported. The paper ends with a short discussion on what is expected to happen in the near future. A future that can be extremely promising if humanity manages to have AI as a proper ally and partner, with distinct roles and specific rules of cooperation and interaction. ","[{'version': 'v1', 'created': 'Wed, 30 Aug 2023 06:41:57 GMT'}, {'version': 'v2', 'created': 'Tue, 26 Sep 2023 12:12:21 GMT'}]",2023-09-27,"[['Anagnostopoulos', 'Christos-Nikolaos', '']]",1,1,2023-08-30,2,1,1,1,0,1,d9cdf3fb84bd84171a8387aee48a15cc1b69f65a,262216957.0,https://www.semanticscholar.org/paper/d9cdf3fb84bd84171a8387aee48a15cc1b69f65a,F1000Research,2023.0,60.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2238001421', 'name': 'Christos-Nikolaos Anagnostopoulos'}]",['University of the Aegean'],['Greece'],2023-08
2309.12415,Alexandre Bonlarron,"Alexandre Bonlarron, Aur\'elie Calabr\`ese, Pierre Kornprobst,
  Jean-Charles R\'egin",Constraints First: A New MDD-based Model to Generate Sentences Under Constraints,"To be published in Proceedings of the Thirty-Second International
  Joint Conference on Artificial Intelligence, IJCAI 2023","Proceedings of the Thirty-Second International Joint Conference on
  Artificial Intelligence Main Track. Pages 1893-1901. Year 2023",10.24963/ijcai.2023/210,,cs.AI cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  This paper introduces a new approach to generating strongly constrained texts. We consider standardized sentence generation for the typical application of vision screening. To solve this problem, we formalize it as a discrete combinatorial optimization problem and utilize multivalued decision diagrams (MDD), a well-known data structure to deal with constraints. In our context, one key strength of MDD is to compute an exhaustive set of solutions without performing any search. Once the sentences are obtained, we apply a language model (GPT-2) to keep the best ones. We detail this for English and also for French where the agreement and conjugation rules are known to be more complex. Finally, with the help of GPT-2, we get hundreds of bona-fide candidate sentences. When compared with the few dozen sentences usually available in the well-known vision screening test (MNREAD), this brings a major breakthrough in the field of standardized sentence generation. Also, as it can be easily adapted for other languages, it has the potential to make the MNREAD test even more valuable and usable. More generally, this paper highlights MDD as a convincing alternative for constrained text generation, especially when the constraints are hard to satisfy, but also for many other prospects. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 18:29:52 GMT'}]",2023-09-25,"[['Bonlarron', 'Alexandre', ''], ['Calabrèse', 'Aurélie', ''], ['Kornprobst', 'Pierre', ''], ['Régin', 'Jean-Charles', '']]",0,1,2023-09-21,1,4,2,1,1,0,af4071e8674b32d71df41f3b3111678cbe2a2097,260850223.0,https://www.semanticscholar.org/paper/af4071e8674b32d71df41f3b3111678cbe2a2097,International Joint Conference on Artificial Intelligence,2023.0,61.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2231483801', 'name': 'Alexandre Bonlarron'}, {'authorId': '39160383', 'name': 'Aurélie Calabrèse'}, {'authorId': '2796589', 'name': 'Pierre Kornprobst'}, {'authorId': '1710771', 'name': 'Jean-Charles Régin'}]","[""Université Côte d'Azur"", 'Aix-Marseille University']",['France'],2023-09
2309.12481,Leonardo Ranaldi Mr,"Leonardo Ranaldi, Fabio Massimo Zanzotto","HANS, are you clever? Clever Hans Effect Analysis of Neural Systems",,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Instruction-tuned Large Language Models (It-LLMs) have been exhibiting outstanding abilities to reason around cognitive states, intentions, and reactions of all people involved, letting humans guide and comprehend day-to-day social interactions effectively. In fact, several multiple-choice questions (MCQ) benchmarks have been proposed to construct solid assessments of the models' abilities. However, earlier works are demonstrating the presence of inherent ""order bias"" in It-LLMs, posing challenges to the appropriate evaluation. In this paper, we investigate It-LLMs' resilience abilities towards a series of probing tests using four MCQ benchmarks. Introducing adversarial examples, we show a significant performance gap, mainly when varying the order of the choices, which reveals a selection bias and brings into discussion reasoning abilities. Following a correlation between first positions and model choices due to positional bias, we hypothesized the presence of structural heuristics in the decision-making process of the It-LLMs, strengthened by including significant examples in few-shot scenarios. Finally, by using the Chain-of-Thought (CoT) technique, we elicit the model to reason and mitigate the bias by obtaining more robust models. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 20:52:18 GMT'}]",2023-09-29,"[['Ranaldi', 'Leonardo', ''], ['Zanzotto', 'Fabio Massimo', '']]",0,0,2023-09-21,1,2,2,0,0,0,a1f755c7c6405820e8d8abfcc8205badbd7c907d,262217567.0,https://www.semanticscholar.org/paper/a1f755c7c6405820e8d8abfcc8205badbd7c907d,arXiv.org,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","[{'authorId': '2008183566', 'name': 'Leonardo Ranaldi'}, {'authorId': '103839825', 'name': 'F. M. Zanzotto'}]","['University of Rome Tor Vergata', 'Idiap Research Institute']","['Switzerland', 'Italy']",2023-09
2309.12485,Nicolas Yax,"Nicolas Yax, Hernan Anll\'o, Stefano Palminteri",Studying and improving reasoning in humans and machines,"The paper is split in 4 parts : main text (pages 2-27), methods
  (pages 28-34), technical appendix (pages 35-45) and supplementary methods
  (pages 46-125)",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  In the present study, we investigate and compare reasoning in large language models (LLM) and humans using a selection of cognitive psychology tools traditionally dedicated to the study of (bounded) rationality. To do so, we presented to human participants and an array of pretrained LLMs new variants of classical cognitive experiments, and cross-compared their performances. Our results showed that most of the included models presented reasoning errors akin to those frequently ascribed to error-prone, heuristic-based human reasoning. Notwithstanding this superficial similarity, an in-depth comparison between humans and LLMs indicated important differences with human-like reasoning, with models limitations disappearing almost entirely in more recent LLMs releases. Moreover, we show that while it is possible to devise strategies to induce better performance, humans and machines are not equally-responsive to the same prompting schemes. We conclude by discussing the epistemological implications and challenges of comparing human and machine behavior for both artificial intelligence and cognitive psychology. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 21:02:05 GMT'}]",2023-09-25,"[['Yax', 'Nicolas', ''], ['Anlló', 'Hernan', ''], ['Palminteri', 'Stefano', '']]",0,0,2023-09-21,1,3,3,0,0,0,ff4acf33aeafcbe7d12afdc6bb9ca26537219658,262217235.0,https://www.semanticscholar.org/paper/ff4acf33aeafcbe7d12afdc6bb9ca26537219658,arXiv.org,2023.0,0.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '2238327629', 'name': 'Nicolas Yax'}, {'authorId': '2244622476', 'name': ""Hernan Anll'o""}, {'authorId': '6286029', 'name': 'Stefano Palminteri'}]","["") Département d'études cognitives, Ecole normale supérieure, Paris, France"", 'Inserm']",['France'],2023-09
2309.12499,Ramakrishna Bairi,"Ramakrishna Bairi, Atharv Sonwane, Aditya Kanade, Vageesh D C, Arun
  Iyer, Suresh Parthasarathy, Sriram Rajamani, B. Ashok, Shashank Shet",CodePlan: Repository-level Coding using LLMs and Planning,,,,,cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Software engineering activities such as package migration, fixing errors reports from static analysis or testing, and adding type annotations or other specifications to a codebase, involve pervasively editing the entire repository of code. We formulate these activities as repository-level coding tasks.   Recent tools like GitHub Copilot, which are powered by Large Language Models (LLMs), have succeeded in offering high-quality solutions to localized coding problems. Repository-level coding tasks are more involved and cannot be solved directly using LLMs, since code within a repository is inter-dependent and the entire repository may be too large to fit into the prompt. We frame repository-level coding as a planning problem and present a task-agnostic framework, called CodePlan to solve it. CodePlan synthesizes a multi-step chain of edits (plan), where each step results in a call to an LLM on a code location with context derived from the entire repository, previous code changes and task-specific instructions. CodePlan is based on a novel combination of an incremental dependency analysis, a change may-impact analysis and an adaptive planning algorithm.   We evaluate the effectiveness of CodePlan on two repository-level tasks: package migration (C#) and temporal code edits (Python). Each task is evaluated on multiple code repositories, each of which requires inter-dependent changes to many files (between 2-97 files). Coding tasks of this level of complexity have not been automated using LLMs before. Our results show that CodePlan has better match with the ground truth compared to baselines. CodePlan is able to get 5/6 repositories to pass the validity checks (e.g., to build without errors and make correct code edits) whereas the baselines (without planning but with the same type of contextual information as CodePlan) cannot get any of the repositories to pass them. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 21:45:17 GMT'}]",2023-09-25,"[['Bairi', 'Ramakrishna', ''], ['Sonwane', 'Atharv', ''], ['Kanade', 'Aditya', ''], ['C', 'Vageesh D', ''], ['Iyer', 'Arun', ''], ['Parthasarathy', 'Suresh', ''], ['Rajamani', 'Sriram', ''], ['Ashok', 'B.', ''], ['Shet', 'Shashank', '']]",0,0,2023-09-21,1,9,1,0,0,0,f81a1b4510631d14b5b565c4701ee056f8d5c72f,262217135.0,https://www.semanticscholar.org/paper/f81a1b4510631d14b5b565c4701ee056f8d5c72f,arXiv.org,2023.0,88.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1823210', 'name': 'Ramakrishna Bairi'}, {'authorId': '2133345604', 'name': 'Atharv Sonwane'}, {'authorId': '2244618470', 'name': 'Aditya Kanade'}, {'authorId': '2244619725', 'name': 'C. VageeshD'}, {'authorId': '2397529', 'name': 'Arun Shankar Iyer'}, {'authorId': '145022639', 'name': 'Suresh Parthasarathy'}, {'authorId': '1685546', 'name': 'S. Rajamani'}, {'authorId': '2244620879', 'name': 'B. Ashok'}, {'authorId': '2215149902', 'name': 'Shashank P. Shet'}]",['Microsoft'],['India'],2023-09
2309.12546,Zifan Wang,"Zifan Wang, Kotaro Funakoshi, Manabu Okumura",Automatic Answerability Evaluation for Question Generation,,,,,cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Conventional automatic evaluation metrics, such as BLEU and ROUGE, developed for natural language generation (NLG) tasks, are based on measuring the n-gram overlap between the generated and reference text. These simple metrics may be insufficient for more complex tasks, such as question generation (QG), which requires generating questions that are answerable by the reference answers. Developing a more sophisticated automatic evaluation metric, thus, remains as an urgent problem in QG research. This work proposes a Prompting-based Metric on ANswerability (PMAN), a novel automatic evaluation metric to assess whether the generated questions are answerable by the reference answers for the QG tasks. Extensive experiments demonstrate that its evaluation results are reliable and align with human evaluations. We further apply our metric to evaluate the performance of QG models, which shows our metric complements conventional metrics. Our implementation of a ChatGPT-based QG model achieves state-of-the-art (SOTA) performance in generating answerable questions. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 00:13:07 GMT'}]",2023-09-25,"[['Wang', 'Zifan', ''], ['Funakoshi', 'Kotaro', ''], ['Okumura', 'Manabu', '']]",1,1,2023-09-22,1,3,1,1,0,1,1f85894177102405583f04ec848540df8413f121,262217090.0,https://www.semanticscholar.org/paper/1f85894177102405583f04ec848540df8413f121,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244876181', 'name': 'Zifan Wang'}, {'authorId': '2241813927', 'name': 'Kotaro Funakoshi'}, {'authorId': '2241832740', 'name': 'Manabu Okumura'}]",['Tokyo Institute of Technology'],['Japan'],2023-09
2309.12551,Vatsal Raina,"Asma Farajidizaji, Vatsal Raina, Mark Gales",Is it Possible to Modify Text to a Target Readability Level? An Initial Investigation Using Zero-Shot Large Language Models,"11 pages, 4 figures, 5 tables",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Text simplification is a common task where the text is adapted to make it easier to understand. Similarly, text elaboration can make a passage more sophisticated, offering a method to control the complexity of reading comprehension tests. However, text simplification and elaboration tasks are limited to only relatively alter the readability of texts. It is useful to directly modify the readability of any text to an absolute target readability level to cater to a diverse audience. Ideally, the readability of readability-controlled generated text should be independent of the source text. Therefore, we propose a novel readability-controlled text modification task. The task requires the generation of 8 versions at various target readability levels for each input text. We introduce novel readability-controlled text modification metrics. The baselines for this task use ChatGPT and Llama-2, with an extension approach introducing a two-step process (generating paraphrases by passing through the language model twice). The zero-shot approaches are able to push the readability of the paraphrases in the desired direction but the final readability remains correlated with the original text's readability. We also find greater drops in semantic and lexical similarity between the source and target texts with greater shifts in the readability. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 00:47:18 GMT'}]",2023-09-25,"[['Farajidizaji', 'Asma', ''], ['Raina', 'Vatsal', ''], ['Gales', 'Mark', '']]",1,1,2023-09-22,1,3,1,2,1,1,d4611ea61f2361193d781f33042860993f1f41f8,262217495.0,https://www.semanticscholar.org/paper/d4611ea61f2361193d781f33042860993f1f41f8,arXiv.org,2023.0,63.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244623443', 'name': 'Asma Farajidizaji'}, {'authorId': '2119533381', 'name': 'Vatsal Raina'}, {'authorId': '2239200722', 'name': 'Mark Gales'}]",['University of Cambridge'],['United Kingdom'],2023-09
2309.12616,Shruti Singh,"Shruti Singh, Hitesh Lodwal, Husain Malwat, Rakesh Thakur, Mayank
  Singh",Unlocking Model Insights: A Dataset for Automated Model Card Generation,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Language models (LMs) are no longer restricted to ML community, and instruction-tuned LMs have led to a rise in autonomous AI agents. As the accessibility of LMs grows, it is imperative that an understanding of their capabilities, intended usage, and development cycle also improves. Model cards are a popular practice for documenting detailed information about an ML model. To automate model card generation, we introduce a dataset of 500 question-answer pairs for 25 ML models that cover crucial aspects of the model, such as its training configurations, datasets, biases, architecture details, and training resources. We employ annotators to extract the answers from the original paper. Further, we explore the capabilities of LMs in generating model cards by answering questions. Our initial experiments with ChatGPT-3.5, LLaMa, and Galactica showcase a significant gap in the understanding of research papers by these aforementioned LMs as well as generating factual textual responses. We posit that our dataset can be used to train models to automate the generation of model cards from paper text and reduce human effort in the model card curation process. The complete dataset is available on https://osf.io/hqt7p/?view_only=3b9114e3904c4443bcd9f5c270158d37 ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 04:46:11 GMT'}]",2023-09-25,"[['Singh', 'Shruti', ''], ['Lodwal', 'Hitesh', ''], ['Malwat', 'Husain', ''], ['Thakur', 'Rakesh', ''], ['Singh', 'Mayank', '']]",1,1,2023-09-22,1,5,1,2,1,1,509ac49d4360c8bcb328a6ac458db3ab0fdec30c,262217385.0,https://www.semanticscholar.org/paper/509ac49d4360c8bcb328a6ac458db3ab0fdec30c,arXiv.org,2023.0,54.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '14918655', 'name': 'Shruti Singh'}, {'authorId': '2244622578', 'name': 'Hitesh Lodwal'}, {'authorId': '2244623998', 'name': 'Husain Malwat'}, {'authorId': '2244624119', 'name': 'Rakesh Thakur'}, {'authorId': '145431050', 'name': 'Mayank Singh'}]",['Indian Institute of Technology Gandhinagar'],['India'],2023-09
2309.12727,Eric Nuertey Coleman,"Eric Nuertey Coleman, Julio Hurtado, Vincenzo Lomonaco",In-context Interference in Chat-based Large Language Models,,,,,cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have had a huge impact on society due to their impressive capabilities and vast knowledge of the world. Various applications and tools have been created that allow users to interact with these models in a black-box scenario. However, one limitation of this scenario is that users cannot modify the internal knowledge of the model, and the only way to add or modify internal knowledge is by explicitly mentioning it to the model during the current interaction. This learning process is called in-context training, and it refers to training that is confined to the user's current session or context. In-context learning has significant applications, but also has limitations that are seldom studied. In this paper, we present a study that shows how the model can suffer from interference between information that continually flows in the context, causing it to forget previously learned knowledge, which can reduce the model's performance. Along with showing the problem, we propose an evaluation benchmark based on the bAbI dataset. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 09:18:55 GMT'}]",2023-09-25,"[['Coleman', 'Eric Nuertey', ''], ['Hurtado', 'Julio', ''], ['Lomonaco', 'Vincenzo', '']]",0,0,2023-09-22,1,3,2,0,0,0,4f9ebbb53e93fa5821b599d00e9beff6322821ef,262217189.0,https://www.semanticscholar.org/paper/4f9ebbb53e93fa5821b599d00e9beff6322821ef,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244619371', 'name': 'Eric Nuertey Coleman'}, {'authorId': '2064859104', 'name': 'J. Hurtado'}, {'authorId': '2055550', 'name': 'Vincenzo Lomonaco'}]",['University of Pisa'],['Italy'],2023-09
2309.12731,Dave Raggett,Dave Raggett,Defeasible Reasoning with Knowledge Graphs,"Accepted for: Knowledge Graph and Semantic Web Conference
  (KGSWC-2023), 13-15 September, 2023, Zaragoza, Spain",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Human knowledge is subject to uncertainties, imprecision, incompleteness and inconsistencies. Moreover, the meaning of many everyday terms is dependent on the context. That poses a huge challenge for the Semantic Web. This paper introduces work on an intuitive notation and model for defeasible reasoning with imperfect knowledge, and relates it to previous work on argumentation theory. PKN is to N3 as defeasible reasoning is to deductive logic. Further work is needed on an intuitive syntax for describing reasoning strategies and tactics in declarative terms, drawing upon the AIF ontology for inspiration. The paper closes with observations on symbolic approaches in the era of large language models. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 09:27:26 GMT'}]",2023-09-25,"[['Raggett', 'Dave', '']]",0,0,2023-09-22,1,1,1,0,0,0,c64d514bfe26e5617f4c65664b3c136d5fd8ec89,262217168.0,https://www.semanticscholar.org/paper/c64d514bfe26e5617f4c65664b3c136d5fd8ec89,Iberoamerican Conference on Knowledge Graphs and Semantic Web,2023.0,15.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244620860', 'name': 'Dave Raggett'}]",['European Research Consortium for Informatics and Mathematics'],['France'],2023-09
2309.12732,Lefteris Moussiades Dr,Lefteris Moussiades and George Zografos,OpenAi's GPT4 as coding assistant,10 pages,,,,cs.AI cs.SE,http://creativecommons.org/licenses/by/4.0/,"  Lately, Large Language Models have been widely used in code generation. GPT4 is considered the most potent Large Language Model from Openai. In this paper, we examine GPT3.5 and GPT4 as coding assistants. More specifically, we have constructed appropriate tests to check whether the two systems can a) answer typical questions that can arise during the code development, b) produce reliable code, and c) contribute to code debugging. The test results are impressive. The performance of GPT4 is outstanding and signals an increase in the productivity of programmers and the reorganization of software development procedures based on these new tools. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 09:31:39 GMT'}]",2023-09-25,"[['Moussiades', 'Lefteris', ''], ['Zografos', 'George', '']]",0,1,2023-09-22,1,2,2,2,0,2,36c4f0d16cb1c4d805f259c1e84063ad27b9cd24,262217453.0,https://www.semanticscholar.org/paper/36c4f0d16cb1c4d805f259c1e84063ad27b9cd24,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2078527', 'name': 'Lefteris Moussiades'}, {'authorId': '144290926', 'name': 'G. Zografos'}]",['International Hellenic University'],['Greece'],2023-09
2309.12813,Hasan Ferit Eniser,"Hasan Ferit Eniser, Valentin W\""ustholz, Maria Christakis",Automatically Testing Functional Properties of Code Translation Models,13 pages including appendix and references,,,,cs.SE cs.LG cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models are becoming increasingly practical for translating code across programming languages, a process known as $transpiling$. Even though automated transpilation significantly boosts developer productivity, a key concern is whether the generated code is correct. Existing work initially used manually crafted test suites to test the translations of a small corpus of programs; these test suites were later automated. In contrast, we devise the first approach for automated, functional, property-based testing of code translation models. Our general, user-provided specifications about the transpiled code capture a range of properties, from purely syntactic to purely semantic ones. As shown by our experiments, this approach is very effective in detecting property violations in popular code translation models, and therefore, in evaluating model quality with respect to given properties. We also go a step further and explore the usage scenario where a user simply aims to obtain a correct translation of some code with respect to certain properties without necessarily being concerned about the overall quality of the model. To this purpose, we develop the first property-guided search procedure for code translation models, where a model is repeatedly queried with slightly different parameters to produce alternative and potentially more correct translations. Our results show that this search procedure helps to obtain significantly better code translations. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 11:00:15 GMT'}]",2023-09-25,"[['Eniser', 'Hasan Ferit', ''], ['Wüstholz', 'Valentin', ''], ['Christakis', 'Maria', '']]",0,0,2023-09-07,1,3,3,0,0,0,033b934bafa666b21d02047de5af6d00b9e983e1,262217299.0,https://www.semanticscholar.org/paper/033b934bafa666b21d02047de5af6d00b9e983e1,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2113090', 'name': 'Hasan Ferit Eniser'}, {'authorId': '2021178', 'name': 'Valentin Wüstholz'}, {'authorId': '2606785', 'name': 'M. Christakis'}]","['ConsenSys, Austria', 'TU Wien', 'Max Planck Institute for Software Systems']","['Germany', 'Austria']",2023-09
2309.12863,Emad Alghamdi Dr,"Emad A. Alghamdi, Jezia Zakraoui, Fares A. Abanmy",Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts,,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Neural machine translation (NMT) has shown impressive performance when trained on large-scale corpora. However, generic NMT systems have demonstrated poor performance on out-of-domain translation. To mitigate this issue, several domain adaptation methods have recently been proposed which often lead to better translation quality than genetic NMT systems. While there has been some continuous progress in NMT for English and other European languages, domain adaption in Arabic has received little attention in the literature. The current study, therefore, aims to explore the effectiveness of domain-specific adaptation for Arabic MT (AMT), in yet unexplored domain, financial news articles. To this end, we developed carefully a parallel corpus for Arabic-English (AR- EN) translation in the financial domain for benchmarking different domain adaptation methods. We then fine-tuned several pre-trained NMT and Large Language models including ChatGPT-3.5 Turbo on our dataset. The results showed that the fine-tuning is successful using just a few well-aligned in-domain AR-EN segments. The quality of ChatGPT translation was superior than other models based on automatic and human evaluations. To the best of our knowledge, this is the first work on fine-tuning ChatGPT towards financial domain transfer learning. To contribute to research in domain translation, we made our datasets and fine-tuned models available at https://huggingface.co/asas-ai/. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 13:37:19 GMT'}]",2023-09-25,"[['Alghamdi', 'Emad A.', ''], ['Zakraoui', 'Jezia', ''], ['Abanmy', 'Fares A.', '']]",1,1,2023-09-22,1,3,2,1,0,1,ea71600d6ffccd7ef99325db282afe462326b1c8,262217530.0,https://www.semanticscholar.org/paper/ea71600d6ffccd7ef99325db282afe462326b1c8,arXiv.org,2023.0,65.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '3366968', 'name': 'Emad A. Alghamdi'}, {'authorId': '73768293', 'name': 'Jezia Zakraoui'}, {'authorId': '2244622893', 'name': 'Fares A. Abanmy'}]",['King Abdulaziz University'],['Saudi Arabia'],2023-09
2309.12871,Xianming Li,"Xianming Li, Jing Li",AnglE-optimized Text Embeddings,"NLP, Text Embedding, Semantic Textual Similarity",,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  High-quality text embedding is pivotal in improving semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. However, a common challenge existing text embedding models face is the problem of vanishing gradients, primarily due to their reliance on the cosine function in the optimization objective, which has saturation zones. To address this issue, this paper proposes a novel angle-optimized text embedding model called AnglE. The core idea of AnglE is to introduce angle optimization in a complex space. This novel approach effectively mitigates the adverse effects of the saturation zone in the cosine function, which can impede gradient and hinder optimization processes. To set up a comprehensive STS evaluation, we experimented on existing short-text STS datasets and a newly collected long-text STS dataset from GitHub Issues. Furthermore, we examine domain-specific STS scenarios with limited labeled data and explore how AnglE works with LLM-annotated data. Extensive experiments were conducted on various tasks including short-text STS, long-text STS, and domain-specific STS tasks. The results show that AnglE outperforms the state-of-the-art (SOTA) STS models that ignore the cosine saturation zone. These findings demonstrate the ability of AnglE to generate high-quality text embeddings and the usefulness of angle optimization in STS. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 13:52:42 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Oct 2023 02:53:29 GMT'}]",2023-10-06,"[['Li', 'Xianming', ''], ['Li', 'Jing', '']]",0,0,2023-09-22,2,2,3,0,0,0,20d0dbcdcf9356396086fe1bbd77637f65b9da1f,262217025.0,https://www.semanticscholar.org/paper/20d0dbcdcf9356396086fe1bbd77637f65b9da1f,arXiv.org,2023.0,50.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244698613', 'name': 'Xianming Li'}, {'authorId': '2256795636', 'name': 'Jing Li'}]",['Hong Kong Polytechnic University'],['Hong Kong'],2023-09
2309.12938,Nalin Wadhwa,"Nalin Wadhwa, Jui Pradhan, Atharv Sonwane, Surya Prakash Sahu,
  Nagarajan Natarajan, Aditya Kanade, Suresh Parthasarathy, Sriram Rajamani",Frustrated with Code Quality Issues? LLMs can Help!,,,,,cs.AI cs.SE,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues. We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The \emph{proposer LLM} of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, the LLM may introduce subtle, unintended functionality changes which may go un-detected by the static analysis. The \emph{ranker LLM} evaluates the changes made by the proposer using a rubric that closely follows the acceptance criteria that a developer would enforce. CORE uses the scores assigned by the ranker LLM to rank the candidate revisions before presenting them to the developer. CORE could revise 59.2% Python files (across 52 quality checks) so that they pass scrutiny by both a tool and a human reviewer. The ranker LLM is able to reduce false positives by 25.8% in these cases. CORE produced revisions that passed the static analysis tool in 76.8% Java files (across 10 quality checks) comparable to 78.3% of a specialized program repair tool, with significantly much less engineering efforts. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 15:37:07 GMT'}]",2023-09-25,"[['Wadhwa', 'Nalin', ''], ['Pradhan', 'Jui', ''], ['Sonwane', 'Atharv', ''], ['Sahu', 'Surya Prakash', ''], ['Natarajan', 'Nagarajan', ''], ['Kanade', 'Aditya', ''], ['Parthasarathy', 'Suresh', ''], ['Rajamani', 'Sriram', '']]",0,0,2023-09-22,1,8,2,0,0,0,87c8a1540993f8a99138a112d2a68bebfe62d0c6,262216950.0,https://www.semanticscholar.org/paper/87c8a1540993f8a99138a112d2a68bebfe62d0c6,arXiv.org,2023.0,52.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2244618408', 'name': 'Nalin Wadhwa'}, {'authorId': '2244618531', 'name': 'Jui Pradhan'}, {'authorId': '2133345604', 'name': 'Atharv Sonwane'}, {'authorId': '2185411106', 'name': 'Surya Prakash Sahu'}, {'authorId': '2244618406', 'name': 'Nagarajan Natarajan'}, {'authorId': '2244618470', 'name': 'Aditya Kanade'}, {'authorId': '145022639', 'name': 'Suresh Parthasarathy'}, {'authorId': '1685546', 'name': 'S. Rajamani'}]",['Microsoft'],['India'],2023-09
2309.13053,Myke Healy,Myke Healy,Using Curriculum Theory to Inform Approaches to Generative AI in Schools,14 pages,,,,cs.CY cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  In an educational landscape dramatically altered by the swift proliferation of Large Language Models, this essay interrogates the urgent this essay interrogates the urgent pedagogical modifications required in secondary schooling. Anchored in Madeline Grumet's triadic framework of curriculum inquiry, the study delineates the multifaceted relationship between Generative AI and Elliot Eisner's explicit, implicit, and null curriculum concepts. It scrutinizes the logistical and ethical challenges, such as the reliability of AI detectors, that educators confront when attempting to assimilate this nascent technology into long-standing curricular structures. Engaging with Ted Aoki's theory of the ""zone of between"", the essay illuminates educators' dilemmas in reconciling prescriptive curricular aims with the fluid realities of classroom life, all within an educational milieu in constant flux due to Generative AI. The paper culminates in a reflective analysis by the researcher, identifying avenues for further scholarly investigation within each of Grumet's constitutive strands of curriculum theory, thereby providing a roadmap for future research on Generative AI's transformative impact on educational practice. ","[{'version': 'v1', 'created': 'Thu, 7 Sep 2023 05:38:36 GMT'}]",2023-09-26,"[['Healy', 'Myke', '']]",0,0,2023-09-07,1,1,2,0,0,0,e7e9db3f99bd0a8d69ee73f95f0fe86c4619fa70,261856209.0,https://www.semanticscholar.org/paper/e7e9db3f99bd0a8d69ee73f95f0fe86c4619fa70,Social Science Research Network,2023.0,17.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2237338971', 'name': 'Myke Healy'}]",['University of Calgary'],['Canada'],2023-09
2309.13078,Ryutaro Yamauchi,"Ryutaro Yamauchi, Sho Sonoda, Akiyoshi Sannai, Wataru Kumagai",LPML: LLM-Prompting Markup Language for Mathematical Reasoning,,,,,cs.AI cs.LG cs.PL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In utilizing large language models (LLMs) for mathematical reasoning, addressing the errors in the reasoning and calculation present in the generated text by LLMs is a crucial challenge. In this paper, we propose a novel framework that integrates the Chain-of-Thought (CoT) method with an external tool (Python REPL). We discovered that by prompting LLMs to generate structured text in XML-like markup language, we could seamlessly integrate CoT and the external tool and control the undesired behaviors of LLMs. With our approach, LLMs can utilize Python computation to rectify errors within CoT. We applied our method to ChatGPT (GPT-3.5) to solve challenging mathematical problems and demonstrated that combining CoT and Python REPL through the markup language enhances the reasoning capability of LLMs. Our approach enables LLMs to write the markup language and perform advanced mathematical reasoning using only zero-shot prompting. ","[{'version': 'v1', 'created': 'Thu, 21 Sep 2023 02:46:20 GMT'}]",2023-09-26,"[['Yamauchi', 'Ryutaro', ''], ['Sonoda', 'Sho', ''], ['Sannai', 'Akiyoshi', ''], ['Kumagai', 'Wataru', '']]",1,1,2023-09-21,1,4,3,2,0,2,b099104d1a065cbc1432af22e6085b1a44dbc839,262465094.0,https://www.semanticscholar.org/paper/b099104d1a065cbc1432af22e6085b1a44dbc839,arXiv.org,2023.0,20.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2265489146', 'name': 'Ryutaro Yamauchi'}, {'authorId': '3112286', 'name': 'Sho Sonoda'}, {'authorId': '41152282', 'name': 'Akiyoshi Sannai'}, {'authorId': '1896666', 'name': 'Wataru Kumagai'}]","['Kyoto University', 'RIKEN Center for Advanced Intelligence Project', 'The University of Tokyo']",['Japan'],2023-09
2309.13094,Gordana Dodig-Crnkovic,Gordana Dodig-Crnkovic,Computational Natural Philosophy: A Thread from Presocratics through Turing to ChatGPT,17 pages,,,,cs.GL cs.AI,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Modern computational natural philosophy conceptualizes the universe in terms of information and computation, establishing a framework for the study of cognition and intelligence. Despite some critiques, this computational perspective has significantly influenced our understanding of the natural world, leading to the development of AI systems like ChatGPT based on deep neural networks. Advancements in this domain have been facilitated by interdisciplinary research, integrating knowledge from multiple fields to simulate complex systems. Large Language Models (LLMs), such as ChatGPT, represent this approach's capabilities, utilizing reinforcement learning with human feedback (RLHF). Current research initiatives aim to integrate neural networks with symbolic computing, introducing a new generation of hybrid computational models. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 11:47:36 GMT'}]",2023-09-26,"[['Dodig-Crnkovic', 'Gordana', '']]",1,1,2023-09-22,1,1,2,1,0,1,f5e4184ff3d7589e7416589e0a7853e314f21c9b,262465089.0,https://www.semanticscholar.org/paper/f5e4184ff3d7589e7416589e0a7853e314f21c9b,arXiv.org,2023.0,93.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1403731773', 'name': 'G. Dodig-Crnkovic'}]","['Chalmers University of Technology', 'Mälardalen University']",['Sweden'],2023-09
2309.13136,Vera Yang,"Vera Yang, Archita Srivastava, Yasaman Etesam, Chuxuan Zhang, Angelica
  Lim",Contextual Emotion Estimation from Image Captions,"Accepted to ACII 2023. Project page:
  http://rosielab.github.io/emotion-captions/",,,,cs.CV cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Emotion estimation in images is a challenging task, typically using computer vision methods to directly estimate people's emotions using face, body pose and contextual cues. In this paper, we explore whether Large Language Models (LLMs) can support the contextual emotion estimation task, by first captioning images, then using an LLM for inference. First, we must understand: how well do LLMs perceive human emotions? And which parts of the information enable them to determine emotions? One initial challenge is to construct a caption that describes a person within a scene with information relevant for emotion perception. Towards this goal, we propose a set of natural language descriptors for faces, bodies, interactions, and environments. We use them to manually generate captions and emotion annotations for a subset of 331 images from the EMOTIC dataset. These captions offer an interpretable representation for emotion estimation, towards understanding how elements of a scene affect emotion perception in LLMs and beyond. Secondly, we test the capability of a large language model to infer an emotion from the resulting image captions. We find that GPT-3.5, specifically the text-davinci-003 model, provides surprisingly reasonable emotion predictions consistent with human annotations, but accuracy can depend on the emotion concept. Overall, the results suggest promise in the image captioning and LLM approach. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 18:44:34 GMT'}]",2023-09-26,"[['Yang', 'Vera', ''], ['Srivastava', 'Archita', ''], ['Etesam', 'Yasaman', ''], ['Zhang', 'Chuxuan', ''], ['Lim', 'Angelica', '']]",0,1,2023-09-22,1,5,2,1,0,1,addfedf79c96e1f94ef02d46a93666ebd3793fc4,262459083.0,https://www.semanticscholar.org/paper/addfedf79c96e1f94ef02d46a93666ebd3793fc4,arXiv.org,2023.0,22.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '101050789', 'name': 'V. Yang'}, {'authorId': '4629751', 'name': 'Archita Srivastava'}, {'authorId': '84184549', 'name': 'Yasaman Etesam'}, {'authorId': '2211066713', 'name': 'Chuxuan Zhang'}, {'authorId': '46261444', 'name': 'Angelica Lim'}]",['Simon Fraser University'],['Canada'],2023-09
2309.13173,Md Tahmid Rahman Laskar,"Mohsinul Kabir, Mohammed Saidul Islam, Md Tahmid Rahman Laskar, Mir
  Tafseer Nayeem, M Saiful Bari, Enamul Hoque",BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP,First two authors contributed equally,,,,cs.CL,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Large Language Models (LLMs) have emerged as one of the most important breakthroughs in natural language processing (NLP) for their impressive skills in language generation and other language-specific tasks. Though LLMs have been evaluated in various tasks, mostly in English, they have not yet undergone thorough evaluation in under-resourced languages such as Bengali (Bangla). In this paper, we evaluate the performance of LLMs for the low-resourced Bangla language. We select various important and diverse Bangla NLP tasks, such as abstractive summarization, question answering, paraphrasing, natural language inference, text classification, and sentiment analysis for zero-shot evaluation with ChatGPT, LLaMA-2, and Claude-2 and compare the performance with state-of-the-art fine-tuned models. Our experimental results demonstrate an inferior performance of LLMs for different Bangla NLP tasks, calling for further effort to develop better understanding of LLMs in low-resource languages like Bangla. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 20:29:34 GMT'}]",2023-09-26,"[['Kabir', 'Mohsinul', ''], ['Islam', 'Mohammed Saidul', ''], ['Laskar', 'Md Tahmid Rahman', ''], ['Nayeem', 'Mir Tafseer', ''], ['Bari', 'M Saiful', ''], ['Hoque', 'Enamul', '']]",1,1,2023-09-22,1,6,1,3,1,2,dd41f3d40f89c93ba866ba482c3c8c617a0b0bad,262465154.0,https://www.semanticscholar.org/paper/dd41f3d40f89c93ba866ba482c3c8c617a0b0bad,arXiv.org,2023.0,41.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2245159964', 'name': 'M. Kabir'}, {'authorId': '2196189043', 'name': 'Mohammed Saidul Islam'}, {'authorId': '46437970', 'name': 'Md Tahmid Rahman Laskar'}, {'authorId': '1807355', 'name': 'Mir Tafseer Nayeem'}, {'authorId': '31773000', 'name': 'M Saiful Bari'}, {'authorId': '2939577', 'name': 'Enamul Hoque'}]","['York University', 'Nanyang Technological University', 'Dialpad Canada Inc. , , ,', 'University of Alberta', 'Islamic University of Technology']","['Canada', 'Singapore', 'Bangladesh']",2023-09
2309.13202,Lifeng Han Dr,"Zihao Li, Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Matthew
  Shardlow, Goran Nenadic",Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts,working paper,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Biomedical literature often uses complex language and inaccessible professional terminologies. That is why simplification plays an important role in improving public health literacy. Applying Natural Language Processing (NLP) models to automate such tasks allows for quick and direct accessibility for lay readers. In this work, we investigate the ability of state-of-the-art large language models (LLMs) on the task of biomedical abstract simplification, using the publicly available dataset for plain language adaptation of biomedical abstracts (\textbf{PLABA}). The methods applied include domain fine-tuning and prompt-based learning (PBL) on: 1) Encoder-decoder models (T5, SciFive, and BART), 2) Decoder-only GPT models (GPT-3.5 and GPT-4) from OpenAI and BioGPT, and 3) Control-token mechanisms on BART-based models. We used a range of automatic evaluation metrics, including BLEU, ROUGE, SARI, and BERTscore, and also conducted human evaluations. BART-Large with Control Token (BART-L-w-CT) mechanisms reported the highest SARI score of 46.54 and T5-base reported the highest BERTscore 72.62. In human evaluation, BART-L-w-CTs achieved a better simplicity score over T5-Base (2.9 vs. 2.2), while T5-Base achieved a better meaning preservation score over BART-L-w-CTs (3.1 vs. 2.6). We also categorised the system outputs with examples, hoping this will shed some light for future research on this task. Our code, fine-tuned models, and data splits are available at \url{https://github.com/HECTA-UoM/PLABA-MU} ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 22:47:32 GMT'}]",2023-09-26,"[['Li', 'Zihao', ''], ['Belkadi', 'Samuel', ''], ['Micheletti', 'Nicolo', ''], ['Han', 'Lifeng', ''], ['Shardlow', 'Matthew', ''], ['Nenadic', 'Goran', '']]",0,1,2023-09-22,1,6,2,3,1,2,a54493bdca9b63c63468714e9b60fe89d56cd265,262459330.0,https://www.semanticscholar.org/paper/a54493bdca9b63c63468714e9b60fe89d56cd265,arXiv.org,2023.0,55.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2118273388', 'name': 'Z. Li'}, {'authorId': '2245373398', 'name': 'Samuel Belkadi'}, {'authorId': '2188780466', 'name': 'Nicolo Micheletti'}, {'authorId': '2196038162', 'name': 'Lifeng Han'}, {'authorId': '2895959', 'name': 'M. Shardlow'}, {'authorId': '2144507', 'name': 'G. Nenadic'}]","['University of Manchester', 'Manchester Metropolitan University']",['United Kingdom'],2023-09
2309.13218,Pivithuru Thejan Amarasinghe,"Pivithuru Thejan Amarasinghe, Su Nguyen, Yuan Sun and Damminda
  Alahakoon",AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling,,,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Business optimisation is the process of finding and implementing efficient and cost-effective means of operation to bring a competitive advantage for businesses. Synthesizing problem formulations is an integral part of business optimisation which is centred around human expertise, thus with a high potential of becoming a bottleneck. With the recent advancements in Large Language Models (LLMs), human expertise needed in problem formulation can potentially be minimized using Artificial Intelligence (AI). However, developing a LLM for problem formulation is challenging, due to training data requirements, token limitations, and the lack of appropriate performance metrics in LLMs. To minimize the requirement of large training data, considerable attention has recently been directed towards fine-tuning pre-trained LLMs for downstream tasks, rather than training a LLM from scratch for a specific task. In this paper, we adopt this approach and propose an AI-Copilot for business optimisation by fine-tuning a pre-trained LLM for problem formulation. To address token limitations, we introduce modularization and prompt engineering techniques to synthesize complex problem formulations as modules that fit into the token limits of LLMs. In addition, we design performance evaluation metrics that are more suitable for assessing the accuracy and quality of problem formulations compared to existing evaluation metrics. Experiment results demonstrate that our AI-Copilot can synthesize complex and large problem formulations for a typical business optimisation problem in production scheduling. ","[{'version': 'v1', 'created': 'Fri, 22 Sep 2023 23:45:21 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Sep 2023 04:19:39 GMT'}]",2023-10-02,"[['Amarasinghe', 'Pivithuru Thejan', ''], ['Nguyen', 'Su', ''], ['Sun', 'Yuan', ''], ['Alahakoon', 'Damminda', '']]",0,0,2023-09-22,2,4,1,0,0,0,13fafa40eb7b15813cdf6c2ead1e1032e7b085f0,262466056.0,https://www.semanticscholar.org/paper/13fafa40eb7b15813cdf6c2ead1e1032e7b085f0,arXiv.org,2023.0,57.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2245404499', 'name': 'Pivithuru Thejan Amarasinghe'}, {'authorId': '145279139', 'name': 'Su Nguyen'}, {'authorId': '2143552525', 'name': 'Yuan Sun'}, {'authorId': '143775049', 'name': 'D. Alahakoon'}]","['La Trobe University', 'RMIT University']",['Australia'],2023-09
2309.13243,Jieun Han,"Jieun Han, Haneul Yoo, Junho Myung, Minsun Kim, Tak Yeon Lee, So-Yeon
  Ahn, Alice Oh",ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education,,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  The integration of generative AI in education is expanding, yet empirical analyses of large-scale, real-world interactions between students and AI systems still remain limited. In this study, we present ChEDDAR, ChatGPT & EFL Learner's Dialogue Dataset As Revising an essay, which is collected from a semester-long longitudinal experiment involving 212 college students enrolled in English as Foreign Langauge (EFL) writing courses. The students were asked to revise their essays through dialogues with ChatGPT. ChEDDAR includes a conversation log, utterance-level essay edit history, self-rated satisfaction, and students' intent, in addition to session-level pre-and-post surveys documenting their objectives and overall experiences. We analyze students' usage patterns and perceptions regarding generative AI with respect to their intent and satisfaction. As a foundational step, we establish baseline results for two pivotal tasks in task-oriented dialogue systems within educational contexts: intent detection and satisfaction estimation. We finally suggest further research to refine the integration of generative AI into education settings, outlining potential scenarios utilizing ChEDDAR. ChEDDAR is publicly available at https://github.com/zeunie/ChEDDAR. ","[{'version': 'v1', 'created': 'Sat, 23 Sep 2023 03:28:25 GMT'}]",2023-09-26,"[['Han', 'Jieun', ''], ['Yoo', 'Haneul', ''], ['Myung', 'Junho', ''], ['Kim', 'Minsun', ''], ['Lee', 'Tak Yeon', ''], ['Ahn', 'So-Yeon', ''], ['Oh', 'Alice', '']]",1,1,2023-09-23,1,7,1,1,0,1,3531e05a330b6aa82eb7863b6014342770ff5dcb,262465991.0,https://www.semanticscholar.org/paper/3531e05a330b6aa82eb7863b6014342770ff5dcb,arXiv.org,2023.0,24.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '47180319', 'name': 'Jieun Han'}, {'authorId': '47111345', 'name': 'Haneul Yoo'}, {'authorId': '2137320052', 'name': 'Jun-Hee Myung'}, {'authorId': '3050376', 'name': 'Minsun Kim'}, {'authorId': '2110755619', 'name': 'T. Lee'}, {'authorId': '7463843', 'name': 'So-Yeon Ahn'}, {'authorId': '2463290', 'name': 'Alice H. Oh'}]",['Korea Advanced Institute of Science and Technology'],['South Korea'],2023-09
2309.13339,Xufeng Zhao,"Xufeng Zhao, Mengdi Li, Wenhao Lu, Cornelius Weber, Jae Hee Lee, Kun
  Chu, Stefan Wermter",Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic,,,,,cs.CL cs.AI cs.LG cs.SC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their behavior, particularly in terms of reasoning, often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. Generative language models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming to improve the zero-shot chain-of-thought reasoning ability of large language models, we propose Logical Chain-of-Thought (LogiCoT), a neurosymbolic framework that leverages principles from symbolic logic to verify and revise the reasoning processes accordingly. Experimental evaluations conducted on language tasks in diverse domains, including arithmetic, commonsense, symbolic, causal inference, and social problems, demonstrate the efficacy of the enhanced reasoning paradigm by logic. ","[{'version': 'v1', 'created': 'Sat, 23 Sep 2023 11:21:12 GMT'}]",2023-09-26,"[['Zhao', 'Xufeng', ''], ['Li', 'Mengdi', ''], ['Lu', 'Wenhao', ''], ['Weber', 'Cornelius', ''], ['Lee', 'Jae Hee', ''], ['Chu', 'Kun', ''], ['Wermter', 'Stefan', '']]",0,0,2023-09-23,1,7,4,0,0,0,55c04e70e2faf2aae6413731d92cafede317d6ee,262465259.0,https://www.semanticscholar.org/paper/55c04e70e2faf2aae6413731d92cafede317d6ee,arXiv.org,2023.0,60.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2145744284', 'name': 'Xufeng Zhao'}, {'authorId': '2004701476', 'name': 'Mengdi Li'}, {'authorId': '1999393286', 'name': 'Wenhao Lu'}, {'authorId': '1798067', 'name': 'C. Weber'}, {'authorId': '39061055', 'name': 'Jae Hee Lee'}, {'authorId': '40530122', 'name': 'Kun-Mo Chu'}, {'authorId': '1736513', 'name': 'S. Wermter'}]",['Universität Hamburg'],['Germany'],2023-09
2309.13633,Tae Soo Kim,"Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, Juho Kim",EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria,,,,,cs.HC cs.AI cs.CL,http://creativecommons.org/licenses/by/4.0/,"  By simply composing prompts, developers can prototype novel generative applications with Large Language Models (LLMs). To refine prototypes into products, however, developers must iteratively revise prompts by evaluating outputs to diagnose weaknesses. Formative interviews (N=8) revealed that developers invest significant effort in manually evaluating outputs as they assess context-specific and subjective criteria. We present EvalLM, an interactive system for iteratively refining prompts by evaluating multiple outputs on user-defined criteria. By describing criteria in natural language, users can employ the system's LLM-based evaluator to get an overview of where prompts excel or fail, and improve these based on the evaluator's feedback. A comparative study (N=12) showed that EvalLM, when compared to manual evaluation, helped participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond prompts, our work can be extended to augment model evaluation and alignment in specific application contexts. ","[{'version': 'v1', 'created': 'Sun, 24 Sep 2023 13:19:38 GMT'}]",2023-09-26,"[['Kim', 'Tae Soo', ''], ['Lee', 'Yoonjoo', ''], ['Shin', 'Jamin', ''], ['Kim', 'Young-Ho', ''], ['Kim', 'Juho', '']]",0,0,2023-09-24,1,5,3,0,0,0,a0d83f9e15e722f23c14eb83cb2f87c1d1ea6400,262459331.0,https://www.semanticscholar.org/paper/a0d83f9e15e722f23c14eb83cb2f87c1d1ea6400,arXiv.org,2023.0,80.0,1.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1410132100', 'name': 'Tae Soo Kim'}, {'authorId': '49380061', 'name': 'Yoonjoo Lee'}, {'authorId': '51228826', 'name': 'Jamin Shin'}, {'authorId': '2145733031', 'name': 'Young-Ho Kim'}, {'authorId': '1800981', 'name': 'Juho Kim'}]","['Korea Advanced Institute of Science and Technology', 'NAVER']",['South Korea'],2023-09
2309.13702,Santiago G\'ongora,"Santiago G\'ongora, Luis Chiruzzo, Gonzalo M\'endez, Pablo Gerv\'as",Skill Check: Some Considerations on the Evaluation of Gamemastering Models for Role-playing Games,"11 pages. Accepted at GALA 2023 (Games and Learning Alliance 12th
  International Conference)",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  In role-playing games a Game Master (GM) is the player in charge of the game, who must design the challenges the players face and narrate the outcomes of their actions. In this work we discuss some challenges to model GMs from an Interactive Storytelling and Natural Language Processing perspective. Following those challenges we propose three test categories to evaluate such dialogue systems, and we use them to test ChatGPT, Bard and OpenAssistant as out-of-the-box GMs. ","[{'version': 'v1', 'created': 'Sun, 24 Sep 2023 17:19:36 GMT'}, {'version': 'v2', 'created': 'Sat, 30 Sep 2023 18:56:04 GMT'}]",2023-10-03,"[['Góngora', 'Santiago', ''], ['Chiruzzo', 'Luis', ''], ['Méndez', 'Gonzalo', ''], ['Gervás', 'Pablo', '']]",1,1,2023-09-24,2,4,2,1,0,1,66c6c3cc8fe03c167fefb21cd74b564f12986ab2,262466035.0,https://www.semanticscholar.org/paper/66c6c3cc8fe03c167fefb21cd74b564f12986ab2,arXiv.org,2023.0,31.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2003583640', 'name': 'Santiago Góngora'}, {'authorId': '2287191', 'name': 'Luis Chiruzzo'}, {'authorId': '145814398', 'name': 'Gonzalo Méndez'}, {'authorId': '2245391560', 'name': ""Pablo Gerv'as""}]","['Universidad Complutense de Madrid', 'Universidad de la República']","['Spain', 'Uruguay']",2023-09
2309.14021,Tejas Vaidhya,"Ayush Kaushal, Tejas Vaidhya, Irina Rish",LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot Compression,9 pages,,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Low Rank Decomposition of matrix - splitting a large matrix into a product of two smaller matrix offers a means for compression that reduces the parameters of a model without sparsification, and hence delivering more speedup on modern hardware. Moreover, unlike quantization, the compressed linear layers remain fully differentiable and all the parameters trainable, while being able to leverage the existing highly efficient kernels over floating point matrices. We study the potential to compress Large Language Models (LLMs) for monolingual Code generation via Low Rank Decomposition (LoRD) and observe that ranks for the linear layers in these models can be reduced by upto 39.58% with less than 1% increase in perplexity. We then use Low Rank Decomposition (LoRD) to compress StarCoder 16B to 13.2B parameter with no drop and to 12.3B with minimal drop in HumanEval Pass@1 score, in less than 10 minutes on a single A100. The compressed models speeds up inference by up to 22.35% with just a single line of change in code over huggingface's implementation with pytorch backend. Low Rank Decomposition (LoRD) models remain compatible with state of the art near-lossless quantization method such as SpQR, which allows leveraging further compression gains of quantization. Lastly, QLoRA over Low Rank Decomposition (LoRD) model further reduces memory requirements by as much as 21.2% over vanilla QLoRA while offering similar gains from parameter efficient fine tuning. Our work shows Low Rank Decomposition (LoRD) as a promising new paradigm for LLM compression. ","[{'version': 'v1', 'created': 'Mon, 25 Sep 2023 10:35:17 GMT'}]",2023-09-26,"[['Kaushal', 'Ayush', ''], ['Vaidhya', 'Tejas', ''], ['Rish', 'Irina', '']]",0,0,2023-09-25,1,3,2,0,0,0,8ec117feff6ee10e3b20a19ac101fee5c99e14d7,262460763.0,https://www.semanticscholar.org/paper/8ec117feff6ee10e3b20a19ac101fee5c99e14d7,arXiv.org,2023.0,71.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1580369404', 'name': 'Ayush Kaushal'}, {'authorId': '2008210195', 'name': 'Tejas Vaidhya'}, {'authorId': '2109771', 'name': 'I. Rish'}]",['Université de Montréal'],['Canada'],2023-09
2309.14379,Andres Karjus,Andres Karjus,Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence,,,,,cs.CL cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  The increasing capacities of large language models (LLMs) present an unprecedented opportunity to scale up data analytics in the humanities and social sciences, augmenting and automating qualitative analytic tasks previously typically allocated to human labor. This contribution proposes a systematic mixed methods framework to harness qualitative analytic expertise, machine scalability, and rigorous quantification, with attention to transparency and replicability. 16 machine-assisted case studies are showcased as proof of concept. Tasks include linguistic and discourse analysis, lexical semantic change detection, interview analysis, historical event cause inference and text mining, detection of political stance, text and idea reuse, genre composition in literature and film; social network inference, automated lexicography, missing metadata augmentation, and multimodal visual cultural analytics. In contrast to the focus on English in the emerging LLM applicability literature, many examples here deal with scenarios involving smaller languages and historical texts prone to digitization distortions. In all but the most difficult tasks requiring expert knowledge, generative LLMs can demonstrably serve as viable research instruments. LLM (and human) annotations may contain errors and variation, but the agreement rate can and should be accounted for in subsequent statistical modeling; a bootstrapping approach is discussed. The replications among the case studies illustrate how tasks previously requiring potentially months of team effort and complex computational pipelines, can now be accomplished by an LLM-assisted scholar in a fraction of the time. Importantly, this approach is not intended to replace, but to augment researcher knowledge and skills. With these opportunities in sight, qualitative expertise and the ability to pose insightful questions have arguably never been more critical. ","[{'version': 'v1', 'created': 'Sun, 24 Sep 2023 14:21:50 GMT'}]",2023-09-27,"[['Karjus', 'Andres', '']]",0,0,2023-09-24,1,1,3,0,0,0,12c56ec22bf9f616f23f83902c856174843f3f4d,262825994.0,https://www.semanticscholar.org/paper/12c56ec22bf9f616f23f83902c856174843f3f4d,arXiv.org,2023.0,153.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '50994722', 'name': 'Andres Karjus'}]",['Estonian Business School'],['Estonia'],2023-09
2309.14391,Andreas Metzger,"Andreas Metzger, Jone Bartel, Jan Laufer",An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems,"To be published at 21st Int'l Conference on Service-Oriented
  Computing (ICSOC 2023), Rome, Italy, November 28-December 1, 2023, ser. LNCS,
  F. Monti, S. Rinderle-Ma, A. Ruiz Cortes, Z. Zheng, M. Mecella, Eds.,
  Springer, 2023",,,,cs.LG cs.AI cs.CL,http://creativecommons.org/licenses/by-nc-nd/4.0/,"  Deep Reinforcement Learning (Deep RL) is increasingly used to cope with the open-world assumption in service-oriented systems. Deep RL was successfully applied to problems such as dynamic service composition, job scheduling, and offloading, as well as service adaptation. While Deep RL offers many benefits, understanding the decision-making of Deep RL is challenging because its learned decision-making policy essentially appears as a black box. Yet, understanding the decision-making of Deep RL is key to help service developers perform debugging, support service providers to comply with relevant legal frameworks, and facilitate service users to build trust. We introduce Chat4XAI to facilitate the understanding of the decision-making of Deep RL by providing natural-language explanations. Compared with visual explanations, the reported benefits of natural-language explanations include better understandability for non-technical users, increased user acceptance and trust, as well as more efficient explanations. Chat4XAI leverages modern AI chatbot technology and dedicated prompt engineering. Compared to earlier work on natural-language explanations using classical software-based dialogue systems, using an AI chatbot eliminates the need for eliciting and defining potential questions and answers up-front. We prototypically realize Chat4XAI using OpenAI's ChatGPT API and evaluate the fidelity and stability of its explanations using an adaptive service exemplar. ","[{'version': 'v1', 'created': 'Mon, 25 Sep 2023 09:05:36 GMT'}]",2023-09-27,"[['Metzger', 'Andreas', ''], ['Bartel', 'Jone', ''], ['Laufer', 'Jan', '']]",1,1,2023-09-25,1,3,3,1,0,1,16acd2d2faa236dfe5f6ab67a0b94a9ed1b1de57,262834657.0,https://www.semanticscholar.org/paper/16acd2d2faa236dfe5f6ab67a0b94a9ed1b1de57,arXiv.org,2023.0,43.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '145485764', 'name': 'Andreas Metzger'}, {'authorId': '134133431', 'name': 'Jon Bartel'}, {'authorId': '2098827102', 'name': 'Jan Laufer'}]",['University of Duisburg-Essen'],['Germany'],2023-09
2309.14779,Hengyu Luo,"Hengyu Luo, Peng Liu, Stefan Esping",Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification,10 pages excluding appendix and reference,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Domain-specific text classification faces the challenge of scarce labeled data due to the high cost of manual labeling. Prompt-learning, known for its efficiency in few-shot scenarios, is proposed as an alternative to traditional fine-tuning methods. And besides, although large language models (LLMs) have gained prominence, small language models (SLMs, with under 1B parameters) offer significant customizability, adaptability, and cost-effectiveness for domain-specific tasks, given industry constraints. In this study, we investigate the potential of SLMs combined with prompt-learning paradigm for domain-specific text classification, specifically within customer-agent interactions in retail. Our evaluations show that, in few-shot settings when prompt-based model fine-tuning is possible, T5-base, a typical SLM with 220M parameters, achieve approximately 75% accuracy with limited labeled data (up to 15% of full data), which shows great potentials of SLMs with prompt-learning. Based on this, We further validate the effectiveness of active few-shot sampling and the ensemble strategy in the prompt-learning pipeline that contribute to a remarkable performance gain. Besides, in zero-shot settings with a fixed model, we underscore a pivotal observation that, although the GPT-3.5-turbo equipped with around 154B parameters garners an accuracy of 55.16%, the power of well designed prompts becomes evident when the FLAN-T5-large, a model with a mere 0.5% of GPT-3.5-turbo's parameters, achieves an accuracy exceeding 31% with the optimized prompt, a leap from its sub-18% performance with an unoptimized one. Our findings underscore the promise of prompt-learning in classification tasks with SLMs, emphasizing the benefits of active few-shot sampling, and ensemble strategies in few-shot settings, and the importance of prompt engineering in zero-shot settings. ","[{'version': 'v1', 'created': 'Tue, 26 Sep 2023 09:24:46 GMT'}]",2023-09-27,"[['Luo', 'Hengyu', ''], ['Liu', 'Peng', ''], ['Esping', 'Stefan', '']]",0,1,2023-09-26,1,3,3,4,2,2,47d04bcfe0f1bed72d03c68cce76b4cf4be03f11,262822537.0,https://www.semanticscholar.org/paper/47d04bcfe0f1bed72d03c68cce76b4cf4be03f11,arXiv.org,2023.0,12.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2110416110', 'name': 'Hengyu Luo'}, {'authorId': '2247922552', 'name': 'Peng Liu'}, {'authorId': '2246883751', 'name': 'Stefan Esping'}]","['Uppsala University', 'Ingka Group, IKEA,']",['Sweden'],2023-09
2309.15088,Jimmy Lin,"Ronak Pradeep, Sahel Sharifymoghaddam, Jimmy Lin",RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models,,,,,cs.IR cs.CL,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Researchers have successfully applied large language models (LLMs) such as ChatGPT to reranking in an information retrieval context, but to date, such work has mostly been built on proprietary models hidden behind opaque API endpoints. This approach yields experimental results that are not reproducible and non-deterministic, threatening the veracity of outcomes that build on such shaky foundations. To address this significant shortcoming, we present RankVicuna, the first fully open-source LLM capable of performing high-quality listwise reranking in a zero-shot setting. Experimental results on the TREC 2019 and 2020 Deep Learning Tracks show that we can achieve effectiveness comparable to zero-shot reranking with GPT-3.5 with a much smaller 7B parameter model, although our effectiveness remains slightly behind reranking with GPT-4. We hope our work provides the foundation for future research on reranking with modern LLMs. All the code necessary to reproduce our results is available at https://github.com/castorini/rank_llm. ","[{'version': 'v1', 'created': 'Tue, 26 Sep 2023 17:31:57 GMT'}]",2023-09-27,"[['Pradeep', 'Ronak', ''], ['Sharifymoghaddam', 'Sahel', ''], ['Lin', 'Jimmy', '']]",1,1,2023-09-26,1,3,2,3,0,3,ba03ca8faa9f01cd9d26b80f08d421376f70de22,262825475.0,https://www.semanticscholar.org/paper/ba03ca8faa9f01cd9d26b80f08d421376f70de22,arXiv.org,2023.0,41.0,3.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1816753042', 'name': 'Ronak Pradeep'}, {'authorId': '71076877', 'name': 'Sahel Sharifymoghaddam'}, {'authorId': '2121626141', 'name': 'Jimmy Lin'}]",['University of Waterloo'],['Canada'],2023-09
2309.15217,Luis Espinosa-Anke,"Shahul Es, Jithin James, Luis Espinosa-Anke, Steven Schockaert",RAGAS: Automated Evaluation of Retrieval Augmented Generation,"Reference-free (not tied to having ground truth available) evaluation
  framework for retrieval agumented generation",,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems are composed of a retrieval and an LLM based generation module, and provide LLMs with knowledge from a reference textual database, which enables them to act as a natural language layer between a user and textual databases, reducing the risk of hallucinations. Evaluating RAG architectures is, however, challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, or the quality of the generation itself. With RAGAs, we put forward a suite of metrics which can be used to evaluate these different dimensions \textit{without having to rely on ground truth human annotations}. We posit that such a framework can crucially contribute to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs. ","[{'version': 'v1', 'created': 'Tue, 26 Sep 2023 19:23:54 GMT'}]",2023-09-28,"[['Es', 'Shahul', ''], ['James', 'Jithin', ''], ['Espinosa-Anke', 'Luis', ''], ['Schockaert', 'Steven', '']]",0,0,2023-09-26,1,4,1,0,0,0,f5e9e5bbe22f0263be1f1ce88c66978a2b927772,263152733.0,https://www.semanticscholar.org/paper/f5e9e5bbe22f0263be1f1ce88c66978a2b927772,arXiv.org,2023.0,29.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2214583051', 'name': 'ES Shahul'}, {'authorId': '2248138289', 'name': 'Jithin James'}, {'authorId': '2258950306', 'name': 'Luis Espinosa Anke'}, {'authorId': '2265382', 'name': 'S. Schockaert'}]","['Cardiff University', 'AMPLYFI, United Kingdom']",['United Kingdom'],2023-09
2309.15487,Alvin De Jun Tan,"Alvin De Jun Tan, Bingquan Shen",Tackling VQA with Pretrained Foundation Models without Further Training,,,,,cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have achieved state-of-the-art results in many natural language processing tasks. They have also demonstrated ability to adapt well to different tasks through zero-shot or few-shot settings. With the capability of these LLMs, researchers have looked into how to adopt them for use with Visual Question Answering (VQA). Many methods require further training to align the image and text embeddings. However, these methods are computationally expensive and requires large scale image-text dataset for training. In this paper, we explore a method of combining pretrained LLMs and other foundation models without further training to solve the VQA problem. The general idea is to use natural language to represent the images such that the LLM can understand the images. We explore different decoding strategies for generating textual representation of the image and evaluate their performance on the VQAv2 dataset. ","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 08:35:24 GMT'}]",2023-09-28,"[['Tan', 'Alvin De Jun', ''], ['Shen', 'Bingquan', '']]",0,0,2023-09-27,1,2,1,0,0,0,a8f05b5ef3d60fb310f8366aa775118df5b700c3,262943225.0,https://www.semanticscholar.org/paper/a8f05b5ef3d60fb310f8366aa775118df5b700c3,arXiv.org,2023.0,25.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2247329925', 'name': 'Alvin De Jun Tan'}, {'authorId': '2247396270', 'name': 'Bingquan Shen'}]","['Nanyang Technological University', 'DSO National Laboratories']",['Singapore'],2023-09
2309.15577,Anthony Cohn,Anthony G Cohn,An Evaluation of ChatGPT-4's Qualitative Spatial Reasoning Capabilities in RCC-8,"10 figures. 8 pages. Accepted for presentation at 36th International
  Workshop on Qualitative Reasoning (QR-23), in conjunction with ECAI2023 in
  Krakow, Poland",,,,cs.AI,http://creativecommons.org/licenses/by/4.0/,"  Qualitative Spatial Reasoning (QSR) is well explored area of Commonsense Reasoning and has multiple applications ranging from Geographical Information Systems to Robotics and Computer Vision. Recently many claims have been made for the capabilities of Large Language Models (LLMs). In this paper we investigate the extent to which one particular LLM can perform classical qualitative spatial reasoning tasks on the mereotopological calculus, RCC-8. ","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 11:23:15 GMT'}]",2023-09-28,"[['Cohn', 'Anthony G', '']]",1,1,2023-09-27,1,1,1,1,0,1,b5a0430d99d33bd83464504a6ba15af24ac225eb,263152389.0,https://www.semanticscholar.org/paper/b5a0430d99d33bd83464504a6ba15af24ac225eb,arXiv.org,2023.0,23.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2248060864', 'name': 'Anthony G Cohn'}]",['The Alan Turing Institute'],['United Kingdom'],2023-09
2309.15656,Ildiko Pilan,"Ildik\'o Pil\'an, Laurent Pr\'evot, Hendrik Buschmeier, Pierre Lison",Conversational Feedback in Scripted versus Spontaneous Dialogues: A Comparative Analysis,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Scripted dialogues such as movie and TV subtitles constitute a widespread source of training data for conversational NLP models. However, the linguistic characteristics of those dialogues are notably different from those observed in corpora of spontaneous interactions. This difference is particularly marked for communicative feedback and grounding phenomena such as backchannels, acknowledgments, or clarification requests. Such signals are known to constitute a key part of the conversation flow and are used by the dialogue participants to provide feedback to one another on their perception of the ongoing interaction. This paper presents a quantitative analysis of such communicative feedback phenomena in both subtitles and spontaneous conversations. Based on dialogue data in English, French, German, Hungarian, Italian, Japanese, Norwegian and Chinese, we extract both lexical statistics and classification outputs obtained with a neural dialogue act tagger. Two main findings of this empirical study are that (1) conversational feedback is markedly less frequent in subtitles than in spontaneous dialogues and (2) subtitles contain a higher proportion of negative feedback. Furthermore, we show that dialogue responses generated by large language models also follow the same underlying trends and include comparatively few occurrences of communicative feedback, except when those models are explicitly fine-tuned on spontaneous dialogues. ","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 13:45:38 GMT'}]",2023-09-28,"[['Pilán', 'Ildikó', ''], ['Prévot', 'Laurent', ''], ['Buschmeier', 'Hendrik', ''], ['Lison', 'Pierre', '']]",0,0,2023-09-27,1,4,1,0,0,0,40e2705b5adabdba9b4f90eb42e66b4fa587324d,263151527.0,https://www.semanticscholar.org/paper/40e2705b5adabdba9b4f90eb42e66b4fa587324d,arXiv.org,2023.0,92.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2248290952', 'name': ""Ildik'o Pil'an""}, {'authorId': '2248291112', 'name': ""Laurent Pr'evot""}, {'authorId': '2849488', 'name': 'Hendrik Buschmeier'}, {'authorId': '2248264152', 'name': 'Pierre Lison'}]","['French National Centre for Scientific Research', 'Bielefeld University', 'Aix-Marseille University', 'Norwegian Computing Center']","['Germany', 'Norway', 'France']",2023-09
2309.15866,Matthew Frenkel,"Matthew Frenkel, Hebah Emara",ChatGPT & Mechanical Engineering: Examining performance on the FE Mechanical Engineering and Undergraduate Exams,"12,000 words, 5 tables, 1 appendix",,,,cs.CY cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The launch of ChatGPT at the end of 2022 generated large interest into possible applications of artificial intelligence in STEM education and among STEM professions. As a result many questions surrounding the capabilities of generative AI tools inside and outside of the classroom have been raised and are starting to be explored. This study examines the capabilities of ChatGPT within the discipline of mechanical engineering. It aims to examine use cases and pitfalls of such a technology in the classroom and professional settings. ChatGPT was presented with a set of questions from junior and senior level mechanical engineering exams provided at a large private university, as well as a set of practice questions for the Fundamentals of Engineering Exam (FE) in Mechanical Engineering. The responses of two ChatGPT models, one free to use and one paid subscription, were analyzed. The paper found that the subscription model (GPT-4) greatly outperformed the free version (GPT-3.5), achieving 76% correct vs 51% correct, but the limitation of text only input on both models makes neither likely to pass the FE exam. The results confirm findings in the literature with regards to types of errors and pitfalls made by ChatGPT. It was found that due to its inconsistency and a tendency to confidently produce incorrect answers the tool is best suited for users with expert knowledge. ","[{'version': 'v1', 'created': 'Tue, 26 Sep 2023 20:12:26 GMT'}]",2023-09-29,"[['Frenkel', 'Matthew', ''], ['Emara', 'Hebah', '']]",1,1,2023-09-26,1,2,2,3,0,3,d47a8522eadb9414cce5b1d1f043b9761c510dd8,263134550.0,https://www.semanticscholar.org/paper/d47a8522eadb9414cce5b1d1f043b9761c510dd8,arXiv.org,2023.0,44.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2247812659', 'name': 'Matthew Frenkel'}, {'authorId': '2248161407', 'name': 'Hebah Emara'}]","['MetroTech Center, Room 303 Brooklyn, NY 11201', 'MetroTech Center, Room 302 Brooklyn, NY 11201', 'University of Bern']",['Switzerland'],2023-09
2309.16021,Panos Kostakos Dr,Tarek Ali and Panos Kostakos,HuntGPT: Integrating Machine Learning-Based Anomaly Detection and Explainable AI with Large Language Models (LLMs),,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  Machine learning (ML) is crucial in network anomaly detection for proactive threat hunting, reducing detection and response times significantly. However, challenges in model training, maintenance, and frequent false positives impact its acceptance and reliability. Explainable AI (XAI) attempts to mitigate these issues, allowing cybersecurity teams to assess AI-generated alerts with confidence, but has seen limited acceptance from incident responders. Large Language Models (LLMs) present a solution through discerning patterns in extensive information and adapting to different functional requirements. We present HuntGPT, a specialized intrusion detection dashboard applying a Random Forest classifier using the KDD99 dataset, integrating XAI frameworks like SHAP and Lime for user-friendly and intuitive model interaction, and combined with a GPT-3.5 Turbo, it delivers threats in an understandable format. The paper delves into the system's architecture, components, and technical accuracy, assessed through Certified Information Security Manager (CISM) Practice Exams, evaluating response quality across six metrics. The results demonstrate that conversational agents, supported by LLM and integrated with XAI, provide robust, explainable, and actionable AI solutions in intrusion detection, enhancing user understanding and interactive experience. ","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 20:58:13 GMT'}]",2023-09-29,"[['Ali', 'Tarek', ''], ['Kostakos', 'Panos', '']]",0,1,2023-09-27,1,2,1,1,0,1,cbbe989337706934f2c15512fb6398e52eae6e90,263136476.0,https://www.semanticscholar.org/paper/cbbe989337706934f2c15512fb6398e52eae6e90,arXiv.org,2023.0,46.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2248191192', 'name': 'Tarek Ali'}, {'authorId': '35688956', 'name': 'Panos Kostakos'}]",['University of Oulu'],['Finland'],2023-09
2309.16248,Catherine Kosten,"Catherine Kosten, Philippe Cudr\'e-Mauroux, Kurt Stockinger",Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  With the recent spike in the number and availability of Large Language Models (LLMs), it has become increasingly important to provide large and realistic benchmarks for evaluating Knowledge Graph Question Answering (KBQA) systems. So far the majority of benchmarks rely on pattern-based SPARQL query generation approaches. The subsequent natural language (NL) question generation is conducted through crowdsourcing or other automated methods, such as rule-based paraphrasing or NL question templates. Although some of these datasets are of considerable size, their pitfall lies in their pattern-based generation approaches, which do not always generalize well to the vague and linguistically diverse questions asked by humans in real-world contexts.   In this paper, we introduce Spider4SPARQL - a new SPARQL benchmark dataset featuring 9,693 previously existing manually generated NL questions and 4,721 unique, novel, and complex SPARQL queries of varying complexity. In addition to the NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs and ontologies, which cover 138 different domains. Our complex benchmark enables novel ways of evaluating the strengths and weaknesses of modern KGQA systems. We evaluate the system with state-of-the-art KGQA systems as well as LLMs, which achieve only up to 45\% execution accuracy, demonstrating that Spider4SPARQL is a challenging benchmark for future research. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 08:41:08 GMT'}]",2023-09-29,"[['Kosten', 'Catherine', ''], ['Cudré-Mauroux', 'Philippe', ''], ['Stockinger', 'Kurt', '']]",0,0,2023-09-28,1,3,1,0,0,0,4ac0d89d022a9ca89967cd812800e18618e83b3f,263135462.0,https://www.semanticscholar.org/paper/4ac0d89d022a9ca89967cd812800e18618e83b3f,arXiv.org,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2072251887', 'name': 'Catherine Kosten'}, {'authorId': '2248177265', 'name': ""Philippe Cudr'e-Mauroux""}, {'authorId': '2113917675', 'name': 'Kurt Stockinger'}]","['University of Fribourg', 'ZHAW Zurich University of Applied Sciences']",['Switzerland'],2023-09
2309.16349,Tom Hosking,"Tom Hosking, Phil Blunsom, Max Bartolo",Human Feedback is not Gold Standard,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Human feedback has become the de facto standard for evaluating the performance of Large Language Models, and is increasingly being used as a training objective. However, it is not clear which properties of a generated output this single `preference' score captures. We hypothesise that preference scores are subjective and open to undesirable biases. We critically analyse the use of human feedback for both training and evaluation, to verify whether it fully captures a range of crucial error criteria. We find that while preference scores have fairly good coverage, they under-represent important aspects like factuality. We further hypothesise that both preference scores and error annotation may be affected by confounders, and leverage instruction-tuned models to generate outputs that vary along two possible confounding dimensions: assertiveness and complexity. We find that the assertiveness of an output skews the perceived rate of factuality errors, indicating that human annotations are not a fully reliable evaluation metric or training objective. Finally, we offer preliminary evidence that using human feedback as a training objective disproportionately increases the assertiveness of model outputs. We encourage future work to carefully consider whether preference scores are well aligned with the desired objective. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 11:18:20 GMT'}]",2023-09-29,"[['Hosking', 'Tom', ''], ['Blunsom', 'Phil', ''], ['Bartolo', 'Max', '']]",0,0,2023-09-28,1,3,1,0,0,0,8a9f75692f946250c70c50b14b71875bf06b2270,263134280.0,https://www.semanticscholar.org/paper/8a9f75692f946250c70c50b14b71875bf06b2270,arXiv.org,2023.0,39.0,2.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","[{'authorId': '73767990', 'name': 'Tom Hosking'}, {'authorId': '2253655838', 'name': 'Phil Blunsom'}, {'authorId': '2248198014', 'name': 'Max Bartolo'}]",['University of Edinburgh'],['United Kingdom'],2023-09
2309.16414,Jan Metzen,"Jan Hendrik Metzen, Piyapat Saranrittichai, Chaithanya Kumar Mummadi",AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models,,,,,cs.CV cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Classifiers built upon vision-language models such as CLIP have shown remarkable zero-shot performance across a broad range of image classification tasks. Prior work has studied different ways of automatically creating descriptor sets for every class based on prompt templates, ranging from manually engineered templates over templates obtained from a large language model to templates built from random words and characters. Up until now, deriving zero-shot classifiers from the respective encoded class descriptors has remained nearly unchanged, i.e., classify to the class that maximizes cosine similarity between its averaged encoded class descriptors and the image encoding. However, weighing all class descriptors equally can be suboptimal when certain descriptors match visual clues on a given image better than others. In this work, we propose AutoCLIP, a method for auto-tuning zero-shot classifiers. AutoCLIP tunes per-image weights to each prompt template at inference time, based on statistics of class descriptor-image similarities. AutoCLIP is fully unsupervised, has very low computational overhead, and can be easily implemented in few lines of code. We show that AutoCLIP outperforms baselines across a broad range of vision-language models, datasets, and prompt templates consistently and by up to 3 percent point accuracy. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 13:08:08 GMT'}, {'version': 'v2', 'created': 'Fri, 29 Sep 2023 08:24:13 GMT'}]",2023-10-02,"[['Metzen', 'Jan Hendrik', ''], ['Saranrittichai', 'Piyapat', ''], ['Mummadi', 'Chaithanya Kumar', '']]",0,0,2023-09-28,2,3,3,0,0,0,99bd3e04b6b65abf3f03de69654059c3710d03e8,263142957.0,https://www.semanticscholar.org/paper/99bd3e04b6b65abf3f03de69654059c3710d03e8,arXiv.org,2023.0,27.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2708564', 'name': 'J. H. Metzen'}, {'authorId': '9359914', 'name': 'Piyapat Saranrittichai'}, {'authorId': '29359383', 'name': 'Chaithanya Kumar Mummadi'}]",['Robert Bosch (India)'],['India'],2023-09
2309.16422,Panos Kostakos Dr,"Mehrdad Kaheh, Danial Khosh Kholgh and Panos Kostakos",Cyber Sentinel: Exploring Conversational Agents in Streamlining Security Tasks with GPT-4,,,,,cs.CR,http://creativecommons.org/licenses/by/4.0/,"  In an era where cyberspace is both a battleground and a backbone of modern society, the urgency of safeguarding digital assets against ever-evolving threats is paramount. This paper introduces Cyber Sentinel, an innovative task-oriented cybersecurity dialogue system that is effectively capable of managing two core functions: explaining potential cyber threats within an organization to the user, and taking proactive/reactive security actions when instructed by the user. Cyber Sentinel embodies the fusion of artificial intelligence, cybersecurity domain expertise, and real-time data analysis to combat the multifaceted challenges posed by cyber adversaries. This article delves into the process of creating such a system and how it can interact with other components typically found in cybersecurity organizations. Our work is a novel approach to task-oriented dialogue systems, leveraging the power of chaining GPT-4 models combined with prompt engineering across all sub-tasks. We also highlight its pivotal role in enhancing cybersecurity communication and interaction, concluding that not only does this framework enhance the system's transparency (Explainable AI) but also streamlines the decision-making process and responding to threats (Actionable AI), therefore marking a significant advancement in the realm of cybersecurity communication. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 13:18:33 GMT'}]",2023-09-29,"[['Kaheh', 'Mehrdad', ''], ['Kholgh', 'Danial Khosh', ''], ['Kostakos', 'Panos', '']]",0,1,2023-09-28,1,3,1,1,0,1,ac2cce2c9b8208e9a37933b38d8ffbb4c6ec8bf6,263136524.0,https://www.semanticscholar.org/paper/ac2cce2c9b8208e9a37933b38d8ffbb4c6ec8bf6,,2023.0,64.0,0.0,0.0,False,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2248188613', 'name': 'Mehrdad Kaheh'}, {'authorId': '2122983935', 'name': 'Danial Khosh Kholgh'}, {'authorId': '35688956', 'name': 'Panos Kostakos'}]",['University of Oulu'],['Finland'],2023-09
2309.16459,Konstantinos Andriopoulos,"Konstantinos Andriopoulos, Johan Pouwelse",Augmenting LLMs with Knowledge: A survey on hallucination prevention,,,,,cs.CL cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Large pre-trained language models have demonstrated their proficiency in storing factual knowledge within their parameters and achieving remarkable results when fine-tuned for downstream natural language processing tasks. Nonetheless, their capacity to access and manipulate knowledge with precision remains constrained, resulting in performance disparities on knowledge-intensive tasks when compared to task-specific architectures. Additionally, the challenges of providing provenance for model decisions and maintaining up-to-date world knowledge persist as open research frontiers. To address these limitations, the integration of pre-trained models with differentiable access mechanisms to explicit non-parametric memory emerges as a promising solution. This survey delves into the realm of language models (LMs) augmented with the ability to tap into external knowledge sources, including external knowledge bases and search engines. While adhering to the standard objective of predicting missing tokens, these augmented LMs leverage diverse, possibly non-parametric external modules to augment their contextual processing capabilities, departing from the conventional language modeling paradigm. Through an exploration of current advancements in augmenting large language models with knowledge, this work concludes that this emerging research direction holds the potential to address prevalent issues in traditional LMs, such as hallucinations, un-grounded responses, and scalability challenges. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 14:09:58 GMT'}]",2023-09-29,"[['Andriopoulos', 'Konstantinos', ''], ['Pouwelse', 'Johan', '']]",0,0,2023-09-28,1,2,3,0,0,0,c182bcd5f37f37fea9f3dad856dc381e0f19578a,263134374.0,https://www.semanticscholar.org/paper/c182bcd5f37f37fea9f3dad856dc381e0f19578a,arXiv.org,2023.0,47.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2248161377', 'name': 'Konstantinos Andriopoulos'}, {'authorId': '1800677', 'name': 'J. Pouwelse'}]",['Delft University of Technology'],['Netherlands'],2023-09
2309.16898,JongYoon Lim,"JongYoon Lim, Inkyu Sa, Bruce MacDonald, and Ho Seok Ahn","A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM",,,,,cs.RO cs.CL cs.CV cs.HC,http://creativecommons.org/licenses/by/4.0/,"  This research explores using lightweight deep neural network architectures to enable the humanoid robot Pepper to understand American Sign Language (ASL) and facilitate non-verbal human-robot interaction. First, we introduce a lightweight and efficient model for ASL understanding optimized for embedded systems, ensuring rapid sign recognition while conserving computational resources. Building upon this, we employ large language models (LLMs) for intelligent robot interactions. Through intricate prompt engineering, we tailor interactions to allow the Pepper Robot to generate natural Co-Speech Gesture responses, laying the foundation for more organic and intuitive humanoid-robot dialogues. Finally, we present an integrated software pipeline, embodying advancements in a socially aware AI interaction model. Leveraging the Pepper Robot's capabilities, we demonstrate the practicality and effectiveness of our approach in real-world scenarios. The results highlight a profound potential for enhancing human-robot interaction through non-verbal interactions, bridging communication gaps, and making technology more accessible and understandable. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 23:54:41 GMT'}]",2023-10-02,"[['Lim', 'JongYoon', ''], ['Sa', 'Inkyu', ''], ['MacDonald', 'Bruce', ''], ['Ahn', 'Ho Seok', '']]",0,0,2023-09-28,1,4,4,0,0,0,31e04aec55f749dc560afe1d8673112f9b32f46b,263310363.0,https://www.semanticscholar.org/paper/31e04aec55f749dc560afe1d8673112f9b32f46b,arXiv.org,2023.0,30.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","[{'authorId': '144267571', 'name': 'Jongyoon Lim'}, {'authorId': '2249529212', 'name': 'Inkyu Sa'}, {'authorId': '2152761106', 'name': 'Bruce A. MacDonald'}, {'authorId': '2249535419', 'name': 'Ho Seok Ahn'}]",['University of Auckland'],['New Zealand'],2023-09
2309.17007,Tianyu Han,"Tianyu Han, Sven Nebelung, Firas Khader, Tianci Wang, Gustav
  Mueller-Franzes, Christiane Kuhl, Sebastian F\""orsch, Jens Kleesiek,
  Christoph Haarburger, Keno K. Bressem, Jakob Nikolas Kather, Daniel Truhn",Medical Foundation Models are Susceptible to Targeted Misinformation Attacks,,,,,cs.LG cs.AI cs.CY,http://creativecommons.org/licenses/by/4.0/,"  Large language models (LLMs) have broad medical knowledge and can reason about medical information across many domains, holding promising potential for diverse medical applications in the near future. In this study, we demonstrate a concerning vulnerability of LLMs in medicine. Through targeted manipulation of just 1.1% of the model's weights, we can deliberately inject an incorrect biomedical fact. The erroneous information is then propagated in the model's output, whilst its performance on other biomedical tasks remains intact. We validate our findings in a set of 1,038 incorrect biomedical facts. This peculiar susceptibility raises serious security and trustworthiness concerns for the application of LLMs in healthcare settings. It accentuates the need for robust protective measures, thorough verification mechanisms, and stringent management of access to these models, ensuring their reliable and safe use in medical practice. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 06:44:36 GMT'}]",2023-10-02,"[['Han', 'Tianyu', ''], ['Nebelung', 'Sven', ''], ['Khader', 'Firas', ''], ['Wang', 'Tianci', ''], ['Mueller-Franzes', 'Gustav', ''], ['Kuhl', 'Christiane', ''], ['Försch', 'Sebastian', ''], ['Kleesiek', 'Jens', ''], ['Haarburger', 'Christoph', ''], ['Bressem', 'Keno K.', ''], ['Kather', 'Jakob Nikolas', ''], ['Truhn', 'Daniel', '']]",0,0,2023-09-29,1,12,3,0,0,0,e94b1b868bf57f0243e42d4f51042bd1f1e621b3,263310503.0,https://www.semanticscholar.org/paper/e94b1b868bf57f0243e42d4f51042bd1f1e621b3,arXiv.org,2023.0,46.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","[{'authorId': '2031129360', 'name': 'T. Han'}, {'authorId': '6280924', 'name': 'S. Nebelung'}, {'authorId': '2047524297', 'name': 'F. Khader'}, {'authorId': '2187873077', 'name': 'Tian Wang'}, {'authorId': '2179698320', 'name': 'Gustav Mueller-Franzes'}, {'authorId': '2064331880', 'name': 'C. Kuhl'}, {'authorId': '2249530443', 'name': 'Sebastian Forsch'}, {'authorId': '2250816789', 'name': 'Jens Kleesiek'}, {'authorId': '1731835', 'name': 'Christoph Haarburger'}, {'authorId': '28908056', 'name': 'K. Bressem'}, {'authorId': '3955759', 'name': 'Jakob Nikolas Kather'}, {'authorId': '3228050', 'name': 'D. Truhn'}]","['University Medical Center of the Johannes Gutenberg University Mainz', 'Universitätsklinikum Aachen', 'Ocumeda GmbH, Munich, Germany', 'Essen University Hospital', 'Charité - Universitätsmedizin Berlin', 'Berlin Institute of Health at Charité - Universitätsmedizin Berlin', 'University Hospital Heidelberg', 'TU Dresden']",['Germany'],2023-09
2309.17057,James Hinns,"David Martens, Camille Dams, James Hinns, and Mark Vergouwen",Tell Me a Story! Narrative-Driven XAI with Large Language Models,,,,,cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  In today's critical domains, the predominance of black-box machine learning models amplifies the demand for Explainable AI (XAI). The widely used SHAP values, while quantifying feature importance, are often too intricate and lack human-friendly explanations. Furthermore, counterfactual (CF) explanations present `what ifs' but leave users grappling with the 'why'. To bridge this gap, we introduce XAIstories. Leveraging Large Language Models, XAIstories provide narratives that shed light on AI predictions: SHAPstories do so based on SHAP explanations to explain a prediction score, while CFstories do so for CF explanations to explain a decision. Our results are striking: over 90% of the surveyed general audience finds the narrative generated by SHAPstories convincing. Data scientists primarily see the value of SHAPstories in communicating explanations to a general audience, with 92% of data scientists indicating that it will contribute to the ease and confidence of nonspecialists in understanding AI predictions. Additionally, 83% of data scientists indicate they are likely to use SHAPstories for this purpose. In image classification, CFstories are considered more or equally convincing as users own crafted stories by over 75% of lay user participants. CFstories also bring a tenfold speed gain in creating a narrative, and improves accuracy by over 20% compared to manually created narratives. The results thereby suggest that XAIstories may provide the missing link in truly explaining and understanding AI predictions. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 08:40:08 GMT'}]",2023-10-02,"[['Martens', 'David', ''], ['Dams', 'Camille', ''], ['Hinns', 'James', ''], ['Vergouwen', 'Mark', '']]",0,0,2023-09-29,1,4,1,0,0,0,0db67e78229bfe436918e1485f7642bb6e6eb0df,263310408.0,https://www.semanticscholar.org/paper/0db67e78229bfe436918e1485f7642bb6e6eb0df,arXiv.org,2023.0,25.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2249583440', 'name': 'David Martens'}, {'authorId': '2249582237', 'name': 'Camille Dams'}, {'authorId': '2249568756', 'name': 'James Hinns'}, {'authorId': '2249548082', 'name': 'Mark Vergouwen'}]",['University of Antwerp'],['Belgium'],2023-09
2309.17072,Jianzhong Qi,"Jianzhong Qi, Zuqing Li, Egemen Tanin",MaaSDB: Spatial Databases in the Era of Large Language Models (Vision Paper),Accepted to appear in ACM SIGSPATIAL 2023,,10.1145/3589132.3625597,,cs.DB,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large language models (LLMs) are advancing rapidly. Such models have demonstrated strong capabilities in learning from large-scale (unstructured) text data and answering user queries. Users do not need to be experts in structured query languages to interact with systems built upon such models. This provides great opportunities to reduce the barrier of information retrieval for the general public. By introducing LLMs into spatial data management, we envisage an LLM-based spatial database system to learn from both structured and unstructured spatial data. Such a system will offer seamless access to spatial knowledge for the users, thus benefiting individuals, business, and government policy makers alike. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 09:09:04 GMT'}]",2023-10-02,"[['Qi', 'Jianzhong', ''], ['Li', 'Zuqing', ''], ['Tanin', 'Egemen', '']]",0,0,2023-09-29,1,3,1,0,0,0,767d2ba78ca9a703160d0010c5d8cb34c2aa97b2,263310484.0,https://www.semanticscholar.org/paper/767d2ba78ca9a703160d0010c5d8cb34c2aa97b2,arXiv.org,2023.0,25.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2249533709', 'name': 'Jianzhong Qi'}, {'authorId': '2249564252', 'name': 'Zuqing Li'}, {'authorId': '3346327', 'name': 'E. Tanin'}]",['University of Melbourne'],['Australia'],2023-09
2309.17122,Lars-Peter Meyer,"Johannes Frey and Lars-Peter Meyer and Natanael Arndt and Felix Brei
  and Kirill Bulert",Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?,accepted for proceedings of DL4KG Workshop @ ISWC 2023 at ceur-ws.org,,,,cs.AI cs.CL cs.DB,http://creativecommons.org/licenses/by/4.0/,"  Large Language Models (LLMs) are advancing at a rapid pace, with significant improvements at natural language processing and coding tasks. Yet, their ability to work with formal languages representing data, specifically within the realm of knowledge graph engineering, remains under-investigated. To evaluate the proficiency of various LLMs, we created a set of five tasks that probe their ability to parse, understand, analyze, and create knowledge graphs serialized in Turtle syntax. These tasks, each embodying distinct degrees of complexity and being able to scale with the size of the problem, have been integrated into our automated evaluation system, the LLM-KG-Bench. The evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4, Claude 1.3, and Claude 2.0, as well as two freely accessible offline models, GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth understanding of the strengths and shortcomings of LLMs in relation to their application within RDF knowledge graph engineering workflows utilizing Turtle representation. While our findings show that the latest commercial models outperform their forerunners in terms of proficiency with the Turtle language, they also reveal an apparent weakness. These models fall short when it comes to adhering strictly to the output formatting constraints, a crucial requirement in this context. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 10:36:04 GMT'}]",2023-10-02,"[['Frey', 'Johannes', ''], ['Meyer', 'Lars-Peter', ''], ['Arndt', 'Natanael', ''], ['Brei', 'Felix', ''], ['Bulert', 'Kirill', '']]",0,1,2023-09-29,1,5,3,4,1,3,06d1c313cf4d583644356e83c62f691cdef9084d,263310661.0,https://www.semanticscholar.org/paper/06d1c313cf4d583644356e83c62f691cdef9084d,arXiv.org,2023.0,13.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2249531945', 'name': 'Johannes Frey'}, {'authorId': '145243956', 'name': 'Lars Meyer'}, {'authorId': '2258592', 'name': 'Natanael Arndt'}, {'authorId': '2236686278', 'name': 'Felix Brei'}, {'authorId': '2108312', 'name': 'Kirill Bulert'}]","['Institute for Applied Informatics, Goerdelerring 9, 04109 Leipzig, Germany, https:// infai.org', 'Agile Knowledge Engineering and Semantic Web (AKSW),', 'Leipzig University', 'eccenca GmbH, Leipzig, Germany, https:// eccenca.com']",['Germany'],2023-09
2309.17147,Julian Ashwin,"Julian Ashwin, Aditya Chhabra and Vijayendra Rao",Using Large Language Models for Qualitative Analysis can Introduce Serious Bias,,,,,cs.CL cs.AI econ.GN q-fin.EC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models (LLMs) are quickly becoming ubiquitous, but the implications for social science research are not yet well understood. This paper asks whether LLMs can help us analyse large-N qualitative data from open-ended interviews, with an application to transcripts of interviews with Rohingya refugees in Cox's Bazaar, Bangladesh. We find that a great deal of caution is needed in using LLMs to annotate text as there is a risk of introducing biases that can lead to misleading inferences. We here mean bias in the technical sense, that the errors that LLMs make in annotating interview transcripts are not random with respect to the characteristics of the interview subjects. Training simpler supervised models on high-quality human annotations with flexible coding leads to less measurement error and bias than LLM annotations. Therefore, given that some high quality annotations are necessary in order to asses whether an LLM introduces bias, we argue that it is probably preferable to train a bespoke model on these annotations than it is to use an LLM for annotation. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 11:19:15 GMT'}, {'version': 'v2', 'created': 'Thu, 5 Oct 2023 12:25:18 GMT'}]",2023-10-06,"[['Ashwin', 'Julian', ''], ['Chhabra', 'Aditya', ''], ['Rao', 'Vijayendra', '']]",0,0,2023-09-29,2,3,4,0,0,0,d3ddd79ead2b75281772f82382bfec1ddcd8b635,263310727.0,https://www.semanticscholar.org/paper/d3ddd79ead2b75281772f82382bfec1ddcd8b635,arXiv.org,2023.0,18.0,0.0,0.0,True,"['Computer Science', 'Economics']","[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","[{'authorId': '2170941844', 'name': 'Julian Ashwin'}, {'authorId': '2249533672', 'name': 'Aditya Chhabra'}, {'authorId': '2249591337', 'name': 'Vijayendra Rao'}]",['Maastricht University'],['Netherlands'],2023-09
2309.17171,Gayashan Weerasundara,"Gayashan Weerasundara, Nisansa de Silva",Comparative Analysis of Named Entity Recognition in the Dungeons and Dragons Domain,9 pages,,,,cs.CL cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Many NLP tasks, although well-resolved for general English, face challenges in specific domains like fantasy literature. This is evident in Named Entity Recognition (NER), which detects and categorizes entities in text. We analyzed 10 NER models on 7 Dungeons and Dragons (D&D) adventure books to assess domain-specific performance. Using open-source Large Language Models, we annotated named entities in these books and evaluated each model's precision. Our findings indicate that, without modifications, Flair, Trankit, and Spacy outperform others in identifying named entities in the D&D context. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 12:09:36 GMT'}]",2023-10-02,"[['Weerasundara', 'Gayashan', ''], ['de Silva', 'Nisansa', '']]",0,0,2023-09-29,1,2,2,0,0,0,c8a30b97fae1ea4ddc3abb4b09bd410e190f0bfd,263310368.0,https://www.semanticscholar.org/paper/c8a30b97fae1ea4ddc3abb4b09bd410e190f0bfd,Recent Advances in Natural Language Processing,2023.0,40.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2249530720', 'name': 'Gayashan Weerasundara'}, {'authorId': '39077183', 'name': 'Nisansa de Silva'}]",['University of Moratuwa'],['Sri Lanka'],2023-09
2309.17234,Sahar Abdelnabi,"Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Sch\""onherr, Mario
  Fritz",LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games,,,,,cs.CL cs.CY cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  There is a growing interest in using Large Language Models (LLMs) as agents to tackle real-world tasks that may require assessing complex situations. Yet, we have a limited understanding of LLMs' reasoning and decision-making capabilities, partly stemming from a lack of dedicated evaluation benchmarks. As negotiating and compromising are key aspects of our everyday communication and collaboration, we propose using scorable negotiation games as a new evaluation framework for LLMs. We create a testbed of diverse text-based, multi-agent, multi-issue, semantically rich negotiation games, with easily tunable difficulty. To solve the challenge, agents need to have strong arithmetic, inference, exploration, and planning capabilities, while seamlessly integrating them. Via a systematic zero-shot Chain-of-Thought prompting (CoT), we show that agents can negotiate and consistently reach successful deals. We quantify the performance with multiple metrics and observe a large gap between GPT-4 and earlier models. Importantly, we test the generalization to new games and setups. Finally, we show that these games can help evaluate other critical aspects, such as the interaction dynamics between agents in the presence of greedy and adversarial players. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 13:33:06 GMT'}]",2023-10-02,"[['Abdelnabi', 'Sahar', ''], ['Gomaa', 'Amr', ''], ['Sivaprasad', 'Sarath', ''], ['Schönherr', 'Lea', ''], ['Fritz', 'Mario', '']]",0,1,2023-09-29,1,5,3,1,0,1,f3bcb9395d8b912361cc534f00e837c832000150,263310628.0,https://www.semanticscholar.org/paper/f3bcb9395d8b912361cc534f00e837c832000150,arXiv.org,2023.0,68.0,4.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '1383113350', 'name': 'Sahar Abdelnabi'}, {'authorId': '2249532110', 'name': 'Amr Gomaa'}, {'authorId': '31215717', 'name': 'S. Sivaprasad'}, {'authorId': '2249532086', 'name': 'Lea Schonherr'}, {'authorId': '2249532235', 'name': 'Mario Fritz'}]","['Helmholtz Center for Information Security', 'German Research Centre for Artificial Intelligence']",['Germany'],2023-09
2310.00117,Mohi Reza,"Mohi Reza, Nathan Laundry, Ilya Musabirov, Peter Dushniku, Zhi Yuan
  ""Michael"" Yu, Kashish Mittal, Tovi Grossman, Michael Liut, Anastasia
  Kuzminykh, Joseph Jay Williams",ABScribe: Rapid Exploration of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models,,,,,cs.HC cs.AI cs.LG,http://creativecommons.org/licenses/by/4.0/,"  Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art large language models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new versions without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers' flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly produce multiple variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text segments for rapid in-place comparisons using mouse-over interactions on a context toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p < 0.001), enhances user perceptions of the revision process (d = 2.41, p < 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 20:11:15 GMT'}]",2023-10-03,"[['Reza', 'Mohi', ''], ['Laundry', 'Nathan', ''], ['Musabirov', 'Ilya', ''], ['Dushniku', 'Peter', ''], ['Yu', 'Zhi Yuan ""Michael""', ''], ['Mittal', 'Kashish', ''], ['Grossman', 'Tovi', ''], ['Liut', 'Michael', ''], ['Kuzminykh', 'Anastasia', ''], ['Williams', 'Joseph Jay', '']]",0,0,2023-09-29,1,10,3,0,0,0,0f71c1e2acf286951544d3bd9eb5d85acfba5af1,263334262.0,https://www.semanticscholar.org/paper/0f71c1e2acf286951544d3bd9eb5d85acfba5af1,arXiv.org,2023.0,82.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '32206132', 'name': 'Mohi Reza'}, {'authorId': '90503735', 'name': 'Nathan Laundry'}, {'authorId': '1826182', 'name': 'Ilya Musabirov'}, {'authorId': '2249761523', 'name': 'Peter Dushniku'}, {'authorId': '2259940482', 'name': 'Zhi Yuan Michael Yu'}, {'authorId': '2249761498', 'name': 'Kashish Mittal'}, {'authorId': '2249760792', 'name': 'Tovi Grossman'}, {'authorId': '1397294204', 'name': 'Michael Liut'}, {'authorId': '2249761286', 'name': 'Anastasia Kuzminykh'}, {'authorId': '2249962138', 'name': 'Joseph Jay Williams'}]",['University of Toronto'],['Canada'],2023-09
2310.00272,Baphumelele Masikisiki,"Baphumelele Masikisiki, Vukosi Marivate, Yvette Hlope",Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thoughts Prompting,Accepted for publication in the Associate Computer Machinery,,,,cs.CL cs.AI,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Large Language Models, such as Generative Pre-trained Transformer 3 (aka. GPT-3), have been developed to understand language through the analysis of extensive text data, allowing them to identify patterns and connections between words. While LLMs have demonstrated impressive performance across various text-related tasks, they encounter challenges in tasks associated with reasoning. To address this challenge, Chain of Thought(CoT) prompting method has been proposed as a means to enhance LLMs' proficiency in complex reasoning tasks like solving math word problems and answering questions based on logical argumentative reasoning. The primary aim of this research is to assess how well four language models can grade reflective essays of third-year medical students. The assessment will specifically target the evaluation of critical thinking skills using CoT prompting.   The research will provide the following contributions; to introduce and educate on the process of instructing models to evaluate reflective essays from a dataset they have not been previously trained on; to illustrate the use of CoT prompting as an instructional approach for training large models to carry out particular tasks. Our results suggest that among all the models, Llama-7b performs the least effectively, displaying the highest mean squared error. Conversely, ChatGPT emerges as the superior model, boasting a higher Cohen kappa score value of 0.53. Lastly, it's important to note that the selected models do prioritise user privacy by allowing users to delete their own conducted conversations. ","[{'version': 'v1', 'created': 'Sat, 30 Sep 2023 06:25:27 GMT'}]",2023-10-03,"[['Masikisiki', 'Baphumelele', ''], ['Marivate', 'Vukosi', ''], ['Hlope', 'Yvette', '']]",1,1,2023-09-30,1,3,2,3,1,2,b7f5a44c2f7d0d134cd3456dde2a6d0d46091c66,263334407.0,https://www.semanticscholar.org/paper/b7f5a44c2f7d0d134cd3456dde2a6d0d46091c66,arXiv.org,2023.0,19.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '31179816', 'name': 'Baphumelele Masikisiki'}, {'authorId': '1841137457', 'name': 'V. Marivate'}, {'authorId': '2249760765', 'name': 'Yvette Hlope'}]",['University of Pretoria'],['South Africa'],2023-09
2310.00299,Asahi Ushio,"Asahi Ushio, Jose Camacho-Collados, Steven Schockaert",RelBERT: Embedding Relations with Language Models,,,,,cs.CL,http://creativecommons.org/licenses/by/4.0/,"  Many applications need access to background knowledge about how different concepts and entities are related. Although Knowledge Graphs (KG) and Large Language Models (LLM) can address this need to some extent, KGs are inevitably incomplete and their relational schema is often too coarse-grained, while LLMs are inefficient and difficult to control. As an alternative, we propose to extract relation embeddings from relatively small language models. In particular, we show that masked language models such as RoBERTa can be straightforwardly fine-tuned for this purpose, using only a small amount of training data. The resulting model, which we call RelBERT, captures relational similarity in a surprisingly fine-grained way, allowing us to set a new state-of-the-art in analogy benchmarks. Crucially, RelBERT is capable of modelling relations that go well beyond what the model has seen during training. For instance, we obtained strong results on relations between named entities with a model that was only trained on lexical relations between concepts, and we observed that RelBERT can recognise morphological analogies despite not being trained on such examples. Overall, we find that RelBERT significantly outperforms strategies based on prompting language models that are several orders of magnitude larger, including recent GPT-based models and open source models. ","[{'version': 'v1', 'created': 'Sat, 30 Sep 2023 08:15:36 GMT'}]",2023-10-03,"[['Ushio', 'Asahi', ''], ['Camacho-Collados', 'Jose', ''], ['Schockaert', 'Steven', '']]",0,1,2023-09-30,1,3,1,0,0,0,cd4692ae5a13931a92798df824116263818208bb,263334289.0,https://www.semanticscholar.org/paper/cd4692ae5a13931a92798df824116263818208bb,arXiv.org,2023.0,145.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '27044733', 'name': 'Asahi Ushio'}, {'authorId': '1387447871', 'name': 'José Camacho-Collados'}, {'authorId': '2265382', 'name': 'S. Schockaert'}]",['Cardiff University'],['United Kingdom'],2023-09
2310.00305,Xuan Zhang,Xuan Zhang and Wei Gao,Towards LLM-based Fact Verification on News Claims with a Hierarchical Step-by-Step Prompting Method,Accepted by AACL 2023,,,,cs.CL,http://creativecommons.org/licenses/by-sa/4.0/,"  While large pre-trained language models (LLMs) have shown their impressive capabilities in various NLP tasks, they are still under-explored in the misinformation domain. In this paper, we examine LLMs with in-context learning (ICL) for news claim verification, and find that only with 4-shot demonstration examples, the performance of several prompting methods can be comparable with previous supervised models. To further boost performance, we introduce a Hierarchical Step-by-Step (HiSS) prompting method which directs LLMs to separate a claim into several subclaims and then verify each of them via multiple questions-answering steps progressively. Experiment results on two public misinformation datasets show that HiSS prompting outperforms state-of-the-art fully-supervised approach and strong few-shot ICL-enabled baselines. ","[{'version': 'v1', 'created': 'Sat, 30 Sep 2023 08:33:04 GMT'}]",2023-10-03,"[['Zhang', 'Xuan', ''], ['Gao', 'Wei', '']]",0,0,2023-09-30,1,2,1,0,0,0,dfab0f3ee6f47e36cccee145794cd117773e6f73,263334529.0,https://www.semanticscholar.org/paper/dfab0f3ee6f47e36cccee145794cd117773e6f73,arXiv.org,2023.0,51.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2249844074', 'name': 'Xuan Zhang'}, {'authorId': '2256952599', 'name': 'Wei Gao'}]",['Singapore Management University'],['Singapore'],2023-09
2310.00355,Keitaro Tanaka,"Taichi Higasa, Keitaro Tanaka, Qi Feng, Shigeo Morishima",Gaze-Driven Sentence Simplification for Language Learners: Enhancing Comprehension and Readability,"Accepted by ACM ICMI 2023 workshops (Multimodal, Interactive
  Interfaces for Education)",,10.1145/3610661.3616177,,cs.CL cs.HC,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  Language learners should regularly engage in reading challenging materials as part of their study routine. Nevertheless, constantly referring to dictionaries is time-consuming and distracting. This paper presents a novel gaze-driven sentence simplification system designed to enhance reading comprehension while maintaining their focus on the content. Our system incorporates machine learning models tailored to individual learners, combining eye gaze features and linguistic features to assess sentence comprehension. When the system identifies comprehension difficulties, it provides simplified versions by replacing complex vocabulary and grammar with simpler alternatives via GPT-3.5. We conducted an experiment with 19 English learners, collecting data on their eye movements while reading English text. The results demonstrated that our system is capable of accurately estimating sentence-level comprehension. Additionally, we found that GPT-3.5 simplification improved readability in terms of traditional readability metrics and individual word difficulty, paraphrasing across different linguistic levels. ","[{'version': 'v1', 'created': 'Sat, 30 Sep 2023 12:18:31 GMT'}]",2023-10-03,"[['Higasa', 'Taichi', ''], ['Tanaka', 'Keitaro', ''], ['Feng', 'Qi', ''], ['Morishima', 'Shigeo', '']]",0,1,2023-09-30,1,4,2,1,0,1,368ce35987ac832e20397b872e01e7af8642ff05,263334305.0,https://www.semanticscholar.org/paper/368ce35987ac832e20397b872e01e7af8642ff05,ICMI Companion,2023.0,26.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '2249762983', 'name': 'Taichi Higasa'}, {'authorId': '2151490042', 'name': 'Keitaro Tanaka'}, {'authorId': '2242825446', 'name': 'Qi Feng'}, {'authorId': '2249758095', 'name': 'Shigeo Morishima'}]","['Waseda University', 'The University of Tokyo']",['Japan'],2023-09
2310.00367,Jonas Belouadi,"Jonas Belouadi, Anne Lauscher, Steffen Eger",AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ,,,,,cs.CL cs.CV,http://creativecommons.org/licenses/by/4.0/,"  Generating bitmap graphics from text has gained considerable attention, yet for scientific figures, vector graphics are often preferred. Given that vector graphics are typically encoded using low-level graphics primitives, generating them directly is difficult. To address this, we propose the use of TikZ, a well-known abstract graphics language that can be compiled to vector graphics, as an intermediate representation of scientific figures. TikZ offers human-oriented, high-level commands, thereby facilitating conditional language modeling with any large language model. To this end, we introduce DaTikZ the first large-scale TikZ dataset, consisting of 120k TikZ drawings aligned with captions. We fine-tune LLaMA on DaTikZ, as well as our new model CLiMA, which augments LLaMA with multimodal CLIP embeddings. In both human and automatic evaluation, CLiMA and LLaMA outperform commercial GPT-4 and Claude 2 in terms of similarity to human-created figures, with CLiMA additionally improving text-image alignment. Our detailed analysis shows that all models generalize well and are not susceptible to memorization. GPT-4 and Claude 2, however, tend to generate more simplistic figures compared to both humans and our models. We make our framework, AutomaTikZ, along with model weights and datasets, publicly available. ","[{'version': 'v1', 'created': 'Sat, 30 Sep 2023 13:15:49 GMT'}]",2023-10-03,"[['Belouadi', 'Jonas', ''], ['Lauscher', 'Anne', ''], ['Eger', 'Steffen', '']]",0,1,2023-09-30,1,3,2,3,1,2,9486179c5ab6e0cff0ef919c34080a882bb9fe9f,263334353.0,https://www.semanticscholar.org/paper/9486179c5ab6e0cff0ef919c34080a882bb9fe9f,arXiv.org,2023.0,101.0,2.0,1.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2138207755', 'name': 'Jonas Belouadi'}, {'authorId': '29891652', 'name': 'Anne Lauscher'}, {'authorId': '2249760564', 'name': 'Steffen Eger'}]","['Universität Hamburg', 'University of Mannheim', 'Bielefeld University']",['Germany'],2023-09
2310.01423,Arslan Akram Doula,Arslan Akram,An Empirical Study of AI Generated Text Detection Tools,"15 Pages, 4 Figures, 2 Tables, 42 References",,,,cs.CL cs.AI cs.LG cs.LO,http://creativecommons.org/licenses/by-nc-sa/4.0/,"  Since ChatGPT has emerged as a major AIGC model, providing high-quality responses across a wide range of applications (including software development and maintenance), it has attracted much interest from many individuals. ChatGPT has great promise, but there are serious problems that might arise from its misuse, especially in the realms of education and public safety. Several AIGC detectors are available, and they have all been tested on genuine text. However, more study is needed to see how effective they are for multi-domain ChatGPT material. This study aims to fill this need by creating a multi-domain dataset for testing the state-of-the-art APIs and tools for detecting artificially generated information used by universities and other research institutions. A large dataset consisting of articles, abstracts, stories, news, and product reviews was created for this study. The second step is to use the newly created dataset to put six tools through their paces. Six different artificial intelligence (AI) text identification systems, including ""GPTkit,"" ""GPTZero,"" ""Originality,"" ""Sapling,"" ""Writer,"" and ""Zylalab,"" have accuracy rates between 55.29 and 97.0%. Although all the tools fared well in the evaluations, originality was particularly effective across the board. ","[{'version': 'v1', 'created': 'Wed, 27 Sep 2023 12:44:12 GMT'}]",2023-10-06,"[['Akram', 'Arslan', '']]",1,1,2023-09-27,1,1,4,1,0,1,82a86cc67d254ea8d2e49c9d7d394d265401c96d,249635702.0,https://www.semanticscholar.org/paper/82a86cc67d254ea8d2e49c9d7d394d265401c96d,arXiv.org,2023.0,44.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","[{'authorId': '2261277403', 'name': 'Arslan Akram'}]","['MLC Lab, Maharban House, House # 209,', 'Zafar Colony, Okara, 56300, Pakistan', 'Superior University']",['Pakistan'],2023-09
2310.01429,Eren Unlu Ph. D.,Eren Unlu,Chatmap : Large Language Model Interaction with Cartographic Data,"9 pages, 4 figures",,,,cs.CL cs.AI,http://creativecommons.org/licenses/by/4.0/,"  The swift advancement and widespread availability of foundational Large Language Models (LLMs), complemented by robust fine-tuning methodologies, have catalyzed their adaptation for innovative and industrious applications. Enabling LLMs to recognize and interpret geospatial data, while offering a linguistic access to vast cartographic datasets, is of significant importance. OpenStreetMap (OSM) is the most ambitious open-source global initiative offering detailed urban and rural geographic data, curated by a community of over 10 million contributors, which constitutes a great potential for LLM applications. In this study, we demonstrate the proof of concept and details of the process of fine-tuning a relatively small scale (1B parameters) LLM with a relatively small artificial dataset curated by a more capable teacher model, in order to provide a linguistic interface to the OSM data of an arbitrary urban region. Through this interface, users can inquire about a location's attributes, covering a wide spectrum of concepts, such as its touristic appeal or the potential profitability of various businesses in that vicinity. The study aims to provide an initial guideline for such generative artificial intelligence (AI) adaptations and demonstrate early signs of useful emerging abilities in this context even in minimal computational settings. The embeddings of artificially curated prompts including OSM data are also investigated in detail, which might be instrumental for potential geospatially aware urban Retrieval Augmented Generation (RAG) applications. ","[{'version': 'v1', 'created': 'Thu, 28 Sep 2023 15:32:36 GMT'}]",2023-10-04,"[['Unlu', 'Eren', '']]",0,0,2023-09-28,1,1,2,0,0,0,ec0ca7eb1f365a8ee74247b9724e190651483706,263608305.0,https://www.semanticscholar.org/paper/ec0ca7eb1f365a8ee74247b9724e190651483706,arXiv.org,2023.0,17.0,1.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Geography', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","[{'authorId': '34669076', 'name': 'Eren Unlu'}]","['Datategy SAS Paris, France']",['France'],2023-09
2310.01434,Tom\'as Marques,"Samuel Carreira, Tom\'as Marques, Jos\'e Ribeiro, Carlos Grilo",Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile,,,,,cs.CL cs.AI cs.LG,http://arxiv.org/licenses/nonexclusive-distrib/1.0/,"  The field of Artificial Intelligence has witnessed remarkable progress in recent years, especially with the emergence of powerful large language models (LLMs) based on the transformer architecture. Cloud-based LLMs, such as OpenAI's ChatGPT, offer impressive capabilities but come with concerns regarding latency and privacy due to network dependencies. This article presents an innovative approach to LLM inference, envisioning a future where LLMs with billions of parameters can be executed directly on mobile devices without network connectivity. The article showcases a fine-tuned GPT LLM with 3 billion parameters that can operate smoothly on devices with as low as 4GB of memory. Through the integration of native code and model quantization techniques, the application not only serves as a general-purpose assistant but also facilitates seamless mobile interactions with text-to-actions features. The article provides insights into the training pipeline, implementation details, test results, and future directions of on-device LLM inference. This breakthrough technology opens up possibilities for empowering users with sophisticated AI capabilities while preserving their privacy and eliminating latency concerns. ","[{'version': 'v1', 'created': 'Fri, 29 Sep 2023 16:30:49 GMT'}]",2023-10-04,"[['Carreira', 'Samuel', ''], ['Marques', 'Tomás', ''], ['Ribeiro', 'José', ''], ['Grilo', 'Carlos', '']]",1,1,2023-09-29,1,4,3,1,0,1,e22048955c6648201f0d708e8b0688d3b1be741d,263609154.0,https://www.semanticscholar.org/paper/e22048955c6648201f0d708e8b0688d3b1be741d,arXiv.org,2023.0,13.0,0.0,0.0,True,['Computer Science'],"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","[{'authorId': '2253468900', 'name': 'Samuel Carreira'}, {'authorId': '2253587452', 'name': ""Tom'as Marques""}, {'authorId': '2195198570', 'name': 'J. Ribeiro'}, {'authorId': '2253468800', 'name': 'Carlos Grilo'}]",['Instituto Politécnico de Leiria'],['Portugal'],2023-09
