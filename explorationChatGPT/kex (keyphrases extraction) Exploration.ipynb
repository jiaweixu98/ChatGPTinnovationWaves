{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kex\n",
    "import pandas as pd\n",
    "readfile = \"D:/data/github/2023summer/ResultsForChatGPTinnovationWaves/\"\n",
    "df = pd.read_csv(readfile + 'LLMs0730.csv')\n",
    "ChatGPTf = df.loc[df['ContainChatGPT'] == 1]\n",
    "# chatGPT发表后，包含ChatGPT的文献（2022年12月至2023年7月，共899篇）\n",
    "ChatGPTf = ChatGPTf.loc[ChatGPTf['publish_date_v1'] > '2022-11-99']\n",
    "ChatGPTf['month'] = ChatGPTf['publish_date_v1'].str.slice(start=5,stop=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "05    249\n",
       "04    171\n",
       "06    149\n",
       "03    126\n",
       "07    108\n",
       "02     59\n",
       "01     24\n",
       "12     13\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChatGPTf['month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全部都预训练好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf\n",
    "modelTF = kex.TF()\n",
    "test_sentences = list(ChatGPTf['abstract'].values)\n",
    "modelTF.train(test_sentences, export_directory='./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf\n",
    "modelTFt = kex.TF()\n",
    "test_sentences = list(ChatGPTf['title'].values)\n",
    "modelTFt.train(test_sentences, export_directory='./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 18:38:46 INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2023-08-07 18:38:46 INFO     built Dictionary(7474 unique tokens: [',', '.', '10,732', 'address', 'adopt']...) from 899 documents (total 122851 corpus positions)\n",
      "2023-08-07 18:38:46 INFO     collecting document frequencies\n",
      "2023-08-07 18:38:46 INFO     PROGRESS: processing document #0\n",
      "2023-08-07 18:38:47 INFO     calculating IDF weights for 899 documents and 7473 features (75979 matrix non-zeros)\n",
      "2023-08-07 18:38:47 INFO     saving TfidfModel object under ./tmp\\tfidf_model, separately None\n",
      "2023-08-07 18:38:47 INFO     saved ./tmp\\tfidf_model\n",
      "2023-08-07 18:38:47 INFO     saving dictionary mapping to ./tmp\\tfidf_dict\n"
     ]
    }
   ],
   "source": [
    "#tf-idf\n",
    "modelTFIDF = kex.TFIDF()\n",
    "test_sentences = list(ChatGPTf['abstract'].values)\n",
    "modelTFIDF.train(test_sentences, export_directory='./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 18:39:04 INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2023-08-07 18:39:04 INFO     built Dictionary(7474 unique tokens: [',', '.', '10,732', 'address', 'adopt']...) from 899 documents (total 122851 corpus positions)\n",
      "2023-08-07 18:39:04 INFO     collecting document frequencies\n",
      "2023-08-07 18:39:04 INFO     PROGRESS: processing document #0\n",
      "2023-08-07 18:39:04 INFO     calculating IDF weights for 899 documents and 7473 features (75979 matrix non-zeros)\n",
      "2023-08-07 18:39:04 INFO     saving TfidfModel object under ./tmp\\tfidf_model, separately None\n",
      "2023-08-07 18:39:04 INFO     saved ./tmp\\tfidf_model\n",
      "2023-08-07 18:39:04 INFO     saving dictionary mapping to ./tmp\\tfidf_dict\n"
     ]
    }
   ],
   "source": [
    "#TFIDFRank\n",
    "modelTFIDFRank = kex.TFIDFRank()\n",
    "test_sentences = list(ChatGPTf['abstract'].values)\n",
    "modelTFIDFRank.train(test_sentences, export_directory='./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LexSpec\n",
    "modelLexSpec = kex.LexSpec()\n",
    "test_sentences = list(ChatGPTf['abstract'].values)\n",
    "modelLexSpec.train(test_sentences, export_directory='./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LexRank\n",
    "modelLexRank = kex.LexRank()\n",
    "test_sentences = list(ChatGPTf['abstract'].values)\n",
    "modelLexRank.train(test_sentences, export_directory='./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyate.term_extraction_pipeline.TermExtractionPipeline at 0x1c4ca1c6a60>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预加载\n",
    "import spacy\n",
    "from pyate.term_extraction_pipeline import TermExtractionPipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"combo_basic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先看总体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     31\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。: 'C:\\\\Users\\\\jiawei/nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m stem2raw \u001b[39m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m ab \u001b[39min\u001b[39;00m ChatGPTf[\u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m----> 5\u001b[0m     results \u001b[39m=\u001b[39m modelTF\u001b[39m.\u001b[39;49mget_keywords(ab, n_keywords\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m results:\n\u001b[0;32m      7\u001b[0m         stem2raw[item[\u001b[39m'\u001b[39m\u001b[39mstemmed\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\site-packages\\kex\\lexical_specificity.py:227\u001b[0m, in \u001b[0;36mTF.get_keywords\u001b[1;34m(self, document, n_keywords)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_trained, \u001b[39m'\u001b[39m\u001b[39mprovide prior before running inference\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    226\u001b[0m \u001b[39m# convert phrase instance\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m phrase_instance, stemmed_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphrase_constructor\u001b[39m.\u001b[39;49mtokenize_and_stem_and_phrase(document)\n\u001b[0;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(phrase_instance) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    229\u001b[0m     \u001b[39m# at least 2 phrase are needed to extract keyphrase\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\site-packages\\kex\\_phrase_constructor.py:180\u001b[0m, in \u001b[0;36mPhraseConstructor.tokenize_and_stem_and_phrase\u001b[1;34m(self, document)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize_and_stem_and_phrase\u001b[39m(\u001b[39mself\u001b[39m, document: \u001b[39mstr\u001b[39m):\n\u001b[0;32m    170\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" tokenization & stemming & phrasing\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \n\u001b[0;32m    172\u001b[0m \u001b[39m     Parameter\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39m    `Phrase.phrase` object, stemmed_token\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     sentence_token, stemmed, pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess(document)\n\u001b[0;32m    182\u001b[0m     \u001b[39m# phraser instance 若是日语，join_without_space为真\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     phrase_structure \u001b[39m=\u001b[39m Phrase(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__language \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mja\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    184\u001b[0m                               maximum_word_number\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__maximum_word_number,\n\u001b[0;32m    185\u001b[0m                               maximum_char_number\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__maximum_char_number)\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\site-packages\\kex\\_phrase_constructor.py:164\u001b[0m, in \u001b[0;36mPhraseConstructor.preprocess\u001b[1;34m(self, document, flatten_sentence)\u001b[0m\n\u001b[0;32m    160\u001b[0m sentence_token \u001b[39m=\u001b[39m [[\n\u001b[0;32m    161\u001b[0m     w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m split_contractions(web_tokenizer(s)) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (w\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    162\u001b[0m ] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(split_multi(document)) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s\u001b[39m.\u001b[39mstrip()) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m    163\u001b[0m stemmed \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__stemmer\u001b[39m.\u001b[39mstem(x), words)) \u001b[39mfor\u001b[39;00m words \u001b[39min\u001b[39;00m sentence_token]\n\u001b[1;32m--> 164\u001b[0m pos \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimplify_pos(x[\u001b[39m1\u001b[39m]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pos_tagger(words))) \u001b[39mfor\u001b[39;00m words \u001b[39min\u001b[39;00m sentence_token]\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m flatten_sentence:\n\u001b[0;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39msentence_token)), \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39mstemmed)), \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39mpos))\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\site-packages\\kex\\_phrase_constructor.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    160\u001b[0m sentence_token \u001b[39m=\u001b[39m [[\n\u001b[0;32m    161\u001b[0m     w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m split_contractions(web_tokenizer(s)) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (w\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    162\u001b[0m ] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(split_multi(document)) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s\u001b[39m.\u001b[39mstrip()) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m    163\u001b[0m stemmed \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__stemmer\u001b[39m.\u001b[39mstem(x), words)) \u001b[39mfor\u001b[39;00m words \u001b[39min\u001b[39;00m sentence_token]\n\u001b[1;32m--> 164\u001b[0m pos \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimplify_pos(x[\u001b[39m1\u001b[39m]), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__pos_tagger(words))) \u001b[39mfor\u001b[39;00m words \u001b[39min\u001b[39;00m sentence_token]\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m flatten_sentence:\n\u001b[0;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39msentence_token)), \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39mstemmed)), \u001b[39mlist\u001b[39m(chain(\u001b[39m*\u001b[39mpos))\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\site-packages\\nltk\\tag\\__init__.py:160\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpos_tag\u001b[39m(tokens, tagset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, lang\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meng\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    136\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     tagger \u001b[39m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\site-packages\\nltk\\tag\\__init__.py:106\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    104\u001b[0m     tagger\u001b[39m.\u001b[39mload(ap_russian_model_loc)\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     tagger \u001b[39m=\u001b[39m PerceptronTagger()\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\site-packages\\nltk\\tag\\perceptron.py:168\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m load:\n\u001b[0;32m    167\u001b[0m     AP_MODEL_LOC \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m--> 168\u001b[0m         find(\u001b[39m\"\u001b[39;49m\u001b[39mtaggers/averaged_perceptron_tagger/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m PICKLE)\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload(AP_MODEL_LOC)\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\site-packages\\nltk\\data.py:524\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39m# Check each item in our path\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[39mfor\u001b[39;00m path_ \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m    523\u001b[0m     \u001b[39m# Is the path item a zipfile?\u001b[39;00m\n\u001b[1;32m--> 524\u001b[0m     \u001b[39mif\u001b[39;00m path_ \u001b[39mand\u001b[39;00m (os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49misfile(path_) \u001b[39mand\u001b[39;00m path_\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m    525\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    526\u001b[0m             \u001b[39mreturn\u001b[39;00m ZipFilePathPointer(path_, resource_name)\n",
      "File \u001b[1;32md:\\software-acsii\\anaconda\\lib\\genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     st \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path)\n\u001b[0;32m     31\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "key5Counter = Counter()\n",
    "stem2raw = {}\n",
    "for ab in ChatGPTf['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        stem2raw[item['stemmed']] = item['raw'][0]\n",
    "        key5Counter[item['stemmed']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropSet = set(['chatgpt','larg languag model','llm','model','paper','studi','research','result','AI','languag model','openai chatgpt','languag','natur languag process','openai chatgpt','natur languag','AI model','foundat model','chatgpt abil','pre-train languag model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT                      802\n",
      "large language models        424\n",
      "LLMs                         378\n",
      "models                       287\n",
      "paper                        276\n",
      "tasks                        232\n",
      "performance                  211\n",
      "results                      177\n",
      "study                        172\n",
      "research                     156\n",
      "data                         126\n",
      "AI                           112\n",
      "dataset                      93\n",
      "humans                       80\n",
      "prompts                      80\n",
      "language models              72\n",
      "language                     67\n",
      "evaluation                   67\n",
      "method                       66\n",
      "potentials                   66\n",
      "code                         64\n",
      "generation                   62\n",
      "questions                    61\n",
      "challenge                    61\n",
      "natural language processing  60\n",
      "text                         58\n",
      "capabilities                 55\n",
      "works                        52\n",
      "findings                     48\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:28} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                        232\n",
      "performance                  211\n",
      "data                         126\n",
      "dataset                      93\n",
      "humans                       80\n",
      "prompts                      80\n",
      "evaluation                   67\n",
      "method                       66\n",
      "potentials                   66\n",
      "code                         64\n",
      "generation                   62\n",
      "questions                    61\n",
      "challenge                    61\n",
      "text                         58\n",
      "capabilities                 55\n",
      "works                        52\n",
      "findings                     48\n",
      "development                  48\n",
      "effectiveness                47\n",
      "systems                      44\n",
      "ability                      42\n",
      "ChatGPT performance          40\n",
      "information                  38\n",
      "responses                    38\n",
      "approach                     36\n",
      "Generative AI                32\n",
      "Applications                 26\n",
      "human evaluators             25\n",
      "knowledge                    23\n"
     ]
    }
   ],
   "source": [
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "n = 30\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:28} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key5Counter = Counter()\n",
    "stem2raw = {}\n",
    "for ab in ChatGPTf['abstract']:\n",
    "    results = modelTFIDF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        stem2raw[item['stemmed']] = item['raw'][0]\n",
    "        key5Counter[item['stemmed']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AI', 30),\n",
       " ('llm', 25),\n",
       " ('educ', 22),\n",
       " ('student', 21),\n",
       " ('code', 21),\n",
       " ('text', 19),\n",
       " ('chatbot', 19),\n",
       " ('question', 18),\n",
       " ('tool', 18),\n",
       " ('program', 17),\n",
       " ('instruct', 17),\n",
       " ('imag', 16),\n",
       " ('data', 15),\n",
       " ('gpt-4', 15),\n",
       " ('translat', 13),\n",
       " ('content', 13),\n",
       " ('detect', 12),\n",
       " ('attack', 12),\n",
       " ('nlp', 12),\n",
       " ('task', 12),\n",
       " ('dataset', 12),\n",
       " ('answer', 11),\n",
       " ('prompt', 11),\n",
       " ('problem', 11),\n",
       " ('respons', 10),\n",
       " ('aigc', 10),\n",
       " ('inform', 10),\n",
       " ('entiti', 9),\n",
       " ('user', 9),\n",
       " ('solut', 9),\n",
       " ('peopl', 9),\n",
       " ('machin translat', 9),\n",
       " ('queri', 9),\n",
       " ('output', 9),\n",
       " ('knowledg', 9),\n",
       " ('detector', 9),\n",
       " ('recommend', 9),\n",
       " ('topic', 8),\n",
       " ('review', 8),\n",
       " ('exam', 8),\n",
       " ('gpt', 8),\n",
       " ('plm', 8),\n",
       " ('hallucin', 8),\n",
       " ('summari', 8),\n",
       " ('softwar engin', 8),\n",
       " ('rlhf', 8),\n",
       " ('feedback', 8),\n",
       " ('video', 8),\n",
       " ('benchmark', 8),\n",
       " ('evalu', 8),\n",
       " ('lm', 8),\n",
       " ('articl', 7),\n",
       " ('applic', 7),\n",
       " ('e.g.', 7),\n",
       " ('abil', 7),\n",
       " ('reason', 7),\n",
       " ('sentiment analysi', 7),\n",
       " ('design', 7),\n",
       " ('transform', 7),\n",
       " ('system', 7),\n",
       " ('cot', 7),\n",
       " ('knowledg graph', 7),\n",
       " ('ner', 7),\n",
       " ('order', 6),\n",
       " ('algorithm', 6),\n",
       " ('style', 6),\n",
       " ('essay', 6),\n",
       " ('concept', 6),\n",
       " ('fact', 6),\n",
       " ('ML', 6),\n",
       " ('nlp task', 6),\n",
       " ('bert', 6),\n",
       " ('QA', 6),\n",
       " ('graph', 6),\n",
       " ('privaci', 6),\n",
       " ('literatur', 6),\n",
       " ('assess', 6),\n",
       " ('idea', 6),\n",
       " ('teacher', 6),\n",
       " ('align', 6),\n",
       " ('claim', 6),\n",
       " ('agi', 6),\n",
       " ('foundat model', 6),\n",
       " ('technolog', 6),\n",
       " ('chatgpt-4', 6),\n",
       " ('instruct tune', 6),\n",
       " ('field', 6),\n",
       " ('memori', 6),\n",
       " ('polici', 6),\n",
       " ('gpt-3.5', 6),\n",
       " ('sota', 5),\n",
       " ('metric', 5),\n",
       " ('error', 5),\n",
       " ('survey', 5),\n",
       " ('paraphras', 5),\n",
       " ('activ', 5),\n",
       " ('principl', 5),\n",
       " ('secur', 5),\n",
       " ('physic', 5),\n",
       " ('mathemat', 5),\n",
       " ('industri', 5),\n",
       " ('correct', 5),\n",
       " ('correct answer', 5),\n",
       " ('introduct', 5),\n",
       " ('logic reason', 5),\n",
       " ('group', 5),\n",
       " ('write', 5),\n",
       " ('kg', 5),\n",
       " ('studi', 5),\n",
       " ('medic imag', 5),\n",
       " ('robust', 5),\n",
       " ('data augment', 5),\n",
       " ('safeti', 5),\n",
       " ('english', 5),\n",
       " ('version', 5),\n",
       " ('univers', 5),\n",
       " ('gai', 5),\n",
       " ('github', 5),\n",
       " ('difficulti', 5),\n",
       " ('sentiment', 5),\n",
       " ('bard', 5),\n",
       " ('phase', 5),\n",
       " ('role', 5),\n",
       " ('test', 5),\n",
       " ('risk', 5),\n",
       " ('research', 5),\n",
       " ('entiti recognit', 4),\n",
       " ('emot', 4),\n",
       " ('abus', 4),\n",
       " ('theori', 4),\n",
       " ('regul', 4),\n",
       " ('plagiar', 4),\n",
       " ('stanc detect', 4),\n",
       " ('explan', 4),\n",
       " ('radiolog report', 4),\n",
       " ('AI system', 4),\n",
       " ('govern', 4),\n",
       " ('human', 4),\n",
       " ('approach', 4),\n",
       " ('googl translat', 4),\n",
       " ('particip', 4),\n",
       " ('creativ', 4),\n",
       " ('toxic', 4),\n",
       " ('chatgpt-gener text', 4),\n",
       " ('explain', 4),\n",
       " ('failur', 4),\n",
       " ('educ sector', 4),\n",
       " ('T5', 4),\n",
       " ('instructgpt', 4),\n",
       " ('KG', 4),\n",
       " ('convers', 4),\n",
       " ('techniqu', 4),\n",
       " ('opinion', 4),\n",
       " ('percept', 4),\n",
       " ('network', 4),\n",
       " ('stack overflow', 4),\n",
       " ('text summar', 4),\n",
       " ('decis', 4),\n",
       " ('translat qualiti', 4),\n",
       " ('framework', 4),\n",
       " ('robot', 4),\n",
       " ('person', 4),\n",
       " ('event', 4),\n",
       " ('relationship', 4),\n",
       " ('vlm', 4),\n",
       " ('ai-gener content', 4),\n",
       " ('law', 4),\n",
       " ('academia', 4),\n",
       " ('MT', 4),\n",
       " ('classif', 4),\n",
       " ('correct solut', 4),\n",
       " ('qualiti', 4),\n",
       " ('term', 4),\n",
       " ('artifici intellig', 4),\n",
       " ('argument', 4),\n",
       " ('financ', 4),\n",
       " ('bias', 4),\n",
       " ('ethic concern', 4),\n",
       " ('learner', 4),\n",
       " ('environ', 4),\n",
       " ('dialogu', 4),\n",
       " ('sentiment analysi task', 4),\n",
       " ('servic', 4),\n",
       " ('googl bard', 4),\n",
       " ('reliabl', 4),\n",
       " ('machine-gener text', 4),\n",
       " ('author', 4),\n",
       " ('sourc code', 4),\n",
       " ('patient', 4),\n",
       " ('recommend scenario', 4),\n",
       " ('rule', 4),\n",
       " ('RL', 4),\n",
       " ('token', 4),\n",
       " ('genai', 4),\n",
       " ('input', 4),\n",
       " ('cost', 4),\n",
       " ('roberta', 4),\n",
       " ('thought', 4),\n",
       " ('roadmap', 4),\n",
       " ('usag', 4),\n",
       " ('bingchat', 4),\n",
       " ('agent', 4),\n",
       " ('factual knowledg', 4),\n",
       " ('open-sourc llm', 4),\n",
       " ('social media', 3),\n",
       " ('machin', 3),\n",
       " ('practition', 3),\n",
       " ('benefit', 3),\n",
       " ('art', 3),\n",
       " ('nlg', 3),\n",
       " ('multitud', 3),\n",
       " ('mind', 3),\n",
       " ('2019', 3),\n",
       " ('sustain', 3),\n",
       " ('AI regul', 3),\n",
       " ('identif', 3),\n",
       " ('type', 3),\n",
       " ('advantag', 3),\n",
       " ('submiss', 3),\n",
       " ('radiologist', 3),\n",
       " ('medic domain', 3),\n",
       " ('societi', 3),\n",
       " ('label', 3),\n",
       " ('human expert', 3),\n",
       " ('hand', 3),\n",
       " ('bug', 3),\n",
       " ('translat perform', 3),\n",
       " ('truth', 3),\n",
       " ('programm', 3),\n",
       " ('apr', 3),\n",
       " ('program repair', 3),\n",
       " ('mathemat reason', 3),\n",
       " ('nli', 3),\n",
       " ('chatgpt-3', 3),\n",
       " ('evolut', 3),\n",
       " ('catalyst', 3),\n",
       " ('journal', 3),\n",
       " ('diseas', 3),\n",
       " ('presenc', 3),\n",
       " ('persona', 3),\n",
       " ('catalog', 3),\n",
       " ('hate speech', 3),\n",
       " ('comparison', 3),\n",
       " ('countri', 3),\n",
       " ('4', 3),\n",
       " ('event extract', 3),\n",
       " ('effort', 3),\n",
       " ('zero-shot set', 3),\n",
       " ('assist', 3),\n",
       " ('infer', 3),\n",
       " ('extern knowledg', 3),\n",
       " ('inabl', 3),\n",
       " ('sampl size', 3),\n",
       " ('log', 3),\n",
       " ('document', 3),\n",
       " ('releas', 3),\n",
       " ('number', 3),\n",
       " ('oper', 3),\n",
       " ('softwar', 3),\n",
       " ('collabor', 3),\n",
       " ('occup', 3),\n",
       " ('tweet', 3),\n",
       " ('gener AI tool', 3),\n",
       " ('human feedback', 3),\n",
       " ('schema', 3),\n",
       " ('work', 3),\n",
       " ('creation', 3),\n",
       " ('in-context learn', 3),\n",
       " ('discuss', 3),\n",
       " ('human prefer', 3),\n",
       " ('imag caption', 3),\n",
       " ('modal', 3),\n",
       " ('ethic', 3),\n",
       " ('capabl', 3),\n",
       " ('word', 3),\n",
       " ('intent', 3),\n",
       " ('factual', 3),\n",
       " ('report', 3),\n",
       " ('feasibl', 3),\n",
       " ('assign', 3),\n",
       " ('abstract', 3),\n",
       " ('scale', 3),\n",
       " ('breadth', 3),\n",
       " ('histori', 3),\n",
       " ('misinform', 3),\n",
       " ('exercis', 3),\n",
       " ('scenario', 3),\n",
       " ('grammat error correct', 3),\n",
       " ('metavers', 3),\n",
       " ('medic advic', 3),\n",
       " ('onlin', 3),\n",
       " ('recommend system', 3),\n",
       " ('stanc', 3),\n",
       " ('human analyst', 3),\n",
       " ('ecosystem', 3),\n",
       " ('graph structur', 3),\n",
       " ('gap', 3),\n",
       " ('search', 3),\n",
       " ('represent', 3),\n",
       " ('mistak', 3),\n",
       " ('weak', 3),\n",
       " ('rate', 3),\n",
       " ('kind', 3),\n",
       " ('method', 3),\n",
       " ('diagnos', 3),\n",
       " ('classifi', 3),\n",
       " ('gpt4', 3),\n",
       " ('DL', 3),\n",
       " ('step', 3),\n",
       " ('tendenc', 3),\n",
       " ('eas', 3),\n",
       " ('drawback', 3),\n",
       " ('situat', 3),\n",
       " ('area', 3),\n",
       " ('item', 3),\n",
       " ('faith', 3),\n",
       " ('harm content', 3),\n",
       " ('adversari exampl', 3),\n",
       " ('outlook', 3),\n",
       " ('bia', 3),\n",
       " ('corpu', 3),\n",
       " ('plan', 3),\n",
       " ('llama', 3),\n",
       " ('IR', 3),\n",
       " ('opportun', 3),\n",
       " ('construct', 3),\n",
       " ('percentag', 3),\n",
       " ('behavior', 3),\n",
       " ('graph data', 3),\n",
       " ('AI technolog', 3),\n",
       " ('causal', 3),\n",
       " ('synthet dataset', 3),\n",
       " ('methodolog', 3),\n",
       " ('launch', 3),\n",
       " ('realm', 3),\n",
       " ('book', 3),\n",
       " ('genai tool', 3),\n",
       " ('higher educ', 3),\n",
       " ('multi-turn convers', 3),\n",
       " ('exampl', 3),\n",
       " ('flan', 3),\n",
       " ('educ activ', 3),\n",
       " ('control', 3),\n",
       " ('gpt3.5', 3),\n",
       " ('gpt-3.5-turbo', 3),\n",
       " ('websit', 3),\n",
       " ('diagnosi', 3),\n",
       " ('vision-languag model', 3),\n",
       " ('object', 3),\n",
       " ('comput vision', 3),\n",
       " ('expert', 3),\n",
       " ('fair', 3),\n",
       " ('human-written text', 3),\n",
       " ('ethic implic', 3),\n",
       " ('consist', 3),\n",
       " ('SE', 3),\n",
       " ('vnhsge', 3),\n",
       " ('vietnames student', 3),\n",
       " ('properti', 3),\n",
       " ('shortcom', 3),\n",
       " ('investor', 3),\n",
       " ('annot', 3),\n",
       " ('chat', 3),\n",
       " ('cours', 3),\n",
       " ('strategi', 3),\n",
       " ('ppo', 3),\n",
       " ('fact-check', 3),\n",
       " ('textit', 3),\n",
       " ('drug', 3),\n",
       " ('attribut', 3),\n",
       " ('impact', 3),\n",
       " ('non-expert', 3),\n",
       " ('public opinion', 3),\n",
       " ('subject', 3),\n",
       " ('simul', 3),\n",
       " ('rouge-l', 2),\n",
       " ('sentenc', 2),\n",
       " ('emoji', 2),\n",
       " ('factual error', 2),\n",
       " ('error type', 2),\n",
       " ('featur', 2),\n",
       " ('systemat comparison', 2),\n",
       " ('ture test', 2),\n",
       " ('predict', 2),\n",
       " ('maxim', 2),\n",
       " ('nlg model', 2),\n",
       " ('tom', 2),\n",
       " ('charact', 2),\n",
       " ('dialogu gener', 2),\n",
       " ('ID', 2),\n",
       " ('ood', 2),\n",
       " ('EU', 2),\n",
       " ('entertain', 2),\n",
       " ('posit sentiment', 2),\n",
       " ('1950', 2),\n",
       " ('review articl', 2),\n",
       " ('drug discoveri', 2),\n",
       " ('manuscript', 2),\n",
       " ('candid', 2),\n",
       " ('pegasu', 2),\n",
       " ('children', 2),\n",
       " ('spatial reason', 2),\n",
       " ('poetri', 2),\n",
       " ('humor', 2),\n",
       " ('stanc detect task', 2),\n",
       " ('social media post', 2),\n",
       " ('radiolog', 2),\n",
       " ('polit elect', 2),\n",
       " ('statement', 2),\n",
       " ('har', 2),\n",
       " ('interfac', 2),\n",
       " ('sector', 2),\n",
       " ('plethora', 2),\n",
       " ('ethic principl', 2),\n",
       " ('judgment', 2),\n",
       " ('advic', 2),\n",
       " ('hc3', 2),\n",
       " ('analog', 2),\n",
       " ('repair', 2),\n",
       " ('translat prompt', 2),\n",
       " ('multilingu translat', 2),\n",
       " ('translat abil', 2),\n",
       " ('trust', 2),\n",
       " ('chatbot respons', 2),\n",
       " ('human-lik respons', 2),\n",
       " ('ethic risk', 2),\n",
       " ('patch', 2),\n",
       " ('apr approach', 2),\n",
       " ('incorrect patch', 2),\n",
       " ('patch gener', 2),\n",
       " ('testb', 2),\n",
       " ('profici', 2),\n",
       " ('medic benchmark', 2),\n",
       " ('79', 2),\n",
       " ('undergraduate-level mathemat', 2),\n",
       " ('data visualis', 2),\n",
       " ('chat2vi', 2),\n",
       " ('construct industri', 2),\n",
       " ('chatgpt failur', 2),\n",
       " ('math', 2),\n",
       " ('systemat review', 2),\n",
       " ('nlu task', 2),\n",
       " ('commonsens reason', 2),\n",
       " ('control group', 2),\n",
       " ('convers AI', 2),\n",
       " ('nlp techniqu', 2),\n",
       " ('debut', 2),\n",
       " ('7', 2),\n",
       " ('human tutor', 2),\n",
       " ('100', 2),\n",
       " ('scheme', 2),\n",
       " ('medic field', 2),\n",
       " ('command', 2),\n",
       " ('scratch', 2),\n",
       " ('etc.', 2),\n",
       " ('decomposit', 2),\n",
       " ('document-level translat', 2),\n",
       " ('translat direct', 2),\n",
       " ('gpt model', 2),\n",
       " ('shot', 2),\n",
       " ('member', 2),\n",
       " ('probabl', 2),\n",
       " ('understand abil', 2),\n",
       " ('red team', 2),\n",
       " ('user prefer', 2),\n",
       " ('conjunct', 2),\n",
       " ('practic', 2),\n",
       " ('pattern', 2),\n",
       " ('prompt pattern', 2),\n",
       " ('prompt engin', 2),\n",
       " ('prompt engin techniqu', 2),\n",
       " ('black-box llm', 2),\n",
       " ('out-of-distribut', 2),\n",
       " ('llm-gener respons', 2),\n",
       " ('robot applic', 2),\n",
       " ('matrix', 2),\n",
       " ('time', 2),\n",
       " ('view', 2),\n",
       " ('healthcar', 2),\n",
       " ('point', 2),\n",
       " ('part', 2),\n",
       " ('chatgpt4', 2),\n",
       " ('fci', 2),\n",
       " ('complet', 2),\n",
       " ('cross-lingu transfer', 2),\n",
       " ('internet', 2),\n",
       " ('AI tool', 2),\n",
       " ('design process', 2),\n",
       " ('visual', 2),\n",
       " ('bow', 2),\n",
       " ('baselin', 2),\n",
       " ('specialis model', 2),\n",
       " ('optim problem', 2),\n",
       " ('complex task', 2),\n",
       " ('experi', 2),\n",
       " ('end', 2),\n",
       " ('begin', 2),\n",
       " ('automat evalu metric', 2),\n",
       " ('digit content', 2),\n",
       " ('multimod', 2),\n",
       " ('visual chatgpt', 2),\n",
       " ('demonstr', 2),\n",
       " ('tiktok', 2),\n",
       " ('wave', 2),\n",
       " ('extract', 2),\n",
       " ('cross-mod encod', 2),\n",
       " ('defens', 2),\n",
       " ('prefer', 2),\n",
       " ('align techniqu', 2),\n",
       " ('bound', 2),\n",
       " ('multimod system', 2),\n",
       " ('disclosur', 2),\n",
       " ('creativ content', 2),\n",
       " ('dall-e2', 2),\n",
       " ('trustworthi', 2),\n",
       " ('stabl diffus', 2),\n",
       " ('current dialogu system', 2),\n",
       " ('databas schema', 2),\n",
       " ('manag', 2),\n",
       " ('extent', 2),\n",
       " ('refactor', 2),\n",
       " ('third-parti librari', 2),\n",
       " ('test question', 2),\n",
       " ('competit', 2),\n",
       " ('passag', 2),\n",
       " ('fine-grain compress', 2),\n",
       " ('gelu', 2),\n",
       " ('glue', 2),\n",
       " ('softmax', 2),\n",
       " ('layer normal', 2),\n",
       " ('gpt-3', 2),\n",
       " ('comput', 2),\n",
       " ('vision', 2),\n",
       " ('medic diagnosi', 2),\n",
       " ('headlin', 2),\n",
       " ('correl', 2),\n",
       " ('measur', 2),\n",
       " ('refin', 2),\n",
       " ('platform', 2),\n",
       " ('innov', 2),\n",
       " ('2017', 2),\n",
       " ('gec', 2),\n",
       " ('over-correct', 2),\n",
       " ('pro', 2),\n",
       " ('reader', 2),\n",
       " ('obstacl', 2),\n",
       " ('github copilot', 2),\n",
       " ('detect method', 2),\n",
       " ('medic knowledg', 2),\n",
       " ('accur advic', 2),\n",
       " ('semant', 2),\n",
       " ('instruct data', 2),\n",
       " ('amount', 2),\n",
       " ('phenomena', 2),\n",
       " ('mturk', 2),\n",
       " ('annot task', 2),\n",
       " ('agreement', 2),\n",
       " ('factual inconsist', 2),\n",
       " ('uncertainti', 2),\n",
       " ('stabil', 2),\n",
       " ('level', 2),\n",
       " ('classif task', 2),\n",
       " ('deploy', 2),\n",
       " ('user privaci', 2),\n",
       " ('academ write', 2),\n",
       " ('scientist', 2),\n",
       " ('access', 2),\n",
       " ('set', 2),\n",
       " ('commonsens knowledg', 2),\n",
       " ('commonsens problem', 2),\n",
       " ('tip', 2),\n",
       " ('scientif write', 2),\n",
       " ('outlin', 2),\n",
       " ('sub-task', 2),\n",
       " ('commun', 2),\n",
       " ('overview', 2),\n",
       " ('pedagogi', 2),\n",
       " ('forc concept inventori', 2),\n",
       " ('thing', 2),\n",
       " ('histor text', 2),\n",
       " ('varianc', 2),\n",
       " ('hug face', 2),\n",
       " ('AI task', 2),\n",
       " ('AI model', 2),\n",
       " ('decad', 2),\n",
       " ('gener summari', 2),\n",
       " ('famili', 2),\n",
       " ('anecdot exampl', 2),\n",
       " ('initi output', 2),\n",
       " ('singl llm', 2),\n",
       " ('1st', 2),\n",
       " ('year', 2),\n",
       " ('FE', 2),\n",
       " ('engin', 2),\n",
       " ('openai chatgpt-4', 2),\n",
       " ('model scale', 2),\n",
       " ('llama-13b', 2),\n",
       " ('gener text', 2),\n",
       " ('multi-turn dialogu', 2),\n",
       " ('guardrail', 2),\n",
       " ('interact', 2),\n",
       " ('degre', 2),\n",
       " ('fraud', 2),\n",
       " ('cheat', 2),\n",
       " ('seri', 2),\n",
       " ('direct', 2),\n",
       " ('medicin', 2),\n",
       " ('trial', 2),\n",
       " ('choic', 2),\n",
       " ('maximum number', 2),\n",
       " ('treatment', 2),\n",
       " ('versatil', 2),\n",
       " ('translat instruct', 2),\n",
       " ('evalu metric', 2),\n",
       " ('intersect', 2),\n",
       " ('rise', 2),\n",
       " ('ift', 2),\n",
       " ('automl', 2),\n",
       " ('caption', 2),\n",
       " ('motiv', 2),\n",
       " ('discrimin', 2),\n",
       " ('synthet data', 2),\n",
       " ('condit', 2),\n",
       " ('sequenc', 2),\n",
       " ('summari faith', 2),\n",
       " ('slu', 2),\n",
       " ('dst', 2),\n",
       " ('dialogu state track', 2),\n",
       " ('accur', 2),\n",
       " ('aigc model', 2),\n",
       " ('privaci threat', 2),\n",
       " ('harm', 2),\n",
       " ('tempor relat', 2),\n",
       " ('develop', 2),\n",
       " (\"students' percept\", 2),\n",
       " ('diagram', 2),\n",
       " ('scholar', 2),\n",
       " ('argument write', 2),\n",
       " ('vocabulari', 2),\n",
       " ('quantiti', 2),\n",
       " ('textbf', 2),\n",
       " ('chines', 2),\n",
       " ('advent', 2),\n",
       " ('busi', 2),\n",
       " ('threat', 2),\n",
       " ('perspect', 2),\n",
       " ('web', 2),\n",
       " ('therapist', 2),\n",
       " ('textbook', 2),\n",
       " ('analysi', 2),\n",
       " ('interest', 2),\n",
       " ('cskb', 2),\n",
       " ('bioinformat', 2),\n",
       " ('progress', 2),\n",
       " ('aspect', 2),\n",
       " ('dall 2', 2),\n",
       " ('robot system', 2),\n",
       " ('compani', 2),\n",
       " ('news', 2),\n",
       " ('architectur design', 2),\n",
       " ('team', 2),\n",
       " ('creativ write', 2),\n",
       " ('medic text', 2),\n",
       " ('fluenci', 2),\n",
       " ('calibr', 2),\n",
       " ('traceabl', 2),\n",
       " ('bloom', 2),\n",
       " ('reproduc', 2),\n",
       " ('bot', 2),\n",
       " ('chatgpt-4 perform', 2),\n",
       " ('social norm', 2),\n",
       " ('coher', 2),\n",
       " ('academ integr', 2),\n",
       " ('imdb', 2),\n",
       " ('causal reason', 2),\n",
       " ('robot abil', 2),\n",
       " ('requir', 2),\n",
       " ('possibl', 2),\n",
       " ('tabular data', 2),\n",
       " ('tabular dataset', 2),\n",
       " ('automat metric', 2),\n",
       " ('databas', 2),\n",
       " ('5,000', 2),\n",
       " ('1000', 2),\n",
       " ('long document', 2),\n",
       " ('paradigm', 2),\n",
       " ('plc', 2),\n",
       " ('automat identif', 2),\n",
       " ('eda', 2),\n",
       " ('outcom', 2),\n",
       " ('dnn', 2),\n",
       " ('IP', 2),\n",
       " ('chain', 2),\n",
       " ('market', 2),\n",
       " ('genai technolog', 2),\n",
       " ('policymak', 2),\n",
       " ('instruction-tun lm', 2),\n",
       " ('modul', 2),\n",
       " ('protein', 2),\n",
       " ('tech compani', 2),\n",
       " ('bing chat', 2),\n",
       " ('constructionist len', 2),\n",
       " ('comput program', 2),\n",
       " ('comput scienc educ', 2),\n",
       " ('instructor', 2),\n",
       " ('architectur', 2),\n",
       " ('textual descript', 2),\n",
       " ('vicuna', 2),\n",
       " ('F1', 2),\n",
       " ('interpret', 2),\n",
       " ('text classif', 2),\n",
       " ('copyright', 2),\n",
       " ('ai-gener imag', 2),\n",
       " ('search tool', 2),\n",
       " ('unit test', 2),\n",
       " ('step-by-step instruct', 2),\n",
       " ('evosuit', 2),\n",
       " ('stage', 2),\n",
       " ('taxonomi', 2),\n",
       " ('rang', 2),\n",
       " ('appl', 2),\n",
       " ('3D', 2),\n",
       " ('top', 2),\n",
       " ('simplif', 2),\n",
       " ('forc', 2),\n",
       " ('gi', 2),\n",
       " ('logic', 2),\n",
       " ('java', 2),\n",
       " ('recommend paradigm', 2),\n",
       " ('linguist capabl', 2),\n",
       " ('critiqu', 2),\n",
       " ('guidelin', 2),\n",
       " ('app', 2),\n",
       " ('neg sentiment', 2),\n",
       " ('mechan', 2),\n",
       " ('instanc', 2),\n",
       " ('social bia', 2),\n",
       " ('inequ', 2),\n",
       " ('languag translat', 2),\n",
       " ('translat task', 2),\n",
       " ('base lm', 2),\n",
       " ('finetun', 2),\n",
       " ('input text', 2),\n",
       " ('stakehold', 2),\n",
       " ('factual consist', 2),\n",
       " ('efl', 2),\n",
       " ('larg lm', 2),\n",
       " ('softwar develop', 2),\n",
       " ('comment', 2),\n",
       " ('context', 2),\n",
       " ('genaibot', 2),\n",
       " ('agents-to-think-with', 2),\n",
       " ('paramet', 2),\n",
       " ('convers system', 2),\n",
       " ('synthet text', 2),\n",
       " ('ethic dilemma', 2),\n",
       " ('bleu', 2),\n",
       " ('landscap', 2),\n",
       " ('crss', 2),\n",
       " ('educ set', 2),\n",
       " ('specif scenario', 2),\n",
       " ('hardwar', 2),\n",
       " ('hardwar engin', 2),\n",
       " ('opt', 2),\n",
       " ('transcript', 2),\n",
       " ('contrast', 2),\n",
       " ('goal-ori dialogu', 2),\n",
       " ('speech', 2),\n",
       " ('jailbreak prompt', 2),\n",
       " ('resili', 2),\n",
       " ('claud', 2),\n",
       " ('divers', 2),\n",
       " ('qlora', 2),\n",
       " ('bart', 2),\n",
       " ('financi domain', 2),\n",
       " ('par', 2),\n",
       " ('categori', 2),\n",
       " ('granular', 2),\n",
       " ('cost-effici', 2),\n",
       " ('icl', 2),\n",
       " ('doctor', 2),\n",
       " ('scienc', 2),\n",
       " ('cybersecur', 2),\n",
       " ('paper', 2),\n",
       " ('zero-shot', 2),\n",
       " ('annot data', 2),\n",
       " ('evid', 2),\n",
       " ('segment', 2),\n",
       " ('futur', 2),\n",
       " ('robot task', 2),\n",
       " ('high-level instruct', 2),\n",
       " ('dimens', 2),\n",
       " ('AR', 2),\n",
       " ('tabl', 2),\n",
       " ('summari qualiti', 2),\n",
       " ('professor', 2),\n",
       " ('sam', 2),\n",
       " ('strength', 2),\n",
       " ('reason process', 2),\n",
       " ('inaccuraci', 2),\n",
       " ('shape', 2),\n",
       " ('3D shape', 2),\n",
       " ('AI assist', 2),\n",
       " ('public attitud', 2),\n",
       " ('3', 2),\n",
       " ('convers agent', 2),\n",
       " ('98', 2),\n",
       " ('product', 2),\n",
       " ('project', 2),\n",
       " ('coher text', 2),\n",
       " ('temperatur paramet', 2),\n",
       " ('class', 2),\n",
       " ('disciplin', 2),\n",
       " ('scientif disciplin', 2),\n",
       " ('altern', 2),\n",
       " ('mine', 2),\n",
       " ('chatgpt-gener code', 2),\n",
       " ('search engin', 2),\n",
       " ('patent', 2),\n",
       " ('vietnam', 2),\n",
       " ('jailbreak', 2),\n",
       " ('assumpt', 2),\n",
       " ('asr system', 2),\n",
       " ('visual input', 2),\n",
       " ('code qualiti', 2),\n",
       " ('alpaca', 2),\n",
       " ('judgement', 2),\n",
       " ('maximum rouge-l', 1),\n",
       " ('rouge-l score', 1),\n",
       " ('phrase', 1),\n",
       " ('27', 1),\n",
       " ('49', 1),\n",
       " ('investor emot', 1),\n",
       " ('role emot', 1),\n",
       " ('open-sourc emot data', 1),\n",
       " ('financi market', 1),\n",
       " ('firm-specif investor emot', 1),\n",
       " ('financi social media platform', 1),\n",
       " ('financi social media text', 1),\n",
       " ('factual metric', 1),\n",
       " ('factual error annot', 1),\n",
       " ('state-of-the-art factual metric', 1),\n",
       " ('factual evalu', 1),\n",
       " ('factual detect space', 1),\n",
       " ('recent chatgpt-bas metric', 1),\n",
       " ('final exam', 1),\n",
       " ('final', 1),\n",
       " ('machin learn final', 1),\n",
       " ('final exam benchmark', 1),\n",
       " ('human-qu final exam question', 1),\n",
       " ('machin learn', 1),\n",
       " ('few-shot learn', 1),\n",
       " ('machin learn topic', 1),\n",
       " ('trace', 1),\n",
       " ('trace tool', 1),\n",
       " ('suitabl trace tool', 1),\n",
       " ('popular open trace tool', 1),\n",
       " ('adopt', 1),\n",
       " ('consist distort', 1),\n",
       " ('ture experi', 1),\n",
       " ('hyper-accuraci distort', 1),\n",
       " ('languag model simul', 1),\n",
       " ('crowd', 1),\n",
       " ('human behavior', 1),\n",
       " ('well-establish find', 1),\n",
       " ('singl arbitrari individu', 1),\n",
       " ('analyt', 1),\n",
       " ('predict analyt', 1),\n",
       " ('transpar predict analyt', 1),\n",
       " ('prescript analyt', 1),\n",
       " ('data-driven prescript analyt', 1),\n",
       " ('predict model', 1),\n",
       " ('evidence-bas remedi advic', 1),\n",
       " ('tailor advic', 1),\n",
       " ('open-domain dialogu system', 1),\n",
       " ('decod', 1),\n",
       " ('divers dialogu respons', 1),\n",
       " ('divers dialogu gener', 1),\n",
       " ('large-scal open-domain dialogu dataset', 1),\n",
       " ('medium-to-small-s dialogu system', 1),\n",
       " ('hard manner', 1),\n",
       " ('super larg dialogu system', 1),\n",
       " ('contemporari nlg system', 1),\n",
       " ('detect system', 1),\n",
       " ('neural theori', 1),\n",
       " ('al.', 1),\n",
       " ('emerg theori', 1),\n",
       " ('mind task', 1),\n",
       " ('social intellig', 1),\n",
       " ('neural tom', 1),\n",
       " ('dialogu session', 1),\n",
       " ('person dialogu agent', 1),\n",
       " ('robust dialogu agent', 1),\n",
       " ('dialogu agent construct', 1),\n",
       " ('charact attribut', 1),\n",
       " ('background', 1),\n",
       " ('scene', 1),\n",
       " ('stori', 1),\n",
       " ('ID exampl', 1),\n",
       " ('ood exampl', 1),\n",
       " ('ood detect', 1),\n",
       " ('ood score', 1),\n",
       " ('ood detect method', 1),\n",
       " ('ID data manifold', 1),\n",
       " ('predict layer distil', 1),\n",
       " ('similarity-bas intermedi layer distil method', 1),\n",
       " ('sustain AI', 1),\n",
       " ('EU AI regul', 1),\n",
       " ('EU AI act', 1),\n",
       " ('AI act', 1),\n",
       " ('jump-start sustain AI regul', 1),\n",
       " ('fair AI', 1),\n",
       " (\"earli adopters' sentiment\", 1),\n",
       " ('earli adopt', 1),\n",
       " ('main topic', 1),\n",
       " ('topic model', 1),\n",
       " ('disrupt', 1),\n",
       " ('earli chatgpt user', 1),\n",
       " ('origin content', 1),\n",
       " ('origin thought', 1),\n",
       " ('origin contribut', 1),\n",
       " ('origin prose score', 1),\n",
       " ('classic ture test', 1),\n",
       " ('98-99', 1),\n",
       " ('lovelac 2.0', 1),\n",
       " ('sequenti question', 1),\n",
       " ('paraphras identif', 1),\n",
       " ('typolog', 1),\n",
       " ('effect paraphras detect', 1),\n",
       " ('paraphras impact detect capabl', 1),\n",
       " ('refin typolog', 1),\n",
       " ('under-represent', 1),\n",
       " ('explain AI', 1),\n",
       " ('drug discoveri process', 1),\n",
       " ('potenti advantag', 1),\n",
       " ('onlin exam', 1),\n",
       " ('oral exam', 1),\n",
       " ('foolproof solut', 1),\n",
       " ('academ misconduct', 1),\n",
       " ('institut', 1),\n",
       " ('tertiari educ set', 1),\n",
       " ('unsupervis pegasu', 1),\n",
       " ('summari candid', 1),\n",
       " ('unsupervis manner', 1),\n",
       " ('supervis setup', 1),\n",
       " ('re-rank summari candid', 1),\n",
       " ('unsupervis model', 1),\n",
       " ('supervis counterpart', 1),\n",
       " ('7.27', 1),\n",
       " ('puzzl', 1),\n",
       " ('smart-101', 1),\n",
       " ('visuo-linguist puzzl', 1),\n",
       " ('neural network', 1),\n",
       " ('smart-101 dataset', 1),\n",
       " ('deep neural network', 1),\n",
       " ('101', 1),\n",
       " ('elementari skill', 1),\n",
       " ('bygpt5', 1),\n",
       " ('end-to-end poetri gener', 1),\n",
       " ('rhyme', 1),\n",
       " ('meter', 1),\n",
       " ('alliter', 1),\n",
       " ('mt5', 1),\n",
       " ('byt5', 1),\n",
       " ('german quatrain', 1),\n",
       " ('humor paper titl', 1),\n",
       " ('2.5k titl', 1),\n",
       " ('large-scal humor', 1),\n",
       " ('funni titl', 1),\n",
       " ('30k', 1),\n",
       " ('fine-tun system', 1),\n",
       " ('end-to-end abstract-to-titl gener problem', 1),\n",
       " ('end-to-end system perform', 1),\n",
       " ('harder problem', 1),\n",
       " ('evas', 1),\n",
       " ('defens evas', 1),\n",
       " ('keylogg', 1),\n",
       " ('worm', 1),\n",
       " ('self-repl', 1),\n",
       " ('self-modif', 1),\n",
       " ('payment-fulfil ransomwar', 1),\n",
       " ('cybersecur question', 1),\n",
       " ('mitr att', 1),\n",
       " ('complex cybersecur goal', 1),\n",
       " ('short-form', 1),\n",
       " ('short-form essay', 1),\n",
       " ('pm 2', 1),\n",
       " ('pm 5', 1),\n",
       " ('physic essay', 1),\n",
       " ('pm 1', 1),\n",
       " ('300', 1),\n",
       " ('71', 1),\n",
       " ('stanc detect refer', 1),\n",
       " ('standpoint', 1),\n",
       " ('p-stanc', 1),\n",
       " ('nov 30', 1),\n",
       " ('favor', 1),\n",
       " ('deep learn model', 1),\n",
       " ('simplifi report', 1),\n",
       " ('medic report', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(key5Counter.items(), key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDFRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key5Counter = Counter()\n",
    "stem2raw = {}\n",
    "for ab in ChatGPTf['abstract']:\n",
    "    results = modelTFIDFRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        stem2raw[item['stemmed']] = item['raw'][0]\n",
    "        key5Counter[item['stemmed']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model', 76),\n",
       " ('llm', 45),\n",
       " ('task', 44),\n",
       " ('data', 40),\n",
       " ('AI', 39),\n",
       " ('chatgpt', 29),\n",
       " ('question', 28),\n",
       " ('dataset', 28),\n",
       " ('text', 24),\n",
       " ('languag', 23),\n",
       " ('code', 22),\n",
       " ('prompt', 21),\n",
       " ('larg languag model', 21),\n",
       " ('research', 20),\n",
       " ('human', 19),\n",
       " ('languag model', 19),\n",
       " ('perform', 18),\n",
       " ('gener', 17),\n",
       " ('instruct', 16),\n",
       " ('educ', 15),\n",
       " ('evalu', 15),\n",
       " ('knowledg', 15),\n",
       " ('respons', 14),\n",
       " ('program', 14),\n",
       " ('problem', 14),\n",
       " ('content', 14),\n",
       " ('tool', 13),\n",
       " ('imag', 13),\n",
       " ('artifici intellig', 13),\n",
       " ('AI system', 12),\n",
       " ('translat', 12),\n",
       " ('detect', 12),\n",
       " ('chatbot', 12),\n",
       " ('answer', 11),\n",
       " ('framework', 11),\n",
       " ('nlp', 11),\n",
       " ('gener AI', 11),\n",
       " ('student', 11),\n",
       " ('reason', 10),\n",
       " ('learn', 10),\n",
       " ('system', 10),\n",
       " ('inform', 10),\n",
       " ('technolog', 9),\n",
       " ('gener model', 9),\n",
       " ('machin translat', 9),\n",
       " ('sentiment analysi', 9),\n",
       " ('softwar engin', 9),\n",
       " ('method', 9),\n",
       " ('studi', 9),\n",
       " ('AI technolog', 8),\n",
       " ('solut', 8),\n",
       " ('attack', 8),\n",
       " ('user', 8),\n",
       " ('foundat model', 8),\n",
       " ('output', 8),\n",
       " ('data augment', 8),\n",
       " ('review', 7),\n",
       " ('exam', 7),\n",
       " ('correct answer', 7),\n",
       " ('abil', 7),\n",
       " ('video', 7),\n",
       " ('recommend', 7),\n",
       " ('googl bard', 7),\n",
       " ('code gener', 7),\n",
       " ('knowledg graph', 7),\n",
       " ('AI model', 6),\n",
       " ('chatgpt-gener text', 6),\n",
       " ('natur languag', 6),\n",
       " ('design', 6),\n",
       " ('text summar', 6),\n",
       " ('novemb 2022', 6),\n",
       " ('summari', 6),\n",
       " ('assess', 6),\n",
       " ('synthet data', 6),\n",
       " ('feedback', 6),\n",
       " ('complex task', 6),\n",
       " ('human evalu', 6),\n",
       " ('ai-gener content', 6),\n",
       " ('entiti', 6),\n",
       " ('analysi', 6),\n",
       " ('test', 6),\n",
       " ('instruct tune', 6),\n",
       " ('sourc code', 6),\n",
       " ('benchmark', 6),\n",
       " ('lm', 6),\n",
       " ('topic', 5),\n",
       " ('stanc detect', 5),\n",
       " ('convers AI', 5),\n",
       " ('concept', 5),\n",
       " ('physic', 5),\n",
       " ('industri', 5),\n",
       " ('logic reason', 5),\n",
       " ('kg', 5),\n",
       " ('nlp task', 5),\n",
       " ('medic imag', 5),\n",
       " ('chatgpt respons', 5),\n",
       " ('result', 5),\n",
       " ('custom servic', 5),\n",
       " ('graph', 5),\n",
       " ('aigc', 5),\n",
       " ('gpt-4', 5),\n",
       " ('qualiti', 5),\n",
       " ('machine-gener text', 5),\n",
       " ('gener text', 5),\n",
       " ('sentiment', 5),\n",
       " ('sentiment analysi task', 5),\n",
       " ('queri', 5),\n",
       " ('transform', 5),\n",
       " ('memori', 5),\n",
       " ('polici', 5),\n",
       " ('limit', 5),\n",
       " ('effect', 5),\n",
       " ('articl', 4),\n",
       " ('essay', 4),\n",
       " ('radiolog report', 4),\n",
       " ('bias', 4),\n",
       " ('activ', 4),\n",
       " ('improv', 4),\n",
       " ('human expert', 4),\n",
       " ('translat perform', 4),\n",
       " ('mathemat', 4),\n",
       " ('correct', 4),\n",
       " ('data set', 4),\n",
       " ('group', 4),\n",
       " ('write', 4),\n",
       " ('educ sector', 4),\n",
       " ('convers', 4),\n",
       " ('network', 4),\n",
       " ('data gener', 4),\n",
       " ('stack overflow', 4),\n",
       " ('QA', 4),\n",
       " ('translat qualiti', 4),\n",
       " ('zero-shot set', 4),\n",
       " ('entiti recognit', 4),\n",
       " ('ethic concern', 4),\n",
       " ('person', 4),\n",
       " ('AI tool', 4),\n",
       " ('human feedback', 4),\n",
       " ('in-context learn', 4),\n",
       " ('align', 4),\n",
       " ('algorithm', 4),\n",
       " ('metric', 4),\n",
       " ('chatgpt perform', 4),\n",
       " ('model perform', 4),\n",
       " ('MT', 4),\n",
       " ('recommend system', 4),\n",
       " ('classifi', 4),\n",
       " ('gener summari', 4),\n",
       " ('set', 4),\n",
       " ('correct solut', 4),\n",
       " ('languag understand', 4),\n",
       " ('human-written text', 4),\n",
       " ('languag translat', 4),\n",
       " ('detector', 4),\n",
       " ('applic', 4),\n",
       " ('dialogu', 4),\n",
       " ('bard', 4),\n",
       " ('role', 4),\n",
       " ('recommend scenario', 4),\n",
       " ('annot', 4),\n",
       " ('requir', 4),\n",
       " ('risk', 4),\n",
       " ('genai', 4),\n",
       " ('higher educ', 4),\n",
       " ('ethic implic', 4),\n",
       " ('vietnames student', 4),\n",
       " ('text gener', 4),\n",
       " ('strategi', 4),\n",
       " ('factual knowledg', 4),\n",
       " ('open-sourc llm', 4),\n",
       " ('earli adopt', 3),\n",
       " ('disrupt technolog', 3),\n",
       " ('question answer', 3),\n",
       " ('paraphras', 3),\n",
       " ('identif', 3),\n",
       " ('potenti', 3),\n",
       " ('human-gener text', 3),\n",
       " ('supervis model', 3),\n",
       " ('social media post', 3),\n",
       " ('principl', 3),\n",
       " ('bug', 3),\n",
       " ('approach', 3),\n",
       " ('googl translat', 3),\n",
       " ('translat abil', 3),\n",
       " ('particip', 3),\n",
       " ('human-lik respons', 3),\n",
       " ('github copilot', 3),\n",
       " ('program repair', 3),\n",
       " ('wide rang', 3),\n",
       " ('failur', 3),\n",
       " ('score', 3),\n",
       " ('paradigm shift', 3),\n",
       " ('diseas', 3),\n",
       " ('techniqu', 3),\n",
       " ('opinion', 3),\n",
       " ('hate speech', 3),\n",
       " ('decis', 3),\n",
       " ('attent', 3),\n",
       " ('event extract', 3),\n",
       " ('current version', 3),\n",
       " ('prompt engin', 3),\n",
       " ('prompt engin techniqu', 3),\n",
       " ('plm', 3),\n",
       " ('sampl', 3),\n",
       " ('sampl size', 3),\n",
       " ('robot', 3),\n",
       " ('model paramet', 3),\n",
       " ('prompt templat', 3),\n",
       " ('softwar', 3),\n",
       " ('version', 3),\n",
       " ('gener AI tool', 3),\n",
       " ('work', 3),\n",
       " ('downstream task', 3),\n",
       " ('visual chatgpt', 3),\n",
       " ('discuss', 3),\n",
       " ('data privaci', 3),\n",
       " ('human prefer', 3),\n",
       " ('imag caption', 3),\n",
       " ('manag', 3),\n",
       " ('factual', 3),\n",
       " ('matrix multipl', 3),\n",
       " ('comput scienc', 3),\n",
       " ('text data', 3),\n",
       " ('abstract', 3),\n",
       " ('idea', 3),\n",
       " ('program languag', 3),\n",
       " ('capabl', 3),\n",
       " ('train model', 3),\n",
       " ('scholarli research', 3),\n",
       " ('comput program', 3),\n",
       " ('grammat error correct', 3),\n",
       " ('experi', 3),\n",
       " ('detect method', 3),\n",
       " ('medic advic', 3),\n",
       " ('instruct data', 3),\n",
       " ('train', 3),\n",
       " ('human analyst', 3),\n",
       " ('classif', 3),\n",
       " ('graph structur', 3),\n",
       " ('search', 3),\n",
       " ('academ write', 3),\n",
       " ('scientif write', 3),\n",
       " ('scenario', 3),\n",
       " ('stabl diffus', 3),\n",
       " ('chatgpt-4', 3),\n",
       " ('error', 3),\n",
       " ('step', 3),\n",
       " ('natur languag process', 3),\n",
       " ('gener languag model', 3),\n",
       " ('machin learn', 3),\n",
       " ('paper', 3),\n",
       " ('softwar develop', 3),\n",
       " ('harm content', 3),\n",
       " ('safeti', 3),\n",
       " ('adversari exampl', 3),\n",
       " ('literatur', 3),\n",
       " ('academ commun', 3),\n",
       " ('code gener task', 3),\n",
       " ('argument', 3),\n",
       " ('plan', 3),\n",
       " ('human-lik text', 3),\n",
       " ('patient', 3),\n",
       " ('gener code', 3),\n",
       " ('construct', 3),\n",
       " ('graph data', 3),\n",
       " ('creativ write', 3),\n",
       " ('educ set', 3),\n",
       " ('RL', 3),\n",
       " ('automat metric', 3),\n",
       " ('synthet dataset', 3),\n",
       " ('gener task', 3),\n",
       " ('domain', 3),\n",
       " ('methodolog', 3),\n",
       " ('reason process', 3),\n",
       " ('genai tool', 3),\n",
       " ('multi-turn convers', 3),\n",
       " ('exampl', 3),\n",
       " ('comput vision', 3),\n",
       " ('cost', 3),\n",
       " ('train data', 3),\n",
       " ('control', 3),\n",
       " ('ner', 3),\n",
       " ('style', 3),\n",
       " ('text classif', 3),\n",
       " ('vision-languag model', 3),\n",
       " ('pre-train model', 3),\n",
       " ('knowledg represent', 3),\n",
       " ('reinforc learn', 3),\n",
       " ('potenti risk', 3),\n",
       " ('hallucin', 3),\n",
       " ('futur', 3),\n",
       " ('civic educ', 3),\n",
       " ('emot', 3),\n",
       " ('chat', 3),\n",
       " ('open-sourc model', 3),\n",
       " ('reward model', 3),\n",
       " ('cours', 3),\n",
       " ('chatgpt capabl', 3),\n",
       " ('public opinion', 3),\n",
       " ('scientif disciplin', 3),\n",
       " ('posit sentiment', 2),\n",
       " ('gener content', 2),\n",
       " ('review articl', 2),\n",
       " ('drug discoveri', 2),\n",
       " ('advantag', 2),\n",
       " ('abstract summar model', 2),\n",
       " ('candid', 2),\n",
       " ('spatial reason', 2),\n",
       " ('humor', 2),\n",
       " ('stanc detect task', 2),\n",
       " ('text classif task', 2),\n",
       " ('medic domain', 2),\n",
       " ('radiolog', 2),\n",
       " ('polit elect', 2),\n",
       " ('societi', 2),\n",
       " ('label', 2),\n",
       " ('har', 2),\n",
       " ('respons AI', 2),\n",
       " ('ethic principl', 2),\n",
       " ('judgment', 2),\n",
       " ('advic', 2),\n",
       " ('secur', 2),\n",
       " ('case studi', 2),\n",
       " ('analog', 2),\n",
       " ('repair', 2),\n",
       " ('translat prompt', 2),\n",
       " ('multilingu translat', 2),\n",
       " ('chatbot respons', 2),\n",
       " ('social media', 2),\n",
       " ('social media data', 2),\n",
       " ('ethic risk', 2),\n",
       " ('AI ethic', 2),\n",
       " ('patch', 2),\n",
       " ('apr', 2),\n",
       " ('patch gener', 2),\n",
       " ('incorrect patch', 2),\n",
       " ('valid', 2),\n",
       " ('linear regress', 2),\n",
       " ('medic benchmark', 2),\n",
       " ('natur languag convers', 2),\n",
       " ('profici', 2),\n",
       " ('undergraduate-level mathemat', 2),\n",
       " ('mathemat reason', 2),\n",
       " ('data visualis', 2),\n",
       " ('AI regul', 2),\n",
       " ('construct industri', 2),\n",
       " ('chatgpt failur', 2),\n",
       " ('massiv amount', 2),\n",
       " ('systemat review', 2),\n",
       " ('comprehens review', 2),\n",
       " ('nlu task', 2),\n",
       " ('commonsens reason', 2),\n",
       " ('deep learn', 2),\n",
       " ('gener AI system', 2),\n",
       " ('control group', 2),\n",
       " ('similar', 2),\n",
       " ('nlp field', 2),\n",
       " ('KG', 2),\n",
       " ('nlp techniqu', 2),\n",
       " ('specif task', 2),\n",
       " ('valuabl tool', 2),\n",
       " ('scheme', 2),\n",
       " ('medic field', 2),\n",
       " ('user experi', 2),\n",
       " ('transform model', 2),\n",
       " ('english text', 2),\n",
       " ('document-level translat', 2),\n",
       " ('translat direct', 2),\n",
       " ('futur research direct', 2),\n",
       " ('graph learn', 2),\n",
       " ('googl search', 2),\n",
       " ('countri', 2),\n",
       " ('understand abil', 2),\n",
       " ('quantit analysi', 2),\n",
       " ('red team', 2),\n",
       " ('attent mechan', 2),\n",
       " ('assist', 2),\n",
       " ('practic', 2),\n",
       " ('pattern', 2),\n",
       " ('prompt pattern', 2),\n",
       " ('polici model', 2),\n",
       " ('infer', 2),\n",
       " ('extern knowledg', 2),\n",
       " ('llm-gener respons', 2),\n",
       " ('robot applic', 2),\n",
       " ('time', 2),\n",
       " ('math word problem', 2),\n",
       " ('ai-pow chatbot', 2),\n",
       " ('zero-shot manner', 2),\n",
       " ('softwar implement', 2),\n",
       " ('collabor', 2),\n",
       " ('AI languag model', 2),\n",
       " ('cross-lingu transfer', 2),\n",
       " ('design process', 2),\n",
       " ('human-comput interact', 2),\n",
       " ('visual', 2),\n",
       " ('specialis model', 2),\n",
       " ('optim problem', 2),\n",
       " ('event', 2),\n",
       " ('natur languag gener task', 2),\n",
       " ('nlg', 2),\n",
       " ('automat evalu metric', 2),\n",
       " ('digit content', 2),\n",
       " ('relat extract', 2),\n",
       " ('demonstr', 2),\n",
       " ('cross-mod encod', 2),\n",
       " ('align techniqu', 2),\n",
       " ('multimod system', 2),\n",
       " ('creativ content', 2),\n",
       " ('gener AI technolog', 2),\n",
       " ('current dialogu system', 2),\n",
       " ('databas schema', 2),\n",
       " ('test question', 2),\n",
       " ('word', 2),\n",
       " ('optim', 2),\n",
       " ('competit', 2),\n",
       " ('data visual', 2),\n",
       " ('fact', 2),\n",
       " ('healthcar provid', 2),\n",
       " ('fine-grain compress', 2),\n",
       " ('layer normal', 2),\n",
       " ('huge memori footprint', 2),\n",
       " ('transformer-bas model', 2),\n",
       " ('fine-tun model', 2),\n",
       " ('unstructur medic text', 2),\n",
       " ('comput', 2),\n",
       " ('vision', 2),\n",
       " ('medic diagnosi', 2),\n",
       " ('creativ', 2),\n",
       " ('gai', 2),\n",
       " ('machin', 2),\n",
       " ('gpt-4 perform', 2),\n",
       " ('misinform', 2),\n",
       " ('exercis', 2),\n",
       " ('gec', 2),\n",
       " ('artifici intellig tool', 2),\n",
       " ('ethic issu', 2),\n",
       " ('github', 2),\n",
       " ('medic knowledg', 2),\n",
       " ('theori', 2),\n",
       " ('model checkpoint', 2),\n",
       " ('annot task', 2),\n",
       " ('hazard analysi', 2),\n",
       " ('factual inconsist', 2),\n",
       " ('level', 2),\n",
       " ('classif task', 2),\n",
       " ('user privaci', 2),\n",
       " ('commonsens knowledg', 2),\n",
       " ('commonsens problem', 2),\n",
       " ('tip', 2),\n",
       " ('open-domain task', 2),\n",
       " ('commun', 2),\n",
       " ('research topic', 2),\n",
       " ('physic educ', 2),\n",
       " ('forc concept inventori', 2),\n",
       " ('diffus model', 2),\n",
       " ('deep gener model', 2),\n",
       " ('mistak', 2),\n",
       " ('histor text', 2),\n",
       " ('hug face', 2),\n",
       " ('AI task', 2),\n",
       " ('anecdot exampl', 2),\n",
       " ('FE', 2),\n",
       " ('engin', 2),\n",
       " ('model scale', 2),\n",
       " ('rate', 2),\n",
       " (\"llms' perform\", 2),\n",
       " ('chat model', 2),\n",
       " ('multi-turn dialogu', 2),\n",
       " ('fake news', 2),\n",
       " ('in-depth analysi', 2),\n",
       " ('applic domain', 2),\n",
       " ('signific role', 2),\n",
       " ('term', 2),\n",
       " ('maximum number', 2),\n",
       " ('DL', 2),\n",
       " ('gener program', 2),\n",
       " ('content gener', 2),\n",
       " ('translat instruct', 2),\n",
       " ('languag gener', 2),\n",
       " ('knowledg model', 2),\n",
       " ('evalu metric', 2),\n",
       " ('design knowledg', 2),\n",
       " ('world knowledg', 2),\n",
       " ('technic report', 2),\n",
       " ('potenti applic', 2),\n",
       " ('cot', 2),\n",
       " ('specif', 2),\n",
       " ('incorrect answer', 2),\n",
       " ('item', 2),\n",
       " ('ML', 2),\n",
       " ('condit', 2),\n",
       " ('summari faith', 2),\n",
       " ('dialogu state track', 2),\n",
       " ('strong perform', 2),\n",
       " ('aigc model', 2),\n",
       " ('privaci threat', 2),\n",
       " ('persona', 2),\n",
       " ('harm', 2),\n",
       " ('predict', 2),\n",
       " ('human rate', 2),\n",
       " ('phase', 2),\n",
       " ('tempor relat', 2),\n",
       " ('difficulti', 2),\n",
       " ('crucial role', 2),\n",
       " ('gener concept', 2),\n",
       " ('gener public', 2),\n",
       " ('widespread adopt', 2),\n",
       " ('googl scholar', 2),\n",
       " ('environment scienc', 2),\n",
       " ('scienc', 2),\n",
       " ('argument write', 2),\n",
       " ('chines', 2),\n",
       " ('llama', 2),\n",
       " ('medic text data', 2),\n",
       " ('perspect', 2),\n",
       " ('IR', 2),\n",
       " ('AI chatbot', 2),\n",
       " ('recent year', 2),\n",
       " ('plug-and-play modul', 2),\n",
       " ('privaci concern', 2),\n",
       " ('textbook', 2),\n",
       " ('cskb', 2),\n",
       " ('domain expert', 2),\n",
       " ('explain', 2),\n",
       " ('ethic', 2),\n",
       " ('dall 2', 2),\n",
       " ('robot system', 2),\n",
       " ('applic scenario', 2),\n",
       " ('compani', 2),\n",
       " ('behavior', 2),\n",
       " ('architectur design', 2),\n",
       " ('program challeng', 2),\n",
       " ('multiple-choic question', 2),\n",
       " ('recent advanc', 2),\n",
       " ('medic text', 2),\n",
       " ('user intent', 2),\n",
       " ('dialogu system', 2),\n",
       " ('social norm', 2),\n",
       " ('academ integr', 2),\n",
       " ('causal reason', 2),\n",
       " ('causal', 2),\n",
       " ('human intellig', 2),\n",
       " ('origin text', 2),\n",
       " ('robot abil', 2),\n",
       " ('gener artifici intellig', 2),\n",
       " ('understand', 2),\n",
       " ('tabular data', 2),\n",
       " ('tabular dataset', 2),\n",
       " ('case', 2),\n",
       " ('natur languag process task', 2),\n",
       " ('long document', 2),\n",
       " ('domain adapt', 2),\n",
       " ('relev respons', 2),\n",
       " ('human-lik convers', 2),\n",
       " ('latest version', 2),\n",
       " ('inform retriev', 2),\n",
       " ('book', 2),\n",
       " ('genai technolog', 2),\n",
       " ('emot support', 2),\n",
       " ('instruction-tun lm', 2),\n",
       " ('larger lm', 2),\n",
       " ('unifi framework', 2),\n",
       " ('tech compani', 2),\n",
       " ('bing chat', 2),\n",
       " ('comput scienc educ', 2),\n",
       " ('gener process', 2),\n",
       " ('suggest', 2),\n",
       " ('test suit', 2),\n",
       " ('human annot', 2),\n",
       " ('convers bot', 2),\n",
       " ('interpret', 2),\n",
       " ('knowledg base', 2),\n",
       " ('ai-gener imag', 2),\n",
       " ('gener AI model', 2),\n",
       " ('search tool', 2),\n",
       " ('unit test', 2),\n",
       " ('step-by-step instruct', 2),\n",
       " ('target task', 2),\n",
       " ('websit', 2),\n",
       " ('content creation', 2),\n",
       " ('diagnosi', 2),\n",
       " ('divers', 2),\n",
       " ('3D', 2),\n",
       " ('origin dataset', 2),\n",
       " ('gi', 2),\n",
       " ('logic', 2),\n",
       " ('code qualiti', 2),\n",
       " ('human programm', 2),\n",
       " ('multimod model', 2),\n",
       " ('recommend paradigm', 2),\n",
       " ('domain knowledg', 2),\n",
       " ('rule', 2),\n",
       " ('linguist capabl', 2),\n",
       " ('prompt design', 2),\n",
       " ('high-qual dataset', 2),\n",
       " ('app', 2),\n",
       " ('neg sentiment', 2),\n",
       " ('structur data', 2),\n",
       " ('input', 2),\n",
       " ('token', 2),\n",
       " ('social bia', 2),\n",
       " ('physic world', 2),\n",
       " ('input text', 2),\n",
       " ('llm respons', 2),\n",
       " ('factual consist', 2),\n",
       " ('consist improv', 2),\n",
       " ('efl', 2),\n",
       " ('larg lm', 2),\n",
       " ('empir evid', 2),\n",
       " ('comment', 2),\n",
       " ('genaibot', 2),\n",
       " ('data annot', 2),\n",
       " ('open-sourc code', 2),\n",
       " ('SE', 2),\n",
       " ('vietnames nation high school graduat examin', 2),\n",
       " ('convers system', 2),\n",
       " ('zero-shot learn', 2),\n",
       " ('synthet text', 2),\n",
       " ('ethic dilemma', 2),\n",
       " ('investor', 2),\n",
       " ('student model', 2),\n",
       " ('teacher model', 2),\n",
       " ('rational gener', 2),\n",
       " ('data scientist', 2),\n",
       " ('specif scenario', 2),\n",
       " ('hardwar', 2),\n",
       " ('hardwar engin', 2),\n",
       " ('largest model', 2),\n",
       " ('goal-ori dialogu', 2),\n",
       " ('interact evalu', 2),\n",
       " ('jailbreak prompt', 2),\n",
       " ('human instruct', 2),\n",
       " ('gener chat model', 2),\n",
       " ('data collect', 2),\n",
       " ('high-qual text', 2),\n",
       " ('fact-check', 2),\n",
       " ('icl', 2),\n",
       " ('real-world data', 2),\n",
       " ('field', 2),\n",
       " ('annot data', 2),\n",
       " ('zero-shot', 2),\n",
       " ('vlm', 2),\n",
       " ('larg vision-languag model', 2),\n",
       " ('agent', 2),\n",
       " ('evid', 2),\n",
       " ('segment', 2),\n",
       " ('drug', 2),\n",
       " ('molecul', 2),\n",
       " ('privaci', 2),\n",
       " ('nlp benchmark', 2),\n",
       " ('fair', 2),\n",
       " ('systemat evalu', 2),\n",
       " ('gener respons', 2),\n",
       " ('robot task', 2),\n",
       " ('tabl', 2),\n",
       " ('practic applic', 2),\n",
       " ('log', 2),\n",
       " ('learner', 2),\n",
       " ('object', 2),\n",
       " ('teacher', 2),\n",
       " ('shape', 2),\n",
       " ('3D shape', 2),\n",
       " ('AI assist', 2),\n",
       " ('process', 2),\n",
       " ('public attitud', 2),\n",
       " ('instruction-tun data', 2),\n",
       " ('convers agent', 2),\n",
       " ('visual data', 2),\n",
       " ('product', 2),\n",
       " ('project', 2),\n",
       " ('coher text', 2),\n",
       " ('human-author text', 2),\n",
       " ('expert', 2),\n",
       " ('survey', 2),\n",
       " ('temperatur paramet', 2),\n",
       " ('comprehens evalu', 2),\n",
       " ('biomed research', 2),\n",
       " ('educ activ', 2),\n",
       " ('toxic', 2),\n",
       " ('relationship', 2),\n",
       " ('ppo', 2),\n",
       " ('chatgpt-gener code', 2),\n",
       " ('attribut', 2),\n",
       " ('comparison', 2),\n",
       " ('search engin', 2),\n",
       " ('patent', 2),\n",
       " ('bingchat', 2),\n",
       " ('microsoft bing chat', 2),\n",
       " ('jailbreak', 2),\n",
       " ('asr system', 2),\n",
       " ('visual input', 2),\n",
       " ('sentenc', 2),\n",
       " ('judgement', 2),\n",
       " (\"earli adopters' sentiment\", 1),\n",
       " ('earli chatgpt user', 1),\n",
       " ('disrupt', 1),\n",
       " ('topic model', 1),\n",
       " ('origin content', 1),\n",
       " ('origin thought', 1),\n",
       " ('origin contribut', 1),\n",
       " ('origin prose score', 1),\n",
       " ('classic ture test', 1),\n",
       " ('sequenti question', 1),\n",
       " ('lovelac 2.0', 1),\n",
       " ('paraphras identif', 1),\n",
       " ('effect paraphras detect', 1),\n",
       " ('paraphras impact detect capabl', 1),\n",
       " ('typolog', 1),\n",
       " ('refin typolog', 1),\n",
       " ('explain AI', 1),\n",
       " ('drug discoveri process', 1),\n",
       " ('potenti advantag', 1),\n",
       " ('onlin exam', 1),\n",
       " ('oral exam', 1),\n",
       " ('foolproof solut', 1),\n",
       " ('academ misconduct', 1),\n",
       " ('realist text', 1),\n",
       " ('summari candid', 1),\n",
       " ('unsupervis model', 1),\n",
       " ('unsupervis pegasu', 1),\n",
       " ('summari output', 1),\n",
       " ('unsupervis manner', 1),\n",
       " ('re-rank summari candid', 1),\n",
       " ('puzzl', 1),\n",
       " ('visuo-linguist puzzl', 1),\n",
       " ('smart-101', 1),\n",
       " ('smart-101 dataset', 1),\n",
       " ('neural network', 1),\n",
       " ('deep neural network', 1),\n",
       " ('reason perform', 1),\n",
       " ('elementari skill', 1),\n",
       " ('poetri', 1),\n",
       " ('end-to-end poetri gener', 1),\n",
       " ('end-to-end model', 1),\n",
       " ('german quatrain', 1),\n",
       " ('state-of-the-art poetri gener system', 1),\n",
       " ('token-fre decoder-onli languag model', 1),\n",
       " ('prior knowledg', 1),\n",
       " ('task-specif model pipelin', 1),\n",
       " ('incorpor prior knowledg', 1),\n",
       " ('humor paper titl', 1),\n",
       " ('funni titl', 1),\n",
       " ('2.5k titl', 1),\n",
       " ('automat system', 1),\n",
       " ('end-to-end abstract-to-titl gener problem', 1),\n",
       " ('large-scal humor', 1),\n",
       " ('fine-tun system', 1),\n",
       " ('end-to-end system perform', 1),\n",
       " ('scientif paper', 1),\n",
       " ('evas', 1),\n",
       " ('defens evas', 1),\n",
       " ('payment-fulfil ransomwar', 1),\n",
       " ('cybersecur question', 1),\n",
       " ('mitr att', 1),\n",
       " ('complex cybersecur goal', 1),\n",
       " ('logic bomb', 1),\n",
       " ('question-and-answ format', 1),\n",
       " ('credenti access', 1),\n",
       " ('CK framework', 1),\n",
       " ('physic essay', 1),\n",
       " ('short-form essay', 1),\n",
       " ('pm 2', 1),\n",
       " ('pm 5', 1),\n",
       " ('pm 1', 1),\n",
       " ('short-form', 1),\n",
       " ('current univers physic modul', 1),\n",
       " ('current AI mlp', 1),\n",
       " ('stanc detect refer', 1),\n",
       " ('deep learn model', 1),\n",
       " ('nov 30', 1),\n",
       " ('medic report', 1),\n",
       " ('simplifi report', 1),\n",
       " ('radiologist', 1),\n",
       " ('15 radiologist', 1),\n",
       " ('key medic find', 1),\n",
       " ('harm passag', 1),\n",
       " ('patient-cent care', 1),\n",
       " ('twenti question', 1),\n",
       " ('guess 94', 1),\n",
       " ('spanish question', 1),\n",
       " ('question context', 1),\n",
       " ('classic twenty-quest game', 1),\n",
       " ('bilingu game', 1),\n",
       " ('neurosci metadata', 1),\n",
       " ('patent invent', 1),\n",
       " ('switch role', 1),\n",
       " ('nation-agnost polit compass test', 1),\n",
       " ('2021 elect', 1),\n",
       " ('die Gr', 1),\n",
       " ('left-libertarian ideolog', 1),\n",
       " ('democrat societi', 1),\n",
       " ('undni 90', 1),\n",
       " ('walk', 1),\n",
       " ('downstair', 1),\n",
       " ('share structur', 1),\n",
       " ('open fridg', 1),\n",
       " ('integ id', 1),\n",
       " ('activ track', 1),\n",
       " ('open door', 1),\n",
       " ('cyber secur', 1),\n",
       " ('honeypot interfac', 1),\n",
       " ('dynam honeypot', 1),\n",
       " ('perimet secur', 1),\n",
       " ('data secur', 1),\n",
       " ('cyber secur postur', 1),\n",
       " ('potenti honeypot interfac', 1),\n",
       " ('command-lin attack', 1),\n",
       " ('delay attack', 1),\n",
       " ('main model', 1),\n",
       " ('main gener model', 1),\n",
       " ('dreamfus model', 1),\n",
       " ('phenaki model', 1),\n",
       " ('audiolm model', 1),\n",
       " ('dalle-2 model', 1),\n",
       " ('flamingo model', 1),\n",
       " ('galactica model', 1),\n",
       " ('respons AI pattern catalogu', 1),\n",
       " ('respons AI challeng', 1),\n",
       " ('pattern-ori respons AI engin approach', 1),\n",
       " ('algorithm-level solut', 1),\n",
       " ('pattern-driven mitig', 1),\n",
       " ('narrow set', 1),\n",
       " ('moral judgment', 1),\n",
       " (\"users' moral judgment\", 1),\n",
       " ('moral advisor', 1),\n",
       " ('consist moral advic', 1),\n",
       " ('contradictori moral belief', 1),\n",
       " ('chat bot', 1),\n",
       " ('digit literaci', 1),\n",
       " ('human question', 1),\n",
       " ('collect dataset', 1),\n",
       " ('hc3 dataset', 1),\n",
       " ('human chatgpt comparison corpu', 1),\n",
       " ('comprehens human evalu', 1),\n",
       " ('hc3', 1),\n",
       " ('abstract concept', 1),\n",
       " ('theoret swampland conjectur', 1),\n",
       " ('full confid', 1),\n",
       " ('visual represent', 1),\n",
       " ('fals inform', 1),\n",
       " ('natur languag process model', 1),\n",
       " ('standard program repair approach', 1),\n",
       " ('autom program repair', 1),\n",
       " ('program repair techniqu', 1),\n",
       " ('softwar bug', 1),\n",
       " ('standard bug', 1),\n",
       " ('recent program repair method', 1),\n",
       " ('40 bug', 1),\n",
       " ('translat robust', 1),\n",
       " ('commerci translat product', 1),\n",
       " ('distant languag', 1),\n",
       " ('provid respons', 1),\n",
       " (\"patients' question\", 1),\n",
       " ('patient-provid commun', 1),\n",
       " ('patient question', 1),\n",
       " ('averag age', 1),\n",
       " ('weakli distinguish', 1),\n",
       " ('keyphras', 1),\n",
       " ('keyphras extract', 1),\n",
       " ('theme-driven keyphras extract', 1),\n",
       " ('human-annot keyphras', 1),\n",
       " ('relev keyphras', 1),\n",
       " ('theme-driven keyphras extract framework', 1),\n",
       " ('unsupervis keyphras extract model', 1),\n",
       " ('extract task', 1),\n",
       " ('de-facto arbit', 1),\n",
       " ('social', 1),\n",
       " ('truth-evalu capac', 1),\n",
       " ('AI truth-tel', 1),\n",
       " ('social feedback mechan', 1),\n",
       " ('truth', 1),\n",
       " ('social practic', 1),\n",
       " ('instruct successor', 1),\n",
       " ('introductori physic cours', 1),\n",
       " ('actual calculus-bas physic', 1),\n",
       " ('frequent indistinguish', 1),\n",
       " ('human-gener phraseolog', 1),\n",
       " ('human respons', 1),\n",
       " ('begin learner', 1),\n",
       " ('repres assess content', 1),\n",
       " ('singl solut', 1),\n",
       " ('design solut', 1),\n",
       " ('divers solut space', 1),\n",
       " ('multipl sourc code solut', 1),\n",
       " ('programming-rel queri', 1),\n",
       " ('work-in-progress prototyp', 1),\n",
       " ('complex queri', 1),\n",
       " ('effect softwar', 1),\n",
       " ('ethic llm', 1),\n",
       " ('ethic danger', 1),\n",
       " ('ethic hazard', 1),\n",
       " ('ethic difficulti', 1),\n",
       " ('recent llm', 1),\n",
       " ('llm applic', 1),\n",
       " ('respons llm', 1),\n",
       " ('convers apr', 1),\n",
       " ('apr approach', 1),\n",
       " ('convers manner', 1),\n",
       " ('numeraci', 1),\n",
       " ('emerg numeraci', 1),\n",
       " ('categor sum', 1),\n",
       " ('eighteen month', 1),\n",
       " ('random row', 1),\n",
       " ('statist analysi', 1),\n",
       " ('next-token predict', 1),\n",
       " ('in-memori dataset', 1),\n",
       " ('unseen test case', 1),\n",
       " ('causal discoveri', 1),\n",
       " ('causal discoveri question', 1),\n",
       " ('previou larg languag model', 1),\n",
       " ('Tu', 1),\n",
       " ('2019', 1),\n",
       " ('chatgpt-gener review', 1),\n",
       " ('origin human-gener review', 1),\n",
       " ('chatgpt text', 1),\n",
       " ('short onlin review', 1),\n",
       " ('seemingly-human repli', 1),\n",
       " ('atyp vocabulari', 1),\n",
       " ('graduate-level mathemat', 1),\n",
       " ('mathemat perform', 1),\n",
       " ('natural-languag mathemat', 1),\n",
       " ('formal mathemat', 1),\n",
       " ('mathemat capabl', 1),\n",
       " ('mathemat assist', 1),\n",
       " ('elementari mathemat', 1),\n",
       " ('visualis', 1),\n",
       " ('nli', 1),\n",
       " ('workabl nli', 1),\n",
       " ('nli system', 1),\n",
       " ('greater visualis infer abil', 1),\n",
       " ('natur languag queri', 1),\n",
       " ('free-form natur languag', 1),\n",
       " ('lgaim', 1),\n",
       " ('lgaim develop', 1),\n",
       " ('lgaim output', 1),\n",
       " ('lgaim set', 1),\n",
       " ('high-risk oblig', 1),\n",
       " ('regul', 1),\n",
       " ('trustworthi AI regul', 1),\n",
       " ('concret high-risk applic', 1),\n",
       " ('construct schedul', 1),\n",
       " ('simpl construct project', 1),\n",
       " ('coher schedul', 1),\n",
       " ('time-consum task', 1),\n",
       " ('interact experi', 1),\n",
       " ('posit interact experi', 1),\n",
       " ('great potenti', 1),\n",
       " ('correct explan', 1),\n",
       " ('correct respons', 1),\n",
       " ('fervent discuss', 1),\n",
       " ('common question', 1),\n",
       " ('form', 1),\n",
       " ('eleven categori', 1),\n",
       " ('human inquiri', 1),\n",
       " ('societ implic', 1),\n",
       " ('comprehens answer', 1),\n",
       " ('prior public chatbot', 1),\n",
       " ('comprehens analysi', 1),\n",
       " ('review boolean queri', 1),\n",
       " ('systemat review research', 1),\n",
       " ('high-qual systemat review', 1),\n",
       " ('invalid review', 1),\n",
       " ('rapid review', 1),\n",
       " ('review cost', 1),\n",
       " ('review topic', 1),\n",
       " ('star', 1),\n",
       " ('star framework', 1),\n",
       " ('goal-direct asp', 1),\n",
       " ('goal-direct convers', 1),\n",
       " ('asp', 1),\n",
       " ('nlu applic', 1),\n",
       " ('qualit reason', 1),\n",
       " ('non-textu reason', 1),\n",
       " ('unreli reason', 1),\n",
       " ('induct reason', 1),\n",
       " ('extrins hallucin', 1),\n",
       " ('hallucin problem', 1),\n",
       " ('23 data set', 1),\n",
       " ('parametr memori', 1),\n",
       " ('cosmolog', 1),\n",
       " ('cosmolog constant lambda', 1),\n",
       " ('hubbl constant', 1),\n",
       " ('cosmolog paramet', 1),\n",
       " ('photometr redshift', 1),\n",
       " (\"killer applications'\", 1),\n",
       " ('shallow learn', 1),\n",
       " ('clumpi factor', 1),\n",
       " ('plagiar check', 1),\n",
       " ('plagiar check softwar', 1),\n",
       " ('potenti plagiar issu', 1),\n",
       " ('popular plagiar detect tool', 1),\n",
       " ('popular AI chatbot', 1),\n",
       " ('academ essay', 1),\n",
       " ('experiment group', 1),\n",
       " ('essay score', 1),\n",
       " (\"students' essay\", 1),\n",
       " ('essay element', 1),\n",
       " ('vice versa', 1),\n",
       " ('human evolut', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(key5Counter.items(), key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LexSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key5Counter = Counter()\n",
    "stem2raw = {}\n",
    "for ab in ChatGPTf['abstract']:\n",
    "    results = modelLexSpec.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        stem2raw[item['stemmed']] = item['raw'][0]\n",
    "        key5Counter[item['stemmed']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AI', 24),\n",
       " ('educ', 20),\n",
       " ('code', 20),\n",
       " ('task', 19),\n",
       " ('llm', 18),\n",
       " ('student', 18),\n",
       " ('question', 17),\n",
       " ('text', 17),\n",
       " ('dataset', 17),\n",
       " ('data', 17),\n",
       " ('tool', 15),\n",
       " ('chatbot', 15),\n",
       " ('gpt-4', 15),\n",
       " ('instruct', 14),\n",
       " ('imag', 13),\n",
       " ('problem', 13),\n",
       " ('program', 13),\n",
       " ('translat', 12),\n",
       " ('respons', 12),\n",
       " ('research', 12),\n",
       " ('chatgpt', 12),\n",
       " ('prompt', 12),\n",
       " ('content', 12),\n",
       " ('attack', 11),\n",
       " ('output', 11),\n",
       " ('answer', 11),\n",
       " ('nlp', 11),\n",
       " ('evalu', 11),\n",
       " ('human', 10),\n",
       " ('model', 10),\n",
       " ('inform', 10),\n",
       " ('user', 9),\n",
       " ('solut', 9),\n",
       " ('detect', 9),\n",
       " ('abil', 9),\n",
       " ('knowledg', 9),\n",
       " ('recommend', 9),\n",
       " ('review', 8),\n",
       " ('peopl', 8),\n",
       " ('design', 8),\n",
       " ('summari', 8),\n",
       " ('languag', 8),\n",
       " ('feedback', 8),\n",
       " ('entiti', 8),\n",
       " ('field', 8),\n",
       " ('lm', 8),\n",
       " ('topic', 7),\n",
       " ('articl', 7),\n",
       " ('exam', 7),\n",
       " ('applic', 7),\n",
       " ('e.g.', 7),\n",
       " ('queri', 7),\n",
       " ('studi', 7),\n",
       " ('transform', 7),\n",
       " ('plm', 7),\n",
       " ('hallucin', 7),\n",
       " ('softwar engin', 7),\n",
       " ('rlhf', 7),\n",
       " ('aigc', 7),\n",
       " ('video', 7),\n",
       " ('detector', 7),\n",
       " ('system', 7),\n",
       " ('benchmark', 7),\n",
       " ('technolog', 7),\n",
       " ('style', 6),\n",
       " ('machin translat', 6),\n",
       " ('reason', 6),\n",
       " ('ML', 6),\n",
       " ('sentiment analysi', 6),\n",
       " ('techniqu', 6),\n",
       " ('nlp task', 6),\n",
       " ('QA', 6),\n",
       " ('work', 6),\n",
       " ('privaci', 6),\n",
       " ('assess', 6),\n",
       " ('idea', 6),\n",
       " ('method', 6),\n",
       " ('foundat model', 6),\n",
       " ('cot', 6),\n",
       " ('analysi', 6),\n",
       " ('test', 6),\n",
       " ('gpt-3.5', 6),\n",
       " ('advantag', 5),\n",
       " ('essay', 5),\n",
       " ('activ', 5),\n",
       " ('AI system', 5),\n",
       " ('secur', 5),\n",
       " ('concept', 5),\n",
       " ('physic', 5),\n",
       " ('explain', 5),\n",
       " ('mathemat', 5),\n",
       " ('industri', 5),\n",
       " ('introduct', 5),\n",
       " ('failur', 5),\n",
       " ('group', 5),\n",
       " ('weak', 5),\n",
       " ('kg', 5),\n",
       " ('medic imag', 5),\n",
       " ('decis', 5),\n",
       " ('gpt', 5),\n",
       " ('bert', 5),\n",
       " ('framework', 5),\n",
       " ('robust', 5),\n",
       " ('input', 5),\n",
       " ('data augment', 5),\n",
       " ('safeti', 5),\n",
       " ('english', 5),\n",
       " ('gener AI', 5),\n",
       " ('align', 5),\n",
       " ('claim', 5),\n",
       " ('capabl', 5),\n",
       " ('order', 5),\n",
       " ('graph', 5),\n",
       " ('algorithm', 5),\n",
       " ('gai', 5),\n",
       " ('agi', 5),\n",
       " ('github', 5),\n",
       " ('chatgpt-4', 5),\n",
       " ('perform', 5),\n",
       " ('sentiment', 5),\n",
       " ('bard', 5),\n",
       " ('reliabl', 5),\n",
       " ('role', 5),\n",
       " ('sourc code', 5),\n",
       " ('knowledg graph', 5),\n",
       " ('memori', 5),\n",
       " ('polici', 5),\n",
       " ('gener', 5),\n",
       " ('risk', 5),\n",
       " ('ner', 5),\n",
       " ('paraphras', 4),\n",
       " ('plagiar', 4),\n",
       " ('explan', 4),\n",
       " ('principl', 4),\n",
       " ('govern', 4),\n",
       " ('googl translat', 4),\n",
       " ('particip', 4),\n",
       " ('fact', 4),\n",
       " ('toxic', 4),\n",
       " ('chatgpt-gener text', 4),\n",
       " ('correct answer', 4),\n",
       " ('simul', 4),\n",
       " ('write', 4),\n",
       " ('educ sector', 4),\n",
       " ('T5', 4),\n",
       " ('instructgpt', 4),\n",
       " ('convers', 4),\n",
       " ('survey', 4),\n",
       " ('network', 4),\n",
       " ('stack overflow', 4),\n",
       " ('text summar', 4),\n",
       " ('translat qualiti', 4),\n",
       " ('sota', 4),\n",
       " ('inabl', 4),\n",
       " ('version', 4),\n",
       " ('tweet', 4),\n",
       " ('person', 4),\n",
       " ('downstream task', 4),\n",
       " ('relationship', 4),\n",
       " ('in-context learn', 4),\n",
       " ('teacher', 4),\n",
       " ('ai-gener content', 4),\n",
       " ('usag', 4),\n",
       " ('univers', 4),\n",
       " ('feasibl', 4),\n",
       " ('metric', 4),\n",
       " ('scenario', 4),\n",
       " ('MT', 4),\n",
       " ('difficulti', 4),\n",
       " ('classif', 4),\n",
       " ('correct solut', 4),\n",
       " ('effect', 4),\n",
       " ('error', 4),\n",
       " ('term', 4),\n",
       " ('artifici intellig', 4),\n",
       " ('argument', 4),\n",
       " ('situat', 4),\n",
       " ('area', 4),\n",
       " ('financ', 4),\n",
       " ('logic reason', 4),\n",
       " ('bias', 4),\n",
       " ('learner', 4),\n",
       " ('dialogu', 4),\n",
       " ('sentiment analysi task', 4),\n",
       " ('googl bard', 4),\n",
       " ('machine-gener text', 4),\n",
       " ('instruct tune', 4),\n",
       " ('author', 4),\n",
       " ('patient', 4),\n",
       " ('recommend scenario', 4),\n",
       " ('exampl', 4),\n",
       " ('literatur', 4),\n",
       " ('behavior', 4),\n",
       " ('rule', 4),\n",
       " ('RL', 4),\n",
       " ('paper', 4),\n",
       " ('launch', 4),\n",
       " ('genai', 4),\n",
       " ('roberta', 4),\n",
       " ('code gener', 4),\n",
       " ('thought', 4),\n",
       " ('roadmap', 4),\n",
       " ('bingchat', 4),\n",
       " ('strength', 4),\n",
       " ('agent', 4),\n",
       " ('factual knowledg', 4),\n",
       " ('identif', 3),\n",
       " ('type', 3),\n",
       " ('stanc detect', 3),\n",
       " ('radiologist', 3),\n",
       " ('radiolog report', 3),\n",
       " ('improv', 3),\n",
       " ('hand', 3),\n",
       " ('bug', 3),\n",
       " ('translat perform', 3),\n",
       " ('truth', 3),\n",
       " ('programm', 3),\n",
       " ('creativ', 3),\n",
       " ('apr', 3),\n",
       " ('program repair', 3),\n",
       " ('mathemat reason', 3),\n",
       " ('nli', 3),\n",
       " ('regul', 3),\n",
       " ('correct', 3),\n",
       " ('chatgpt-3', 3),\n",
       " ('evolut', 3),\n",
       " ('catalyst', 3),\n",
       " ('KG', 3),\n",
       " ('diseas', 3),\n",
       " ('presenc', 3),\n",
       " ('process', 3),\n",
       " ('percept', 3),\n",
       " ('opinion', 3),\n",
       " ('persona', 3),\n",
       " ('catalog', 3),\n",
       " ('comparison', 3),\n",
       " ('effort', 3),\n",
       " ('event extract', 3),\n",
       " ('zero-shot set', 3),\n",
       " ('assist', 3),\n",
       " ('sampl size', 3),\n",
       " ('robot', 3),\n",
       " ('log', 3),\n",
       " ('time', 3),\n",
       " ('document', 3),\n",
       " ('releas', 3),\n",
       " ('number', 3),\n",
       " ('oper', 3),\n",
       " ('softwar', 3),\n",
       " ('collabor', 3),\n",
       " ('occup', 3),\n",
       " ('gener AI tool', 3),\n",
       " ('human feedback', 3),\n",
       " ('baselin', 3),\n",
       " ('event', 3),\n",
       " ('complex task', 3),\n",
       " ('experi', 3),\n",
       " ('schema', 3),\n",
       " ('end', 3),\n",
       " ('entiti recognit', 3),\n",
       " ('visual chatgpt', 3),\n",
       " ('discuss', 3),\n",
       " ('human prefer', 3),\n",
       " ('vlm', 3),\n",
       " ('law', 3),\n",
       " ('imag caption', 3),\n",
       " ('word', 3),\n",
       " ('intent', 3),\n",
       " ('factual', 3),\n",
       " ('report', 3),\n",
       " ('assign', 3),\n",
       " ('abstract', 3),\n",
       " ('scale', 3),\n",
       " ('breadth', 3),\n",
       " ('challeng', 3),\n",
       " ('academia', 3),\n",
       " ('histori', 3),\n",
       " ('exercis', 3),\n",
       " ('grammat error correct', 3),\n",
       " ('metavers', 3),\n",
       " ('medic advic', 3),\n",
       " ('onlin', 3),\n",
       " ('recommend system', 3),\n",
       " ('theori', 3),\n",
       " ('human analyst', 3),\n",
       " ('ecosystem', 3),\n",
       " ('graph structur', 3),\n",
       " ('gap', 3),\n",
       " ('search', 3),\n",
       " ('learn', 3),\n",
       " ('mistak', 3),\n",
       " ('AI model', 3),\n",
       " ('engin', 3),\n",
       " ('rate', 3),\n",
       " ('qualiti', 3),\n",
       " ('gener text', 3),\n",
       " ('kind', 3),\n",
       " ('classifi', 3),\n",
       " ('step', 3),\n",
       " ('eas', 3),\n",
       " ('categori', 3),\n",
       " ('human evalu', 3),\n",
       " ('drawback', 3),\n",
       " ('item', 3),\n",
       " ('environ', 3),\n",
       " ('faith', 3),\n",
       " ('harm content', 3),\n",
       " ('servic', 3),\n",
       " ('adversari exampl', 3),\n",
       " ('phase', 3),\n",
       " ('develop', 3),\n",
       " ('outlook', 3),\n",
       " ('corpu', 3),\n",
       " ('plan', 3),\n",
       " ('llama', 3),\n",
       " ('IR', 3),\n",
       " ('opportun', 3),\n",
       " ('interest', 3),\n",
       " ('ethic concern', 3),\n",
       " ('construct', 3),\n",
       " ('percentag', 3),\n",
       " ('graph data', 3),\n",
       " ('AI technolog', 3),\n",
       " ('synthet dataset', 3),\n",
       " ('methodolog', 3),\n",
       " ('realm', 3),\n",
       " ('book', 3),\n",
       " ('abus', 3),\n",
       " ('genai tool', 3),\n",
       " ('higher educ', 3),\n",
       " ('multi-turn convers', 3),\n",
       " ('flan', 3),\n",
       " ('cost', 3),\n",
       " ('control', 3),\n",
       " ('websit', 3),\n",
       " ('diagnosi', 3),\n",
       " ('vision-languag model', 3),\n",
       " ('object', 3),\n",
       " ('expert', 3),\n",
       " ('fair', 3),\n",
       " ('human-written text', 3),\n",
       " ('ethic implic', 3),\n",
       " ('consist', 3),\n",
       " ('opt', 3),\n",
       " ('token', 3),\n",
       " ('softwar develop', 3),\n",
       " ('futur', 3),\n",
       " ('vietnames student', 3),\n",
       " ('properti', 3),\n",
       " ('shortcom', 3),\n",
       " ('investor', 3),\n",
       " ('annot', 3),\n",
       " ('emot', 3),\n",
       " ('chat', 3),\n",
       " ('cours', 3),\n",
       " ('strategi', 3),\n",
       " ('ppo', 3),\n",
       " ('fact-check', 3),\n",
       " ('textit', 3),\n",
       " ('attribut', 3),\n",
       " ('impact', 3),\n",
       " ('open-sourc llm', 3),\n",
       " ('non-expert', 3),\n",
       " ('public opinion', 3),\n",
       " ('subject', 3),\n",
       " ('entertain', 2),\n",
       " ('disrupt technolog', 2),\n",
       " ('1950', 2),\n",
       " ('review articl', 2),\n",
       " ('drug discoveri', 2),\n",
       " ('human-gener text', 2),\n",
       " ('candid', 2),\n",
       " ('pegasu', 2),\n",
       " ('children', 2),\n",
       " ('poetri', 2),\n",
       " ('humor', 2),\n",
       " ('submiss', 2),\n",
       " ('stanc detect task', 2),\n",
       " ('prolifer', 2),\n",
       " ('radiolog', 2),\n",
       " ('phenomenon', 2),\n",
       " ('polit elect', 2),\n",
       " ('statement', 2),\n",
       " ('label', 2),\n",
       " ('har', 2),\n",
       " ('interfac', 2),\n",
       " ('sector', 2),\n",
       " ('ethic principl', 2),\n",
       " ('judgment', 2),\n",
       " ('advic', 2),\n",
       " ('hc3', 2),\n",
       " ('human expert', 2),\n",
       " ('analog', 2),\n",
       " ('varieti', 2),\n",
       " ('openai', 2),\n",
       " ('repair', 2),\n",
       " ('approach', 2),\n",
       " ('translat prompt', 2),\n",
       " ('multilingu translat', 2),\n",
       " ('translat abil', 2),\n",
       " ('trust', 2),\n",
       " ('chatbot respons', 2),\n",
       " ('multitud', 2),\n",
       " ('human-lik respons', 2),\n",
       " ('ethic risk', 2),\n",
       " ('patch', 2),\n",
       " ('incorrect patch', 2),\n",
       " ('patch gener', 2),\n",
       " ('testb', 2),\n",
       " ('2019', 2),\n",
       " ('profici', 2),\n",
       " ('79', 2),\n",
       " ('undergraduate-level mathemat', 2),\n",
       " ('data visualis', 2),\n",
       " ('chat2vi', 2),\n",
       " ('AI regul', 2),\n",
       " ('construct industri', 2),\n",
       " ('chatgpt failur', 2),\n",
       " ('math', 2),\n",
       " ('massiv amount', 2),\n",
       " ('systemat review', 2),\n",
       " ('nlu task', 2),\n",
       " ('control group', 2),\n",
       " ('spectrum', 2),\n",
       " ('convers AI', 2),\n",
       " ('debut', 2),\n",
       " ('7', 2),\n",
       " ('human tutor', 2),\n",
       " ('100', 2),\n",
       " ('scheme', 2),\n",
       " ('gpt3', 2),\n",
       " ('transform model', 2),\n",
       " ('hate speech', 2),\n",
       " ('scratch', 2),\n",
       " ('etc.', 2),\n",
       " ('distribut', 2),\n",
       " ('decomposit', 2),\n",
       " ('document-level translat', 2),\n",
       " ('translat direct', 2),\n",
       " ('shot', 2),\n",
       " ('countri', 2),\n",
       " ('understand abil', 2),\n",
       " ('conjunct', 2),\n",
       " ('practic', 2),\n",
       " ('pattern', 2),\n",
       " ('prompt pattern', 2),\n",
       " ('prompt engin', 2),\n",
       " ('prompt engin techniqu', 2),\n",
       " ('reinforc', 2),\n",
       " ('out-of-distribut', 2),\n",
       " ('infer', 2),\n",
       " ('llm-gener respons', 2),\n",
       " ('robot applic', 2),\n",
       " ('matrix', 2),\n",
       " ('150', 2),\n",
       " ('novemb 2022', 2),\n",
       " ('view', 2),\n",
       " ('healthcar', 2),\n",
       " ('point', 2),\n",
       " ('zero-shot manner', 2),\n",
       " ('part', 2),\n",
       " ('fci', 2),\n",
       " ('complet', 2),\n",
       " ('cross-lingu transfer', 2),\n",
       " ('internet', 2),\n",
       " ('AI tool', 2),\n",
       " ('design process', 2),\n",
       " ('societi', 2),\n",
       " ('visual', 2),\n",
       " ('bow', 2),\n",
       " ('result', 2),\n",
       " ('optim problem', 2),\n",
       " ('begin', 2),\n",
       " ('nlg', 2),\n",
       " ('automat evalu metric', 2),\n",
       " ('digit content', 2),\n",
       " ('demonstr', 2),\n",
       " ('tiktok', 2),\n",
       " ('cross-mod encod', 2),\n",
       " ('defens', 2),\n",
       " ('prefer', 2),\n",
       " ('bound', 2),\n",
       " ('align techniqu', 2),\n",
       " ('multimod system', 2),\n",
       " ('disclosur', 2),\n",
       " ('trustworthi', 2),\n",
       " ('analys', 2),\n",
       " ('stabl diffus', 2),\n",
       " ('current dialogu system', 2),\n",
       " ('modal', 2),\n",
       " ('databas schema', 2),\n",
       " ('manag', 2),\n",
       " ('extent', 2),\n",
       " ('refactor', 2),\n",
       " ('third-parti librari', 2),\n",
       " ('test question', 2),\n",
       " ('competit', 2),\n",
       " ('gpt-3', 2),\n",
       " ('passag', 2),\n",
       " ('fine-grain compress', 2),\n",
       " ('gelu', 2),\n",
       " ('glue', 2),\n",
       " ('layer normal', 2),\n",
       " ('softmax', 2),\n",
       " ('comput', 2),\n",
       " ('vision', 2),\n",
       " ('creation', 2),\n",
       " ('headlin', 2),\n",
       " ('correl', 2),\n",
       " ('measur', 2),\n",
       " ('refin', 2),\n",
       " ('gpt-4 perform', 2),\n",
       " ('depth', 2),\n",
       " ('platform', 2),\n",
       " ('cpu', 2),\n",
       " ('preliminari evalu', 2),\n",
       " ('innov', 2),\n",
       " ('2017', 2),\n",
       " ('misinform', 2),\n",
       " ('attempt', 2),\n",
       " ('gec', 2),\n",
       " ('over-correct', 2),\n",
       " ('simpl prompt', 2),\n",
       " ('reader', 2),\n",
       " ('obstacl', 2),\n",
       " ('pro', 2),\n",
       " ('github copilot', 2),\n",
       " ('detect method', 2),\n",
       " ('accur advic', 2),\n",
       " ('medic knowledg', 2),\n",
       " ('instruct data', 2),\n",
       " ('amount', 2),\n",
       " ('phenomena', 2),\n",
       " ('mturk', 2),\n",
       " ('annot task', 2),\n",
       " ('agreement', 2),\n",
       " ('factual inconsist', 2),\n",
       " ('stabil', 2),\n",
       " ('level', 2),\n",
       " ('classif task', 2),\n",
       " ('deploy', 2),\n",
       " ('academ write', 2),\n",
       " ('access', 2),\n",
       " ('set', 2),\n",
       " ('commonsens knowledg', 2),\n",
       " ('commonsens problem', 2),\n",
       " ('tip', 2),\n",
       " ('outlin', 2),\n",
       " ('sub-task', 2),\n",
       " ('commun', 2),\n",
       " ('pedagogi', 2),\n",
       " ('forc concept inventori', 2),\n",
       " ('thing', 2),\n",
       " ('histor text', 2),\n",
       " ('varianc', 2),\n",
       " ('hug face', 2),\n",
       " ('AI task', 2),\n",
       " ('decad', 2),\n",
       " ('bodi', 2),\n",
       " ('gener summari', 2),\n",
       " ('famili', 2),\n",
       " ('initi output', 2),\n",
       " ('1st', 2),\n",
       " ('year', 2),\n",
       " ('FE', 2),\n",
       " ('model scale', 2),\n",
       " ('hospit', 2),\n",
       " ('guardrail', 2),\n",
       " ('chat model', 2),\n",
       " ('barrier', 2),\n",
       " ('interact', 2),\n",
       " ('degre', 2),\n",
       " ('fraud', 2),\n",
       " ('cheat', 2),\n",
       " ('gpt4', 2),\n",
       " ('seri', 2),\n",
       " ('direct', 2),\n",
       " ('applic domain', 2),\n",
       " ('medicin', 2),\n",
       " ('trial', 2),\n",
       " ('choic', 2),\n",
       " ('maximum number', 2),\n",
       " ('DL', 2),\n",
       " ('instrctgpt', 2),\n",
       " ('success', 2),\n",
       " ('tendenc', 2),\n",
       " ('treatment', 2),\n",
       " ('versatil', 2),\n",
       " ('translat instruct', 2),\n",
       " ('evalu metric', 2),\n",
       " ('intersect', 2),\n",
       " ('potenti', 2),\n",
       " ('rise', 2),\n",
       " ('ift', 2),\n",
       " ('caption', 2),\n",
       " ('motiv', 2),\n",
       " ('discrimin', 2),\n",
       " ('synthet data', 2),\n",
       " ('implic', 2),\n",
       " ('practition', 2),\n",
       " ('condit', 2),\n",
       " ('sequenc', 2),\n",
       " ('summari faith', 2),\n",
       " ('slu', 2),\n",
       " ('dst', 2),\n",
       " ('dialogu state track', 2),\n",
       " ('accur', 2),\n",
       " ('languag model', 2),\n",
       " ('aigc model', 2),\n",
       " ('privaci threat', 2),\n",
       " ('bing', 2),\n",
       " ('harm', 2),\n",
       " ('predict', 2),\n",
       " ('human rate', 2),\n",
       " ('tempor relat', 2),\n",
       " ('4', 2),\n",
       " ('diagram', 2),\n",
       " ('light', 2),\n",
       " ('accuraci', 2),\n",
       " ('bia', 2),\n",
       " ('scholar', 2),\n",
       " ('journal', 2),\n",
       " ('argument write', 2),\n",
       " ('vocabulari', 2),\n",
       " ('textbf', 2),\n",
       " ('concern', 2),\n",
       " ('chines', 2),\n",
       " ('advent', 2),\n",
       " ('busi', 2),\n",
       " ('10', 2),\n",
       " ('threat', 2),\n",
       " ('perspect', 2),\n",
       " ('therapist', 2),\n",
       " ('textbook', 2),\n",
       " ('cskb', 2),\n",
       " ('bioinformat', 2),\n",
       " ('benefit', 2),\n",
       " ('progress', 2),\n",
       " ('aspect', 2),\n",
       " ('ethic', 2),\n",
       " ('dall 2', 2),\n",
       " ('compani', 2),\n",
       " ('architectur design', 2),\n",
       " ('team', 2),\n",
       " ('medic text', 2),\n",
       " ('fluenci', 2),\n",
       " ('chatgpt perform', 2),\n",
       " ('traceabl', 2),\n",
       " ('bloom', 2),\n",
       " ('reproduc', 2),\n",
       " ('bot', 2),\n",
       " ('social norm', 2),\n",
       " ('coher', 2),\n",
       " ('academ integr', 2),\n",
       " ('imdb', 2),\n",
       " ('causal', 2),\n",
       " ('causal reason', 2),\n",
       " ('robot abil', 2),\n",
       " ('requir', 2),\n",
       " ('possibl', 2),\n",
       " ('tabular dataset', 2),\n",
       " ('tabular data', 2),\n",
       " ('natur languag instruct', 2),\n",
       " ('automat metric', 2),\n",
       " ('practic applic', 2),\n",
       " ('databas', 2),\n",
       " ('complex', 2),\n",
       " ('1000', 2),\n",
       " ('long document', 2),\n",
       " ('paradigm', 2),\n",
       " ('correspond', 2),\n",
       " ('plc', 2),\n",
       " ('automat identif', 2),\n",
       " ('eda', 2),\n",
       " ('limit', 2),\n",
       " ('dnn', 2),\n",
       " ('IP', 2),\n",
       " ('chain', 2),\n",
       " ('genai technolog', 2),\n",
       " ('policymak', 2),\n",
       " ('instruction-tun lm', 2),\n",
       " ('tech compani', 2),\n",
       " ('bing chat', 2),\n",
       " ('constructionist len', 2),\n",
       " ('comput scienc educ', 2),\n",
       " ('comput program', 2),\n",
       " ('chatgpt impact', 2),\n",
       " ('instructor', 2),\n",
       " ('architectur', 2),\n",
       " ('sustain', 2),\n",
       " ('textual descript', 2),\n",
       " ('vicuna', 2),\n",
       " ('interpret', 2),\n",
       " ('dall-e2', 2),\n",
       " ('copyright', 2),\n",
       " ('gpt-3.5-turbo', 2),\n",
       " ('search tool', 2),\n",
       " ('unit test', 2),\n",
       " ('stage', 2),\n",
       " ('taxonomi', 2),\n",
       " ('case', 2),\n",
       " ('gpt3.5', 2),\n",
       " ('rang', 2),\n",
       " ('appl', 2),\n",
       " ('3D', 2),\n",
       " ('top', 2),\n",
       " ('simplif', 2),\n",
       " ('forc', 2),\n",
       " ('gi', 2),\n",
       " ('logic', 2),\n",
       " ('java', 2),\n",
       " ('recommend paradigm', 2),\n",
       " ('linguist capabl', 2),\n",
       " ('critiqu', 2),\n",
       " ('guidelin', 2),\n",
       " ('app', 2),\n",
       " ('neg sentiment', 2),\n",
       " ('mechan', 2),\n",
       " ('instanc', 2),\n",
       " ('inequ', 2),\n",
       " ('languag translat', 2),\n",
       " ('translat task', 2),\n",
       " ('base lm', 2),\n",
       " ('finetun', 2),\n",
       " ('input text', 2),\n",
       " ('stakehold', 2),\n",
       " ('vulner', 2),\n",
       " ('factual consist', 2),\n",
       " ('efl', 2),\n",
       " ('larg lm', 2),\n",
       " ('comment', 2),\n",
       " ('context', 2),\n",
       " ('genaibot', 2),\n",
       " ('agents-to-think-with', 2),\n",
       " ('paramet', 2),\n",
       " ('SE', 2),\n",
       " ('vnhsge', 2),\n",
       " ('extern knowledg', 2),\n",
       " ('convers system', 2),\n",
       " ('synthet text', 2),\n",
       " ('code snippet', 2),\n",
       " ('bleu', 2),\n",
       " ('stanc', 2),\n",
       " ('landscap', 2),\n",
       " ('crss', 2),\n",
       " ('educ set', 2),\n",
       " ('specif scenario', 2),\n",
       " ('hardwar', 2),\n",
       " ('hardwar engin', 2),\n",
       " ('transcript', 2),\n",
       " ('goal-ori dialogu', 2),\n",
       " ('jailbreak prompt', 2),\n",
       " ('resili', 2),\n",
       " ('mind', 2),\n",
       " ('claud', 2),\n",
       " ('art', 2),\n",
       " ('divers', 2),\n",
       " ('qlora', 2),\n",
       " ('bart', 2),\n",
       " ('financi domain', 2),\n",
       " ('par', 2),\n",
       " ('granular', 2),\n",
       " ('cost-effici', 2),\n",
       " ('icl', 2),\n",
       " ('mainstream', 2),\n",
       " ('scienc', 2),\n",
       " ('cybersecur', 2),\n",
       " ('zero-shot', 2),\n",
       " ('annot data', 2),\n",
       " ('gpt-2', 2),\n",
       " ('evid', 2),\n",
       " ('segment', 2),\n",
       " ('drug', 2),\n",
       " ('modul', 2),\n",
       " ('robot task', 2),\n",
       " ('dimens', 2),\n",
       " ('AR', 2),\n",
       " ('tabl', 2),\n",
       " ('sam', 2),\n",
       " ('reason process', 2),\n",
       " ('inaccuraci', 2),\n",
       " ('shape', 2),\n",
       " ('3D shape', 2),\n",
       " ('AI assist', 2),\n",
       " ('public attitud', 2),\n",
       " ('3', 2),\n",
       " ('convers agent', 2),\n",
       " ('98', 2),\n",
       " ('product', 2),\n",
       " ('project', 2),\n",
       " ('human-author text', 2),\n",
       " ('coher text', 2),\n",
       " ('disciplin', 2),\n",
       " ('scientif disciplin', 2),\n",
       " ('altern', 2),\n",
       " ('chatgpt-gener code', 2),\n",
       " ('patent', 2),\n",
       " ('vietnam', 2),\n",
       " ('jailbreak', 2),\n",
       " ('assumpt', 2),\n",
       " ('geographi', 2),\n",
       " ('asr system', 2),\n",
       " ('visual input', 2),\n",
       " ('code qualiti', 2),\n",
       " ('alpaca', 2),\n",
       " ('judgement', 2),\n",
       " ('main topic', 1),\n",
       " ('earli adopt', 1),\n",
       " (\"earli adopters' sentiment\", 1),\n",
       " ('topic model', 1),\n",
       " ('disrupt', 1),\n",
       " ('earli chatgpt user', 1),\n",
       " ('origin content', 1),\n",
       " ('origin thought', 1),\n",
       " ('origin contribut', 1),\n",
       " ('origin prose score', 1),\n",
       " ('classic ture test', 1),\n",
       " ('98-99', 1),\n",
       " ('sequenti question', 1),\n",
       " ('lovelac 2.0', 1),\n",
       " ('paraphras identif', 1),\n",
       " ('typolog', 1),\n",
       " ('effect paraphras detect', 1),\n",
       " ('refin typolog', 1),\n",
       " ('paraphras impact detect capabl', 1),\n",
       " ('under-represent', 1),\n",
       " ('explain AI', 1),\n",
       " ('potenti advantag', 1),\n",
       " ('drug discoveri process', 1),\n",
       " ('human-author', 1),\n",
       " ('onlin exam', 1),\n",
       " ('oral exam', 1),\n",
       " ('foolproof solut', 1),\n",
       " ('institut', 1),\n",
       " ('academ misconduct', 1),\n",
       " ('realist text', 1),\n",
       " ('unsupervis pegasu', 1),\n",
       " ('unsupervis manner', 1),\n",
       " ('summari candid', 1),\n",
       " ('supervis setup', 1),\n",
       " ('unsupervis model', 1),\n",
       " ('re-rank summari candid', 1),\n",
       " ('supervis counterpart', 1),\n",
       " ('7.27', 1),\n",
       " ('puzzl', 1),\n",
       " ('smart-101', 1),\n",
       " ('visuo-linguist puzzl', 1),\n",
       " ('neural network', 1),\n",
       " ('deep neural network', 1),\n",
       " ('smart-101 dataset', 1),\n",
       " ('101', 1),\n",
       " ('elementari skill', 1),\n",
       " ('pictur', 1),\n",
       " ('bygpt5', 1),\n",
       " ('end-to-end poetri gener', 1),\n",
       " ('rhyme', 1),\n",
       " ('meter', 1),\n",
       " ('alliter', 1),\n",
       " ('mt5', 1),\n",
       " ('byt5', 1),\n",
       " ('german quatrain', 1),\n",
       " ('humor paper titl', 1),\n",
       " ('2.5k titl', 1),\n",
       " ('funni titl', 1),\n",
       " ('large-scal humor', 1),\n",
       " ('30k', 1),\n",
       " ('fine-tun system', 1),\n",
       " ('end-to-end abstract-to-titl gener problem', 1),\n",
       " ('automat system', 1),\n",
       " ('evas', 1),\n",
       " ('defens evas', 1),\n",
       " ('keylogg', 1),\n",
       " ('worm', 1),\n",
       " ('self-repl', 1),\n",
       " ('self-modif', 1),\n",
       " ('payment-fulfil ransomwar', 1),\n",
       " ('cybersecur question', 1),\n",
       " ('mitr att', 1),\n",
       " ('complex cybersecur goal', 1),\n",
       " ('short-form', 1),\n",
       " ('short-form essay', 1),\n",
       " ('pm 2', 1),\n",
       " ('pm 5', 1),\n",
       " ('physic essay', 1),\n",
       " ('pm 1', 1),\n",
       " ('300', 1),\n",
       " ('71', 1),\n",
       " ('stanc detect refer', 1),\n",
       " ('standpoint', 1),\n",
       " ('p-stanc', 1),\n",
       " ('nov 30', 1),\n",
       " ('deep learn model', 1),\n",
       " ('favor', 1),\n",
       " ('simplifi report', 1),\n",
       " ('medic report', 1),\n",
       " ('15 radiologist', 1),\n",
       " ('harm passag', 1),\n",
       " ('patient-cent care', 1),\n",
       " ('questionnair', 1),\n",
       " ('twenti question', 1),\n",
       " ('guess 94', 1),\n",
       " ('spanish question', 1),\n",
       " ('bilingu game', 1),\n",
       " ('question context', 1),\n",
       " ('classic twenty-quest game', 1),\n",
       " ('neurosci metadata', 1),\n",
       " ('switch role', 1),\n",
       " ('2021 elect', 1),\n",
       " ('nation-agnost polit compass test', 1),\n",
       " ('630', 1),\n",
       " ('flight', 1),\n",
       " ('germani', 1),\n",
       " ('unen', 1),\n",
       " ('netherland', 1),\n",
       " ('groenlink', 1),\n",
       " ('walk', 1),\n",
       " ('activ track', 1),\n",
       " ('open fridg', 1),\n",
       " ('label semant', 1),\n",
       " ('human activ recognit', 1),\n",
       " ('integ id', 1),\n",
       " ('long-tail activ distribut set', 1),\n",
       " ('honeypot interfac', 1),\n",
       " ('dynam honeypot', 1),\n",
       " ('cyber secur', 1),\n",
       " ('potenti honeypot interfac', 1),\n",
       " ('perimet secur', 1),\n",
       " ('cyber secur postur', 1),\n",
       " ('command-lin attack', 1),\n",
       " ('delay attack', 1),\n",
       " ('scientif text', 1),\n",
       " ('main model', 1),\n",
       " ('dreamfus model', 1),\n",
       " ('phenaki model', 1),\n",
       " ('audiolm model', 1),\n",
       " ('dalle-2 model', 1),\n",
       " ('respons AI', 1),\n",
       " ('respons AI pattern catalogu', 1),\n",
       " ('respons AI challeng', 1),\n",
       " ('pattern-ori respons AI engin approach', 1),\n",
       " ('organis', 1),\n",
       " ('pattern-driven mitig', 1),\n",
       " ('moral judgment', 1),\n",
       " (\"users' moral judgment\", 1),\n",
       " ('moral advisor', 1),\n",
       " ('contradictori moral belief', 1),\n",
       " ('consist moral advic', 1),\n",
       " ('fun', 1),\n",
       " ('chat bot', 1),\n",
       " ('hc3 dataset', 1),\n",
       " ('https://github.com/hello-simpleai/chatgpt-comparison-detection.', 1),\n",
       " ('human question', 1),\n",
       " ('human chatgpt comparison corpu', 1),\n",
       " ('abstract concept', 1),\n",
       " ('theoret swampland conjectur', 1),\n",
       " ('full confid', 1),\n",
       " ('visual represent', 1),\n",
       " ('standard bug', 1),\n",
       " ('softwar bug', 1),\n",
       " ('40 bug', 1),\n",
       " ('standard program repair approach', 1),\n",
       " ('autom program repair', 1),\n",
       " ('program repair techniqu', 1),\n",
       " ('recent program repair method', 1),\n",
       " ('translat robust', 1),\n",
       " ('commerci translat product', 1),\n",
       " ('distant languag', 1),\n",
       " (\"patients' trust\", 1),\n",
       " ('provid respons', 1),\n",
       " ('lower trust', 1),\n",
       " ('patient-provid commun', 1),\n",
       " ('chatgpt-gener respons', 1),\n",
       " (\"patients' question\", 1),\n",
       " ('keyphras', 1),\n",
       " ('keyphras extract', 1),\n",
       " ('theme-driven keyphras extract', 1),\n",
       " ('human-annot keyphras', 1),\n",
       " ('theme-driven keyphras extract framework', 1),\n",
       " ('relev keyphras', 1),\n",
       " ('unsupervis keyphras extract model', 1),\n",
       " ('social media', 1),\n",
       " ('extract task', 1),\n",
       " ('social media data', 1),\n",
       " ('social', 1),\n",
       " ('de-facto arbit', 1),\n",
       " ('verac', 1),\n",
       " ('operation', 1),\n",
       " ('truth-stat', 1),\n",
       " ('listen', 1),\n",
       " ('truth-evalu capac', 1),\n",
       " ('AI truth-tel', 1),\n",
       " ('controversi', 1),\n",
       " ('introductori physic cours', 1),\n",
       " ('actual calculus-bas physic', 1),\n",
       " ('frequent indistinguish', 1),\n",
       " ('chatgtp', 1),\n",
       " ('preconcept', 1),\n",
       " ('singl solut', 1),\n",
       " ('design solut', 1),\n",
       " ('divers solut space', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(key5Counter.items(), key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LexRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "key5Counter = Counter()\n",
    "stem2raw = {}\n",
    "for ab in ChatGPTf['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        stem2raw[item['stemmed']] = item['raw'][0]\n",
    "        key5Counter[item['stemmed']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model', 83),\n",
       " ('chatgpt', 49),\n",
       " ('task', 45),\n",
       " ('llm', 41),\n",
       " ('data', 38),\n",
       " ('AI', 37),\n",
       " ('dataset', 32),\n",
       " ('question', 30),\n",
       " ('larg languag model', 26),\n",
       " ('text', 25),\n",
       " ('languag model', 23),\n",
       " ('languag', 22),\n",
       " ('code', 22),\n",
       " ('perform', 20),\n",
       " ('human', 19),\n",
       " ('prompt', 19),\n",
       " ('research', 19),\n",
       " ('gener', 18),\n",
       " ('studi', 16),\n",
       " ('evalu', 16),\n",
       " ('respons', 15),\n",
       " ('instruct', 15),\n",
       " ('educ', 14),\n",
       " ('tool', 14),\n",
       " ('knowledg', 14),\n",
       " ('problem', 14),\n",
       " ('system', 13),\n",
       " ('content', 13),\n",
       " ('program', 13),\n",
       " ('translat', 12),\n",
       " ('answer', 12),\n",
       " ('detect', 12),\n",
       " ('imag', 12),\n",
       " ('AI system', 11),\n",
       " ('learn', 11),\n",
       " ('nlp', 11),\n",
       " ('chatbot', 11),\n",
       " ('artifici intellig', 11),\n",
       " ('inform', 11),\n",
       " ('technolog', 10),\n",
       " ('gener model', 10),\n",
       " ('framework', 10),\n",
       " ('user', 10),\n",
       " ('gener AI', 10),\n",
       " ('student', 10),\n",
       " ('abil', 9),\n",
       " ('machin translat', 9),\n",
       " ('reason', 9),\n",
       " ('result', 9),\n",
       " ('softwar engin', 9),\n",
       " ('solut', 8),\n",
       " ('attack', 8),\n",
       " ('sentiment analysi', 8),\n",
       " ('foundat model', 8),\n",
       " ('output', 8),\n",
       " ('data augment', 8),\n",
       " ('method', 8),\n",
       " ('chatgpt perform', 8),\n",
       " ('exam', 7),\n",
       " ('AI technolog', 7),\n",
       " ('natur languag', 7),\n",
       " ('correct answer', 7),\n",
       " ('chatgpt respons', 7),\n",
       " ('feedback', 7),\n",
       " ('human evalu', 7),\n",
       " ('capabl', 7),\n",
       " ('recommend', 7),\n",
       " ('googl bard', 7),\n",
       " ('code gener', 7),\n",
       " ('sourc code', 7),\n",
       " ('knowledg graph', 7),\n",
       " ('review', 6),\n",
       " ('AI model', 6),\n",
       " ('wide rang', 6),\n",
       " ('chatgpt-gener text', 6),\n",
       " ('design', 6),\n",
       " ('text summar', 6),\n",
       " ('novemb 2022', 6),\n",
       " ('summari', 6),\n",
       " ('assess', 6),\n",
       " ('synthet data', 6),\n",
       " ('complex task', 6),\n",
       " ('video', 6),\n",
       " ('ai-gener content', 6),\n",
       " ('entiti', 6),\n",
       " ('gpt-4', 6),\n",
       " ('sentiment analysi task', 6),\n",
       " ('analysi', 6),\n",
       " ('test', 6),\n",
       " ('instruct tune', 6),\n",
       " ('effect', 6),\n",
       " ('benchmark', 6),\n",
       " ('topic', 5),\n",
       " ('potenti', 5),\n",
       " ('concept', 5),\n",
       " ('physic', 5),\n",
       " ('logic reason', 5),\n",
       " ('kg', 5),\n",
       " ('nlp task', 5),\n",
       " ('medic imag', 5),\n",
       " ('custom servic', 5),\n",
       " ('aigc', 5),\n",
       " ('natur languag process', 5),\n",
       " ('qualiti', 5),\n",
       " ('machine-gener text', 5),\n",
       " ('gener text', 5),\n",
       " ('applic', 5),\n",
       " ('domain', 5),\n",
       " ('memori', 5),\n",
       " ('limit', 5),\n",
       " ('chatgpt capabl', 5),\n",
       " ('queri', 5),\n",
       " ('lm', 5),\n",
       " ('articl', 4),\n",
       " ('essay', 4),\n",
       " ('stanc detect', 4),\n",
       " ('bias', 4),\n",
       " ('activ', 4),\n",
       " ('challeng', 4),\n",
       " ('improv', 4),\n",
       " ('style', 4),\n",
       " ('approach', 4),\n",
       " ('mathemat', 4),\n",
       " ('industri', 4),\n",
       " ('data set', 4),\n",
       " ('group', 4),\n",
       " ('write', 4),\n",
       " ('educ sector', 4),\n",
       " ('convers', 4),\n",
       " ('convers AI', 4),\n",
       " ('network', 4),\n",
       " ('data gener', 4),\n",
       " ('stack overflow', 4),\n",
       " ('translat qualiti', 4),\n",
       " ('zero-shot set', 4),\n",
       " ('entiti recognit', 4),\n",
       " ('paper', 4),\n",
       " ('ethic concern', 4),\n",
       " ('person', 4),\n",
       " ('AI tool', 4),\n",
       " ('human feedback', 4),\n",
       " ('downstream task', 4),\n",
       " ('in-context learn', 4),\n",
       " ('align', 4),\n",
       " ('graph', 4),\n",
       " ('algorithm', 4),\n",
       " ('metric', 4),\n",
       " ('model perform', 4),\n",
       " ('MT', 4),\n",
       " ('experi', 4),\n",
       " ('recommend system', 4),\n",
       " ('correct solut', 4),\n",
       " ('languag understand', 4),\n",
       " ('human-written text', 4),\n",
       " ('dialogu', 4),\n",
       " ('sentiment', 4),\n",
       " ('bard', 4),\n",
       " ('role', 4),\n",
       " ('recommend scenario', 4),\n",
       " ('annot', 4),\n",
       " ('hallucin', 4),\n",
       " ('requir', 4),\n",
       " ('transform', 4),\n",
       " ('risk', 4),\n",
       " ('genai', 4),\n",
       " ('higher educ', 4),\n",
       " ('polici', 4),\n",
       " ('ethic implic', 4),\n",
       " ('reward model', 4),\n",
       " ('strategi', 4),\n",
       " ('factual knowledg', 4),\n",
       " ('open-sourc llm', 4),\n",
       " ('earli adopt', 3),\n",
       " ('question answer', 3),\n",
       " ('paraphras', 3),\n",
       " ('identif', 3),\n",
       " ('human-gener text', 3),\n",
       " ('radiolog report', 3),\n",
       " ('principl', 3),\n",
       " ('human expert', 3),\n",
       " ('bug', 3),\n",
       " ('translat perform', 3),\n",
       " ('translat abil', 3),\n",
       " ('particip', 3),\n",
       " ('human-lik respons', 3),\n",
       " ('github copilot', 3),\n",
       " ('mathemat reason', 3),\n",
       " ('correct', 3),\n",
       " ('failur', 3),\n",
       " ('score', 3),\n",
       " ('diseas', 3),\n",
       " ('techniqu', 3),\n",
       " ('decis', 3),\n",
       " ('attent', 3),\n",
       " ('current version', 3),\n",
       " ('prompt engin', 3),\n",
       " ('prompt engin techniqu', 3),\n",
       " ('input', 3),\n",
       " ('sampl', 3),\n",
       " ('sampl size', 3),\n",
       " ('robot', 3),\n",
       " ('model paramet', 3),\n",
       " ('softwar', 3),\n",
       " ('version', 3),\n",
       " ('gener AI tool', 3),\n",
       " ('work', 3),\n",
       " ('automat evalu metric', 3),\n",
       " ('visual chatgpt', 3),\n",
       " ('discuss', 3),\n",
       " ('human prefer', 3),\n",
       " ('imag caption', 3),\n",
       " ('gener AI model', 3),\n",
       " ('emot support', 3),\n",
       " ('manag', 3),\n",
       " ('factual', 3),\n",
       " ('comput scienc', 3),\n",
       " ('plm', 3),\n",
       " ('text data', 3),\n",
       " ('abstract', 3),\n",
       " ('idea', 3),\n",
       " ('train model', 3),\n",
       " ('comput program', 3),\n",
       " ('grammat error correct', 3),\n",
       " ('ethic issu', 3),\n",
       " ('detect method', 3),\n",
       " ('medic advic', 3),\n",
       " ('instruct data', 3),\n",
       " ('classifi', 3),\n",
       " ('human analyst', 3),\n",
       " ('classif', 3),\n",
       " ('graph structur', 3),\n",
       " ('search', 3),\n",
       " ('academ write', 3),\n",
       " ('set', 3),\n",
       " ('scientif write', 3),\n",
       " ('scenario', 3),\n",
       " ('latest version', 3),\n",
       " ('gener summari', 3),\n",
       " ('stabl diffus', 3),\n",
       " ('chatgpt-4', 3),\n",
       " ('error', 3),\n",
       " ('languag translat', 3),\n",
       " ('detector', 3),\n",
       " ('data collect', 3),\n",
       " ('ML', 3),\n",
       " ('gener languag model', 3),\n",
       " ('harm content', 3),\n",
       " ('safeti', 3),\n",
       " ('adversari exampl', 3),\n",
       " ('literatur', 3),\n",
       " ('academ commun', 3),\n",
       " ('scienc', 3),\n",
       " ('code gener task', 3),\n",
       " ('argument', 3),\n",
       " ('plan', 3),\n",
       " ('recent year', 3),\n",
       " ('human-lik text', 3),\n",
       " ('patient', 3),\n",
       " ('gener code', 3),\n",
       " ('construct', 3),\n",
       " ('graph data', 3),\n",
       " ('creativ write', 3),\n",
       " ('educ set', 3),\n",
       " ('RL', 3),\n",
       " ('understand', 3),\n",
       " ('automat metric', 3),\n",
       " ('synthet dataset', 3),\n",
       " ('methodolog', 3),\n",
       " ('reason process', 3),\n",
       " ('book', 3),\n",
       " ('genai tool', 3),\n",
       " ('multi-turn convers', 3),\n",
       " ('exampl', 3),\n",
       " ('cost', 3),\n",
       " ('train data', 3),\n",
       " ('control', 3),\n",
       " ('ner', 3),\n",
       " ('text classif', 3),\n",
       " ('vision-languag model', 3),\n",
       " ('code qualiti', 3),\n",
       " ('pre-train model', 3),\n",
       " ('knowledg represent', 3),\n",
       " ('reinforc learn', 3),\n",
       " ('potenti risk', 3),\n",
       " ('softwar develop', 3),\n",
       " ('futur', 3),\n",
       " ('vietnames student', 3),\n",
       " ('emot', 3),\n",
       " ('chat', 3),\n",
       " ('open-sourc model', 3),\n",
       " ('cours', 3),\n",
       " ('human instruct', 3),\n",
       " ('field', 3),\n",
       " ('public opinion', 3),\n",
       " ('scientif disciplin', 3),\n",
       " ('disrupt technolog', 2),\n",
       " ('posit sentiment', 2),\n",
       " ('gener content', 2),\n",
       " ('review articl', 2),\n",
       " ('drug discoveri', 2),\n",
       " ('advantag', 2),\n",
       " ('supervis model', 2),\n",
       " ('abstract summar model', 2),\n",
       " ('humor', 2),\n",
       " ('stanc detect task', 2),\n",
       " ('text classif task', 2),\n",
       " ('medic domain', 2),\n",
       " ('great potenti', 2),\n",
       " ('polit elect', 2),\n",
       " ('societi', 2),\n",
       " ('label', 2),\n",
       " ('respons AI', 2),\n",
       " ('ethic principl', 2),\n",
       " ('judgment', 2),\n",
       " ('advic', 2),\n",
       " ('case studi', 2),\n",
       " ('analog', 2),\n",
       " ('repair', 2),\n",
       " ('translat prompt', 2),\n",
       " ('googl translat', 2),\n",
       " ('multilingu translat', 2),\n",
       " ('chatbot respons', 2),\n",
       " ('social media', 2),\n",
       " ('social media data', 2),\n",
       " ('human respons', 2),\n",
       " ('ethic risk', 2),\n",
       " ('AI ethic', 2),\n",
       " ('apr', 2),\n",
       " ('patch', 2),\n",
       " ('patch gener', 2),\n",
       " ('incorrect patch', 2),\n",
       " ('valid', 2),\n",
       " ('linear regress', 2),\n",
       " ('medic benchmark', 2),\n",
       " ('natur languag convers', 2),\n",
       " ('profici', 2),\n",
       " ('undergraduate-level mathemat', 2),\n",
       " ('data visualis', 2),\n",
       " ('natur languag interfac', 2),\n",
       " ('AI regul', 2),\n",
       " ('construct industri', 2),\n",
       " ('correct respons', 2),\n",
       " ('chatgpt failur', 2),\n",
       " ('massiv amount', 2),\n",
       " ('systemat review', 2),\n",
       " ('nlu task', 2),\n",
       " ('deep learn', 2),\n",
       " ('gener AI system', 2),\n",
       " ('control group', 2),\n",
       " ('similar', 2),\n",
       " ('evolut', 2),\n",
       " ('nlp field', 2),\n",
       " ('chatgpt strength', 2),\n",
       " ('KG', 2),\n",
       " ('research area', 2),\n",
       " ('nlp techniqu', 2),\n",
       " ('specif task', 2),\n",
       " ('valuabl tool', 2),\n",
       " ('scheme', 2),\n",
       " ('medic field', 2),\n",
       " ('user experi', 2),\n",
       " ('transform model', 2),\n",
       " ('import aspect', 2),\n",
       " ('hate speech', 2),\n",
       " ('english text', 2),\n",
       " ('data sourc', 2),\n",
       " ('QA', 2),\n",
       " ('gpt', 2),\n",
       " ('document-level translat', 2),\n",
       " ('translat direct', 2),\n",
       " ('futur research direct', 2),\n",
       " ('graph learn', 2),\n",
       " ('googl search', 2),\n",
       " ('understand abil', 2),\n",
       " ('event extract', 2),\n",
       " ('red team', 2),\n",
       " ('attent mechan', 2),\n",
       " ('assist', 2),\n",
       " ('chatgpt model', 2),\n",
       " ('practic', 2),\n",
       " ('pattern', 2),\n",
       " ('prompt pattern', 2),\n",
       " ('polici model', 2),\n",
       " ('infer', 2),\n",
       " ('extern knowledg', 2),\n",
       " ('llm-gener respons', 2),\n",
       " ('robot applic', 2),\n",
       " ('time', 2),\n",
       " ('probabl', 2),\n",
       " ('zero-shot manner', 2),\n",
       " ('prompt templat', 2),\n",
       " ('softwar implement', 2),\n",
       " ('collabor', 2),\n",
       " ('cross-lingu transfer', 2),\n",
       " ('subsequ gener', 2),\n",
       " ('design process', 2),\n",
       " ('rlhf', 2),\n",
       " ('visual', 2),\n",
       " ('baselin', 2),\n",
       " ('specialis model', 2),\n",
       " ('optim problem', 2),\n",
       " ('event', 2),\n",
       " ('AI usag', 2),\n",
       " ('natur languag gener task', 2),\n",
       " ('nlg', 2),\n",
       " ('chatgpt evalu', 2),\n",
       " ('digit content', 2),\n",
       " ('demonstr', 2),\n",
       " ('demonstr exampl', 2),\n",
       " ('superior perform', 2),\n",
       " ('chatgpt output', 2),\n",
       " ('daili life', 2),\n",
       " ('multimod system', 2),\n",
       " ('creativ content', 2),\n",
       " ('gener AI technolog', 2),\n",
       " ('huge popular', 2),\n",
       " ('current dialogu system', 2),\n",
       " ('databas schema', 2),\n",
       " ('test question', 2),\n",
       " ('word', 2),\n",
       " ('optim', 2),\n",
       " ('competit', 2),\n",
       " ('fact', 2),\n",
       " ('healthcar provid', 2),\n",
       " ('fine-grain compress', 2),\n",
       " ('layer normal', 2),\n",
       " ('huge memori footprint', 2),\n",
       " ('transformer-bas model', 2),\n",
       " ('matrix multipl', 2),\n",
       " ('fine-tun model', 2),\n",
       " ('unstructur medic text', 2),\n",
       " ('comput', 2),\n",
       " ('vision', 2),\n",
       " ('creativ', 2),\n",
       " ('gai', 2),\n",
       " ('machin', 2),\n",
       " ('program languag', 2),\n",
       " ('gpt-4 perform', 2),\n",
       " ('scholarli research', 2),\n",
       " ('misinform', 2),\n",
       " ('exercis', 2),\n",
       " ('sota model', 2),\n",
       " ('gec', 2),\n",
       " ('github', 2),\n",
       " ('medic knowledg', 2),\n",
       " ('inform content', 2),\n",
       " ('theori', 2),\n",
       " ('model checkpoint', 2),\n",
       " ('annot task', 2),\n",
       " ('hazard analysi', 2),\n",
       " ('factual inconsist', 2),\n",
       " ('level', 2),\n",
       " ('classif task', 2),\n",
       " ('commonsens knowledg', 2),\n",
       " ('commonsens problem', 2),\n",
       " ('tip', 2),\n",
       " ('open-domain task', 2),\n",
       " ('commun', 2),\n",
       " ('research topic', 2),\n",
       " ('forc concept inventori', 2),\n",
       " ('diffus model', 2),\n",
       " ('deep gener model', 2),\n",
       " ('mistak', 2),\n",
       " ('histor text', 2),\n",
       " ('AI task', 2),\n",
       " ('hug face', 2),\n",
       " ('anecdot exampl', 2),\n",
       " ('FE', 2),\n",
       " ('engin', 2),\n",
       " ('model scale', 2),\n",
       " ('rate', 2),\n",
       " (\"llms' perform\", 2),\n",
       " ('chat model', 2),\n",
       " ('multi-turn dialogu', 2),\n",
       " ('in-depth analysi', 2),\n",
       " ('applic domain', 2),\n",
       " ('signific role', 2),\n",
       " ('term', 2),\n",
       " ('maximum number', 2),\n",
       " ('DL', 2),\n",
       " ('gener program', 2),\n",
       " ('step', 2),\n",
       " ('natur languag understand', 2),\n",
       " ('translat instruct', 2),\n",
       " ('languag gener', 2),\n",
       " ('evalu metric', 2),\n",
       " ('design knowledg', 2),\n",
       " ('world knowledg', 2),\n",
       " ('potenti applic', 2),\n",
       " ('cot', 2),\n",
       " ('specif', 2),\n",
       " ('incorrect answer', 2),\n",
       " ('item', 2),\n",
       " ('virtual assist', 2),\n",
       " ('condit', 2),\n",
       " ('machin learn', 2),\n",
       " ('openai chatgpt', 2),\n",
       " ('summari faith', 2),\n",
       " ('dialogu state track', 2),\n",
       " ('spoken languag understand', 2),\n",
       " ('strong perform', 2),\n",
       " ('aigc model', 2),\n",
       " ('privaci threat', 2),\n",
       " ('persona', 2),\n",
       " ('predict', 2),\n",
       " ('human rate', 2),\n",
       " ('phase', 2),\n",
       " ('tempor relat', 2),\n",
       " ('prompt techniqu', 2),\n",
       " ('difficulti', 2),\n",
       " ('crucial role', 2),\n",
       " ('gener concept', 2),\n",
       " ('gener public', 2),\n",
       " ('widespread adopt', 2),\n",
       " ('googl scholar', 2),\n",
       " ('accuraci', 2),\n",
       " ('argument write', 2),\n",
       " ('chines', 2),\n",
       " ('llama', 2),\n",
       " ('program repair', 2),\n",
       " ('chatgpt behavior', 2),\n",
       " ('perspect', 2),\n",
       " ('IR', 2),\n",
       " ('plug-and-play modul', 2),\n",
       " ('privaci concern', 2),\n",
       " ('textbook', 2),\n",
       " ('cskb', 2),\n",
       " ('domain expert', 2),\n",
       " ('explain', 2),\n",
       " ('ethic', 2),\n",
       " ('dall 2', 2),\n",
       " ('robot system', 2),\n",
       " ('applic scenario', 2),\n",
       " ('compani', 2),\n",
       " ('behavior', 2),\n",
       " ('architectur design', 2),\n",
       " ('program challeng', 2),\n",
       " ('multiple-choic question', 2),\n",
       " ('empir find', 2),\n",
       " ('medic text', 2),\n",
       " ('dialogu system', 2),\n",
       " ('human languag', 2),\n",
       " ('academ integr', 2),\n",
       " ('causal reason', 2),\n",
       " ('causal', 2),\n",
       " ('human intellig', 2),\n",
       " ('origin text', 2),\n",
       " ('robot abil', 2),\n",
       " ('numer understand', 2),\n",
       " ('tabular data', 2),\n",
       " ('tabular dataset', 2),\n",
       " ('case', 2),\n",
       " ('natur languag process task', 2),\n",
       " ('long document', 2),\n",
       " ('domain adapt', 2),\n",
       " ('relev respons', 2),\n",
       " ('inform retriev', 2),\n",
       " ('genai technolog', 2),\n",
       " ('instruction-tun lm', 2),\n",
       " ('unifi framework', 2),\n",
       " ('tech compani', 2),\n",
       " ('bing chat', 2),\n",
       " ('comput scienc educ', 2),\n",
       " ('chatgpt impact', 2),\n",
       " ('potenti impact', 2),\n",
       " ('impress capabl', 2),\n",
       " ('gener process', 2),\n",
       " ('suggest', 2),\n",
       " ('human annot', 2),\n",
       " ('convers bot', 2),\n",
       " ('gpt-4 model', 2),\n",
       " ('interpret', 2),\n",
       " ('knowledg base', 2),\n",
       " ('ai-gener imag', 2),\n",
       " ('search tool', 2),\n",
       " ('unit test', 2),\n",
       " ('step-by-step instruct', 2),\n",
       " ('target task', 2),\n",
       " ('websit', 2),\n",
       " ('content creation', 2),\n",
       " ('diagnosi', 2),\n",
       " ('divers', 2),\n",
       " ('impact', 2),\n",
       " ('3D', 2),\n",
       " ('comput vision', 2),\n",
       " ('gi', 2),\n",
       " ('logic', 2),\n",
       " ('human programm', 2),\n",
       " ('propos system', 2),\n",
       " ('multimod model', 2),\n",
       " ('recommend paradigm', 2),\n",
       " ('rule', 2),\n",
       " ('domain knowledg', 2),\n",
       " ('linguist capabl', 2),\n",
       " ('prompt design', 2),\n",
       " ('high-qual dataset', 2),\n",
       " ('app', 2),\n",
       " ('neg sentiment', 2),\n",
       " ('structur data', 2),\n",
       " ('token', 2),\n",
       " ('social bia', 2),\n",
       " ('physic world', 2),\n",
       " ('input text', 2),\n",
       " ('llm respons', 2),\n",
       " ('factual consist', 2),\n",
       " ('consist improv', 2),\n",
       " ('efl', 2),\n",
       " ('larg lm', 2),\n",
       " ('comment', 2),\n",
       " ('genaibot', 2),\n",
       " ('data annot', 2),\n",
       " ('paramet', 2),\n",
       " ('open-sourc code', 2),\n",
       " ('SE', 2),\n",
       " ('vietnames nation high school graduat examin', 2),\n",
       " ('civic educ', 2),\n",
       " ('convers system', 2),\n",
       " ('zero-shot learn', 2),\n",
       " ('synthet text', 2),\n",
       " ('ethic dilemma', 2),\n",
       " ('investor', 2),\n",
       " ('student model', 2),\n",
       " ('teacher model', 2),\n",
       " ('rational gener', 2),\n",
       " ('paradigm shift', 2),\n",
       " ('specif scenario', 2),\n",
       " ('hardwar', 2),\n",
       " ('hardwar engin', 2),\n",
       " ('largest model', 2),\n",
       " ('goal-ori dialogu', 2),\n",
       " ('interact evalu', 2),\n",
       " ('jailbreak prompt', 2),\n",
       " ('gener chat model', 2),\n",
       " ('high-qual text', 2),\n",
       " ('fact-check', 2),\n",
       " ('icl', 2),\n",
       " ('real-world data', 2),\n",
       " ('annot data', 2),\n",
       " ('zero-shot', 2),\n",
       " ('vlm', 2),\n",
       " ('larg vision-languag model', 2),\n",
       " ('agent', 2),\n",
       " ('evid', 2),\n",
       " ('drug', 2),\n",
       " ('privaci', 2),\n",
       " ('nlp benchmark', 2),\n",
       " ('fair', 2),\n",
       " ('systemat evalu', 2),\n",
       " ('gener respons', 2),\n",
       " ('robot task', 2),\n",
       " ('tabl', 2),\n",
       " ('practic applic', 2),\n",
       " ('log', 2),\n",
       " ('object', 2),\n",
       " ('shape', 2),\n",
       " ('3D shape', 2),\n",
       " ('AI assist', 2),\n",
       " ('process', 2),\n",
       " ('public attitud', 2),\n",
       " ('social media post', 2),\n",
       " ('opinion', 2),\n",
       " ('instruction-tun data', 2),\n",
       " ('train', 2),\n",
       " ('convers agent', 2),\n",
       " ('visual data', 2),\n",
       " ('natur', 2),\n",
       " ('product', 2),\n",
       " ('project', 2),\n",
       " ('coher text', 2),\n",
       " ('human-author text', 2),\n",
       " ('expert', 2),\n",
       " ('temperatur paramet', 2),\n",
       " ('comprehens evalu', 2),\n",
       " ('educ activ', 2),\n",
       " ('toxic', 2),\n",
       " ('relationship', 2),\n",
       " ('ppo', 2),\n",
       " ('text gener', 2),\n",
       " ('chatgpt-gener code', 2),\n",
       " ('attribut', 2),\n",
       " ('search engin', 2),\n",
       " ('patent', 2),\n",
       " ('bingchat', 2),\n",
       " ('jailbreak', 2),\n",
       " ('asr system', 2),\n",
       " ('visual input', 2),\n",
       " ('sentenc', 2),\n",
       " ('judgement', 2),\n",
       " (\"earli adopters' sentiment\", 1),\n",
       " ('earli chatgpt user', 1),\n",
       " ('disrupt', 1),\n",
       " ('topic model', 1),\n",
       " ('origin content', 1),\n",
       " ('origin thought', 1),\n",
       " ('origin contribut', 1),\n",
       " ('origin prose score', 1),\n",
       " ('classic ture test', 1),\n",
       " ('sequenti question', 1),\n",
       " ('lovelac 2.0', 1),\n",
       " ('paraphras identif', 1),\n",
       " ('effect paraphras detect', 1),\n",
       " ('paraphras impact detect capabl', 1),\n",
       " ('typolog', 1),\n",
       " ('refin typolog', 1),\n",
       " ('popular dataset', 1),\n",
       " ('explain AI', 1),\n",
       " ('potenti advantag', 1),\n",
       " ('drug discoveri process', 1),\n",
       " ('onlin exam', 1),\n",
       " ('oral exam', 1),\n",
       " ('foolproof solut', 1),\n",
       " ('academ misconduct', 1),\n",
       " ('realist text', 1),\n",
       " ('unsupervis model', 1),\n",
       " ('summari candid', 1),\n",
       " ('unsupervis pegasu', 1),\n",
       " ('unsupervis manner', 1),\n",
       " ('supervis setup', 1),\n",
       " ('re-rank summari candid', 1),\n",
       " ('summari output', 1),\n",
       " ('puzzl', 1),\n",
       " ('visuo-linguist puzzl', 1),\n",
       " ('smart-101', 1),\n",
       " ('smart-101 dataset', 1),\n",
       " ('neural network', 1),\n",
       " ('deep neural network', 1),\n",
       " ('elementari skill', 1),\n",
       " ('broad skill', 1),\n",
       " ('poetri', 1),\n",
       " ('end-to-end model', 1),\n",
       " ('end-to-end poetri gener', 1),\n",
       " ('german quatrain', 1),\n",
       " ('token-fre decoder-onli languag model', 1),\n",
       " ('prior knowledg', 1),\n",
       " ('state-of-the-art poetri gener system', 1),\n",
       " ('task-specif model pipelin', 1),\n",
       " ('incorpor prior knowledg', 1),\n",
       " ('humor paper titl', 1),\n",
       " ('funni titl', 1),\n",
       " ('automat system', 1),\n",
       " ('2.5k titl', 1),\n",
       " ('end-to-end abstract-to-titl gener problem', 1),\n",
       " ('fine-tun system', 1),\n",
       " ('large-scal humor', 1),\n",
       " ('end-to-end system perform', 1),\n",
       " ('evas', 1),\n",
       " ('defens evas', 1),\n",
       " ('cybersecur question', 1),\n",
       " ('payment-fulfil ransomwar', 1),\n",
       " ('mitr att', 1),\n",
       " ('complex cybersecur goal', 1),\n",
       " ('logic bomb', 1),\n",
       " ('question-and-answ format', 1),\n",
       " ('credenti access', 1),\n",
       " ('surpris featur', 1),\n",
       " ('physic essay', 1),\n",
       " ('short-form essay', 1),\n",
       " ('pm 2', 1),\n",
       " ('pm 5', 1),\n",
       " ('pm 1', 1),\n",
       " ('short-form', 1),\n",
       " ('current univers physic modul', 1),\n",
       " ('current AI mlp', 1),\n",
       " ('stanc detect refer', 1),\n",
       " ('deep learn model', 1),\n",
       " ('nov 30', 1),\n",
       " ('rule-bas model', 1),\n",
       " ('medic report', 1),\n",
       " ('simplifi report', 1),\n",
       " ('radiologist', 1),\n",
       " ('15 radiologist', 1),\n",
       " ('harm passag', 1),\n",
       " ('key medic find', 1),\n",
       " ('patient-cent care', 1),\n",
       " ('twenti question', 1),\n",
       " ('guess 94', 1),\n",
       " ('spanish question', 1),\n",
       " ('question context', 1),\n",
       " ('classic twenty-quest game', 1),\n",
       " ('bilingu game', 1),\n",
       " ('neurosci metadata', 1),\n",
       " ('switch role', 1),\n",
       " ('question-answ role', 1),\n",
       " ('nation-agnost polit compass test', 1),\n",
       " ('2021 elect', 1),\n",
       " ('die Gr', 1),\n",
       " ('democrat societi', 1),\n",
       " ('left-libertarian ideolog', 1),\n",
       " ('undni 90', 1),\n",
       " ('walk', 1),\n",
       " ('downstair', 1),\n",
       " ('open fridg', 1),\n",
       " ('share structur', 1),\n",
       " ('integ id', 1),\n",
       " ('activ track', 1),\n",
       " ('open door', 1),\n",
       " ('human activ recognit', 1),\n",
       " ('honeypot interfac', 1),\n",
       " ('cyber secur', 1),\n",
       " ('dynam honeypot', 1),\n",
       " ('perimet secur', 1),\n",
       " ('data secur', 1),\n",
       " ('cyber secur postur', 1),\n",
       " ('potenti honeypot interfac', 1),\n",
       " ('interfac', 1),\n",
       " ('command-lin attack', 1),\n",
       " ('main model', 1),\n",
       " ('main gener model', 1),\n",
       " ('dreamfus model', 1),\n",
       " ('phenaki model', 1),\n",
       " ('audiolm model', 1),\n",
       " ('dalle-2 model', 1),\n",
       " ('flamingo model', 1),\n",
       " ('galactica model', 1),\n",
       " ('respons AI pattern catalogu', 1),\n",
       " ('respons AI challeng', 1),\n",
       " ('pattern-ori respons AI engin approach', 1),\n",
       " ('narrow set', 1),\n",
       " ('discuss worldwid', 1),\n",
       " ('moral judgment', 1),\n",
       " (\"users' moral judgment\", 1),\n",
       " ('moral advisor', 1),\n",
       " ('consist moral advic', 1),\n",
       " ('contradictori moral belief', 1),\n",
       " ('chat bot', 1),\n",
       " ('digit literaci', 1),\n",
       " ('human question', 1),\n",
       " ('collect dataset', 1),\n",
       " ('human chatgpt comparison corpu', 1),\n",
       " ('hc3 dataset', 1),\n",
       " ('comprehens human evalu', 1),\n",
       " ('hc3', 1),\n",
       " ('abstract concept', 1),\n",
       " ('theoret swampland conjectur', 1),\n",
       " ('full confid', 1),\n",
       " ('visual represent', 1),\n",
       " ('fals inform', 1),\n",
       " ('statement', 1),\n",
       " ('standard program repair approach', 1),\n",
       " ('autom program repair', 1),\n",
       " ('softwar bug', 1),\n",
       " ('standard bug', 1),\n",
       " ('program repair techniqu', 1),\n",
       " ('recent program repair method', 1),\n",
       " ('40 bug', 1),\n",
       " ('translat robust', 1),\n",
       " ('commerci translat product', 1),\n",
       " ('distant languag', 1),\n",
       " ('provid respons', 1),\n",
       " (\"patients' question\", 1),\n",
       " ('patient question', 1),\n",
       " ('averag age', 1),\n",
       " ('patient-provid commun', 1),\n",
       " ('trust', 1),\n",
       " ('keyphras', 1),\n",
       " ('keyphras extract', 1),\n",
       " ('theme-driven keyphras extract', 1),\n",
       " ('human-annot keyphras', 1),\n",
       " ('relev keyphras', 1),\n",
       " ('theme-driven keyphras extract framework', 1),\n",
       " ('unsupervis keyphras extract model', 1),\n",
       " ('extract task', 1),\n",
       " ('de-facto arbit', 1),\n",
       " ('truth', 1),\n",
       " ('truth-evalu capac', 1),\n",
       " ('social', 1),\n",
       " ('promis vector', 1),\n",
       " ('AI truth-tel', 1),\n",
       " ('social practic', 1),\n",
       " ('social feedback mechan', 1),\n",
       " ('introductori physic cours', 1),\n",
       " ('actual calculus-bas physic', 1),\n",
       " ('frequent indistinguish', 1),\n",
       " ('human-gener phraseolog', 1),\n",
       " ('begin learner', 1),\n",
       " ('standard content', 1),\n",
       " ('singl solut', 1),\n",
       " ('design solut', 1),\n",
       " ('multipl sourc code solut', 1),\n",
       " ('divers solut space', 1),\n",
       " ('work-in-progress prototyp', 1),\n",
       " ('programming-rel queri', 1),\n",
       " ('complex queri', 1),\n",
       " ('problem-solv skill', 1),\n",
       " ('ethic llm', 1),\n",
       " ('ethic danger', 1),\n",
       " ('ethic hazard', 1),\n",
       " ('ethic difficulti', 1),\n",
       " ('recent llm', 1),\n",
       " ('llm applic', 1),\n",
       " ('respons llm', 1),\n",
       " ('convers apr', 1),\n",
       " ('apr approach', 1),\n",
       " ('convers manner', 1),\n",
       " ('prior approach', 1),\n",
       " ('valid feedback', 1),\n",
       " ('numeraci', 1),\n",
       " ('emerg numeraci', 1),\n",
       " ('categor sum', 1),\n",
       " ('eighteen month', 1),\n",
       " ('random row', 1),\n",
       " ('statist analysi', 1),\n",
       " ('next-token predict', 1),\n",
       " ('descript statist', 1),\n",
       " ('python librari', 1),\n",
       " ('causal discoveri', 1),\n",
       " ('causal discoveri question', 1),\n",
       " ('previou larg languag model', 1),\n",
       " ('Tu', 1),\n",
       " ('2019', 1),\n",
       " ('chatgpt-gener review', 1),\n",
       " ('origin human-gener review', 1),\n",
       " ('chatgpt text', 1),\n",
       " ('short onlin review', 1),\n",
       " ('seemingly-human repli', 1),\n",
       " ('atyp vocabulari', 1),\n",
       " ('graduate-level mathemat', 1),\n",
       " ('formal mathemat', 1),\n",
       " ('natural-languag mathemat', 1),\n",
       " ('mathemat perform', 1),\n",
       " ('mathemat capabl', 1),\n",
       " ('mathemat assist', 1),\n",
       " ('elementari mathemat', 1),\n",
       " ('visualis', 1),\n",
       " ('nli', 1),\n",
       " ('workabl nli', 1),\n",
       " ('natur languag queri', 1),\n",
       " ('nli system', 1),\n",
       " ('free-form natur languag', 1),\n",
       " ('lgaim', 1),\n",
       " ('lgaim develop', 1),\n",
       " ('lgaim set', 1),\n",
       " ('lgaim output', 1),\n",
       " ('high-risk oblig', 1),\n",
       " ('regul', 1),\n",
       " ('trustworthi AI regul', 1),\n",
       " ('concret high-risk applic', 1),\n",
       " ('construct schedul', 1),\n",
       " ('simpl construct project', 1),\n",
       " ('coher schedul', 1),\n",
       " ('interact experi', 1),\n",
       " ('time-consum task', 1),\n",
       " ('posit interact experi', 1),\n",
       " ('correct explan', 1),\n",
       " ('fervent discuss', 1),\n",
       " ('common question', 1),\n",
       " ('form', 1),\n",
       " ('eleven categori', 1),\n",
       " ('human inquiri', 1),\n",
       " ('societ implic', 1),\n",
       " ('prior public chatbot', 1),\n",
       " ('comprehens answer', 1),\n",
       " ('broad rang', 1),\n",
       " ('review boolean queri', 1),\n",
       " ('systemat review research', 1),\n",
       " ('high-qual systemat review', 1),\n",
       " ('invalid review', 1),\n",
       " ('rapid review', 1),\n",
       " ('review cost', 1),\n",
       " ('comprehens review', 1),\n",
       " ('review topic', 1),\n",
       " ('star', 1),\n",
       " ('star framework', 1),\n",
       " ('goal-direct asp', 1),\n",
       " ('goal-direct convers', 1),\n",
       " ('asp', 1),\n",
       " ('qualit reason', 1),\n",
       " ('non-textu reason', 1),\n",
       " ('unreli reason', 1),\n",
       " ('induct reason', 1),\n",
       " ('commonsens reason', 1),\n",
       " ('23 data set', 1),\n",
       " ('extrins hallucin', 1),\n",
       " ('parametr memori', 1),\n",
       " ('cosmolog', 1),\n",
       " ('cosmolog constant lambda', 1),\n",
       " ('hubbl constant', 1),\n",
       " ('cosmolog paramet', 1),\n",
       " ('shallow learn', 1),\n",
       " ('photometr redshift', 1),\n",
       " (\"killer applications'\", 1),\n",
       " ('clumpi factor', 1),\n",
       " ('plagiar check', 1),\n",
       " ('plagiar check softwar', 1),\n",
       " ('potenti plagiar issu', 1),\n",
       " ('popular plagiar detect tool', 1),\n",
       " ('popular AI chatbot', 1),\n",
       " ('academ essay', 1),\n",
       " ('experiment group', 1),\n",
       " ('essay score', 1),\n",
       " (\"students' essay\", 1),\n",
       " ('essay element', 1),\n",
       " ('human evolut', 1),\n",
       " ('human endeavor', 1),\n",
       " ('vice versa', 1),\n",
       " ('post-pandem era', 1),\n",
       " ('scholarli discours', 1),\n",
       " ('underli psycholog principl', 1),\n",
       " ('linguist ambigu', 1),\n",
       " ('modern nlp', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(key5Counter.items(), key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropSet = set(['chatgpt','larg languag model','llm','model','paper','studi','research','result','AI','languag model','openai chatgpt','languag','natur languag process','openai chatgpt','natur languag','AI model','foundat model','chatgpt abil','pre-train languag model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                        64\n",
      "dataset                      48\n",
      "data                         43\n",
      "questions                    39\n",
      "performance                  36\n",
      "humans                       30\n",
      "prompts                      30\n",
      "text                         27\n",
      "code                         26\n",
      "Generative                   24\n",
      "evaluations                  22\n",
      "education                    21\n",
      "responses                    20\n",
      "system                       20\n",
      "frameworks                   19\n",
      "Users                        19\n",
      "abilities                    18\n",
      "instruction                  18\n",
      "chatbot                      17\n",
      "problems                     17\n",
      "knowledge                    17\n",
      "information                  17\n",
      "students                     17\n",
      "ChatGPT performance          16\n",
      "program                      16\n",
      "Answers                      16\n",
      "tool                         16\n",
      "method                       15\n",
      "approaches                   15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=15)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "n = 30\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:28} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combo_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downstream finance               5.730453\n",
      "models for financial             5.250000\n",
      "finance tasks                    4.980453\n",
      "financial text                   4.980453\n",
      "language models                  4.980453\n",
      "results on downstream            4.500000\n",
      "models for financial text        4.160906\n",
      "results on downstream finance    4.160906\n",
      "downstream finance tasks         3.961500\n",
      "language models for financial    3.200000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(ChatGPTf['abstract'].values[0])\n",
    "print(doc._.combo_basic.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于词频，看具体的月份 (效果一般，看不出特别的词)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2022-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                0.042105\n",
      "dataset              0.042105\n",
      "data                 0.031579\n",
      "text                 0.031579\n",
      "performance          0.031579\n",
      "method               0.021053\n",
      "tool                 0.021053\n",
      "questions            0.021053\n",
      "works                0.021053\n",
      "challenge            0.021053\n",
      "ability              0.021053\n",
      "humans               0.021053\n",
      "pre-tuned NLP model  0.010526\n",
      "findings             0.010526\n"
     ]
    }
   ],
   "source": [
    "month = '12'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:20} {1:f}'.format(stem2raw[k], v/sum(key5Counter.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions            0.029586\n",
      "tasks                0.023669\n",
      "dataset              0.023669\n",
      "ability              0.023669\n",
      "prompts              0.017751\n",
      "findings             0.017751\n",
      "performance          0.017751\n",
      "limitations          0.017751\n",
      "generation           0.011834\n",
      "humans               0.011834\n",
      "method               0.011834\n",
      "AI systems           0.011834\n",
      "information          0.011834\n",
      "text                 0.011834\n"
     ]
    }
   ],
   "source": [
    "month = '01'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:20} {1:f}'.format(stem2raw[k], v/sum(key5Counter.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                0.038860\n",
      "performance          0.031088\n",
      "data                 0.020725\n",
      "evaluation           0.020725\n",
      "questions            0.018135\n",
      "prompts              0.018135\n",
      "ChatGPT performance  0.015544\n",
      "responses            0.012953\n",
      "humans               0.012953\n",
      "dataset              0.012953\n",
      "capabilities         0.007772\n",
      "code                 0.007772\n",
      "development          0.007772\n",
      "method               0.007772\n"
     ]
    }
   ],
   "source": [
    "month = '02'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:20} {1:f}'.format(stem2raw[k], v/sum(key5Counter.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                0.043321\n",
      "performance          0.031288\n",
      "data                 0.015644\n",
      "prompts              0.015644\n",
      "questions            0.014440\n",
      "humans               0.014440\n",
      "code                 0.014440\n",
      "capabilities         0.012034\n",
      "dataset              0.012034\n",
      "generation           0.010830\n",
      "evaluation           0.009627\n",
      "challenge            0.009627\n",
      "effectiveness        0.008424\n",
      "ChatGPT performance  0.008424\n"
     ]
    }
   ],
   "source": [
    "month = '03'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:20} {1:f}'.format(stem2raw[k], v/sum(key5Counter.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance          0.041301\n",
      "tasks                0.041301\n",
      "data                 0.021090\n",
      "evaluation           0.017575\n",
      "prompts              0.015817\n",
      "dataset              0.014938\n",
      "humans               0.014060\n",
      "challenge            0.013181\n",
      "potentials           0.012302\n",
      "generation           0.012302\n",
      "findings             0.010545\n",
      "approach             0.009666\n",
      "systems              0.009666\n",
      "ChatGPT performance  0.009666\n"
     ]
    }
   ],
   "source": [
    "month = '04'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:20} {1:f}'.format(stem2raw[k], v/sum(key5Counter.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                0.037237\n",
      "performance          0.034234\n",
      "data                 0.024024\n",
      "dataset              0.015616\n",
      "method               0.014414\n",
      "code                 0.014414\n",
      "humans               0.013213\n",
      "potentials           0.012613\n",
      "evaluation           0.012613\n",
      "prompts              0.011411\n",
      "generation           0.010811\n",
      "challenge            0.010210\n",
      "text                 0.010210\n",
      "capabilities         0.009610\n"
     ]
    }
   ],
   "source": [
    "month = '05'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:20} {1:f}'.format(stem2raw[k], v/sum(key5Counter.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                0.043796\n",
      "performance          0.036496\n",
      "dataset              0.019812\n",
      "data                 0.018770\n",
      "method               0.016684\n",
      "humans               0.016684\n",
      "code                 0.011470\n",
      "prompts              0.011470\n",
      "questions            0.010428\n",
      "effectiveness        0.010428\n",
      "capabilities         0.010428\n",
      "potentials           0.010428\n",
      "development          0.009385\n",
      "Generative AI        0.009385\n"
     ]
    }
   ],
   "source": [
    "month = '06'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:20} {1:f}'.format(stem2raw[k], v/sum(key5Counter.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance          0.040698\n",
      "tasks                0.027616\n",
      "data                 0.026163\n",
      "potentials           0.015988\n",
      "generation           0.015988\n",
      "challenge            0.014535\n",
      "text                 0.014535\n",
      "prompts              0.013081\n",
      "development          0.013081\n",
      "effectiveness        0.011628\n",
      "systems              0.011628\n",
      "code                 0.011628\n",
      "dataset              0.010174\n",
      "code generation      0.008721\n"
     ]
    }
   ],
   "source": [
    "month = '07'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelTF.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:20} {1:f}'.format(stem2raw[k], v/sum(key5Counter.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于lexrank，看具体的月份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropSet = set(['chatgpt','larg languag model','llm','model','paper','studi','research','result','AI','languag model','openai chatgpt','languag','natur languag process','openai chatgpt','natur languag','AI model','foundat model','chatgpt abil','pre-train languag model', 'nlp', 'larg gener model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37 2022-12 & 2023-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions                      4\n",
      "dataset                        3\n",
      "technologies                   2\n",
      "potential                      2\n",
      "solutions                      2\n",
      "text                           2\n",
      "human-generated text           2\n",
      "humans                         2\n",
      "great potential                2\n",
      "AI systems                     2\n",
      "responses                      2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '01'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month) | (ChatGPTf['month'] =='12') ]['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 1:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 59 2023-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions                      3\n",
      "tasks                          3\n",
      "prompts                        3\n",
      "current version                3\n",
      "data                           3\n",
      "Answers                        2\n",
      "tool                           2\n",
      "failures                       2\n",
      "frameworks                     2\n",
      "data sets                      2\n",
      "learning                       2\n",
      "essays                         2\n",
      "NLP tasks                      2\n",
      "dataset                        2\n",
      "translation                    2\n",
      "translation quality            2\n",
      "attention                      2\n",
      "prompt engineering             2\n",
      "prompt engineering techniques  2\n",
      "performance                    2\n",
      "responses                      2\n",
      "robotics                       2\n",
      "robotics applications          2\n",
      "prompt templates               2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '02'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 1:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 126 2023-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problems                       6\n",
      "tasks                          6\n",
      "prompts                        6\n",
      "dataset                        6\n",
      "humans                         5\n",
      "questions                      5\n",
      "data                           4\n",
      "performance                    3\n",
      "version                        3\n",
      "content                        3\n",
      "images                         3\n",
      "capabilities                   3\n",
      "exams                          3\n",
      "Artificial intelligence        3\n",
      "machine translation            3\n",
      "information                    3\n",
      "Generative                     3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '03'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 2:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 171 2023-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                          11\n",
      "data                           8\n",
      "text                           5\n",
      "humans                         5\n",
      "dataset                        5\n",
      "performance                    5\n",
      "code                           5\n",
      "Artificial intelligence        4\n",
      "instruction                    4\n",
      "program                        4\n",
      "Users                          4\n",
      "content                        4\n",
      "Generative                     4\n",
      "education                      4\n",
      "evaluations                    3\n",
      "method                         3\n",
      "translation                    3\n",
      "knowledge                      3\n",
      "ChatGPT performance            3\n",
      "Google Bard                    3\n",
      "analysis                       3\n",
      "responses                      3\n",
      "ChatGPT responses              3\n",
      "students                       3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '04'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 2:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 249 2023-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                          14\n",
      "data                           12\n",
      "code                           9\n",
      "Generative                     8\n",
      "dataset                        8\n",
      "instruction                    7\n",
      "text                           7\n",
      "evaluations                    7\n",
      "benchmark                      5\n",
      "images                         5\n",
      "system                         5\n",
      "questions                      5\n",
      "performance                    5\n",
      "source code                    4\n",
      "recommendations                4\n",
      "humans                         4\n",
      "content                        4\n",
      "code generation                4\n",
      "tool                           4\n",
      "reason                         4\n",
      "knowledge                      4\n",
      "chatbot                        4\n",
      "prompts                        4\n",
      "LMs                            4\n",
      "students                       4\n",
      "generative models              4\n",
      "examples                       3\n",
      "translation                    3\n",
      "control                        3\n",
      "text classification            3\n",
      "Artificial intelligence        3\n",
      "detection                      3\n",
      "tests                          3\n",
      "Instruction tuning             3\n",
      "attacks                        3\n",
      "GPT-4                          3\n",
      "memory                         3\n",
      "wide range                     3\n",
      "program                        3\n",
      "Generative AI                  3\n",
      "reinforcement learning         3\n",
      "potential risks                3\n",
      "problems                       3\n",
      "software engineering           3\n",
      "future                         3\n",
      "Answers                        3\n",
      "abilities                      3\n",
      "dialogues                      3\n",
      "correct answers                3\n",
      "open-source models             3\n",
      "reward models                  3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '05'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 2:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 149 2023-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks                          8\n",
      "questions                      7\n",
      "dataset                        7\n",
      "assessment                     4\n",
      "detection                      4\n",
      "outputs                        4\n",
      "data                           4\n",
      "information                    4\n",
      "education                      4\n",
      "Sentiment analysis             4\n",
      "program                        3\n",
      "text                           3\n",
      "summaries                      3\n",
      "mathematics                    3\n",
      "Answers                        3\n",
      "instruction                    3\n",
      "responses                      3\n",
      "evaluations                    3\n",
      "learning                       3\n",
      "humans                         3\n",
      "knowledge                      3\n",
      "code                           3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '06'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 2:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 108 2023-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data                           7\n",
      "text                           7\n",
      "code                           4\n",
      "questions                      4\n",
      "tool                           3\n",
      "AI systems                     3\n",
      "Bard                           3\n",
      "performance                    3\n",
      "system                         3\n",
      "responses                      3\n",
      "knowledge graph                3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '07'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['abstract']:\n",
    "    results = modelLexRank.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 2:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标题：论文数量增加，仍主要以评价为主"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf\n",
    "modelTFt = kex.TF()\n",
    "test_sentences = list(ChatGPTf['title'].values)\n",
    "modelTFt.train(test_sentences, export_directory='./tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 18:06:13 INFO     adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2023-08-07 18:06:13 INFO     built Dictionary(1903 unique tokens: ['\"', ':', 'adopt', 'chatgpt', 'data']...) from 899 documents (total 7805 corpus positions)\n",
      "2023-08-07 18:06:13 INFO     collecting document frequencies\n",
      "2023-08-07 18:06:13 INFO     PROGRESS: processing document #0\n",
      "2023-08-07 18:06:13 INFO     calculating IDF weights for 899 documents and 1902 features (7581 matrix non-zeros)\n",
      "2023-08-07 18:06:13 INFO     saving TfidfModel object under ./tmp\\tfidf_model, separately None\n",
      "2023-08-07 18:06:13 INFO     saved ./tmp\\tfidf_model\n",
      "2023-08-07 18:06:13 INFO     saving dictionary mapping to ./tmp\\tfidf_dict\n"
     ]
    }
   ],
   "source": [
    "#TFIDFRank\n",
    "modelTFIDFRankt = kex.TFIDFRank()\n",
    "test_sentences = list(ChatGPTf['title'].values)\n",
    "modelTFIDFRankt.train(test_sentences, export_directory='./tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "key5Counter = Counter()\n",
    "stem2raw = {}\n",
    "for ab in ChatGPTf['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        stem2raw[item['stemmed']] = item['raw'][0]\n",
    "        key5Counter[item['stemmed']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropSet = set(['chatgpt','larg languag model','llm','model','paper','studi','research','result','AI','languag model','openai chatgpt','languag','natur languag process','openai chatgpt','natur languag','AI model','foundat model','chatgpt abil','pre-train languag model','gener larg languag model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT                      302\n",
      "Large Language Model         118\n",
      "Evaluation                   24\n",
      "Generative AI                22\n",
      "GPT-4                        21\n",
      "AI                           19\n",
      "LLMs                         19\n",
      "Potential                    17\n",
      "Challenges                   16\n",
      "Language Models              16\n",
      "Empirical Study              16\n",
      "Case Study                   15\n",
      "Education                    15\n",
      "Survey                       12\n",
      "Application                  12\n",
      "Detection                    11\n",
      "Limitations                  11\n",
      "Cases                        10\n",
      "comprehensive evaluation     9\n",
      "Preliminary Study            9\n",
      "Study                        9\n",
      "Opportunities                8\n",
      "Chatbots                     8\n",
      "Human                        8\n",
      "Era                          8\n",
      "Generation                   7\n",
      "analysis                     7\n",
      "Bias                         7\n",
      "Perspectives                 7\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:28} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation                   24\n",
      "Generative AI                22\n",
      "GPT-4                        21\n",
      "Potential                    17\n",
      "Challenges                   16\n",
      "Empirical Study              16\n",
      "Case Study                   15\n",
      "Education                    15\n",
      "Survey                       12\n",
      "Application                  12\n",
      "Detection                    11\n",
      "Limitations                  11\n",
      "Cases                        10\n",
      "comprehensive evaluation     9\n",
      "Preliminary Study            9\n",
      "Opportunities                8\n",
      "Chatbots                     8\n",
      "Human                        8\n",
      "Era                          8\n",
      "Generation                   7\n",
      "analysis                     7\n",
      "Bias                         7\n",
      "Perspectives                 7\n",
      "Practices                    7\n",
      "Social Media                 7\n",
      "Performance                  7\n",
      "Evidence                     6\n",
      "Impact                       6\n",
      "Power                        6\n"
     ]
    }
   ],
   "source": [
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "n = 30\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:28} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDFRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key5Counter = Counter()\n",
    "stem2raw = {}\n",
    "for ab in ChatGPTf['title']:\n",
    "    results = modelTFIDFRankt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        stem2raw[item['stemmed']] = item['raw'][0]\n",
    "        key5Counter[item['stemmed']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT                      301\n",
      "Large Language Model         118\n",
      "Evaluation                   24\n",
      "Generative AI                22\n",
      "GPT-4                        21\n",
      "AI                           19\n",
      "LLMs                         19\n",
      "Potential                    17\n",
      "Challenges                   16\n",
      "Language Models              16\n",
      "Empirical Study              16\n",
      "Case Study                   15\n",
      "Education                    15\n",
      "Survey                       12\n",
      "Application                  12\n",
      "Detection                    11\n",
      "Limitations                  11\n",
      "Cases                        10\n",
      "comprehensive evaluation     9\n",
      "Preliminary Study            9\n",
      "Study                        9\n",
      "Opportunities                8\n",
      "Chatbots                     8\n",
      "Human                        8\n",
      "Era                          8\n",
      "Generation                   7\n",
      "analysis                     7\n",
      "Bias                         7\n",
      "Perspectives                 7\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:28} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation                   24\n",
      "Generative AI                22\n",
      "GPT-4                        21\n",
      "Potential                    17\n",
      "Challenges                   16\n",
      "Empirical Study              16\n",
      "Case Study                   15\n",
      "Education                    15\n",
      "Survey                       12\n",
      "Application                  12\n",
      "Detection                    11\n",
      "Limitations                  11\n",
      "Cases                        10\n",
      "comprehensive evaluation     9\n",
      "Preliminary Study            9\n",
      "Opportunities                8\n",
      "Chatbots                     8\n",
      "Human                        8\n",
      "Era                          8\n",
      "Generation                   7\n",
      "analysis                     7\n",
      "Bias                         7\n",
      "Perspectives                 7\n",
      "Practices                    7\n",
      "Social Media                 7\n",
      "Performance                  7\n",
      "Evidence                     6\n",
      "Impact                       6\n",
      "Power                        6\n"
     ]
    }
   ],
   "source": [
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf['title']:\n",
    "    results = modelTFIDFRankt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "n = 30\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    print('{0:28} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看具体的月份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "05    249\n",
       "04    171\n",
       "06    149\n",
       "03    126\n",
       "07    108\n",
       "02     59\n",
       "01     24\n",
       "12     13\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ChatGPTf['month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2022-12 & 2023-01**\n",
    "\n",
    "**37** papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbots                       3\n",
      "Detection                      2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '12'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month) | (ChatGPTf['month'] == '01')]['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    if v>1:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbots in a Botnet World\n",
      "Chatbots as Problem Solvers: Playing Twenty Questions with Role Reversals\n",
      "Chatbots in a Honeypot World\n",
      "Developing Responsible Chatbots for Financial Services: A Pattern-Oriented Responsible AI Engineering Approach\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month1201 = ChatGPTf.loc[(ChatGPTf['month'] == month) | (ChatGPTf['month'] == '01')]\n",
    "for i in month1201.loc[month1201['title'].str.contains('Chatbots',flags=re.IGNORECASE)]['title']:\n",
    "    print(i)\n",
    "print()\n",
    "# for i in month1201.loc[month1201['title'].str.contains('detection',flags=re.IGNORECASE)]['title']:\n",
    "#     print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2023-02**\n",
    "\n",
    "**59** papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limitations                    3\n",
      "Evolution                      2\n",
      "BERT                           2\n",
      "Mis                            2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '02'\n",
    "key5Counter = Counter()\n",
    "n = 15\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    n -= 1\n",
    "    if n== 0:\n",
    "        break\n",
    "    if v>1:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech\n",
      "Exploring the Limits of ChatGPT for Query or Aspect-based Text Summarization\n",
      "Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations\n",
      "\n",
      "Deep Machine Learning in Cosmology: Evolution or Revolution?\n",
      "Combining Generative Artificial Intelligence (AI) and the Internet: Heading towards Evolution or Degradation?\n",
      "ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design\n",
      "\n",
      "How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study\n",
      "Talking Abortion (Mis)information with ChatGPT on TikTok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month02 = ChatGPTf.loc[(ChatGPTf['month'] == '02')]\n",
    "for i in month02.loc[month02['title'].str.contains('Limit',flags=re.IGNORECASE)]['title']:\n",
    "    print(i)\n",
    "print()\n",
    "for i in month02.loc[month02['title'].str.contains('Evolution',flags=re.IGNORECASE)]['title']:\n",
    "    print(i)\n",
    "print()\n",
    "for i in month02.loc[month02['title'].str.contains('Mis')]['title']:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2023-03**\n",
    "\n",
    "**126** papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4                          7\n",
      "Evaluation                     6\n",
      "Generative AI                  3\n",
      "Cases                          3\n",
      "Preliminary Study              3\n",
      "Human                          3\n",
      "Potential                      3\n",
      "Empirical Study                3\n",
      "Application                    3\n",
      "Survey                         3\n",
      "Case Study                     3\n",
      "Perspectives                   2\n",
      "AIGC                           2\n",
      "analysis                       2\n",
      "Ethics                         2\n",
      "Limitations                    2\n",
      "Future                         2\n",
      "Fundamentals                   2\n",
      "Education                      2\n",
      "Practices                      2\n",
      "Power                          2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '03'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v >1:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential\n",
      "DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4\n",
      "A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n",
      "Sparks of Artificial General Intelligence: Early experiments with GPT-4\n",
      "Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology\n",
      "Advances in apparent conceptual physics reasoning in GPT-4\n",
      "Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations\n",
      "\n",
      "Can ChatGPT Assess Human Personalities? A General Evaluation Framework\n",
      "Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT\n",
      "Art-ificial Intelligence: The Effect of AI Disclosure on Evaluations of Creative Content\n",
      "Evaluation of ChatGPT as a Question Answering System for Answering Complex Questions\n",
      "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation\n",
      "Can we trust the evaluation on ChatGPT?\n",
      "A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability\n",
      "Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT\n",
      "Evaluation of ChatGPT for NLP-based Mental Health Applications\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month02 = ChatGPTf.loc[(ChatGPTf['month'] == '03')]\n",
    "for i in month02.loc[month02['title'].str.contains('GPT-4',flags=re.IGNORECASE)]['title']:\n",
    "    print(i)\n",
    "print()\n",
    "for i in month02.loc[month02['title'].str.contains('Evaluation',flags=re.IGNORECASE)]['title']:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2023-04**\n",
    "\n",
    "**171** papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenges                     6\n",
      "Case Study                     4\n",
      "Evaluation                     4\n",
      "Opportunities                  4\n",
      "Potential                      4\n",
      "Perspectives                   3\n",
      "Empirical Study                3\n",
      "Power                          3\n",
      "Social Media                   3\n",
      "GPT-4                          3\n",
      "Generative AI                  3\n",
      "Preliminary Study              3\n",
      "Performance                    3\n",
      "Education                      3\n",
      "Survey                         3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month = '04'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v >2:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2023-05**\n",
    "\n",
    "**249** papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI                  7\n",
      "Evaluation                     7\n",
      "Empirical Study                6\n",
      "Detection                      6\n",
      "Challenges                     6\n",
      "Application                    5\n",
      "Code Generation                4\n",
      "Era                            4\n",
      "Case Study                     3\n",
      "GPTs                           3\n",
      "Human                          3\n",
      "Survey                         3\n",
      "Benchmark                      3\n",
      "comprehensive evaluation       3\n",
      "Reasoning                      3\n",
      "Performance                    3\n",
      "Texts                          3\n"
     ]
    }
   ],
   "source": [
    "month = '05'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v >2:\n",
    "        print('{0:30} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2023-06**\n",
    "\n",
    "**149** papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI                                                6\n",
      "Evaluation                                                   6\n",
      "GPT-4                                                        6\n",
      "Cases                                                        5\n",
      "Potential                                                    5\n",
      "Education                                                    4\n",
      "Vietnamese National High School Graduation Examination       3\n",
      "Case Study                                                   3\n"
     ]
    }
   ],
   "source": [
    "month = '06'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 2:\n",
    "        print('{0:60} {1:d}'.format(stem2raw[k], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2023-07**\n",
    "\n",
    "**108** papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical study                                              4\n",
      "Generative AI                                                3\n",
      "potential                                                    3\n",
      "education                                                    3\n"
     ]
    }
   ],
   "source": [
    "month = '07'\n",
    "key5Counter = Counter()\n",
    "for ab in ChatGPTf.loc[(ChatGPTf['month'] == month)]['title']:\n",
    "    results = modelTFt.get_keywords(ab, n_keywords=10)\n",
    "    for item in results:\n",
    "        if  item['stemmed'] in dropSet:\n",
    "            continue\n",
    "        else:\n",
    "            key5Counter[item['stemmed']] += 1\n",
    "for k,v in sorted(key5Counter.items(), key = lambda x: -x[1]):\n",
    "    if v > 2:\n",
    "        print('{0:60} {1:d}'.format(stem2raw[k], v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
